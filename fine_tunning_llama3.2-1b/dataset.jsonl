{"text": "Introduction  to Algorithms  \nFourth  Edition  Thomas H. Cormen \nCharles E. Leiserson \nRonald L. Rivest \nClifford Stein \nIntroduction  to Algorithms  \nFourth  Edition  \nThe MIT Press \nCambridge, Massachusetts London, England c \ue001  2022 Massachusetts Institute of Technology \nAll rights reserved. No part of this book may be reproduced in any form or by any elect ronic or mechanical means \n(including photocopying, recording, or information storage and retrieval) without permission in writ ing from the \npublisher. \nThe MIT Press would like to thank the anonymous peer reviewers who provided comment s on drafts of this book. \nThe generous work of academic experts is essential for establishing the authority and qua lity of our publications. \nWe acknowledge with gratitude the contributions of these otherwise uncredited reade rs. \nThis book was set in Times Roman and MathTime Professional II by the authors. \nNames: Cormen, Thomas H., author. j Leiserson, Charles Eric, author. j \nRivest, Ronald L., author. j Stein, Clifford, author. \nTitle: Introduction to algorithms / Thomas H. Cormen, Charles E. Leiserson, \nRonald L. Rivest, Clifford Stein. \nDescription: Fourth edition. j Cambridge, Massachusetts : The MIT Press, \n[2022] j Includes bibliographical references and index. \nIdenti\u00fbers:  LCCN  2021037260  j ISBN  9780262046305  \nSubjects: LCSH: Computer programming. j Computer algorithms. \nClassi\u00fbcation:  LCC  QA76.6  .C662  2022  j DDC  005.13--dc23  \nLC  record  available  at http://lccn.loc.gov/2021037260  \n10 9 8 7 6 5 4 3 2 1  Contents \nPreface  xiii  \nI Foundations  \nIntroduction  3 \n1 The  Role  of Algorithms  in Computing  5 \n1.1  Algorithms  5 \n1.2  Algorithms  as a technology  12 \n2 Getting  Started  17  \n2.1  Insertion  sort  17 \n2.2 Analyzing algorithms 25 \n2.3  Designing  algorithms  34 \n3 Characterizing  Running  Times  49  \n3.1  O-notation,  \ufffd-notation,  and  \u201a-notation  50 \n3.2  Asymptotic  notation:  formal  de\u00fbnitions  53 \n3.3  Standard  notations  and  common  functions  63 \n4 Divide-and-Conquer  76  \n4.1  Multiplying  square  matrices  80 \n4.2  Strassen\u2019s  algorithm  for  matrix  multiplication  85 \n4.3  The  substitution  method  for  solving  recurrences  90 \n4.4  The  recursion-tree  method  for  solving  recurrences  95 \n4.5  The  master  method  for  solving  recurrences  101 \n? 4.6  Proof  of the  continuous  master  theorem  107 \n? 4.7  Akra-Bazzi  recurrences  115 vi Contents \n5 Probabilistic  Analysis  and  Randomized  Algorithms  126  \n5.1  The  hiring  problem  126 \n5.2  Indicator  random  variables  130 \n5.3  Randomized  algorithms  134 \n? 5.4  Probabilistic  analysis  and  further  uses  of indicator  random variables \n140 \nII Sorting  and  Order  Statistics  \nIntroduction  157  \n6 Heapsort  161  \n6.1  Heaps  161 \n6.2  Maintaining  the  heap  property  164 \n6.3  Building  a heap  167 \n6.4  The  heapsort  algorithm  170 \n6.5  Priority  queues  172 \n7 Quicksort  182  \n7.1  Description  of quicksort  183 \n7.2  Performance  of quicksort  187 \n7.3  A randomized  version  of quicksort  191 \n7.4  Analysis  of quicksort  193 \n8 Sorting  in Linear  Time  205  \n8.1  Lower  bounds  for  sorting  205 \n8.2  Counting  sort  208 \n8.3  Radix  sort  211 \n8.4  Bucket  sort  215 \n9 Medians  and  Order  Statistics  227  \n9.1  Minimum  and  maximum  228 \n9.2 Selection in expected linear time 230 \n9.3  Selection  in worst-case  linear  time  236 \nIII  Data  Structures  \nIntroduction  249  \n10  Elementary  Data  Structures  252  \n10.1  Simple  array-based  data  structures:  arrays,  matrices , stacks, queues \n252 \n10.2  Linked  lists  258 \n10.3  Representing  rooted  trees  265 Contents vii \n11  Hash  Tables  272  \n11.1  Direct-address  tables  273 \n11.2  Hash  tables  275 \n11.3  Hash  functions  282 \n11.4  Open  addressing  293 \n11.5  Practical  considerations  301 \n12  Binary  Search  Trees  312  \n12.1  What  is a binary  search  tree?  312 \n12.2  Querying  a binary  search  tree  316 \n12.3  Insertion  and  deletion  321 \n13  Red-Black  Trees  331  \n13.1  Properties  of red-black  trees  331 \n13.2  Rotations  335 \n13.3  Insertion  338 \n13.4  Deletion  346 \nIV  Advanced  Design  and  Analysis  Techniques  \nIntroduction  361  \n14  Dynamic  Programming  362  \n14.1  Rod  cutting  363 \n14.2  Matrix-chain  multiplication  373 \n14.3  Elements  of dynamic  programming  382 \n14.4  Longest  common  subsequence  393 \n14.5  Optimal  binary  search  trees  400 \n15  Greedy  Algorithms  417  \n15.1  An  activity-selection  problem  418 \n15.2  Elements  of the  greedy  strategy  426 \n15.3  Huffman  codes  431 \n15.4  Of\u00fcine  caching  440 \n16  Amortized  Analysis  448  \n16.1  Aggregate  analysis  449 \n16.2  The  accounting  method  453 \n16.3  The  potential  method  456 \n16.4  Dynamic  tables  460 viii Contents \nV Advanced  Data  Structures  \nIntroduction  477  \n17  Augmenting  Data  Structures  480  \n17.1  Dynamic  order  statistics  480 \n17.2  How  to augment  a data  structure  486 \n17.3  Interval  trees  489 \n18  B-Trees  497  \n18.1  De\u00fbnition  of B-trees  501 \n18.2  Basic  operations  on  B-trees  504 \n18.3  Deleting  a key  from  a B-tree  513 \n19  Data  Structures  for  Disjoint  Sets  520  \n19.1  Disjoint-set  operations  520 \n19.2  Linked-list  representation  of disjoint  sets  523 \n19.3  Disjoint-set  forests  527 \n? 19.4  Analysis  of union  by  rank  with  path  compression  531 \nVI  Graph  Algorithms  \nIntroduction  547  \n20  Elementary  Graph  Algorithms  549  \n20.1  Representations  of graphs  549 \n20.2  Breadth-\u00fbrst  search  554 \n20.3  Depth-\u00fbrst  search  563 \n20.4  Topological  sort  573 \n20.5  Strongly  connected  components  576 \n21  Minimum  Spanning  Trees  585  \n21.1  Growing  a minimum  spanning  tree  586 \n21.2  The  algorithms  of Kruskal  and  Prim  591 \n22  Single-Source  Shortest  Paths  604  \n22.1  The  Bellman-Ford  algorithm  612 \n22.2  Single-source  shortest  paths  in directed  acyclic  graphs 616 \n22.3  Dijkstra\u2019s  algorithm  620 \n22.4  Difference  constraints  and  shortest  paths  626 \n22.5  Proofs  of shortest-paths  properties  633 Contents ix \n23  All-Pairs  Shortest  Paths  646  \n23.1  Shortest  paths  and  matrix  multiplication  648 \n23.2  The  Floyd-Warshall  algorithm  655 \n23.3  Johnson\u2019s  algorithm  for  sparse  graphs  662 \n24  Maximum  Flow  670  \n24.1  Flow  networks  671 \n24.2  The  Ford-Fulkerson  method  676 \n24.3  Maximum  bipartite  matching  693 \n25  Matchings  in Bipartite  Graphs  704  \n25.1  Maximum  bipartite  matching  (revisited)  705 \n25.2  The  stable-marriage  problem  716 \n25.3  The  Hungarian  algorithm  for  the  assignment  problem  723 \nVII  Selected  Topics  \nIntroduction  745  \n26  Parallel  Algorithms  748  \n26.1  The  basics  of fork-join  parallelism  750 \n26.2  Parallel  matrix  multiplication  770 \n26.3  Parallel  merge  sort  775 \n27  Online  Algorithms  791  \n27.1  Waiting  for  an elevator  792 \n27.2  Maintaining  a search  list  795 \n27.3  Online  caching  802 \n28  Matrix  Operations  819  \n28.1  Solving  systems  of linear  equations  819 \n28.2  Inverting  matrices  833 \n28.3  Symmetric  positive-de\u00fbnite  matrices  and  least-squar es approximation \n838 \n29  Linear  Programming  850  \n29.1  Linear  programming  formulations  and  algorithms  853 \n29.2 Formulating problems as linear programs 860 \n29.3  Duality  866 \n30  Polynomials  and  the  FFT  877  \n30.1  Representing  polynomials  879 \n30.2  The  DFT  and  FFT  885 \n30.3  FFT  circuits  894 x Contents \n31  Number-Theoretic  Algorithms  903  \n31.1  Elementary  number-theoretic  notions  904 \n31.2  Greatest  common  divisor  911 \n31.3  Modular  arithmetic  916 \n31.4  Solving  modular  linear  equations  924 \n31.5  The  Chinese  remainder  theorem  928 \n31.6  Powers  of an element  932 \n31.7  The  RSA  public-key  cryptosystem  936 \n? 31.8  Primality  testing  942 \n32  String  Matching  957  \n32.1  The  naive  string-matching  algorithm  960 \n32.2  The  Rabin-Karp  algorithm  962 \n32.3  String  matching  with  \u00fbnite  automata  967 \n? 32.4  The  Knuth-Morris-Pratt  algorithm  975 \n32.5  Suf\u00fbx  arrays  985 \n33  Machine-Learning  Algorithms  1003  \n33.1  Clustering  1005 \n33.2  Multiplicative-weights  algorithms  1015 \n33.3  Gradient  descent  1022 \n34  NP-Completeness  1042  \n34.1  Polynomial  time  1048 \n34.2  Polynomial-time  veri\u00fbcation  1056 \n34.3  NP-completeness  and  reducibility  1061 \n34.4  NP-completeness  proofs  1072 \n34.5  NP-complete  problems  1080 \n35  Approximation  Algorithms  1104  \n35.1  The  vertex-cover  problem  1106 \n35.2  The  traveling-salesperson  problem  1109 \n35.3  The  set-covering  problem  1115 \n35.4  Randomization  and  linear  programming  1119 \n35.5  The  subset-sum  problem  1124 \nVIII  Appendix:  Mathematical  Background  \nIntroduction  1139  \nA Summations  1140  \nA.1  Summation  formulas  and  properties  1140 \nA.2 Bounding summations 1145 Contents xi \nB Sets,  Etc.  1153  \nB.1  Sets  1153 \nB.2 Relations 1158 \nB.3  Functions  1161 \nB.4  Graphs  1164 \nB.5  Trees  1169 \nC Counting  and  Probability  1178  \nC.1  Counting  1178 \nC.2 Probability 1184 \nC.3  Discrete  random  variables  1191 \nC.4  The  geometric  and  binomial  distributions  1196 \n? C.5  The  tails  of the  binomial  distribution  1203 \nD Matrices  1214  \nD.1  Matrices  and  matrix  operations  1214 \nD.2 Basic matrix properties 1219 \nBibliography  1227  \nIndex  1251  Preface \nNot so long ago, anyone who had heard the word <alg orithm= was almost certainly \na computer scientist or mathematician. With compute rs having become prevalent in \nour modern lives, however, the term is no longer es oteric. If you look around your \nhome,  you\u2019ll  \u00fbnd  algorithms  running  in the  most  mundane  places: your microwave \noven, your washing machine, and, of course, your co mputer. You ask algorithms \nto make recommendations to you: what music you migh t like or what route to \ntake  when  driving.  Our  society,  for  better  or for  worse,  asks  algorithms to suggest \nsentences for convicted criminals. You even rely on  algorithms to keep you alive, \nor at least not to kill you: the control systems in  your car or in medical equipment. 1 \nThe word <algorithm= appears somewhere in the news seemingly every day. \nTherefore, it behooves you to understand algorithms  not just as a student or \npractitioner of computer science, but as a citizen of the world.  Once  you  understand  \nalgorithms, you can educate others about what algor ithms are, how they operate, \nand what their limitations are. \nThis book provides a comprehensive introduction to the modern study  of com-  \nputer algorithms. It presents many algorithms and c overs them in considerable \ndepth, yet makes their design accessible to all lev els of readers. All the analyses \nare laid out, some simple, some more involved. We h ave tried to keep explanations \nclear  without  sacri\u00fbcing  depth  of coverage  or mathematical  rigor. \nEach chapter presents an algorithm, a design techni que, an application area, or a \nrelated topic. Algorithms are described in English and in a pseudocode designed to \nbe readable by anyone who has done a little program ming. The book  contains  231  \n\u00fbgures4many  with  multiple  parts4illustrating  how  the  algorithms work. Since \nwe emphasize ef\ufb01ciency  as a design criterion, we include careful analyses of the \nrunning times of the algorithms. \n1 To  understand  many  of the  ways  in which  algorithms  in\u00fcuence  our daily lives, see the book by \nFry  [162].  xiv  Preface  \nThe text is intended primarily for use in undergrad uate or graduate courses in \nalgorithms or data structures. Because it discusses  engineering issues in algorithm \ndesign, as well as mathematical aspects, it is equa lly well suited  for  self-study  by  \ntechnical professionals. \nIn this, the fourth edition, we have once again upd ated the entire book. The \nchanges cover a broad spectrum, including new chapt ers and sections,  color  illus-  \ntrations,  and  what  we  hope  you\u2019ll  \u00fbnd  to be a more  engaging  writing style. \nTo  the  teacher  \nWe have designed this book to be both versatile and  complete. You  should  \u00fbnd  it \nuseful for a variety of courses, from an undergradu ate course in data structures up \nthrough a graduate course in algorithms. Because we  have provided considerably \nmore  material  than  can  \u00fbt in a typical  one-term  course,  you  can select the material \nthat best supports the course you wish to teach. \nYou  should  \u00fbnd  it easy  to organize  your  course  around  just  the  chapters you \nneed.  We  have  made  chapters  relatively  self-contained,  so that you need not \nworry about an unexpected and unnecessary dependenc e of one chapter  on  an-  \nother. Whereas in an undergraduate course, you migh t use only some sections \nfrom a chapter, in a graduate course, you might cov er the entire chapter. \nWe  have  included  931  exercises  and  162  problems.  Each  section  ends  with  exer-  \ncises, and each chapter ends with problems. The exe rcises are generally  short  ques-  \ntions that test basic mastery of the material. Some  are simple self-check  thought  \nexercises, but many are substantial and suitable as  assigned homework.  The  prob-  \nlems include more elaborate case studies which ofte n introduce new material. They \noften consist of several parts that lead the studen t through the  steps  required  to ar-  \nrive at a solution. \nAs with the third edition of this book, we have mad e publicly available solutions \nto some, but by no means all, of the problems and e xercises. You can  \u00fbnd  these  so-  \nlutions on our website, http://mitpress.mit.edu/alg orithms/. You will want to check \nthis site to see whether it contains the solution t o an exercise or problem that you \nplan to assign. Since the set of solutions that we post might grow over time, we \nrecommend that you check the site each time you tea ch the course. \nWe have starred ( ?) the sections and exercises that are more suitable  for graduate \nstudents than for undergraduates. A starred section  is not necessarily  more  dif\u00fb-  \ncult than an unstarred one, but it may require an u nderstanding of more advanced \nmathematics. Likewise, starred exercises may requir e an advanced background or \nmore than average creativity. Preface  xv \nTo  the  student  \nWe hope that this textbook provides you with an enj oyable introduction  to the  \u00fbeld  \nof algorithms. We have attempted to make every algo rithm accessible  and  inter-  \nesting.  To  help  you  when  you  encounter  unfamiliar  or dif\u00fbcul t algorithms, we \ndescribe  each  one  in a step-by-step  manner.  We  also  provide  careful explanations \nof the mathematics needed to understand the analysi s of the algorithms  and  sup-  \nporting  \u00fbgures  to help  you  visualize  what  is going  on.  \nSince this book is large, your class will probably cover only a portion of its \nmaterial.  Although  we  hope  that  you  will  \u00fbnd  this  book  helpfu l to you as a course \ntextbook now, we have also tried to make it compreh ensive enough to warrant space \non your future professional bookshelf. \nWhat  are  the  prerequisites  for  reading  this  book?  \n\ue001 You need some programming experience. In particular , you should understand \nrecursive procedures and simple data structures, su ch as arrays and linked lists \n(although  Section  10.2  covers  linked  lists  and  a variant  that  you  may  \u00fbnd  new).  \n\ue001 You should have some facility with mathematical pro ofs, and especially proofs \nby mathematical induction. A few portions of the bo ok rely on some knowledge \nof elementary calculus. Although this book uses mat hematics throughout, Part I \nand Appendices A\u2013D teach you all the mathematical t echniques you will need. \nOur  website,  http://mitpress.mit.edu/algorithms/,  links to solutions for some of \nthe problems and exercises. Feel free to check your  solutions against ours. We ask, \nhowever, that you not send your solutions to us. \nTo  the  professional  \nThe wide range of topics in this book makes it an e xcellent handbook  on  algo-  \nrithms.  Because  each  chapter  is relatively  self-contained , you can focus on the \ntopics most relevant to you. \nSince most of the algorithms we discuss have great practical utility, we address \nimplementation concerns and other engineering issue s. We often provide practical \nalternatives to the few algorithms that are primari ly of theoretical interest. \nIf you  wish  to implement  any  of the  algorithms,  you  should  \u00fbnd  the  transla-  \ntion of our pseudocode into your favorite programmi ng language to be a fairly \nstraightforward task. We have designed the pseudoco de to present each algorithm \nclearly and succinctly. Consequently, we do not add ress error handling and other \nsoftware-engineering  issues  that  require  speci\u00fbc  assumptions  about  your  program-  \nming environment. We attempt to present each algori thm simply and  directly  with-  \nout allowing the idiosyncrasies of a particular pro gramming language to obscure its \nessence. If you are used to 0-origin  arrays,  you  might  \u00fbnd  our  frequent  practice  of xvi  Preface  \nindexing arrays from 1 a minor stumbling block. You can always either subt ract 1 \nfrom our indices or just overallocate the array and  leave position 0 unused. \nWe understand that if you are using this book outsi de of a course, then you \nmight be unable to check your solutions to problems  and exercises against solutions \nprovided  by  an instructor.  Our  website,  http://mitpress.m it.edu/algorithms/, links \nto solutions for some of the problems and exercises  so that you can check your \nwork. Please do not send your solutions to us. \nTo  our  colleagues  \nWe have supplied an extensive bibliography and poin ters to the current literature. \nEach chapter ends with a set of chapter notes that give historical  details  and  ref-  \nerences. The chapter notes do not provide a complet e reference to the  whole  \u00fbeld  \nof algorithms, however. Though it may be hard to be lieve for a book of this size, \nspace constraints prevented us from including many interesting algorithms. \nDespite myriad requests from students for solutions  to problems and exercises, \nwe have adopted the policy of not citing references  for them, removing  the  temp-  \ntation for students to look up a solution rather th an to discover it themselves. \nChanges  for  the  fourth  edition  \nAs we said about the changes for the second and thi rd editions, depending on how \nyou look at it, the book changed either not much or  quite a bit. A quick look at the \ntable  of contents  shows  that  most  of the  third-edition  chapt ers and sections appear \nin the fourth edition. We removed three chapters an d several sections, but we have \nadded three new chapters and several new sections a part from these new chapters. \nWe  kept  the  hybrid  organization  from  the  \u00fbrst  three  editions . Rather than \norganizing chapters only by problem domains or only  according to techniques, \nthis book incorporates elements of both. It contain s technique-based  chapters  on  \ndivide-and-conquer,  dynamic  programming,  greedy  algorithms,  amortized  analy-  \nsis,  augmenting  data  structures,  NP-completeness,  and  approximation algorithms. \nBut it also has entire parts on sorting, on data st ructures for dynamic sets, and on \nalgorithms  for  graph  problems.  We  \u00fbnd  that  although  you  need  to know  how  to ap-  \nply techniques for designing and analyzing algorith ms, problems seldom announce \nto you which techniques are most amenable to solvin g them. \nSome of the changes in the fourth edition apply gen erally across the book, and \nsome  are  speci\u00fbc  to particular  chapters  or sections.  Here  is a summary of the most \nsigni\u00fbcant  general  changes:  \n\ue001 We  added  140  new  exercises  and  22  new  problems.  We  also  improv ed many of \nthe old exercises and problems, often as the result  of reader feedback. (Thanks \nto all readers who made suggestions.) Preface  xvii \n\ue001 We have color! With designers from the MIT Press, w e selected a limited \npalette, devised to convey information and to be pl easing to the eye. (We are \ndelighted  to display  red-black  trees  in4get  this4red  and  black!) To enhance \nreadability,  de\u00fbned  terms,  pseudocode  comments,  and  page  numbers  in the  in-  \ndex are in color. \n\ue001 Pseudocode procedures appear on a tan background to  make them easier to spot, \nand  they  do  not  necessarily  appear  on  the  page  of their  \u00fbrst  reference. When \nthey  don\u2019t,  the  text  directs  you  to the  relevant  page.  In the  same vein, nonlocal \nreferences to numbered equations, theorems, lemmas,  and corollaries include \nthe page number. \n\ue001 We removed topics that were rarely taught. We dropp ed in their entirety the \nchapters on Fibonacci heaps, van Emde Boas trees, a nd computational  geom-  \netry. In addition, the following material was excis ed: the maximum-subarray  \nproblem, implementing pointers and objects, perfect  hashing, randomly built \nbinary  search  trees,  matroids,  push-relabel  algorithms  for  maximum  \u00fcow,  the  \niterative fast Fourier transform method, the detail s of the simplex algorithm for \nlinear  programming,  and  integer  factorization.  You  can  \u00fbnd  all the removed \nmaterial on our website, http://mitpress.mit.edu/al gorithms/. \n\ue001 We reviewed the entire book and rewrote sentences, paragraphs, and sections \nto make the writing clearer, more personal, and gen der neutral. For example, \nthe  <traveling-salesman  problem=  in the  previous  editions  is now called the \n<traveling-salesperson  problem.=  We  believe  that  it is critically important for \nengineering  and  science,  including  our  own  \u00fbeld  of computer  science, to be \nwelcoming to everyone. (The one place that stumped us is in Chapter  13,  which  \nrequires  a term  for  a parent\u2019s  sibling.  Because  the  English  language has no such \ngender-neutral  term,  we  regretfully  stuck  with  <uncle.=)  \n\ue001 The chapter notes, bibliography, and index were upd ated, re\u00fcecting  the  dra-  \nmatic  growth  of the  \u00fbeld  of algorithms  since  the  third  editio n. \n\ue001 We corrected errors, posting most corrections on ou r website of third-edition  \nerrata. Those that were reported while we were in f ull swing preparing this \nedition were not posted, but were corrected in this  edition. (Thanks again to all \nreaders who helped us identify issues.) \nThe  speci\u00fbc  changes  for  the  fourth  edition  include  the  following: \n\ue001 We  renamed  Chapter  3 and  added  a section  giving  an overview  of asymptotic \nnotation  before  delving  into  the  formal  de\u00fbnitions.  \n\ue001 Chapter  4 underwent  substantial  changes  to improve  its  mathematical  founda-  \ntion and make it more robust and intuitive. The not ion of an algorithmic  re-  \ncurrence  was  introduced,  and  the  topic  of ignoring  \u00fcoors  and  ceilings  in recur-  xviii  Preface  \nrences was addressed more rigorously. The second ca se of the master theorem \nincorporates polylogarithmic factors, and a rigorou s proof of a <continuous= \nversion of the master theorem is now provided. We a lso present the powerful \nand  general  Akra-Bazzi  method  (without  proof).  \n\ue001 The  deterministic  order-statistic  algorithm  in Chapter  9 is slightly different, and \nthe analyses of both the randomized and determinist ic order-statistic  algorithms  \nhave been revamped. \n\ue001 In addition  to stacks  and  queues,  Section  10.1  discusses  ways to store arrays \nand matrices. \n\ue001 Chapter  11  on  hash  tables  includes  a modern  treatment  of hash  functions. It \nalso  emphasizes  linear  probing  as an ef\u00fbcient  method  for  resolving collisions \nwhen the underlying hardware implements caching to favor local searches. \n\ue001 To  replace  the  sections  on  matroids  in Chapter  15,  we  convert ed a problem in \nthe  third  edition  about  of\u00fcine  caching  into  a full  section.  \n\ue001 Section  16.4  now  contains  a more  intuitive  explanation  of the  potential  func-  \ntions to analyze table doubling and halving. \n\ue001 Chapter  17  on  augmenting  data  structures  was  relocated  from  Part III to Part V, \nre\u00fcecting  our  view  that  this  technique  goes  beyond  basic  material. \n\ue001 Chapter  25  is a new  chapter  about  matchings  in bipartite  graphs. It presents \nalgorithms  to \u00fbnd  a matching  of maximum  cardinality,  to solve  the  stable-  \nmarriage  problem,  and  to \u00fbnd  a maximum-weight  matching  (known  as the  <as-  \nsignment problem=). \n\ue001 Chapter  26,  on  task-parallel  computing,  has  been  updated  with  modern  termi-  \nnology, including the name of the chapter. \n\ue001 Chapter  27,  which  covers  online  algorithms,  is another  new  chapter. In an \nonline algorithm, the input arrives over time, rath er than being available in its \nentirety at the start of the algorithm. The chapter  describes several examples \nof online algorithms, including determining how lon g to wait for an elevator \nbefore taking the stairs, maintaining a linked list  via the move-to-front  heuristic,  \nand evaluating replacement policies for caches. \n\ue001 In Chapter 29, we removed the detailed presentation  of the simplex algorithm, \nas it was math heavy without really conveying many algorithmic ideas. The \nchapter now focuses on the key aspect of how to mod el problems as linear \nprograms, along with the essential duality property  of linear programming. \n\ue001 Section  32.5  adds  to the  chapter  on  string  matching  the  simpl e, yet powerful, \nstructure  of suf\u00fbx  arrays.  Preface  xix \n\ue001 Chapter  33,  on  machine  learning,  is the  third  new  chapter.  It introduces  sev-  \neral basic methods used in machine learning: cluste ring to group similar items \ntogether,  weighted-majority  algorithms,  and  gradient  descent  to \u00fbnd  the  mini-  \nmizer of a function. \n\ue001 Section  34.5.6  summarizes  strategies  for  polynomial-time  reductions to show \nthat  problems  are  NP-hard.  \n\ue001 The  proof  of the  approximation  algorithm  for  the  set-covering  problem  in Sec-  \ntion  35.3  has  been  revised.  \nWebsite  \nYou can use our website, http://mitpress.mit.edu/al gorithms/,  to obtain  supplemen-  \ntary information and to communicate with us. The we bsite links to a list of known \nerrors, material from the third edition that is not  included in the fourth edition, \nsolutions to selected exercises and problems, Pytho n implementations of many of \nthe algorithms in this book, a list explaining the corny professor jokes (of course), \nas well as other content, which we may add to. The website also tells you how to \nreport errors or make suggestions. \nHow  we  produced  this  book  \nLike the previous three editions, the fourth editio n was produced in L A T E X 2 \" . We \nused the Times font with mathematics typeset using the MathTime Professional II \nfonts. As in all previous editions, we compiled the  index using  Windex,  a C pro-  \ngram that we wrote, and produced the bibliography u sing B IBT E X.  The  PDF  \u00fbles  \nfor  this  book  were  created  on  a MacBook  Pro  running  macOS  10.14.  \nOur  plea  to Apple  in the  preface  of the  third  edition  to update  MacDraw Pro for \nmacOS  10  went  for  naught,  and  so we  continued  to draw  illustrations  on  pre-Intel  \nMacs running MacDraw Pro under the Classic environm ent of older versions of \nmacOS  10.  Many  of the  mathematical  expressions  appearing  in illustrations were \nlaid in with the psfrag package for L A T E X 2 \" . \nAcknowledgments  for  the  fourth  edition  \nWe have been working with the MIT Press since we st arted writing  the  \u00fbrst  edi-  \ntion  in 1987,  collaborating  with  several  directors,  editor s, and production staff. \nThroughout our association with the MIT Press, thei r support has  always  been  out-  \nstanding. Special thanks to our editors Marie Lee, who put up with us for far too \nlong,  and  Elizabeth  Swayze,  who  pushed  us over  the  \u00fbnish  line. Thanks also to \nDirector Amy Brand and to Alex Hoopes. xx Preface  \nAs in the third edition, we were geographically dis tributed while producing \nthe fourth edition, working in the Dartmouth Colleg e Department of Computer \nScience;  the  MIT  Computer  Science  and  Arti\u00fbcial  Intelligen ce Laboratory and \nthe MIT Department of Electrical Engineering and Co mputer Science; and the \nColumbia University Department of Industrial Engine ering and  Operations  Re-  \nsearch, Department of Computer Science, and Data Sc ience Institute. During the \nCOVID-19  pandemic,  we  worked  largely  from  home.  We  thank  our  respective \nuniversities and colleagues for providing such supp ortive and  stimulating  environ-  \nments. As we complete this book, those of us who ar e not retired are eager to return \nto our respective universities now that the pandemi c seems to be abating. \nJulie  Sussman,  P.P.A.,  came  to our  rescue  once  again  with  her  technical  copy-  \nediting  under  tremendous  time  pressure.  If not  for  Julie,  this book would be riddled \nwith  errors  (or,  let\u2019s  say,  many  more  errors  than  it has)  and  would  be far  less  read-  \nable.  Julie,  we  will  be forever  indebted  to you.  Errors  that  remain  are  the  responsi-  \nbility  of the  authors  (and  probably  were  inserted  after  Julie read the material). \nDozens of errors in previous editions were correcte d in the process of creating \nthis  edition.  We  thank  our  readers4too  many  to list  them  all4 who have reported \nerrors and suggested improvements over the years. \nWe received considerable help in preparing some of the new material in this \nedition.  Neville  Campbell  (unaf\u00fbliated),  Bill  Kuszmaul  of MIT, and Chee Yap of \nNYU provided valuable advice regarding the treatmen t of recurrences  in Chapter  4. \nYan  Gu  of the  University  of California,  Riverside,  provided  feedback on parallel \nalgorithms  in Chapter  26.  Rob  Shapire  of Microsoft  Research  altered our approach \nto the material on machine learning with his detail ed comments on  Chapter  33.  Qi  \nQi  of MIT  helped  with  the  analysis  of the  Monty  Hall  problem  (Problem  C-1).  \nMolly Seaman and Mary Reilly of the MIT Press helpe d us select the color \npalette  in the  illustrations,  and  Wojciech  Jarosz  of Dartmo uth College suggested \ndesign  improvements  to our  newly  colored  \u00fbgures.  Yichen  (Annie)  Ke  and  Linda  \nXiao, who have since graduated from Dartmouth, aide d in colorizing  the  illus-  \ntrations, and Linda also produced many of the Pytho n implementations that are \navailable  on  the  book\u2019s  website.  \nFinally,  we  thank  our  wives4Wendy  Leiserson,  Gail  Rivest,  Rebecca Ivry, and \nthe  late  Nicole  Cormen4and  our  families.  The  patience  and  encouragement of \nthose who love us made this project possible. We af fectionately dedicate this book \nto them. \nTHOMAS  H. CORMEN  Lebanon, New Hampshire \nCHARLES E. LEISERSON  Cambridge,  Massachusetts  \nRONALD  L. R IVEST Cambridge,  Massachusetts  \nCLIFFORD  STEIN New York, New York \nJune,  2021  Part  I Foundations  Introduction  \nWhen you design and analyze algorithms, you need to  be able to describe how they \noperate and how to design them. You also need some mathematical tools to show \nthat  your  algorithms  do  the  right  thing  and  do  it ef\u00fbciently.  This part will get you \nstarted. Later parts of this book will build upon t his base. \nChapter  1 provides  an overview  of algorithms  and  their  place  in modern  com-  \nputing  systems.  This  chapter  de\u00fbnes  what  an algorithm  is and  lists some examples. \nIt also makes a case for considering algorithms as a technology,  alongside  tech-  \nnologies such as fast hardware, graphical user inte rfaces, object-oriented  systems,  \nand networks. \nIn Chapter  2, we  see  our  \u00fbrst  algorithms,  which  solve  the  problem of sorting \na sequence of n numbers. They are written in a pseudocode which, al though not \ndirectly translatable to any conventional programmi ng language,  conveys  the  struc-  \nture of the algorithm clearly enough that you shoul d be able to implement it in the \nlanguage of your choice. The sorting algorithms we examine are insertion sort, \nwhich uses an incremental approach, and merge sort,  which uses a recursive  tech-  \nnique  known  as <divide-and-conquer.=  Although  the  time  each requires increases \nwith the value of n, the rate of increase differs between the two algo rithms. We \ndetermine these running times in Chapter 2, and we develop a useful <asymptotic= \nnotation to express them. \nChapter  3 precisely  de\u00fbnes  asymptotic  notation.  We\u2019ll  use  asymptotic notation \nto bound  the  growth  of functions4most  often,  functions  that  describe the running \ntime  of algorithms4from  above  and  below.  The  chapter  starts  by  informally  de\u00fbn-  \ning the most commonly used asymptotic notations and  giving an example of how to \napply  them.  It then  formally  de\u00fbnes  \u00fbve  asymptotic  notations  and  presents  conven-  \ntions  for  how  to put  them  together.  The  rest  of Chapter  3 is primarily a presentation \nof mathematical notation, more to ensure that your use of notation matches that in \nthis book than to teach you new mathematical concep ts. 4 Part  I Foundations  \nChapter  4 delves  further  into  the  divide-and-conquer  metho d introduced in \nChapter  2. It provides  two  additional  examples  of divide-and-conquer  algorithms  \nfor  multiplying  square  matrices,  including  Strassen\u2019s  surprising  method.  Chapter  4 \ncontains methods for solving recurrences, which are  useful for  describing  the  run-  \nning times of recursive algorithms. In the substitu tion method, you guess an answer \nand prove it correct. Recursion trees provide one w ay to generate  a guess.  Chap-  \nter  4 also  presents  the  powerful  technique  of the  <master  method,= which you can \noften  use  to solve  recurrences  that  arise  from  divide-and-conquer  algorithms.  Al-  \nthough the chapter provides a proof of a foundation al theorem on which the master \ntheorem depends, you should feel free to employ the  master method  without  delv-  \ning  into  the  proof.  Chapter  4 concludes  with  some  advanced  topics. \nChapter  5 introduces  probabilistic  analysis  and  randomize d algorithms. You \ntypically use probabilistic analysis to determine t he running time of an algorithm \nin cases in which, due to the presence of an inhere nt probability distribution, the \nrunning time may differ on different inputs of the same size. In some cases, you \nmight assume that the inputs conform to a known pro bability distribution, so that \nyou are averaging the running time over all possibl e inputs. In other cases, the \nprobability distribution comes not from the inputs but from random choices made \nduring the course of the algorithm. An algorithm wh ose behavior is determined \nnot  only  by  its  input  but  by  the  values  produced  by  a random-nu mber generator is a \nrandomized algorithm. You can use randomized algori thms to enforce a probability \ndistribution  on  the  inputs4thereby  ensuring  that  no  partic ular input always causes \npoor  performance4or  even  to bound  the  error  rate  of algorith ms that are allowed \nto produce incorrect results on a limited basis. \nAppendices A\u2013D contain other mathematical material that you will  \u00fbnd  helpful  \nas you read this book. You might have seen much of the material in the appendix \nchapters  before  having  read  this  book  (although  the  speci\u00fbc  de\u00fbnitions  and  nota-  \ntional conventions we use may differ in some cases from what you have seen in \nthe past), and so you should think of the appendice s as reference  material.  On  the  \nother hand, you probably have not already seen most  of the material in Part I. All \nthe chapters in Part I and the appendices are writt en with a tutorial  \u00fcavor.  1 The  Role  of Algorithms  in Computing  \nWhat  are  algorithms?  Why  is the  study  of algorithms  worthwhile?  What  is the  role  \nof algorithms relative to other technologies used i n computers?  This  chapter  will  \nanswer these questions. \n1.1  Algorithms  \nInformally, an algorithm  is any  well-de\u00fbned  computational  procedure  that  takes  \nsome value, or set of values, as input  and produces some value, or set of values, as \noutput  in a \u00fbnite  amount  of time.  An  algorithm  is thus  a sequence  of computational \nsteps that transform the input into the output. \nYou  can  also  view  an algorithm  as a tool  for  solving  a well-speci\u00fbed  computa-  \ntional  problem. The  statement  of the  problem  speci\u00fbes  in general  terms  the  desired \ninput/output relationship for problem instances, ty pically of arbitrarily large size. \nThe  algorithm  describes  a speci\u00fbc  computational  procedure  for  achieving  that  in-  \nput/output relationship for all problem instances. \nAs an example, suppose that you need to sort a sequ ence of numb ers  into  mono-  \ntonically increasing order. This problem arises fre quently in practice and provides \nfertile ground for introducing many standard design  techniques and analysis tools. \nHere  is how  we  formally  de\u00fbne  the  sorting  problem : \nInput:  A sequence of n numbers ha 1 ;a  2 ;:::;a  n i. \nOutput:  A permutation (reordering) ha 0 \n1 ;a  0 \n2 ;:::;a  0 \nn i of the input sequence such \nthat a 0 \n1 \u0dc4 a 0 \n2 \u0dc4 \ue001 \ue001 \ue001 \u0dc4  a 0 \nn . \nThus, given the input sequence h31;41;59;26;41;58 i, a correct sorting algorithm \nreturns as output the sequence h26;31;41;41;58;59 i. Such an input sequence is 6 Chapter  1 The  Role  of Algorithms  in Computing  \ncalled an instance  of the sorting problem. In general, an instance  of a problem  1 \nconsists of the input (satisfying whatever constrai nts are imposed in the problem \nstatement) needed to compute a solution to the prob lem. \nBecause many programs use it as an intermediate ste p, sorting is a fundamental \noperation in computer science. As a result, you hav e a large number  of good  sort-  \ning algorithms at your disposal. Which algorithm is  best for a given application \ndepends  on4among  other  factors4the  number  of items  to be sorted, the extent \nto which the items are already somewhat sorted, pos sible restrictions on the item \nvalues, the architecture of the computer, and the k ind of storage devices to be used: \nmain  memory,  disks,  or even4archaically4tapes.  \nAn algorithm for a computational problem is correct  if, for  every  problem  in-  \nstance provided as input, it halts4\u00fbnishes  its  computing  in \u00fbnite  time4and  out-  \nputs the correct solution to the problem instance. A correct algorithm solves  the \ngiven computational problem. An incorrect algorithm  might not halt at all on some \ninput instances, or it might halt with an incorrect  answer. Contrary to what you \nmight expect, incorrect algorithms can sometimes be  useful, if you can control \ntheir  error  rate.  We\u2019ll  see  an example  of an algorithm  with  a controllable error rate \nin Chapter  31  when  we  study  algorithms  for  \u00fbnding  large  prime  numbers.  Ordi-  \nnarily,  however,  we\u2019ll  concern  ourselves  only  with  correct  algorithms. \nAn  algorithm  can  be speci\u00fbed  in English,  as a computer  progra m, or even as \na hardware  design.  The  only  requirement  is that  the  speci\u00fbca tion must provide a \nprecise description of the computational procedure to be followed. \nWhat  kinds  of problems  are  solved  by  algorithms?  \nSorting is by no means the only computational probl em for which algorithms have \nbeen developed. (You probably suspected as much whe n you saw the size of this \nbook.) Practical applications of algorithms are ubi quitous and  include  the  follow-  \ning examples: \n\ue001 The  Human  Genome  Project  has  made  great  progress  toward  the  goals  of iden-  \ntifying  all  the  roughly  30,000  genes  in human  DNA,  determini ng the sequences \nof the roughly 3 billion  chemical  base  pairs  that  make  up  human  DNA,  stor-  \ning this information in databases, and developing t ools for data analysis. Each \nof these steps requires sophisticated algorithms. A lthough the solutions to the \nvarious problems involved are beyond the scope of t his book, many methods to \nsolve these biological problems use ideas presented  here, enabling scientists to \naccomplish  tasks  while  using  resources  ef\u00fbciently.  Dynami c programming, as \n1 Sometimes, when the problem context is known, probl em instances are themselves simply called \n<problems.= 1.1 Algorithms 7 \nin Chapter  14,  is an important  technique  for  solving  several  of these biological \nproblems, particularly ones that involve determinin g similarity between DNA \nsequences. The savings realized are in time, both h uman and machine, and in \nmoney, as more information can be extracted by labo ratory techniques. \n\ue001 The internet enables people all around the world to  quickly access and retrieve \nlarge amounts of information. With the aid of cleve r algorithms, sites on the \ninternet are able to manage and manipulate this lar ge volume of data.  Exam-  \nples of problems that make essential use of algorit hms include \u00fbnding  good  \nroutes on which the data travels (techniques for so lving such problems appear \nin Chapter  22),  and  using  a search  engine  to quickly  \u00fbnd  pages  on  which  par-  \nticular information resides (related techniques are  in Chapters  11  and  32).  \n\ue001 Electronic commerce enables goods and services to b e negotiated  and  ex-  \nchanged electronically, and it depends on the priva cy of personal  informa-  \ntion such as credit card numbers, passwords, and ba nk statements. The core \ntechnologies  used  in electronic  commerce  include  public-k ey cryptography and \ndigital  signatures  (covered  in Chapter  31),  which  are  based  on  numerical  algo-  \nrithms and number theory. \n\ue001 Manufacturing and other commercial enterprises ofte n need to allocate scarce \nresources  in the  most  bene\u00fbcial  way.  An  oil  company  might  wish to know \nwhere to place its wells in order to maximize its e xpected pro\u00fbt.  A political  \ncandidate might want to determine where to spend mo ney buying campaign  ad-  \nvertising in order to maximize the chances of winni ng an election. An airline \nmight  wish  to assign  crews  to \u00fcights  in the  least  expensive  way  possible,  mak-  \ning  sure  that  each  \u00fcight  is covered  and  that  government  regul ations regarding \ncrew scheduling are met. An internet service provid er might wish to determine \nwhere to place additional resources in order to ser ve its customers  more  effec-  \ntively. All of these are examples of problems that can be solved by modeling \nthem as linear programs, which Chapter 29 explores.  \nAlthough some of the details of these examples are beyond the scope of this \nbook, we do give underlying techniques that apply t o these problems and problem \nareas.  We  also  show  how  to solve  many  speci\u00fbc  problems,  inclu ding the following: \n\ue001 You have a road map on which the distance between e ach pair of a djacent  in-  \ntersections is marked, and you wish to determine th e shortest route from one \nintersection to another. The number of possible rou tes can be huge, even if you \ndisallow routes that cross over themselves. How can  you choose which of all \npossible  routes  is the  shortest?  You  can  start  by  modeling  the road map (which \nis itself a model of the actual roads) as a graph ( which we will meet in Part VI \nand  Appendix  B).  In this  graph,  you  wish  to \u00fbnd  the  shortest  path from one \nvertex to another. Chapter 22 shows how to solve th is problem ef\u00fbciently.  8 Chapter  1 The  Role  of Algorithms  in Computing  \n\ue001 Given  a mechanical  design  in terms  of a library  of parts,  wher e each part may \ninclude instances of other parts, list the parts in  order so that each part appears \nbefore any part that uses it. If the design compris es n parts, then there are n\u0160 \npossible orders, where n\u0160 denotes the factorial function. Because the factori al \nfunction grows faster than even an exponential func tion, you cannot feasibly \ngenerate each possible order and then verify that, within that order, each part \nappears before the parts using it (unless you have only a few p arts).  This  prob-  \nlem is an instance of topological sorting, and Chap ter 20 shows how to solve \nthis  problem  ef\u00fbciently.  \n\ue001 A doctor needs to determine whether an image repres ents a cancerous tumor or \na benign one. The doctor has available images of ma ny other tumors, some of \nwhich are known to be cancerous and some of which a re known to be benign. \nA cancerous tumor is likely to be more similar to o ther cancerous tumors than \nto benign tumors, and a benign tumor is more likely  to be similar to other  be-  \nnign  tumors.  By  using  a clustering  algorithm,  as in Chapter  33,  the  doctor  can  \nidentify which outcome is more likely. \n\ue001 You  need  to compress  a large  \u00fble  containing  text  so that  it occupies less space. \nMany ways to do so are known, including <LZW compre ssion,= which looks for \nrepeating  character  sequences.  Chapter  15  studies  a different  approach,  <Huff-  \nman coding,= which encodes characters by bit sequen ces of various lengths, \nwith characters occurring more frequently encoded b y shorter bit sequences. \nThese lists are far from exhaustive (as you again h ave probably surmised from \nthis  book\u2019s  heft),  but  they  exhibit  two  characteristics  common to many interesting \nalgorithmic problems: \n1. They  have  many  candidate  solutions,  the  overwhelming  majority of which do \nnot solve the problem at hand. Finding one that doe s, or one that is <best,=  with-  \nout explicitly examining each possible solution, ca n present quite a challenge. \n2. They  have  practical  applications.  Of  the  problems  in the  above  list,  \u00fbnding  the  \nshortest path provides the easiest examples. A tran sportation  \u00fbrm,  such  as a \ntrucking  or railroad  company,  has  a \u00fbnancial  interest  in \u00fbnding shortest paths \nthrough a road or rail network because taking short er paths results in lower \nlabor  and  fuel  costs.  Or  a routing  node  on  the  internet  might  need  to \u00fbnd  the  \nshortest path through the network in order to route  a message quickly.  Or  a \nperson  wishing  to drive  from  New  York  to Boston  might  want  to \u00fbnd driving \ndirections using a navigation app. \nNot  every  problem  solved  by  algorithms  has  an easily  identi\u00fbed  set  of candi-  \ndate solutions. For example, given a set of numeric al values representing samples \nof a signal taken at regular time intervals, the di screte Fourier transform converts 1.1 Algorithms 9 \nthe time domain to the frequency domain. That is, i t approximates the signal as a \nweighted sum of sinusoids, producing the strength o f various frequencies which, \nwhen summed, approximate the sampled signal. In add ition to lying at the heart of \nsignal processing, discrete Fourier transforms have  applications  in data  compres-  \nsion and multiplying large polynomials and integers . Chapter 30  gives  an ef\u00fbcient  \nalgorithm, the fast Fourier transform (commonly cal led the FFT), for this problem. \nThe chapter also sketches out the design of a hardw are FFT circuit. \nData  structures  \nThis book also presents several data structures. A data  structure  is a way to store \nand  organize  data  in order  to facilitate  access  and  modi\u00fbcations.  Using  the  appro-  \npriate data structure or structures is an important  part of algorithm  design.  No  sin-  \ngle data structure works well for all purposes, and  so you should know the strengths \nand limitations of several of them. \nTechnique  \nAlthough you can use this book as a <cookbook= for algorithms, you  might  some-  \nday  encounter  a problem  for  which  you  cannot  readily  \u00fbnd  a published algorithm \n(many of the exercises and problems in this book, f or example). This book will \nteach you techniques of algorithm design and analys is so that you  can  develop  al-  \ngorithms on your own, show that they give the corre ct answer, and  analyze  their  ef-  \n\u00fbciency.  Different  chapters  address  different  aspects  of algorithmic  problem  solv-  \ning.  Some  chapters  address  speci\u00fbc  problems,  such  as \u00fbnding  medians and order \nstatistics in Chapter 9, computing minimum spanning  trees in Chapter  21,  and  de-  \ntermining  a maximum  \u00fcow  in a network  in Chapter  24.  Other  chap ters introduce \ntechniques,  such  as divide-and-conquer  in Chapters  2 and  4, dynamic programming \nin Chapter  14,  and  amortized  analysis  in Chapter  16.  \nHard  problems  \nMost  of this  book  is about  ef\u00fbcient  algorithms.  Our  usual  measure  of ef\u00fbciency  \nis speed: how long does an algorithm take to produc e its result? There  are  some  \nproblems, however, for which we know of no algorith m that runs in a reasonable \namount  of time.  Chapter  34  studies  an interesting  subset  of these problems, which \nare  known  as NP-complete.  \nWhy  are  NP-complete  problems  interesting?  First,  although  no  ef\u00fbcient  algo-  \nrithm  for  an NP-complete  problem  has  ever  been  found,  nobody  has ever proven \nthat  an ef\u00fbcient  algorithm  for  one  cannot  exist.  In other  words, no one knows \nwhether  ef\u00fbcient  algorithms  exist  for  NP-complete  problem s. Second, the set of 10  Chapter  1 The  Role  of Algorithms  in Computing  \nNP-complete  problems  has  the  remarkable  property  that  if an ef\u00fbcient  algorithm  \nexists  for  any  one  of them,  then  ef\u00fbcient  algorithms  exist  for  all  of them.  This  re-  \nlationship  among  the  NP-complete  problems  makes  the  lack  of ef\u00fbcient  solutions  \nall  the  more  tantalizing.  Third,  several  NP-complete  probl ems are similar, but not \nidentical,  to problems  for  which  we  do  know  of ef\u00fbcient  algor ithms. Computer \nscientists are intrigued by how a small change to t he problem statement can cause \na big  change  to the  ef\u00fbciency  of the  best  known  algorithm.  \nYou  should  know  about  NP-complete  problems  because  some  of them  arise  sur-  \nprisingly often in real applications. If you are ca lled upon to produce  an ef\u00fbcient  \nalgorithm  for  an NP-complete  problem,  you  are  likely  to spend a lot of time in a \nfruitless search. If, instead, you can show that th e problem is NP-complete,  you  \ncan  spend  your  time  developing  an ef\u00fbcient  approximation  algorithm, that is, an \nalgorithm that gives a good, but not necessarily th e best possible, solution. \nAs a concrete example, consider a delivery company with a central depot. Each \nday, it loads up delivery trucks at the depot and s ends them around to deliver goods \nto several addresses. At the end of the day, each t ruck must end up back at the depot \nso that it is ready to be loaded for the next day. To reduce costs, the company wants \nto select an order of delivery stops that yields th e lowest overall distance traveled by \neach  truck.  This  problem  is the  well-known  <traveling-sale sperson problem,= and it \nis NP-complete.  2 It has  no  known  ef\u00fbcient  algorithm.  Under  certain  assumptio ns, \nhowever,  we  know  of ef\u00fbcient  algorithms  that  compute  overal l distances close to \nthe  smallest  possible.  Chapter  35  discusses  such  <approxim ation algorithms.= \nAlternative  computing  models  \nFor many years, we could count on processor clock s peeds increasing at a steady \nrate. Physical limitations present a fundamental ro adblock to ever-increasing  clock  \nspeeds, however: because power density increases su perlinearly with clock speed, \nchips run the risk of melting once their clock spee ds become h igh  enough.  In or-  \nder to perform more computations per second, theref ore, chips are being designed \nto contain not just one but several processing <cor es.= We can liken  these  multi-  \ncore computers to several sequential computers on a  single chip. In other words, \nthey are a type of <parallel computer.= In order to  elicit the best performance \nfrom multicore computers, we need to design algorit hms with parallelism in mind. \nChapter  26  presents  a model  for  =task-parallel=  algorithms , which take advantage \nof multiple processing cores. This model has advant ages from both theoretical and \n2 To  be precise,  only  decision  problems4those  with  a <yes/no=  answer4can  be NP-complete.  The  \ndecision version of the traveling salesperson probl em asks whether there exists an order of stops \nwhose distance totals at most a given amount. 1.1 Algorithms 11 \npractical  standpoints,  and  many  modern  parallel-programm ing platforms embrace \nsomething similar to this model of parallelism. \nMost of the examples in this book assume that all o f the input data are available \nwhen an algorithm begins running. Much of the work in algorithm design makes \nthe  same  assumption.  For  many  important  real-world  example s, however, the input \nactually arrives over time, and the algorithm must decide how to proceed without \nknowing what data will arrive in the future. In a d ata center, jobs are constantly \narriving and departing, and a scheduling algorithm must decide when and where to \nrun a job, without knowing what jobs will be arrivi ng in the future.  Traf\u00fbc  must  \nbe routed in the internet based on the current stat e, without knowing about where \ntraf\u00fbc  will  arrive  in the  future.  Hospital  emergency  rooms  make triage decisions \nabout  which  patients  to treat  \u00fbrst  without  knowing  when  other patients will be \narriving in the future and what treatments they wil l need. Algorithms that receive \ntheir input over time, rather than having all the i nput present at the start, are online  \nalgorithms, which  Chapter  27  examines.  \nExercises  \n1.1-1  \nDescribe  your  own  real-world  example  that  requires  sorting . Describe one that \nrequires  \u00fbnding  the  shortest  distance  between  two  points.  \n1.1-2  \nOther  than  speed,  what  other  measures  of ef\u00fbciency  might  you  need to consider in \na real-world  setting?  \n1.1-3  \nSelect a data structure that you have seen, and dis cuss its strengths and limitations. \n1.1-4  \nHow  are  the  shortest-path  and  traveling-salesperson  problems  given  above  similar?  \nHow  are  they  different?  \n1.1-5  \nSuggest  a real-world  problem  in which  only  the  best  solution  will do. Then come \nup with one in which <approximately= the best solut ion is good enough. \n1.1-6  \nDescribe  a real-world  problem  in which  sometimes  the  entire  input is available \nbefore you need to solve the problem, but other tim es the input is not entirely \navailable in advance and arrives over time. 12  Chapter  1 The  Role  of Algorithms  in Computing  \n1.2  Algorithms  as a technology  \nIf computers  were  in\u00fbnitely  fast  and  computer  memory  were  free, would you have \nany  reason  to study  algorithms?  The  answer  is yes,  if for  no  other reason than that \nyou would still like to be certain that your soluti on method terminates and does so \nwith the correct answer. \nIf computers  were  in\u00fbnitely  fast,  any  correct  method  for  solving a problem \nwould do. You would probably want your implementati on to be within the bounds \nof good software engineering practice (for example,  your implementation should \nbe well designed and documented), but you would mos t often use whichever \nmethod was the easiest to implement. \nOf  course,  computers  may  be fast,  but  they  are  not  in\u00fbnitely  fast. Computing \ntime is therefore a bounded resource, which makes i t precious. Although the saying \ngoes, <Time is money,= time is even more valuable t han money: you can get back \nmoney after you spend it, but once time is spent, y ou can never get it back. Memory \nmay  be inexpensive,  but  it is neither  in\u00fbnite  nor  free.  You  should choose algorithms \nthat  use  the  resources  of time  and  space  ef\u00fbciently.  \nEf\u00fbciency  \nDifferent algorithms devised to solve the same prob lem often differ dramatically in \ntheir  ef\u00fbciency.  These  differences  can  be much  more  signi\u00fbc ant than differences \ndue to hardware and software. \nAs an example, Chapter 2 introduces two algorithms for sorting.  The  \u00fbrst,  \nknown as insertion  sort, takes time roughly equal to c 1 n 2 to sort n items, where c 1 \nis a constant that does not depend on n. That is, it takes time roughly proportional \nto n 2 . The second, merge  sort, takes time roughly equal to c 2 n lg n, where lg n \nstands for log 2 n and c 2 is another constant that also does not depend on n. Inser-  \ntion sort typically has a smaller constant factor t han merge sort, so that c 1 < c  2 . \nWe\u2019ll  see  that  the  constant  factors  can  have  far  less  of an impact on the running \ntime than the dependence on the input size n. Let\u2019s  write  insertion  sort\u2019s  running  \ntime as c 1 n \ue001 n and  merge  sort\u2019s  running  time  as c 2 n \ue001 lg n. Then we see that where \ninsertion sort has a factor of n in its running time, merge sort has a factor of lg n, \nwhich is much smaller. For example, when n is 1000 , lg n is approximately 10, and \nwhen n is 1,000,000,  lg n is approximately only 20. Although  insertion  sort  usu-  \nally runs faster than merge sort for small input si zes, once the input size n becomes \nlarge  enough,  merge  sort\u2019s  advantage  of lg n versus n more than compensates for \nthe difference in constant factors. No matter how m uch smaller c 1 is than c 2 , there \nis always a crossover point beyond which merge sort  is faster. 1.2  Algorithms  as a technology  13 \nFor a concrete example, let us pit a faster compute r (computer A)  running  inser-  \ntion sort against a slower computer (computer B) ru nning merge sort. They each \nmust sort an array of 10  million numbers. (Although 10  million numbers might \nseem  like  a lot,  if the  numbers  are  eight-byte  integers,  then  the input occupies \nabout 80  megabytes,  which  \u00fbts  in the  memory  of even  an inexpensive  laptop  com-  \nputer many times over.) Suppose that computer A exe cutes 10  billion instructions \nper second (faster than any single sequential compu ter at the time of this writing) \nand computer B executes only 10  million instructions per second (much slower \nthan most contemporary computers), so that computer  A is 1000  times faster than \ncomputer B in raw computing power. To make the diff erence even more dramatic, \nsuppose  that  the  world\u2019s  craftiest  programmer  codes  insertion  sort  in machine  lan-  \nguage for computer A, and the resulting code requir es 2n  2 instructions to sort n \nnumbers. Suppose further that just an average progr ammer implements merge \nsort,  using  a high-level  language  with  an inef\u00fbcient  compil er, with the resulting \ncode taking 50n  lg n instructions. To sort 10  million numbers, computer A takes \n2 \ue001 .10  7 / 2 instructions \n10  10  instructions/second D 20,000 seconds (more than 5:5  hours) ; \nwhile computer B takes \n50  \ue001 10  7 lg 10  7 instructions \n10  7 instructions/second \ue002 1163  seconds (under 20  minutes) : \nBy using an algorithm whose running time grows more  slowly, even with a poor \ncompiler, computer B runs more than 17  times  faster  than  computer  A!  The  ad-  \nvantage of merge sort is even more pronounced when sorting 100  million numbers: \nwhere insertion sort takes more than 23  days, merge sort takes under four hours. \nAlthough 100  million might seem like a large number, there are m ore than 100  mil-  \nlion web searches every half hour, more than 100  million emails sent every minute, \nand  some  of the  smallest  galaxies  (known  as ultra-compact  dwarf  galaxies)  con-  \ntain about 100  million stars. In general, as the problem size incr eases, so does the \nrelative advantage of merge sort. \nAlgorithms  and  other  technologies  \nThe example above shows that you should consider al gorithms, like  computer  hard-  \nware, as a technology. Total  system  performance  depends  on  choosing  ef\u00fbcient  \nalgorithms  as much  as on  choosing  fast  hardware.  Just  as rapid advances are being \nmade in other computer technologies, they are being  made in algorithms as well. \nYou might wonder whether algorithms are truly that important on contemporary \ncomputers in light of other advanced technologies, such as 14  Chapter  1 The  Role  of Algorithms  in Computing  \n\ue001 advanced computer architectures and fabrication tec hnologies, \n\ue001 easy-to-use,  intuitive,  graphical  user  interfaces  (GUIs) , \n\ue001 object-oriented  systems,  \n\ue001 integrated web technologies, \n\ue001 fast networking, both wired and wireless, \n\ue001 machine learning, \n\ue001 and mobile devices. \nThe answer is yes. Although some applications do no t explicitly  require  algorith-  \nmic content at the application level (such as some simple, web-based  applications),  \nmany  do.  For  example,  consider  a web-based  service  that  determines how to travel \nfrom one location to another. Its implementation wo uld rely on fast hardware, a \ngraphical  user  interface,  wide-area  networking,  and  also  possibly  on  object  ori-  \nentation. It would also require algorithms for oper ations such  as \u00fbnding  routes  \n(probably  using  a shortest-path  algorithm),  rendering  maps,  and  interpolating  ad-  \ndresses. \nMoreover, even an application that does not require  algorithmic content at the \napplication level relies heavily upon algorithms. D oes the application rely on fast \nhardware?  The  hardware  design  used  algorithms.  Does  the  application rely on \ngraphical  user  interfaces?  The  design  of any  GUI  relies  on  algorithms. Does the \napplication  rely  on  networking?  Routing  in networks  relies  heavily on algorithms. \nWas the application written in a language other tha n machine code?  Then  it was  \nprocessed by a compiler, interpreter, or assembler,  all of which make extensive use \nof algorithms. Algorithms are at the core of most t echnologies used  in contempo-  \nrary computers. \nMachine learning can be thought of as a method for performing algorithmic tasks \nwithout explicitly designing an algorithm, but inst ead inferring patterns from data \nand  thereby  automatically  learning  a solution.  At  \u00fbrst  glance, machine learning, \nwhich automates the process of algorithmic design, may seem to make learning \nabout algorithms obsolete. The opposite is true, ho wever. Machine learning is \nitself a collection of algorithms, just under a dif ferent name.  Furthermore,  it cur-  \nrently seems that the successes of machine learning  are mainly for problems for \nwhich we, as humans, do not really understand what the right algorithm  is. Promi-  \nnent examples include computer vision and automatic  language translation. For \nalgorithmic problems that humans understand well, s uch as most of the problems \nin this  book,  ef\u00fbcient  algorithms  designed  to solve  a speci\u00fb c problem are typically \nmore  successful  than  machine-learning  approaches.  \nData  science  is an interdisciplinary  \u00fbeld  with  the  goal  of extracting knowledge \nand insights from structured and unstructured data.  Data science uses methods Problems for Chapter 1 15 \nfrom statistics, computer science, and optimization . The design and analysis of \nalgorithms  is fundamental  to the  \u00fbeld.  The  core  techniques  of data science, which \noverlap  signi\u00fbcantly  with  those  in machine  learning,  include  many  of the  algo-  \nrithms in this book. \nFurthermore,  with  the  ever-increasing  capacities  of compu ters, we use them to \nsolve larger problems than ever before. As we saw i n the above comparison  be-  \ntween insertion sort and merge sort, it is at large r problem sizes that the differences \nin ef\u00fbciency  between  algorithms  become  particularly  promi nent. \nHaving a solid base of algorithmic knowledge and te chnique is one characteristic \nthat  de\u00fbnes  the  truly  skilled  programmer.  With  modern  compu ting technology, you \ncan accomplish some tasks without knowing much abou t algorithms, but with a \ngood background in algorithms, you can do much, muc h more. \nExercises  \n1.2-1  \nGive  an example  of an application  that  requires  algorithmic  content  at the  applica-  \ntion level, and discuss the function of the algorit hms involved. \n1.2-2  \nSuppose that for inputs of size n on a particular computer, insertion sort runs in 8n  2 \nsteps and merge sort runs in 64n  lg n steps. For which values of n does insertion \nsort  beat  merge  sort?  \n1.2-3  \nWhat is the smallest value of n such that an algorithm whose running time is 100n  2 \nruns faster than an algorithm whose running time is  2 n on  the  same  machine?  \nProblems  \n1-1  Comparison  of running  times  \nFor each function f.n/  and time t in the following table, determine the largest \nsize n of a problem that can be solved in time t , assuming that the algorithm to \nsolve the problem takes f.n/  microseconds. 16  Chapter  1 The  Role  of Algorithms  in Computing  \n1 1 1 1 1 1 1 \nsecond minute hour day month year century \nlg n \np n \nn \nn lg n \nn 2 \nn 3 \n2 n \nn\u0160 \nChapter  notes  \nThere are many excellent texts on the general topic  of algorithms, including those \nby  Aho,  Hopcroft,  and  Ullman  [5,  6],  Dasgupta,  Papadimitriou,  and  Vazirani  [107],  \nEdmonds  [133],  Erickson  [135],  Goodrich  and  Tamassia  [195,  196],  Kleinberg  \nand  Tardos  [257],  Knuth  [259,  260,  261,  262,  263],  Levitin  [298],  Louridas  [305],  \nMehlhorn  and  Sanders  [325],  Mitzenmacher  and  Upfal  [331],  Neapolitan  [342],  \nRoughgarden  [385,  386,  387,  388],  Sanders,  Mehlhorn,  Dietzfelbinger,  and  De-  \nmentiev  [393],  Sedgewick  and  Wayne  [402],  Skiena  [414],  Soltys-Kulinicz  [419],  \nWilf  [455],  and  Williamson  and  Shmoys  [459].  Some  of the  more  practical  as-  \npects  of algorithm  design  are  discussed  by  Bentley  [49,  50,  51],  Bhargava  [54],  \nKochenderfer  and  Wheeler  [268],  and  McGeoch  [321].  Surveys  of the  \u00fbeld  of al-  \ngorithms  can  also  be found  in books  by  Atallah  and  Blanton  [27,  28]  and  Mehta  and  \nSahhi  [326].  For  less  technical  material,  see  the  books  by  Christian  and  Grif\u00fbths  \n[92],  Cormen  [104],  Erwig  [136],  MacCormick  [307],  and  V\u00a8  ocking  et al.  [448].  \nOverviews  of the  algorithms  used  in computational  biology  can be found in books \nby  Jones  and  Pevzner  [240],  Elloumi  and  Zomaya  [134],  and  Marchisio  [315].  2 Getting  Started  \nThis  chapter  will  familiarize  you  with  the  framework  we\u2019ll  use throughout the book \nto think about the design and analysis of algorithm s. It is self-contained,  but  it does  \ninclude several references to material that will be  introduced  in Chapters  3 and  4. \n(It also contains several summations, which Appendi x A shows how to solve.) \nWe\u2019ll  begin  by  examining  the  insertion  sort  algorithm  to solve  the  sorting  prob-  \nlem  introduced  in Chapter  1. We\u2019ll  specify  algorithms  using  a pseudocode that \nshould be understandable to you if you have done co mputer programming.  We\u2019ll  \nsee why insertion sort correctly sorts and analyze its running time. The analysis \nintroduces a notation that describes how running ti me increases with the number \nof items to be sorted. Following a discussion of in sertion sort, we\u2019ll  use  a method  \ncalled  divide-and-conquer  to develop  a sorting  algorithm  called  merge  sort.  We\u2019ll  \nend  with  an analysis  of merge  sort\u2019s  running  time.  \n2.1  Insertion  sort  \nOur  \u00fbrst  algorithm,  insertion  sort,  solves  the  sorting  problem  introduced  in Chap-  \nter  1: \nInput:  A sequence of n numbers ha 1 ;a  2 ;:::;a  n i. \nOutput:  A permutation (reordering) ha 0 \n1 ;a  0 \n2 ;:::;a  0 \nn i of the input sequence such \nthat a 0 \n1 \u0dc4 a 0 \n2 \u0dc4 \ue001 \ue001 \ue001 \u0dc4  a 0 \nn . \nThe numbers to be sorted are also known as the keys. Although  the  problem  is con-  \nceptually about sorting a sequence, the input comes  in the form of an array with \nn elements.  When  we  want  to sort  numbers,  it\u2019s  often  because  they are the keys \nassociated with other data, which we call satellite  data. Together,  a key  and  satel-  \nlite data form a record . For example, consider a spreadsheet containing st udent \nrecords with many associated pieces of data such as  age, grade-point  average,  and  \nnumber of courses taken. Any one of these quantitie s could be a key, but when the 18 Chapter 2 Getting Started \nspreadsheet sorts, it moves the associated record ( the satellite data) with the key. \nWhen describing a sorting algorithm, we focus on th e keys, but it is important to \nremember that there usually is associated satellite  data. \nIn this  book,  we\u2019ll  typically  describe  algorithms  as proced ures written in a pseu-  \ndocode  that  is similar  in many  respects  to C, C++,  Java,  Python,  1 or JavaScript.  \n(Apologies  if we\u2019ve  omitted  your  favorite  programming  language.  We  can\u2019t  list  \nthem all.) If you have been introduced to any of th ese languages, you should have \nlittle trouble understanding algorithms <coded= in pseudocode. What separates \npseudocode from real code is that in pseudocode, we  employ wh atever  expres-  \nsive method is most clear and concise to specify a given algorithm. Sometimes \nthe clearest method is English, so do not be surpri sed if you come  across  an En-  \nglish phrase or sentence embedded within a section that looks more like real code. \nAnother difference between pseudocode and real code  is that pseudocode  often  ig-  \nnores  aspects  of software  engineering4such  as data  abstrac tion, modularity, and \nerror  handling4in  order  to convey  the  essence  of the  algorit hm more concisely. \nWe start with insertion  sort, which  is an ef\u00fbcient  algorithm  for  sorting  a small  \nnumber of elements. Insertion sort works the way yo u might sort a hand of playing \ncards. Start with an empty left hand and the cards in a pile on the table. Pick up \nthe  \u00fbrst  card  in the  pile  and  hold  it with  your  left  hand.  Then,  with your right hand, \nremove one card at a time from the pile, and insert  it into the correct position in \nyour  left  hand.  As  Figure  2.1  illustrates,  you  \u00fbnd  the  correc t position for a card \nby comparing it with each of the cards already in y our left hand, starting at the \nright and moving left. As soon as you see a card in  your left hand whose value is \nless  than  or equal  to the  card  you\u2019re  holding  in your  right  hand, insert the card that \nyou\u2019re  holding  in your  right  hand  just  to the  right  of this  card in your left hand. If \nall the cards in your left hand have values greater  than the card in your right hand, \nthen place this card as the leftmost card in your l eft hand. At all times, the cards \nheld in your left hand are sorted, and these cards were originally the top cards of \nthe pile on the table. \nThe pseudocode for insertion sort is given as the p rocedure I NSERTION-SORT  \non the facing page. It takes two parameters: an arr ay A containing the values to \nbe sorted and the number n of values of sort. The values occupy positions A\u01521\ufffd  \nthrough A\u0152n\ufffd  of the array, which we denote by A\u01521  W n\ufffd. When the I NSERTION- \nSORT  procedure  is \u00fbnished,  array  A\u01521  W n\ufffd contains the original values, but in sorted \norder. \n1 If you\u2019re  familiar  with  only  Python,  you  can  think  of arrays  as similar to Python lists. 2.1 Insertion sort 19 \n2 \n\u2665 \u2665 \u2665 \n2 \n\u2665 4 \n\u2665 \u2665 \u2665 \u2665 \u2665 4 \n\u2665 5 \u2665 \u2665 \u2665  \u2665 \u2665  5 \u2665 \u2665 7 \u2665 \n\u2665 \u2665 \n\u2665 \u2665 \u2665 \u2665 7 \u2665 \u2665 \n10  \u2665 \u2665 \u2665 \u2665 \n\u2665 \u2665 \u2665 \u2665 \u2665 \n\u2665 \u2665 10  \u2665 \nFigure  2.1  Sorting a hand of cards using insertion sort. \nI NSERTION-SORT  .A;n/  \n1 for  i D 2 to n \n2 key  D A\u0152i\ufffd  \n3 / / Insert A\u0152i\ufffd  into the sorted subarray A\u01521  W i \ue003 1\ufffd. \n4 j D i \ue003 1 \n5 while  j >0  and A\u0152j\ufffd>  key  \n6 A\u0152j  C 1\ufffd D A\u0152j\ufffd  \n7 j D j \ue003 1 \n8 A\u0152j  C 1\ufffd D key  \nLoop  invariants  and  the  correctness  of insertion  sort  \nFigure 2.2 shows how this algorithm works for an ar ray A that starts out with \nthe sequence h5;2;4;6;1;3 i. The index i indicates the <current card= being \ninserted into the hand. At the beginning of each it eration of the for  loop, which \nis indexed by i , the subarray  (a contiguous portion of the array) consisting of \nelements A\u01521  W i \ue003 1\ufffd (that is, A\u01521\ufffd  through A\u0152i  \ue003 1\ufffd) constitutes the currently sorted \nhand, and the remaining subarray A\u0152i  C 1 W n\ufffd (elements A\u0152i  C 1\ufffd through A\u0152n\ufffd) \ncorresponds to the pile of cards still on the table . In fact, elements A\u01521  W i \ue003 1\ufffd are \nthe elements originally  in positions  1 through  i \ue003 1, but now in sorted order. We \nstate these properties of A\u01521  W i \ue003 1\ufffd formally as a loop  invariant : 20 Chapter 2 Getting Started \n1 2 3 4 5 6 \n5 2 4 6 1 3 (a) 1 2 3 4 5 6 \n2 5 4 6 1 3 (b) 1 2 3 4 5 6 \n2 4 5 6 1 3 (c) \n1 2 3 4 5 6 \n2 4 5 6 1 3 (d) 1 2 3 4 5 6 \n2 4 5 6 1 3 (e) 1 2 3 4 5 6 \n2 4 5 6 1 3 (f) \nFigure  2.2  The operation of I NSERTION-SORT.A;n/ , where A initially contains the sequence \nh5;2;4;6;1;3 i and n D 6. Array indices appear above the rectangles, and va lues stored in the \narray positions appear within the rectangles. (a)\u2013(e)  The iterations of the for  loop  of lines  138.  In \neach iteration, the blue rectangle holds the key ta ken from A\u0152i\ufffd, which is compared with the values \nin tan  rectangles  to its  left  in the  test  of line  5. Orange  arrows show array values moved one position \nto the  right  in line  6, and  blue  arrows  indicate  where  the  key  moves  to in line  8. (f)  The  \u00fbnal  sorted  \narray. \nAt the start of each iteration of the for  loop  of lines  138,  the  subarray  \nA\u01521  W i \ue003 1\ufffd consists of the elements originally in A\u01521  W i \ue003 1\ufffd, but in sorted \norder. \nLoop invariants help us understand why an algorithm  is correct.  When  you\u2019re  \nusing a loop invariant, you need to show three thin gs: \nInitialization:  It is true  prior  to the  \u00fbrst  iteration  of the  loop.  \nMaintenance:  If it is true before an iteration of the loop, it r emains true before \nthe next iteration. \nTermination:  The  loop  terminates,  and  when  it terminates,  the  invariant4 usually \nalong  with  the  reason  that  the  loop  terminated4gives  us a useful property that \nhelps show that the algorithm is correct. \nWhen  the  \u00fbrst  two  properties  hold,  the  loop  invariant  is true  prior to every iteration \nof the  loop.  (Of  course,  you  are  free  to use  established  facts  other than the loop \ninvariant itself to prove that the loop invariant r emains true before each iteration.) \nA loop-invariant  proof  is a form  of mathematical  induction,  where to prove that a \nproperty holds, you prove a base case and an induct ive step. Here, showing that the \ninvariant  holds  before  the  \u00fbrst  iteration  corresponds  to the base case, and showing \nthat the invariant holds from iteration to iteratio n corresponds to the inductive step. \nThe third property is perhaps the most important on e, since you are using the \nloop invariant to show correctness. Typically, you use the loop invariant along with \nthe condition that caused the loop to terminate. Ma thematical induction typically \napplies  the  inductive  step  in\u00fbnitely,  but  in a loop  invarian t the <induction= stops \nwhen the loop terminates. 2.1 Insertion sort 21 \nLet\u2019s  see  how  these  properties  hold  for  insertion  sort.  \nInitialization:  We  start  by  showing  that  the  loop  invariant  holds  before  the  \u00fbrst \nloop iteration, when i D 2. 2 The subarray A\u01521  W i \ue003 1\ufffd consists of just the \nsingle element A\u01521\ufffd, which is in fact the original element in A\u01521\ufffd. Moreover, \nthis subarray is sorted (after all, how could a sub array with just one value not \nbe sorted?),  which  shows  that  the  loop  invariant  holds  prior  to the  \u00fbrst  iteration  \nof the loop. \nMaintenance:  Next, we tackle the second property: showing that e ach iteration \nmaintains the loop invariant. Informally, the body of the for  loop works by \nmoving the values in A\u0152i  \ue003 1\ufffd, A\u0152i  \ue003 2\ufffd, A\u0152i  \ue003 3\ufffd, and so on by one position \nto the  right  until  it \u00fbnds  the  proper  position  for  A\u0152i\ufffd  (lines  437),  at which  point  \nit inserts the value of A\u0152i\ufffd  (line  8).  The  subarray  A\u01521  W i\ufffd then consists of the \nelements originally in A\u01521  W i\ufffd, but in sorted order. Incrementing  i (increasing \nits value by 1) for the next iteration of the for  loop then preserves the loop \ninvariant. \nA more formal treatment of the second property woul d require us to state and \nshow a loop invariant for the while  loop  of lines  537.  Let\u2019s  not  get  bogged  \ndown  in such  formalism  just  yet.  Instead,  we\u2019ll  rely  on  our  informal analysis to \nshow that the second property holds for the outer l oop. \nTermination:  Finally, we examine loop termination. The loop vari able i starts \nat 2 and increases by 1 in each  iteration.  Once  i \u2019s value  exceeds  n in line  1, the  \nloop terminates. That is, the loop terminates once i equals n C 1. Substituting \nn C 1 for i in the wording of the loop invariant yields that th e subarray A\u01521  W n\ufffd \nconsists of the elements originally in A\u01521  W n\ufffd, but in sorted order. Hence, the \nalgorithm is correct. \nThis method of loop invariants is used to show corr ectness in various places \nthroughout this book. \nPseudocode  conventions  \nWe use the following conventions in our pseudocode.  \n\ue001 Indentation indicates block structure. For example,  the body of the for  loop that \nbegins  on  line  1 consists  of lines  238,  and  the  body  of the  while  loop that \n2 When the loop is a for  loop,  the  loop-invariant  check  just  prior  to the  \u00fbrst  iteration  occurs  immedi-  \nately  after  the  initial  assignment  to the  loop-counter  variable  and  just  before  the  \u00fbrst  test  in the  loop  \nheader. In the case of I NSERTION-SORT, this time is after assigning 2 to the variable i but before the \n\u00fbrst  test  of whether  i \u0dc4 n. 22 Chapter 2 Getting Started \nbegins  on  line  5 contains  lines  637  but  not  line  8. Our  indenta tion style applies \nto if-else  statements 3 as well. Using indentation instead of textual indic ators \nof block structure, such as begin  and end  statements or curly braces, reduces \nclutter while preserving, or even enhancing, clarit y. 4 \n\ue001 The looping constructs while , for, and repeat-until  and the if-else  conditional \nconstruct  have  interpretations  similar  to those  in C, C++,  Java, Python, and \nJavaScript.  5 In this book, the loop counter retains its value af ter the loop is \nexited,  unlike  some  situations  that  arise  in C++  and  Java.  Thus, immediately \nafter a for  loop,  the  loop  counter\u2019s  value  is the  value  that  \u00fbrst  exceede d the for  \nloop bound. 6 We used this property in our correctness argument f or insertion \nsort. The for  loop  header  in line  1 is for  i D 2 to n, and so when this loop \nterminates, i equals nC1. We use the keyword to when a for  loop increments its \nloop counter in each iteration, and we use the keyw ord downto  when a for  loop \ndecrements  its loop counter (reduces its value by 1 in each iteration). When \nthe loop counter changes by an amount greater than 1, the amount of change \nfollows the optional keyword by. \n\ue001 The symbol < / /= indicates that the remainder of the line is a com ment. \n\ue001 Variables (such as i , j , and key) are  local  to the  given  procedure.  We  won\u2019t  use  \nglobal variables without explicit indication. \n\ue001 We access array elements by specifying the array na me followed by the index \nin square brackets. For example, A\u0152i\ufffd  indicates the i th element of the array A. \nAlthough many programming languages enforce 0-origin  indexing  for  arrays  (0 \nis the smallest valid index), we choose whichever i ndexing scheme is clearest \nfor human readers to understand. Because people usu ally start counting at 1, \nnot 0, most4but  not  all4of  the  arrays  in this  book  use  1-origin  indexing.  To  be \n3 In an if-else  statement, we indent else  at the same level as its matching if. The  \u00fbrst  executable  line  \nof an else  clause appears on the same line as the keyword else. For multiway tests, we use elseif  for \ntests  after  the  \u00fbrst  one.  When  it is the  \u00fbrst  line  in an  else  clause, an if statement appears on the line \nfollowing else  so that you do not misconstrue it as elseif . \n4 Each pseudocode procedure in this book appears on o ne page so that you do not need to discern \nlevels of indentation in pseudocode that is split a cross pages. \n5 Most  block-structured  languages  have  equivalent  construc ts, though the exact syntax may differ. \nPython lacks repeat-until  loops, and its for  loops operate differently from the for  loops in this book. \nThink of the pseudocode line < for  i D 1 to n= as equivalent  to <for  i in range(1,  n+1)=  in Python.  \n6 In Python, the loop counter retains its value after  the loop is exited, but the value it retains is th e \nvalue  it had  during  the  \u00fbnal  iteration  of the  for  loop, rather than the value that exceeded the loop \nbound. That is because a Python for  loop iterates through a list, which may contain non numeric \nvalues. 2.1 Insertion sort 23 \nclear about whether a particular algorithm assumes 0-origin  or 1-origin  index-  \ning,  we\u2019ll  specify  the  bounds  of the  arrays  explicitly.  If you are implementing \nan algorithm that we specify using 1-origin  indexing,  but  you\u2019re  writing  in a \nprogramming language that enforces 0-origin  indexing  (such  as C, C++,  Java,  \nPython,  or JavaScript),  then  give  yourself  credit  for  being  able to adjust. You \ncan either always subtract 1 from each index or allocate each array with one \nextra position and just ignore position 0. \nThe notation < W= denotes a subarray. Thus, A\u0152i  W j\ufffd indicates the subarray of A \nconsisting of the elements A\u0152i\ufffd;A\u0152i  C 1\ufffd;:::;A\u0152j\ufffd . 7 We also use this notation \nto indicate the bounds of an array, as we did earli er when discussing the array \nA\u01521  W n\ufffd. \n\ue001 We typically organize compound data into objects , which are composed of \nattributes . We access a particular attribute using the syntax  found in many \nobject-oriented  programming  languages:  the  object  name,  followed by a dot, \nfollowed by the attribute name. For example, if an object x has attribute f , we \ndenote this attribute by x: f . \nWe treat a variable representing an array or object  as a pointer (known as a \nreference in some programming languages) to the dat a representing the array \nor object. For all attributes f of an object x , setting y D x causes y: f to \nequal x: f . Moreover, if we now set x: f D 3, then afterward not only does x: f \nequal 3, but y: f equals 3 as well. In other words, x and y point to the same \nobject after the assignment y D x . This way of treating arrays and objects is \nconsistent with most contemporary programming langu ages. \nOur  attribute  notation  can  <cascade.=  For  example,  suppose  that the attribute f \nis itself a pointer to some type of object that has  an attribute g. Then the notation \nx: f : g is implicitly parenthesized as .x:  f /: g. In other words, if we had assigned \ny D x: f , then x: f : g is the same as y: g. \nSometimes a pointer refers to no object at all. In this case, we give it the special \nvalue NIL. \n\ue001 We pass parameters to a procedure by value : the called procedure receives its \nown copy of the parameters, and if it assigns a val ue to a parameter, the change \nis not seen by the calling procedure. When objects are pas sed, the pointer to \nthe  data  representing  the  object  is copied,  but  the  object\u2019s  attributes are not. For \nexample, if x is a parameter of a called procedure, the assignmen t x D y within \n7 If you\u2019re  used  to programming  in Python,  bear  in mind  that  in this book, the subarray A\u0152i  W j\ufffd \nincludes the element A\u0152j\ufffd . In Python, the last element of A\u0152i  W j\ufffd is A\u0152j  \ue003 1\ufffd. Python allows negative \nindices, which count from the back end of the list.  This book does not use negative array indices. 24 Chapter 2 Getting Started \nthe called procedure is not visible to the calling procedure. The assignment \nx: f D 3, however, is visible if the calling procedure has a pointer to the same \nobject as x . Similarly, arrays are passed by pointer, so that a pointer to the array \nis passed, rather than the entire array, and change s to individual array elements \nare visible to the calling procedure. Again, most c ontemporary programming \nlanguages work this way. \n\ue001 A return  statement immediately transfers control back to the  point of call in \nthe calling procedure. Most return  statements also take a value to pass back to \nthe  caller.  Our  pseudocode  differs  from  many  programming  languages in that \nwe allow multiple values to be returned in a single  return  statement without \nhaving to create objects to package them together. 8 \n\ue001 The boolean operators <and= and <or= are short  circuiting . That is, evaluate \nthe expression < x and y = by  \u00fbrst  evaluating  x . If x evaluates to FALSE , then \nthe entire expression cannot evaluate to TRUE , and therefore y is not evaluated. \nIf, on the other hand, x evaluates to TRUE , y must be evaluated to determine \nthe value of the entire expression. Similarly, in t he expression < x or y = the  ex-  \npression y is evaluated only if x evaluates to FALSE. Short-circuiting  operators  \nallow us to write boolean expressions such as < x \u00a4 NIL and x: f D y = without \nworrying about what happens upon evaluating x: f when x is NIL. \n\ue001 The keyword error  indicates that an error occurred because conditions  were \nwrong for the procedure to have been called, and th e procedure immediately \nterminates. The calling procedure is responsible fo r handling the error, and so \nwe do not specify what action to take. \nExercises  \n2.1-1  \nUsing Figure 2.2 as a model, illustrate the operati on of I NSERTION-SORT  on an \narray initially containing the sequence h31;41;59;26;41;58 i. \n2.1-2  \nConsider the procedure S UM-ARRAY on the facing page. It computes the sum of \nthe n numbers in array A\u01521  W n\ufffd. State a loop invariant for this procedure, and us e \nits initialization, maintenance, and termination pr operties to show that the S UM- \nARRAY procedure returns the sum of the numbers in A\u01521  W n\ufffd. \n8 Python\u2019s  tuple  notation  allows  return  statements to return multiple values without creati ng objects \nfrom  a programmer-de\u00fbned  class.  2.2  Analyzing  algorithms  25 \nSUM-ARRAY.A;n/  \n1 sum  D 0 \n2 for  i D 1 to n \n3 sum  D sum  C A\u0152i\ufffd  \n4 return  sum  \n2.1-3  \nRewrite the I NSERTION-SORT  procedure  to sort  into  monotonically  decreasing  in-  \nstead of monotonically increasing order. \n2.1-4  \nConsider the searching  problem : \nInput:  A sequence of n numbers ha 1 ;a  2 ;:::;a  n i stored in array A\u01521  W n\ufffd and a \nvalue x . \nOutput:  An index i such that x equals A\u0152i\ufffd  or the special value NIL if x does not \nappear in A. \nWrite pseudocode for linear  search, which  scans  through  the  array  from  begin-  \nning to end, looking for x . Using a loop invariant, prove that your algorithm  is \ncorrect.  Make  sure  that  your  loop  invariant  ful\u00fblls  the  three necessary properties. \n2.1-5  \nConsider the problem of adding two n-bit  binary  integers  a and b, stored in two \nn-element  arrays  A\u01520  W n \ue003 1\ufffd and B\u01520  W n \ue003 1\ufffd, where each element is either 0 \nor 1, a D P  n\ue0021 \ni D0 A\u0152i\ufffd  \ue001 2 i , and b D P  n\ue0021 \ni D0 B\u0152i\ufffd  \ue001 2 i . The sum c D a C b of the \ntwo integers should be stored in binary form in an .n C 1/-element  array  C\u01520  W n\ufffd, \nwhere c D P  n \ni D0 C\u0152i\ufffd  \ue001 2 i . Write a procedure A DD-BINARY-I NTEGERS  that takes \nas input arrays A and B , along with the length n, and returns array C holding the \nsum. \n2.2  Analyzing  algorithms  \nAnalyzing  an algorithm has come to mean predicting the resour ces that the algo-  \nrithm requires. You might consider resources such a s memory, communication \nbandwidth, or energy consumption. Most often, howev er, you\u2019ll want  to measure  \ncomputational time. If you analyze several candidat e algorithms for a problem, 26 Chapter 2 Getting Started \nyou  can  identify  the  most  ef\u00fbcient  one.  There  might  be more  than just one viable \ncandidate, but you can often rule out several infer ior algorithms in the process. \nBefore you can analyze an algorithm, you need a mod el of the technology that \nit runs on, including the resources of that technol ogy and a way to express their \ncosts.  Most  of this  book  assumes  a generic  one-processor,  random-access  ma-  \nchine  (RAM)  model of computation as the implementation technolo gy, with the \nunderstanding that algorithms are implemented as co mputer programs. In the RAM \nmodel, instructions execute one after another, with  no concurrent operations. The \nRAM model assumes that each instruction takes the s ame amount of time as any \nother  instruction  and  that  each  data  access4using  the  value  of a variable or storing \ninto  a variable4takes  the  same  amount  of time  as any  other  data access. In other \nwords, in the RAM model each instruction or data ac cess takes a constant amount \nof time4even  indexing  into  an array.  9 \nStrictly  speaking,  we  should  precisely  de\u00fbne  the  instructi ons of the RAM model \nand their costs. To do so, however, would be tediou s and yield little  insight  into  al-  \ngorithm design and analysis. Yet we must be careful  not to abuse the RAM model. \nFor  example,  what  if a RAM  had  an instruction  that  sorts?  Then  you could sort \nin just one step. Such a RAM would be unrealistic, since such instructions do \nnot  appear  in real  computers.  Our  guide,  therefore,  is how  real  computers  are  de-  \nsigned. The RAM model contains instructions commonl y found in real computers: \narithmetic (such as add, subtract, multiply, divide , remainder,  \u00fcoor,  ceiling),  data  \nmovement (load, store, copy), and control (conditio nal and unconditional branch, \nsubroutine call and return). \nThe  data  types  in the  RAM  model  are  integer,  \u00fcoating  point  (for  storing  real-  \nnumber approximations), and character. Real compute rs do not usually have a \nseparate data type for the boolean values TRUE and FALSE . Instead, they often test \nwhether an integer value is 0 (FALSE ) or nonzero ( TRUE ), as in C. Although we \ntypically  do  not  concern  ourselves  with  precision  for  \u00fcoating-point  values  in this  \nbook  (many  numbers  cannot  be represented  exactly  in \u00fcoating  point), precision is \ncrucial for most applications. We also assume that each word of data has a limit on \nthe number of bits. For example, when working with inputs of size n, we typically \n9 We assume that each element of a given array occupi es the same number of bytes and that the \nelements of a given array are stored in contiguous memory locations. For example, if array A\u01521  W n\ufffd \nstarts at memory address 1000  and each element occupies four bytes, then element A\u0152i\ufffd  is at address \n1000  C 4.i  \ue003 1/. In general, computing the address in memory of a particular array element requires \nat most one subtraction (no subtraction for a 0-origin  array),  one  multiplication  (often  implemented  \nas a shift operation if the element size is an exac t power of 2), and one addition. Furthermore, for \ncode that iterates through the elements of an array  in order, an optimizing compiler can generate the \naddress of each element using just one addition, by  adding the element size to the address of the \npreceding element. 2.2  Analyzing  algorithms  27 \nassume that integers are represented by c log 2 n bits for some constant c \ue004 1. We \nrequire c \ue004 1 so that each word can hold the value of n, enabling us to index \nthe individual input elements, and we restrict c to be a constant so that the word \nsize does not grow arbitrarily. (If the word size c ould grow arbitrarily, we could \nstore huge amounts of data in one word and operate on it all in constant  time4an  \nunrealistic scenario.) \nReal computers contain instructions not listed abov e, and such  instructions  rep-  \nresent a gray area in the RAM model. For example, i s exponentiation  a constant-  \ntime  instruction?  In the  general  case,  no:  to compute  x n when x and n are general \nintegers typically takes time logarithmic in n (see  equation  (31.34)  on  page  934),  \nand  you  must  worry  about  whether  the  result  \u00fbts  into  a compute r word. If n is an \nexact power of 2, however, exponentiation can usually be viewed as a constant-time  \noperation. Many computers have a <shift left= instr uction, which in constant time \nshifts the bits of an integer by n positions to the left. In most computers, shifting \nthe bits of an integer by 1 position to the left is equivalent to multiplying b y 2, so \nthat shifting the bits by n positions to the left is equivalent to multiplying by 2 n . \nTherefore, such computers can compute 2 n in 1 constant-time  instruction  by  shift-  \ning the integer 1 by n positions to the left, as long as n is no more than the number \nof bits  in a computer  word.  We\u2019ll  try  to avoid  such  gray  areas  in the RAM model \nand treat computing 2 n and multiplying by 2 n as constant-time  operations  when  \nthe  result  is small  enough  to \u00fbt in a computer  word.  \nThe RAM model does not account for the memory hiera rchy that is common \nin contemporary computers. It models neither caches  nor virtual  memory.  Sev-  \neral other computational models attempt to account for memory-hierarchy  effects,  \nwhich  are  sometimes  signi\u00fbcant  in real  programs  on  real  machines.  Section  11.5  \nand  a handful  of problems  in this  book  examine  memory-hierar chy effects, but for \nthe most part, the analyses in this book do not con sider them. Models that include \nthe memory hierarchy are quite a bit more complex t han the RAM model, and so \nthey  can  be dif\u00fbcult  to work  with.  Moreover,  RAM-model  analy ses are usually \nexcellent predictors of performance on actual machi nes. \nAlthough it is often straightforward to analyze an algorithm in the RAM model, \nsometimes it can be quite a challenge. You might ne ed to employ mathematical \ntools such as combinatorics, probability theory, al gebraic dexterity, and the ability \nto identify  the  most  signi\u00fbcant  terms  in a formula.  Because  an algorithm might \nbehave differently for each possible input, we need  a means for summarizing that \nbehavior in simple, easily understood formulas. \nAnalysis  of insertion  sort  \nHow long does the I NSERTION-SORT  procedure  take?  One  way  to tell  would  be for  \nyou to run it on your computer and time how long it  takes to run. Of  course,  you\u2019d  28 Chapter 2 Getting Started \n\u00fbrst  have  to implement  it in a real  programming  language,  since you cannot run our \npseudocode  directly.  What  would  such  a timing  test  tell  you?  You  would  \u00fbnd  out  \nhow long insertion sort takes to run on your partic ular computer, on that particular \ninput, under the particular implementation that you  created, with the particular \ncompiler or interpreter that you ran, with the part icular libraries that you linked \nin, and with the particular background tasks that w ere running on your computer \nconcurrently with your timing test (such as checkin g for incoming information over \na network). If you run insertion sort again on your  computer with the same input, \nyou might even get a different timing result. From running just one implementation \nof insertion sort on just one computer and on just one input, what would you be able \nto determine  about  insertion  sort\u2019s  running  time  if you  were  to give it a different \ninput, if you were to run it on a different compute r, or if you were to implement it \nin a different  programming  language?  Not  much.  We  need  a way  to predict, given \na new input, how long insertion sort will take. \nInstead of timing a run, or even several runs, of i nsertion sort, we can determine \nhow  long  it takes  by  analyzing  the  algorithm  itself.  We\u2019ll  examine how many times \nit executes each line of pseudocode and how long ea ch line of pseudocode takes \nto run.  We\u2019ll  \u00fbrst  come  up  with  a precise  but  complicated  form ula for the running \ntime.  Then,  we\u2019ll  distill  the  important  part  of the  formula  using  a convenient  no-  \ntation that can help us compare the running times o f different algorithms for the \nsame problem. \nHow  do  we  analyze  insertion  sort?  First,  let\u2019s  acknowledge  that the running time \ndepends  on  the  input.  You  shouldn\u2019t  be terribly  surprised  that sorting a thousand \nnumbers takes longer than sorting three numbers. Mo reover, insertion sort can take \ndifferent amounts of time to sort two input arrays of the same size, depending on \nhow nearly sorted they already are. Even though the  running time can depend on \nmany  features  of the  input,  we\u2019ll  focus  on  the  one  that  has  been shown to have \nthe greatest effect, namely the size of the input, and describe the running time of a \nprogram as a function of the size of its input. To do so, we need to de\u00fbne  the  terms  \n<running time= and <input size= more carefully. We also need to be clear about \nwhether we are discussing the running time for an i nput that elicits  the  worst-case  \nbehavior,  the  best-case  behavior,  or some  other  case.  \nThe best notion for input  size  depends on the problem being studied. For many \nproblems, such as sorting or computing discrete Fou rier transforms,  the  most  nat-  \nural measure is the number  of items  in the  input4for  example,  the  number  n of \nitems being sorted. For many other problems, such a s multiplying two integers, \nthe best measure of input size is the total  number  of bits  needed to represent the \ninput in ordinary binary notation. Sometimes it is more appropriate to describe the \nsize of the input with more than just one number. F or example, if the input to an \nalgorithm is a graph, we usually characterize the i nput size by both the number 2.2  Analyzing  algorithms  29 \nof vertices  and  the  number  of edges  in the  graph.  We\u2019ll  indica te which input size \nmeasure is being used with each problem we study. \nThe running  time  of an algorithm  on  a particular  input  is the  number  of in-  \nstructions and data accesses executed. How we accou nt for these costs should be \nindependent of any particular computer, but within the framework of the RAM \nmodel. For the moment, let us adopt the following v iew. A constant amount of \ntime  is required  to execute  each  line  of our  pseudocode.  One  line might take more \nor less  time  than  another  line,  but  we\u2019ll  assume  that  each  execution of the kth line \ntakes c k time, where c k is a constant. This viewpoint is in keeping with th e RAM \nmodel,  and  it also  re\u00fcects  how  the  pseudocode  would  be implem ented on most \nactual computers. 10  \nLet\u2019s  analyze  the  I NSERTION-SORT  procedure.  As  promised,  we\u2019ll  start  by  de-  \nvising a precise formula that uses the input size a nd all the statement costs c k . \nThis  formula  turns  out  to be messy,  however.  We\u2019ll  then  switch  to a simpler  no-  \ntation that is more concise and easier to use. This  simpler notation makes clear \nhow to compare the running times of algorithms, esp ecially as the size of the input \nincreases. \nTo analyze the I NSERTION-SORT  procedure,  let\u2019s  view  it on  the  following  page  \nwith the time cost of each statement and the number  of times each statement is \nexecuted. For each i D 2;3;:::;n , let t i denote the number of times the while  \nloop  test  in line  5 is executed  for  that  value  of i . When a for  or while  loop exits \nin the  usual  way4because  the  test  in the  loop  header  comes  up  FALSE4the  test  is \nexecuted one time more than the loop body. Because comments are not executable \nstatements, assume that they take no time. \nThe running time of the algorithm is the sum of run ning times for each  state-  \nment executed. A statement that takes c k steps to execute and executes m times \ncontributes c k m to the total running time. 11  We usually denote the running time of \nan algorithm on an input of size n by T.n/ . To compute T.n/ , the running time \nof I NSERTION-SORT  on an input of n values, we sum the products of the cost  and \ntimes columns, obtaining \n10  There are some subtleties here. Computational steps  that we specify in English are often variants \nof a procedure that requires more than just a const ant amount of time. For example, in the R ADIX- \nSORT  procedure  on  page  213,  one  line  reads  <use  a stable  sort  to sort array A on digit i ,= which, \nas we shall see, takes more than a constant amount of time. Also, although a statement that calls a \nsubroutine takes only constant time, the subroutine  itself, once invoked, may take more. That is, we \nseparate the process of calling  the  subroutine4passing  parameters  to it, etc.4from  the  process of \nexecuting  the subroutine. \n11  This characteristic does not necessarily hold for a  resource such as memory. A statement that \nreferences m words of memory and is executed n times does not necessarily reference mn  distinct \nwords of memory. 30 Chapter 2 Getting Started \nI NSERTION-SORT  .A;n/  cost  times  \n1 for  i D 2 to n c 1 n \n2 key  D A\u0152i\ufffd  c 2 n \ue003 1 \n3 / / Insert A\u0152i\ufffd  into the sorted subarray A\u01521  W i \ue003 1\ufffd. 0 n \ue003 1 \n4 j D i \ue003 1 c 4 n \ue003 1 \n5 while  j >0  and A\u0152j\ufffd>  key  c 5 P  n \ni D2 t i \n6 A\u0152j  C 1\ufffd D A\u0152j\ufffd  c 6 P  n \ni D2 .t i \ue003 1/ \n7 j D j \ue003 1 c 7 P  n \ni D2 .t i \ue003 1/ \n8 A\u0152j  C 1\ufffd D key  c 8 n \ue003 1 \nT.n/  D c 1 n C c 2 .n \ue003 1/ C c 4 .n \ue003 1/ C c 5 n X  \ni D2 t i C c 6 n X  \ni D2 .t i \ue003 1/ \nC c 7 n X  \ni D2 .t i \ue003 1/ C c 8 .n \ue003 1/:  \nEven  for  inputs  of a given  size,  an algorithm\u2019s  running  time  may depend on \nwhich  input of that size is given. For example, in I NSERTION-SORT, the best case \noccurs when the array is already sorted. In this ca se, each time  that  line  5 executes,  \nthe value of key4the  value  originally  in A\u0152i\ufffd4is  already  greater  than  or equal  to \nall values in A\u01521  W i \ue003 1\ufffd, so that the while  loop  of lines  537  always  exits  upon  the  \n\u00fbrst  test  in line  5. Therefore,  we  have  that  t i D 1 for i D 2;3;:::;n , and the \nbest-case  running  time  is given  by  \nT.n/  D c 1 n C c 2 .n \ue003 1/ C c 4 .n \ue003 1/ C c 5 .n \ue003 1/ C c 8 .n \ue003 1/ \nD .c 1 C c 2 C c 4 C c 5 C c 8 /n \ue003 .c 2 C c 4 C c 5 C c 8 /: (2.1)  \nWe can express this running time as an  C b for constants  a and b that depend on \nthe statement costs c k (where a D c 1 Cc 2 Cc 4 Cc 5 Cc 8 and b D c 2 Cc 4 Cc 5 Cc 8 ). \nThe running time is thus a linear  function  of n. \nThe worst case arises when the array is in reverse sorted order4that  is, it starts  \nout in decreasing order. The procedure must compare  each element A\u0152i\ufffd  with each \nelement in the entire sorted subarray A\u01521  W i \ue003 1\ufffd, and so t i D i for i D 2;3;:::;n . \n(The  procedure  \u00fbnds  that  A\u0152j\ufffd>  key  every  time  in line  5, and  the  while  loop exits \nonly when j reaches 0.) Noting that \nn X  \ni D2 i D \ue001 n X  \ni D1 i ! \n\ue003 1 \nD n.n  C 1/ \n2 \ue003 1 (by  equation  (A.2)  on  page  1141)  2.2  Analyzing  algorithms  31 \nand \nn X  \ni D2 .i \ue003 1/ D n\ue0021 X  \ni D1 i \nD n.n  \ue003 1/ \n2 (again, by equation (A.2)) , \nwe  \u00fbnd  that  in the  worst  case,  the  running  time  of I NSERTION-SORT  is \nT.n/  D c 1 n C c 2 .n \ue003 1/ C c 4 .n \ue003 1/ C c 5 \u00ce n.n  C 1/ \n2 \ue003 1 \u00cf \nC c 6 \u00ce n.n  \ue003 1/ \n2 \u00cf \nC c 7 \u00ce n.n  \ue003 1/ \n2 \u00cf \nC c 8 .n \ue003 1/ \nD \ue002 c 5 \n2 C c 6 \n2 C c 7 \n2 \u00cd \nn 2 C \ue002 \nc 1 C c 2 C c 4 C c 5 \n2 \ue003 c 6 \n2 \ue003 c 7 \n2 C c 8 \u00cd \nn \n\ue003 .c 2 C c 4 C c 5 C c 8 /: (2.2) \nWe  can  express  this  worst-case  running  time  as an  2 C bn  C c for constants a, b, \nand c that again depend on the statement costs c k (now, a D c 5 =2  C c 6 =2  C c 7 =2, \nb D c 1 C c 2 C c 4 C c 5 =2  \ue003 c 6 =2  \ue003 c 7 =2  C c 8 , and c D \ue003.c 2 C c 4 C c 5 C c 8 /). The \nrunning time is thus a quadratic  function  of n. \nTypically, as in insertion sort, the running time o f an algorithm  is \u00fbxed  for  a \ngiven  input,  although  we\u2019ll  also  see  some  interesting  <rand omized= algorithms \nwhose  behavior  can  vary  even  for  a \u00fbxed  input.  \nWorst-case  and  average-case  analysis  \nOur  analysis  of insertion  sort  looked  at both  the  best  case,  in which the input array \nwas already sorted, and the worst case, in which th e input array was reverse sorted. \nFor  the  remainder  of this  book,  though,  we\u2019ll  usually  (but  not always) concentrate \non  \u00fbnding  only  the  worst-case  running  time, that is, the longest running time for \nany  input of size n. Why?  Here  are  three  reasons:  \n\ue001 The  worst-case  running  time  of an algorithm  gives  an upper  bound  on  the  run-  \nning time for any  input. If you know it, then you have a guarantee th at the \nalgorithm never takes any longer. You need not make  some educated guess \nabout the running time and hope that it never gets much worse. This feature is \nespecially  important  for  real-time  computing,  in which  operations  must  com-  \nplete by a deadline. \n\ue001 For some algorithms, the worst case occurs fairly o ften. For example,  in search-  \ning a database for a particular piece of informatio n, the searching  algorithm\u2019s  \nworst case often occurs when the information is not  present in the database. In \nsome applications, searches for absent information may be frequent. 32 Chapter 2 Getting Started \n\ue001 The <average case= is often roughly as bad as the w orst case. Suppose that \nyou run insertion sort on an array of n randomly chosen numbers. How long \ndoes it take to determine where in subarray A\u01521  W i \ue003 1\ufffd to insert element A\u0152i\ufffd? \nOn  average,  half  the  elements  in A\u01521  W i \ue003 1\ufffd are less than A\u0152i\ufffd, and half the \nelements  are  greater.  On  average,  therefore,  A\u0152i\ufffd  is compared with just half \nof the subarray A\u01521  W i \ue003 1\ufffd, and so t i is about i=2. The  resulting  average-case  \nrunning time turns out to be a quadratic function o f the input size, just like the \nworst-case  running  time.  \nIn some  particular  cases,  we\u2019ll  be interested  in the  average-case  running time of \nan algorithm.  We\u2019ll  see  the  technique  of probabilistic  analysis  applied to various \nalgorithms  throughout  this  book.  The  scope  of average-case  analysis is limited, \nbecause it may not be apparent what constitutes an <average= input for a particular \nproblem.  Often,  we\u2019ll  assume  that  all  inputs  of a given  size  are equally likely. In \npractice, this assumption may be violated, but we c an sometimes use a randomized  \nalgorithm , which makes random choices, to allow a probabilis tic analysis and yield \nan expected  running time. We explore randomized algorithms more  in Chapter  5 \nand in several other subsequent chapters. \nOrder  of growth  \nIn order to ease our analysis of the I NSERTION-SORT  procedure, we used some \nsimplifying abstractions. First, we ignored the act ual cost of each statement, using \nthe constants c k to represent  these  costs.  Still,  the  best-case  and  worst-case  run-  \nning  times  in equations  (2.1)  and  (2.2)  are  rather  unwieldy.  The constants in these \nexpressions  give  us more  detail  than  we  really  need.  That\u2019s  why we also expressed \nthe  best-case  running  time  as an  C b for constants a and b that  depend  on  the  state-  \nment costs c k and  why  we  expressed  the  worst-case  running  time  as an  2 C bn  C c \nfor constants a, b, and c that depend on the statement costs. We thus ignored  not \nonly the actual statement costs, but also the abstr act costs c k . \nLet\u2019s  now  make  one  more  simplifying  abstraction:  it is the  rate  of growth , or \norder  of growth , of the running time that really interests us. We therefore consider \nonly the leading term of a formula (e.g., an  2 ), since  the  lower-order  terms  are  rela-  \ntively  insigni\u00fbcant  for  large  values  of n. We  also  ignore  the  leading  term\u2019s  constant  \ncoef\u00fbcient,  since  constant  factors  are  less  signi\u00fbcant  than  the  rate  of growth  in de-  \ntermining  computational  ef\u00fbciency  for  large  inputs.  For  insertion  sort\u2019s  worst-case  \nrunning  time,  when  we  ignore  the  lower-order  terms  and  the  leading  term\u2019s  con-  \nstant  coef\u00fbcient,  only  the  factor  of n 2 from the leading term remains. That factor, \nn 2 , is by far the most important part of the running time. For example, suppose that \nan algorithm implemented on a particular machine ta kes n 2 =100  C 100n  C 17  mi-  \ncroseconds on an input of size n. Although  the  coef\u00fbcients  of 1=100  for the n 2 term \nand 100  for the n term differ by four orders of magnitude, the n 2 =100  term  domi-  2.2  Analyzing  algorithms  33 \nnates the 100n  term once n exceeds  10,000.  Although  10,000  might  seem  large,  it \nis smaller  than  the  population  of an average  town.  Many  real-world problems have \nmuch larger input sizes. \nTo highlight the order of growth of the running tim e, we have a special notation \nthat  uses  the  Greek  letter  \u201a (theta).  We  write  that  insertion  sort  has  a worst-case  \nrunning time of \u201a.n  2 / (pronounced <theta of n-squared=  or just  <theta  n-squared=).  \nWe  also  write  that  insertion  sort  has  a best-case  running  time of \u201a.n/  (<theta of n= \nor <theta n=). For now, think of \u201a-notation  as saying  <roughly  proportional  when  \nn is large,= so that \u201a.n  2 / means <roughly proportional to n 2 when n is large= and \n\u201a.n/  means <roughly proportional to n when n is large=  We\u2019ll  use  \u201a-notation  \ninformally  in this  chapter  and  de\u00fbne  it precisely  in Chapter  3. \nWe  usually  consider  one  algorithm  to be more  ef\u00fbcient  than  another  if its  worst-  \ncase running time has a lower order of growth. Due to constant factors  and  lower-  \norder terms, an algorithm whose running time has a higher order of growth might \ntake less time for small inputs than an algorithm w hose running  time  has  a lower  or-  \nder of growth. But on large enough inputs, an algor ithm whose worst-case  running  \ntime is \u201a.n  2 /, for example, takes less time in the worst case th an an algorithm \nwhose  worst-case  running  time  is \u201a.n  3 /. Regardless of the constants hidden by \nthe \u201a-notation,  there  is always  some  number,  say  n 0 , such that for all input sizes \nn \ue004 n 0 , the \u201a.n  2 / algorithm beats the \u201a.n  3 / algorithm in the worst case. \nExercises  \n2.2-1  \nExpress the function n 3 =1000  C 100n  2 \ue003 100n  C 3 in terms of \u201a-notation.  \n2.2-2  \nConsider sorting n numbers stored in array A\u01521  W n\ufffd by  \u00fbrst  \u00fbnding  the  smallest  \nelement of A\u01521  W n\ufffd and exchanging it with the element in A\u01521\ufffd. Then  \u00fbnd  the  \nsmallest element of A\u01522  W n\ufffd, and exchange it with A\u01522\ufffd. Then  \u00fbnd  the  smallest  \nelement of A\u01523  W n\ufffd, and exchange it with A\u01523\ufffd. Continue in this manner for the \n\u00fbrst  n \ue003 1 elements of A. Write pseudocode for this algorithm, which is kno wn \nas selection  sort. What  loop  invariant  does  this  algorithm  maintain?  Why  does  it \nneed  to run  for  only  the  \u00fbrst  n \ue003 1 elements, rather than for all n elements?  Give  the  \nworst-case  running  time  of selection  sort  in \u201a-notation.  Is the  best-case  running  \ntime  any  better?  \n2.2-3  \nConsider  linear  search  again  (see  Exercise  2.1-4).  How  many  elements of the input \narray need to be checked on the average, assuming t hat the element being searched \nfor  is equally  likely  to be any  element  in the  array?  How  about  in the  worst  case?  34 Chapter 2 Getting Started \nUsing \u201a-notation,  give  the  average-case  and  worst-case  running  times of linear \nsearch.  Justify  your  answers.  \n2.2-4  \nHow  can  you  modify  any  sorting  algorithm  to have  a good  best-case  running  time?  \n2.3  Designing  algorithms  \nYou can choose from a wide range of algorithm desig n techniques. Insertion sort \nuses the incremental  method: for each element A\u0152i\ufffd, insert it into its proper place \nin the subarray A\u01521  W i\ufffd, having already sorted the subarray A\u01521  W i \ue003 1\ufffd. \nThis section examines another design method, known as <divide-and-conquer,=  \nwhich  we  explore  in more  detail  in Chapter  4. We\u2019ll  use  divide-and-conquer  to \ndesign  a sorting  algorithm  whose  worst-case  running  time  is much less than that \nof insertion  sort.  One  advantage  of using  an algorithm  that  follows  the  divide-and-  \nconquer method is that analyzing its running time i s often straightforward, using \ntechniques  that  we\u2019ll  explore  in Chapter  4. \n2.3.1  The  divide-and-conquer  method  \nMany useful algorithms are recursive  in structure: to solve a given problem, they \nrecurse  (call themselves) one or more times to handle close ly related subprob-  \nlems. These algorithms typically follow the divide-and-conquer  method: they \nbreak the problem into several subproblems that are  similar to the  original  prob-  \nlem but smaller in size, solve the subproblems recu rsively, and then combine these \nsolutions to create a solution to the original prob lem. \nIn the  divide-and-conquer  method,  if the  problem  is small  enough4the  base  \ncase4you  just  solve  it directly  without  recursing.  Otherwise4t he recursive  case  \n4you  perform  three  characteristic  steps:  \nDivide  the problem into one or more subproblems that are s maller instances of the \nsame problem. \nConquer  the subproblems by solving them recursively. \nCombine  the subproblem solutions to form a solution to the original problem. \nThe merge  sort  algorithm  closely  follows  the  divide-and-conquer  method.  In \neach step, it sorts a subarray A\u0152p  W r\ufffd, starting with the entire array A\u01521  W n\ufffd and \nrecursing down to smaller and smaller subarrays. He re is how merge sort operates: 2.3 Designing algorithms 35 \nDivide  the subarray A\u0152p  W r\ufffd to be sorted into two adjacent subarrays, each of h alf \nthe size. To do so, compute the midpoint q of A\u0152p  W r\ufffd (taking the average of p \nand r ), and divide A\u0152p  W r\ufffd into subarrays A\u0152p  W q\ufffd and A\u0152q  C 1 W r\ufffd. \nConquer  by sorting each of the two subarrays A\u0152p  W q\ufffd and A\u0152q  C 1 W r\ufffd recursively \nusing merge sort. \nCombine  by merging the two sorted subarrays A\u0152p  W q\ufffd and A\u0152q  C 1 W r\ufffd back into \nA\u0152p  W r\ufffd, producing the sorted answer. \nThe  recursion  <bottoms  out=4it  reaches  the  base  case4when  the subarray A\u0152p  W r\ufffd \nto be sorted has just 1 element, that is, when p equals r . As  we  noted  in the  ini-  \ntialization argument for I NSERTION-SORT\u2019s loop  invariant,  a subarray  comprising  \njust a single element is always sorted. \nThe key operation of the merge sort algorithm occur s in the <combine= step, \nwhich merges two adjacent, sorted subarrays. The me rge operation is performed \nby the auxiliary procedure M ERGE.A;p;q;r/  on the following page, where A is \nan array and p, q, and r are indices into the array such that p \u0dc4 q < r  . The \nprocedure assumes that the adjacent subarrays A\u0152p  W q\ufffd and A\u0152q  C 1 W r\ufffd were  al-  \nready recursively sorted. It merges  the two sorted subarrays to form a single sorted \nsubarray that replaces the current subarray A\u0152p  W r\ufffd. \nTo understand how the M ERGE  procedure  works,  let\u2019s  return  to our  card-playing  \nmotif. Suppose that you have two piles of cards fac e up on a table. Each pile is \nsorted,  with  the  smallest-value  cards  on  top.  You  wish  to merge the two piles \ninto a single sorted output pile, which is to be fa ce down on the table. The basic \nstep consists of choosing the smaller of the two ca rds on top of the  face-up  piles,  \nremoving  it from  its  pile4which  exposes  a new  top  card4and  placing this card \nface down onto the output pile. Repeat this step un til one input pile is empty, at \nwhich  time  you  can  just  take  the  remaining  input  pile  and  \u00fcip  over the entire pile, \nplacing it face down onto the output pile. \nLet\u2019s  think  about  how  long  it takes  to merge  two  sorted  piles  of cards. Each basic \nstep takes constant time, since you are comparing j ust the two top cards. If the two \nsorted piles that you start with each have n=2  cards, then the number of basic steps \nis at least n=2  (since in whichever pile was emptied, every card wa s found to be \nsmaller than some card from the other pile) and at most n (actually, at most n \ue003 1, \nsince after n \ue003 1 basic steps, one of the piles must be empty). With each basic step \ntaking constant time and the total number of basic steps being between n=2  and n, \nwe can say that merging takes time roughly proporti onal to n. That is, merging \ntakes \u201a.n/  time. \nIn detail, the M ERGE  procedure works as follows. It copies the two subar rays \nA\u0152p  W q\ufffd and A\u0152q  C 1 W r\ufffd into temporary arrays L and R (<left= and <right=), and \nthen it merges the values in L and R back into A\u0152p  W r\ufffd. Lines  1 and  2 compute  the  \nlengths n L and n R of the subarrays A\u0152p  W q\ufffd and A\u0152q  C 1 W r\ufffd, respectively. Then 36 Chapter 2 Getting Started \nMERGE.A;p;q;r/  \n1 n L D q \ue003 p C 1 / / length of A\u0152p  W q\ufffd \n2 n R D r \ue003 q / / length of A\u0152q  C 1 W r\ufffd \n3 let L\u01520  W n L \ue003 1\ufffd and R\u01520  W n R \ue003 1\ufffd be new arrays \n4 for  i D 0 to n L \ue003 1 / / copy A\u0152p  W q\ufffd into L\u01520  W n L \ue003 1\ufffd \n5 L\u0152i\ufffd  D A\u0152p  C i\ufffd \n6 for  j D 0 to n R \ue003 1 / / copy A\u0152q  C 1 W r\ufffd into R\u01520  W n R \ue003 1\ufffd \n7 R\u0152j\ufffd  D A\u0152q  C j C 1\ufffd \n8 i D 0 / / i indexes the smallest remaining element in L \n9 j D 0 / / j indexes the smallest remaining element in R \n10  k D p / / k indexes the location in A to \u00fbll  \n11  / / As long as each of the arrays L and R contains an unmerged element, \n/ / copy the smallest unmerged element back into A\u0152p  W r\ufffd. \n12  while  i<n  L and j <n  R \n13  if L\u0152i\ufffd  \u0dc4 R\u0152j\ufffd  \n14  A\u0152k\ufffd  D L\u0152i\ufffd  \n15  i D i C 1 \n16  else  A\u0152k\ufffd  D R\u0152j\ufffd  \n17  j D j C 1 \n18  k D k C 1 \n19  / / Having gone through one of L and R entirely, copy the \n/ / remainder of the other to the end of A\u0152p  W r\ufffd. \n20 while  i<n  L \n21  A\u0152k\ufffd  D L\u0152i\ufffd  \n22 i D i C 1 \n23  k D k C 1 \n24  while  j <n  R \n25  A\u0152k\ufffd  D R\u0152j\ufffd  \n26  j D j C 1 \n27  k D k C 1 \nline  3 creates  arrays  L\u01520  W n L \ue003 1\ufffd and R\u01520  W n R \ue003 1\ufffd with respective lengths n L \nand n R . 12  The for  loop  of lines  435  copies  the  subarray  A\u0152p  W q\ufffd into L, and the for  \nloop  of lines  637  copies  the  subarray  A\u0152q  C 1 W r\ufffd into R. \nLines  8318,  illustrated  in Figure  2.3,  perform  the  basic  steps. The while  loop \nof lines  12318  repeatedly  identi\u00fbes  the  smallest  value  in L and R that has yet to \n12  This procedure is the rare case that uses both 1-origin  indexing  (for  array  A) and 0-origin  indexing  \n(for arrays L and R). Using 0-origin  indexing  for  L and R makes for a simpler loop invariant in \nExercise  2.3-3.  2.3 Designing algorithms 37 \nA \nL R 1 2 3 \ni j k \n(a) 2 4 6 7 1 2 3 5 A \nL R \ni j k \n(b) 2 4 6 7 1 \n2 3 5 1 2 4 6 7 1 2 3 5 4 6 7 1 2 3 5 \nA \nL R 9 10  11  12  13  14  15  16  \ni j k \n(c) 2 4 6 7 1 \n2 3 5 1 6 7 1 2 3 5 2 A \nL R \ni j k \n(d) 2 4 6 7 1 \n2 3 5 1 7 1 2 3 5 2 2 9 10  11  12  13  14  15  16  \n9 10  11  12  13  14  15  16  9 10  11  12  13  14  15  16  8 \n\u2026 17  \n\u2026 \n8 \n\u2026 17  \n\u2026 8 \n\u2026 17  \n\u2026 \n8 \n\u2026 17  \n\u2026 1 2 3 0 1 2 3 1 2 3 \n1 2 3 1 2 3 1 2 3 1 2 3 0 0 \n0 0 \n0 0 0 \nA \nL R 1 2 3 \ni j k \n(e) 2 4 6 7 1 \n2 3 5 1 1 2 3 5 2 2 3 A \nL R \ni j k \n(f) 2 4 6 7 1 \n2 3 5 1 2 3 5 2 2 3 4 \nA \nL R \ni j k \n(g) 2 4 6 7 1 \n2 3 5 1 3 5 2 2 3 4 5 A \nL R 1 2 3 4 1 2 3 4 \ni j k \n(h) 2 4 6 7 1 \n2 3 5 1 7 2 2 3 4 5 6 9 10  11  12  13  14  15  16  \n9 10  11  12  13  14  15  16  9 10  11  12  13  14  15  16  9 10  11  12  13  14  15  16  8 \n\u2026 17  \n\u2026 \n8 \n\u2026 17  \n\u2026 8 \n\u2026 17  \n\u2026 8 \n\u2026 17  \n\u2026 \n1 2 3 1 2 3 1 2 3 \n1 2 3 1 2 3 0 0 \n0 4 0 0 0 0 0 \nFigure  2.3  The operation of the while  loop  in lines  8318  in the  call  MERGE.A;9;12;16/ , when \nthe subarray A\u01529  W 16\ufffd  contains the values h2;4;6;7;1;2;3;5 i. After allocating and copying into \nthe arrays L and R, the array L contains h2;4;6;7 i, and the array R contains h1;2;3;5 i. Tan \npositions in A contain  their  \u00fbnal  values,  and  tan  positions  in L and R contain values that have yet \nto be copied back into A. Taken together, the tan positions always comprise  the values originally \nin A\u01529  W 16\ufffd. Blue positions in A contain values that will be copied over, and dark p ositions in L \nand R contain values that have already been copied back i nto A. (a)\u2013(g)  The arrays A, L, and R, and \ntheir respective indices k, i , and j prior  to each  iteration  of the  loop  of lines  12318.  At  the  point in \npart (g), all values in R have been copied back into A (indicated by j equaling the length of R), and \nso the while  loop  in lines  12318  terminates.  (h)  The arrays and indices at termination. The while  \nloops  of lines  20323  and  24327  copied  back  into  A the remaining values in L and R, which are the \nlargest values originally in A\u01529  W 16\ufffd. Here,  lines  20323  copied  L\u01522  W 3\ufffd into A\u015215  W 16\ufffd, and because \nall values in R had already been copied back into A, the while  loop  of lines  24327  iterated  0 times. \nAt this point, the subarray in A\u01529  W 16\ufffd  is sorted. 38 Chapter 2 Getting Started \nbe copied back into A\u0152p  W r\ufffd and copies it back in. As the comments indicate, th e \nindex k gives the position of A that  is being  \u00fblled  in,  and  the  indices  i and j give the \npositions in L and R, respectively, of the smallest remaining values. E ventually, \neither all of L or all of R is copied back into A\u0152p  W r\ufffd, and this loop terminates. \nIf the loop terminates because all of R has been copied back, that is, because j \nequals n R , then i is still less than n L , so that some of L has yet to be copied back, \nand these values are the greatest in both L and R. In this case, the while  loop \nof lines  20323  copies  these  remaining  values  of L into the last few positions of \nA\u0152p  W r\ufffd. Because j equals n R , the while  loop  of lines  24327  iterates  0 times. If \ninstead the while  loop  of lines  12318  terminates  because  i equals n L , then all of L \nhas already been copied back into A\u0152p  W r\ufffd, and the while  loop  of lines  24327  copies  \nthe remaining values of R back into the end of A\u0152p  W r\ufffd. \nTo see that the M ERGE  procedure runs in \u201a.n/  time, where n D r \ue003 p C 1, 13  \nobserve  that  each  of lines  133  and  8310  takes  constant  time,  and the for  loops \nof lines  437  take  \u201a.n  L C n R / D \u201a.n/  time. 14  To account for the three while  \nloops  of lines  12318,  20323,  and  24327,  observe  that  each  iteration of these loops \ncopies exactly one value from L or R back into A and that every value is copied \nback into A exactly once. Therefore, these three loops together  make a total of n \niterations. Since each iteration of each of the thr ee loops takes constant time, the \ntotal time spent in these three loops is \u201a.n/ . \nWe can now use the M ERGE  procedure  as a subroutine  in the  merge  sort  al-  \ngorithm. The procedure M ERGE-SORT.A;p;r/  on  the  facing  page  sorts  the  ele-  \nments in the subarray A\u0152p  W r\ufffd. If p equals r , the subarray has just 1 element and \nis therefore  already  sorted.  Otherwise,  we  must  have  p < r  , and MERGE-SORT  \nruns the divide, conquer, and combine steps. The di vide step simply computes an \nindex q that partitions A\u0152p  W r\ufffd into two adjacent subarrays: A\u0152p  W q\ufffd, containing \ndn=2e elements, and A\u0152q  C 1 W r\ufffd, containing bn=2c elements. 15  The initial call \nMERGE-SORT  .A;1;n/  sorts the entire array A\u01521  W n\ufffd. \nFigure  2.4  illustrates  the  operation  of the  procedure  for  n D 8, showing also the \nsequence of divide and merge steps. The algorithm r ecursively divides the array \ndown to 1-element  subarrays.  The  combine  steps  merge  pairs  of 1-element  subar-  \n13  If you\u2019re  wondering  where  the  <C1= comes from, imagine that r D p C 1. Then  the  subar-  \nray A\u0152p  W r\ufffd consists of two elements, and r \ue003 p C 1 D 2. \n14  Chapter  3 shows  how  to formally  interpret  equations  contain ing \u201a-notation.  \n15  The expression dxe denotes the least integer greater than or equal to x, and bxc denotes the \ngreatest integer less than or equal to x. These  notations  are  de\u00fbned  in Section  3.3.  The  easiest  way  \nto verify that setting q to b.p  C r/=2c yields subarrays A\u0152p  W q\ufffd and A\u0152q  C 1 W r\ufffd of sizes dn=2e and \nbn=2c, respectively, is to examine the four cases that a rise depending on whether each of p and r is \nodd or even. 2.3 Designing algorithms 39 \nMERGE-SORT.A;p;r/  \n1 if p \ue004 r / / zero  or one  element?  \n2 return  \n3 q D b.p  C r/=2c / / midpoint of A\u0152p  W r\ufffd \n4 MERGE-SORT  .A;p;q/  / / recursively sort A\u0152p  W q\ufffd \n5 MERGE-SORT  .A;q  C 1;r/  / / recursively sort A\u0152q  C 1 W r\ufffd \n6 / / Merge A\u0152p  W q\ufffd and A\u0152q  C 1 W r\ufffd into A\u0152p  W r\ufffd. \n7 MERGE.A;p;q;r/  \nrays to form sorted subarrays of length 2, merges those to form sorted subarrays \nof length 4, and  merges  those  to form  the  \u00fbnal  sorted  subarray  of length  8. If n \nis not an exact power of 2, then some divide steps create subarrays whose len gths \ndiffer by 1. (For example, when dividing a subarray of length 7, one subarray has \nlength 4 and the other has length 3.) Regardless of the lengths of the two subarrays \nbeing merged, the time to merge a total of n items is \u201a.n/ . \n2.3.2  Analyzing  divide-and-conquer  algorithms  \nWhen an algorithm contains a recursive call, you ca n often describe its running \ntime by a recurrence  equation  or recurrence , which describes the overall running \ntime on a problem of size n in terms of the running time of the same algorithm on \nsmaller inputs. You can then use mathematical tools  to solve the recurrence and \nprovide bounds on the performance of the algorithm.  \nA recurrence  for  the  running  time  of a divide-and-conquer  algorithm falls out \nfrom the three steps of the basic method. As we did  for insertion sort, let T.n/  \nbe the  worst-case  running  time  on  a problem  of size  n. If the problem size is \nsmall enough, say n<n  0 for some constant n 0 >0, the straightforward solution \ntakes constant time, which we write as \u201a.1/ . 16  Suppose that the division of the \nproblem yields a subproblems, each with size n=b, that is, 1=b  the size of the \noriginal. For merge sort, both a and b are 2, but  we\u2019ll  see  other  divide-and-conquer  \nalgorithms in which a \u00a4 b. It takes T.n=b/  time to solve one subproblem of \nsize n=b, and so it takes aT.n=b/  time to solve all a of them. If it takes D.n/  time \nto divide the problem into subproblems and C.n/  time to combine the solutions to \nthe subproblems into the solution to the original p roblem, we get the recurrence \n16  If you\u2019re  wondering  where  \u201a.1/  comes from, think of it this way. When we say that n 2 =100  \nis \u201a.n  2 /, we  are  ignoring  the  coef\u00fbcient  1=100  of the factor n 2 . Likewise, when we say that a \nconstant c is \u201a.1/, we  are  ignoring  the  coef\u00fbcient  c of the factor 1 (which you can also think of \nas n 0 ). 40 Chapter 2 Getting Started \n12  3 7 9 14  6 11  2 1 2 3 4 5 6 7 8 \n12  3 7 9 14  6 11  2 1 2 3 4 5 6 7 8 p q r \np q r p q r \n12  3 7 9 1 2 3 4 p,q r \n3 1 2 p,r \n12  3 1 2 p,q r divide \ndivide \ndivide \nmerge 1 \n2 \n3 \n5 6 \n4 11 \np,q r \n14  6 11  2 5 6 7 8 p,q r 12 16 \np,q r \np,r \n12  9 3 4 p,r 7 8 \np,r \n7 6 5 6 p,r 13 14 \np,r \n14  2 7 8 p,r 17 18 \np,r \n11  \n9 7 3 4 p,q r 9 \n14  6 5 6 p,q r 15 \n11  2 7 8 p,q r 19 \nmerge \n3 7 9 12  2 6 11  14  1 2 3 4 5 6 7 8 p q r p q r 10 \n2 3 6 7 9 11  12  14  1 2 3 4 5 6 7 8 p q r merge 21 20 \nFigure  2.4  The operation of merge sort on the array A with length 8 that initially contains the \nsequence h12;3;7;9;14;6;11;2 i. The indices p, q, and r into each subarray appear above their \nvalues. Numbers in italics indicate the order in wh ich the MERGE-SORT  and MERGE  procedures are \ncalled following the initial call of M ERGE-SORT.A;1;8/ . \nT.n/  D ( \n\u201a.1/  if n<n  0 ; \nD.n/  C aT.n=b/  C C.n/  otherwise : \nChapter  4 shows  how  to solve  common  recurrences  of this  form.  \nSometimes, the n=b  size  of the  divide  step  isn\u2019t  an integer.  For  example,  the  \nMERGE-SORT  procedure divides a problem of size n into subproblems of sizes \ndn=2e and bn=2c. Since the difference between dn=2e and bn=2c is at most 1, 2.3 Designing algorithms 41 \nwhich for large n is much smaller than the effect of dividing n by 2, we\u2019ll  squint  a \nlittle and just call them both size n=2. As  Chapter  4 will  discuss,  this  simpli\u00fbcation  \nof ignoring  \u00fcoors  and  ceilings  does  not  generally  affect  the  order of growth of a \nsolution  to a divide-and-conquer  recurrence.  \nAnother  convention  we\u2019ll  adopt  is to omit  a statement  of the  base cases of the \nrecurrence,  which  we\u2019ll  also  discuss  in more  detail  in Chapter  4. The  reason  is \nthat the base cases are pretty much always T.n/  D \u201a.1/  if n < n  0 for some \nconstant n 0 >0. That\u2019s  because  the  running  time  of an algorithm  on  an input  of \nconstant size is constant. We save ourselves a lot of extra writing by adopting this \nconvention. \nAnalysis  of merge  sort  \nHere\u2019s  how  to set  up  the  recurrence  for  T.n/, the  worst-case  running  time  of merge  \nsort on n numbers. \nDivide:  The divide step just computes the middle of the sub array, which takes \nconstant time. Thus, D.n/  D \u201a.1/ . \nConquer:  Recursively solving two subproblems, each of size n=2, contributes \n2T.n=2/  to the  running  time  (ignoring  the  \u00fcoors  and  ceilings,  as we  discussed). \nCombine:  Since the M ERGE  procedure on an n-element  subarray  takes  \u201a.n/  \ntime, we have C.n/  D \u201a.n/ . \nWhen we add the functions D.n/  and C.n/  for the merge sort analysis, we are \nadding a function that is \u201a.n/  and a function that is \u201a.1/ . This sum is a linear \nfunction of n. That is, it is roughly proportional to n when n is large, and so \nmerge  sort\u2019s  dividing  and  combining  times  together  are  \u201a.n/ . Adding \u201a.n/  to \nthe 2T.n=2/  term from the conquer step gives the recurrence for  the worst-case  \nrunning time T.n/  of merge sort: \nT.n/  D 2T.n=2/  C \u201a.n/:  (2.3)  \nChapter  4 presents  the  <master  theorem,=  which  shows  that  T.n/  D \u201a.n  lg n/. 17  \nCompared  with  insertion  sort,  whose  worst-case  running  time is \u201a.n  2 /, merge sort \ntrades away a factor of n for a factor of lg n. Because the logarithm function grows \nmore  slowly  than  any  linear  function,  that\u2019s  a good  trade.  For large enough inputs, \nmerge sort, with its \u201a.n  lg n/ worst-case  running  time,  outperforms  insertion  sort,  \nwhose  worst-case  running  time  is \u201a.n  2 /. \n17  The notation lg n stands for log 2 n, although  the  base  of the  logarithm  doesn\u2019t  matter  here,  but  as \ncomputer scientists, we like logarithms base 2. Section  3.3  discusses  other  standard  notation.  42 Chapter 2 Getting Started \nWe do not need the master theorem, however, to unde rstand intuitively why the \nsolution  to recurrence  (2.3)  is T.n/  D \u201a.n  lg n/. For simplicity, assume that n is \nan exact power of 2 and that the implicit base case is n D 1. Then  recurrence  (2.3)  \nis essentially \nT.n/  D ( \nc 1 if n D 1;  \n2T.n=2/  C c 2 n if n>1;  (2.4)  \nwhere the constant c 1 >0  represents the time required to solve a problem of size 1, \nand c 2 >0  is the time per array element of the divide and com bine steps. 18  \nFigure  2.5  illustrates  one  way  of \u00fbguring  out  the  solution  to recurrence  (2.4).  \nPart  (a)  of the  \u00fbgure  shows  T.n/ , which part (b) expands into an equivalent tree \nrepresenting the recurrence. The c 2 n term  denotes  the  cost  of dividing  and  com-  \nbining at the top level of recursion, and the two s ubtrees of the root are the two \nsmaller recurrences T.n=2/ . Part (c) shows this process carried one step furt her by \nexpanding T.n=2/ . The cost for dividing and combining at each of th e two nodes \nat the second level of recursion is c 2 n=2. Continue to expand each node in the tree \nby breaking it into its constituent parts as determ ined by the recurrence, until the \nproblem sizes get down to 1, each with a cost of c 1 . Part (d) shows the resulting \nrecursion  tree. \nNext, add the costs across each level of the tree. The top level has total cost c 2 n, \nthe next level down has total cost c 2 .n=2/  C c 2 .n=2/  D c 2 n, the level after that has \ntotal cost c 2 .n=4/  C c 2 .n=4/  C c 2 .n=4/  C c 2 .n=4/  D c 2 n, and so on. Each level \nhas twice as many nodes as the level above, but eac h node contributes only half \nthe cost of a node from the level above. From one l evel to the next, doubling and \nhalving cancel each other out, so that the cost acr oss each level is the same: c 2 n. In \ngeneral, the level that is i levels below the top has 2 i nodes, each contributing a cost \nof c 2 .n=2  i /, so that the i th level below the top has total cost 2 i \ue001 c 2 .n=2  i / D c 2 n. \nThe bottom level has n nodes, each contributing a cost of c 1 , for a total cost of c 1 n. \nThe  total  number  of levels  of the  recursion  tree  in Figure  2.5  is lg n C 1, where \nn is the number of leaves, corresponding to the input  size. An informal inductive \nargument  justi\u00fbes  this  claim.  The  base  case  occurs  when  n D 1, in which case \nthe tree has only 1 level. Since lg 1 D 0, we have that lg n C 1 gives the correct \nnumber of levels. Now assume as an inductive hypoth esis that the number of levels \nof a recursion tree with 2 i leaves is lg 2 i C 1 D i C 1 (since for any value of i , we \nhave that lg 2 i D i ). Because we assume that the input size is an exac t power of 2, \nthe next input size to consider is 2 i C1 . A tree with n D 2 i C1 leaves has 1 more \n18  It is unlikely that c 1 is exactly the time to solve problems of size 1 and that c 2 n is exactly the \ntime  of the  divide  and  combine  steps.  We\u2019ll  look  more  closely  at bounding  recurrences  in Chapter  4, \nwhere  we\u2019ll  be more  careful  about  this  kind  of detail.  2.3 Designing algorithms 43 \n\u2026 \n\u2026 \n(d) (c) (b) (a) T.n/  \nc 2 n c 2 n c 2 n \nT.n=2/  T.n=2/  \nc 2 n=2  c 2 n=2  c 2 n=2  c 2 n=2  \nT.n=4/  T.n=4/  T.n=4/  T.n=4/  \nc 2 n=4  c 2 n=4  c 2 n=4  c 2 n=4  \nc 1 c 1 c 1 c 1 c 1 c 1 c 1 c 1 c 1 c 1 c 1 c 1 \nn lg n C 1 c 2 n \nc 2 n c 2 n \nc 1 n \nTotal: c 2 n lg n C c 1 n \nFigure  2.5  How  to construct  a recursion  tree  for  the  recurrence  (2.4).  Part (a)  shows T.n/ , which \nprogressively expands in (b)\u2013(d)  to form the recursion tree. The fully expanded tree  in part (d) \nhas lg n C 1 levels. Each level above the leaves contributes a t otal cost of c 2 n, and the leaf level \ncontributes c 1 n. The total cost, therefore, is c 2 n lg n C c 1 n D \u201a.n  lg n/. 44 Chapter 2 Getting Started \nlevel than a tree with 2 i leaves, and so the total number of levels is .i C 1/ C 1 D \nlg 2 i C1 C 1. \nTo  compute  the  total  cost  represented  by  the  recurrence  (2.4), simply add up the \ncosts of all the levels. The recursion tree has lg n C 1 levels. The levels above the \nleaves each cost c 2 n, and the leaf level costs c 1 n, for a total cost of c 2 n lg n Cc 1 n D \n\u201a.n  lg n/. \nExercises  \n2.3-1  \nUsing  Figure  2.4  as a model,  illustrate  the  operation  of merg e sort on an array \ninitially containing the sequence h3;41;52;26;38;57;9;49 i. \n2.3-2  \nThe  test  in line  1 of the  MERGE-SORT  procedure reads < if p \ue004 r = rather than < if \np \u00a4 r .= If MERGE-SORT  is called with p>r  , then the subarray A\u0152p  W r\ufffd is empty. \nArgue that as long as the initial call of M ERGE-SORT.A;1;n/  has n \ue004 1, the test \n<if p \u00a4 r = suf\u00fbces  to ensure  that  no  recursive  call  has  p>r  . \n2.3-3  \nState a loop invariant for the while  loop  of lines  12318  of the  MERGE  procedure. \nShow how to use it, along with the while  loops  of lines  20323  and  24327,  to prove  \nthat the M ERGE  procedure is correct. \n2.3-4  \nUse mathematical induction to show that when n \ue004 2 is an exact power of 2, the \nsolution of the recurrence \nT.n/  D ( \n2 if n D 2;  \n2T.n=2/  C n if n>2  \nis T.n/  D n lg n. \n2.3-5  \nYou can also think of insertion sort as a recursive  algorithm. In order to sort \nA\u01521  W n\ufffd, recursively sort the subarray A\u01521  W n \ue003 1\ufffd and then insert A\u0152n\ufffd  into the \nsorted subarray A\u01521  W n \ue003 1\ufffd. Write  pseudocode  for  this  recursive  version  of inser-  \ntion  sort.  Give  a recurrence  for  its  worst-case  running  time. \n2.3-6  \nReferring  back  to the  searching  problem  (see  Exercise  2.1-4 ), observe that if the \nsubarray being searched is already sorted, the sear ching algorithm can check the \nmidpoint of the subarray against v and eliminate half of the subarray from further Problems for Chapter 2 45 \nconsideration. The binary  search  algorithm repeats this procedure, halving the \nsize of the remaining portion of the subarray each time. Write pseudocode, either \niterative or recursive, for binary search. Argue th at the worst-case  running  time  of \nbinary search is \u201a.lg n/. \n2.3-7  \nThe while  loop  of lines  537  of the  I NSERTION-SORT  procedure  in Section  2.1  \nuses a linear search to scan (backward) through the  sorted subarray A\u01521  W j \ue003 1\ufffd. \nWhat  if insertion  sort  used  a binary  search  (see  Exercise  2.3-6)  instead  of a linear  \nsearch?  Would  that  improve  the  overall  worst-case  running  time of insertion sort \nto \u201a.n  lg n/? \n2.3-8  \nDescribe an algorithm that, given a set S of n integers and another integer x , de-  \ntermines whether S contains two elements that sum to exactly x . Your algorithm \nshould take \u201a.n  lg n/ time in the worst case. \nProblems  \n2-1  Insertion  sort  on  small  arrays  in merge  sort  \nAlthough merge sort runs in \u201a.n  lg n/ worst-case  time  and  insertion  sort  runs  \nin \u201a.n  2 / worst-case  time,  the  constant  factors  in insertion  sort  can  make it faster \nin practice for small problem sizes on many machine s. Thus it makes sense to \ncoarsen  the leaves of the recursion by using insertion sort  within merge sort when \nsubproblems  become  suf\u00fbciently  small.  Consider  a modi\u00fbcat ion to merge sort in \nwhich n=k  sublists of length k are sorted using insertion sort and then merged \nusing the standard merging mechanism, where k is a value to be determined. \na. Show that insertion sort can sort the n=k  sublists, each of length k, in \u201a.nk/  \nworst-case  time.  \nb. Show how to merge the sublists in \u201a.n  lg.n=k//  worst-case  time.  \nc. Given  that  the  modi\u00fbed  algorithm  runs  in \u201a.nk  C n lg.n=k//  worst-case  time,  \nwhat is the largest value of k as a function of n for  which  the  modi\u00fbed  algorithm  \nhas the same running time as standard merge sort, i n terms of \u201a-notation?  \nd. How should you choose k in practice?  46 Chapter 2 Getting Started \n2-2  Correctness  of bubblesort  \nBubblesort  is a popular,  but  inef\u00fbcient,  sorting  algorithm . It works by repeatedly \nswapping adjacent elements that are out of order. T he procedure B UBBLESORT  \nsorts array A\u01521  W n\ufffd. \nBUBBLESORT  .A;n/  \n1 for  i D 1 to n \ue003 1 \n2 for  j D n downto  i C 1 \n3 if A\u0152j\ufffd<A\u0152j  \ue003 1\ufffd \n4 exchange A\u0152j\ufffd  with A\u0152j  \ue003 1\ufffd \na. Let A 0 denote the array A after BUBBLESORT  .A;n/  is executed. To prove that \nBUBBLESORT  is correct, you need to prove that it terminates an d that \nA 0 \u01521\ufffd  \u0dc4 A 0 \u01522\ufffd  \u0dc4 \ue001 \ue001 \ue001 \u0dc4  A 0 \u0152n\ufffd:  (2.5)  \nIn order to show that B UBBLESORT  actually sorts, what else do you need to \nprove?  \nThe  next  two  parts  prove  inequality  (2.5).  \nb. State precisely a loop invariant for the for  loop  in lines  234,  and  prove  that  this  \nloop invariant holds. Your proof should use the str ucture of the  loop-invariant  \nproof presented in this chapter. \nc. Using the termination condition of the loop invaria nt proved in part (b), state \na loop invariant for the for  loop  in lines  134  that  allows  you  to prove  inequal-  \nity  (2.5).  Your  proof  should  use  the  structure  of the  loop-invariant  proof  pre-  \nsented in this chapter. \nd. What  is the  worst-case  running  time  of BUBBLESORT ? How  does  it compare  \nwith the running time of I NSERTION-SORT? \n2-3  Correctness  of Horner\u2019s  rule  \nYou  are  given  the  coef\u00fbcents  a 0 ;a  1 ;a  2 ;:::;a  n of a polynomial \nP.x/  D n X  \nkD0 a k x k \nD a 0 C a 1 x C a 2 x 2 C \ue001 \ue001 \ue001 C  a n\ue0021 x n\ue0021 C a n x n ; \nand you want to evaluate this polynomial for a give n value of x . Horner\u2019s  rule  \nsays to evaluate the polynomial according to this p arenthesization: Problems for Chapter 2 47 \nP.x/  D a 0 C x \ue002 \na 1 C x \u00e3 \na 2 C \ue001 \ue001 \ue001 C  x.a  n\ue0021 C xa  n / \ue001 \ue001 \ue001  \u00e4 \u00cd \n: \nThe procedure H ORNER  implements  Horner\u2019s  rule  to evaluate  P.x/ , given the \ncoef\u00fbcients  a 0 ;a  1 ;a  2 ;:::;a  n in an array A\u01520  W n\ufffd and the value of x . \nHORNER.A;n;x/  \n1 p D 0 \n2 for  i D n downto  0 \n3 p D A\u0152i\ufffd  C x \ue001 p \n4 return  p \na. In terms of \u201a-notation,  what  is the  running  time  of this  procedure?  \nb. Write  pseudocode  to implement  the  naive  polynomial-evalua tion algorithm that \ncomputes each term of the polynomial from scratch. What is the running time \nof this  algorithm?  How  does  it compare  with  HORNER? \nc. Consider the following loop invariant for the proce dure HORNER : \nAt the start of each iteration of the for  loop  of lines  233,  \np D n\ue002.i C1/  X  \nkD0 A\u0152k  C i C 1\ufffd \ue001 x k : \nInterpret a summation with no terms as equaling 0. Following the structure \nof the  loop-invariant  proof  presented  in this  chapter,  use  this loop invariant to \nshow that, at termination, p D P  n \nkD0 A\u0152k\ufffd  \ue001 x k . \n2-4  Inversions  \nLet A\u01521  W n\ufffd be an array of n distinct numbers. If i <j  and A\u0152i\ufffd>A\u0152j\ufffd , then the \npair .i;j/  is called an inversion  of A. \na. List  the  \u00fbve  inversions  of the  array  h2;3;8;6;1 i. \nb. What array with elements from the set f1;2;:::;n g has  the  most  inversions?  \nHow  many  does  it have?  \nc. What is the relationship between the running time o f insertion sort and the \nnumber  of inversions  in the  input  array?  Justify  your  answer  . \nd. Give  an algorithm  that  determines  the  number  of inversions  in any permutation \non n elements in \u201a.n  lg n/ worst-case  time.  (Hint: Modify merge sort.) 48 Chapter 2 Getting Started \nChapter  notes  \nIn 1968,  Knuth  published  the  \u00fbrst  of three  volumes  with  the  general title The Art of \nComputer  Programming  [259,  260,  261].  The  \u00fbrst  volume  ushered  in the  modern  \nstudy of computer algorithms with a focus on the an alysis of running time. The \nfull series remains an engaging and worthwhile refe rence for many of the topics \npresented  here.  According  to Knuth,  the  word  <algorithm=  is derived from the \nname  <al-Khow\u02c6  arizm\u02c6  \u0131,= a ninth-century  Persian  mathemat ician. \nAho,  Hopcroft,  and  Ullman  [5]  advocated  the  asymptotic  analysis of algorithms \n4using  notations  that  Chapter  3 introduces,  including  \u201a-notation4as  a means  \nof comparing relative performance. They also popula rized the use of recurrence \nrelations to describe the running times of recursiv e algorithms. \nKnuth  [261]  provides  an encyclopedic  treatment  of many  sorting algorithms. His \ncomparison  of sorting  algorithms  (page  381)  includes  exact  step-counting  analyses,  \nlike  the  one  we  performed  here  for  insertion  sort.  Knuth\u2019s  discussion of insertion \nsort encompasses several variations of the algorith m. The most important of these \nis Shell\u2019s  sort,  introduced  by  D.  L. Shell,  which  uses  insert ion sort on periodic \nsubarrays of the input to produce a faster sorting algorithm. \nMerge  sort  is also  described  by  Knuth.  He  mentions  that  a mechanical  colla-  \ntor capable of merging two decks of punched cards i n a single pass was invented \nin 1938.  J. von  Neumann,  one  of the  pioneers  of computer  scien ce, apparently \nwrote  a program  for  merge  sort  on  the  EDVAC  computer  in 1945.  \nThe early history of proving programs correct is de scribed by Gries  [200],  who  \ncredits  P. Naur  with  the  \u00fbrst  article  in this  \u00fbeld.  Gries  attributes loop invariants to \nR. W.  Floyd.  The  textbook  by  Mitchell  [329]  is a good  referenc e on how to prove \nprograms correct. 3 Characterizing  Running  Times  \nThe  order  of growth  of the  running  time  of an algorithm,  de\u00fbne d in Chapter 2, \ngives  a simple  way  to characterize  the  algorithm\u2019s  ef\u00fbcienc y and also allows us \nto compare  it with  alternative  algorithms.  Once  the  input  size n becomes large \nenough, merge sort, with its \u201a.n  lg n/ worst-case  running  time,  beats  insertion  sort,  \nwhose  worst-case  running  time  is \u201a.n  2 /. Although we can sometimes determine \nthe exact running time of an algorithm, as we did f or insertion sort in Chapter 2, \nthe extra precision is rarely worth the effort of c omputing it. For large enough \ninputs,  the  multiplicative  constants  and  lower-order  terms of an exact running time \nare dominated by the effects of the input size itse lf. \nWhen we look at input sizes large enough to make re levant only the order of \ngrowth of the running time, we are studying the asymptotic  ef\u00fbciency  of algo-  \nrithms. That is, we are concerned with how the runn ing time of an algorithm \nincreases with the size of the input in the limit , as the size of the input increases \nwithout bound. Usually, an algorithm that is asympt otically more  ef\u00fbcient  is the  \nbest choice for all but very small inputs. \nThis chapter gives several standard methods for sim plifying the  asymptotic  anal-  \nysis of algorithms. The next section presents infor mally the three most commonly \nused types of <asymptotic notation,= of which we ha ve already seen an example \nin \u201a-notation.  It also  shows  one  way  to use  these  asymptotic  notations to reason \nabout  the  worst-case  running  time  of insertion  sort.  Then  we  look at asymptotic \nnotations more formally and present several notatio nal con ventions  used  through-  \nout this book. The last section reviews the behavio r of functions that commonly \narise when analyzing algorithms. 50  Chapter  3 Characterizing  Running  Times  \n3.1  O-notation,  \ue001-notation,  and  \u201a-notation  \nWhen  we  analyzed  the  worst-case  running  time  of insertion  sort in Chapter 2, we \nstarted with the complicated expression \n\ue002 c 5 \n2 C c 6 \n2 C c 7 \n2 \u00cd \nn 2 C \ue002 \nc 1 C c 2 C c 4 C c 5 \n2 \ue003 c 6 \n2 \ue003 c 7 \n2 C c 8 \u00cd \nn \n\ue003 .c 2 C c 4 C c 5 C c 8 /: \nWe  then  discarded  the  lower-order  terms  .c 1 C c 2 C c 4 C c 5 =2  \ue003 c 6 =2  \ue003 c 7 =2  C c 8 /n \nand c 2 C c 4 C c 5 C c 8 , and  we  also  ignored  the  coef\u00fbcient  c 5 =2  C c 6 =2  C c 7 =2  \nof n 2 . That left just the factor n 2 , which we put into \u201a-notation  as \u201a.n  2 /. We \nuse this style to characterize running times of alg orithms: discard  the  lower-order  \nterms  and  the  coef\u00fbcient  of the  leading  term,  and  use  a notati on that focuses on the \nrate of growth of the running time. \n\u201a-notation  is not  the  only  such  <asymptotic  notation.=  In this  section,  we\u2019ll  \nsee other forms of asymptotic notation as well. We start with intuitive looks at \nthese notations, revisiting insertion sort to see h ow we can apply them. In the next \nsection,  we\u2019ll  see  the  formal  de\u00fbnitions  of our  asymptotic  notations, along with \nconventions for using them. \nBefore  we  get  into  speci\u00fbcs,  bear  in mind  that  the  asymptotic  notations  we\u2019ll  see  \nare designed so that they characterize functions in  general. It so happens that the \nfunctions we are most interested in denote the runn ing times of algorithms. But \nasymptotic notation can apply to functions that cha racterize some other aspect of \nalgorithms (the amount of space they use, for examp le), or even to functions that \nhave nothing whatsoever to do with algorithms. \nO-notation  \nO-notation  characterizes  an upper  bound  on the asymptotic behavior of a function. \nIn other words, it says that a function grows no faster than a certain rate, based on \nthe  highest-order  term.  Consider,  for  example,  the  functio n 7n  3 C 100n  2 \ue003 20n  C 6. \nIts  highest-order  term  is 7n  3 , and  so we  say  that  this  function\u2019s  rate  of growth  is n 3 . \nBecause this function grows no faster than n 3 , we can write that it is O.n  3 /. You \nmight be surprised that we can also write that the function 7n  3 C 100n  2 \ue003 20n  C 6 \nis O.n  4 /. Why?  Because  the  function  grows  more  slowly  than  n 4 , we are correct \nin saying that it grows no faster. As you might hav e guessed, this function is also \nO.n  5 /, O.n  6 /, and so on. More generally, it is O.n  c / for any constant c \ue004 3. 3.1 O-notation, \ufffd-notation, and \u201a-notation 51 \n\ue001-notation  \n\ufffd-notation  characterizes  a lower  bound  on the asymptotic behavior of a function. \nIn other words, it says that a function grows at least as fast as a certain rate, based \n4as  in O-notation4on  the  highest-order  term.  Because  the  highest- order term \nin the function 7n  3 C 100n  2 \ue003 20n  C 6 grows at least as fast as n 3 , this function \nis \ufffd.n  3 /. This function is also \ufffd.n  2 / and \ufffd.n/ . More generally, it is \ufffd.n  c / for \nany constant c \u0dc4 3. \n\u201a-notation  \n\u201a-notation  characterizes  a tight  bound  on the asymptotic behavior of a function. It \nsays that a function grows precisely  at a certain  rate,  based4once  again4on  the  \nhighest-order  term.  Put  another  way,  \u201a-notation  characterizes  the  rate  of growth  of \nthe function to within a constant factor from above  and to within a constant factor \nfrom below. These two constant factors need not be equal. \nIf you can show that a function is both O.f.n//  and \ufffd.f  .n//  for  some  func-  \ntion f.n/ , then you have shown that the function is \u201a.f.n// . (The next section \nstates this fact as a theorem.) For example, since the function 7n  3 C100n  2 \ue00320nC6 \nis both O.n  3 / and \ufffd.n  3 /, it is also \u201a.n  3 /. \nExample:  Insertion  sort  \nLet\u2019s  revisit  insertion  sort  and  see  how  to work  with  asymptotic  notation  to charac-  \nterize its \u201a.n  2 / worst-case  running  time  without  evaluating  summations  as we did \nin Chapter 2. Here is the I NSERTION-SORT  procedure once again: \nI NSERTION-SORT  .A;n/  \n1 for  i D 2 to n \n2 key  D A\u0152i\ufffd  \n3 / / Insert A\u0152i\ufffd  into the sorted subarray A\u01521  W i \ue003 1\ufffd. \n4 j D i \ue003 1 \n5 while  j >0  and A\u0152j\ufffd>  key  \n6 A\u0152j  C 1\ufffd D A\u0152j\ufffd  \n7 j D j \ue003 1 \n8 A\u0152j  C 1\ufffd D key  \nWhat  can  we  observe  about  how  the  pseudocode  operates?  The  procedure has \nnested loops. The outer loop is a for  loop that runs n \ue003 1 times, regardless of the \nvalues being sorted. The inner loop is a while  loop, but the number of iterations \nit makes depends on the values being sorted. The lo op variable j starts at i \ue003 1 52  Chapter  3 Characterizing  Running  Times  \neach of the \nn/3 largest  \nvalues moves through each \nof these \nn/3 positions  to somewhere \nin these \nn/3 positions  A\u01521  W n=3\ufffd  A\u0152n=3  C 1 W 2n=3\ufffd  A\u01522n=3  C 1 W n\ufffd \nFigure  3.1  The \ufffd.n  2 / lower  bound  for  insertion  sort.  If the  \u00fbrst  n=3  positions contain the n=3  \nlargest values, each of these values must move thro ugh each of the middle n=3  positions, one position \nat a time, to end up somewhere in the last n=3  positions. Since each of n=3  values moves through at \nleast each of n=3  positions, the time taken in this case is at least proportional to .n=3/.n=3/  D n 2 =9, \nor \ufffd.n  2 /. \nand decreases by 1 in each iteration until either it reaches 0 or A\u0152j\ufffd  \u0dc4 key. For a \ngiven value of i , the while  loop might iterate 0 times, i \ue003 1 times, or anywhere in \nbetween. The body of the while  loop  (lines  637)  takes  constant  time  per  iteration  \nof the while  loop. \nThese  observations  suf\u00fbce  to deduce  an O.n  2 / running time for any case of \nI NSERTION-SORT, giving us a blanket statement that covers all inp uts. The run- \nning time is dominated by the inner loop. Because e ach of the n \ue003 1 iterations of \nthe outer loop causes the inner loop to iterate at most i \ue003 1 times, and because i is \nat most n, the total number of iterations of the inner loop is at most .n \ue003 1/.n  \ue003 1/, \nwhich is less than n 2 . Since each iteration of the inner loop takes cons tant time, \nthe total time spent in the inner loop is at most a  constant times n 2 , or O.n  2 /. \nWith  a little  creativity,  we  can  also  see  that  the  worst-case  running time of \nI NSERTION-SORT  is \ufffd.n  2 /. By  saying  that  the  worst-case  running  time  of an \nalgorithm is \ufffd.n  2 /, we mean that for every input size n above a certain threshold, \nthere is at least one input of size n for which the algorithm takes at least cn  2 time, \nfor some positive constant c . It does not necessarily mean that the algorithm t akes \nat least cn  2 time for all inputs. \nLet\u2019s  now  see  why  the  worst-case  running  time  of I NSERTION-SORT  is \ufffd.n  2 /. \nFor a value to end up to the right of where it star ted, it must have been moved in \nline  6. In fact,  for  a value  to end  up  k positions to the right of where it started, \nline  6 must  have  executed  k times.  As  Figure  3.1  shows,  let\u2019s  assume  that  n is \na multiple of 3 so that we can divide the array A into groups of n=3  positions. \nSuppose that in the input to I NSERTION-SORT, the n=3  largest values occupy the \n\u00fbrst  n=3  array positions A\u01521  W n=3\ufffd. (It does not matter what relative order they \nhave  within  the  \u00fbrst  n=3  positions.)  Once  the  array  has  been  sorted,  each  of these  \nn=3  values ends up somewhere in the last n=3  positions A\u01522n=3  C 1 W n\ufffd. For that \nto happen, each of these n=3  values must pass through each of the middle n=3  \npositions A\u0152n=3  C 1 W 2n=3\ufffd . Each of these n=3  values passes through these middle 3.2  Asymptotic  notation:  formal  de\ufb01nitions  53 \nn=3  positions one position at a time, by at least n=3  executions  of line  6. Because  \nat least n=3  values have to pass through at least n=3  positions, the time taken by \nI NSERTION-SORT  in the worst case is at least proportional to .n=3/.n=3/  D n 2 =9, \nwhich is \ufffd.n  2 /. \nBecause we have shown that I NSERTION-SORT  runs in O.n  2 / time in all cases \nand that there is an input that makes it take \ufffd.n  2 / time, we can conclude that the \nworst-case  running  time  of I NSERTION-SORT  is \u201a.n  2 /. It does not matter that \nthe constant factors for upper and lower bounds mig ht differ. What matters is \nthat  we  have  characterized  the  worst-case  running  time  to within constant factors \n(discounting  lower-order  terms).  This  argument  does  not  show that I NSERTION- \nSORT  runs in \u201a.n  2 / time in all cases.  Indeed,  we  saw  in Chapter  2 that  the  best-  \ncase running time is \u201a.n/ . \nExercises  \n3.1-1  \nModify  the  lower-bound  argument  for  insertion  sort  to handl e input sizes that are \nnot necessarily a multiple of 3. \n3.1-2  \nUsing reasoning similar to what we used for inserti on sort, analyze the running \ntime  of the  selection  sort  algorithm  from  Exercise  2.2-2.  \n3.1-3  \nSuppose that \u02db is a fraction in the range 0 < \u02db < 1 . Show how to generalize \nthe  lower-bound  argument  for  insertion  sort  to consider  an input in which the \u02dbn  \nlargest  values  start  in the  \u00fbrst  \u02dbn  positions. What additional restriction do you \nneed to put on \u02db? What  value  of \u02db maximizes the number of times that the \u02dbn  \nlargest values must pass through each of the middle  .1 \ue003 2\u02db/n  array  positions?  \n3.2  Asymptotic  notation:  formal  de\u00fbnitions  \nHaving  seen  asymptotic  notation  informally,  let\u2019s  get  more  formal. The notations \nwe use to describe the asymptotic running time of a n algorithm are  de\u00fbned  in \nterms of functions whose domains are typically the set N of natural numbers or \nthe set R of real numbers. Such notations are convenient for describing  a running-  \ntime function T.n/. This  section  de\u00fbnes  the  basic  asymptotic  notations  and  also \nintroduces some common <proper= notational abuses. 54  Chapter  3 Characterizing  Running  Times  \n(a) (b) (c) n n n n 0 n 0 n 0 f.n/  D \u201a.g.n//  f.n/  D O.g.n//  f.n/  D \ufffd.g.n//  f.n/  \nf.n/  f.n/  \ncg.n/  cg.n/  \nc 1 g.n/  c 2 g.n/  \nFigure  3.2  Graphic  examples  of the  O, \ufffd, and \u201a notations. In each part, the value of n 0 shown \nis the minimum possible value, but any greater valu e also works. (a)  O-notation  gives  an  upper  \nbound for a function to within a constant factor. W e write f.n/  D O.g.n//  if there are positive \nconstants n 0 and c such that at and to the right of n 0 , the value of f.n/  always  lies  on  or be-  \nlow cg.n/ . (b)  \ufffd-notation  gives  a lower  bound  for  a function  to within  a const ant factor. We write \nf.n/  D \ufffd.g.n//  if there are positive constants n 0 and c such that at and to the right of n 0 , the value \nof f.n/  always lies on or above cg.n/ . (c)  \u201a-notation  bounds  a function  to within  constant  factors.  \nWe write f.n/  D \u201a.g.n//  if there exist positive constants n 0 , c 1 , and c 2 such that at and to the right \nof n 0 , the value of f.n/  always lies between c 1 g.n/  and c 2 g.n/  inclusive. \nO-notation  \nAs  we  saw  in Section  3.1,  O-notation  describes  an asymptotic  upper  bound . We \nuse O-notation  to give  an upper  bound  on  a function,  to within  a constant factor. \nHere  is the  formal  de\u00fbnition  of O-notation.  For  a given  function  g.n/ , we denote \nby O.g.n//  (pronounced  <big-oh  of g of n= or sometimes just <oh of g of n=) the \nset  of functions  \nO.g.n//  D ff.n/  W there exist positive constants c and n 0 such that \n0 \u0dc4 f.n/  \u0dc4 cg.n/  for all n \ue004 n 0 g : 1 \nA function f.n/  belongs to the set O.g.n//  if there exists a positive constant c such \nthat f.n/  \u0dc4 cg.n/  for  suf\u00fbciently  large  n. Figure  3.2(a)  shows  the  intuition  behind  \nO-notation.  For  all  values  n at and to the right of n 0 , the value of the function f.n/  \nis on or below cg.n/ . \nThe  de\u00fbnition  of O.g.n//  requires that every function f.n/  in the set O.g.n//  \nbe asymptotically  nonnegative : f.n/  must be nonnegative whenever n is suf\u00fb-  \nciently large. (An asymptotically  positive  function is one that is positive for all \n1 Within set notation, a colon means <such that.= 3.2  Asymptotic  notation:  formal  de\ufb01nitions  55 \nsuf\u00fbciently  large  n.) Consequently, the function g.n/  itself must be asymptotically \nnonnegative, or else the set O.g.n//  is empty. We therefore assume that every \nfunction used within O-notation  is asymptotically  nonnegative.  This  assumption  \nholds  for  the  other  asymptotic  notations  de\u00fbned  in this  chap ter as well. \nYou  might  be surprised  that  we  de\u00fbne  O-notation  in terms  of sets.  Indeed,  you  \nmight expect that we would write < f.n/  2 O.g.n// = to indicate that f.n/  be-  \nlongs to the set O.g.n// . Instead, we usually write < f.n/  D O.g.n// = and say \n<f.n/  is big-oh  of g.n/= to express  the  same  notion.  Although  it may  seem  con-  \nfusing  at \u00fbrst  to abuse  equality  in this  way,  we\u2019ll  see  later  in this section that doing \nso has its advantages. \nLet\u2019s  explore  an example  of how  to use  the  formal  de\u00fbnition  of O-notation  to \njustify  our  practice  of discarding  lower-order  terms  and  ignoring  the  constant  coef-  \n\u00fbcient  of the  highest-order  term.  We\u2019ll  show  that  4n  2 C100n  C500  D O.n  2 /, even \nthough  the  lower-order  terms  have  much  larger  coef\u00fbcients  than the leading term. \nWe  need  to \u00fbnd  positive  constants  c and n 0 such that 4n  2 C 100n  C 500  \u0dc4 cn  2 \nfor all n \ue004 n 0 . Dividing both sides by n 2 gives 4 C 100=n  C 500=n  2 \u0dc4 c . This \ninequality  is satis\u00fbed  for  many  choices  of c and n 0 . For example, if we choose \nn 0 D 1, then this inequality holds for c D 604. If we choose n 0 D 10, then c D 19  \nworks, and choosing n 0 D 100  allows us to use c D 5:05. \nWe  can  also  use  the  formal  de\u00fbnition  of O-notation  to show  that  the  function  \nn 3 \ue003 100n  2 does not belong to the set O.n  2 /, even  though  the  coef\u00fbcient  of n 2 \nis a large negative number. If we had n 3 \ue003 100n  2 D O.n  2 /, then there would be \npositive constants c and n 0 such that n 3 \ue003 100n  2 \u0dc4 cn  2 for all n \ue004 n 0 . Again, we \ndivide both sides by n 2 , giving n \ue003 100  \u0dc4 c . Regardless of what value we choose \nfor the constant c , this inequality does not hold for any value of n>c  C 100. \n\ue001-notation  \nJust  as O-notation  provides  an asymptotic  upper  bound on a function, \ufffd-notation  \nprovides an asymptotic  lower  bound . For a given function g.n/ , we denote \nby \ufffd.g.n//  (pronounced  <big-omega  of g of n= or sometimes just <omega of g \nof n=) the set of functions \n\ufffd.g.n//  D ff.n/  W there exist positive constants c and n 0 such that \n0 \u0dc4 cg.n/  \u0dc4 f.n/  for all n \ue004 n 0 g : \nFigure  3.2(b)  shows  the  intuition  behind  \ufffd-notation.  For  all  values  n at or to the \nright of n 0 , the value of f.n/  is on or above cg.n/ . \nWe\u2019ve  already  shown  that  4n  2 C 100n  C 500  D O.n  2 /. Now  let\u2019s  show  that  \n4n  2 C 100n  C 500  D \ufffd.n  2 /. We  need  to \u00fbnd  positive  constants  c and n 0 such that \n4n  2 C 100n  C 500  \ue004 cn  2 for all n \ue004 n 0 . As before, we divide both sides by n 2 , 56  Chapter  3 Characterizing  Running  Times  \ngiving 4 C 100=n  C 500=n  2 \ue004 c . This inequality holds when n 0 is any positive \ninteger and c D 4. \nWhat  if we  had  subtracted  the  lower-order  terms  from  the  4n  2 term instead of \nadding  them?  What  if we  had  a small  coef\u00fbcient  for  the  n 2 term?  The  function  \nwould still be \ufffd.n  2 /. For  example,  let\u2019s  show  that  n 2 =100  \ue003 100n  \ue003 500  D \ufffd.n  2 /. \nDividing by n 2 gives 1=100  \ue003 100=n  \ue003 500=n  2 \ue004 c . We can choose any value \nfor n 0 that  is at least  10,005  and  \u00fbnd  a positive  value  for  c . For example, when \nn 0 D 10,005,  we  can  choose  c D 2:49  \ue005 10  \ue0029 . Yes,  that\u2019s  a tiny  value  for  c , but it \nis positive. If we select a larger value for n 0 , we can also increase c . For example, \nif n 0 D 100,000,  then  we  can  choose  c D 0:0089 . The higher the value of n 0 , the \ncloser  to the  coef\u00fbcient  1=100  we can choose c . \n\u201a-notation  \nWe use \u201a-notation  for  asymptotically  tight  bounds . For a given function g.n/ , we \ndenote by \u201a.g.n//  (<theta of g of n=) the set of functions \n\u201a.g.n//  D ff.n/  W there exist positive constants c 1 , c 2 , and n 0 such that \n0 \u0dc4 c 1 g.n/  \u0dc4 f.n/  \u0dc4 c 2 g.n/  for all n \ue004 n 0 g : \nFigure  3.2(c)  shows  the  intuition  behind  \u201a-notation.  For  all  values  of n at and to \nthe right of n 0 , the value of f.n/  lies at or above c 1 g.n/  and at or below c 2 g.n/ . In \nother words, for all n \ue004 n 0 , the function f.n/  is equal to g.n/  to within constant \nfactors. \nThe  de\u00fbnitions  of O-, \ufffd-, and  \u201a-notations  lead  to the  following  theorem,  whose  \nproof  we  leave  as Exercise  3.2-4.  \nTheorem  3.1  \nFor any two functions f.n/  and g.n/ , we have f.n/  D \u201a.g.n//  if and only if \nf.n/  D O.g.n//  and f.n/  D \ufffd.g.n// . \nWe  typically  apply  Theorem  3.1  to prove  asymptotically  tight  bounds  from  asymp-  \ntotic upper and lower bounds. \nAsymptotic  notation  and  running  times  \nWhen you use asymptotic notation to characterize an  algorithm\u2019s  running  time,  \nmake sure that the asymptotic notation you use is a s precise as possible without \noverstating which running time it applies to. Here are some examples of using \nasymptotic notation properly and improperly to char acterize running times. \nLet\u2019s  start  with  insertion  sort.  We  can  correctly  say  that  insertion  sort\u2019s  worst-  \ncase running time is O.n  2 /, \ufffd.n  2 /, and4due  to Theorem  3.14\u201a.n  2 /. Although 3.2  Asymptotic  notation:  formal  de\ufb01nitions  57 \nall  three  ways  to characterize  the  worst-case  running  times  are correct, the \u201a.n  2 / \nbound is the most precise and hence the most prefer red. We can also correctly say \nthat  insertion  sort\u2019s  best-case  running  time  is O.n/ , \ufffd.n/ , and \u201a.n/ , again with \n\u201a.n/  the most precise and therefore the most preferred. \nHere is what we cannot  correctly  say:  insertion  sort\u2019s  running  time  is \u201a.n  2 /. \nThat  is an overstatement  because  by  omitting  <worst-case=  from the statement, \nwe\u2019re  left  with  a blanket  statement  covering  all  cases.  The  error  here  is that  inser-  \ntion sort does not run in \u201a.n  2 / time  in all  cases  since,  as we\u2019ve  seen,  it runs  in \n\u201a.n/  time in the best case. We can correctly say that in sertion sort\u2019s  running  time  \nis O.n  2 /, however, because in all cases, its running time g rows no faster than n 2 . \nWhen we say O.n  2 / instead of \u201a.n  2 /, there is no problem in having cases whose \nrunning time grows more slowly than n 2 . Likewise, we cannot correctly say that \ninsertion  sort\u2019s  running  time  is \u201a.n/ , but we can say that its running time is \ufffd.n/ . \nHow  about  merge  sort?  Since  merge  sort  runs  in \u201a.n  lg n/ time in all cases, \nwe can just say that its running time is \u201a.n  lg n/ without  specifying  worst-case,  \nbest-case,  or any  other  case.  \nPeople  occasionally  con\u00fcate  O-notation  with  \u201a-notation  by  mistakenly  using  \nO-notation  to indicate  an asymptotically  tight  bound.  They  say things like <an \nO.n  lg n/-time  algorithm  runs  faster  than  an O.n  2 /-time  algorithm.=  Maybe  it \ndoes,  maybe  it doesn\u2019t.  Since  O-notation  denotes  only  an asymptotic  upper  bound,  \nthat  so-called  O.n  2 /-time  algorithm  might  actually  run  in \u201a.n/  time. You should \nbe careful to choose the appropriate asymptotic not ation. If you want to indicate \nan asymptotically tight bound, use \u201a-notation.  \nWe typically use asymptotic notation to provide the  simplest and most precise \nbounds possible. For example, if an algorithm has a  running time of 3n  2 C 20n  \nin all cases, we use asymptotic notation to write t hat its running time is \u201a.n  2 /. \nStrictly speaking, we are also correct in writing t hat the running time is O.n  3 / or \n\u201a.3n  2 C 20n/ . Neither of these expressions is as useful as writ ing \u201a.n  2 / in this \ncase, however: O.n  3 / is less precise than \u201a.n  2 / if the running time is 3n  2 C 20n, \nand \u201a.3n  2 C 20n/  introduces complexity that obscures the order of gr owth. By \nwriting the simplest and most precise bound, such a s \u201a.n  2 /, we can categorize \nand compare different algorithms. Throughout the bo ok, you will see asymptotic \nrunning times that are almost always based on polyn omials and logarithms:  func-  \ntions such as n, n lg 2 n, n 2 lg n, or n 1=2  . You will also see some other functions, \nsuch as exponentials, lg lg n, and lg \ue003 n (see  Section  3.3).  It is usually  fairly  easy  \nto compare  the  rates  of growth  of these  functions.  Problem  3-3  gives  you  good  \npractice. 58  Chapter  3 Characterizing  Running  Times  \nAsymptotic  notation  in equations  and  inequalities  \nAlthough  we  formally  de\u00fbne  asymptotic  notation  in terms  of sets, we use the equal \nsign ( D) instead of the set membership sign ( 2) within formulas. For example, we \nwrote that 4n  2 C 100n  C 500  D O.n  2 /. We might also write 2n  2 C 3n  C 1 D \n2n  2 C \u201a.n/. How  do  we  interpret  such  formulas?  \nWhen the asymptotic notation stands alone (that is,  not within a larger formula) \non  the  right-hand  side  of an equation  (or  inequality),  as in 4n  2 C 100n  C 500  D \nO.n  2 /, the equal sign means set membership: 4n  2 C 100n  C 500  2 O.n  2 /. In \ngeneral, however, when asymptotic notation appears in a formula, we interpret it as \nstanding for some anonymous function that we do not  care to name. For example, \nthe formula 2n  2 C 3n  C 1 D 2n  2 C \u201a.n/  means that 2n  2 C 3n  C 1 D 2n  2 C f.n/ , \nwhere f.n/  2 \u201a.n/ . In this case, we let f.n/  D 3n  C 1, which indeed belongs \nto \u201a.n/ . \nUsing asymptotic notation in this manner can help e liminate inessential detail \nand clutter in an equation. For example, in Chapter  2 we expressed  the  worst-case  \nrunning time of merge sort as the recurrence \nT.n/  D 2T.n=2/  C \u201a.n/:  \nIf we are interested only in the asymptotic behavio r of T.n/ , there is no point in \nspecifying  all  the  lower-order  terms  exactly,  because  they  are all understood to be \nincluded in the anonymous function denoted by the t erm \u201a.n/ . \nThe number of anonymous functions in an expression is understood to be equal \nto the number of times the asymptotic notation appe ars. For example,  in the  ex-  \npression \nn X  \ni D1 O.i/;  \nthere is only a single anonymous function (a functi on of i ). This expression is thus \nnot the same as O.1/  C O.2/  C \ue001 \ue001 \ue001 C  O.n/, which  doesn\u2019t  really  have  a clean  \ninterpretation. \nIn some  cases,  asymptotic  notation  appears  on  the  left-hand  side of an equation, \nas in \n2n  2 C \u201a.n/  D \u201a.n  2 /: \nInterpret such equations using the following rule: No  matter  how  the  anonymous  \nfunctions  are  chosen  on  the  left  of the  equal  sign,  there  is a way  to choose  the  \nanonymous  functions  on  the  right  of the  equal  sign  to make  the  equation  valid . \nThus, our example means that for any  function f.n/  2 \u201a.n/ , there is some function \ng.n/  2 \u201a.n  2 / such that 2n  2 Cf.n/  D g.n/  for all n. In other  words,  the  right-hand  \nside of an equation provides a coarser level of det ail than the left-hand  side.  3.2  Asymptotic  notation:  formal  de\ufb01nitions  59 \nWe can chain together a number of such relationship s, as in \n2n  2 C 3n  C 1 D 2n  2 C \u201a.n/  \nD \u201a.n  2 /: \nBy the rules above, interpret each equation separat ely. The \u00fbrst  equation  says  that  \nthere is some function f.n/  2 \u201a.n/  such that 2n  2 C3n  C1 D 2n  2 C f.n/  for all n. \nThe second equation says that for any  function g.n/  2 \u201a.n/  (such as the f.n/  just \nmentioned), there is some function h.n/  2 \u201a.n  2 / such that 2n  2 C g.n/  D h.n/  for \nall n. This interpretation implies that 2n  2 C 3n  C 1 D \u201a.n  2 /, which is what the \nchaining of equations intuitively says. \nProper  abuses  of asymptotic  notation  \nBesides the abuse of equality to mean set membershi p, which we now see has a \nprecise mathematical interpretation, another abuse of asymptotic notation occurs \nwhen the variable tending toward 1  must be inferred from context. For example, \nwhen we say O.g.n//, we  can  assume  that  we\u2019re  interested  in the  growth  of g.n/  \nas n grows, and if we say O.g.m//  we\u2019re  talking  about  the  growth  of g.m/  as m \ngrows. The free variable in the expression indicate s what variable is going to 1. \nThe most common situation requiring contextual know ledge of which variable \ntends to 1  occurs when the function inside the asymptotic nota tion is a constant, \nas in the expression O.1/ . We cannot infer from the expression which variabl e is \ngoing to 1, because no variable appears there. The context mu st disambiguate. For \nexample, if the equation using asymptotic notation is f.n/  D O.1/, it\u2019s  apparent  \nthat  the  variable  we\u2019re  interested  in is n. Knowing  from  context  that  the  variable  of \ninterest is n, however, allows us to make perfect sense of the e xpression by using \nthe  formal  de\u00fbnition  of O-notation:  the  expression  f.n/  D O.1/  means that the \nfunction f.n/  is bounded from above by a constant as n goes to 1. Technically, it \nmight be less ambiguous if we explicitly indicated the variable tending to 1  in the \nasymptotic notation itself, but that would clutter the notation. Instead, we simply \nensure that the context makes it clear which variab le (or variables) tend to 1. \nWhen the function inside the asymptotic notation is  bounded by  a positive  con-  \nstant, as in T.n/  D O.1/ , we often abuse asymptotic notation in yet another  way, \nespecially when stating recurrences. We may write s omething like T.n/  D O.1/  \nfor n < 3. According  to the  formal  de\u00fbnition  of O-notation,  this  statement  is \nmeaningless,  because  the  de\u00fbnition  only  says  that  T.n/  is bounded above by a \npositive constant c for n \ue004 n 0 for some n 0 > 0. The value of T.n/  for n < n  0 \nneed not be so bounded. Thus, in the example T.n/  D O.1/  for n<3 , we cannot \ninfer any constraint on T.n/  when n<3 , because it might be that n 0 >3. \nWhat is conventionally meant when we say T.n/  D O.1/  for n<3  is that there \nexists a positive constant c such that T.n/  \u0dc4 c for n<3 . This convention saves 60  Chapter  3 Characterizing  Running  Times  \nus the trouble of naming the bounding constant, all owing it to remain anonymous \nwhile we focus on more important variables in an an alysis. Similar abuses occur \nwith the other asymptotic notations. For example, T.n/  D \u201a.1/  for n<3  means \nthat T.n/  is bounded above and below by positive constants wh en n<3 . \nOccasionally,  the  function  describing  an algorithm\u2019s  running time may not be \nde\u00fbned  for  certain  input  sizes,  for  example,  when  an algorit hm assumes that the \ninput size is an exact power of 2. We still use asymptotic notation to describe the \ngrowth of the running time, understanding that any constraints apply only when \nthe  function  is de\u00fbned.  For  example,  suppose  that  f.n/  is de\u00fbned  only  on  a subset  \nof the natural or nonnegative real numbers. Then f.n/  D O.g.n//  means that the \nbound 0 \u0dc4 T.n/  \u0dc4 cg.n/  in the  de\u00fbnition  of O-notation  holds  for  all  n \ue004 n 0 over \nthe domain of f.n/ , that is, where f.n/  is de\u00fbned.  This  abuse  is rarely  pointed  \nout, since what is meant is generally clear from co ntext. \nIn mathematics,  it\u2019s  okay4and  often  desirable4to  abuse  a notation, as long as \nwe  don\u2019t  misuse  it. If we  understand  precisely  what  is meant  by  the  abuse  and  don\u2019t  \ndraw incorrect conclusions, it can simplify our mat hematical language, contribute \nto our  higher-level  understanding,  and  help  us focus  on  what  really matters. \no-notation  \nThe asymptotic upper bound provided by O-notation  may  or may  not  be asymp-  \ntotically tight. The bound 2n  2 D O.n  2 / is asymptotically tight, but the bound \n2n  D O.n  2 / is not. We use o-notation  to denote  an upper  bound  that  is not  asymp-  \ntotically  tight.  We  formally  de\u00fbne  o.g.n//  (<little-oh  of g of n=) as the set \no.g.n//  D ff.n/  W for any positive constant c>0 , there exists a constant \nn 0 >0  such that 0 \u0dc4 f.n/<cg.n/  for all n \ue004 n 0 g : \nFor example, 2n  D o.n  2 /, but 2n  2 \u00a4 o.n  2 /. \nThe  de\u00fbnitions  of O-notation  and  o-notation  are  similar.  The  main  difference  \nis that in f.n/  D O.g.n// , the bound 0 \u0dc4 f.n/  \u0dc4 cg.n/  holds for some con-  \nstant c>0 , but in f.n/  D o.g.n// , the bound 0 \u0dc4 f.n/  < cg.n/  holds for all \nconstants c>0 . Intuitively, in o-notation,  the  function  f.n/  becomes  insigni\u00fbcant  \nrelative to g.n/  as n gets large: \nlim \nn!1  f.n/  \ng.n/  D 0:  \nSome  authors  use  this  limit  as a de\u00fbnition  of the  o-notation,  but  the  de\u00fbnition  in \nthis book also restricts the anonymous functions to  be asymptotically nonnegative. 3.2  Asymptotic  notation:  formal  de\ufb01nitions  61 \n!-notation  \nBy analogy, !-notation  is to \ufffd-notation  as o-notation  is to O-notation.  We  use  \n!-notation  to denote  a lower  bound  that  is not  asymptotically  tight.  One  way  to \nde\u00fbne  it is by  \nf.n/  2 !.g.n//  if and only if g.n/  2 o.f.n//:  \nFormally,  however,  we  de\u00fbne  !.g.n//  (<little-omega  of g of n=) as the set \n!.g.n//  D ff.n/  W for any positive constant c>0 , there exists a constant \nn 0 >0  such that 0 \u0dc4 cg.n/<f.n/  for all n \ue004 n 0 g : \nWhere  the  de\u00fbnition  of o-notation  says  that  f.n/  < cg.n/, the  de\u00fbnition  of \n!-notation  says  the  opposite:  that  cg.n/  < f.n/ . For examples of !-notation,  \nwe have n 2 =2  D !.n/ , but n 2 =2  \u00a4 !.n  2 /. The relation f.n/  D !.g.n//  implies \nthat \nlim \nn!1  f.n/  \ng.n/  D 1  ; \nif the limit exists. That is, f.n/  becomes arbitrarily large relative to g.n/  as n gets \nlarge. \nComparing  functions  \nMany of the relational properties of real numbers a pply to asymptotic comparisons \nas well. For the following, assume that f.n/  and g.n/  are asymptotically positive. \nTransitivity:  \nf.n/  D \u201a.g.n//  and g.n/  D \u201a.h.n//  imply f.n/  D \u201a.h.n//;  \nf.n/  D O.g.n//  and g.n/  D O.h.n//  imply f.n/  D O.h.n//;  \nf.n/  D \ufffd.g.n//  and g.n/  D \ufffd.h.n//  imply f.n/  D \ufffd.h.n//  ; \nf.n/  D o.g.n//  and g.n/  D o.h.n//  imply f.n/  D o.h.n//;  \nf.n/  D !.g.n//  and g.n/  D !.h.n//  imply f.n/  D !.h.n//:  \nRe\u00fcexivity:  \nf.n/  D \u201a.f.n//;  \nf.n/  D O.f.n//;  \nf.n/  D \ufffd.f  .n//  : \nSymmetry:  \nf.n/  D \u201a.g.n//  if and only if g.n/  D \u201a.f.n//:  62  Chapter  3 Characterizing  Running  Times  \nTranspose  symmetry:  \nf.n/  D O.g.n//  if and only if g.n/  D \ufffd.f  .n//  ; \nf.n/  D o.g.n//  if and only if g.n/  D !.f.n//:  \nBecause these properties hold for asymptotic notati ons, we can draw an analogy \nbetween the asymptotic comparison of two functions f and g and the comparison \nof two real numbers a and b: \nf.n/  D O.g.n//  is like a \u0dc4 b;  \nf.n/  D \ufffd.g.n//  is like a \ue004 b;  \nf.n/  D \u201a.g.n//  is like a D b;  \nf.n/  D o.g.n//  is like a<b;  \nf.n/  D !.g.n//  is like a>b:  \nWe say that f.n/  is asymptotically  smaller  than g.n/  if f.n/  D o.g.n// , and f.n/  \nis asymptotically  larger  than g.n/  if f.n/  D !.g.n// . \nOne  property  of real  numbers,  however,  does  not  carry  over  to asymptotic  nota-  \ntion: \nTrichotomy:  For any two real numbers a and b, exactly one of the following \nmust hold: a<b , a D b, or a>b . \nAlthough any two real numbers can be compared, not all functions  are  asymptot-  \nically comparable. That is, for two functions f.n/  and g.n/ , it may be the case \nthat neither f.n/  D O.g.n//  nor f.n/  D \ufffd.g.n//  holds. For example, we cannot \ncompare the functions n and n 1Csin n using asymptotic notation, since the value of \nthe exponent in n 1Csin n oscillates between 0 and 2, taking on all values in  between. \nExercises  \n3.2-1  \nLet f.n/  and g.n/  be asymptotically nonnegative functions. Using the basic de\u00fb-  \nnition of \u201a-notation,  prove  that  max  ff.n/;g.n/ g D  \u201a.f.n/  C g.n// . \n3.2-2  \nExplain why the statement, <The running time of alg orithm A is at least O.n  2 /,= is \nmeaningless. \n3.2-3  \nIs 2 nC1 D O.2  n /? Is 2 2n  D O.2  n /? \n3.2-4  \nProve  Theorem  3.1.  3.3  Standard  notations  and  common  functions  63 \n3.2-5  \nProve that the running time of an algorithm is \u201a.g.n//  if and  only  if its  worst-case  \nrunning time is O.g.n//  and  its  best-case  running  time  is \ufffd.g.n// . \n3.2-6  \nProve that o.g.n//  \\ !.g.n//  is the empty set. \n3.2-7  \nWe can extend our notation to the case of two param eters n and m that can go to \n1  independently at different rates. For a given funct ion g.n;m/ , we denote by \nO.g.n;m//  the set of functions \nO.g.n;m//  D ff.n;m/  W there exist positive constants c , n 0 , and m 0 \nsuch that 0 \u0dc4 f.n;m/  \u0dc4 cg.n;m/  \nfor all n \ue004 n 0 or m \ue004 m 0 g : \nGive  corresponding  de\u00fbnitions  for  \ufffd.g.n;  m//  and \u201a.g.n;m// . \n3.3  Standard  notations  and  common  functions  \nThis section reviews some standard mathematical fun ctions and  notations  and  ex-  \nplores the relationships among them. It also illust rates the use of the asymptotic \nnotations. \nMonotonicity  \nA function f.n/  is monotonically  increasing  if m \u0dc4 n implies f.m/  \u0dc4 f.n/ . \nSimilarly, it is monotonically  decreasing  if m \u0dc4 n implies f.m/  \ue004 f.n/. A func-  \ntion f.n/  is strictly  increasing  if m < n  implies f.m/ < f.n/  and strictly  de-  \ncreasing  if m<n  implies f.m/>f.n/ . \nFloors  and  ceilings  \nFor any real number x , we denote the greatest integer less than or equal  to x by bx c \n(read  <the  \u00fcoor  of x =) and the least integer greater than or equal to x by dx e (read \n<the ceiling of x =).  The  \u00fcoor  function  is monotonically  increasing,  as is the  ceiling \nfunction. \nFloors and ceilings obey the following properties. For any integer n, we have \nbnc D  n D dne : (3.1)  \nFor all real x , we have 64  Chapter  3 Characterizing  Running  Times  \nx \ue003 1 <  bx c \u0dc4  x \u0dc4 dx e < x  C 1:  (3.2)  \nWe also have \n\ue003 bx c D d\ue003x e ; (3.3)  \nor equivalently, \n\ue003 dx e D b\ue003x c : (3.4)  \nFor any real number x \ue004 0 and integers a;b>0 , we have \n\u00e5 dx=ae \nb \u00e6 \nD \u00e5 x \nab  \u00e6 \n; (3.5)  \n\u00e7 bx=ac \nb \u00e8 \nD \u00e7 x \nab  \u00e8 \n; (3.6)  \n\u00e5 a \nb \u00e6 \n\u0dc4 a C .b \ue003 1/ \nb ; (3.7)  \n\u00e7 a \nb \u00e8 \n\ue004 a \ue003 .b \ue003 1/ \nb : (3.8)  \nFor any integer n and real number x , we have \nbn C x c D  n C bx c ; (3.9)  \ndn C x e D  n C dx e : (3.10)  \nModular  arithmetic  \nFor any integer a and any positive integer n, the value a mod n is the remainder  \n(or residue ) of the quotient a=n: \na mod n D a \ue003 n ba=nc : (3.11)  \nIt follows that \n0 \u0dc4 a mod n<n;  (3.12)  \neven when a is negative. \nGiven  a well-de\u00fbned  notion  of the  remainder  of one  integer  when  divided  by  an-  \nother, it is convenient to provide special notation  to indicate equality of remainders. \nIf .a mod n/ D .b mod n/, we write a D b .mod n/ and say that a is equivalent  \nto b, modulo n. In other words, a D b .mod n/ if a and b have  the  same  remain-  \nder when divided by n. Equivalently, a D b .mod n/ if and only if n is a divisor \nof b \ue003 a. We write a \u00a4 b .mod n/ if a is not equivalent to b, modulo n. 3.3  Standard  notations  and  common  functions  65 \nPolynomials  \nGiven  a nonnegative  integer  d , a polynomial  in n of degree  d is a function p.n/  \nof the form \np.n/  D d X  \ni D0 a i n i ; \nwhere the constants a 0 ;a  1 ;:::;a  d are the coef\ufb01cients  of the polynomial and \na d \u00a4 0. A polynomial is asymptotically positive if and on ly if a d > 0. For an \nasymptotically positive polynomial p.n/  of degree d , we have p.n/  D \u201a.n  d /. For \nany real constant a \ue004 0, the function n a is monotonically increasing, and for any \nreal constant a \u0dc4 0, the function n a is monotonically decreasing. We say that a \nfunction f.n/  is polynomially  bounded  if f.n/  D O.n  k / for some constant k. \nExponentials  \nFor all real a>0 , m, and n, we have the following identities: \na 0 D 1;  \na 1 D a;  \na \ue0021 D 1=a  ; \n.a m / n D a mn  ; \n.a m / n D .a n / m ; \na m a n D a mCn : \nFor all n and a \ue004 1, the function a n is monotonically increasing in n. When \nconvenient, we assume that 0 0 D 1. \nWe can relate the rates of growth of polynomials an d exponentials  by  the  fol-  \nlowing fact. For all real constants a>1  and b, we have \nlim \nn!1  n b \na n D 0;  \nfrom which we can conclude that \nn b D o.a  n /: (3.13)  \nThus, any exponential function with a base strictly  greater than 1 grows faster than \nany polynomial function. \nUsing e to denote 2:71828:::, the  base  of the  natural-logarithm  function,  we  \nhave for all real x , \ne x D 1 C x C x 2 \n2\u0160 C x 3 \n3\u0160 C \ue001 \ue001 \ue001 D  1  X  \ni D0 x i \ni\u0160 ; 66  Chapter  3 Characterizing  Running  Times  \nwhere <\u0160= denotes  the  factorial  function  de\u00fbned  later  in this  sectio n. For all real x , \nwe have the inequality \n1 C x \u0dc4 e x ; (3.14)  \nwhere equality holds only when x D 0. When jx j \u0dc4  1, we have the approximation \n1 C x \u0dc4 e x \u0dc4 1 C x C x 2 : (3.15)  \nWhen x !  0, the approximation of e x by 1 C x is quite good: \ne x D 1 C x C \u201a.x  2 /: \n(In this equation, the asymptotic notation is used to describe the limiting behavior \nas x !  0 rather than as x ! 1 .) We have for all x , \nlim \nn!1  \ue002 \n1 C x \nn \u00cd n \nD e x : (3.16)  \nLogarithms  \nWe use the following notations: \nlg n D log 2 n (binary logarithm) , \nln n D log e n (natural logarithm) , \nlg k n D .lg n/ k (exponentiation) , \nlg lg n D lg.lg n/ (composition) . \nWe adopt the following notational convention: in th e absence of parentheses, a \nlogarithm  function  applies  only  to the  next  term  in the  formu la, so that lg n C 1 \nmeans .lg n/ C 1 and not lg.n C 1/. \nFor any constant b > 1 , the function log b n is unde\u00fbned  if n \u0dc4 0, strictly \nincreasing if n>0 , negative if 0<n<1 , positive if n>1 , and 0 if n D 1. For \nall real a>0 , b>0 , c>0 , and n, we have \na D b log b a ; (3.17)  \nlog c .ab/  D log c a C log c b;  (3.18)  \nlog b a n D n log b a;  \nlog b a D log c a \nlog c b ; (3.19)  \nlog b .1=a/  D \ue003  log b a;  (3.20)  \nlog b a D 1 \nlog a b ; \na log b c D c log b a ; (3.21)  \nwhere, in each equation above, logarithm bases are not 1. 3.3  Standard  notations  and  common  functions  67 \nBy  equation  (3.19),  changing  the  base  of a logarithm  from  one  constant  to an-  \nother changes the value of the logarithm by only a constant factor. Consequently, \nwe often use the notation <lg n= when  we  don\u2019t  care  about  constant  factors,  such  \nas in O-notation.  Computer  scientists  \u00fbnd  2 to be the  most  natural  base  for  loga-  \nrithms because so many algorithms and data structur es involve splitting a problem \ninto two parts. \nThere is a simple series expansion for ln .1 C x/  when jx j <1: \nln.1 C x/  D x \ue003 x 2 \n2 C x 3 \n3 \ue003 x 4 \n4 C x 5 \n5 \ue003 \ue001 \ue001 \ue001  : (3.22)  \nWe also have the following inequalities for x>  \ue0031: \nx \n1 C x \u0dc4 ln.1 C x/  \u0dc4 x;  (3.23)  \nwhere equality holds only for x D 0. \nWe say that a function f.n/  is polylogarithmically  bounded  if f.n/  D O.lg k n/ \nfor some constant k. We can relate the growth of polynomials and polyl ogarithms \nby substituting lg n for n and 2 a for a in equation  (3.13).  For  all  real  constants  \na>0  and b, we have \nlg b n D o.n  a /: (3.24)  \nThus, any positive polynomial function grows faster  than any polylogarithmic  func-  \ntion. \nFactorials  \nThe notation n\u0160 (read <n factorial=)  is de\u00fbned  for  integers  n \ue004 0 as \nn\u0160 D ( \n1 if n D 0;  \nn \ue001 .n \ue003 1/\u0160  if n>0:  \nThus, n\u0160 D 1 \ue001 2 \ue001 3 \ue001 \ue001 \ue001  n. \nA weak upper bound on the factorial function is n\u0160 \u0dc4 n n , since each of the n \nterms in the factorial product is at most n. Stirling\u2019s  approximation , \nn\u0160 D p \n2\ufffdn  \ue002 n \ne \u00cd n \u00ce \n1 C \u201a \u00ce 1 \nn \u00cf\u00cf  \n; (3.25)  \nwhere e is the base of the natural logarithm, gives us a ti ghter upper bound, and a \nlower  bound  as well.  Exercise  3.3-4  asks  you  to prove  the  three facts \nn\u0160 D o.n  n /; (3.26)  \nn\u0160 D !.2  n /; (3.27)  \nlg.n\u0160/  D \u201a.n  lg n/;  (3.28)  68  Chapter  3 Characterizing  Running  Times  \nwhere  Stirling\u2019s  approximation  is helpful  in proving  equation  (3.28).  The  following  \nequation also holds for all n \ue004 1: \nn\u0160 D p \n2\ufffdn  \ue002 n \ne \u00cd n \ne \u02db n (3.29)  \nwhere \n1 \n12n  C 1 <\u02db  n < 1 \n12n  : \nFunctional  iteration  \nWe use the notation f .i/  .n/  to denote the function f.n/  iteratively applied i times \nto an initial value of n. Formally, let f.n/  be a function  over  the  reals.  For  non-  \nnegative integers i , we  recursively  de\u00fbne  \nf .i/  .n/  D ( \nn if i D 0;  \nf.f  .i \ue0021/  .n//  if i >0:  (3.30)  \nFor example, if f.n/  D 2n, then f .i/  .n/  D 2 i n. \nThe  iterated  logarithm  function  \nWe use the notation lg \ue003 n (read <log star of n=) to denote  the  iterated  logarithm,  de-  \n\u00fbned  as follows.  Let  lg .i/  n be as de\u00fbned  above,  with  f.n/  D lg n. Because  the  log-  \narithm  of a nonpositive  number  is unde\u00fbned,  lg .i/  n is de\u00fbned  only  if lg .i \ue0021/  n>0 . \nBe sure to distinguish lg .i/  n (the logarithm function applied i times in succession, \nstarting with argument n) from lg i n (the logarithm of n raised to the i th power). \nThen  we  de\u00fbne  the  iterated  logarithm  function  as \nlg \ue003 n D min \u02da \ni \ue004 0 W lg .i/  n \u0dc4 1 \ue009 \n: \nThe iterated logarithm is a very  slowly growing function: \nlg \ue003 2 D 1;  \nlg \ue003 4 D 2;  \nlg \ue003 16  D 3;  \nlg \ue003 65536  D 4;  \nlg \ue003 .2 65536  / D 5:  \nSince the number of atoms in the observable univers e is estimated to be about 10  80  , \nwhich is much less than 2 65536  D 10  65536=  lg 10  \ue002 10  19;728  , we rarely encounter an \ninput size n for which lg \ue003 n>5 . 3.3  Standard  notations  and  common  functions  69 \nFibonacci  numbers  \nWe  de\u00fbne  the  Fibonacci  numbers  F i , for i \ue004 0, as follows: \nF i D \u0128 \n0 if i D 0;  \n1 if i D 1;  \nF i \ue0021 C F i \ue0022 if i \ue004 2:  (3.31)  \nThus,  after  the  \u00fbrst  two,  each  Fibonacci  number  is the  sum  of the two previous \nones, yielding the sequence \n0; 1; 1; 2; 3; 5; 8; 13;  21;  34;  55;  :::  : \nFibonacci numbers are related to the golden  ratio  \ufffd and its conjugate y \ufffd , which are \nthe two roots of the equation \nx 2 D x C 1:  \nAs  Exercise  3.3-7  asks  you  to prove,  the  golden  ratio  is given  by \n\ufffd D 1 C p \n5 \n2 (3.32)  \nD 1:61803:::  ; \nand its conjugate, by \ny \ufffd D 1 \ue003 p \n5 \n2 (3.33)  \nD \ue003:61803:::  : \nSpeci\u00fbcally,  we  have  \nF i D \ufffd i \ue003 y \ufffd i \np \n5 ; \nwhich  can  be proved  by  induction  (Exercise  3.3-8).  Since  \u02c7 \u02c7 y \ufffd \u02c7 \u02c7 <1, we have \n\u02c7 \u02c7 y \ufffd i \u02c7 \u02c7 \np \n5 < 1 p \n5 \n< 1 \n2 ; \nwhich implies that \nF i D \u00e7 \ufffd i \np \n5 C 1 \n2 \u00e8 \n; (3.34)  \nwhich is to say that the i th Fibonacci number F i is equal to \ufffd i = p \n5 rounded to the \nnearest integer. Thus, Fibonacci numbers grow expon entially. 70  Chapter  3 Characterizing  Running  Times  \nExercises  \n3.3-1  \nShow that if f.n/  and g.n/  are monotonically increasing functions, then so are  \nthe functions f.n/  C g.n/  and f.g.n// , and if f.n/  and g.n/  are in addition \nnonnegative, then f.n/  \ue001 g.n/  is monotonically increasing. \n3.3-2  \nProve that b\u02dbncCd.1 \ue003 \u02db/ne D  n for any integer n and real number \u02db in the range \n0 \u0dc4 \u02db \u0dc4 1. \n3.3-3  \nUse  equation  (3.14)  or other  means  to show  that  .n C o.n//  k D \u201a.n  k / for any real \nconstant k. Conclude that dne k D \u201a.n  k / and bnc k D \u201a.n  k /. \n3.3-4  \nProve the following: \na. Equation  (3.21).  \nb. Equations  (3.26)3(3.28).  \nc. lg.\u201a.n//  D \u201a.lg n/. \n? 3.3-5  \nIs the function dlg ne\u0160 polynomially  bounded?  Is the  function  dlg lg ne\u0160 polynomi-  \nally  bounded?  \n? 3.3-6  \nWhich is asymptotically larger: lg .lg \ue003 n/ or lg \ue003 .lg n/? \n3.3-7  \nShow that the golden ratio \ufffd and its conjugate y \ufffd both satisfy the equation \nx 2 D x C 1. \n3.3-8  \nProve by induction that the i th Fibonacci  number  satis\u00fbes  the  equation  \nF i D .\ufffd  i \ue003 y \ufffd i /= p \n5;  \nwhere \ufffd is the golden ratio and y \ufffd is its conjugate. \n3.3-9  \nShow that k lg k D \u201a.n/  implies k D \u201a.n=  lg n/. Problems for Chapter 3 71 \nProblems  \n3-1  Asymptotic  behavior  of polynomials  \nLet \np.n/  D d X  \ni D0 a i n i ; \nwhere a d > 0, be a degree-d polynomial in n, and let k be a constant. Use the \nde\u00fbnitions  of the  asymptotic  notations  to prove  the  followi ng properties. \na. If k \ue004 d , then p.n/  D O.n  k /. \nb. If k \u0dc4 d , then p.n/  D \ufffd.n  k /. \nc. If k D d , then p.n/  D \u201a.n  k /. \nd. If k>d  , then p.n/  D o.n  k /. \ne. If k<d  , then p.n/  D !.n  k /. \n3-2  Relative  asymptotic  growths  \nIndicate, for each pair of expressions .A;B/  in the table below whether A is O, o, \n\ufffd, !, or \u201a of B . Assume that k \ue004 1, \ufffd > 0 , and c>1  are constants. Write your \nanswer in the form of the table with <yes= or <no= written in each box. \nA B O o \ufffd ! \u201a \na. lg k n n \ue001 \nb. n k c n \nc. p n n sin n \nd. 2 n 2 n=2  \ne. n lg c c lg n \nf. lg.n\u0160/  lg.n n / \n3-3  Ordering  by asymptotic  growth  rates  \na. Rank  the  following  functions  by  order  of growth.  That  is, \u00fbnd  an arrange-  \nment g 1 ;g  2 ;:::;g  30  of the functions satisfying g 1 D \ufffd.g  2 /, g 2 D \ufffd.g  3 /, . . . , \ng 29  D \ufffd.g  30  /. Partition your list into equivalence classes such  that functions \nf.n/  and g.n/  belong to the same class if and only if f.n/  D \u201a.g.n// . 72  Chapter  3 Characterizing  Running  Times  \nlg.lg \ue003 n/ 2 lg \ue002 n . p \n2/ lg n n 2 n\u0160 .lg n/\u0160  \n.3=2/  n n 3 lg 2 n lg.n\u0160/  2 2 n n 1=  lg n \nln ln n lg \ue003 n n \ue001 2 n n lg lg n ln n 1 \n2 lg n .lg n/ lg n e n 4 lg n .n C 1/\u0160  p \nlg n \nlg \ue003 .lg n/ 2 p  2 lg n n 2 n n lg n 2  2 nC1 \nb. Give  an example  of a single  nonnegative  function  f.n/  such  that  for  all  func-  \ntions g i .n/  in part (a), f.n/  is neither O.g  i .n//  nor \ufffd.g  i .n//. \n3-4  Asymptotic  notation  properties  \nLet f.n/  and g.n/  be asymptotically positive functions. Prove or disp rove each of \nthe following conjectures. \na. f.n/  D O.g.n//  implies g.n/  D O.f.n// . \nb. f.n/  C g.n/  D \u201a.min ff.n/;g.n/ g/. \nc. f.n/  D O.g.n//  implies lg f.n/  D O.lg g.n// , where lg g.n/  \ue004 1 and \nf.n/  \ue004 1 for  all  suf\u00fbciently  large  n. \nd. f.n/  D O.g.n//  implies 2 f .n/  D O \u00e3 \n2 g.n/  \u00e4 \n. \ne. f.n/  D O..f.n//  2 /. \nf. f.n/  D O.g.n//  implies g.n/  D \ufffd.f  .n// . \ng. f.n/  D \u201a.f.n=2// . \nh. f.n/  C o.f.n//  D \u201a.f.n// . \n3-5  Manipulating  asymptotic  notation  \nLet f.n/  and g.n/  be asymptotically positive functions. Prove the fol lowing iden-  \ntities: \na. \u201a.\u201a.f.n///  D \u201a.f.n// . \nb. \u201a.f.n//  C O.f.n//  D \u201a.f.n// . \nc. \u201a.f.n//  C \u201a.g.n//  D \u201a.f.n/  C g.n// . \nd. \u201a.f.n//  \ue001 \u201a.g.n//  D \u201a.f.n/  \ue001 g.n// . Problems for Chapter 3 73 \ne. Argue that for any real constants a 1 ;b  1 > 0  and integer constants k 1 ;k  2 , the \nfollowing asymptotic bound holds: \n.a 1 n/ k 1 lg k 2 .a 2 n/ D \u201a.n  k 1 lg k 2 n/:  \n? f. Prove that for S \u0dc2 Z, we have \nX  \nk2S \u201a.f.k//  D \u201a \ue001 X  \nk2S f.k/  ! \n; \nassuming that both sums converge. \n? g. Show that for S \u0dc2 Z, the following asymptotic bound does not necessari ly \nhold, even assuming that both products converge, by  giving a counterexample: \nY  \nk2S \u201a.f.k//  D \u201a \ue001 Y  \nk2S f.k/  ! \n: \n3-6  Variations  on  O and  \u02dd \nSome  authors  de\u00fbne  \ufffd-notation  in a slightly  different  way  than  this  textbook  does. \nWe\u2019ll  use  the  nomenclature  1  \ufffd (read  <omega  in\u00fbnity=)  for  this  alternative  de\u00fbni-  \ntion. We say that f.n/  D 1  \ufffd.g.n//  if there exists a positive constant c such that \nf.n/  \ue004 cg.n/  \ue004 0 for  in\u00fbnitely  many  integers  n. \na. Show that for any two asymptotically nonnegative fu nctions f.n/  and g.n/ , we \nhave f.n/  D O.g.n//  or f.n/  D 1  \ufffd.g.n//  (or both). \nb. Show that there exist two asymptotically nonnegativ e functions f.n/  and g.n/  \nfor which neither f.n/  D O.g.n//  nor f.n/  D \ufffd.g.n//  holds. \nc. Describe the potential advantages and disadvantages  of using 1  \ufffd-notation  in-  \nstead of \ufffd-notation  to characterize  the  running  times  of programs.  \nSome  authors  also  de\u00fbne  O in a slightly  different  manner.  We\u2019ll  use  O 0 for the \nalternative  de\u00fbnition:  f.n/  D O 0 .g.n//  if and only if jf.n/ j D  O.g.n// . \nd. What happens to each direction of the <if and only if= in Theor em  3.1  on  \npage  56  if we  substitute  O 0 for O but still use \ufffd? \nSome  authors  de\u00fbne  e O (read  <soft-oh=)  to mean  O with  logarithmic  factors  ig-  \nnored: 74  Chapter  3 Characterizing  Running  Times  \ne O.g.n//  D ff.n/  W there exist positive constants c , k, and n 0 such that \n0 \u0dc4 f.n/  \u0dc4 cg.n/  lg k .n/  for all n \ue004 n 0 g : \ne. De\u00fbne  e \ufffd and e \u201a in a similar  manner.  Prove  the  corresponding  analog  to Theo-  \nrem  3.1.  \n3-7  Iterated  functions  \nWe can apply the iteration operator \ue003 used in the lg \ue003 function to any monotonically \nincreasing function f.n/  over the reals. For a given constant c 2 R, we  de\u00fbne  the  \niterated function f \ue003 \nc by \nf \ue003 \nc .n/  D min \u02da \ni \ue004 0 W f .i/  .n/  \u0dc4 c \ue009 \n; \nwhich  need  not  be well  de\u00fbned  in all  cases.  In other  words,  the  quantity f \ue003 \nc .n/  is \nthe minimum number of iterated applications of the function f required to reduce \nits argument down to c or less. \nFor each of the functions f.n/  and constants c in the table below, give as tight \na bound as possible on f \ue003 \nc .n/. If there is no i such that f .i/  .n/  \u0dc4 c , write  <unde-  \n\u00fbned=  as your  answer.  \nf.n/  c f \ue003 \nc .n/  \na. n \ue003 1 0 \nb. lg n 1 \nc. n=2  1 \nd. n=2  2 \ne. p n 2 \nf. p n 1 \ng. n 1=3  2 \nChapter  notes  \nKnuth  [259]  traces  the  origin  of the  O-notation  to a number-theory  text  by  P. Bach-  \nmann  in 1892.  The  o-notation  was  invented  by  E. Landau  in 1909  for  his  discussio n \nof the distribution of prime numbers. The \ufffd and \u201a notations were advocated by \nKnuth  [265]  to correct  the  popular,  but  technically  sloppy,  practice  in the  litera-  \nture of using O-notation  for  both  upper  and  lower  bounds.  As  noted  earlier  in \nthis chapter, many people continue to use the O-notation  where  the  \u201a-notation  is \nmore  technically  precise.  The  soft-oh  notation  e O in Problem  3-6  was  introduced  Notes for Chapter 3 75 \nby  Babai,  Luks,  and  Seress  [31],  although  it was  originally  written as O\ue006. Some \nauthors  now  de\u00fbne  e O.g.n//  as ignoring factors that are logarithmic in g.n/ , rather \nthan in n. With  this  de\u00fbnition,  we  can  say  that  n2  n D e O.2  n /, but  with  the  de\u00fb-  \nnition  in Problem  3-6,  this  statement  is not  true.  Further  discussion of the history \nand development of asymptotic notations appears in works by Knuth  [259,  265]  \nand  Brassard  and  Bratley  [70].  \nNot  all  authors  de\u00fbne  the  asymptotic  notations  in the  same  way, although the \nvarious  de\u00fbnitions  agree  in most  common  situations.  Some  of the  alternative  def-  \ninitions encompass functions that are not asymptoti cally nonnegative, as long as \ntheir absolute values are appropriately bounded. \nEquation  (3.29)  is due  to Robbins  [381].  Other  properties  of elementary  math-  \nematical functions can be found in any good mathema tical reference, such as \nAbramowitz  and  Stegun  [1]  or Zwillinger  [468],  or in a calcul us book, such as \nApostol  [19]  or Thomas  et al.  [433].  Knuth  [259]  and  Graham,  Knuth,  and  Patash-  \nnik  [199]  contain  a wealth  of material  on  discrete  mathemati cs as used in computer \nscience. 4 Divide-and-Conquer  \nThe  divide-and-conquer  method  is a powerful  strategy  for  designing asymptotically \nef\u00fbcient  algorithms.  We  saw  an example  of divide-and-conquer  in Section  2.3.1  \nwhen  learning  about  merge  sort.  In this  chapter,  we\u2019ll  explo re applications of the \ndivide-and-conquer  method  and  acquire  valuable  mathemati cal tools that you can \nuse to solve the recurrences that arise when analyz ing divide-and-conquer  algo-  \nrithms. \nRecall  that  for  divide-and-conquer,  you  solve  a given  problem  (instance)  recur-  \nsively.  If the  problem  is small  enough4the  base  case4you  just  solve  it directly  \nwithout  recursing.  Otherwise4the  recursive  case4you  perform  three  character-  \nistic steps: \nDivide  the problem into one or more subproblems that are s maller instances of the \nsame problem. \nConquer  the subproblems by solving them recursively. \nCombine  the subproblem solutions to form a solution to the original problem. \nA divide-and-conquer  algorithm  breaks  down  a large  problem  into  smaller  sub-  \nproblems, which themselves may be broken down into even smaller subproblems, \nand so forth. The recursion bottoms  out  when  it reaches  a base  case  and  the  sub-  \nproblem is small enough to solve directly without f urther recursing. \nRecurrences  \nTo  analyze  recursive  divide-and-conquer  algorithms,  we\u2019ll  need  some  mathemat-  \nical tools. A recurrence  is an equation that describes a function in terms o f its \nvalue on other, typically smaller, arguments. Recur rences go hand in hand with \nthe  divide-and-conquer  method  because  they  give  us a natura l way to characterize \nthe running times of recursive algorithms mathemati cally. You saw an example \nof a recurrence  in Section  2.3.2  when  we  analyzed  the  worst-c ase running time of \nmerge sort. Chapter  4 Divide-and-Conquer  77 \nFor  the  divide-and-conquer  matrix-multiplication  algorithms  presented  in Sec-  \ntions  4.1  and  4.2,  we\u2019ll  derive  recurrences  that  describe  their  worst-case  running  \ntimes.  To  understand  why  these  two  divide-and-conquer  algorithms perform the \nway  they  do,  you\u2019ll  need  to learn  how  to solve  the  recurrences  that describe their \nrunning  times.  Sections  4.334.7  teach  several  methods  for  solving recurrences. \nThese sections also explore the mathematics behind recurrences, which can give \nyou  stronger  intuition  for  designing  your  own  divide-and-c onquer algorithms. \nWe  want  to get  to the  algorithms  as soon  as possible.  So,  let\u2019s  just cover a few \nrecurrence  basics  now,  and  then  we\u2019ll  look  more  deeply  at recurrences, especially \nhow  to solve  them,  after  we  see  the  matrix-multiplication  examples. \nThe general form of a recurrence is an equation or inequality that describes a \nfunction over the integers or reals using the funct ion itself. It contains two or more \ncases, depending on the argument. If a case involve s the recursive invocation of the \nfunction on different (usually smaller) inputs, it is a recursive  case. If a case does \nnot involve a recursive invocation, it is a base  case. There may be zero, one, or \nmany functions that satisfy the statement of the re currence. The recurrence is well  \nde\ufb01ned  if there  is at least  one  function  that  satis\u00fbes  it, and  ill de\ufb01ned  otherwise. \nAlgorithmic  recurrences  \nWe\u2019ll  be particularly  interested  in recurrences  that  descr ibe the running times of \ndivide-and-conquer  algorithms.  A recurrence  T.n/  is algorithmic  if, for every \nsuf\u00fbciently  large  threshold  constant n 0 >0, the following two properties hold: \n1. For  all  n<n  0 , we have T.n/  D \u201a.1/ . \n2. For all n \ue004 n 0 , every  path  of recursion  terminates  in a de\u00fbned  base  case  within \na \u00fbnite  number  of recursive  invocations.  \nSimilar to how we sometimes abuse asymptotic notati on (see page  60),  when  a \nfunction  is not  de\u00fbned  for  all  arguments,  we  understand  that  this  de\u00fbnition  is con-  \nstrained to values of n for which T.n/  is de\u00fbned.  \nWhy would a recurrence T.n/  that  represents  a (correct)  divide-and-conquer  al-  \ngorithm\u2019s  worst-case  running  time  satisfy  these  properties  for  all  suf\u00fbciently  large  \nthreshold  constants?  The  \u00fbrst  property  says  that  there  exist constants c 1 ;c 2 such \nthat 0 <c  1 \u0dc4 T.n/  \u0dc4 c 2 for n <n  0 . For every legal input, the algorithm must \noutput  the  solution  to the  problem  it\u2019s  solving  in \u00fbnite  time  (see  Section  1.1).  Thus  \nwe can let c 1 be the minimum amount of time to call and return fr om a procedure, \nwhich must be positive, because machine instruction s need to be executed  to in-  \nvoke a procedure. The running time of the algorithm  may not be de\u00fbned  for  some  \nvalues of n if there  are  no  legal  inputs  of that  size,  but  it must  be de\u00fbned  for at \nleast  one,  or else  the  <algorithm=  doesn\u2019t  solve  any  problem . Thus we can let c 2 be \nthe  algorithm\u2019s  maximum  running  time  on  any  input  of size  n <n  0 , where n 0 is 78  Chapter  4 Divide-and-Conquer  \nsuf\u00fbciently  large  that  the  algorithm  solves  at least  one  problem of size less than n 0 . \nThe  maximum  is well  de\u00fbned,  since  there  are  at most  a \u00fbnite  number of inputs of \nsize less than n 0 , and there is at least one if n 0 is suf\u00fbciently  large.  Consequently,  \nT.n/  satis\u00fbes  the  \u00fbrst  property.  If the  second  property  fails  to hold for T.n/ , then \nthe  algorithm  isn\u2019t  correct,  because  it would  end  up  in an in\u00fbnite recursive loop or \notherwise fail to compute a solution. Thus, it stan ds to reason that a recurrence for \nthe  worst-case  running  time  of a correct  divide-and-conque r algorithm would be \nalgorithmic. \nConventions  for  recurrences  \nWe adopt the following convention: \nWhenever  a recurrence  is stated  without  an  explicit  base  case,  we  assume  \nthat  the  recurrence  is algorithmic.  \nThat  means  you\u2019re  free  to pick  any  suf\u00fbciently  large  thresho ld constant n 0 for the \nrange of base cases where T.n/  D \u201a.1/ . Interestingly, the asymptotic solutions of \nmost  algorithmic  recurrences  you\u2019re  likely  to see  when  analyzing  algorithms  don\u2019t  \ndepend  on  the  choice  of threshold  constant,  as long  as it\u2019s  large enough to make \nthe  recurrence  well  de\u00fbned.  \nAsymptotic  solutions  of algorithmic  divide-and-conquer  recurrences  also  don\u2019t  \ntend  to change  when  we  drop  any  \u00fcoors  or ceilings  in a recurrence  de\u00fbned  on  the  \nintegers  to convert  it to a recurrence  de\u00fbned  on  the  reals.  Section  4.7  gives  a suf-  \n\u00fbcient  condition  for  ignoring  \u00fcoors  and  ceilings  that  applies  to most  of the  divide-  \nand-conquer  recurrences  you\u2019re  likely  to see.  Consequently,  we\u2019ll  frequently  state  \nalgorithmic  recurrences  without  \u00fcoors  and  ceilings.  Doing  so generally  simpli\u00fbes  \nthe statement of the recurrences, as well as any ma th that we do with them. \nYou may sometimes see recurrences that are not equa tions, but rather  inequal-  \nities, such as T.n/  \u0dc4 2T.n=2/  C \u201a.n/ . Because such a recurrence states only \nan upper bound on T.n/ , we express its solution using O-notation  rather  than  \n\u201a-notation.  Similarly,  if the  inequality  is reversed  to T.n/  \ue004 2T.n=2/  C \u201a.n/ , \nthen, because the recurrence gives only a lower bou nd on T.n/ , we use \ufffd-notation  \nin its solution. \nDivide-and-conquer  and  recurrences  \nThis  chapter  illustrates  the  divide-and-conquer  method  by  presenting and using \nrecurrences  to analyze  two  divide-and-conquer  algorithms  for multiplying n \ue005 n \nmatrices.  Section  4.1  presents  a simple  divide-and-conque r algorithm that solves \na matrix-multiplication  problem  of size  n by breaking it into four subproblems of \nsize n=2, which it then solves recursively. The running tim e of the algorithm can \nbe characterized by the recurrence Chapter  4 Divide-and-Conquer  79 \nT .n/  D 8T .n=2/  C \u201a.1/ ;  \nwhich turns out to have the solution T .n/  D \u201a.n  3 /. Although  this  divide-and-  \nconquer algorithm is no faster than the straightfor ward method that uses a triply \nnested  loop,  it leads  to an asymptotically  faster  divide-and-conquer  algorithm  due  \nto V. Strassen,  which  we\u2019ll  explore  in Section  4.2.  Strassen\u2019s  remarkable  algorithm  \ndivides a problem of size n into seven subproblems of size n=2  which it solves \nrecursively.  The  running  time  of Strassen\u2019s  algorithm  can  be described by the \nrecurrence \nT .n/  D 7T .n=2/  C \u201a.n  2 / ; \nwhich has the solution T .n/  D \u201a.n  lg 7 / D O.n  2:81  /. Strassen\u2019s  algorithm  beats  \nthe straightforward looping method asymptotically. \nThese  two  divide-and-conquer  algorithms  both  break  a probl em of size n into \nseveral subproblems of size n=2. Although  it is common  when  using  divide-and-  \nconquer for all the subproblems to have the same si ze, that isn\u2019t  always  the  case.  \nSometimes  it\u2019s  productive  to divide  a problem  of size  n into  subproblems  of differ-  \nent sizes, and then the recurrence describing the r unning time  re\u00fcects  the  irregular-  \nity.  For  example,  consider  a divide-and-conquer  algorithm  that divides a problem \nof size n into one subproblem of size n=3  and another of size 2n=3 , taking \u201a.n/  \ntime to divide the problem and combine the solution s to the subproblems. Then the \nalgorithm\u2019s  running  time  can  be described  by  the  recurrence  \nT .n/  D T .n=3/  C T .2n=3/  C \u201a.n/ ;  \nwhich turns out to have solution T .n/  D \u201a.n  lg n/. We\u2019ll  even  see  an algorithm  in \nChapter 9 that solves a problem of size n by recursively solving a subproblem of \nsize n=5  and another of size 7n=10 , taking \u201a.n/  time for the divide and combine \nsteps.  Its  performance  satis\u00fbes  the  recurrence  \nT .n/  D T .n=5/  C T .7n=10/  C \u201a.n/ ;  \nwhich has solution T .n/  D \u201a.n/ . \nAlthough  divide-and-conquer  algorithms  usually  create  subproblems with sizes \na constant  fraction  of the  original  problem  size,  that\u2019s  not  always the case. For \nexample, a recursive version of linear search (see Exercise 2.1-4)  creates  just  one  \nsubproblem, with one element less than the original  problem. Each recursive call \ntakes constant time plus the time to recursively so lve a subproblem with one less \nelement, leading to the recurrence \nT .n/  D T .n  \ue003 1/ C \u201a.1/ ;  \nwhich has solution T .n/  D \u201a.n/. Nevertheless,  the  vast  majority  of ef\u00fbcient  \ndivide-and-conquer  algorithms  solve  subproblems  that  are  a constant fraction of \nthe  size  of the  original  problem,  which  is where  we\u2019ll  focus  our efforts. 80  Chapter  4 Divide-and-Conquer  \nSolving  recurrences  \nAfter  learning  about  divide-and-conquer  algorithms  for  matrix multiplication in \nSections  4.1  and  4.2,  we\u2019ll  explore  several  mathematical  tools  for  solving  recur-  \nrences4that  is, for  obtaining  asymptotic  \u201a-, O-, or \ufffd-bounds  on  their  solutions.  \nWe  want  simple-to-use  tools  that  can  handle  the  most  commonly  occurring  situa-  \ntions. But we also want general tools that work, pe rhaps with a little more effort, \nfor less common cases. This chapter offers four met hods for solving recurrences: \n\ue001 In the substitution  method  (Section  4.3),  you  guess  the  form  of a bound  and  \nthen use mathematical induction to prove your guess  correct and  solve  for  con-  \nstants. This method is perhaps the most robust meth od for solving recurrences, \nbut it also requires you to make a good guess and t o produce an inductive proof. \n\ue001 The recursion-tree  method  (Section  4.4)  models  the  recurrence  as a tree  whose  \nnodes represent the costs incurred at various level s of the recursion. To solve \nthe recurrence, you determine the costs at each lev el and add them up, perhaps \nusing techniques for bounding summations from Secti on A.2. Even  if you  don\u2019t  \nuse this method to formally prove a bound, it can b e helpful in guessing the form \nof the bound for use in the substitution method. \n\ue001 The master  method  (Sections  4.5  and  4.6)  is the  easiest  method,  when  it applies . \nIt provides bounds for recurrences of the form \nT.n/  D aT.n=b/  C f.n/;  \nwhere a >0  and b >1  are constants and f.n/  is a given <driving= function. \nThis type of recurrence tends to arise more frequen tly in the study of algorithms \nthan  any  other.  It characterizes  a divide-and-conquer  algorithm that creates \na subproblems, each of which is 1=b  times the size of the original problem, \nusing f.n/  time for the divide and combine steps. To apply the  master method, \nyou need to memorize three cases, but once you do, you can easily determine \nasymptotic  bounds  on  running  times  for  many  divide-and-con quer algorithms. \n\ue001 The Akra-Bazzi  method  (Section  4.7)  is a general  method  for  solving  divide-  \nand-conquer  recurrences.  Although  it involves  calculus,  it can be used to attack \nmore complicated recurrences than those addressed b y the master method. \n4.1  Multiplying  square  matrices  \nWe  can  use  the  divide-and-conquer  method  to multiply  square  matrices.  If you\u2019ve  \nseen matrices before, then you probably know how to  multiply them.  (Otherwise,  4.1  Multiplying  square  matrices  81 \nyou  should  read  Section  D.1.)  Let  A D .a ik  / and B D .b jk  / be square n \ue005 n \nmatrices. The matrix product C D A \ue001 B is also an n \ue005 n matrix, where for \ni;j  D 1;2;:::;n , the .i;j/  entry of C is given by \nc ij D n X  \nkD1 a ik  \ue001 b kj  : (4.1)  \nGenerally,  we\u2019ll  assume  that  the  matrices  are  dense , meaning that most of the n 2 \nentries are not 0, as opposed to sparse , where most of the n 2 entries are 0 and the \nnonzero entries can be stored more compactly than i n an n \ue005 n array. \nComputing the matrix C requires computing n 2 matrix entries, each of which is \nthe sum of n pairwise products of input elements from A and B . The M ATRIX- \nMULTIPLY procedure implements this strategy in a straightfor ward manner, and \nit generalizes the problem slightly. It takes as in put three n \ue005 n matrices A, B , \nand C , and it adds the matrix product A \ue001 B to C , storing the result in C . Thus, it \ncomputes C D C C A \ue001 B , instead of just C D A \ue001 B . If only the product A \ue001 B is \nneeded, just initialize all n 2 entries of C to 0 before calling the procedure, which \ntakes an additional \u201a.n  2 / time.  We\u2019ll  see  that  the  cost  of matrix  multiplication  \nasymptotically dominates this initialization cost. \nMATRIX-MULTIPLY .A;B;C;n/  \n1 for  i D 1 to n / / compute entries in each of n rows \n2 for  j D 1 to n / / compute n entries in row i \n3 for  k D 1 to n \n4 c ij D c ij C a ik  \ue001 b kj  / / add  in another  term  of equation  (4.1)  \nThe pseudocode for M ATRIX-MULTIPLY works as follows. The for  loop of \nlines  134  computes  the  entries  of each  row  i , and within a given row i , the for  loop \nof lines  234  computes  each  of the  entries  c ij for each column j . Each iteration of \nthe for  loop  of lines  334  adds  in one  more  term  of equation  (4.1).  \nBecause each of the triply nested for  loops runs for exactly n iterations, and \neach  execution  of line  4 takes  constant  time,  the  MATRIX-MULTIPLY procedure \noperates in \u201a.n  3 / time. Even if we add in the \u201a.n  2 / time for initializing C to 0, \nthe running time is still \u201a.n  3 /. \nA simple  divide-and-conquer  algorithm  \nLet\u2019s  see  how  to compute  the  matrix  product  A \ue001 B using  divide-and-conquer.  For  \nn>1 , the divide step partitions the n \ue005 n matrices into four n=2  \ue005 n=2  submatrices. \nWe\u2019ll  assume  that  n is an exact power of 2, so that as the algorithm recurses, we \nare guaranteed that the submatrix dimensions are in teger. (Exercise  4.1-1  asks  you  82  Chapter  4 Divide-and-Conquer  \nto relax this assumption.) As with M ATRIX-MULTIPLY, we\u2019ll  actually  compute  \nC D C C A \ue001 B . But  to simplify  the  math  behind  the  algorithm,  let\u2019s  assume  that C \nhas been initialized to the zero matrix, so that we  are indeed computing C D A \ue001 B . \nThe divide step views each of the n \ue005 n matrices A, B , and C as four n=2  \ue005 n=2  \nsubmatrices: \nA D \u00ce A 11  A 12  \nA 21  A 22  \u00cf \n; B  D \u00ce B 11  B 12  \nB 21  B 22  \u00cf \n; C  D \u00ce C 11  C 12  \nC 21  C 22  \u00cf \n: (4.2)  \nThen we can write the matrix product as \n\u00ce C 11  C 12  \nC 21  C 22  \u00cf \nD \u00ce A 11  A 12  \nA 21  A 22  \u00cf\u00ce  B 11  B 12  \nB 21  B 22  \u00cf \n(4.3)  \nD \u00ce A 11  \ue001 B 11  C A 12  \ue001 B 21  A 11  \ue001 B 12  C A 12  \ue001 B 22  \nA 21  \ue001 B 11  C A 22  \ue001 B 21  A 21  \ue001 B 12  C A 22  \ue001 B 22  \u00cf \n; (4.4)  \nwhich corresponds to the equations \nC 11  D A 11  \ue001 B 11  C A 12  \ue001 B 21  ; (4.5)  \nC 12  D A 11  \ue001 B 12  C A 12  \ue001 B 22  ; (4.6)  \nC 21  D A 21  \ue001 B 11  C A 22  \ue001 B 21  ; (4.7)  \nC 22  D A 21  \ue001 B 12  C A 22  \ue001 B 22  : (4.8)  \nEquations  (4.5)3(4.8)  involve  eight  n=2  \ue005 n=2  multiplications and four additions \nof n=2  \ue005 n=2  submatrices. \nAs we look to transform these equations to an algor ithm that can be described \nwith pseudocode, or even implemented for real, ther e are two common approaches \nfor implementing the matrix partitioning. \nOne  strategy  is to allocate  temporary  storage  to hold  A\u2019s four  submatrices  A 11  , \nA 12  , A 21  , and A 22  and B \u2019s four  submatrices  B 11  , B 12  , B 21  , and B 22  . Then copy \neach element in A and B to its corresponding location in the appropriate su bmatrix. \nAfter the recursive conquer step, copy the elements  in each of C \u2019s four  submatrices  \nC 11  , C 12  , C 21  , and C 22  to their corresponding locations in C . This approach takes \n\u201a.n  2 / time, since 3n  2 elements are copied. \nThe second approach uses index calculations and is faster and more practical. A \nsubmatrix  can  be speci\u00fbed  within  a matrix  by  indicating  wher e within the matrix \nthe submatrix lies without touching any matrix elem ents. Partitioning a matrix \n(or recursively, a submatrix) only involves arithme tic on this location information, \nwhich has constant size independent of the size of the matrix. Changes to the \nsubmatrix elements update the original matrix, sinc e they occupy the same storage. \nGoing  forward,  we\u2019ll  assume  that  index  calculations  are  used  and  that  partition-  \ning can be performed in \u201a.1/  time.  Exercise  4.1-3  asks  you  to show  that  it makes  \nno difference to the overall asymptotic running tim e of matrix multiplication,  how-  \never,  whether  the  partitioning  of matrices  uses  the  \u00fbrst  method of copying or the 4.1  Multiplying  square  matrices  83 \nsecond  method  of index  calculation.  But  for  other  divide-and-conquer  matrix  cal-  \nculations, such as matrix addition, it can make a d ifference, as Exercise  4.1-4  asks  \nyou to show. \nThe procedure M ATRIX-MULTIPLY-RECURSIVE uses  equations  (4.5)3(4.8)  to \nimplement  a divide-and-conquer  strategy  for  square-matri x multiplication. Like \nMATRIX-MULTIPLY , the procedure M ATRIX-MULTIPLY-RECURSIVE computes \nC D C C A \ue001 B since, if necessary, C can be initialized to 0 before the procedure \nis called in order to compute only C D A \ue001 B . \nMATRIX-MULTIPLY-RECURSIVE .A;B;C;n/  \n1 if n == 1 \n2 / / Base case. \n3 c 11  D c 11  C a 11  \ue001 b 11  \n4 return  \n5 / / Divide. \n6 partition A, B , and C into n=2  \ue005 n=2  submatrices \nA 11  ;A  12  ;A  21  ;A  22  ; B 11  ;B  12  ;B  21  ;B  22  ; \nand C 11  ;C  12  ;C  21  ;C  22  ; respectively \n7 / / Conquer. \n8 MATRIX-MULTIPLY-RECURSIVE .A  11  ;B  11  ;C  11  ;n=2/  \n9 MATRIX-MULTIPLY-RECURSIVE .A  11  ;B  12  ;C  12  ;n=2/  \n10  MATRIX-MULTIPLY-RECURSIVE .A  21  ;B  11  ;C  21  ;n=2/  \n11  MATRIX-MULTIPLY-RECURSIVE .A  21  ;B  12  ;C  22  ;n=2/  \n12  MATRIX-MULTIPLY-RECURSIVE .A  12  ;B  21  ;C  11  ;n=2/  \n13  MATRIX-MULTIPLY-RECURSIVE .A  12  ;B  22  ;C  12  ;n=2/  \n14  MATRIX-MULTIPLY-RECURSIVE .A  22  ;B  21  ;C  21  ;n=2/  \n15  MATRIX-MULTIPLY-RECURSIVE .A  22  ;B  22  ;C  22  ;n=2/  \nAs  we  walk  through  the  pseudocode,  we\u2019ll  derive  a recurrence  to characterize \nits running time. Let T.n/  be the  worst-case  time  to multiply  two  n \ue005 n matrices \nusing this procedure. \nIn the base case, when n D 1, line  3 performs  just  the  one  scalar  multiplica-  \ntion and one addition, which means that T.1/  D \u201a.1/ . As is our convention for \nconstant base cases, we can omit this base case in the statement of the recurrence. \nThe recursive case occurs when n>1. As  discussed,  we\u2019ll  use  index  calcula-  \ntions  to partition  the  matrices  in line  6, taking  \u201a.1/  time.  Lines  8315  recursively  \ncall M ATRIX-MULTIPLY-RECURSIVE a total  of eight  times.  The  \u00fbrst  four  recur-  \nsive  calls  compute  the  \u00fbrst  terms  of equations  (4.5)3(4.8),  and the subsequent four \nrecursive calls compute and add in the second terms . Each recursive call adds the \nproduct of a submatrix of A and a submatrix of B to the appropriate submatrix 84  Chapter  4 Divide-and-Conquer  \nof C in place, thanks to index calculations. Because eac h recursive call multiplies \ntwo n=2  \ue005 n=2  matrices, thereby contributing T.n=2/  to the overall running time, \nthe time taken by all eight recursive calls is 8T.n=2/ . There is no combine step, \nbecause the matrix C is updated in place. The total time for the recursi ve case, \ntherefore, is the sum of the partitioning time and the time for all the recursive calls, \nor \u201a.1/  C 8T.n=2/ . \nThus, omitting the statement of the base case, our recurrence for the running \ntime of M ATRIX-MULTIPLY-RECURSIVE is \nT.n/  D 8T.n=2/  C \u201a.1/:  (4.9)  \nAs  we\u2019ll  see  from  the  master  method  in Section  4.5,  recurrence  (4.9)  has  the  solu-  \ntion T.n/  D \u201a.n  3 /, which means that it has the same asymptotic runni ng time as \nthe straightforward M ATRIX-MULTIPLY procedure. \nWhy is the \u201a.n  3 / solution to this recurrence so much larger than the  \u201a.n  lg n/ \nsolution  to the  merge-sort  recurrence  (2.3)  on  page  41?  After all, the recurrence \nfor merge sort contains a \u201a.n/  term, whereas the recurrence for recursive matrix \nmultiplication contains only a \u201a.1/  term. \nLet\u2019s  think  about  what  the  recursion  tree  for  recurrence  (4.9) would look like \nas compared with the recursion tree for merge sort,  illustrated  in Figure  2.5  on  \npage  43.  The  factor  of 2 in the  merge-sort  recurrence  determines  how  many  chil-  \ndren each tree node has, which in turn determines h ow many terms contribute to the \nsum at each level of the tree. In comparison, for t he recurrence (4.9)  for  MATRIX- \nMULTIPLY-RECURSIVE , each internal node in the recursion tree has eigh t children, \nnot two, leading to a <bushier= recursion tree with  many more leaves, despite the \nfact that the internal nodes are each much smaller.  Consequently, the solution to \nrecurrence  (4.9)  grows  much  more  quickly  than  the  solution  to recurrence  (2.3),  \nwhich is borne out in the actual solutions: \u201a.n  3 / versus \u201a.n  lg n/. \nExercises  \nNote: You  may  wish  to read  Section  4.5  before  attempting  some  of these exercises. \n4.1-1  \nGeneralize  MATRIX-MULTIPLY-RECURSIVE to multiply n \ue005 n matrices for which \nn is not necessarily an exact power of 2. Give  a recurrence  describing  its  running  \ntime. Argue that it runs in \u201a.n  3 / time in the worst case. \n4.1-2  \nHow quickly can you multiply a kn  \ue005 n matrix (kn  rows and n columns) by an \nn \ue005 kn  matrix, where k \ue004 1, using M ATRIX-MULTIPLY-RECURSIVE as a subrou-  \ntine?  Answer  the  same  question  for  multiplying  an n \ue005 kn  matrix by a kn  \ue005 n \nmatrix.  Which  is asymptotically  faster,  and  by  how  much?  4.2  Strassen\u2019s  algorithm  for  matrix  multiplication  85 \n4.1-3  \nSuppose that instead of partitioning matrices by in dex calculation in M ATRIX- \nMULTIPLY-RECURSIVE , you copy the appropriate elements of A, B , and C into \nseparate n=2  \ue005 n=2  submatrices A 11  , A 12  , A 21  , A 22  ; B 11  , B 12  , B 21  , B 22  ; and C 11  , \nC 12  , C 21  , C 22  , respectively. After the recursive calls, you copy  the results from C 11  , \nC 12  , C 21  , and C 22  back into the appropriate places in C . How  does  recurrence  (4.9)  \nchange,  and  what  is its  solution?  \n4.1-4  \nWrite  pseudocode  for  a divide-and-conquer  algorithm  MATRIX-ADD-RECURSIVE \nthat sums two n \ue005 n matrices A and B by partitioning each of them into four \nn=2  \ue005 n=2  submatrices and then recursively summing correspond ing pairs  of sub-  \nmatrices. Assume that matrix partitioning uses \u201a.1/-time  index  calculations.  \nWrite  a recurrence  for  the  worst-case  running  time  of MATRIX-ADD-RECURSIVE , \nand solve your recurrence. What happens if you use \u201a.n  2 /-time  copying  to imple-  \nment  the  partitioning  instead  of index  calculations?  \n4.2  Strassen\u2019s  algorithm  for  matrix  multiplication  \nYou  might  \u00fbnd  it hard  to imagine  that  any  matrix  multiplicati on algorithm could \ntake less than \u201a.n  3 / time,  since  the  natural  de\u00fbnition  of matrix  multiplication  re-  \nquires n 3 scalar multiplications. Indeed, many mathematicians  presumed that it \nwas not possible to multiply matrices in o.n  3 / time  until  1969,  when  V. Strassen  \n[424]  published  a remarkable  recursive  algorithm  for  multi plying n \ue005 n matrices. \nStrassen\u2019s  algorithm  runs  in \u201a.n  lg 7 / time. Since lg 7 D 2:8073549:::  , Strassen\u2019s  \nalgorithm runs in O.n  2:81  / time, which is asymptotically better than the \u201a.n  3 / \nMATRIX-MULTIPLY and M ATRIX-MULTIPLY-RECURSIVE procedures. \nThe  key  to Strassen\u2019s  method  is to use  the  divide-and-conque r idea from the \nMATRIX-MULTIPLY-RECURSIVE procedure, but make the recursion tree less \nbushy.  We\u2019ll  actually  increase  the  work  for  each  divide  and  combine step by a \nconstant factor, but the reduction in bushiness wil l pay off. We  won\u2019t  reduce  the  \nbushiness  from  the  eight-way  branching  of recurrence  (4.9)  all the way down to \nthe  two-way  branching  of recurrence  (2.3),  but  we\u2019ll  improv e it just a little, and \nthat will make a big difference. Instead of perform ing eight recursive  multiplica-  \ntions of n=2  \ue005 n=2  matrices,  Strassen\u2019s  algorithm  performs  only  seven.  The  cost \nof eliminating one matrix multiplication is several  new additions and subtractions \nof n=2  \ue005 n=2  matrices, but still only a constant number. Rather than saying  <addi-  \ntions  and  subtractions=  everywhere,  we\u2019ll  adopt  the  common  terminology  of call-  86  Chapter  4 Divide-and-Conquer  \ning them both <additions= because subtraction is st ructurally the same computation \nas addition, except for a change of sign. \nTo get an inkling how the number of multiplications  might be reduced, as well \nas why reducing the number of multiplications might  be desirable  for  matrix  calcu-  \nlations, suppose that you have two numbers x and y , and you want to calculate the \nquantity x 2 \ue003 y 2 . The straightforward calculation requires two mult iplications to \nsquare x and y , followed by one subtraction (which you can think of as a <negative \naddition=).  But  let\u2019s  recall  the  old  algebra  trick  x 2 \ue003 y 2 D x 2 \ue003 xy  C xy  \ue003 y 2 D \nx.x  \ue003 y/  C y.x  \ue003 y/  D .x C y/.x  \ue003 y/. Using this formulation of the desired \nquantity, you could instead compute the sum x C y and the difference x \ue003 y and \nthen multiply them, requiring only a single multipl ication and two additions. At \nthe cost of an extra addition, only one multiplicat ion is needed  to compute  an ex-  \npression that looks as if it requires two. If x and y are  scalars,  there\u2019s  not  much  \ndifference: both approaches require three scalar op erations. If x and y are large \nmatrices, however, the cost of multiplying outweigh s the cost of adding, in which \ncase  the  second  method  outperforms  the  \u00fbrst,  although  not  asymptotically. \nStrassen\u2019s  strategy  for  reducing  the  number  of matrix  multiplications  at the  ex-  \npense  of more  matrix  additions  is not  at all  obvious4perhaps  the  biggest  under-  \nstatement in this book! As with M ATRIX-MULTIPLY-RECURSIVE, Strassen\u2019s  al-  \ngorithm  uses  the  divide-and-conquer  method  to compute  C D C C A \ue001 B , where \nA, B , and C are all n \ue005 n matrices and n is an exact power of 2. Strassen\u2019s  algo-  \nrithm computes the four submatrices C 11  , C 12  , C 21  , and C 22  of C from equations \n(4.5)3(4.8)  on  page  82  in four  steps.  We\u2019ll  analyze  costs  as we go along to develop \na recurrence T.n/  for  the  overall  running  time.  Let\u2019s  see  how  it works:  \n1. If n D 1, the matrices each contain a single element. Perfo rm a single scalar \nmultiplication  and  a single  scalar  addition,  as in line  3 of MATRIX-MULTIPLY- \nRECURSIVE , taking \u201a.1/  time,  and  return.  Otherwise,  partition  the  input  ma-  \ntrices A and B and output matrix C into n=2  \ue005 n=2  submatrices,  as in equa-  \ntion  (4.2).  This  step  takes  \u201a.1/  time by index calculation, just as in M ATRIX- \nMULTIPLY-RECURSIVE . \n2. Create n=2  \ue005 n=2  matrices S 1 ;S  2 ;:::;S  10  , each  of which  is the  sum  or dif-  \nference  of two  submatrices  from  step  1. Create  and  zero  the  entries of seven \nn=2  \ue005 n=2  matrices P 1 ;P  2 ;:::;P  7 to hold seven n=2  \ue005 n=2  matrix products. \nAll 17  matrices can be created, and the P i initialized, in \u201a.n  2 / time. \n3. Using  the  submatrices  from  step  1 and  the  matrices  S 1 ;S  2 ;:::;S  10  created in \nstep 2, recursively compute each of the seven matri x products P 1 ;P  2 ;:::;P  7 , \ntaking 7T.n=2/  time. \n4. Update  the  four  submatrices  C 11  ;C  12  ;C  21  ;C  22  of the result matrix C by adding \nor subtracting various P i matrices, which takes \u201a.n  2 / time. 4.2  Strassen\u2019s  algorithm  for  matrix  multiplication  87 \nWe\u2019ll  see  the  details  of steps  234  in a moment,  but  we  already  have enough \ninformation to set up a recurrence for the running time of Strassen\u2019s  method.  As  is \ncommon,  the  base  case  in step  1 takes  \u201a.1/  time,  which  we\u2019ll  omit  when  stating  \nthe recurrence. When n > 1, steps  1, 2, and  4 take  a total  of \u201a.n  2 / time, and \nstep  3 requires  seven  multiplications  of n=2  \ue005 n=2  matrices. Hence, we obtain the \nfollowing  recurrence  for  the  running  time  of Strassen\u2019s  algorithm: \nT.n/  D 7T.n=2/  C \u201a.n  2 /: (4.10)  \nCompared with M ATRIX-MULTIPLY-RECURSIVE, we  have  traded  off  one  recur-  \nsive submatrix multiplication for a constant number  of submatrix  additions.  Once  \nyou  understand  recurrences  and  their  solutions,  you\u2019ll  be able  to see  why  this  trade-  \noff actually leads to a lower asymptotic running ti me. By the master  method  in Sec-  \ntion  4.5,  recurrence  (4.10)  has  the  solution  T.n/  D \u201a.n  lg 7 / D O.n  2:81  /, beating \nthe \u201a.n  3 /-time  algorithms.  \nNow,  let\u2019s  delve  into  the  details.  Step  2 creates  the  followi ng 10  matrices: \nS 1 D B 12  \ue003 B 22  ; \nS 2 D A 11  C A 12  ; \nS 3 D A 21  C A 22  ; \nS 4 D B 21  \ue003 B 11  ; \nS 5 D A 11  C A 22  ; \nS 6 D B 11  C B 22  ; \nS 7 D A 12  \ue003 A 22  ; \nS 8 D B 21  C B 22  ; \nS 9 D A 11  \ue003 A 21  ; \nS 10  D B 11  C B 12  : \nThis step adds or subtracts n=2  \ue005 n=2  matrices 10  times, taking \u201a.n  2 / time. \nStep  3 recursively  multiplies  n=2  \ue005 n=2  matrices 7 times  to compute  the  follow-  \ning n=2  \ue005 n=2  matrices, each of which is the sum or difference of  products of A \nand B submatrices: \nP 1 D A 11  \ue001 S 1 .D A 11  \ue001 B 12  \ue003 A 11  \ue001 B 22  /; \nP 2 D S 2 \ue001 B 22  .D A 11  \ue001 B 22  C A 12  \ue001 B 22  /; \nP 3 D S 3 \ue001 B 11  .D A 21  \ue001 B 11  C A 22  \ue001 B 11  /; \nP 4 D A 22  \ue001 S 4 .D A 22  \ue001 B 21  \ue003 A 22  \ue001 B 11  /; \nP 5 D S 5 \ue001 S 6 .D A 11  \ue001 B 11  C A 11  \ue001 B 22  C A 22  \ue001 B 11  C A 22  \ue001 B 22  /; \nP 6 D S 7 \ue001 S 8 .D A 12  \ue001 B 21  C A 12  \ue001 B 22  \ue003 A 22  \ue001 B 21  \ue003 A 22  \ue001 B 22  /; \nP 7 D S 9 \ue001 S 10  .D A 11  \ue001 B 11  C A 11  \ue001 B 12  \ue003 A 21  \ue001 B 11  \ue003 A 21  \ue001 B 12  /: 88  Chapter  4 Divide-and-Conquer  \nThe only multiplications that the algorithm perform s are those  in the  middle  col-  \numn  of these  equations.  The  right-hand  column  just  shows  what these products \nequal  in terms  of the  original  submatrices  created  in step  1, but the terms are never \nexplicitly calculated by the algorithm. \nStep  4 adds  to and  subtracts  from  the  four  n=2  \ue005 n=2  submatrices  of the  prod-  \nuct C the various P i matrices  created  in step  3. We  start  with  \nC 11  D C 11  C P 5 C P 4 \ue003 P 2 C P 6 : \nExpanding  the  calculation  on  the  right-hand  side,  with  the  expansion of each P i \non its own line and vertically aligning terms that cancel out, we see that the update \nto C 11  equals \nA 11  \ue001 B 11  C A 11  \ue001 B 22  C A 22  \ue001 B 11  C A 22  \ue001 B 22  \n\ue003 A 22  \ue001 B 11  C A 22  \ue001 B 21  \n\ue003 A 11  \ue001 B 22  \ue003 A 12  \ue001 B 22  \n\ue003 A 22  \ue001 B 22  \ue003 A 22  \ue001 B 21  C A 12  \ue001 B 22  C A 12  \ue001 B 21  \nA 11  \ue001 B 11  C A 12  \ue001 B 21  ; \nwhich  corresponds  to equation  (4.5).  Similarly,  setting  \nC 12  D C 12  C P 1 C P 2 \nmeans that the update to C 12  equals \nA 11  \ue001 B 12  \ue003 A 11  \ue001 B 22  \nC A 11  \ue001 B 22  C A 12  \ue001 B 22  \nA 11  \ue001 B 12  C A 12  \ue001 B 22  ; \ncorresponding  to equation  (4.6).  Setting  \nC 21  D C 21  C P 3 C P 4 \nmeans that the update to C 21  equals \nA 21  \ue001 B 11  C A 22  \ue001 B 11  \n\ue003 A 22  \ue001 B 11  C A 22  \ue001 B 21  \nA 21  \ue001 B 11  C A 22  \ue001 B 21  ; \ncorresponding  to equation  (4.7).  Finally,  setting  \nC 22  D C 22  C P 5 C P 1 \ue003 P 3 \ue003 P 7 \nmeans that the update to C 22  equals 4.2  Strassen\u2019s  algorithm  for  matrix  multiplication  89 \nA 11  \ue001 B 11  C A 11  \ue001 B 22  C A 22  \ue001 B 11  C A 22  \ue001 B 22  \n\ue003 A 11  \ue001 B 22  C A 11  \ue001 B 12  \n\ue003 A 22  \ue001 B 11  \ue003 A 21  \ue001 B 11  \n\ue003 A 11  \ue001 B 11  \ue003 A 11  \ue001 B 12  C A 21  \ue001 B 11  C A 21  \ue001 B 12  \nA 22  \ue001 B 22  C A 21  \ue001 B 12  ; \nwhich  corresponds  to equation  (4.8).  Altogether,  since  we  add or subtract n=2\ue005n=2  \nmatrices  12  times  in step  4, this  step  indeed  takes  \u201a.n  2 / time. \nWe  can  see  that  Strassen\u2019s  remarkable  algorithm,  comprising  steps  134,  pro-  \nduces the correct matrix product using 7 submatrix multiplications and 18  subma-  \ntrix  additions.  We  can  also  see  that  recurrence  (4.10)  chara cterizes its running time. \nSince  Section  4.5  shows  that  this  recurrence  has  the  solutio n T.n/  D \u201a.n  lg 7 / D \no.n  3 /, Strassen\u2019s  method  asymptotically  beats  the  \u201a.n  3 / MATRIX-MULTIPLY and \nMATRIX-MULTIPLY-RECURSIVE procedures. \nExercises  \nNote: You  may  wish  to read  Section  4.5  before  attempting  some  of these exercises. \n4.2-1  \nUse  Strassen\u2019s  algorithm  to compute  the  matrix  product  \n\u00ce 1 3  \n7 5  \u00cf\u00ce  6 8  \n4 2  \u00cf \n: \nShow your work. \n4.2-2  \nWrite  pseudocode  for  Strassen\u2019s  algorithm.  \n4.2-3  \nWhat is the largest k such that if you can multiply 3 \ue005 3 matrices using k multi-  \nplications (not assuming commutativity of multiplic ation), then you can multiply \nn \ue005 n matrices in o.n  lg 7 / time?  What  is the  running  time  of this  algorithm?  \n4.2-4  \nV . Pan discovered a way of multiplying 68  \ue005 68  matrices  using  132,464  multi-  \nplications, a way of multiplying 70  \ue005 70  matrices  using  143,640  multiplications,  \nand a way of multiplying 72  \ue005 72  matrices  using  155,424  multiplications.  Which  \nmethod yields the best asymptotic running time when  used in a divide-and-conquer  \nmatrix-multiplication  algorithm?  How  does  it compare  with  Strassen\u2019s  algorithm?  90  Chapter  4 Divide-and-Conquer  \n4.2-5  \nShow how to multiply the complex numbers a C bi and c C di  using only three \nmultiplications of real numbers. The algorithm shou ld take a, b, c , and d as input \nand produce the real component ac  \ue003 bd  and the imaginary component ad  C bc  \nseparately. \n4.2-6  \nSuppose that you have a \u201a.n  \u02db /-time  algorithm  for  squaring  n \ue005 n matrices, where \n\u02db \ue004 2. Show how to use that algorithm to multiply two di fferent n \ue005 n matrices in \n\u201a.n  \u02db / time. \n4.3  The  substitution  method  for  solving  recurrences  \nNow that you have seen how recurrences characterize  the running  times  of divide-  \nand-conquer  algorithms,  let\u2019s  learn  how  to solve  them.  We  start in this section \nwith the substitution  method , which is the most general of the four methods in this \nchapter. The substitution method comprises two step s: \n1. Guess  the  form  of the  solution  using  symbolic  constants.  \n2. Use mathematical induction to show that the solu tion works, and  \u00fbnd  the  con-  \nstants. \nTo apply the inductive hypothesis, you substitute t he guessed solution  for  the  func-  \ntion  on  smaller  values4hence  the  name  <substitution  method .= This method is \npowerful, but you must guess the form of the answer . Although generating a good \nguess  might  seem  dif\u00fbcult,  a little  practice  can  quickly  improve your intuition. \nYou can use the substitution method to establish ei ther an upper or a lower bound \non  a recurrence.  It\u2019s  usually  best  not  to try  to do  both  at the  same time. That is, \nrather than trying to prove a \u201a-bound  directly,  \u00fbrst  prove  an O-bound,  and  then  \nprove an \ufffd-bound.  Together,  they  give  you  a \u201a-bound  (Theorem  3.1  on  page  56).  \nAs  an example  of the  substitution  method,  let\u2019s  determine  an asymptotic upper \nbound on the recurrence: \nT.n/  D 2T.bn=2c/ C \u201a.n/:  (4.11)  \nThis  recurrence  is similar  to recurrence  (2.3)  on  page  41  for  merge sort, except \nfor  the  \u00fcoor  function,  which  ensures  that  T.n/  is de\u00fbned  over  the  integers.  Let\u2019s  \nguess  that  the  asymptotic  upper  bound  is the  same4T.n/  D O.n  lg n/4and  use  \nthe substitution method to prove it. \nWe\u2019ll  adopt  the  inductive  hypothesis  that  T.n/  \u0dc4 cn  lg n for all n \ue004 n 0 , where \nwe\u2019ll  choose  the  speci\u00fbc  constants  c > 0  and n 0 > 0  later, after we see what 4.3  The  substitution  method  for  solving  recurrences  91 \nconstraints they need to obey. If we can establish this inductive hypothesis, we can \nconclude that T.n/  D O.n  lg n/. It would be dangerous to use T.n/  D O.n  lg n/ \nas the inductive hypothesis because the constants m atter, as we\u2019ll  see  in a moment  \nin our discussion of pitfalls. \nAssume by induction that this bound holds for all n umbers at least as big as n 0 \nand less than n. In particular, therefore, if n \ue004 2n  0 , it holds for bn=2c, yielding \nT.bn=2c/ \u0dc4 c bn=2c lg.bn=2c/. Substituting  into  recurrence  (4.11)4hence  the  \nname  <substitution=  method4yields  \nT.n/  \u0dc4 2.c  bn=2c lg.bn=2c// C \u201a.n/  \n\u0dc4 2.c.n=2/  lg.n=2//  C \u201a.n/  \nD cn  lg.n=2/  C \u201a.n/  \nD cn  lg n \ue003 cn  lg 2 C \u201a.n/  \nD cn  lg n \ue003 cn  C \u201a.n/  \n\u0dc4 cn  lg n;  \nwhere the last step holds if we constrain the const ants n 0 and c to be suf\u00fbciently  \nlarge that for n \ue004 2n  0 , the quantity cn  dominates the anonymous function hidden \nby the \u201a.n/  term. \nWe\u2019ve  shown  that  the  inductive  hypothesis  holds  for  the  inductive case, but we \nalso need to prove that the inductive hypothesis ho lds for the base cases of the \ninduction, that is, that T.n/  \u0dc4 cn  lg n when n 0 \u0dc4 n<2n  0 . As long as n 0 >1  (a \nnew constraint on n 0 ), we have lg n >0 , which implies that n lg n >0. So  let\u2019s  \npick n 0 D 2. Since  the  base  case  of recurrence  (4.11)  is not  stated  expli citly, by our \nconvention, T.n/  is algorithmic, which means that T.2/  and T.3/  are constant (as \nthey  should  be if they  describe  the  worst-case  running  time  of any real program on \ninputs of size 2 or 3). Picking c D max fT.2/;T.3/ g yields T.2/  \u0dc4 c<.2  lg 2/c  \nand T.3/  \u0dc4 c<.3  lg 3/c  , establishing the inductive hypothesis for the bas e cases. \nThus, we have T.n/  \u0dc4 cn  lg n for all n \ue004 2, which implies that the solution to \nrecurrence  (4.11)  is T.n/  D O.n  lg n/. \nIn the algorithms literature, people rarely carry o ut their substitution proofs to \nthis level of detail, especially in their treatment  of base cases. The reason is that for \nmost  algorithmic  divide-and-conquer  recurrences,  the  base cases are all handled in \npretty much the same way. You ground the induction on a range of values from a \nconvenient positive constant n 0 up to some constant n 0 \n0 >n  0 such that for n \ue004 n 0 \n0 , \nthe  recurrence  always  bottoms  out  in a constant-sized  base  case between n 0 and n 0 \n0 . \n(This example used n 0 \n0 D 2n  0 .) Then,  it\u2019s  usually  apparent,  without  spelling  out  \nthe details, that with a suitably large choice of t he leading constant (such as c for \nthis example), the inductive hypothesis can be made  to hold for all the values in the \nrange from n 0 to n 0 \n0 . 92  Chapter  4 Divide-and-Conquer  \nMaking  a good  guess  \nUnfortunately, there is no general way to correctly  guess the tightest asymptotic \nsolution to an arbitrary recurrence. Making a good guess takes experience and, \noccasionally, creativity. Fortunately, learning som e recurrence-solving  heuristics,  \nas well as playing around with recurrences to gain experience, can help you become \na good  guesser.  You  can  also  use  recursion  trees,  which  we\u2019ll  see  in Section  4.4,  to \nhelp generate good guesses. \nIf a recurrence  is similar  to one  you\u2019ve  seen  before,  then  guessing a similar \nsolution is reasonable. As an example, consider the  recurrence \nT.n/  D 2T.n=2  C 17/  C \u201a.n/;  \nde\u00fbned  on  the  reals.  This  recurrence  looks  somewhat  like  the  merge-sort  recur-  \nrence  (2.3),  but  it\u2019s  more  complicated  because  of the  added  <17= in the argument \nto T on  the  right-hand  side.  Intuitively,  however,  this  additional  term  shouldn\u2019t  \nsubstantially affect the solution to the recurrence . When n is large, the relative \ndifference between n=2  and n=2  C 17  is not that large: both cut n nearly in half. \nConsequently, it makes sense to guess that T.n/  D O.n  lg n/, which you can verify \nis correct  using  the  substitution  method  (see  Exercise  4.3-1).  \nAnother way to make a good guess is to determine lo ose upper and lower bounds \non the recurrence and then reduce your range of unc ertainty. For example, you \nmight start with a lower bound of T.n/  D \ufffd.n/  for  recurrence  (4.11),  since  the  \nrecurrence includes the term \u201a.n/ , and you can prove an initial upper bound of \nT.n/  D O.n  2 /. Then split your time between trying to lower the upper bound and \ntrying to raise the lower bound until you converge on the correct, asymptotically \ntight solution, which in this case is T.n/  D \u201a.n  lg n/. \nA trick  of the  trade:  subtracting  a low-order  term  \nSometimes, you might correctly guess a tight asympt otic bound on the solution \nof a recurrence, but somehow the math fails to work  out in the induction proof. \nThe problem frequently turns out to be that the ind uctive assumption is not strong \nenough. The trick to resolving this problem is to r evise your guess by subtracting  \na lower-order  term  when  you  hit  such  a snag.  The  math  then  often goes through. \nConsider the recurrence \nT.n/  D 2T.n=2/  C \u201a.1/  (4.12)  \nde\u00fbned  on  the  reals.  Let\u2019s  guess  that  the  solution  is T.n/  D O.n/  and try to show \nthat T.n/  \u0dc4 cn  for n \ue004 n 0 , where we choose the constants c;n  0 > 0  suitably. \nSubstituting our guess into the recurrence, we obta in \nT.n/  \u0dc4 2.c.n=2//  C \u201a.1/  \nD cn  C \u201a.1/;  4.3  The  substitution  method  for  solving  recurrences  93 \nwhich, unfortunately, does not imply that T.n/  \u0dc4 cn  for any  choice of c . We might \nbe tempted to try a larger guess, say T.n/  D O.n  2 /. Although this larger guess \nworks, it provides only a loose upper bound. It tur ns out that our original guess of \nT.n/  D O.n/  is correct and tight. In order to show that it is c orrect, however, we \nmust strengthen our inductive hypothesis. \nIntuitively, our guess is nearly right: we are off only by \u201a.1/, a lower-order  \nterm. Nevertheless, mathematical induction requires  us to prove the exact  form of \nthe  inductive  hypothesis.  Let\u2019s  try  our  trick  of subtracting  a lower-order  term  from  \nour previous guess: T.n/  \u0dc4 cn  \ue003 d , where d \ue004 0 is a constant. We now have \nT.n/  \u0dc4 2.c.n=2/  \ue003 d/  C \u201a.1/  \nD cn  \ue003 2d  C \u201a.1/  \n\u0dc4 cn  \ue003 d \ue003 .d \ue003 \u201a.1//  \n\u0dc4 cn  \ue003 d \nas long as we choose d to be larger  than  the  anonymous  upper-bound  constant  \nhidden by the \u201a-notation.  Subtracting  a lower-order  term  works!  Of  course , we \nmust not forget to handle the base case, which is t o choose the constant c large \nenough that cn  \ue003 d dominates the implicit base cases. \nYou  might  \u00fbnd  the  idea  of subtracting  a lower-order  term  to be counterintuitive. \nAfter  all,  if the  math  doesn\u2019t  work  out,  shouldn\u2019t  you  increase  your  guess?  Not  \nnecessarily! When the recurrence contains more than  one recursive invocation \n(recurrence  (4.12)  contains  two),  if you  add  a lower-order  term to the guess, then \nyou end up adding it once for each of the recursive  invocations. Doing so takes \nyou  even  further  away  from  the  inductive  hypothesis.  On  the  other hand, if you \nsubtract  a lower-order  term  from  the  guess,  then  you  get  to subtract it once for each \nof the recursive invocations. In the above example,  we subtracted the constant d \ntwice  because  the  coef\u00fbcient  of T.n=2/  is 2. We ended up with the inequality \nT.n/  \u0dc4 cn  \ue003 d \ue003 .d \ue003 \u201a.1// , and we readily found a suitable value for d . \nAvoiding  pitfalls  \nAvoid using asymptotic notation in the inductive hy pothesis for the substitution \nmethod  because  it\u2019s  error  prone.  For  example,  for  recurrence  (4.11),  we  can  falsely  \n<prove= that T.n/  D O.n/  if we unwisely adopt T.n/  D O.n/  as our inductive \nhypothesis: \nT.n/  \u0dc4 2 \ue001 O.bn=2c/ C \u201a.n/  \nD 2 \ue001 O.n/  C \u201a.n/  \nD O.n/:  \u0143  wrong! 94  Chapter  4 Divide-and-Conquer  \nThe problem with this reasoning is that the constan t hidden by the O-notation  \nchanges. We can expose the fallacy by repeating the  <proof= using an explicit \nconstant. For the inductive hypothesis, assume that  T.n/  \u0dc4 cn  for all n \ue004 n 0 , \nwhere c;n  0 >0  are  constants.  Repeating  the  \u00fbrst  two  steps  in the  inequalit y chain \nyields \nT.n/  \u0dc4 2.c  bn=2c/ C \u201a.n/  \n\u0dc4 cn  C \u201a.n/:  \nNow, indeed cnC\u201a.n/  D O.n/ , but the constant hidden by the O-notation  must  be \nlarger than c because the anonymous function hidden by the \u201a.n/  is asymptotically \npositive. We cannot take the third step to conclude  that cn  C \u201a.n/  \u0dc4 cn, thus \nexposing the fallacy. \nWhen using the substitution method, or more general ly mathematical induction, \nyou must be careful that the constants hidden by an y asymptotic notation are the \nsame  constants  throughout  the  proof.  Consequently,  it\u2019s  best to avoid asymptotic \nnotation in your inductive hypothesis and to name c onstants explicitly. \nHere\u2019s  another  fallacious  use  of the  substitution  method  to show that the solution \nto recurrence  (4.11)  is T.n/  D O.n/ . We guess T.n/  \u0dc4 cn  and then argue \nT.n/  \u0dc4 2.c  bn=2c/ C \u201a.n/  \n\u0dc4 cn  C \u201a.n/  \nD O.n/;  \u0143  wrong! \nsince c is a positive constant. The mistake stems from the difference between our \ngoal4to  prove  that  T.n/  D O.n/4and  our  inductive  hypothesis4to  prove  that  \nT.n/  \u0dc4 cn. When using the substitution method, or in any ind uctive proof, you \nmust prove the exact  statement of the inductive hypothesis. In this case , we must \nexplicitly prove that T.n/  \u0dc4 cn  to show that T.n/  D O.n/ . \nExercises  \n4.3-1  \nUse the substitution method to show that each of th e following recurrences  de\u00fbned  \non  the  reals  has  the  asymptotic  solution  speci\u00fbed:  \na. T.n/  D T.n  \ue003 1/ C n has solution T.n/  D O.n  2 /. \nb. T.n/  D T.n=2/  C \u201a.1/  has solution T.n/  D O.lg n/. \nc. T.n/  D 2T.n=2/  C n has solution T.n/  D \u201a.n  lg n/. \nd. T.n/  D 2T.n=2  C 17/  C n has solution T.n/  D O.n  lg n/. \ne. T.n/  D 2T.n=3/  C \u201a.n/  has solution T.n/  D \u201a.n/ . \nf. T.n/  D 4T.n=2/  C \u201a.n/  has solution T.n/  D \u201a.n  2 /. 4.4  The  recursion-tree  method  for  solving  recurrences  95 \n4.3-2  \nThe solution to the recurrence T.n/  D 4T.n=2/  C n turns out to be T.n/  D \u201a.n  2 /. \nShow that a substitution proof with the assumption T.n/  \u0dc4 cn  2 fails. Then show \nhow  to subtract  a lower-order  term  to make  a substitution  proof work. \n4.3-3  \nThe recurrence T.n/  D 2T.n  \ue003 1/ C 1 has the solution T.n/  D O.2  n /. Show that a \nsubstitution proof fails with the assumption T.n/  \u0dc4 c2  n , where c>0  is constant. \nThen  show  how  to subtract  a lower-order  term  to make  a substit ution proof work. \n4.4  The  recursion-tree  method  for  solving  recurrences  \nAlthough you can use the substitution method to pro ve that a solution  to a recur-  \nrence is correct, you might have trouble coming up with a good guess. Drawing \nout  a recursion  tree,  as we  did  in our  analysis  of the  merge-sort  recurrence  in Sec-  \ntion  2.3.2,  can  help.  In a recursion  tree, each node represents the cost of a single \nsubproblem somewhere in the set of recursive functi on invocations. You typically \nsum  the  costs  within  each  level  of the  tree  to obtain  the  per-level costs, and then you \nsum  all  the  per-level  costs  to determine  the  total  cost  of all  levels of the recursion. \nSometimes, however, adding up the total cost takes more creativity. \nA recursion tree is best used to generate intuition  for a good guess, which you \ncan then verify by the substitution method. If you are meticulous when drawing out \na recursion tree and summing the costs, however, yo u can use a recursion tree as a \ndirect proof of a solution to a recurrence. But if you use it only to generate a good \nguess, you can often tolerate a small amount of <sl oppiness,= which can simplify \nthe math. When you verify your guess with the subst itution method later on, your \nmath should be precise. This section demonstrates h ow you can use recursion trees \nto solve recurrences, generate good guesses, and ga in intuition for recurrences. \nAn  illustrative  example  \nLet\u2019s  see  how  a recursion  tree  can  provide  a good  guess  for  an upper-bound  solution  \nto the recurrence \nT.n/  D 3T.n=4/  C \u201a.n  2 /: (4.13)  \nFigure  4.1  shows  how  to derive  the  recursion  tree  for  T.n/  D 3T.n=4/  C cn  2 , \nwhere the constant c >0  is the  upper-bound  constant  in the  \u201a.n  2 / term. Part (a) \nof the  \u00fbgure  shows  T.n/, which  part  (b)  expands  into  an equivalent  tree  represent-  \ning the recurrence. The cn  2 term at the root represents the cost at the top lev el \nof recursion, and the three subtrees of the root re present the costs incurred by the 96  Chapter  4 Divide-and-Conquer  \n\u2026 \n\u2026 \n(d) (c) (b) (a) T.n/  cn  2 cn  2 \ncn  2 T \ue002 n \n4 \u00cd \nT \ue002 n \n4 \u00cd \nT \ue002 n \n4 \u00cd \nT \ue002 n \n16  \u00cd \nT \ue002 n \n16  \u00cd \nT \ue002 n \n16  \u00cd \nT \ue002 n \n16  \u00cd \nT \ue002 n \n16  \u00cd \nT \ue002 n \n16  \u00cd \nT \ue002 n \n16  \u00cd \nT \ue002 n \n16  \u00cd \nT \ue002 n \n16  \u00cd \ncn  2 c \ue002 n \n4 \u00cd 2 \nc \ue002 n \n4 \u00cd 2 \nc \ue002 n \n4 \u00cd 2 \nc \ue002 n \n4 \u00cd 2 \nc \ue002 n \n4 \u00cd 2 \nc \ue002 n \n4 \u00cd 2 \nc \ue002 n \n16  \u00cd 2 \nc \ue002 n \n16  \u00cd 2 \nc \ue002 n \n16  \u00cd 2 \nc \ue002 n \n16  \u00cd 2 \nc \ue002 n \n16  \u00cd 2 \nc \ue002 n \n16  \u00cd 2 \nc \ue002 n \n16  \u00cd 2 \nc \ue002 n \n16  \u00cd 2 \nc \ue002 n \n16  \u00cd 2 3 \n16  cn  2 \n\u00ce 3 \n16  \u00cf 2 \ncn  2 log 4 n \n3 log 4 n D n log 4 3 \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.n  log 4 3 / \nTotal: O.n  2 / \nFigure  4.1  Constructing a recursion tree for the recurrence T.n/  D 3T.n=4/  C cn  2 . Part (a)  \nshows T.n/ , which progressively expands in (b)\u2013(d)  to form the recursion tree. The fully expanded \ntree in (d)  has height log 4 n. 4.4  The  recursion-tree  method  for  solving  recurrences  97 \nsubproblems of size n=4. Part (c) shows this process carried one step furt her by \nexpanding each node with cost T.n=4/  from part (b). The cost for each of the three \nchildren of the root is c.n=4/  2 . We continue expanding each node in the tree by \nbreaking it into its constituent parts as determine d by the recurrence. \nBecause subproblem sizes decrease by a factor of 4 every time we go down one \nlevel, the recursion must eventually bottom out in a base case where n<n  0 . By \nconvention, the base case is T.n/  D \u201a.1/  for n < n  0 , where n 0 > 0  is any \nthreshold  constant  suf\u00fbciently  large  that  the  recurrence  is well  de\u00fbned.  For  the  \npurpose  of intuition,  however,  let\u2019s  simplify  the  math  a little.  Let\u2019s  assume  that  n \nis an exact power of 4 and that the base case is T.1/  D \u201a.1/ . As it turns out, these \nassumptions  don\u2019t  affect  the  asymptotic  solution.  \nWhat\u2019s  the  height  of the  recursion  tree?  The  subproblem  size  for a node at \ndepth i is n=4  i . As we descend the tree from the root, the subprob lem size hits \nn D 1 when n=4  i D 1 or, equivalently, when i D log 4 n. Thus, the tree has \ninternal nodes at depths 0;1;2;:::;  log 4 n \ue003 1 and leaves at depth log 4 n. \nPart  (d)  of Figure  4.1  shows  the  cost  at each  level  of the  tree.  Each level has \nthree times as many nodes as the level above, and s o the number of nodes at \ndepth i is 3 i . Because subproblem sizes reduce by a factor of 4 for each level \nfurther from the root, each internal node at depth i D 0;1;2;:::;  log 4 n \ue003 1 has a \ncost of c.n=4  i / 2 . Multiplying, we see that the total cost of all no des at a given \ndepth i is 3 i c.n=4  i / 2 D .3=16/  i cn  2 . The bottom level, at depth log 4 n, con-  \ntains 3 log 4 n D n log 4 3 leaves  (using  equation  (3.21)  on  page  66).  Each  leaf  con-  \ntributes \u201a.1/ , leading to a total leaf cost of \u201a.n  log 4 3 /. \nNow we add up the costs over all levels to determin e the cost for the entire tree: \nT.n/  D cn  2 C 3 \n16  cn  2 C \u00ce 3 \n16  \u00cf 2 \ncn  2 C \ue001\ue001\ue001 C  \u00ce 3 \n16  \u00cf log 4 n \ncn  2 C \u201a.n  log 4 3 / \nD log 4 n X  \ni D0 \u00ce 3 \n16  \u00cf i \ncn  2 C \u201a.n  log 4 3 / \n< 1  X  \ni D0 \u00ce 3 \n16  \u00cf i \ncn  2 C \u201a.n  log 4 3 / \nD 1 \n1 \ue003 .3=16/  cn  2 C \u201a.n  log 4 3 / (by  equation  (A.7)  on  page  1142)  \nD 16  \n13  cn  2 C \u201a.n  log 4 3 / \nD O.n  2 / (\u201a.n  log 4 3 / D O.n  0:8  / D O.n  2 /) . \nWe\u2019ve  derived  the  guess  of T.n/  D O.n  2 / for  the  original  recurrence.  In this  exam-  \nple,  the  coef\u00fbcients  of cn  2 form  a decreasing  geometric  series.  By  equation  (A.7),  \nthe  sum  of these  coef\u00fbcients  is bounded  from  above  by  the  constant 16=13 . Since 98  Chapter  4 Divide-and-Conquer  \nthe  root\u2019s  contribution  to the  total  cost  is cn  2 , the cost of the root dominates the \ntotal cost of the tree. \nIn fact, if O.n  2 / is indeed  an upper  bound  for  the  recurrence  (as  we\u2019ll  verify  in \na moment),  then  it must  be a tight  bound.  Why?  The  \u00fbrst  recursi ve call contributes \na cost of \u201a.n  2 /, and so \ufffd.n  2 / must be a lower bound for the recurrence. \nLet\u2019s  now  use  the  substitution  method  to verify  that  our  guess is correct, namely, \nthat T.n/  D O.n  2 / is an upper bound for the recurrence T.n/  D 3T.n=4/ C\u201a.n  2 /. \nWe want to show that T.n/  \u0dc4 dn  2 for some constant d > 0 . Using the same \nconstant c>0  as before, we have \nT.n/  \u0dc4 3T.n=4/  C cn  2 \n\u0dc4 3d.n=4/  2 C cn  2 \nD 3 \n16  dn  2 C cn  2 \n\u0dc4 dn  2 ; \nwhere the last step holds if we choose d \ue004 .16=13/c  . \nFor the base case of the induction, let n 0 > 0  be a suf\u00fbciently  large  threshold  \nconstant  that  the  recurrence  is well  de\u00fbned  when  T.n/  D \u201a.1/  for n < n  0 . We \ncan pick d large enough that d dominates the constant hidden by the \u201a, in which \ncase dn  2 \ue004 d \ue004 T.n/  for 1 \u0dc4 n<n  0 , completing the proof of the base case. \nThe substitution proof we just saw involves two nam ed constants, c and d . We \nnamed c and  used  it to stand  for  the  upper-bound  constant  hidden  and  guaranteed to \nexist by the \u201a-notation.  We  cannot  pick  c arbitrarily4it\u2019s  given  to us4although,  \nfor any such c , any constant c 0 \ue004 c also  suf\u00fbces.  We  also  named  d , but we were \nfree  to choose  any  value  for  it that  \u00fbt our  needs.  In this  examp le, the value of d \nhappened to depend on the value of c , which  is \u00fbne,  since  d is constant if c is \nconstant. \nAn  irregular  example  \nLet\u2019s  \u00fbnd  an asymptotic  upper  bound  for  another,  more  irregular,  example.  Fig-  \nure  4.2  shows  the  recursion  tree  for  the  recurrence  \nT.n/  D T.n=3/  C T.2n=3/  C \u201a.n/:  (4.14)  \nThis  recursion  tree  is unbalanced,  with  different  root-to- leaf paths having different \nlengths.  Going  left  at any  node  produces  a subproblem  of one-third the size, and \ngoing  right  produces  a subproblem  of two-thirds  the  size.  Let n 0 >0  be the implicit \nthreshold constant such that T.n/  D \u201a.1/  for 0<n<n  0 , and let c represent the \nupper-bound  constant  hidden  by  the  \u201a.n/  term for n \ue004 n 0 . There are actually two \nn 0 constants  here4one  for  the  threshold  in the  recurrence,  and  the other for the \nthreshold in the \u201a-notation,  so we\u2019ll  let  n 0 be the larger of the two constants. 4.4  The  recursion-tree  method  for  solving  recurrences  99 \u2026 \n\u2026 cn  \ncn  cn  cn  \nc \ue002 n \n3 \u00cd \nc \u00ce 2n  \n3 \u00cf \nc \ue002 n \n9 \u00cd \nc \u00ce 2n  \n9 \u00cf \nc \u00ce 2n  \n9 \u00cf \nc \u00ce 4n  \n9 \u00cf \n\ue00a \nlog 3=2  .n=n  0 / \u00da \nC 1 \nTotal: O.n  lg n/ \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \n\u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \n\u201a.1/  \n\u201a.n/  \nFigure  4.2  A recursion tree for the recurrence T.n/  D T.n=3/  C T.2n=3/  C cn. \nThe height of the tree runs down the right edge of the tree, corresponding  to sub-  \nproblems of sizes n;.2=3/n;.4=9/n;:::;\u201a.1/  with costs bounded by cn;c.2n=3/;  \nc.4n=9/;:::;\u201a.1/ , respectively. We hit the rightmost leaf when .2=3/  h n<n  0 \u0dc4 \n.2=3/  h\ue0021 n, which happens when h D blog 3=2  .n=n  0 /cC  1 since,  applying  the  \u00fcoor  \nbounds  in equation  (3.2)  on  page  64  with  x D log 3=2  .n=n  0 /, we have .2=3/  h n D \n.2=3/  bxcC1 n<.2=3/  x n D .n 0 =n/n  D n 0 and .2=3/  h\ue0021 n D .2=3/  bxc n>.2=3/  x n \nD .n 0 =n/n  D n 0 . Thus, the height of the tree is h D \u201a.lg n/. \nWe\u2019re  now  in a position  to understand  the  upper  bound.  Let\u2019s  postpone dealing \nwith the leaves for a moment. Summing the costs of internal nodes across each \nlevel, we have at most cn  per level times the \u201a.lg n/ tree height for a total cost of \nO.n  lg n/ for all internal nodes. \nIt remains to deal with the leaves of the recursion  tree, which represent base \ncases, each costing \u201a.1/. How  many  leaves  are  there?  It\u2019s  tempting  to upper-  \nbound their number by the number of leaves in a com plete binary tree of height \nh D blog 3=2  .n=n  0 /c C  1, since  the  recursion  tree  is contained  within  such  a com-  \nplete binary tree. But this approach turns out to g ive us a poor bound. The \ncomplete binary tree has 1 node at the root, 2 nodes at depth 1, and  gener-  \nally 2 k nodes at depth k. Since the height is h D b log 3=2  nc C  1, there are 100  Chapter  4 Divide-and-Conquer  \n2 h D 2 blog 3=2  ncC1 \u0dc4 2n  log 3=2  2 leaves in the complete binary tree, which is an \nupper bound on the number of leaves in the recursio n tree. Because the cost of \neach leaf is \u201a.1/ , this analysis says that the total cost of all lea ves in the recursion \ntree is O.n  log 3=2  2 / D O.n  1:71  /, which is an asymptotically greater bound than the  \nO.n  lg n/ cost  of all  internal  nodes.  In fact,  as we\u2019re  about  to see,  this bound is \nnot tight. The cost of all leaves in the recursion tree is O.n/4asymptotically  less \nthan O.n  lg n/. In other words, the cost of the internal nodes do minates the cost of \nthe leaves, not vice versa. \nRather than analyzing the leaves, we could quit rig ht now and prove  by  substi-  \ntution that T.n/  D \u201a.n  lg n/. This  approach  works  (see  Exercise  4.4-3),  but  it\u2019s  \ninstructive to understand how many leaves this recu rsion tree has. You may see \nrecurrences for which the cost of leaves dominates the cost of internal nodes, and \nthen  you\u2019ll  be in better  shape  if you\u2019ve  had  some  experience  analyzing the number \nof leaves. \nTo  \u00fbgure  out  how  many  leaves  there  really  are,  let\u2019s  write  a recurrence L.n/  for \nthe number of leaves in the recursion tree for T.n/ . Since all the leaves in T.n/  \nbelong either to the left subtree or the right subt ree of the root, we have \nL.n/  D ( \n1 if n<n  0 ; \nL.n=3/  C L.2n=3/  if n \ue004 n 0 : (4.15)  \nThis  recurrence  is similar  to recurrence  (4.14),  but  it\u2019s  missing the \u201a.n/  term, and \nit contains an explicit base case. Because this rec urrence omits the \u201a.n/  term, it \nis much  easier  to solve.  Let\u2019s  apply  the  substitution  method  to show that it has \nsolution L.n/  D O.n/ . Using the inductive hypothesis L.n/  \u0dc4 dn  for some \nconstant d > 0 , and assuming that the inductive hypothesis holds for all values \nless than n, we have \nL.n/  D L.n=3/  C L.2n=3/  \n\u0dc4 dn=3  C 2.dn/=3  \n\u0dc4 dn;  \nwhich holds for any d >0 . We can now choose d large enough to handle the base \ncase L.n/  D 1 for 0 < n < n  0 , for which d D 1 suf\u00fbces,  thereby  completing  \nthe substitution method for the upper bound on leav es. (Exercise  4.4-2  asks  you  to \nprove that L.n/  D \u201a.n/ .) \nReturning  to recurrence  (4.14)  for  T.n/ , it now becomes apparent that the total \ncost of leaves over all levels must be L.n/  \ue001 \u201a.1/  D \u201a.n/ . Since we have derived \nthe bound of O.n  lg n/ on the cost of the internal nodes, it follows that the solution \nto recurrence  (4.14)  is T.n/  D O.n  lg n/ C \u201a.n/  D O.n  lg n/. (Exercise  4.4-3  \nasks you to prove that T.n/  D \u201a.n  lg n/.) \nIt\u2019s  wise  to verify  any  bound  obtained  with  a recursion  tree  by  using  the  sub-  \nstitution  method,  especially  if you\u2019ve  made  simplifying  assumptions. But another 4.5  The  master  method  for  solving  recurrences  101 \nstrategy  altogether  is to use  more-powerful  mathematics,  typically in the form of \nthe master method in the next section (which unfort unately doesn\u2019t  apply  to recur-  \nrence  (4.14))  or the  Akra-Bazzi  method  (which  does,  but  requires calculus). Even \nif you use a powerful method, a recursion tree can improve you r intuition  for  what\u2019s  \ngoing on beneath the heavy math. \nExercises  \n4.4-1  \nFor each of the following recurrences, sketch its r ecursion tree, and guess a good \nasymptotic upper bound on its solution. Then use th e substitution method to verify \nyour answer. \na. T.n/  D T.n=2/  C n 3 . \nb. T.n/  D 4T.n=3/  C n. \nc. T.n/  D 4T.n=2/  C n. \nd. T.n/  D 3T.n  \ue003 1/ C 1. \n4.4-2  \nUse  the  substitution  method  to prove  that  recurrence  (4.15)  has the asymptotic \nlower bound L.n/  D \ufffd.n/ . Conclude that L.n/  D \u201a.n/ . \n4.4-3  \nUse  the  substitution  method  to prove  that  recurrence  (4.14)  has the solution T.n/  D \n\ufffd.n  lg n/. Conclude that T.n/  D \u201a.n  lg n/. \n4.4-4  \nUse a recursion tree to justify a good guess for th e solution to the recurrence \nT.n/  D T.\u02dbn/ CT..1\ue003\u02db/n/C\u201a.n/ , where \u02db is a constant in the range 0<\u02db<1 . \n4.5  The  master  method  for  solving  recurrences  \nThe master method provides a <cookbook= method for solving algorithmic  recur-  \nrences of the form \nT.n/  D aT.n=b/  C f.n/;  (4.16)  \nwhere a>0  and b>1  are constants. We call f.n/  a driving  function , and we call \na recurrence of this general form a master  recurrence . To use the master method, \nyou  need  to memorize  three  cases,  but  then  you\u2019ll  be able  to solve many master \nrecurrences quite easily. 102  Chapter  4 Divide-and-Conquer  \nA master  recurrence  describes  the  running  time  of a divide-and-conquer  algo-  \nrithm that divides a problem of size n into a subproblems, each of size n=b  < n. \nThe algorithm solves the a subproblems recursively, each in T.n=b/  time. The \ndriving function f.n/  encompasses  the  cost  of dividing  the  problem  before  the  re-  \ncursion, as well as the cost of combining the resul ts of the recursive solutions to \nsubproblems. For example, the recurrence arising fr om Strassen\u2019s  algorithm  is a \nmaster recurrence with a D 7, b D 2, and driving function f.n/  D \u201a.n  2 /. \nAs we have mentioned, in solving a recurrence that describes the running time \nof an algorithm,  one  technicality  that  we\u2019d  often  prefer  to ignore is the requirement \nthat the input size n be an integer. For example, we saw that the running  time \nof merge  sort  can  be described  by  recurrence  (2.3),  T.n/  D 2T.n=2/  C \u201a.n/ , \non  page  41.  But  if n is an odd  number,  we  really  don\u2019t  have  two  problems  of \nexactly half the size. Rather, to ensure that the p roblem sizes are integers, we round \none subproblem down to size bn=2c and the other up to size dn=2e, so the true \nrecurrence is T.n/  D T.dn=2e C  T.bn=2c/ C \u201a.n/. But  this  \u00fcoors-and-ceilings  \nrecurrence is longer to write and messier to deal w ith than recurrence  (2.3),  which  \nis de\u00fbned  on  the  reals.  We\u2019d  rather  not  worry  about  \u00fcoors  and  ceilings,  if we  don\u2019t  \nhave to, especially since the two recurrences have the same \u201a.n  lg n/ solution. \nThe master method allows you to state a master recu rrence without  \u00fcoors  and  \nceilings and implicitly infer them. No matter how t he arguments are rounded up \nor down to the nearest integer, the asymptotic boun ds that it provides remain the \nsame.  Moreover,  as we\u2019ll  see  in Section  4.6,  if you  de\u00fbne  your  master recurrence \non  the  reals,  without  implicit  \u00fcoors  and  ceilings,  the  asymptotic  bounds  still  don\u2019t  \nchange.  Thus  you  can  ignore  \u00fcoors  and  ceilings  for  master  recurrences.  Section  4.7  \ngives  suf\u00fbcient  conditions  for  ignoring  \u00fcoors  and  ceilings  in more  general  divide-  \nand-conquer  recurrences.  \nThe  master  theorem  \nThe master method depends upon the following theore m. \nTheorem  4.1  (Master  theorem)  \nLet a > 0  and b > 1  be constants, and let f.n/  be a driving function that is \nde\u00fbned  and  nonnegative  on  all  suf\u00fbciently  large  reals.  De\u00fbn e the recurrence T.n/  \non n 2 N by \nT.n/  D aT.n=b/  C f.n/;  (4.17)  \nwhere aT.n=b/  actually means a 0 T.bn=bc/ C a 00 T.dn=be/ for some constants \na 0 \ue004 0 and a 00 \ue004 0 satisfying a D a 0 C a 00 . Then the asymptotic behavior of T.n/  \ncan be characterized as follows: 4.5  The  master  method  for  solving  recurrences  103 \n1. If there  exists  a constant  \ufffd > 0  such that f.n/  D O.n  log b a\ue002\ue001 /, then T.n/  D \n\u201a.n  log b a /. \n2. If there exists a constant k \ue004 0 such that f.n/  D \u201a.n  log b a lg k n/, then T.n/  D \n\u201a.n  log b a lg kC1 n/. \n3. If there  exists  a constant  \ufffd>0  such that f.n/  D \ufffd.n  log b aC\ue001 /, and if f.n/  addi-  \ntionally  satis\u00fbes  the  regularity  condition  af.n=b/  \u0dc4 cf.n/  for some constant \nc<1  and  all  suf\u00fbciently  large  n, then T.n/  D \u201a.f.n// . \nBefore  applying  the  master  theorem  to some  examples,  let\u2019s  spend  a few  mo-  \nments to understand broadly what it says. The funct ion n log b a is called the water-  \nshed  function . In each of the three cases, we compare the drivin g function f.n/  to \nthe watershed function n log b a . Intuitively,  if the  watershed  function  grows  asymp-  \ntotically  faster  than  the  driving  function,  then  case  1 applies. Case 2 applies if the \ntwo  functions  grow  at nearly  the  same  asymptotic  rate.  Case  3 is the <opposite= of \ncase  1, where  the  driving  function  grows  asymptotically  faster than the watershed \nfunction. But the technical details matter. \nIn case  1, not  only  must  the  watershed  function  grow  asymptot ically faster than \nthe driving function, it must grow polynomially  faster.  That  is, the  watershed  func-  \ntion n log b a must be asymptotically larger than the driving func tion f.n/  by at least \na factor of \u201a.n  \ue001 / for some constant \ufffd>0 . The master theorem then says that the \nsolution is T.n/  D \u201a.n  log b a /. In this case, if we look at the recursion tree fo r the \nrecurrence, the cost per level grows at least geome trically from root to leaves, and \nthe total cost of leaves dominates the total cost o f the internal nodes. \nIn case 2, the watershed and driving functions grow  at nearly the  same  asymp-  \ntotic  rate.  But  more  speci\u00fbcally,  the  driving  function  grows  faster  than  the  wa-  \ntershed function by a factor of \u201a.lg k n/, where k \ue004 0. The master theorem \nsays that we tack on an extra lg n factor to f.n/ , yielding the solution T.n/  D \n\u201a.n  log b a lg kC1 n/. In this case, each level of the recursion tree co sts approxi- \nmately  the  same4\u201a.n  log b a lg k n/4and  there  are  \u201a.lg n/ levels. In practice, the \nmost common situation for case 2 occurs when k D 0, in which  case  the  water-  \nshed and driving functions have the same asymptotic  growth, and the solution is \nT.n/  D \u201a.n  log b a lg n/. \nCase  3 mirrors  case  1. Not  only  must  the  driving  function  grow  asymptotically \nfaster than the watershed function, it must grow polynomially  faster. That is, the \ndriving function f.n/  must be asymptotically larger than the watershed fu nction \nn log b a by at least a factor of \u201a.n  \ue001 / for some constant \ufffd>0 . Moreover, the driving \nfunction must satisfy the regularity condition that  af.n=b/  \u0dc4 cf.n/. This  condi-  \ntion  is satis\u00fbed  by  most  of the  polynomially  bounded  functions  that  you\u2019re  likely  \nto encounter  when  applying  case  3. The  regularity  condition  might  not  be satis\u00fbed  104  Chapter  4 Divide-and-Conquer  \nif the driving function grows slowly in local areas , yet relatively quickly overall. \n(Exercise  4.5-5  gives  an example  of such  a function.)  For  case  3, the  master  theo-  \nrem says that the solution is T.n/  D \u201a.f.n// . If we look at the recursion tree, the \ncost per level drops at least geometrically from th e root to the leaves, and the root \ncost dominates the cost of all other nodes. \nIt\u2019s  worth  looking  again  at the  requirement  that  there  be polynomial separation \nbetween the watershed function and the driving func tion for either  case  1 or case  3 \nto apply.  The  separation  doesn\u2019t  need  to be much,  but  it must  be there, and it must \ngrow polynomially. For example, for the recurrence T.n/  D 4T.n=2/  C n 1:99  \n(admittedly  not  a recurrence  you\u2019re  likely  to see  when  analy zing an algorithm), the \nwatershed function is n log b a D n 2 . Hence the driving function f.n/  D n 1:99  is \npolynomially smaller by a factor of n 0:01  . Thus  case  1 applies  with  \ufffd D 0:01. \nUsing  the  master  method  \nTo use the master method, you determine which case (if any) of the master theorem \napplies and write down the answer. \nAs  a \u00fbrst  example,  consider  the  recurrence  T.n/  D 9T.n=3/  C n. For this \nrecurrence, we have a D 9 and b D 3, which implies that n log b a D n log 3 9 D \u201a.n  2 ). \nSince f.n/  D n D O.n  2\ue002\ue001 / for any constant \ufffd \u0dc4 1, we  can  apply  case  1 of the  \nmaster theorem to conclude that the solution is T.n/  D \u201a.n  2 /. \nNow consider the recurrence T.n/  D T.2n=3/  C 1, which has a D 1 and \nb D 3=2, which means that the watershed function is n log b a D n log 3=2  1 D n 0 D 1. \nCase 2 applies since f.n/  D 1 D \u201a.n  log b a lg 0 n/ D \u201a.1/ . The solution to the \nrecurrence is T.n/  D \u201a.lg n/. \nFor the recurrence T.n/  D 3T.n=4/  C n lg n, we have a D 3 and b D 4, which \nmeans that n log b a D n log 4 3 D O.n  0:793  /. Since f.n/  D n lg n D \ufffd.n  log 4 3C\ue001 /, \nwhere \ufffd can be as large as approximately 0:2, case  3 applies  as long  as the  regularity  \ncondition holds for f.n/. It does,  because  for  suf\u00fbciently  large  n, we have that \naf.n=b/  D 3.n=4/  lg.n=4/  \u0dc4 .3=4/n  lg n D cf.n/  for c D 3=4. By  case  3, the  \nsolution to the recurrence is T.n/  D \u201a.n  lg n/. \nNext,  let\u2019s  look  at the  recurrence  T.n/  D 2T.n=2/  C n lg n, where we have \na D 2, b D 2, and n log b a D n log 2 2 D n. Case 2 applies since f.n/  D n lg n D \n\u201a.n  log b a lg 1 n/. We conclude that the solution is T.n/  D \u201a.n  lg 2 n/. \nWe can use the master method to solve the recurrenc es we saw in Sections  2.3.2,  \n4.1,  and  4.2.  \nRecurrence  (2.3),  T.n/  D 2T.n=2/  C \u201a.n/, on  page  41,  characterizes  the  run-  \nning time of merge sort. Since a D 2 and b D 2, the watershed function is \nn log b a D n log 2 2 D n. Case 2 applies because f.n/  D \u201a.n/ , and the solution is \nT.n/  D \u201a.n  lg n/. 4.5  The  master  method  for  solving  recurrences  105 \nRecurrence  (4.9),  T.n/  D 8T.n=2/  C \u201a.1/, on  page  84,  describes  the  running  \ntime of the simple recursive algorithm for matrix m ultiplication. We have a D 8 \nand b D 2, which means that the watershed function is n log b a D n log 2 8 D n 3 . \nSince n 3 is polynomially larger than the driving function f.n/  D \u201a.1/4indeed,  \nwe have f.n/  D O.n  3\ue002\ue001 / for any positive \ufffd < 34case  1 applies.  We  conclude  \nthat T.n/  D \u201a.n  3 /. \nFinally,  recurrence  (4.10),  T.n/  D 7T.n=2/  C \u201a.n  2 /, on  page  87,  arose  from  \nthe  analysis  of Strassen\u2019s  algorithm  for  matrix  multiplica tion. For this recurrence, \nwe have a D 7 and b D 2, and the watershed function is n log b a D n lg 7 . Observing  \nthat lg 7 D 2:807355::: , we can let \ufffd D 0:8  and bound the driving function \nf.n/  D \u201a.n  2 / D O.n  lg 7\ue002\ue001 /. Case  1 applies  with  solution  T.n/  D \u201a.n  lg 7 /. \nWhen  the  master  method  doesn\u2019t  apply  \nThere  are  situations  where  you  can\u2019t  use  the  master  theorem.  For example, it can \nbe that the watershed function and the driving func tion cannot be asymptotically \ncompared. We might have that f.n/  \ue007  n log b a for  an in\u00fbnite  number  of values  \nof n but also that f.n/  \ue008  n log b a for  an in\u00fbnite  number  of different  values  of n. \nAs a practical matter, however, most of the driving  functions that arise in the study \nof algorithms can be meaningfully compared with the  watershed function. If you \nencounter  a master  recurrence  for  which  that\u2019s  not  the  case,  you\u2019ll  have  to resort  to \nsubstitution or other methods. \nEven when the relative growths of the driving and w atershed functions can be \ncompared, the master theorem does not cover all the  possibilities. There is a gap \nbetween  cases  1 and  2 when  f.n/  D o.n  log b a /, yet the watershed function does \nnot grow polynomially faster than the driving funct ion. Similarly, there is a gap \nbetween  cases  2 and  3 when  f.n/  D !.n  log b a / and the driving function grows \nmore than polylogarithmically faster than the water shed function, but it does not \ngrow polynomially faster. If the driving function f alls into one of these gaps, or if \nthe  regularity  condition  in case  3 fails  to hold,  you\u2019ll  need  to use something other \nthan the master method to solve the recurrence. \nAs an example of a driving function falling into a gap, consider the recurrence \nT.n/  D 2T.n=2/  C n=  lg n. Since a D 2 and b D 2, the watershed function \nis n log b a D n log 2 2 D n 1 D n. The driving function is n=  lg n D o.n/, which \nmeans that it grows asymptotically more slowly than  the watershed function n. \nBut n=  lg n grows only logarithmically  slower than n, not polynomially  slower. \nMore  precisely,  equation  (3.24)  on  page  67  says  that  lg n D o.n  \ue001 / for any constant \n\ufffd>0 , which means that 1=  lg n D !.n  \ue002\ue001 / and n=  lg n D !.n  1\ue002\ue001 / D !.n  log b a\ue002\ue001 /. \nThus no constant \ufffd >0  exists such that n=  lg n D O.n  log b a\ue002\ue001 /, which is required \nfor  case  1 to apply.  Case  2 fails  to apply  as well,  since  n=  lg n D \u201a.n  log b a lg k n/, \nwhere k D \ue0031, but k must be nonnegative for case 2 to apply. 106  Chapter  4 Divide-and-Conquer  \nTo solve this kind of recurrence, you must use anot her method, such  as the  sub-  \nstitution  method  (Section  4.3)  or the  Akra-Bazzi  method  (Section  4.7).  (Exer-  \ncise  4.6-3  asks  you  to show  that  the  answer  is \u201a.n  lg lg n/.) Although the master \ntheorem  doesn\u2019t  handle  this  particular  recurrence,  it does  handle the overwhelming \nmajority of recurrences that tend to arise in pract ice. \nExercises  \n4.5-1  \nUse the master method to give tight asymptotic boun ds for the following  recur-  \nrences. \na. T.n/  D 2T.n=4/  C 1. \nb. T.n/  D 2T.n=4/  C p n. \nc. T.n/  D 2T.n=4/  C p n lg 2 n. \nd. T.n/  D 2T.n=4/  C n. \ne. T.n/  D 2T.n=4/  C n 2 . \n4.5-2  \nProfessor  Caesar  wants  to develop  a matrix-multiplication  algorithm  that  is asymp-  \ntotically  faster  than  Strassen\u2019s  algorithm.  His  algorithm  will  use  the  divide-and-  \nconquer method, dividing each matrix into n=4  \ue005 n=4  submatrices, and the divide \nand combine steps together will take \u201a.n  2 / time.  Suppose  that  the  professor\u2019s  al-  \ngorithm creates a recursive subproblems of size n=4. What is the largest integer \nvalue of a for which his algorithm could possibly run asymptot ically faster than \nStrassen\u2019s?  \n4.5-3  \nUse  the  master  method  to show  that  the  solution  to the  binary- search recurrence \nT.n/  D T.n=2/  C \u201a.1/  is T.n/  D \u201a.lg n/. (See  Exercise  2.3-6  for  a description  \nof binary search.) \n4.5-4  \nConsider the function f.n/  D lg n. Argue that although f.n=2/  < f.n/ , the \nregularity condition af.n=b/  \u0dc4 cf.n/  with a D 1 and b D 2 does not hold for \nany constant c <1 . Argue further that for any \ufffd >0, the  condition  in case  3 that  \nf.n/  D \ufffd.n  log b aC\ue001 / does not hold. 4.6  Proof  of the  continuous  master  theorem  107 \n4.5-5  \nShow that for suitable constants a, b, and \ufffd , the function f.n/  D 2 dlg ne satis\u00fbes  all  \nthe  conditions  in case  3 of the  master  theorem  except  the  regularity condition. \n? 4.6  Proof  of the  continuous  master  theorem  \nProving  the  master  theorem  (Theorem  4.1)  in its  full  general ity, especially dealing \nwith  the  knotty  technical  issue  of \u00fcoors  and  ceilings,  is beyond the scope of this \nbook. This section, however, states and proves a va riant of the master theorem, \ncalled the continuous  master  theorem  1 in which  the  master  recurrence  (4.17)  is \nde\u00fbned  over  suf\u00fbciently  large  positive  real  numbers.  The  proof of this version, \nuncomplicated  by  \u00fcoors  and  ceilings,  contains  the  main  ideas needed to understand \nhow  master  recurrences  behave.  Section  4.7  discusses  \u00fcoors  and  ceilings  in divide-  \nand-conquer  recurrences  at greater  length,  presenting  suf\u00fbcient  conditions  for  them  \nnot to affect the asymptotic solutions. \nOf  course,  since  you  need  not  understand  the  proof  of the  mast er theorem in \norder to apply the master method, you may choose to  skip this section. But if you \nwish  to study  more-advanced  algorithms  beyond  the  scope  of this textbook, you \nmay appreciate a better understanding of the underl ying mathematics, which the \nproof of the continuous master theorem provides. \nAlthough we usually assume that recurrences are alg orithmic and  don\u2019t  require  \nan explicit statement of a base case, we must be mu ch more careful for proofs that \njustify the practice. The lemmas and theorem in thi s section explicitly state the base \ncases, because the inductive proofs require mathema tical grounding. It is common \nin the world of mathematics to be extraordinarily c areful proving theorems that \njustify acting more casually in practice. \nThe proof of the continuous master theorem involves  two lemmas.  Lemma  4.2  \nuses  a slightly  simpli\u00fbed  master  recurrence  with  a threshol d constant of n 0 D 1, \nrather than the more general n 0 >0  threshold constant implied by the unstated base \ncase. The lemma employs a recursion tree to reduce the solution  of the  simpli\u00fbed  \nmaster  recurrence  to that  of evaluating  a summation.  Lemma  4.3  then  provides  \nasymptotic bounds for the summation, mirroring the three cases  of the  master  the-  \norem. Finally, the continuous master theorem itself  (Theorem  4.4)  gives  asymp-  \ntotic bounds for master recurrences, while generali zing to an arbitrary threshold \nconstant n 0 >0  as implied by the unstated base case. \n1 This terminology does not mean that either T.n/  or f.n/  need be continuous, only that the domain \nof T.n/  is the real numbers, as opposed to integers. 108  Chapter  4 Divide-and-Conquer  \nSome  of the  proofs  use  the  properties  described  in Problem  3-5  on  pages  72373  \nto combine and simplify complicated asymptotic expr essions. Although  Prob-  \nlem  3-5  addresses  only  \u201a-notation,  the  properties  enumerated  there  can  be ex-  \ntended to O-notation  and  \ufffd-notation  as well.  \nHere\u2019s  the  \u00fbrst  lemma.  \nLemma  4.2  \nLet a > 0  and b > 1  be constants, and let f.n/  be a function  de\u00fbned  over  real  \nnumbers n \ue004 1. Then the recurrence \nT.n/  D ( \n\u201a.1/  if 0 \u0dc4 n<1;  \naT.n=b/  C f.n/  if n \ue004 1 \nhas solution \nT.n/  D \u201a.n  log b a / C blog b nc X  \nj D0 a j f.n=b  j /: (4.18)  \nProof  Consider  the  recursion  tree  in Figure  4.3.  Let\u2019s  look  \u00fbrst  at its  inter-  \nnal nodes. The root of the tree has cost f.n/ , and it has a children, each with \ncost f.n=b/ . (It is convenient to think of a as being  an integer,  especially  when  vi-  \nsualizing the recursion tree, but the mathematics d oes not require it.) Each of these \nchildren has a children, making a 2 nodes at depth 2, and each of the a children \nhas cost f.n=b  2 /. In general, there are a j nodes at depth j , and each node has \ncost f.n=b  j /. \nNow,  let\u2019s  move  on  to understanding  the  leaves.  The  tree  grows  downward  un-  \ntil n=b  j becomes less than 1. Thus, the tree has height blog b nc C  1, because \nn=b  blog b nc \ue004 n=b  log b n D 1 and n=b  blog b ncC1 < n=b  log b n D 1. Since, as we \nhave observed, the number of nodes at depth j is a j and all the leaves are at \ndepth blog b nc C  1, the tree contains a blog b ncC1 leaves.  Using  the  identity  (3.21)  \non  page  66,  we  have  a blog b ncC1 \u0dc4 a log b nC1 D an  log b a D O.n  log b a /, since a is \nconstant, and a blog b ncC1 \ue004 a log b n D n log b a D \ufffd.n  log b a /. Consequently, the total \nnumber of leaves is \u201a.n  log b a /4asymptotically,  the  watershed  function.  \nWe  are  now  in a position  to derive  equation  (4.18)  by  summing  the costs of \nthe  nodes  at each  depth  in the  tree,  as shown  in the  \u00fbgure.  The  \u00fbrst term in the \nequation is the total costs of the leaves. Since ea ch leaf is at depth blog b nc C  1 \nand n=b  blog b ncC1 < 1 , the base case of the recurrence gives the cost of  a \nleaf: T.n=b  blog b ncC1 / D \u201a.1/ . Hence the cost of all \u201a.n  log b a / leaves is \n\u201a.n  log b a / \ue001 \u201a.1/  D \u201a.n  log b a / by  Problem  3-5(d).  The  second  term  in equa-  \ntion  (4.18)  is the  cost  of the  internal  nodes,  which,  in the  underlying  divide-and-  \nconquer algorithm, represents the costs of dividing  problems into subproblems and 4.6  Proof  of the  continuous  master  theorem  109 \n\u2026 \u2026 \n\u2026 \n\u2026 \u2026 \u2026 \u2026 \n\u2026 \u2026 \u2026 \u2026 \n\u2026 \u2026 \u2026 \n\u2026 f.n/  f.n/  \na a a a \na a a a \na a a a a \nf.n=b/  f.n=b/  f.n=b/  \nf.n=b  2 / f.n=b  2 / f.n=b  2 / f.n=b  2 / f.n=b  2 / f.n=b  2 / f.n=b  2 / f.n=b  2 / f.n=b  2 / af.n=b/  \na 2 f.n=b  2 / blog b nc C  1 \na blog b ncC1 \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.1/  \u201a.n  log b a / \nTotal: \u201a.n  log b a / C blog b nc X  \nj D0 a j f.n=b  j / \nFigure  4.3  The recursion tree generated by T.n/  D aT.n=b/  C f.n/ . The tree is a complete a-ary  \ntree with a blog b ncC1 leaves and height blog b nc C  1. The cost of the nodes at each depth is shown \nat the  right,  and  their  sum  is given  in equation  (4.18).  \nthen recombining the subproblems. Since the cost fo r all the internal nodes at \ndepth j is a j f.n=b  j /, the total cost of all internal nodes is \nblog b nc X  \nj D0 a j f.n=b  j /: \nAs  we\u2019ll  see,  the  three  cases  of the  master  theorem  depend  on  the distribution of \nthe total cost across levels of the recursion tree:  \nCase  1: The costs increase geometrically from the root to t he leaves, growing by \na constant factor with each level. \nCase  2: The costs depend on the value of k in the theorem. With k D 0, the costs \nare equal for each level; with k D 1, the costs grow linearly from the root to \nthe leaves; with k D 2, the growth is quadratic; and in general, the cost s grow \npolynomially in k. \nCase  3: The costs decrease geometrically from the root to t he leaves, shrinking \nby a constant factor with each level. 110  Chapter  4 Divide-and-Conquer  \nThe  summation  in equation  (4.18)  describes  the  cost  of the  dividing  and  com-  \nbining  steps  in the  underlying  divide-and-conquer  algorithm.  The  next  lemma  pro-  \nvides  asymptotic  bounds  on  the  summation\u2019s  growth.  \nLemma  4.3  \nLet a > 0  and b > 1  be constants, and let f.n/  be a function  de\u00fbned  over  real  \nnumbers n \ue004 1. Then the asymptotic behavior of the function \ng.n/  D blog b nc X  \nj D0 a j f.n=b  j /; (4.19)  \nde\u00fbned  for  n \ue004 1, can be characterized as follows: \n1. If there  exists  a constant  \ufffd > 0  such that f.n/  D O.n  log b a\ue002\ue001 /, then g.n/  D \nO.n  log b a /. \n2. If there exists a constant k \ue004 0 such that f.n/  D \u201a.n  log b a lg k n/, then g.n/  D \n\u201a.n  log b a lg kC1 n/. \n3. If there  exists  a constant  c in the range 0<c <1  such that 0 < af.n=b/  \u0dc4 \ncf.n/  for all n \ue004 1, then g.n/  D \u201a.f.n// . \nProof  For  case  1, we  have  f.n/  D O.n  log b a\ue002\ue001 /, which implies that f.n=b  j / D \nO..n=b  j / log b a\ue002\ue001 /. Substituting  into  equation  (4.19)  yields  \ng.n/  D blog b nc X  \nj D0 a j O \u00ce \ue002 n \nb j \u00cd log b a\ue002\ue001 \u00cf \nD O \ue001 blog b nc X  \nj D0 a j \ue002 n \nb j \u00cd log b a\ue002\ue001 ! \n(by  Problem  3-5(c),  repeatedly)  \nD O \ue001 \nn log b a\ue002\ue001 blog b nc X  \nj D0 \u00ce ab  \ue001 \nb log b a \u00cf j ! \nD O \ue001 \nn log b a\ue002\ue001 blog b nc X  \nj D0 .b \ue001 / j ! \n(by  equation  (3.17)  on  page  66)  \nD O \u00ce \nn log b a\ue002\ue001 \u00ce b \ue001.blog b ncC1/  \ue003 1 \nb \ue001 \ue003 1 \u00cf\u00cf  \n(by  equation  (A.6)  on  page  1142)  , \nthe last series being geometric. Since b and \ufffd are constants, the b \ue001 \ue003 1 denom-  \ninator  doesn\u2019t  affect  the  asymptotic  growth  of g.n/ , and neither does the \ue0031 in 4.6  Proof  of the  continuous  master  theorem  111 \nthe numerator. Since b \ue001.blog b ncC1/  \u0dc4 .b log b nC1 / \ue001 D b \ue001 n \ue001 D O.n  \ue001 /, we obtain \ng.n/  D O.n  log b a\ue002\ue001 \ue001 O.n  \ue001 // D O.n  log b a /, thereby  proving  case  1. \nCase 2 assumes that f.n/  D \u201a.n  log b a lg k n/, from which we can conclude that \nf.n=b  j / D \u201a..n=b  j / log b a lg k .n=b  j //. Substituting  into  equation  (4.19)  and  re-  \npeatedly  applying  Problem  3-5(c)  yields  \ng.n/  D \u201a \ue001 blog b nc X  \nj D0 a j \ue002 n \nb j \u00cd log b a \nlg k \ue002 n \nb j \u00cd ! \nD \u201a \ue001 \nn log b a blog b nc X  \nj D0 a j \nb j log b a lg k \ue002 n \nb j \u00cd ! \nD \u201a \ue001 \nn log b a blog b nc X  \nj D0 lg k \ue002 n \nb j \u00cd ! \nD \u201a \ue001 \nn log b a blog b nc X  \nj D0 \u00ce log b .n=b  j / \nlog b 2 \u00cf k ! \n(by  equation  (3.19)  on  page  66)  \nD \u201a \ue001 \nn log b a blog b nc X  \nj D0 \u00ce log b n \ue003 j \nlog b 2 \u00cf k ! \n(by  equations  (3.17),  (3.18),  \nand  (3.20))  \nD \u201a \ue001 \nn log b a \nlog k \nb 2 blog b nc X  \nj D0 .log b n \ue003 j/  k ! \nD \u201a \ue001 \nn log b a blog b nc X  \nj D0 .log b n \ue003 j/  k ! \n(b>1  and k are constants) . \nThe summation within the \u201a-notation  can  be bounded  from  above  as follows:  \nblog b nc X  \nj D0 .log b n \ue003 j/  k \u0dc4 blog b nc X  \nj D0 .blog b nc C  1 \ue003 j/  k \nD blog b ncC1 X  \nj D1 j k (reindexing4pages  114331144)  \nD O..blog b nc C  1/ kC1 / (by  Exercise  A.1-5  on  page  1144)  \nD O.log kC1 \nb n/ (by  Exercise  3.3-3  on  page  70)  . \nExercise  4.6-1  asks  you  to show  that  the  summation  can  simila rly be bounded from \nbelow by \ufffd.log kC1 \nb n/. Since  we  have  tight  upper  and  lower  bounds,  the  summa-  \ntion is \u201a.log kC1 \nb n/, from which we can conclude that g.n/  D \u201a \u00e3 \nn log b a log kC1 \nb n \u00e4 \n, \nthereby completing the proof of case 2. 112  Chapter  4 Divide-and-Conquer  \nFor  case  3, observe  that  f.n/  appears  in the  de\u00fbnition  (4.19)  of g.n/  (when \nj D 0) and that all terms of g.n/  are positive. Therefore, we must have g.n/  D \n\ufffd.f  .n// , and it only remains to prove that g.n/  D O.f.n// . Performing j itera-  \ntions of the inequality af.n=b/  \u0dc4 cf.n/  yields a j f.n=b  j / \u0dc4 c j f.n/. Substitut-  \ning  into  equation  (4.19),  we  obtain  \ng.n/  D blog b nc X  \nj D0 a j f.n=b  j / \n\u0dc4 blog b nc X  \nj D0 c j f.n/  \n\u0dc4 f.n/  1  X  \nj D0 c j \nD f.n/  \u00ce 1 \n1 \ue003 c \u00cf \n(by  equation  (A.7)  on  page  1142  since  jc j <1) \nD O.f.n//:  \nThus, we can conclude that g.n/  D \u201a.f.n//. With  case  3 proved,  the  entire  proof  \nof the lemma is complete. \nWe can now state and prove the continuous master th eorem. \nTheorem  4.4  (Continuous  master  theorem)  \nLet a>0  and b>1  be constants, and let f.n/  be a driving  function  that  is de\u00fbned  \nand  nonnegative  on  all  suf\u00fbciently  large  reals.  De\u00fbne  the  algorithmic recurrence \nT.n/  on the positive real numbers by \nT.n/  D aT.n=b/  C f.n/:  \nThen the asymptotic behavior of T.n/  can be characterized as follows: \n1. If there  exists  a constant  \ufffd > 0  such that f.n/  D O.n  log b a\ue002\ue001 /, then T.n/  D \n\u201a.n  log b a /. \n2. If there exists a constant k \ue004 0 such that f.n/  D \u201a.n  log b a lg k n/, then T.n/  D \n\u201a.n  log b a lg kC1 n/. \n3. If there  exists  a constant  \ufffd>0  such that f.n/  D \ufffd.n  log b aC\ue001 /, and if f.n/  ad-  \nditionally  satis\u00fbes  the  regularity  condition  af.n=b/  \u0dc4 cf.n/  for some constant \nc<1  and  all  suf\u00fbciently  large  n, then T.n/  D \u201a.f.n// . \nProof  The  idea  is to bound  the  summation  (4.18)  from  Lemma  4.2  by  applying \nLemma  4.3.  But  we  must  account  for  Lemma  4.2  using  a base  case  for 0<n<1 , 4.6  Proof  of the  continuous  master  theorem  113 \nwhereas this theorem uses an implicit base case for  0<n<n  0 , where n 0 >0  is \nan arbitrary threshold constant. Since the recurren ce is algorithmic, we can assume \nthat f.n/  is de\u00fbned  for  n \ue004 n 0 . \nFor n>0, let  us de\u00fbne  two  auxiliary  functions  T 0 .n/  D T.n  0 n/ and f 0 .n/  D \nf.n  0 n/. We have \nT 0 .n/  D T.n  0 n/ \nD ( \n\u201a.1/  if n 0 n<n  0 ; \naT.n  0 n=b/  C f.n  0 n/ if n 0 n \ue004 n 0 \nD ( \n\u201a.1/  if n<1;  \naT  0 .n=b/  C f 0 .n/  if n \ue004 1:  (4.20)  \nWe have obtained a recurrence for T 0 .n/  that  satis\u00fbes  the  conditions  of Lemma  4.2,  \nand by that lemma, the solution is \nT 0 .n/  D \u201a.n  log b a / C blog b nc X  \nj D0 a j f 0 .n=b  j /: (4.21)  \nTo solve T 0 .n/, we  \u00fbrst  need  to bound  f 0 .n/. Let\u2019s  examine  the  individual  cases  \nin the theorem. \nThe  condition  for  case  1 is f.n/  D O.n  log b a\ue002\ue001 / for some constant \ufffd >0 . We \nhave \nf 0 .n/  D f.n  0 n/ \nD O..n  0 n/ log b a\ue002\ue001 / \nD O.n  log b a\ue002\ue001 /; \nsince a, b, n 0 , and \ufffd are all constant. The function f 0 .n/  satis\u00fbes  the  conditions  of \ncase  1 of Lemma  4.3,  and  the  summation  in equation  (4.18)  of Lemma  4.2  evaluates  \nto O.n  log b a /. Because a, b and n 0 are all constants, we have \nT.n/  D T 0 .n=n  0 / \nD \u201a..n=n  0 / log b a / C O..n=n  0 / log b a / \nD \u201a.n  log b a / C O.n  log b a / \nD \u201a.n  log b a / (by  Problem  3-5(b))  , \nthereby  completing  case  1 of the  theorem.  \nThe condition for case 2 is f.n/  D \u201a.n  log b a lg k n/ for some constant k \ue004 0. \nWe have \nf 0 .n/  D f.n  0 n/ \nD \u201a..n  0 n/ log b a lg k .n 0 n//  \nD \u201a.n  log b a lg k n/ (by eliminating the constant terms) . 114  Chapter  4 Divide-and-Conquer  \nSimilar  to the  proof  of case  1, the  function  f 0 .n/  satis\u00fbes  the  conditions  of case  2 \nof Lemma  4.3.  The  summation  in equation  (4.18)  of Lemma  4.2  is therefore \n\u201a.n  log b a lg kC1 n/, which implies that \nT.n/  D T 0 .n=n  0 / \nD \u201a..n=n  0 / log b a / C \u201a..n=n  0 / log b a lg kC1 .n=n  0 // \nD \u201a.n  log b a / C \u201a.n  log b a lg kC1 n/ \nD \u201a.n  log b a lg kC1 n/ (by  Problem  3-5(c))  , \nwhich proves case 2 of the theorem. \nFinally,  the  condition  for  case  3 is f.n/  D \ufffd.n  log b aC\ue001 / for some constant \ufffd>0  \nand f.n/  additionally  satis\u00fbes  the  regularity  condition  af.n=b/  \u0dc4 cf.n/  for all \nn \ue004 n 0 and some constants c < 1  and n 0 > 1. The  \u00fbrst  part  of case  3 is like  \ncase  1: \nf 0 .n/  D f.n  0 n/ \nD \ufffd..n  0 n/ log b aC\ue001 / \nD \ufffd.n  log b aC\ue001 /: \nUsing  the  de\u00fbnition  of f 0 .n/  and the fact that n 0 n \ue004 n 0 for all n \ue004 1, we have for \nn \ue004 1 that \naf  0 .n=b/  D af.n  0 n=b/  \n\u0dc4 cf.n  0 n/ \nD cf  0 .n/:  \nThus f 0 .n/  satis\u00fbes  the  requirements  for  case  3 of Lemma  4.3,  and  the  summation \nin equation  (4.18)  of Lemma  4.2  evaluates  to \u201a.f  0 .n//, yielding \nT.n/  D T 0 .n=n  0 / \nD \u201a..n=n  0 / log b a / C \u201a.f  0 .n=n  0 // \nD \u201a.f  0 .n=n  0 // \nD \u201a.f.n//;  \nwhich  completes  the  proof  of case  3 of the  theorem  and  thus  the  whole theorem. \nExercises  \n4.6-1  \nShow that P  blog b nc \nj D0 .log b n \ue003 j/  k D \ufffd.log kC1 \nb n/. \n? 4.6-2  \nShow  that  case  3 of the  master  theorem  is overstated  (which  is also  why  case  3 \nof Lemma  4.3  does  not  require  that  f.n/  D \ufffd.n  log b aC\ue001 /) in the sense that the 4.7  Akra-Bazzi  recurrences  115 \nregularity condition af.n=b/  \u0dc4 cf.n/  for some constant c <1  implies that there \nexists a constant \ufffd>0  such that f.n/  D \ufffd.n  log b aC\ue001 /. \n? 4.6-3  \nFor f.n/  D \u201a.n  log b a = lg n/, prove  that  the  summation  in equation  (4.19)  has  solu-  \ntion g.n/  D \u201a.n  log b a lg lg n/. Conclude that a master recurrence T.n/  using f.n/  \nas its driving function has solution T.n/  D \u201a.n  log b a lg lg n/. \n? 4.7  Akra-Bazzi  recurrences  \nThis section provides an overview of two advanced t opics related  to divide-and-  \nconquer  recurrences.  The  \u00fbrst  deals  with  technicalities  arising from the use of \n\u00fcoors  and  ceilings,  and  the  second  discusses  the  Akra-Bazzi  method,  which  in-  \nvolves  a little  calculus,  for  solving  complicated  divide-and-conquer  recurrences.  \nIn particular,  we\u2019ll  look  at the  class  of algorithmic  divide-and-conquer  recur-  \nrences  originally  studied  by  M.  Akra  and  L. Bazzi  [13].  These  Akra-Bazzi  recur-  \nrences take the form \nT.n/  D f.n/  C k X  \ni D1 a i T.n=b  i /; (4.22)  \nwhere k is a positive integer; all the constants a 1 ;a  2 ;:::;a  k 2 R are  strictly  posi-  \ntive; all the constants b 1 ;b  2 ;:::;b  k 2 R are strictly greater than 1; and the driving \nfunction f.n/  is de\u00fbned  on  suf\u00fbciently  large  nonnegative  reals  and  is itself  non-  \nnegative. \nAkra-Bazzi  recurrences  generalize  the  class  of recurrence s addressed by the \nmaster theorem. Whereas master recurrences characte rize the running times of \ndivide-and-conquer  algorithms  that  break  a problem  into  equal-sized  subproblems  \n(modulo  \u00fcoors  and  ceilings),  Akra-Bazzi  recurrences  can  describe the running time \nof divide-and-conquer  algorithms  that  break  a problem  into  different-sized  sub-  \nproblems. The master theorem, however, allows you t o ignore \u00fcoors  and  ceilings,  \nbut  the  Akra-Bazzi  method  for  solving  Akra-Bazzi  recurrenc es needs an additional \nrequirement  to deal  with  \u00fcoors  and  ceilings.  \nBut  before  diving  into  the  Akra-Bazzi  method  itself,  let\u2019s  understand  the  lim-  \nitations  involved  in ignoring  \u00fcoors  and  ceilings  in Akra-Ba zzi recurrences. As \nyou\u2019re  aware,  algorithms  generally  deal  with  integer-sized  inputs.  The  mathemat-  \nics for recurrences is often easier with real numbe rs, however, than with integers, \nwhere  we  must  cope  with  \u00fcoors  and  ceilings  to ensure  that  terms  are  well  de\u00fbned.  \nThe  difference  may  not  seem  to be much4especially  because  that\u2019s  often  the  truth  \nwith  recurrences4but  to be mathematically  correct,  we  must  be careful with our 116  Chapter  4 Divide-and-Conquer  \nassumptions. Since our end goal is to understand al gorithms and not the vagaries \nof mathematical  corner  cases,  we\u2019d  like  to be casual  yet  rigorous. How can we \ntreat  \u00fcoors  and  ceilings  casually  while  still  ensuring  rigor?  \nFrom  a mathematical  point  of view,  the  dif\u00fbculty  in dealing  with  \u00fcoors  and  \nceilings is that some driving functions can be real ly, really weird.  So  it\u2019s  not  okay  in \ngeneral  to ignore  \u00fcoors  and  ceilings  in Akra-Bazzi  recurren ces. Fortunately, most \nof the driving functions we encounter in the study of algorithms behave nicely, and \n\u00fcoors  and  ceilings  don\u2019t  make  a difference.  \nThe  polynomial-growth  condition  \nIf the driving function f.n/  in equation  (4.22)  is well  behaved  in the  following  \nsense,  it\u2019s  okay  to drop  \u00fcoors  and  ceilings.  \nA function f.n/  de\u00fbned  on  all  suf\u00fbciently  large  positive  reals  satis\u00fbes  the  \npolynomial-growth  condition  if there exists a constant y n>0  such that the \nfollowing holds: for every constant \ufffd \ue004 1, there exists a constant d > 1  \n(depending on \ufffd) such that f.n/=d  \u0dc4 f.\ue001n/  \u0dc4 df.n/  for all 1 \u0dc4 \ue001 \u0dc4 \ufffd \nand n \ue004 y  n. \nThis  de\u00fbnition  may  be one  of the  hardest  in this  textbook  to get your head around. \nTo  a \u00fbrst  order,  it says  that  f.n/  satis\u00fbes  the  property  that  f.\u201a.n//  D \u201a.f.n// , \nalthough  the  polynomial-growth  condition  is actually  somewhat  stronger  (see  Ex-  \nercise  4.7-4).  The  de\u00fbnition  also  implies  that  f.n/  is asymptotically positive (see \nExercise  4.7-3).  \nExamples  of functions  that  satisfy  the  polynomial-growth  condition include any \nfunction of the form f.n/  D \u201a.n  \u02db lg \u02c7 n lg lg \ue002 n/, where \u02db, \u02c7, and \ufffd are constants. \nMost of the polynomially bounded functions used in this book satisfy the condition. \nExponentials  and  superexponentials  do  not  (see  Exercise  4.7-2,  for  example),  and  \nthere also exist polynomially bounded functions tha t do not. \nFloors  and  ceilings  in <nice=  recurrences  \nWhen  the  driving  function  in an Akra-Bazzi  recurrence  satis\u00fbes  the  polynomial-  \ngrowth  condition,  \u00fcoors  and  ceilings  don\u2019t  change  the  asymp totic behavior of the \nsolution. The following theorem, which is presented  without proof, formalizes this \nnotion. \nTheorem  4.5  \nLet T.n/  be a function  de\u00fbned  on  the  nonnegative  reals  that  satis\u00fbes  recur-  \nrence  (4.22),  where  f.n/  satis\u00fbes  the  polynomial-growth  condition.  Let  T 0 .n/  be \nanother  function  de\u00fbned  on  the  natural  numbers  also  satisfying  recurrence  (4.22),  4.7  Akra-Bazzi  recurrences  117 \nexcept that each T.n=b  i / is replaced either with T.dn=b  i e/ or with T.bn=b  i c/. \nThen we have T 0 .n/  D \u201a.T.n// . \nFloors and ceilings represent a minor perturbation to the arguments  in the  re-  \ncursion.  By  inequality  (3.2)  on  page  64,  they  perturb  an argument by at most 1. \nBut much larger perturbations are tolerable. As lon g as the driving function f.n/  \nin recurrence  (4.22)  satis\u00fbes  the  polynomial-growth  condition,  it turns  out  that  re-  \nplacing any term T.n=b  i / with T.n=b  i C h i .n//, where jh i .n/j D  O.n=  lg 1C\ue001 n/ \nfor some constant \ufffd > 0  and  suf\u00fbciently  large  n, leaves the asymptotic solution \nunaffected.  Thus,  the  divide  step  in a divide-and-conquer  algorithm  can  be moder-  \nately  coarse  without  affecting  the  solution  to its  running- time recurrence. \nThe  Akra-Bazzi  method  \nThe  Akra-Bazzi  method,  not  surprisingly,  was  developed  to solve  Akra-Bazzi  re-  \ncurrences  (4.22),  which  by  dint  of Theorem  4.5,  applies  in the  presence  of \u00fcoors  \nand ceilings or even larger perturbations, as just discussed. The method involves \n\u00fbrst  determining  the  unique  real  number  p such that P  k \ni D1 a i =b  p \ni D 1. Such a p \nalways exists, because when p ! \ue0031 , the sum goes to 1; it decreases as p in-  \ncreases; and when p ! 1 , it goes to 0. The  Akra-Bazzi  method  then  gives  the  \nsolution to the recurrence as \nT.n/  D \u201a \u00ce \nn p \u00ce \n1 C Z n \n1 f.x/  \nx pC1 dx  \u00cf\u00cf  \n: (4.23)  \nAs an example, consider the recurrence \nT.n/  D T.n=5/  C T.7n=10/  C n:  (4.24)  \nWe\u2019ll  see  the  similar  recurrence  (9.1)  on  page  240  when  we  study an algorithm for \nselecting the i th smallest element from a set of n numbers. This recurrence has the \nform  of equation  (4.22),  where  a 1 D a 2 D 1, b 1 D 5, b 2 D 10=7 , and f.n/  D n. \nTo  solve  it, the  Akra-Bazzi  method  says  that  we  should  determ ine the unique p \nsatisfying \n\u00ce 1 \n5 \u00cf p \nC \u00ce 7 \n10  \u00cf p \nD 1:  \nSolving for p is kind  of messy4it  turns  out  that  p D 0:83978:::4but  we  can  \nsolve the recurrence without actually knowing the e xact value for p. Observe  that  \n.1=5/  0 C .7=10/  0 D 2 and .1=5/  1 C .7=10/  1 D 9=10 , and thus p lies in the \nrange 0 < p < 1 . That  turns  out  to be suf\u00fbcient  for  the  Akra-Bazzi  method  \nto give  us the  solution.  We\u2019ll  use  the  fact  from  calculus  that  if k \u00a4 \ue0031, then R \nx k dx  D x kC1 =.k  C 1/, which  we\u2019ll  apply  with  k D \ue003p \u00a4 \ue0031. The  Akra-Bazzi  118  Chapter  4 Divide-and-Conquer  \nsolution  (4.23)  gives  us \nT.n/  D \u201a \u00ce \nn p \u00ce \n1 C Z n \n1 f.x/  \nx pC1 dx  \u00cf\u00cf  \nD \u201a \u00ce \nn p \u00ce \n1 C Z n \n1 x \ue002p dx  \u00cf\u00cf  \nD \u201a \u00ce \nn p \u00ce \n1 C \u00d0 x 1\ue002p \n1 \ue003 p \ue00b n \n1 \u00cf\u00cf  \nD \u201a \u00ce \nn p \u00ce \n1 C \u00ce n 1\ue002p \n1 \ue003 p \ue003 1 \n1 \ue003 p \u00cf\u00cf\u00cf  \nD \u201a \u00e3 \nn p \ue001 \u201a.n  1\ue002p / \u00e4 \n(because 1 \ue003 p is a positive constant) \nD \u201a.n/  (by  Problem  3-5(d))  . \nAlthough  the  Akra-Bazzi  method  is more  general  than  the  mast er theorem, it \nrequires calculus and sometimes a bit more reasonin g. You also must ensure that \nyour  driving  function  satis\u00fbes  the  polynomial-growth  condition  if you  want  to ig-  \nnore  \u00fcoors  and  ceilings,  although  that\u2019s  rarely  a problem.  When it applies, the \nmaster method is much simpler to use, but only when  subproblem sizes are more \nor less equal. They are both good tools for your al gorithmic toolkit. \nExercises  \n? 4.7-1  \nConsider  an Akra-Bazzi  recurrence  T.n/  on  the  reals  as given  in recurrence  (4.22),  \nand  de\u00fbne  T 0 .n/  as \nT 0 .n/  D cf.n/  C k X  \ni D1 a i T 0 .n=b  i /; \nwhere c>0  is constant. Prove that whatever the implicit initi al conditions for T.n/  \nmight be, there exist initial conditions for T 0 .n/  such that T 0 .n/  D cT.n/  for \nall n>0 . Conclude that we can drop the asymptotics on a dr iving function in any \nAkra-Bazzi  recurrence  without  affecting  its  asymptotic  solution. \n4.7-2  \nShow that f.n/  D n 2 satis\u00fbes  the  polynomial-growth  condition  but  that  f.n/  D 2 n \ndoes not. \n4.7-3  \nLet f.n/  be a function  that  satis\u00fbes  the  polynomial-growth  conditio n. Prove that \nf.n/  is asymptotically positive, that is, there exists a  constant n 0 \ue004 0 such that \nf.n/  \ue004 0 for all n \ue004 n 0 . Problems for Chapter 4 119 \n? 4.7-4  \nGive  an example  of a function  f.n/  that  does  not  satisfy  the  polynomial-growth  \ncondition but for which f.\u201a.n//  D \u201a.f.n// . \n4.7-5  \nUse  the  Akra-Bazzi  method  to solve  the  following  recurrence s. \na. T.n/  D T.n=2/  C T.n=3/  C T.n=6/  C n lg n. \nb. T.n/  D 3T.n=3/  C 8T.n=4/  C n 2 = lg n. \nc. T.n/  D .2=3/T.n=3/  C .1=3/T.2n=3/  C lg n. \nd. T.n/  D .1=3/T.n=3/  C 1=n. \ne. T.n/  D 3T.n=3/  C 3T.2n=3/  C n 2 . \n? 4.7-6  \nUse  the  Akra-Bazzi  method  to prove  the  continuous  master  theorem. \nProblems  \n4-1  Recurrence  examples  \nGive  asymptotically  tight  upper  and  lower  bounds  for  T.n/  in each of the following \nalgorithmic  recurrences.  Justify  your  answers.  \na. T.n/  D 2T.n=2/  C n 3 . \nb. T.n/  D T.8n=11/  C n. \nc. T.n/  D 16T.n=4/  C n 2 . \nd. T.n/  D 4T.n=2/  C n 2 lg n. \ne. T.n/  D 8T.n=3/  C n 2 . \nf. T.n/  D 7T.n=2/  C n 2 lg n. \ng. T.n/  D 2T.n=4/  C p n. \nh. T.n/  D T.n  \ue003 2/ C n 2 . 120  Chapter  4 Divide-and-Conquer  \n4-2  Parameter-passing  costs  \nThroughout this book, we assume that parameter pass ing during procedure calls \ntakes constant time, even if an N -element  array  is being  passed.  This  assumption  \nis valid in most systems because a pointer to the a rray is passed, not the array itself. \nThis  problem  examines  the  implications  of three  parameter- passing strategies: \n1. Arrays  are  passed  by  pointer.  Time  D \u201a.1/ . \n2. Arrays are passed by copying. Time D \u201a.N/ , where N is the size of the array. \n3. Arrays  are  passed  by  copying  only  the  subrange  that  might  be accessed by the \ncalled procedure. Time D \u201a.n/  if the subarray contains n elements. \nConsider the following three algorithms: \na. The  recursive  binary-search  algorithm  for  \u00fbnding  a number  in a sorted array \n(see  Exercise  2.3-6).  \nb. The MERGE-SORT  procedure  from  Section  2.3.1.  \nc. The M ATRIX-MULTIPLY-RECURSIVE procedure  from  Section  4.1.  \nGive  nine  recurrences  T a1  .N;n/;T  a2  .N;n/;:::;T  c3  .N;n/  for  the  worst-case  run-  \nning times of each of the three algorithms above wh en arrays and matrices are \npassed  using  each  of the  three  parameter-passing  strategies  above.  Solve  your  re-  \ncurrences, giving tight asymptotic bounds. \n4-3  Solving  recurrences  with  a change  of variables  \nSometimes, a little algebraic manipulation can make  an unknown  recurrence  simi-  \nlar  to one  you  have  seen  before.  Let\u2019s  solve  the  recurrence  \nT.n/  D 2T  \u00e3p n \u00e4 C \u201a.lg n/ (4.25)  \nby  using  the  change-of-variables  method.  \na. De\u00fbne  m D lg n and S.m/  D T.2  m /. Rewrite  recurrence  (4.25)  in terms  of m \nand S.m/ . \nb. Solve your recurrence for S.m/ . \nc. Use your solution for S.m/  to conclude that T.n/  D \u201a.lg n lg lg n/. \nd. Sketch  the  recursion  tree  for  recurrence  (4.25),  and  use  it to explain intuitively \nwhy the solution is T.n/  D \u201a.lg n lg lg n/. \nSolve the following recurrences by changing variabl es: Problems for Chapter 4 121 \ne. T.n/  D 2T.  p n/ C \u201a.1/ . \nf. T.n/  D 3T.  3 p n/ C \u201a.n/ . \n4-4  More  recurrence  examples  \nGive  asymptotically  tight  upper  and  lower  bounds  for  T.n/  in each of the following \nrecurrences.  Justify  your  answers.  \na. T.n/  D 5T.n=3/  C n lg n. \nb. T.n/  D 3T.n=3/  C n=  lg n. \nc. T.n/  D 8T.n=2/  C n 3 p n. \nd. T.n/  D 2T.n=2  \ue003 2/ C n=2. \ne. T.n/  D 2T.n=2/  C n=  lg n. \nf. T.n/  D T.n=2/  C T.n=4/  C T.n=8/  C n. \ng. T.n/  D T.n  \ue003 1/ C 1=n. \nh. T.n/  D T.n  \ue003 1/ C lg n. \ni. T.n/  D T.n  \ue003 2/ C 1=  lg n. \nj. T.n/  D p nT.  p n/ C n. \n4-5  Fibonacci  numbers  \nThis problem develops properties of the Fibonacci n umbers, which  are  de\u00fbned  \nby  recurrence  (3.31)  on  page  69.  We\u2019ll  explore  the  technique  of generating  func-  \ntions  to solve  the  Fibonacci  recurrence.  De\u00fbne  the  generating  function  (or formal  \npower  series ) F as \nF .\u00b4/  D 1  X  \ni D0 F i \u00b4 i \nD 0 C \u00b4 C \u00b4 2 C 2\u00b4  3 C 3\u00b4  4 C 5\u00b4  5 C 8\u00b4  6 C 13\u00b4  7 C 21\u00b4  8 C \ue001 \ue001 \ue001  ; \nwhere F i is the i th Fibonacci number. \na. Show that F .\u00b4/  D \u00b4 C \u00b4F .\u00b4/  C \u00b4 2 F .\u00b4/. 122  Chapter  4 Divide-and-Conquer  \nb. Show that \nF .\u00b4/  D \u00b4 \n1 \ue003 \u00b4 \ue003 \u00b4 2 \nD \u00b4 \n.1 \ue003 \ufffd\u00b4/.1  \ue003 y \ufffd\u00b4/  \nD 1 p \n5 \u00ce 1 \n1 \ue003 \ufffd\u00b4  \ue003 1 \n1 \ue003 y \ufffd\u00b4  \u00cf \n; \nwhere \ufffd is the golden ratio, and y \ufffd is its  conjugate  (see  page  69).  \nc. Show that \nF .\u00b4/  D 1  X  \ni D0 1 p \n5 .\ufffd  i \ue003 y \ufffd i /\u00b4 i : \nYou  may  use  without  proof  the  generating-function  version  of equation  (A.7)  on  \npage  1142,  P  1  \nkD0 x k D 1=.1  \ue003 x/. Because this equation involves a generating \nfunction, x is a formal  variable,  not  a real-valued  variable,  so that  you  don\u2019t  \nhave to worry about convergence of the summation or  about the requirement in \nequation  (A.7)  that  jx j <1, which  doesn\u2019t  make  sense  here.  \nd. Use part (c) to prove that F i D \ufffd i = p \n5 for i >0 , rounded to the nearest integer. \n(Hint: Observe  that  \u02c7 \u02c7 y \ufffd \u02c7 \u02c7 <1.) \ne. Prove that F i C2 \ue004 \ufffd i for i \ue004 0. \n4-6  Chip  testing  \nProfessor Diogenes has n supposedly  identical  integrated-circuit  chips  that  in prin-  \nciple  are  capable  of testing  each  other.  The  professor\u2019s  test jig accommodates two \nchips at a time. When the jig is loaded, each chip tests the other and reports whether \nit is good or bad. A good chip always reports accur ately whether the other chip is \ngood or bad, but the professor cannot trust the ans wer of a bad chip. Thus, the four \npossible outcomes of a test are as follows: \nChip A says Chip B says Conclusion \nB is good A is good both are good, or both are bad \nB is good A is bad at least one is bad \nB is bad A is good at least one is bad \nB is bad A is bad at least one is bad \na. Show that if at least n=2  chips  are  bad,  the  professor  cannot  necessarily  deter-  \nmine which chips are good using any strategy based on this kind of pairwise \ntest. Assume that the bad chips can conspire to foo l the professor. Problems for Chapter 4 123 \nNow you will design an algorithm to identify which chips are good and which are \nbad, assuming that more than n=2  of the chips are good. First, you will determine \nhow to identify one good chip. \nb. Show that bn=2c pairwise  tests  are  suf\u00fbcient  to reduce  the  problem  to one  of \nnearly half the size. That is, show how to use bn=2c pairwise tests to obtain a \nset with at most dn=2e chips that still has the property that more than ha lf of \nthe chips are good. \nc. Show how to apply the solution to part (b) recursiv ely to identify one good \nchip.  Give  and  solve  the  recurrence  that  describes  the  numbe r of tests needed \nto identify one good chip. \nYou have now determined how to identify one good ch ip. \nd. Show how to identify all the good chips with an add itional \u201a.n/  pairwise tests. \n4-7  Monge  arrays  \nAn m \ue005 n array A of real numbers is a Monge  array  if for all i , j , k, and l such \nthat 1 \u0dc4 i <k  \u0dc4 m and 1 \u0dc4 j <l  \u0dc4 n, we have \nA\u0152i; j \ufffd  C A\u0152k; l\ufffd  \u0dc4 A\u0152i; l\ufffd  C A\u0152k; j \ufffd :  \nIn other words, whenever we pick two rows and two c olumns of a Monge array and \nconsider the four elements at the intersections of the rows and the columns, the sum \nof the  upper-left  and  lower-right  elements  is less  than  or equal to the sum of the \nlower-left  and  upper-right  elements.  For  example,  the  following array is Monge: \n10  17  13  28  23  \n17  22  16  29  23  \n24  28  22  34  24  \n11  13  6 17  7 \n45  44  32  37  23  \n36  33  19  21  6 \n75  66  51  53  34  \na. Prove that an array is Monge if and only if for all  i D 1;2;:::;m  \ue003 1 and \nj D 1;2;:::;n  \ue003 1, we have \nA\u0152i; j \ufffd  C A\u0152i  C 1;j  C 1\ufffd \u0dc4 A\u0152i;j  C 1\ufffd C A\u0152i  C 1; j \ufffd :  \n(Hint: For the <if= part, use induction separately on rows  and columns.) \nb. The following array is not Monge. Change one elemen t in order to make it \nMonge. ( Hint: Use part (a).) 124  Chapter  4 Divide-and-Conquer  \n37  23  22  32  \n21  6 7 10  \n53  34  30  31  \n32  13  9 6 \n43  21  15  8 \nc. Let f.i/  be the index of the column containing the leftmost minimum element \nof row i . Prove that f.1/  \u0dc4 f.2/  \u0dc4 \ue001 \ue001 \ue001 \u0dc4  f.m/  for any m \ue005 n Monge array. \nd. Here  is a description  of a divide-and-conquer  algorithm  that  computes  the  left-  \nmost minimum element in each row of an m \ue005 n Monge array A: \nConstruct a submatrix A 0 of A consisting  of the  even-numbered  rows  of A. \nRecursively determine the leftmost minimum for each  row of A 0 . Then \ncompute  the  leftmost  minimum  in the  odd-numbered  rows  of A. \nExplain  how  to compute  the  leftmost  minimum  in the  odd-numbe red rows of A \n(given  that  the  leftmost  minimum  of the  even-numbered  rows  is known) in \nO.m  C n/ time. \ne. Write the recurrence for the running time of the al gorithm in part (d). Show \nthat its solution is O.m  C n log m/. \nChapter  notes  \nDivide-and-conquer  as a technique  for  designing  algorithm s dates back at least to \n1962  in an article  by  Karatsuba  and  Ofman  [242],  but  it might  have been used \nwell  before  then.  According  to Heideman,  Johnson,  and  Burrus  [211],  C. F. Gauss  \ndevised  the  \u00fbrst  fast  Fourier  transform  algorithm  in 1805,  and  Gauss\u2019s  formulation  \nbreaks the problem into smaller subproblems whose s olutions are combined. \nStrassen\u2019s  algorithm  [424]  caused  much  excitement  when  it appeared  in 1969.  \nBefore then, few imagined the possibility of an alg orithm asymptotically faster than \nthe basic M ATRIX-MULTIPLY procedure. Shortly thereafter, S. Winograd reduced \nthe  number  of submatrix  additions  from  18  to 15  while  still  using seven submatrix \nmultiplications. This improvement, which Winograd a pparently never published \n(and which is frequently miscited in the literature ), may enhance the practicality \nof the method, but it does not affect its asymptoti c performance.  Probert  [368]  \ndescribed  Winograd\u2019s  algorithm  and  showed  that  with  seven  multiplications,  15  \nadditions is the minimum possible. \nStrassen\u2019s  \u201a.n  lg 7 / D O.n  2:81  / bound  for  matrix  multiplication  held  until  1987,  \nwhen  Coppersmith  and  Winograd  [103]  made  a signi\u00fbcant  advan ce, improving the Notes for Chapter 4 125 \nbound to O.n  2:376  / time with a mathematically sophisticated but wildly  impracti- \ncal algorithm based on tensor products. It took app roximately 25  years  before  the  \nasymptotic  upper  bound  was  again  improved.  In 2012  Vassilevska  Williams  [445]  \nimproved it to O.n  2:37287  /, and  two  years  later  Le  Gall  [278]  achieved  O.n  2:37286  /, \nboth of them using mathematically fascinating but i mpractical algorithms. The best \nlower bound to date is just the obvious \ufffd.n  2 / bound  (obvious  because  any  algo-  \nrithm  for  matrix  multiplication  must  \u00fbll  in the  n 2 elements of the product matrix). \nThe performance of M ATRIX-MULTIPLY-RECURSIVE can  be improved  in prac-  \ntice by coarsening the leaves of the recursion. It also exhibits  better  cache  behav-  \nior than M ATRIX-MULTIPLY , although M ATRIX-MULTIPLY can be improved by \n<tiling.=  Leiserson  et al.  [293]  conducted  a performance-engineering  study  of ma-  \ntrix multiplication in which a parallel and vectori zed divide-and-conquer  algorithm  \nachieved  the  highest  performance.  Strassen\u2019s  algorithm  can be practical for large \ndense matrices, although large matrices tend to be sparse, and sparse methods can \nbe much  faster.  When  using  limited-precision  \u00fcoating-point  values,  Strassen\u2019s  al-  \ngorithm produces larger numerical errors than the \u201a.n  3 / algorithms do, although \nHigham  [215]  demonstrated  that  Strassen\u2019s  algorithm  is amply accurate for some \napplications. \nRecurrences  were  studied  as early  as 1202  by  Leonardo  Bonacci  [66],  also  \nknown as Fibonacci, for whom the Fibonacci numbers are named, although Indian \nmathematicians had discovered Fibonacci numbers cen turies before. The French \nmathematician  De  Moivre  [108]  introduced  the  method  of gene rating functions \nwith  which  he studied  Fibonacci  numbers  (see  Problem  4-5).  Knuth  [259]  and  \nLiu  [302]  are  good  resources  for  learning  the  method  of gener ating functions. \nAho,  Hopcroft,  and  Ullman  [5,  6] offered  one  of the  \u00fbrst  gener al methods for \nsolving  recurrences  arising  from  the  analysis  of divide-and-conquer  algorithms.  \nThe master method was adapted from Bentley, Haken, and Saxe [52].  The  Akra-  \nBazzi  method  is due  (unsurprisingly)  to Akra  and  Bazzi  [13].  Divide-and-conquer  \nrecurrences have been studied by many researchers, including  Campbell  [79],  Gra-  \nham,  Knuth,  and  Patashnik  [199],  Kuszmaul  and  Leiserson  [274],  Leighton  [287],  \nPurdom  and  Brown  [371],  Roura  [389],  Verma  [447],  and  Yap  [462]. \nThe  issue  of \u00fcoors  and  ceilings  in divide-and-conquer  recur rences, including a \ntheorem  similar  to Theorem  4.5,  was  studied  by  Leighton  [287].  Leighton  pro-  \nposed  a version  of the  polynomial-growth  condition.  Campbell  [79]  removed  sev-  \neral  limitations  in Leighton\u2019s  statement  of it and  showed  that  there  were  polyno-  \nmially  bounded  functions  that  do  not  satisfy  Leighton\u2019s  condition. Campbell also \ncarefully studied many other technical issues, incl uding the well-de\u00fbnedness  of \ndivide-and-conquer  recurrences.  Kuszmaul  and  Leiserson  [274]  provided  a proof  \nof Theorem  4.5  that  does  not  involve  calculus  or other  higher  math.  Both  Camp-  \nbell and Leighton explored the perturbations of arg uments beyond  simple  \u00fcoors  \nand ceilings. 5 Probabilistic  Analysis  and  Randomized  \nAlgorithms  \nThis chapter introduces probabilistic analysis and randomized algorithms. If you \nare unfamiliar with the basics of probability theor y, you should read Sections \nC.13C.4  of Appendix  C, which  review  this  material.  We\u2019ll  revisit probabilistic \nanalysis and randomized algorithms several times th roughout this book. \n5.1  The  hiring  problem  \nSuppose  that  you  need  to hire  a new  of\u00fbce  assistant.  Your  previous attempts at \nhiring have been unsuccessful, and you decide to us e an employment agency. The \nemployment agency sends you one candidate each day.  You interview that person \nand then decide either to hire that person or not. You must pay the employment \nagency a small fee to interview an applicant. To ac tually hire an applicant is more \ncostly,  however,  since  you  must  \u00fbre  your  current  of\u00fbce  assis tant and also pay a \nsubstantial hiring fee to the employment agency. Yo u are committed to having, at \nall times, the best possible person for the job. Th erefore, you decide that, after \ninterviewing each applicant, if that applicant is b etter quali\u00fbed  than  the  current  \nof\u00fbce  assistant,  you  will  \u00fbre  the  current  of\u00fbce  assistant  and hire the new applicant. \nYou are willing to pay the resulting price of this strategy, but you wish to estimate \nwhat that price will be. \nThe procedure H IRE-ASSISTANT on the facing page expresses this strategy for \nhiring  in pseudocode.  The  candidates  for  the  of\u00fbce  assistan t job are numbered 1 \nthrough n and interviewed in that order. The procedure assume s that after  inter-  \nviewing candidate i , you can determine whether candidate i is the best candidate \nyou have seen so far. It starts by creating a dummy  candidate, numbered 0, who is \nless  quali\u00fbed  than  each  of the  other  candidates.  \nThe cost model for this problem differs from the mo del described in Chapter 2. \nWe focus not on the running time of H IRE-ASSISTANT , but instead on the fees paid \nfor  interviewing  and  hiring.  On  the  surface,  analyzing  the  cost of this algorithm 5.1 The hiring problem 127 \nHIRE-ASSISTANT .n/  \n1 best D 0 / / candidate  0 is a least-quali\u00fbed  dummy  candidate  \n2 for  i D 1 to n \n3 interview candidate i \n4 if candidate i is better than candidate best \n5 best D i \n6 hire candidate i \nmay seem very different from analyzing the running time of, say, merge sort. The \nanalytical techniques used, however, are identical whether we are analyzing cost \nor running time. In either case, we are counting th e number of times certain basic \noperations are executed. \nInterviewing has a low cost, say c i , whereas hiring is expensive, costing c h . Let-  \nting m be the number of people hired, the total cost assoc iated with this algorithm \nis O.c  i n C c h m/. No matter how many people you hire, you always in terview n \ncandidates and thus always incur the cost c i n associated with interviewing. We \ntherefore concentrate on analyzing c h m, the hiring cost. This quantity depends on \nthe order in which you interview candidates. \nThis scenario serves as a model for a common comput ational paradigm.  Al-  \ngorithms  often  need  to \u00fbnd  the  maximum  or minimum  value  in a sequence by \nexamining each element of the sequence and maintain ing a current <winner.= The \nhiring problem models how often a procedure updates  its notion of which element \nis currently winning. \nWorst-case  analysis  \nIn the worst case, you actually hire every candidat e that you interview.  This  situa-  \ntion occurs if the candidates come in strictly incr easing order of quality, in which \ncase you hire n times, for a total hiring cost of O.c  h n/. \nOf  course,  the  candidates  do  not  always  come  in increasing  order of quality. In \nfact, you have no idea about the order in which the y arrive, nor do you have any \ncontrol over this order. Therefore, it is natural t o ask what we expect to happen in \na typical or average case. \nProbabilistic  analysis  \nProbabilistic  analysis  is the use of probability in the analysis of proble ms. Most \ncommonly, we use probabilistic analysis to analyze the running  time  of an algo-  \nrithm. Sometimes we use it to analyze other quantit ies, such as the hiring cost in 128  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nprocedure H IRE-ASSISTANT . In order to perform a probabilistic analysis, we must \nuse knowledge of, or make assumptions about, the di stribution of the inputs. Then \nwe  analyze  our  algorithm,  computing  an average-case  runnin g time, where we take \nthe average, or expected value, over the distributi on of the possible inputs. When \nreporting such a running time, we refer to it as th e average-case  running  time. \nYou must be careful in deciding on the distribution  of inputs. For some problems, \nyou may reasonably assume something about the set o f all possible inputs, and \nthen you can use probabilistic analysis as a techni que for designing  an ef\u00fbcient  \nalgorithm and as a means for gaining insight into a  problem. For other problems, \nyou cannot characterize a reasonable input distribu tion, and in these cases you \ncannot use probabilistic analysis. \nFor the hiring problem, we can assume that the appl icants come in a random \norder.  What  does  that  mean  for  this  problem?  We  assume  that  you can compare \nany  two  candidates  and  decide  which  one  is better  quali\u00fbed,  which is to say that \nthere is a total order on the candidates. (See Sect ion B.2 for the  de\u00fbnition  of a total  \norder.) Thus, you can rank each candidate with a un ique number from 1 through n, \nusing rank.i/  to denote the rank of applicant i , and adopt the convention that a \nhigher  rank  corresponds  to a better  quali\u00fbed  applicant.  The  ordered list hrank.1/;  \nrank.2/;:::;  rank.n/i is a permutation of the list h1;2;:::;n i. Saying that the \napplicants come in a random order is equivalent to saying that this list of ranks is \nequally likely to be any one of the n\u0160 permutations of the numbers 1 through n. \nAlternatively, we say that the ranks form a uniform  random  permutation , that is, \neach of the possible n\u0160 permutations appears with equal probability. \nSection  5.2  contains  a probabilistic  analysis  of the  hiring  problem. \nRandomized  algorithms  \nIn order to use probabilistic analysis, you need to  know something  about  the  dis-  \ntribution of the inputs. In many cases, you know li ttle about the  input  distribu-  \ntion. Even if you do know something about the distr ibution, you might not be able \nto model this knowledge computationally. Yet, proba bility and randomness often \nserve as tools for algorithm design and analysis, b y making part of the algorithm \nbehave randomly. \nIn the hiring problem, it may seem as if the candid ates are being presented to \nyou in a random order, but you have no way of knowi ng whether they really are. \nThus, in order to develop a randomized algorithm fo r the hiring problem, you need \ngreater  control  over  the  order  in which  you\u2019ll  interview  the  candidates. We will, \ntherefore, change the model slightly. The employmen t agency sends you a list of \nthe n candidates  in advance.  On  each  day,  you  choose,  randomly,  which  candi-  \ndate to interview. Although you know nothing about the candidates (besides their \nnames),  we  have  made  a signi\u00fbcant  change.  Instead  of accepti ng the order given 5.1 The hiring problem 129 \nto you  by  the  employment  agency  and  hoping  that  it\u2019s  random,  you have instead \ngained control of the process and enforced a random  order. \nMore generally, we call an algorithm randomized  if its behavior is determined \nnot only by its input but also by values produced b y a random-number  generator . \nWe  assume  that  we  have  at our  disposal  a random-number  genera tor RANDOM . \nA call to R ANDOM.a;b/  returns an integer between a and b, inclusive, with each \nsuch integer being equally likely. For example, R ANDOM.0;1/  produces 0 with \nprobability 1=2, and it produces 1 with probability 1=2. A call to R ANDOM.3;7/  \nreturns any one of 3, 4, 5, 6, or 7, each with probability 1=5. Each integer returned \nby RANDOM  is independent of the integers returned on previous  calls. You may \nimagine R ANDOM  as rolling a .b \ue003 a C 1/-sided  die  to obtain  its  output.  (In  prac-  \ntice, most programming environments offer a pseudorandom-number  generator : \na deterministic algorithm returning numbers that <l ook= statistically random.) \nWhen analyzing the running time of a randomized alg orithm, we take  the  expec-  \ntation of the running time over the distribution of  values returned by the random \nnumber generator. We distinguish these algorithms f rom those in which the input \nis random by referring to the running time of a ran domized algorithm as an ex-  \npected  running  time. In general,  we  discuss  the  average-case  running  time  when  \nthe probability distribution is over the inputs to the algorithm, and we discuss the \nexpected running time when the algorithm itself mak es random choices. \nExercises  \n5.1-1  \nShow that the assumption that you are always able t o determine which candidate is \nbest,  in line  4 of procedure  HIRE-ASSISTANT , implies that you know a total order \non the ranks of the candidates. \n? 5.1-2  \nDescribe an implementation of the procedure R ANDOM.a;b/  that makes calls only \nto RANDOM.0;1/ . What is the expected running time of your procedu re, as a \nfunction of a and b? \n? 5.1-3  \nYou wish to implement a program that outputs 0 with probability 1=2  and 1 with \nprobability 1=2. At your disposal is a procedure B IASED-RANDOM  that outputs \neither 0 or 1, but it outputs 1 with some probability p and 0 with probability 1 \ue003 p, \nwhere 0 < p < 1 . You do not know what p is. Give  an algorithm  that  uses  \nBIASED-RANDOM  as a subroutine, and returns an unbiased answer, re turning 0 \nwith probability 1=2  and 1 with probability 1=2. What is the expected running \ntime of your algorithm as a function of p? 130  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \n5.2  Indicator  random  variables  \nIn order to analyze many algorithms, including the hiring problem, we use indicator \nrandom variables. Indicator random variables provid e a convenient method for \nconverting  between  probabilities  and  expectations.  Given  a sample space S and an \nevent A, the indicator  random  variable  I fAg associated with event A is de\u00fbned  as \nI fAg D  ( \n1 if A occurs ; \n0 if A does not occur : (5.1)  \nAs a simple example, let us determine the expected number of heads obtained \nwhen  \u00fcipping  a fair  coin.  The  sample  space  for  a single  coin  \u00fcip is S D fH;T  g, \nwith Pr fH g D  Pr fT g D  1=2. We  can  then  de\u00fbne  an indicator  random  vari-  \nable X H  , associated with the coin coming up heads, which i s the event H . This \nvariable  counts  the  number  of heads  obtained  in this  \u00fcip,  and  it is 1 if the coin \ncomes up heads and 0 otherwise. We write \nX H  D I fH g \nD ( \n1 if H occurs ; \n0 if T occurs : \nThe  expected  number  of heads  obtained  in one  \u00fcip  of the  coin  is simply  the  ex-  \npected value of our indicator variable X H  : \nE \u0152X  H  \ufffd D E \u0152I fH g\ufffd \nD 1 \ue001 Pr fH g C  0 \ue001 Pr fT g \nD 1 \ue001 .1=2/  C 0 \ue001 .1=2/  \nD 1=2:  \nThus  the  expected  number  of heads  obtained  by  one  \u00fcip  of a fair  coin is 1=2. As \nthe following lemma shows, the expected value of an  indicator random variable \nassociated with an event A is equal to the probability that A occurs. \nLemma  5.1  \nGiven  a sample  space  S and an event A in the sample space S , let X A D I fAg. \nThen E \u0152X  A \ufffd D Pr fAg. \nProof  By  the  de\u00fbnition  of an indicator  random  variable  from  equation  (5.1)  and  \nthe  de\u00fbnition  of expected  value,  we  have  \nE \u0152X  A \ufffd D E \u0152I fAg\ufffd \nD 1 \ue001 Pr fAg C  0 \ue001 Pr \u02da \nA \ue009 \nD Pr fAg ; 5.2  Indicator  random  variables  131 \nwhere A denotes S \ue003 A, the complement of A. \nAlthough indicator random variables may seem cumber some for an applica-  \ntion  such  as counting  the  expected  number  of heads  on  a \u00fcip  of a single coin, \nthey are useful for analyzing situations that perfo rm repeated random trials. In \nAppendix C, for example, indicator random variables  provide a simple way to \ndetermine the expected number of heads in n coin  \u00fcips.  One  option  is to con-  \nsider separately the probability of obtaining 0 heads, 1 head, 2 heads,  etc.  to ar-  \nrive  at the  result  of equation  (C.41)  on  page  1199.  Alternati  vely, we can employ \nthe  simpler  method  proposed  in equation  (C.42),  which  uses  indicator random \nvariables implicitly. Making this argument more exp licit, let X i be the indicator \nrandom variable associated with the event in which the i th \u00fcip  comes  up  heads:  \nX i D I fthe i th \u00fcip  results  in the  event  H g. Let X be the  random  variable  denot-  \ning the total number of heads in the n coin  \u00fcips,  so that  \nX D n X  \ni D1 X i : \nIn order to compute the expected number of heads, t ake the expectation of both \nsides of the above equation to obtain \nE \u0152X\ufffd  D E \" n X  \ni D1 X i # \n: (5.2)  \nBy  Lemma  5.1,  the  expectation  of each  of the  random  variables  is E \u0152X  i \ufffd D 1=2  for \ni D 1;2;:::;n . Then we can compute the sum of the expectations: P  n \ni D1 E \u0152X  i \ufffd D \nn=2. But  equation  (5.2)  calls  for  the  expectation  of the  sum,  not  the  sum  of the  ex-  \npectations.  How  can  we  resolve  this  conundrum?  Linearity  of expectation,  equa-  \ntion  (C.24)  on  page  1192,  to the  rescue:  the  expectation  of the  sum  always  equals  \nthe  sum  of the  expectations . Linearity of expectation applies even when there is \ndependence among the random variables. Combining in dicator random variables \nwith linearity of expectation gives us a powerful t echnique to compute expected \nvalues when multiple events occur. We now can compu te the expected number of \nheads: \nE \u0152X\ufffd  D E \" n X  \ni D1 X i # \nD n X  \ni D1 E \u0152X  i \ufffd \nD n X  \ni D1 1=2  \nD n=2:  132  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nThus,  compared  with  the  method  used  in equation  (C.41),  indicator  random  vari-  \nables greatly simplify the calculation. We use indi cator random  variables  through-  \nout this book. \nAnalysis  of the  hiring  problem  using  indicator  random  variables  \nReturning to the hiring problem, we now wish to com pute the expected number of \ntimes  that  you  hire  a new  of\u00fbce  assistant.  In order  to use  a probabilistic analysis, \nlet\u2019s  assume  that  the  candidates  arrive  in a random  order,  as discussed  in Sec-  \ntion  5.1.  (We\u2019ll  see  in Section  5.3  how  to remove  this  assumpt ion.) Let X be the \nrandom variable whose value equals the number of ti mes you hire a new  of\u00fbce  as-  \nsistant.  We  could  then  apply  the  de\u00fbnition  of expected  value  from  equation  (C.23)  \non  page  1192  to obtain  \nE \u0152X\ufffd  D n X  \nxD1 x Pr fX D x g ; \nbut  this  calculation  would  be cumbersome.  Instead,  let\u2019s  simplify the calculation \nby using indicator random variables. \nTo use indicator random variables, instead of compu ting E \u0152X\ufffd  by  de\u00fbning  just  \none  variable  denoting  the  number  of times  you  hire  a new  of\u00fbce  assistant, think \nof the  process  of hiring  as repeated  random  trials  and  de\u00fbne  n variables indicating \nwhether each particular candidate is hired. In part icular, let X i be the indicator \nrandom variable associated with the event in which the i th candidate is hired. Thus, \nX i D I fcandidate i is hired g \nD ( \n1 if candidate i is hired ; \n0 if candidate i is not hired ; \nand \nX D X 1 C X 2 C \ue001 \ue001 \ue001 C  X n : (5.3)  \nLemma  5.1  gives  \nE \u0152X  i \ufffd D Pr fcandidate i is hired g ; \nand  we  must  therefore  compute  the  probability  that  lines  536  of H IRE-ASSISTANT \nare executed. \nCandidate i is hired,  in line  6, exactly  when  candidate  i is better than each of \ncandidates 1 through i \ue003 1. Because we have assumed that the candidates arriv e in \na random  order,  the  \u00fbrst  i candidates have appeared in a random order. Any one  of \nthese  \u00fbrst  i candidates  is equally  likely  to be the  best  quali\u00fbed  so far.  Candidate i \nhas a probability of 1=i  of being  better  quali\u00fbed  than  candidates  1 through i \ue003 1 \nand thus a probability of 1=i  of being  hired.  By  Lemma  5.1,  we  conclude  that  5.2  Indicator  random  variables  133 \nE \u0152X  i \ufffd D 1=i:  (5.4)  \nNow we can compute E \u0152X\ufffd: \nE \u0152X\ufffd  D E \" n X  \ni D1 X i # \n(by  equation  (5.3))  (5.5)  \nD n X  \ni D1 E \u0152X  i \ufffd (by  equation  (C.24),  linearity  of expectation)  \nD n X  \ni D1 1 \ni (by  equation  (5.4))  \nD ln n C O.1/  (by  equation  (A.9),  the  harmonic  series)  . (5.6)  \nEven though you interview n people, you actually hire only approximately ln n of \nthem, on average. We summarize this result in the f ollowing lemma. \nLemma  5.2  \nAssuming that the candidates are presented in a ran dom order, algorithm H IRE- \nASSISTANT has  an average-case  total  hiring  cost  of O.c  h ln n/. \nProof  The  bound  follows  immediately  from  our  de\u00fbnition  of the  hiring cost \nand  equation  (5.6),  which  shows  that  the  expected  number  of hires  is approxi-  \nmately ln n. \nThe  average-case  hiring  cost  is a signi\u00fbcant  improvement  over  the  worst-case  \nhiring cost of O.c  h n/. \nExercises  \n5.2-1  \nIn H IRE-ASSISTANT, assuming  that  the  candidates  are  presented  in a random  or-  \nder,  what  is the  probability  that  you  hire  exactly  one  time?  What is the probability \nthat you hire exactly n times?  \n5.2-2  \nIn H IRE-ASSISTANT, assuming  that  the  candidates  are  presented  in a random  or-  \nder,  what  is the  probability  that  you  hire  exactly  twice?  \n5.2-3  \nUse indicator random variables to compute the expec ted value of the sum of n dice. 134  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \n5.2-4  \nThis exercise asks you to (partly) verify that line arity of expectation holds even \nif the random variables are not independent. Consid er two 6-sided  dice  that  are  \nrolled  independently.  What  is the  expected  value  of the  sum?  Now consider the \ncase  where  the  \u00fbrst  die  is rolled  normally  and  then  the  second  die is set equal to the \nvalue  shown  on  the  \u00fbrst  die.  What  is the  expected  value  of the  sum?  Now  consider  \nthe  case  where  the  \u00fbrst  die  is rolled  normally  and  the  second  die is set equal to 7 \nminus  the  value  of the  \u00fbrst  die.  What  is the  expected  value  of the  sum?  \n5.2-5  \nUse indicator random variables to solve the followi ng problem, which is known as \nthe hat-check  problem . Each of n customers  gives  a hat  to a hat-check  person  at a \nrestaurant.  The  hat-check  person  gives  the  hats  back  to the  customers in a random \norder. What is the expected number of customers who  get back their  own  hat?  \n5.2-6  \nLet A\u01521  W n\ufffd be an array of n distinct numbers. If i <j  and A\u0152i\ufffd > A\u0152j \ufffd , then the \npair .i;j/  is called an inversion  of A. (See  Problem  2-4  on  page  47  for  more  on  \ninversions.) Suppose that the elements of A form a uniform random permutation \nof h1;2;:::;n i. Use indicator random variables to compute the exp ected number \nof inversions. \n5.3  Randomized  algorithms  \nIn the previous section, we showed how knowing a di stribution on the inputs can \nhelp  us to analyze  the  average-case  behavior  of an algorithm . What if you do \nnot  know  the  distribution?  Then  you  cannot  perform  an average-case  analysis.  \nAs  mentioned  in Section  5.1,  however,  you  might  be able  to use  a randomized \nalgorithm. \nFor a problem such as the hiring problem, in which it is helpful to assume that \nall permutations of the input are equally likely, a  probabilistic analysis can guide \nus when developing a randomized algorithm. Instead of assuming  a distribution \nof inputs, we impose a distribution. In particular, before running the a lgorithm, \nlet\u2019s  randomly  permute  the  candidates  in order  to enforce  the property that every \npermutation  is equally  likely.  Although  we  have  modi\u00fbed  the  algorithm, we still \nexpect  to hire  a new  of\u00fbce  assistant  approximately  ln n times. But now we expect \nthis to be the case for any  input, rather than for inputs drawn from a particul ar \ndistribution. \nLet us further explore the distinction between prob abilistic analysis  and  ran-  \ndomized  algorithms.  In Section  5.2,  we  claimed  that,  assumi ng that the candidates 5.3  Randomized  algorithms  135 \narrive in a random order, the expected number of ti mes you hire a new  of\u00fbce  as-  \nsistant is about ln n. This algorithm is deterministic: for any particul ar input, the \nnumber  of times  a new  of\u00fbce  assistant  is hired  is always  the  same. Furthermore, \nthe  number  of times  you  hire  a new  of\u00fbce  assistant  differs  for  different inputs, \nand it depends on the ranks of the various candidat es. Since this number depends \nonly on the ranks of the candidates, to represent a  particular input, we can just \nlist, in order, the ranks hrank.1/;  rank.2/;:::;  rank.n/i of the  candidates.  Given  \nthe rank list A 1 D h1;2;3;4;5;6;7;8;9;10 i, a new  of\u00fbce  assistant  is always  \nhired 10  times, since each successive candidate is better th an the previous one, and \nlines  536  of HIRE-ASSISTANT are  executed  in each  iteration.  Given  the  list  of \nranks A 2 D h10;9;8;7;6;5;4;3;2;1 i, a new  of\u00fbce  assistant  is hired  only  once,  \nin the  \u00fbrst  iteration.  Given  a list  of ranks  A 3 D h5;2;1;8;4;7;10;9;3;6 i, a new \nof\u00fbce  assistant  is hired  three  times,  upon  interviewing  the  candidates with ranks 5, \n8, and 10. Recalling that the cost of our algorithm depends on how many times \nyou  hire  a new  of\u00fbce  assistant,  we  see  that  there  are  expensiv e inputs such as A 1 , \ninexpensive inputs such as A 2 , and moderately expensive inputs such as A 3 . \nConsider,  on  the  other  hand,  the  randomized  algorithm  that  \u00fbrst permutes the list \nof candidates and then determines the best candidat e. In this case, we randomize in \nthe  algorithm,  not  in the  input  distribution.  Given  a partic ular input, say A 3 above, \nwe cannot say how many times the maximum is updated , because this quantity \ndiffers  with  each  run  of the  algorithm.  The  \u00fbrst  time  you  run  the algorithm on A 3 , \nit might produce the permutation A 1 and perform 10  updates. But the second \ntime you run the algorithm, it might produce the pe rmutation A 2 and perform only \none update. The third time you run the algorithm, i t might perform some other \nnumber of updates. Each time you run the algorithm,  its execution depends on \nthe random choices made and is likely to differ fro m the previous execution of the \nalgorithm. For this algorithm and many other random ized algorithms, no  particular  \ninput  elicits  its  worst-case  behavior . Even your worst enemy cannot produce a \nbad input array, since the random permutation makes  the input order irrelevant. \nThe  randomized  algorithm  performs  badly  only  if the  random- number generator \nproduces an <unlucky= permutation. \nFor the hiring problem, the only change needed in t he code is to randomly  per-  \nmute the array, as done in the R ANDOMIZED -HIRE-ASSISTANT procedure. This \nsimple change creates a randomized algorithm whose performance matches that \nobtained by assuming that the candidates were prese nted in a random order. \nRANDOMIZED -HIRE-ASSISTANT .n/  \n1 randomly permute the list of candidates \n2 HIRE-ASSISTANT .n/  136  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nLemma  5.3  \nThe expected hiring cost of the procedure R ANDOMIZED -HIRE-ASSISTANT is \nO.c  h ln n/. \nProof  Permuting the input array achieves a situation iden tical to that  of the  prob-  \nabilistic analysis of H IRE-ASSISTANT in Section  5.2.  \nBy  carefully  comparing  Lemmas  5.2  and  5.3,  you  can  see  the  difference between \nprobabilistic  analysis  and  randomized  algorithms.  Lemma  5.2  makes  an assump-  \ntion  about  the  input.  Lemma  5.3  makes  no  such  assumption,  although randomizing \nthe input takes some additional time. To remain con sistent with our terminology, \nwe  couched  Lemma  5.2  in terms  of the  average-case  hiring  cost  and  Lemma  5.3  in \nterms of the expected hiring cost. In the remainder  of this section, we discuss some \nissues involved in randomly permuting inputs. \nRandomly  permuting  arrays  \nMany randomized algorithms randomize the input by p ermuting a given  input  ar-  \nray.  We\u2019ll  see  elsewhere  in this  book  other  ways  to randomize  an algorithm, but \nnow,  let\u2019s  see  how  we  can  randomly  permute  an array  of n elements. The goal is \nto produce a uniform  random  permutation , that is, a permutation that is as likely \nas any other permutation. Since there are n\u0160 possible permutations, we want the \nprobability that any particular permutation is prod uced to be 1=n\u0160 . \nYou might think that to prove that a permutation is  a uniform random  permuta-  \ntion,  it suf\u00fbces  to show  that,  for  each  element  A\u0152i\ufffd, the probability that the element \nwinds up in position j is 1=n. Exercise  5.3-4  shows  that  this  weaker  condition  is, \nin fact,  insuf\u00fbcient.  \nOur  method  to generate  a random  permutation  permutes  the  array in place : at \nmost a constant number of elements of the input arr ay are ever stored outside the \narray. The procedure R ANDOMLY-PERMUTE permutes an array A\u01521  W n\ufffd in place in \n\u201a.n/  time. In its i th iteration, it chooses the element A\u0152i\ufffd  randomly from among \nelements A\u0152i\ufffd  through A\u0152n\ufffd. After the i th iteration, A\u0152i\ufffd  is never altered. \nRANDOMLY-PERMUTE .A;n/  \n1 for  i D 1 to n \n2 swap A\u0152i\ufffd  with A\u0152RANDOM .i; n/\ufffd  \nWe use a loop invariant to show that procedure R ANDOMLY-PERMUTE produces \na uniform random permutation. A k-permutation  on a set of n elements  is a se-  5.3  Randomized  algorithms  137 \nquence containing k of the n elements,  with  no  repetitions.  (See  page  1180  in \nAppendix C.) There are n\u0160=.n  \ue003 k/\u0160  such possible k-permutations.  \nLemma  5.4  \nProcedure R ANDOMLY-PERMUTE computes a uniform random permutation. \nProof  We use the following loop invariant: \nJust  prior  to the  i th iteration of the for  loop  of lines  132,  for  each  possible  \n.i \ue003 1/-permutation  of the  n elements, the subarray A\u01521  W i \ue003 1\ufffd contains this \n.i \ue003 1/-permutation  with  probability  .n \ue003 i C 1/\u0160=n\u0160 . \nWe  need  to show  that  this  invariant  is true  prior  to the  \u00fbrst  loop iteration, that each \niteration of the loop maintains the invariant, that  the loop terminates, and that the \ninvariant provides a useful property to show correc tness when the loop terminates. \nInitialization:  Consider  the  situation  just  before  the  \u00fbrst  loop  iteration,  so that \ni D 1. The loop invariant says that for each possible 0-permutation,  the  sub-  \narray A\u01521  W 0\ufffd contains this 0-permutation  with  probability  .n \ue003 i C 1/\u0160=n\u0160  D \nn\u0160=n\u0160  D 1. The subarray A\u01521  W 0\ufffd is an empty subarray, and a 0-permutation  has  \nno elements. Thus, A\u01521  W 0\ufffd contains any 0-permutation  with  probability  1, and \nthe  loop  invariant  holds  prior  to the  \u00fbrst  iteration.  \nMaintenance:  By the loop invariant, we assume that just before t he i th iteration, \neach possible .i \ue003 1/-permutation  appears  in the  subarray  A\u01521  W i \ue003 1\ufffd with  prob-  \nability .n \ue003 i C 1/\u0160=n\u0160 . We shall show that after the i th iteration, each possible \ni -permutation  appears  in the  subarray  A\u01521  W i\ufffd with probability .n \ue003 i/\u0160=n\u0160. In-  \ncrementing i for the next iteration then maintains the loop inva riant. \nLet us examine the i th iteration. Consider a particular i -permutation,  and  de-  \nnote the elements in it by hx 1 ;x  2 ;:::;x  i i. This permutation consists of an \n.i \ue003 1/-permutation  hx 1 ;:::;x  i \ue0021 i followed by the value x i that the algorithm \nplaces in A\u0152i\ufffd. Let E 1 denote  the  event  in which  the  \u00fbrst  i \ue003 1 iterations have \ncreated the particular .i \ue003 1/-permutation  hx 1 ;:::;x  i \ue0021 i in A\u01521  W i \ue003 1\ufffd. By \nthe loop invariant, Pr fE 1 g D  .n \ue003 i C 1/\u0160=n\u0160 . Let E 2 be the event that the \ni th iteration puts x i in position A\u0152i\ufffd. The i -permutation  hx 1 ;:::;x  i i appears \nin A\u01521  W i\ufffd precisely when both E 1 and E 2 occur, and so we wish to compute \nPr fE 2 \\ E 1 g. Using  equation  (C.16)  on  page  1187,  we  have  \nPr fE 2 \\ E 1 g D  Pr fE 2 j E 1 g Pr fE 1 g : \nThe probability Pr fE 2 j E 1 g equals 1=.n\ue003i C1/ because in line 2 the algorithm \nchooses x i randomly from the n \ue003 i C 1 values in positions A\u0152i  W n\ufffd. Thus, we \nhave 138  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nPr fE 2 \\ E 1 g D  Pr fE 2 j E 1 g Pr fE 1 g \nD 1 \nn \ue003 i C 1 \ue001 .n \ue003 i C 1/\u0160  \nn\u0160 \nD .n \ue003 i/\u0160  \nn\u0160 : \nTermination:  The loop terminates, since it is a for  loop iterating n times. At \ntermination, i D n C 1, and we have that the subarray A\u01521  W n\ufffd is a given \nn-permutation  with  probability  .n \ue003 .n C 1/ C 1/\u0160=n\u0160  D 0\u0160=n\u0160  D 1=n\u0160 . \nThus, RANDOMLY-PERMUTE produces a uniform random permutation. \nA randomized  algorithm  is often  the  simplest  and  most  ef\u00fbcie nt way to solve a \nproblem. \nExercises  \n5.3-1  \nProfessor Marceau objects to the loop invariant use d in the proof  of Lemma  5.4.  He  \nquestions  whether  it holds  prior  to the  \u00fbrst  iteration.  He  reasons that we could just \nas easily declare that an empty subarray contains n o 0-permutations.  Therefore,  \nthe probability that an empty subarray contains a 0-permutation  should  be 0, thus \ninvalidating  the  loop  invariant  prior  to the  \u00fbrst  iteration . Rewrite the procedure \nRANDOMLY-PERMUTE so that its associated loop invariant applies to a nonempty \nsubarray  prior  to the  \u00fbrst  iteration,  and  modify  the  proof  of Lemma  5.4  for  your  \nprocedure. \n5.3-2  \nProfessor  Kelp  decides  to write  a procedure  that  produces  at random  any  permu-  \ntation except the identity  permutation , in which every element ends up where it \nstarted. He proposes the procedure P ERMUTE-WITHOUT-I DENTITY . Does this \nprocedure  do  what  Professor  Kelp  intends?  \nPERMUTE-WITHOUT-I DENTITY .A;n/  \n1 for  i D 1 to n \ue003 1 \n2 swap A\u0152i\ufffd  with A\u0152RANDOM.i C 1; n/\ufffd  \n5.3-3  \nConsider the P ERMUTE-WITH-ALL procedure on the facing page, which instead \nof swapping element A\u0152i\ufffd  with a random element from the subarray A\u0152i  W n\ufffd, swaps \nit with a random element from anywhere in the array . Does P ERMUTE-WITH-ALL \nproduce  a uniform  random  permutation?  Why  or why  not?  5.3  Randomized  algorithms  139 \nPERMUTE-WITH-ALL .A;n/  \n1 for  i D 1 to n \n2 swap A\u0152i\ufffd  with A\u0152RANDOM .1; n/\ufffd  \n5.3-4  \nProfessor  Knievel  suggests  the  procedure  PERMUTE-BY-CYCLE to generate  a uni-  \nform random permutation. Show that each element A\u0152i\ufffd  has a 1=n  probability of \nwinding up in any particular position in B . Then  show  that  Professor  Knievel  is \nmistaken by showing that the resulting permutation is not uniformly random. \nPERMUTE-BY-CYCLE .A;n/  \n1 let B\u01521  W n\ufffd be a new array \n2 offset D RANDOM.1;n/  \n3 for  i D 1 to n \n4 dest D i C offset \n5 if dest >n  \n6 dest D dest \ue003 n \n7 B\u0152dest \ufffd D A\u0152i\ufffd  \n8 return  B \n5.3-5  \nProfessor  Gallup  wants  to create  a random  sample  of the set f1;2;3;:::;n g, that \nis, an m-element  subset  S , where 0 \u0dc4 m \u0dc4 n, such that each m-subset  is equally  \nlikely  to be created.  One  way  is to set  A\u0152i\ufffd  D i , for i D 1;2;3;:::;n , call \nRANDOMLY-PERMUTE .A/, and  then  take  just  the  \u00fbrst  m array elements. This \nmethod makes n calls to the R ANDOM  procedure.  In Professor  Gallup\u2019s  applica-  \ntion, n is much larger than m, and so the professor wants to create a random sam ple \nwith fewer calls to R ANDOM . \nRANDOM-SAMPLE .m;n/  \n1 S D ;  \n2 for  k D n \ue003 m C 1 to n / / iterates m times \n3 i D RANDOM.1;k/  \n4 if i 2 S \n5 S D S [ fkg \n6 else  S D S [ fi g \n7 return  S 140  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nShow that the procedure R ANDOM-SAMPLE on  the  previous  page  returns  a ran-  \ndom m-subset  S of f1;2;3;:::;n g, in which each m-subset  is equally  likely,  while  \nmaking only m calls to RANDOM . \n? 5.4  Probabilistic  analysis  and  further  uses  of indicator  random  variables  \nThis advanced section further illustrates probabili stic analysis  by  way  of four  ex-  \namples.  The  \u00fbrst  determines  the  probability  that  in a room  of k people, two of them \nshare the same birthday. The second example examine s what happens  when  ran-  \ndomly tossing balls into bins. The third investigat es <streaks= of consecutive heads \nwhen  \u00fcipping  coins.  The  \u00fbnal  example  analyzes  a variant  of the hiring problem in \nwhich you have to make decisions without actually i nterviewing all the candidates. \n5.4.1  The  birthday  paradox  \nOur  \u00fbrst  example  is the  birthday  paradox . How many people must there be in a \nroom before there is a 50% chance that two of them were born on the same day  of \nthe  year?  The  answer  is surprisingly  few.  The  paradox  is that  it is in fact far fewer \nthan the number of days in a year, or even half the  number of days in a year, as we \nshall see. \nTo answer this question, we index the people in the  room with the integers \n1;2;:::;k , where k is the number of people in the room. We ignore the issue \nof leap years and assume that all years have n D 365  days. For i D 1;2;:::;k , \nlet b i be the day of the year on which person i \u2019s birthday  falls,  where  1 \u0dc4 b i \u0dc4 n. \nWe also assume that birthdays are uniformly distrib uted across the n days of the \nyear, so that Pr fb i D r g D  1=n  for i D 1;2;:::;k  and r D 1;2;:::;n . \nThe probability that two given people, say i and j , have matching birthdays \ndepends on whether the random selection of birthday s is independent. We assume \nfrom now on that birthdays are independent, so that  the probability that i \u2019s birthday  \nand j \u2019s birthday  both  fall  on  day  r is \nPr fb i D r and b j D r g D  Pr fb i D r g Pr fb j D r g \nD 1 \nn 2 : \nThus, the probability that they both fall on the sa me day is \nPr fb i D b j g D  n X  \nr D1 Pr fb i D r and b j D r g 5.4  Probabilistic  analysis  and  further  uses  of indicator  random variables 141 \nD n X  \nr D1 1 \nn 2 \nD 1 \nn : (5.7)  \nMore intuitively, once b i is chosen, the probability that b j is chosen to be the same \nday is 1=n. As long as the birthdays are independent, the pro bability that i and j \nhave the same birthday is the same as the probabili ty that the birthday of one of \nthem falls on a given day. \nWe can analyze the probability of at least 2 out of k people having matching \nbirthdays by looking at the complementary event. Th e probability that at least two \nof the birthdays match is 1 minus the probability that all the birthdays are di fferent. \nThe event B k that k people have distinct birthdays is \nB k D k \\  \ni D1 A i ; \nwhere A i is the event that person i \u2019s birthday  is different  from  person  j \u2019s for  \nall j <i  . Since we can write B k D A k \\ B k\ue0021 , we  obtain  from  equation  (C.18)  \non  page  1189  the  recurrence  \nPr fB k g D  Pr fB k\ue0021 g Pr fA k j B k\ue0021 g ; (5.8)  \nwhere we take Pr fB 1 g D  Pr fA 1 g D  1 as an initial condition. In other words, \nthe probability that b 1 ;b  2 ;:::;b  k are distinct birthdays equals the probability that \nb 1 ;b  2 ;:::;b  k\ue0021 are distinct birthdays multiplied by the probabilit y that b k \u00a4 b i \nfor i D 1;2;:::;k  \ue003 1, given that b 1 ;b  2 ;:::;b  k\ue0021 are distinct. \nIf b 1 ;b  2 ;:::;b  k\ue0021 are distinct, the conditional probability that b k \u00a4 b i for \ni D 1;2;:::;k  \ue003 1 is Pr fA k j B k\ue0021 g D  .n \ue003 k C 1/=n , since out of the n days, \nn \ue003 .k \ue003 1/ days  are  not  taken.  We  iteratively  apply  the  recurrence  (5.8) to obtain \nPr fB k g D  Pr fB k\ue0021 g Pr fA k j B k\ue0021 g \nD Pr fB k\ue0022 g Pr fA k\ue0021 j B k\ue0022 g Pr fA k j B k\ue0021 g \n: : : \nD Pr fB 1 g Pr fA 2 j B 1 g Pr fA 3 j B 2 g \ue001 \ue001 \ue001  Pr fA k j B k\ue0021 g \nD 1 \ue001 \u00ce n \ue003 1 \nn \u00cf\u00ce  n \ue003 2 \nn \u00cf \n\ue001 \ue001 \ue001  \u00ce n \ue003 k C 1 \nn \u00cf \nD 1 \ue001 \u00ce \n1 \ue003 1 \nn \u00cf\u00ce  \n1 \ue003 2 \nn \u00cf \n\ue001 \ue001 \ue001  \u00ce \n1 \ue003 k \ue003 1 \nn \u00cf \n: \nInequality  (3.14)  on  page  66,  1 C x \u0dc4 e x , gives us 142  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nPr fB k g \u0dc4  e \ue0021=n  e \ue0022=n  \ue001 \ue001 \ue001  e \ue002.k\ue0021/=n  \nD e \ue002 P  k\ue0031 \ni D1 i=n  \nD e \ue002k.k\ue0021/=2n  \n\u0dc4 1 \n2 \nwhen \ue003k.k  \ue003 1/=2n  \u0dc4 ln.1=2/ . The probability that all k birthdays are distinct \nis at most 1=2  when k.k  \ue003 1/ \ue004 2n  ln 2 or, solving the quadratic equation, when \nk \ue004 .1 C p \n1 C .8 ln 2/n/=2 . For n D 365, we must have k \ue004 23. Thus, if at \nleast  23  people  are  in a room,  the  probability  is at least  1=2  that at least two people \nhave  the  same  birthday.  Since  a year  on  Mars  is 669  Martian  days long, it takes 31  \nMartians to get the same effect. \nAn  analysis  using  indicator  random  variables  \nIndicator random variables afford a simpler but app roximate analysis  of the  birth-  \nday paradox. For each pair .i;j/  of the k people  in the  room,  de\u00fbne  the  indicator  \nrandom variable X ij , for 1 \u0dc4 i <j  \u0dc4 k, by \nX ij D I fperson i and person j have the same birthday g \nD ( \n1 if person i and person j have the same birthday ; \n0 otherwise : \nBy  equation  (5.7),  the  probability  that  two  people  have  matc hing birthdays is 1=n, \nand  thus  by  Lemma  5.1  on  page  130,  we  have  \nE \u0152X  ij \ufffd D Pr fperson i and person j have the same birthday g \nD 1=n:  \nLetting X be the random variable that counts the number of pa irs of individuals \nhaving the same birthday, we have \nX D k\ue0021 X  \ni D1 k X  \nj Di C1 X ij : \nTaking expectations of both sides and applying line arity of expectation, we obtain \nE \u0152X\ufffd  D E \" k\ue0021 X  \ni D1 k X  \nj Di C1 X ij # \nD k\ue0021 X  \ni D1 k X  \nj Di C1 E \u0152X  ij \ufffd 5.4  Probabilistic  analysis  and  further  uses  of indicator  random variables 143 \nD \ue001 \nk \n2 ! \n1 \nn \nD k.k  \ue003 1/ \n2n  : \nWhen k.k  \ue003 1/ \ue004 2n, therefore, the expected number of pairs of people  with the \nsame birthday is at least 1. Thus, if we have at least p \n2n  C 1 individuals in a room, \nwe can expect at least two to have the same birthda y. For n D 365, if k D 28, the \nexpected number of pairs with the same birthday is .28  \ue001 27/=.2  \ue001 365/  \ue002 1:0356 . \nThus,  with  at least  28  people,  we  expect  to \u00fbnd  at least  one  matching  pair  of birth-  \ndays.  On  Mars,  with  669  days per year, we need at least 38  Martians. \nThe  \u00fbrst  analysis,  which  used  only  probabilities,  determined  the  number  of peo-  \nple required for the probability to exceed 1=2  that a matching pair of birthdays \nexists, and the second analysis, which used indicat or random variables, determined \nthe number such that the expected number of matchin g birthdays is 1. Although \nthe exact numbers of people differ for the two situ ations, they are  the  same  asymp-  \ntotically: \u201a.  p n/. \n5.4.2  Balls  and  bins  \nConsider a process in which you randomly toss ident ical balls into b bins,  num-  \nbered 1;2;:::;b . The tosses are independent, and on each toss the ball is equally \nlikely to end up in any bin. The probability that a  tossed ball lands in any given bin \nis 1=b. If we  view  the  ball-tossing  process  as a sequence  of Bernoul li trials (see \nAppendix  C.4),  where  success  means  that  the  ball  falls  in the  given bin, then each \ntrial has a probability 1=b  of success.  This  model  is particularly  useful  for  analyz-  \ning  hashing  (see  Chapter  11),  and  we  can  answer  a variety  of interesting questions \nabout  the  ball-tossing  process.  (Problem  C-2  asks  addition al questions about balls \nand bins.) \n\ue001 How  many  balls  fall  in a given  bin?  The number of balls that fall in a given \nbin follows the binomial distribution b.kI n;1=b/ . If you toss n balls,  equa-  \ntion  (C.41)  on  page  1199  tells  us that  the  expected  number  of balls that fall in \nthe given bin is n=b. \n\ue001 How  many  balls  must  you  toss,  on  the  average,  until  a given  bin  contains  a ball?  \nThe number of tosses until the given bin receives a  ball follows the geometric \ndistribution with probability 1=b  and,  by  equation  (C.36)  on  page  1197,  the  \nexpected number of tosses until success is 1=.1=b/  D b. \n\ue001 How  many  balls  must  you  toss  until  every  bin  contains  at least  one  ball?  Let us \ncall a toss in which a ball falls into an empty bin  a <hit.= We want to know the \nexpected number n of tosses required to get b hits. 144  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nUsing the hits, we can partition the n tosses into stages. The i th stage consists \nof the tosses after the .i \ue003 1/st hit up to and including the i th hit.  The  \u00fbrst  stage  \nconsists  of the  \u00fbrst  toss,  since  you  are  guaranteed  to have  a hit when all bins are \nempty. For each toss during the i th stage, i \ue003 1 bins contain balls and b \ue003 i C 1 \nbins are empty. Thus, for each toss in the i th stage, the probability of obtaining \na hit is .b \ue003 i C 1/=b . \nLet n i denote the number of tosses in the i th stage. The number of tosses \nrequired to get b hits is n D P  b \ni D1 n i . Each random variable n i has  a ge-  \nometric distribution with probability of success .b \ue003 i C 1/=b  and thus, by \nequation  (C.36),  we  have  \nE \u0152n i \ufffd D b \nb \ue003 i C 1 : \nBy linearity of expectation, we have \nE \u0152n\ufffd  D E \" b X  \ni D1 n i # \nD b X  \ni D1 E \u0152n i \ufffd \nD b X  \ni D1 b \nb \ue003 i C 1 \nD b b X  \ni D1 1 \ni (by  equation  (A.14)  on  page  1144)  \nD b.ln b C O.1//  (by  equation  (A.9)  on  page  1142)  . \nIt therefore takes approximately b ln b tosses before we can expect that every \nbin has a ball. This problem is also known as the coupon  collector\u2019s  problem , \nwhich says that if you are trying to collect each o f b different coupons, then \nyou should expect to acquire approximately b ln b randomly obtained coupons \nin order to succeed. \n5.4.3  Streaks  \nSuppose  that  you  \u00fcip  a fair  coin  n times. What is the longest streak of consecutive \nheads  that  you  expect  to see?  We\u2019ll  prove  upper  and  lower  boun ds separately to \nshow that the answer is \u201a.lg n/. 5.4  Probabilistic  analysis  and  further  uses  of indicator  random variables 145 \nWe  \u00fbrst  prove  that  the  expected  length  of the  longest  streak  of heads is O.lg n/. \nThe  probability  that  each  coin  \u00fcip  is a head  is 1=2. Let A ik  be the event that a \nstreak of heads of length at least k begins with the i th coin  \u00fcip  or,  more  precisely,  \nthe event that the k consecutive  coin  \u00fcips  i;i  C 1;:::;i  C k \ue003 1 yield only heads, \nwhere 1 \u0dc4 k \u0dc4 n and 1 \u0dc4 i \u0dc4 n \ue003k C1. Since  coin  \u00fcips  are  mutually  independent,  \nfor any given event A ik  , the probability that all k \u00fcips  are  heads  is \nPr fA ik  g D  1 \n2 k : (5.9)  \nFor k D 2 dlg ne, \nPr fA i;2dlg ne g D  1 \n2 2dlg ne \n\u0dc4 1 \n2 2 lg n \nD 1 \nn 2 ; \nand thus the probability that a streak of heads of length at least 2 dlg ne begins in \nposition i is quite small. There are at most n \ue003 2 dlg ne C  1 positions where such \na streak can begin. The probability that a streak o f heads of length at least 2 dlg ne \nbegins anywhere is therefore \nPr ( n\ue0022dlg neC1 [  \ni D1 A i;2dlg ne ) \n\u0dc4 n\ue0022dlg neC1 X  \ni D1 Pr fA i;2dlg ne g (by  Boole\u2019s  inequality  (C.21)  on  page  1190)  \n\u0dc4 n\ue0022dlg neC1 X  \ni D1 1 \nn 2 \n< n X  \ni D1 1 \nn 2 \nD 1 \nn : (5.10)  \nWe  can  use  inequality  (5.10)  to bound  the  length  of the  longes t streak. For \nj D 0;1;2;:::;n , let L j be the event that the longest streak of heads has l ength \nexactly j , and let L be the  length  of the  longest  streak.  By  the  de\u00fbnition  of ex-  \npected value, we have \nE \u0152L\ufffd  D n X  \nj D0 j Pr fL j g : (5.11)  146  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nWe could try to evaluate this sum using upper bound s on each Pr fL j g similar \nto those  computed  in inequality  (5.10).  Unfortunately,  this method yields weak \nbounds. We can use some intuition gained by the abo ve analysis to obtain a good \nbound, however. For no individual term in the summa tion in equation  (5.11)  are  \nboth the factors j and Pr fL j g large.  Why?  When  j \ue004 2 dlg ne, then Pr fL j g is \nvery small, and when j <2  dlg ne, then j is fairly small. More precisely, since \nthe events L j for j D 0;1;:::;n  are disjoint, the probability that a streak of head s \nof length at least 2 dlg ne begins anywhere is P  n \nj D2dlg ne Pr fL j g. Inequality  (5.10)  \ntells us that the probability that a streak of head s of length at least 2 dlg ne begins \nanywhere is less than 1=n, which means that P  n \nj D2dlg ne Pr fL j g <1=n. Also,  not-  \ning that P  n \nj D0 Pr fL j g D  1, we have that P  2dlg ne\ue0021 \nj D0 Pr fL j g \u0dc4  1. Thus, we obtain \nE \u0152L\ufffd  D n X  \nj D0 j Pr fL j g \nD 2dlg ne\ue0021 X  \nj D0 j Pr fL j g C  n X  \nj D2dlg ne j Pr fL j g \n< 2dlg ne\ue0021 X  \nj D0 .2 dlg ne/ Pr fL j g C  n X  \nj D2dlg ne n Pr fL j g \nD 2 dlg ne 2dlg ne\ue0021 X  \nj D0 Pr fL j g C  n n X  \nj D2dlg ne Pr fL j g \n< 2  dlg ne \ue001 1 C n \ue001 1 \nn \nD O.lg n/:  \nThe probability that a streak of heads exceeds r dlg ne \u00fcips  diminishes  quickly  \nwith r . Let\u2019s  get  a rough  bound  on  the  probability  that  a streak  of at least r dlg ne \nheads occurs, for r \ue004 1. The probability that a streak of at least r dlg ne heads \nstarts in position i is \nPr fA i;r  dlg ne g D  1 \n2 r dlg ne \n\u0dc4 1 \nn r : \nA streak of at least r dlg ne heads cannot start in the last n \ue003 r dlg ne C  1 \u00fcips,  but  \nlet\u2019s  overestimate  the  probability  of such  a streak  by  allow ing it to start anywhere \nwithin the n coin  \u00fcips.  Then  the  probability  that  a streak  of at least  r dlg ne heads 5.4  Probabilistic  analysis  and  further  uses  of indicator  random variables 147 \noccurs is at most \nPr ( n [  \ni D1 A i;r  dlg ne ) \n\u0dc4 n X  \ni D1 Pr fA i;r  dlg ne g (by  Boole\u2019s  inequality  (C.21))  \n\u0dc4 n X  \ni D1 1 \nn r \nD 1 \nn r \ue0021 : \nEquivalently, the probability is at least 1 \ue003 1=n  r \ue0021 that the longest streak has length \nless than r dlg ne. \nAs an example, during n D 1000  coin  \u00fcips,  the  probability  of encountering  a \nstreak of at least 2 dlg ne D  20  heads is at most 1=n  D 1=1000 . The chance of a \nstreak of at least 3 dlg ne D  30  heads is at most 1=n  2 D 1=1,000,000.  \nLet\u2019s  now  prove  a complementary  lower  bound:  the  expected  length of the \nlongest streak of heads in n coin  \u00fcips  is \ufffd.lg n/. To prove this bound, we look \nfor streaks of length s by partitioning the n \u00fcips  into  approximately  n=s  groups of \ns \u00fcips  each.  If we  choose  s D b.lg n/=2c, we\u2019ll  see  that  it is likely  that  at least  one  \nof these  groups  comes  up  all  heads,  which  means  that  it\u2019s  likely that the longest \nstreak has length at least s D \ufffd.lg n/. We\u2019ll  then  show  that  the  longest  streak  has  \nexpected length \ufffd.lg n/. \nLet\u2019s  partition  the  n coin  \u00fcips  into  at least  bn=  b.lg n/=2cc groups of b.lg n/=2c \nconsecutive  \u00fcips  and  bound  the  probability  that  no  group  comes up all heads. By \nequation  (5.9),  the  probability  that  the  group  starting  in position i comes up all \nheads is \nPr fA i;b.lg n/=2c g D  1 \n2 b.lg n/=2c \n\ue004 1 p n : \nThe probability that a streak of heads of length at  least b.lg n/=2c does not begin \nin position i is therefore at most 1 \ue003 1=  p n. Since the bn=  b.lg n/=2cc groups are \nformed  from  mutually  exclusive,  independent  coin  \u00fcips,  the  probability that every \none of these groups fails to be a streak of length b.lg n/=2c is at most \n\u00e3 \n1 \ue003 1=  p n \u00e4 bn=b.lg n/=2cc  \u0dc4 \u00e3 \n1 \ue003 1=  p n \u00e4 n=b.lg n/=2c\ue0021 \n\u0dc4 \u00e3 \n1 \ue003 1=  p n \u00e4 2n=  lg n\ue0021 \n\u0dc4 e \ue002.2n=  lg n\ue0021/=  p  n \nD O.e  \ue002 ln n / \nD O.1=n/:  (5.12)  148  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nFor  this  argument,  we  used  inequality  (3.14),  1 C x \u0dc4 e x , on  page  66  and  the  fact,  \nwhich you may verify, that .2n=  lg n \ue003 1/=  p n \ue004 ln n for  suf\u00fbciently  large  n. \nWe want to bound the probability that the longest s treak equals or exceeds \nb.lg n/=2c. To do so, let L be the event that the longest streak of heads equal s \nor exceeds s D b.lg n/=2c. Let L be the complementary event, that the longest \nstreak of heads is strictly less than s , so that Pr fLg C  Pr \u02da \nL \ue009 \nD 1. Let F be the \nevent that every group of s \u00fcips  fails  to be a streak  of s heads.  By  inequality  (5.12),  \nwe have Pr fF g D  O.1=n/ . If the longest streak of heads is less than s , then \ncertainly every group of s \u00fcips  fails  to be a streak  of s heads, which means that \nevent L implies event F . Of  course,  event  F could occur even if event L does not \n(for example, if a streak of s or more heads crosses over the boundary between two  \ngroups), and so we have Pr \u02da L \ue009 \u0dc4 Pr fF g D  O.1=n/ . Since Pr fLg C  Pr \u02da L \ue009 D 1, \nwe have that \nPr fLg D  1 \ue003 Pr \u02da \nL \ue009 \n\ue004 1 \ue003 Pr fF g \nD 1 \ue003 O.1=n/:  \nThat is, the probability that the longest streak eq uals or exceeds b.lg n/=2c is \nn X  \nj Db.lg n/=2c Pr fL j g \ue004  1 \ue003 O.1=n/:  (5.13)  \nWe can now calculate a lower bound on the expected length of the longest streak, \nbeginning  with  equation  (5.11)  and  proceeding  in a manner  similar to our analysis \nof the upper bound: \nE \u0152L\ufffd  D n X  \nj D0 j Pr fL j g \nD b.lg n/=2c\ue0021 X  \nj D0 j Pr fL j g C  n X  \nj Db.lg n/=2c j Pr fL j g \n\ue004 b.lg n/=2c\ue0021 X  \nj D0 0 \ue001 Pr fL j g C  n X  \nj Db.lg n/=2c b.lg n/=2c Pr fL j g \nD 0 \ue001 b.lg n/=2c\ue0021 X  \nj D0 Pr fL j g C b.lg n/=2c n X  \nj Db.lg n/=2c Pr fL j g \n\ue004 0 C b.lg n/=2c .1 \ue003 O.1=n//  (by  inequality  (5.13))  \nD \ufffd.lg n/:  5.4  Probabilistic  analysis  and  further  uses  of indicator  random variables 149 \nAs with the birthday paradox, we can obtain a simpl er, but approximate, analysis \nusing indicator random variables. Instead of determ ining the expected length of \nthe  longest  streak,  we\u2019ll  \u00fbnd  the  expected  number  of streaks  with at least a given \nlength. Let X ik  D I fA ik  g be the indicator random variable associated with a \nstreak of heads of length at least k beginning with the i th coin  \u00fcip.  To  count  the  \ntotal  number  of such  streaks,  de\u00fbne  \nX k D n\ue002kC1 X  \ni D1 X ik  : \nTaking expectations and using linearity of expectat ion, we have \nE \u0152X  k \ufffd D E \" n\ue002kC1 X  \ni D1 X ik  # \nD n\ue002kC1 X  \ni D1 E \u0152X  ik  \ufffd \nD n\ue002kC1 X  \ni D1 Pr fA ik  g \nD n\ue002kC1 X  \ni D1 1 \n2 k \nD n \ue003 k C 1 \n2 k : \nBy plugging in various values for k, we can calculate the expected number of \nstreaks of length at least k. If this expected number is large (much greater th an 1), \nthen we expect many streaks of length k to occur,  and  the  probability  that  one  oc-  \ncurs is high. If this expected number is small (muc h less than 1), then we expect to \nsee few streaks of length k, and the probability that one occurs is low. If k D c lg n, \nfor some positive constant c , we obtain \nE \u0152X  c lg n \ufffd D n \ue003 c lg n C 1 \n2 c lg n \nD n \ue003 c lg n C 1 \nn c \nD 1 \nn c\ue0021 \ue003 .c lg n \ue003 1/=n  \nn c\ue0021 \nD \u201a.1=n  c\ue0021 /: \nIf c is large, the expected number of streaks of length c lg n is small,  and  we  con-  \nclude  that  they  are  unlikely  to occur.  On  the  other  hand,  if c D 1=2, then we 150  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nobtain E \u0152X  .1=2/  lg n \ufffd D \u201a.1=n  1=2\ue0021 / D \u201a.n  1=2  /, and  we  expect  there  to be numer-  \nous streaks of length .1=2/  lg n. Therefore, one streak of such a length is likely to \noccur. We can conclude that the expected length of the longest streak is \u201a.lg n/. \n5.4.4  The  online  hiring  problem  \nAs  a \u00fbnal  example,  let\u2019s  consider  a variant  of the  hiring  problem. Suppose now \nthat you do not wish to interview all the candidate s in order to \u00fbnd  the  best  one.  \nYou  also  want  to avoid  hiring  and  \u00fbring  as you  \u00fbnd  better  and  better applicants. \nInstead, you are willing to settle for a candidate who is close to the  best,  in ex-  \nchange for hiring exactly once. You must obey one c ompany requirement: after \neach interview you must either immediately offer th e position to the applicant or \nimmediately  reject  the  applicant.  What  is the  trade-off  between minimizing the \namount of interviewing and maximizing the quality o f the candidate  hired?  \nWe can model this problem in the following way. Aft er meeting an applicant, \nyou are able to give each one a score. Let score.i/  denote the score you give to \nthe i th applicant, and assume that no two applicants rec eive the same score. After \nyou have seen j applicants, you know which of the j has the highest score, but \nyou do not know whether any of the remaining n \ue003 j applicants will receive a \nhigher score. You decide to adopt the strategy of s electing a positive integer k<n , \ninterviewing  and  then  rejecting  the  \u00fbrst  k applicants,  and  hiring  the  \u00fbrst  applicant  \nthereafter who has a higher score than all precedin g applicants. If it turns out that \nthe  best-quali\u00fbed  applicant  was  among  the  \u00fbrst  k interviewed, then you hire the nth \napplicant4the  last  one  interviewed.  We  formalize  this  strategy in the procedure \nONLINE-MAXIMUM.k;n/ , which returns the index of the candidate you wish  to \nhire. \nONLINE-MAXIMUM.k;n/  \n1 best-score  D \ue0031  \n2 for  i D 1 to k \n3 if score.i/>  best-score  \n4 best-score  D score.i/  \n5 for  i D k C 1 to n \n6 if score.i/>  best-score  \n7 return  i \n8 return  n \nIf we determine, for each possible value of k, the probability that you hire \nthe  most  quali\u00fbed  applicant,  then  you  can  choose  the  best  possible k and  imple-  \nment the strategy with that value. For the moment, assume that k is \u00fbxed.  Let  5.4  Probabilistic  analysis  and  further  uses  of indicator  random variables 151 \nM.j/  D max fscore.i/  W 1 \u0dc4 i \u0dc4 j g denote the maximum score among applicants \n1 through j . Let S be the  event  that  you  succeed  in choosing  the  best-quali\u00fbed  \napplicant, and let S i be the  event  that  you  succeed  when  the  best-quali\u00fbed  appli-  \ncant is the i th one interviewed. Since the various S i are disjoint, we have that \nPr fS g D  P  n \ni D1 Pr fS i g. Noting  that  you  never  succeed  when  the  best-quali\u00fbed  \napplicant  is one  of the  \u00fbrst  k, we have that Pr fS i g D  0 for i D 1;2;:::;k . Thus, \nwe obtain \nPr fS g D  n X  \ni DkC1 Pr fS i g : (5.14)  \nWe now compute Pr fS i g. In order  to succeed  when  the  best-quali\u00fbed  applicant  \nis the i th one,  two  things  must  happen.  First,  the  best-quali\u00fbed  applicant must be in \nposition i , an event which we denote by B i . Second, the algorithm must not select \nany of the applicants in positions k C 1 through i \ue003 1, which happens only if, for \neach j such that k C 1 \u0dc4 j \u0dc4 i \ue003 1, line  6 \u00fbnds  that  score.j/<  best-score. (Be-  \ncause scores are unique, we can ignore the possibil ity of score.j/  D best-score .) \nIn other words, all of the values score.k C 1/ through score.i \ue003 1/ must be less \nthan M.k/ . If any are greater than M.k/ , the algorithm instead returns the index \nof the  \u00fbrst  one  that  is greater.  We  use  O i to denote  the  event  that  none  of the  ap-  \nplicants in position k C 1 through i \ue003 1 are chosen. Fortunately, the two events B i \nand O i are independent. The event O i depends only on the relative ordering of the \nvalues in positions 1 through i \ue003 1, whereas B i depends only on whether the value \nin position i is greater than the values in all other positions. The ordering of the \nvalues in positions 1 through i \ue003 1 does not affect whether the value in position i \nis greater than all of them, and the value in posit ion i does not affect the ordering \nof the values in positions 1 through i \ue003 1. Thus,  we  can  apply  equation  (C.17)  on  \npage  1188  to obtain  \nPr fS i g D  Pr fB i \\ O i g D  Pr fB i g Pr fO i g : \nWe have Pr fB i g D  1=n  since the maximum is equally likely to be in any on e of the \nn positions. For event O i to occur, the maximum value in positions 1 through i \ue003 1, \nwhich is equally likely to be in any of these i \ue003 1 positions, must be in one of the \n\u00fbrst  k positions. Consequently, Pr fO i g D  k=.i  \ue003 1/ and Pr fS i g D  k=.n.i  \ue003 1//. \nUsing  equation  (5.14),  we  have  \nPr fS g D  n X  \ni DkC1 Pr fS i g \nD n X  \ni DkC1 k \nn.i  \ue003 1/ 152  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nD k \nn n X  \ni DkC1 1 \ni \ue003 1 \nD k \nn n\ue0021 X  \ni Dk 1 \ni : \nWe approximate by integrals to bound this summation  from above and below. By \nthe  inequalities  (A.19)  on  page  1150,  we  have  \nZ n \nk 1 \nx dx  \u0dc4 n\ue0021 X  \ni Dk 1 \ni \u0dc4 Z n\ue0021 \nk\ue0021 1 \nx dx:  \nEvaluating  these  de\u00fbnite  integrals  gives  us the  bounds  \nk \nn .ln n \ue003 ln k/  \u0dc4 Pr fS g \u0dc4  k \nn .ln.n \ue003 1/ \ue003 ln.k \ue003 1//;  \nwhich provide a rather tight bound for Pr fS g. Because you wish to maximize your \nprobability of success, let us focus on choosing th e value of k that maximizes the \nlower bound on Pr fS g. (Besides,  the  lower-bound  expression  is easier  to maximiz e \nthan  the  upper-bound  expression.)  Differentiating  the  expression .k=n/. ln n \ue003ln k/  \nwith respect to k, we obtain \n1 \nn .ln n \ue003 ln k \ue003 1/:  \nSetting this derivative equal to 0, we see that you maximize the lower bound on \nthe probability when ln k D ln n \ue003 1 D ln.n=e/  or, equivalently, when k D n=e. \nThus, if you implement our strategy with k D n=e, you succeed in hiring the \nbest-quali\u00fbed  applicant  with  probability  at least  1=e. \nExercises  \n5.4-1  \nHow many people must there be in a room before the probability that someone \nhas the same birthday as you do is at least 1=2? How  many  people  must  there  be \nbefore the probability that at least two people hav e a birthday on  July  4 is greater  \nthan 1=2? \n5.4-2  \nHow many people must there be in a room before the probability that two people \nhave the same birthday is at least 0:99? For  that  many  people,  what  is the  expected  \nnumber  of pairs  of people  who  have  the  same  birthday?  Problems for Chapter 5 153 \n5.4-3  \nYou toss balls into b bins  until  some  bin  contains  two  balls.  Each  toss  is indepen-  \ndent, and each ball is equally likely to end up in any bin. What is the expected \nnumber  of ball  tosses?  \n? 5.4-4  \nFor the analysis of the birthday paradox, is it imp ortant that the  birthdays  be mutu-  \nally  independent,  or is pairwise  independence  suf\u00fbcient?  Justify your answer. \n? 5.4-5  \nHow many people should be invited to a party in ord er to make it likely that there \nare three people  with  the  same  birthday?  \n? 5.4-6  \nWhat is the probability that a k-string  (de\u00fbned  on  page  1179)  over  a set  of size  n \nforms a k-permutation?  How  does  this  question  relate  to the  birthday  paradox?  \n? 5.4-7  \nYou toss n balls into n bins, where each toss is independent and the ball i s equally \nlikely to end up in any bin. What is the expected n umber of empt y bins?  What  is \nthe  expected  number  of bins  with  exactly  one  ball?  \n? 5.4-8  \nSharpen the lower bound on streak length by showing  that in n \u00fcips  of a fair  coin,  \nthe probability is at least 1 \ue003 1=n  that a streak of length lg n \ue003 2 lg lg n consecutive \nheads occurs. \nProblems  \n5-1  Probabilistic  counting  \nWith a b-bit  counter,  we  can  ordinarily  only  count  up  to 2 b \ue003 1. With  R. Morris\u2019s  \nprobabilistic  counting , we can count up to a much larger value at the exp ense of \nsome loss of precision. \nWe let a counter value of i represent a count of n i for i D 0;1;:::;2  b \ue003 1, where \nthe n i form an increasing sequence of nonnegative values. We assume that  the  ini-  \ntial value of the counter is 0, representing a count of n 0 D 0. The I NCREMENT \noperation works on a counter containing the value i in a probabilistic manner. If \ni D 2 b \ue003 1, then  the  operation  reports  an over\u00fcow  error.  Otherwise,  the I NCRE- \nMENT operation increases the counter by 1 with probability 1=.n  i C1 \ue003 n i /, and it \nleaves the counter unchanged with probability 1 \ue003 1=.n  i C1 \ue003 n i /. 154  Chapter  5 Probabilistic  Analysis  and  Randomized  Algori thms \nIf we select n i D i for all i \ue004 0, then the counter is an ordinary one. More \ninteresting situations arise if we select, say, n i D 2 i \ue0021 for i >0  or n i D F i (the \ni th Fibonacci  number4see  equation  (3.31)  on  page  69).  \nFor this problem, assume that n 2 b \ue0021 is large enough that the probability of an \nover\u00fcow  error  is negligible.  \na. Show that the expected value represented by the cou nter after n I NCREMENT \noperations have been performed is exactly n. \nb. The analysis of the variance of the count represent ed by the counter depends \non the sequence of the n i . Let us consider a simple case: n i D 100i  for \nall i \ue004 0. Estimate the variance in the value represented by  the register after n \nI NCREMENT operations have been performed. \n5-2  Searching  an  unsorted  array  \nThis problem examines three algorithms for searchin g for a value x in an unsorted \narray A consisting of n elements. \nConsider the following randomized strategy: pick a random index i into A. If \nA\u0152i\ufffd  D x , then terminate; otherwise, continue the search by  picking a new random \nindex into A. Continue picking random indices into A until  you  \u00fbnd  an index  j \nsuch that A\u0152j \ufffd  D x or until every element of A has been checked. This strategy \nmay examine a given element more than once, because  it picks from the whole set \nof indices each time. \na. Write pseudocode for a procedure R ANDOM-SEARCH to implement  the  strat-  \negy above. Be sure that your algorithm terminates w hen all indices into A have \nbeen picked. \nb. Suppose that there is exactly one index i such that A\u0152i\ufffd  D x . What is the \nexpected number of indices into A that must be picked before x is found and \nRANDOM-SEARCH terminates?  \nc. Generalizing  your  solution  to part  (b),  suppose  that  there  are k \ue004 1 indices i \nsuch that A\u0152i\ufffd  D x . What is the expected number of indices into A that must \nbe picked before x is found and R ANDOM-SEARCH terminates?  Your  answer  \nshould be a function of n and k. \nd. Suppose that there are no indices i such that A\u0152i\ufffd  D x . What is the expected \nnumber of indices into A that must be picked before all elements of A have \nbeen checked and R ANDOM-SEARCH terminates?  \nNow consider a deterministic linear search algorith m. The algorithm, which we \ncall D ETERMINISTIC -SEARCH , searches A for x in order, considering A\u01521\ufffd; A\u01522\ufffd;  Notes for Chapter 5 155 \nA\u01523\ufffd; : : : ; A\u0152n\ufffd  until  either  it \u00fbnds  A\u0152i\ufffd  D x or it reaches the end of the array. \nAssume that all possible permutations of the input array are equally likely. \ne. Suppose that there is exactly one index i such that A\u0152i\ufffd  D x . What is the \naverage-case  running  time  of DETERMINISTIC -SEARCH? What  is the  worst-  \ncase running time of D ETERMINISTIC -SEARCH? \nf. Generalizing  your  solution  to part  (e),  suppose  that  there  are k \ue004 1 indices i \nsuch that A\u0152i\ufffd  D x . What  is the  average-case  running  time  of DETERMINISTIC - \nSEARCH? What  is the  worst-case  running  time  of DETERMINISTIC -S EARCH? \nYour answer should be a function of n and k. \ng. Suppose that there are no indices i such that A\u0152i\ufffd  D x . What  is the  average-case  \nrunning time of D ETERMINISTIC -SEARCH? What  is the  worst-case  running  \ntime of D ETERMINISTIC -SEARCH? \nFinally, consider a randomized algorithm S CRAMBLE-SEARCH that  \u00fbrst  randomly  \npermutes the input array and then runs the determin istic linear search given above \non the resulting permuted array. \nh. Letting k be the number of indices i such that A\u0152i\ufffd  D x , give  the  worst-case  and  \nexpected running times of S CRAMBLE-SEARCH for the cases in which k D 0 \nand k D 1. Generalize  your  solution  to handle  the  case  in which  k \ue004 1. \ni. Which  of the  three  searching  algorithms  would  you  use?  Expla in your answer. \nChapter  notes  \nBollob\u00b4  as [65],  Hofri  [223],  and  Spencer  [420]  contain  a wealth  of advanced  prob-  \nabilistic techniques. The advantages of randomized algorithms are discussed and \nsurveyed  by  Karp  [249]  and  Rabin  [372].  The  textbook  by  Motwa ni and Raghavan \n[336]  gives  an extensive  treatment  of randomized  algorithm s. \nThe RANDOMLY-PERMUTE procedure  is by  Durstenfeld  [128],  based  on  an ear-  \nlier  procedure  by  Fisher  and  Yates  [143,  p. 34].  \nSeveral variants of the hiring problem have been wi dely studied. These problems \nare more commonly referred to as <secretary problem s.= Examples of work in this \narea  are  the  paper  by  Ajtai,  Meggido,  and  Waarts  [11]  and  another  by  Kleinberg  \n[258],  which  ties  the  secretary  problem  to online  ad auction s. Part  II Sorting  and  Order  Statistics  Introduction  \nThis part presents several algorithms that solve th e following sorting  problem : \nInput:  A sequence of n numbers ha 1 ;a  2 ;:::;a  n i. \nOutput:  A permutation (reordering) ha 0 \n1 ;a  0 \n2 ;:::;a  0 \nn i of the input sequence such \nthat a 0 \n1 \u0dc4 a 0 \n2 \u0dc4 \ue001 \ue001 \ue001 \u0dc4  a 0 \nn . \nThe input sequence is usually an n-element  array,  although  it may  be represented  \nin some other fashion, such as a linked list. \nThe  structure  of the  data  \nIn practice, the numbers to be sorted are rarely is olated values. Each is usually part \nof a collection of data called a record . Each record contains a key, which is the \nvalue to be sorted. The remainder of the record con sists of satellite  data, which are \nusually carried around with the key. In practice, w hen a sorting algorithm permutes \nthe keys, it must permute the satellite data as wel l. If each record includes a large \namount of satellite data, it often pays to permute an array of pointers to the records \nrather than the records themselves in order to mini mize data movement. \nIn a sense, it is these implementation details that  distinguish an algorithm from \na full-blown  program.  A sorting  algorithm  describes  the  method to determine the \nsorted  order,  regardless  of whether  what\u2019s  being  sorted  are  individual numbers or \nlarge records containing many bytes of satellite da ta. Thus, when focusing on the \nproblem of sorting, we typically assume that the in put consists only of numbers. \nTranslating an algorithm for sorting numbers into a  program for sorting records \nis conceptually straightforward, although in a give n engineering situation other \nsubtleties may make the actual programming task a c hallenge. 158  Part  II Sorting  and  Order  Statistics  \nWhy  sorting?  \nMany computer scientists consider sorting to be the  most fundamental problem in \nthe study of algorithms. There are several reasons:  \n\ue001 Sometimes an application inherently needs to sort i nformation. For example, \nin order to prepare customer statements, banks need  to sort checks by check \nnumber. \n\ue001 Algorithms often use sorting as a key subroutine. F or example, a program that \nrenders graphical objects which are layered on top of each other might have \nto sort the objects according to an <above= relatio n so that it can draw these \nobjects from bottom to top. We will see numerous al gorithms in this text that \nuse sorting as a subroutine. \n\ue001 We can draw from among a wide variety of sorting al gorithms, and they employ \na rich set of techniques. In fact, many important t echniques used throughout \nalgorithm design appear in sorting algorithms that have been developed over \nthe years. In this way, sorting is also a problem o f historical interest. \n\ue001 We  can  prove  a nontrivial  lower  bound  for  sorting  (as  we\u2019ll  do  in Chapter  8).  \nSince the best upper bounds match the lower bound a symptotically,  we  can  con-  \nclude that certain of our sorting algorithms are as ymptotically  optimal.  More-  \nover, we can use the lower bound for sorting to pro ve lower bounds for various \nother problems. \n\ue001 Many engineering issues come to the fore when imple menting sorting  algo-  \nrithms. The fastest sorting program for a particula r situation may depend on \nmany factors, such as prior knowledge about the key s and satellite data, the \nmemory hierarchy (caches and virtual memory) of the  host computer, and the \nsoftware environment. Many of these issues are best  dealt with at the  algorith-  \nmic level, rather than by <tweaking= the code. \nSorting  algorithms  \nWe introduced two algorithms that sort n real numbers in Chapter 2. Insertion sort \ntakes \u201a.n  2 / time in the worst case. Because its inner loops are  tight, however, it is \na fast sorting algorithm for small input sizes. Mor eover, unlike merge sort, it sorts \nin place , meaning that at most a constant number of element s of the input array \nare ever stored outside the array, which can be adv antageous for  space  ef\u00fbciency.  \nMerge sort has a better asymptotic running time, \u201a.n  lg n/, but the M ERGE  proce-  \ndure  it uses  does  not  operate  in place.  (We\u2019ll  see  a paralleli zed version of merge \nsort  in Section  26.3.)  Part  II Sorting  and  Order  Statistics  159 \nThis part introduces two more algorithms that sort arbitrary real  numbers.  Heap-  \nsort,  presented  in Chapter  6, sorts  n numbers in place in O.n  lg n/ time. It uses an \nimportant data structure, called a heap, which can also implement a priority queue. \nQuicksort,  in Chapter  7, also  sorts  n numbers  in place,  but  its  worst-case  running  \ntime is \u201a.n  2 /. Its expected running time is \u201a.n  lg n/, however, and it generally \noutperforms heapsort in practice. Like insertion so rt, quicksort has tight code, and \nso the hidden constant factor in its running time i s small. It is a popular algorithm \nfor sorting large arrays. \nInsertion sort, merge sort, heapsort, and quicksort  are all comparison sorts: they \ndetermine the sorted order of an input array by com paring elements.  Chapter  8 be-  \ngins  by  introducing  the  decision-tree  model  in order  to study  the  performance  limi-  \ntations of comparison sorts. Using this model, we p rove a lower bound of \ufffd.n  lg n/ \non  the  worst-case  running  time  of any  comparison  sort  on  n inputs, thus showing \nthat heapsort and merge sort are asymptotically opt imal comparison sorts. \nChapter  8 then  goes  on  to show  that  we  might  be able  to beat  this  lower bound \nof \ufffd.n  lg n/ if an algorithm can gather information about the so rted order of the \ninput by means other than comparing elements. The c ounting sort algorithm, for \nexample, assumes that the input numbers belong to t he set f0;1;:::;k g. By using \narray indexing as a tool for determining relative o rder, counting sort can sort n \nnumbers in \u201a.k  C n/ time. Thus, when k D O.n/ , counting sort runs in time that \nis linear in the size of the input array. A related  algorithm, radix sort, can be used \nto extend the range of counting sort. If there are n integers to sort, each integer \nhas d digits, and each digit can take on up to k possible values, then radix sort can \nsort the numbers in \u201a.d.n  C k//  time. When d is a constant and k is O.n/ , radix \nsort runs in linear time. A third algorithm, bucket  sort, requires knowledge of the \nprobabilistic distribution of numbers in the input array. It can sort n real numbers \nuniformly  distributed  in the  half-open  interval  \u01520;1/  in average-case  O.n/  time. \nThe table on the following page summarizes the runn ing times of the  sorting  al-  \ngorithms  from  Chapters  2 and  638.  As  usual,  n denotes the number of items to sort. \nFor counting sort, the items to sort are integers i n the set f0;1;:::;k g. For radix \nsort, each item is a d -digit  number,  where  each  digit  takes  on  k possible values. For \nbucket sort, we assume that the keys are real numbe rs uniformly distributed in the \nhalf-open  interval  \u01520;1/. The  rightmost  column  gives  the  average-case  or expected  \nrunning time, indicating which one it gives when it  differs from  the  worst-case  run-  \nning  time.  We  omit  the  average-case  running  time  of heapsort  because we do not \nanalyze it in this book. 160  Part  II Sorting  and  Order  Statistics  \nWorst-case  Average-case/expected  \nAlgorithm running time running time \nInsertion sort \u201a.n  2 / \u201a.n  2 / \nMerge sort \u201a.n  lg n/ \u201a.n  lg n/ \nHeapsort O.n  lg n/ 4  \nQuicksort  \u201a.n  2 / \u201a.n  lg n/ (expected) \nCounting sort \u201a.k  C n/ \u201a.k  C n/ \nRadix sort \u201a.d.n  C k//  \u201a.d.n  C k//  \nBucket sort \u201a.n  2 / \u201a.n/  (average-case)  \nOrder  statistics  \nThe i th order statistic of a set of n numbers is the i th smallest number in the set. \nYou can, of course, select the i th order statistic by sorting the input and indexin g \nthe i th element of the output. With no assumptions about  the input distribution, \nthis method runs in \ufffd.n  lg n/ time,  as the  lower  bound  proved  in Chapter  8 shows.  \nChapter  9 shows  how  to \u00fbnd  the  i th smallest element in O.n/  time, even when \nthe elements are arbitrary real numbers. We present  a randomized algorithm with \ntight pseudocode that runs in \u201a.n  2 / time in the worst case, but whose expected \nrunning time is O.n/ . We also give a more complicated algorithm that ru ns in \nO.n/  worst-case  time.  \nBackground  \nAlthough  most  of this  part  does  not  rely  on  dif\u00fbcult  mathemat ics, some sections \ndo require mathematical sophistication. In particul ar, analyses of quicksort, bucket \nsort,  and  the  order-statistic  algorithm  use  probability,  which  is reviewed  in Ap-  \npendix C, and the material on probabilistic analysi s and randomized algorithms in \nChapter  5. 6 Heapsort  \nThis chapter introduces another sorting algorithm: heapsort. Like merge sort, but \nunlike  insertion  sort,  heapsort\u2019s  running  time  is O.n  lg n/. Like insertion sort, but \nunlike merge sort, heapsort sorts in place: only a constant number of array elements \nare stored outside the input array at any time. Thu s, heapsort combines the better \nattributes of the two sorting algorithms we have al ready discussed. \nHeapsort also introduces another algorithm design t echnique:  using  a data  struc-  \nture, in this case one we call a <heap,= to manage information. Not only is the heap \ndata  structure  useful  for  heapsort,  but  it also  makes  an ef\u00fbcient priority queue. The \nheap data structure will reappear in algorithms in later chapters. \nThe term <heap= was originally coined in the contex t of heapsort, but it has since \ncome  to refer  to <garbage-collected  storage,=  such  as the  programming languages \nJava  and  Python  provide.  Please  don\u2019t  be confused.  The  heap  data structure is not \ngarbage-collected  storage.  This  book  is consistent  in using the term <heap= to refer \nto the data structure, not the storage class. \n6.1  Heaps  \nThe (binary)  heap  data structure is an array object that we can view as a nearly \ncomplete  binary  tree  (see  Section  B.5.3),  as shown  in Figure  6.1.  Each  node  of \nthe tree corresponds to an element of the array. Th e tree is completely  \u00fblled  on  \nall  levels  except  possibly  the  lowest,  which  is \u00fblled  from  the left up to a point. \nAn array A\u01521  W n\ufffd that represents a heap is an object with an attribu te A:  heap-size, \nwhich represents how many elements in the heap are stored within array A. That \nis, although A\u01521  W n\ufffd may contain numbers, only the elements in A\u01521  W A:  heap-size\ufffd, \nwhere 0 \u0dc4 A:  heap-size  \u0dc4 n, are valid elements of the heap. If A:  heap-size  D 0, \nthen the heap is empty. The root of the tree is A\u01521\ufffd, and given the index i of a node, 162 Chapter 6 Heapsort \n(a) 16  14  10  8 7 9 3 2 4 1 1 2 3 4 5 6 7 8 9 10  \n(b) 1 \n2 3 \n4 5 6 7 \n8 9 10  16  \n14  10  \n8 7 9 3 \n2 4 1 \nFigure  6.1  A max-heap  viewed  as (a)  a binary tree and (b)  an array. The number within the circle at \neach node in the tree is the value stored at that n ode. The number above a node is the corresponding \nindex in the array. Above and below the array are l ines showing parent-child  relationships,  with  \nparents always to the left of their children. The t ree has height  3, and  the  node  at index  4 (with  \nvalue  8) has  height  1. \nthere\u2019s  a simple  way  to compute  the  indices  of its  parent,  left child, and right child \nwith  the  one-line  procedures  PARENT , LEFT, and RIGHT . \nPARENT.i/  \n1 return  bi=2c \nLEFT.i/  \n1 return  2i \nRIGHT.i/  \n1 return  2i C 1 \nOn  most  computers,  the  LEFT procedure can compute 2i in one instruction by \nsimply shifting the binary representation of i left by one bit position. Similarly, the \nRIGHT  procedure can quickly compute 2i C 1 by shifting the binary representation \nof i left by one bit position and then adding 1. The P ARENT procedure can compute \nbi=2c by shifting i right  one  bit  position.  Good  implementations  of heapsort  often \nimplement these procedures as macros or inline proc edures. \nThere  are  two  kinds  of binary  heaps:  max-heaps  and  min-heaps . In both kinds, \nthe values in the nodes satisfy a heap  property, the  speci\u00fbcs  of which  depend  on  \nthe kind of heap. In a max-heap , the max-heap  property  is that for every node i \nother than the root, \nA\u0152PARENT.i/\ufffd  \ue004 A\u0152i\ufffd;  6.1 Heaps 163 \nthat is, the value of a node is at most the value o f its parent. Thus, the largest \nelement  in a max-heap  is stored  at the  root,  and  the  subtree  rooted at a node contains \nvalues no larger than that contained at the node it self. A min-heap  is organized in \nthe opposite way: the min-heap  property  is that for every node i other than the \nroot, \nA\u0152PARENT.i/\ufffd  \u0dc4 A\u0152i\ufffd:  \nThe  smallest  element  in a min-heap  is at the  root.  \nThe  heapsort  algorithm  uses  max-heaps.  Min-heaps  commonly  implement  prior-  \nity  queues,  which  we  discuss  in Section  6.5.  We\u2019ll  be precise  in specifying whether \nwe  need  a max-heap  or a min-heap  for  any  particular  application,  and  when  prop-  \nerties  apply  to either  max-heaps  or min-heaps,  we  just  use  the term <heap.= \nViewing  a heap  as a tree,  we  de\u00fbne  the  height  of a node in a heap to be the \nnumber of edges on the longest simple downward path  from the node to a leaf, and \nwe  de\u00fbne  the  height  of the  heap  to be the  height  of its  root.  Since a heap of n ele-  \nments is based on a complete binary tree, its heigh t is \u201a.lg n/ (see  Exercise  6.1-2).  \nAs  we\u2019ll  see,  the  basic  operations  on  heaps  run  in time  at most  proportional to the \nheight of the tree and thus take O.lg n/ time. The remainder of this chapter presents \nsome basic procedures and shows how they are used i n a sorting algorithm and a \npriority-queue  data  structure.  \n\ue001 The M AX-HEAPIFY procedure, which runs in O.lg n/ time,  is the  key  to main-  \ntaining  the  max-heap  property.  \n\ue001 The B UILD-MAX-HEAP procedure,  which  runs  in linear  time,  produces  a max-  \nheap from an unordered input array. \n\ue001 The HEAPSORT  procedure, which runs in O.n  lg n/ time, sorts an array in \nplace. \n\ue001 The procedures M AX-HEAP-I NSERT , M AX-HEAP-EXTRACT-MAX, M AX- \nHEAP-I NCREASE-KEY, and M AX-HEAP-MAXIMUM allow the heap data \nstructure to implement a priority queue. They run i n O.lg n/ time plus the \ntime for mapping between objects being inserted int o the priority queue and \nindices in the heap. \nExercises  \n6.1-1  \nWhat are the minimum and maximum numbers of element s in a heap of height h? \n6.1-2  \nShow that an n-element  heap  has  height  blg nc. 164 Chapter 6 Heapsort \n6.1-3  \nShow  that  in any  subtree  of a max-heap,  the  root  of the  subtree  contains the largest \nvalue occurring anywhere in that subtree. \n6.1-4  \nWhere  in a max-heap  might  the  smallest  element  reside,  assum ing that all elements \nare  distinct?  \n6.1-5  \nAt  which  levels  in a max-heap  might  the  kth largest element reside, for 2 \u0dc4 k \u0dc4 \nbn=2c, assuming  that  all  elements  are  distinct?  \n6.1-6  \nIs an array  that  is in sorted  order  a min-heap?  \n6.1-7  \nIs the array with values h33;19;20;15;13;10;2;13;16;12 i a max-heap?  \n6.1-8  \nShow that, with the array representation for storin g an n-element  heap,  the  leaves  \nare the nodes indexed by bn=2c C  1; bn=2c C  2;:::;n . \n6.2  Maintaining  the  heap  property  \nThe procedure M AX-HEAPIFY on  the  facing  page  maintains  the  max-heap  prop-  \nerty. Its inputs are an array A with the heap-size  attribute and an index i into the \narray. When it is called, M AX-HEAPIFY assumes that the binary trees rooted at \nLEFT.i/  and RIGHT.i/  are  max-heaps,  but  that  A\u0152i\ufffd  might  be smaller  than  its  chil-  \ndren,  thus  violating  the  max-heap  property.  MAX-HEAPIFY lets the value at A\u0152i\ufffd  \n<\u00fcoat  down=  in the  max-heap  so that  the  subtree  rooted  at index i obeys  the  max-  \nheap property. \nFigure  6.2  illustrates  the  action  of MAX-HEAPIFY . Each step determines the \nlargest of the elements A\u0152i\ufffd, A\u0152LEFT.i/\ufffd, and A\u0152RIGHT.i/\ufffd  and stores the index of \nthe largest element in largest . If A\u0152i\ufffd  is largest, then the subtree rooted at node i is \nalready  a max-heap  and  nothing  else  needs  to be done.  Otherwi se, one of the two \nchildren contains the largest element. Positions i and largest swap their contents, \nwhich causes node i and  its  children  to satisfy  the  max-heap  property.  The  node  in-  \ndexed by largest , however, just had its value decreased, and thus t he subtree rooted \nat largest might  violate  the  max-heap  property.  Consequently,  MAX-HEAPIFY \ncalls itself recursively on that subtree. 6.2  Maintaining  the  heap  property  165 \n16  \n4 10  \n14  7 9 \n2 8 1 \n(a) 16  \n14  10  \n4 7 9 3 \n2 8 1 \n(b) \n16  \n14  10  \n8 7 9 3 \n2 4 1 \n(c) 3 1 \n3 \n4 5 6 7 \n9 10  2 \n8 1 \n3 \n4 5 6 7 \n9 10  2 \n8 \n1 \n3 \n4 5 6 7 \n9 10  2 \n8 i \ni \ni \nFigure  6.2  The action of M AX-HEAPIFY.A;2/ , where A:  heap-size  D 10. The  node  that  poten-  \ntially  violates  the  max-heap  property  is shown  in blue.  (a)  The  initial  con\u00fbguration,  with  A\u01522\ufffd  at \nnode i D 2 violating  the  max-heap  property  since  it is not  larger  than  both  children.  The  max-heap  \nproperty is restored for node 2 in (b)  by exchanging A\u01522\ufffd  with A\u01524\ufffd, which  destroys  the  max-heap  \nproperty for node 4. The recursive call M AX-HEAPIFY.A;4/  now has i D 4. After A\u01524\ufffd  and A\u01529\ufffd  \nare swapped, as shown in (c), node 4 is \u00fbxed  up,  and  the  recursive  call  MAX-HEAPIFY.A;9/  yields \nno further change to the data structure. \nMAX-HEAPIFY .A;i/  \n1 l D LEFT.i/  \n2 r D RIGHT.i/  \n3 if l \u0dc4 A:  heap-size  and A\u0152l\ufffd>A\u0152i\ufffd  \n4 largest D l \n5 else  largest D i \n6 if r \u0dc4 A:  heap-size  and A\u0152r\ufffd>A\u0152 largest \ufffd \n7 largest D r \n8 if largest \u00a4 i \n9 exchange A\u0152i\ufffd  with A\u0152largest \ufffd \n10  MAX-HEAPIFY .A;  largest / 166 Chapter 6 Heapsort \nTo analyze M AX-HEAPIFY , let T.n/  be the  worst-case  running  time  that  the  \nprocedure takes on a subtree of size at most n. For a tree rooted at a given node i , \nthe running time is the \u201a.1/  time  to \u00fbx  up  the  relationships  among  the  elements  \nA\u0152i\ufffd, A\u0152LEFT.i/\ufffd, and A\u0152RIGHT.i/\ufffd, plus the time to run M AX-HEAPIFY on a \nsubtree rooted at one of the children of node i (assuming  that  the  recursive  call  oc-  \ncurs).  The  children\u2019s  subtrees  each  have  size  at most  2n=3  (see  Exercise  6.2-2),  and  \ntherefore we can describe the running time of M AX-HEAPIFY by the recurrence \nT.n/  \u0dc4 T.2n=3/  C \u201a.1/:  (6.1)  \nThe solution to this recurrence, by case 2 of the m aster theorem  (Theorem  4.1  on  \npage  102),  is T.n/  D O.lg n/. Alternatively, we can characterize the running ti me \nof M AX-HEAPIFY on a node of height h as O.h/ . \nExercises  \n6.2-1  \nUsing  Figure  6.2  as a model,  illustrate  the  operation  of MAX-HEAPIFY .A;3/  on \nthe array A D h27;17;3;16;13;10;1;5;7;12;4;8;9;0 i. \n6.2-2  \nShow that each child of the root of an n-node  heap  is the  root  of a subtree  containing  \nat most 2n=3  nodes. What is the smallest constant \u02db such that each subtree has at \nmost \u02dbn  nodes?  How  does  that  affect  the  recurrence  (6.1)  and  its  solution?  \n6.2-3  \nStarting with the procedure M AX-HEAPIFY , write pseudocode for the procedure \nMIN-HEAPIFY .A;i/, which  performs  the  corresponding  manipulation  on  a min-  \nheap. How does the running time of M IN-HEAPIFY compare with that of M AX- \nHEAPIFY? \n6.2-4  \nWhat is the effect of calling M AX-HEAPIFY .A;i/  when the element A\u0152i\ufffd  is larger \nthan  its  children?  \n6.2-5  \nWhat is the effect of calling M AX-HEAPIFY .A;i/  for i>A:  heap-size=2? \n6.2-6  \nThe code for M AX-HEAPIFY is quite  ef\u00fbcient  in terms  of constant  factors,  except  \npossibly  for  the  recursive  call  in line  10,  for  which  some  compilers might produce \ninef\u00fbcient  code.  Write  an ef\u00fbcient  MAX-HEAPIFY that uses an iterative control \nconstruct (a loop) instead of recursion. 6.3  Building  a heap  167 \n6.2-7  \nShow  that  the  worst-case  running  time  of MAX-HEAPIFY on a heap of size n \nis \ufffd.lg n/. (Hint: For a heap with n nodes, give node values that cause M AX- \nHEAPIFY to be called recursively at every node on a simple path from the root \ndown to a leaf.) \n6.3  Building  a heap  \nThe procedure B UILD-MAX-HEAP converts an array A\u01521  W n\ufffd into  a max-heap  by  \ncalling M AX-HEAPIFY in a bottom-up  manner.  Exercise  6.1-8  says  that  the  ele-  \nments in the subarray A\u0152bn=2c C  1 W n\ufffd are all leaves of the tree, and so each is \na 1-element  heap  to begin  with.  BUILD-MAX-HEAP goes  through  the  remain-  \ning nodes of the tree and runs M AX-HEAPIFY on  each  one.  Figure  6.3  shows  an \nexample of the action of B UILD-MAX-HEAP. \nBUILD-MAX-HEAP .A;n/  \n1 A:  heap-size  D n \n2 for  i D bn=2c downto  1 \n3 MAX-HEAPIFY .A;i/  \nTo show why B UILD-MAX-HEAP works correctly, we use the following loop \ninvariant: \nAt the start of each iteration of the for  loop  of lines  233,  each  node  i C 1; \ni C 2;:::;n  is the  root  of a max-heap.  \nWe  need  to show  that  this  invariant  is true  prior  to the  \u00fbrst  loop iteration, that each \niteration of the loop maintains the invariant, that  the loop terminates, and that the \ninvariant provides a useful property to show correc tness when the loop terminates. \nInitialization:  Prior  to the  \u00fbrst  iteration  of the  loop,  i D bn=2c. Each node \nbn=2c C  1; bn=2c C  2;:::;n  is a leaf  and  is thus  the  root  of a trivial  max-heap.  \nMaintenance:  To see that each iteration maintains the loop invar iant, observe \nthat the children of node i are numbered higher than i . By the loop invariant, \ntherefore,  they  are  both  roots  of max-heaps.  This  is precise ly the condition \nrequired for the call M AX-HEAPIFY .A;i/  to make node i a max-heap  root.  \nMoreover, the M AX-HEAPIFY call preserves the property that nodes i C 1; \ni C 2;:::;n  are  all  roots  of max-heaps.  Decrementing  i in the for  loop update \nreestablishes the loop invariant for the next itera tion. 168 Chapter 6 Heapsort \n1 \n2 3 \n4 5 6 7 \n8 9 10  1 \n2 3 \n4 5 6 7 \n8 9 10  1 \n2 3 \n4 5 6 7 \n8 9 10  1 \n2 3 \n4 5 6 7 \n8 9 10  1 \n2 3 \n4 5 6 7 \n8 9 10  1 \n2 3 \n4 5 6 7 \n8 9 10  4 \n1 3 \n2 9 10  \n14  8 7 \n(a) 16  4 1 2 3 16  9 10  14  8 7 \n4 \n1 3 \n2 9 10  \n14  8 7 \n(b) 16  \n4 \n1 3 \n14  9 10  \n2 8 7 \n(c) 16  4 \n1 10  \n14  9 3 \n2 8 7 \n(d) 16  \n4 \n16  10  \n14  9 3 \n2 8 1 \n(e) 7 16  \n14  10  \n8 9 3 \n2 4 1 \n(f) 7 A \ni i \ni i \ni \nFigure  6.3  The operation of B UILD-MAX-HEAP, showing the data structure before the call to \nMAX-HEAPIFY in line  3 of BUILD-MAX-HEAP. The node indexed by i in each iteration is shown \nin blue. (a)  A 10-element  input  array  A and the binary tree it represents. The loop index i refers \nto node 5 before the call M AX-HEAPIFY.A;i/ . (b)  The  data  structure  that  results.  The  loop  in-  \ndex i for the next iteration refers to node 4. (c)\u2013(e)  Subsequent iterations of the for  loop in \nBUILD-MAX-HEAP. Observe  that  whenever  MAX-HEAPIFY is called on a node, the two subtrees \nof that  node  are  both  max-heaps.  (f)  The  max-heap  after  BUILD-MAX-HEAP \u00fbnishes.  6.3  Building  a heap  169 \nTermination:  The loop makes exactly bn=2c iterations, and so it terminates. At \ntermination, i D 0. By the loop invariant, each node 1;2;:::;n  is the root of a \nmax-heap.  In particular,  node  1 is. \nWe can compute a simple upper bound on the running time of B UILD-MAX- \nHEAP as follows. Each call to M AX-HEAPIFY costs O.lg n/ time, and B UILD- \nMAX-HEAP makes O.n/  such calls. Thus, the running time is O.n  lg n/. This \nupper bound, though correct, is not as tight as it can be. \nWe can derive a tighter asymptotic bound by observi ng that the time for M AX- \nHEAPIFY to run at a node varies with the height of the node  in the tree, and that the \nheights  of most  nodes  are  small.  Our  tighter  analysis  relies  on the properties that \nan n-element  heap  has  height  blg nc (see  Exercise  6.1-2)  and  at most  \u00db \nn=2  hC1 \ue00c \nnodes of any height h (see  Exercise  6.3-4).  \nThe time required by M AX-HEAPIFY when called on a node of height h \nis O.h/ . Letting c be the constant implicit in the asymptotic notation , we can \nexpress the total cost of B UILD-MAX-HEAP as being bounded from above by P  blg nc \nhD0 \u00db n=2  hC1 \ue00c ch. As  Exercise  6.3-2  shows,  we  have  \u00db n=2  hC1 \ue00c \ue004 1=2  for \n0 \u0dc4 h \u0dc4 blg nc. Since dx e \u0dc4  2x  for any x \ue004 1=2, we have \u00db \nn=2  hC1 \ue00c \n\u0dc4 n=2  h . We \nthus obtain \nblg nc X  \nhD0 \u00e5 n \n2 hC1 \u00e6 \nch  \n\u0dc4 blg nc X  \nhD0 n \n2 h ch  \nD cn  blg nc X  \nhD0 h \n2 h \n\u0dc4 cn  1  X  \nhD0 h \n2 h \n\u0dc4 cn  \ue001 1=2  \n.1 \ue003 1=2/  2 (by  equation  (A.11)  on  page  1142  with  x D 1=2) \nD O.n/:  \nHence,  we  can  build  a max-heap  from  an unordered  array  in linear time. \nTo  build  a min-heap,  use  the  procedure  BUILD-MIN-HEAP, which is the same as \nBUILD-MAX-HEAP but with the call to M AX-HEAPIFY in line  3 replaced  by  a call  \nto M IN-HEAPIFY (see  Exercise  6.2-3).  BUILD-MIN-HEAP produces  a min-heap  \nfrom an unordered linear array in linear time. 170 Chapter 6 Heapsort \nExercises  \n6.3-1  \nUsing  Figure  6.3  as a model,  illustrate  the  operation  of BUILD-MAX-HEAP on the \narray A D h5;3;17;10;84;19;6;22;9 i. \n6.3-2  \nShow that \u00db \nn=2  hC1 \ue00c \n\ue004 1=2  for 0 \u0dc4 h \u0dc4 blg nc. \n6.3-3  \nWhy does the loop index i in line 2 of B UILD-MAX-HEAP decrease from bn=2c \nto 1 rather than increase from 1 to bn=2c? \n6.3-4  \nShow that there are at most \u00db \nn=2  hC1 \ue00c \nnodes of height h in any n-element  heap.  \n6.4  The  heapsort  algorithm  \nThe heapsort algorithm, given by the procedure H EAPSORT , starts by calling the \nBUILD-MAX-HEAP procedure  to build  a max-heap  on  the  input  array  A\u01521  W n\ufffd. \nSince the maximum element of the array is stored at  the root A\u01521\ufffd, HEAPSORT  can \nplace  it into  its  correct  \u00fbnal  position  by  exchanging  it with  A\u0152n\ufffd. If the procedure \nthen discards node n from  the  heap4and  it can  do  so by  simply  decrementing  \nA:  heap-size4the  children  of the  root  remain  max-heaps,  but  the  new  root  element \nmight  violate  the  max-heap  property.  To  restore  the  max-heap  property,  the  pro-  \ncedure just calls M AX-HEAPIFY .A;1/, which  leaves  a max-heap  in A\u01521  W n \ue003 1\ufffd. \nThe HEAPSORT  procedure  then  repeats  this  process  for  the  max-heap  of size  n \ue003 1 \ndown to a heap of size 2. (See  Exercise  6.4-2  for  a precise  loop  invariant.)  \nHEAPSORT  .A;n/  \n1 BUILD-MAX-HEAP .A;n/  \n2 for  i D n downto  2 \n3 exchange A\u01521\ufffd  with A\u0152i\ufffd  \n4 A:  heap-size  D A:  heap-size  \ue003 1 \n5 MAX-HEAPIFY .A;1/  \nFigure  6.4  shows  an example  of the  operation  of HEAPSORT  after  line  1 has  built  \nthe  initial  max-heap.  The  \u00fbgure  shows  the  max-heap  before  the  \u00fbrst  iteration  of \nthe for  loop  of lines  235  and  after  each  iteration.  6.4 The heapsort algorithm 171 \n(a) (b) (c) \n(d) (e) (f) \n(g) (h) (i) \n(j) (k) 1 2 3 4 7 8 9 10  14  16  10  2 \n1 3 \n4 7 8 9 \n16  14  \n1 \n2 3 \n4 7 8 9 \n16  14  10  3 \n2 1 \n9 8 7 4 \n10  14  16  4 \n2 3 \n9 8 7 1 \n10  14  16  8 \n3 7 \n4 2 1 9 \n16  14  10  7 \n4 3 \n9 8 2 1 \n10  14  16  9 \n8 3 \n2 1 7 4 \n16  14  10  10  \n8 9 \n3 1 7 4 \n16  14  2 14  \n8 10  \n3 9 7 4 \n16  1 2 16  \n14  10  \n3 9 7 8 \n1 4 2 \nA i i \ni i i \ni i i \ni \nFigure  6.4  The operation of H EAPSORT . (a)  The  max-heap  data  structure  just  after  BUILD-MAX- \nHEAP has  built  it in line  1. (b)\u2013(j)  The  max-heap  just  after  each  call  of MAX-HEAPIFY in line  5, \nshowing the value of i at that  time.  Only  blue  nodes  remain  in the  heap.  Tan  nodes  contain the largest \nvalues in the array, in sorted order. (k)  The resulting sorted array A. 172 Chapter 6 Heapsort \nThe HEAPSORT  procedure takes O.n  lg n/ time, since the call to B UILD-MAX- \nHEAP takes O.n/  time and each of the n \ue003 1 calls to M AX-HEAPIFY takes O.lg n/ \ntime. \nExercises  \n6.4-1  \nUsing  Figure  6.4  as a model,  illustrate  the  operation  of HEAPSORT  on the array \nA D h5;13;2;25;7;17;20;8;4 i. \n6.4-2  \nArgue the correctness of H EAPSORT  using the following loop invariant: \nAt the start of each iteration of the for  loop  of lines  235,  the  subarray  A\u01521  W i\ufffd \nis a max-heap  containing  the  i smallest elements of A\u01521  W n\ufffd, and  the  subar-  \nray A\u0152i  C 1 W n\ufffd contains the n \ue003 i largest elements of A\u01521  W n\ufffd, sorted. \n6.4-3  \nWhat is the running time of H EAPSORT  on an array A of length n that is already \nsorted  in increasing  order?  How  about  if the  array  is already  sorted in decreasing \norder?  \n6.4-4  \nShow  that  the  worst-case  running  time  of HEAPSORT  is \ufffd.n  lg n/. \n? 6.4-5  \nShow that when all the elements of A are  distinct,  the  best-case  running  time  of \nHEAPSORT  is \ufffd.n  lg n/. \n6.5  Priority  queues  \nIn Chapter  8, we  will  see  that  any  comparison-based  sorting  algorithm requires \n\ufffd.n  lg n/ comparisons and hence \ufffd.n  lg n/ time.  Therefore,  heapsort  is asymp-  \ntotically  optimal  among  comparison-based  sorting  algorithms.  Yet,  a good  imple-  \nmentation  of quicksort,  presented  in Chapter  7, usually  beats  it in practice.  Never-  \ntheless, the heap data structure itself has many us es. In this section, we present one \nof the  most  popular  applications  of a heap:  as an ef\u00fbcient  priority queue. As with \nheaps,  priority  queues  come  in two  forms:  max-priority  queues  and  min-priority  \nqueues.  We\u2019ll  focus  here  on  how  to implement  max-priority  queues, which are \nin turn  based  on  max-heaps.  Exercise  6.5-3  asks  you  to write  the procedures for \nmin-priority  queues.  6.5  Priority  queues  173 \nA priority  queue  is a data structure for maintaining a set S of elements, each \nwith an associated value called a key. A max-priority  queue  supports the following \noperations: \nI NSERT.S;x;k/  inserts the element x with key k into the set S , which is equivalent \nto the operation S D S [ fx g. \nMAXIMUM.S/  returns the element of S with the largest key. \nEXTRACT-MAX.S/  removes and returns the element of S with the largest key. \nI NCREASE-KEY .S;x;k/  increases the value of element x \u2019s key  to the  new  value  k, \nwhich is assumed to be at least as large as x \u2019s current  key  value.  \nAmong  their  other  applications,  you  can  use  max-priority  queues to schedule \njobs  on  a computer  shared  among  multiple  users.  The  max-prio rity queue keeps \ntrack of the jobs to be performed and their relativ e priorities.  When  a job  is \u00fbn-  \nished  or interrupted,  the  scheduler  selects  the  highest-pr iority job from among \nthose pending by calling E XTRACT-MAX. The scheduler can add a new job to \nthe queue at any time by calling I NSERT . \nAlternatively, a min-priority  queue  supports the operations I NSERT , MINIMUM , \nEXTRACT-MIN, and D ECREASE-KEY. A min-priority  queue  can  be used  in an \nevent-driven  simulator.  The  items  in the  queue  are  events  to be simulated, each \nwith an associated time of occurrence that serves a s its key. The events must be \nsimulated in order of their time of occurrence, bec ause the simulation of an event \ncan cause other events to be simulated in the futur e. The simulation program calls \nEXTRACT-MIN at each step to choose the next event to simulate. As new events are \nproduced,  the  simulator  inserts  them  into  the  min-priority  queue by calling I NSERT . \nWe\u2019ll  see  other  uses  for  min-priority  queues,  highlighting  the D ECREASE-KEY \noperation,  in Chapters  21  and  22.  \nWhen you use a heap to implement a priority queue w ithin a given application, \nelements of the priority queue correspond to object s in the application.  Each  ob-  \nject contains a key. If the priority queue is imple mented by a heap, you need to \ndetermine which application object corresponds to a  given heap element, and vice \nversa. Because the heap elements are stored in an a rray, you need a way to map \napplication objects to and from array indices. \nOne  way  to map  between  application  objects  and  heap  elements  uses handles , \nwhich are additional information stored in the obje cts and heap elements that give \nenough information to perform the mapping. Handles are often implemented to \nbe opaque to the surrounding code, thereby maintain ing an abstraction  barrier  be-  \ntween the application and the priority queue. For e xample, the handle within an \napplication object might contain the corresponding index into the heap array. But \nsince only the code for the priority queue accesses  this index, the index is entirely \nhidden from the application code. Because heap elem ents change locations within 174 Chapter 6 Heapsort \nthe array during heap operations, an actual impleme ntation of the priority queue, \nupon relocating a heap element, must also update th e array indices  in the  corre-  \nsponding handles. Conversely, each element in the h eap might contain a pointer \nto the corresponding application object, but the he ap element knows this pointer \nas only an opaque handle and the application maps t his handle to an application \nobject.  Typically,  the  worst-case  overhead  for  maintainin g handles is O.1/  per \naccess. \nAs an alternative to incorporating handles in appli cation objects, you can store \nwithin the priority queue a mapping from applicatio n objects to array indices in the \nheap. The advantage of doing so is that the mapping  is contained entirely within \nthe priority queue, so that the application objects  need no further embellishment. \nThe disadvantage lies in the additional cost of est ablishing and maintaining the \nmapping.  One  option  for  the  mapping  is a hash  table  (see  Chapter  11).  1 The added \nexpected time for a hash table to map an object to an array index is just O.1/ , \nthough  the  worst-case  time  can  be as bad  as \u201a.n/ . \nLet\u2019s  see  how  to implement  the  operations  of a max-priority  queue  using  a max-  \nheap. In the previous sections, we treated the arra y elements as the keys to be \nsorted, implicitly assuming that any satellite data  moved with the corresponding \nkeys. When a heap implements a priority queue, we i nstead treat each  array  ele-  \nment as a pointer to an object in the priority queu e, so that the object is analogous \nto the satellite data when sorting. We further assu me that each such object has an \nattribute key, which determines where in the heap the object bel ongs. For a heap \nimplemented by an array A, we refer to A\u0152i\ufffd:  key. \nThe procedure M AX-HEAP-MAXIMUM on the facing page implements the \nMAXIMUM operation in \u201a.1/  time, and M AX-HEAP-EXTRACT-MAX implements \nthe operation E XTRACT-MAX. M AX-HEAP-EXTRACT-MAX is similar to the for  \nloop  body  (lines  335)  of the  HEAPSORT  procedure. We implicitly assume that \nMAX-HEAPIFY compares  priority-queue  objects  based  on  their  key  attributes. We \nalso assume that when M AX-HEAPIFY exchanges  elements  in the  array,  it is ex-  \nchanging pointers and also that it updates the mapp ing between objects  and  ar-  \nray indices. The running time of M AX-HEAP-EXTRACT-MAX is O.lg n/, since \nit performs only a constant amount of work on top o f the O.lg n/ time for \nMAX-HEAPIFY , plus whatever overhead is incurred within M AX-HEAPIFY for \nmapping  priority-queue  objects  to array  indices.  \nThe procedure M AX-HEAP-I NCREASE-KEY on  page  176  implements  the  \nI NCREASE-KEY operation.  It \u00fbrst  veri\u00fbes  that  the  new  key  k will not cause the \nkey in the object x to decrease, and if there is no problem, it gives x the new key \nvalue.  The  procedure  then  \u00fbnds  the  index  i in the array corresponding to object x , \n1 In Python, dictionaries are implemented with hash t ables. 6.5  Priority  queues  175 \nMAX-HEAP-MAXIMUM.A/  \n1 if A:  heap-size  <1  \n2 error  <heap  under\u00fcow=  \n3 return  A\u01521\ufffd  \nMAX-HEAP-EXTRACT-MAX .A/  \n1 max D MAX-HEAP-MAXIMUM.A/  \n2 A\u01521\ufffd  D A\u0152A:  heap-size\ufffd \n3 A:  heap-size  D A:  heap-size  \ue003 1 \n4 MAX-HEAPIFY .A;1/  \n5 return  max \nso that A\u0152i\ufffd  is x . Because increasing the key of A\u0152i\ufffd  might  violate  the  max-heap  \nproperty, the procedure then, in a manner reminisce nt of the insertion loop (lines \n537)  of I NSERTION-SORT  on  page  19,  traverses  a simple  path  from  this  node  to-  \nward  the  root  to \u00fbnd  a proper  place  for  the  newly  increased  key  . As M AX-HEAP- \nI NCREASE-KEY traverses  this  path,  it repeatedly  compares  an element\u2019s  key to \nthat of its parent, exchanging pointers and continu ing if the element\u2019s  key  is larger,  \nand  terminating  if the  element\u2019s  key  is smaller,  since  the  max-heap  property  now  \nholds.  (See  Exercise  6.5-7  for  a precise  loop  invariant.)  Like M AX-HEAPIFY when \nused in a priority queue, M AX-HEAP-I NCREASE-KEY updates the information \nthat maps objects to array indices when array eleme nts are exchanged.  Figure  6.5  \nshows an example of a M AX-HEAP-I NCREASE-KEY operation. In addition to \nthe overhead for mapping priority queue objects to array indices, the running time \nof M AX-HEAP-I NCREASE-KEY on an n-element  heap  is O.lg n/, since the path \ntraced  from  the  node  updated  in line  3 to the  root  has  length  O.lg n/. \nThe procedure M AX-HEAP-I NSERT on the next page implements the I NSERT \noperation. It takes as inputs the array A implementing  the  max-heap,  the  new  \nobject x to be inserted  into  the  max-heap,  and  the  size  n of array A. The procedure \n\u00fbrst  veri\u00fbes  that  the  array  has  room  for  the  new  element.  It then expands the \nmax-heap  by  adding  to the  tree  a new  leaf  whose  key  is \ue0031. Then it calls M AX- \nHEAP-I NCREASE-KEY to set the key of this new element to its correct v alue and \nmaintain  the  max-heap  property.  The  running  time  of MAX-HEAP-I NSERT on an \nn-element  heap  is O.lg n/ plus the overhead for mapping priority queue object s to \nindices. \nIn summary,  a heap  can  support  any  priority-queue  operation  on a set of size n in \nO.lg n/ time, plus the overhead for mapping priority queue objects to array indices. 176 Chapter 6 Heapsort \nMAX-HEAP-I NCREASE-KEY .A;x;k/  \n1 if k<x:  key  \n2 error  <new key is smaller than current key= \n3 x: key  D k \n4 \u00fbnd  the  index  i in array A where object x occurs \n5 while  i >1  and A\u0152PARENT.i/\ufffd:  key  <A\u0152i\ufffd:  key  \n6 exchange A\u0152i\ufffd  with A\u0152PARENT.i/\ufffd, updating the information that maps \npriority queue objects to array indices \n7 i D PARENT.i/  \nMAX-HEAP-I NSERT .A;x;n/  \n1 if A:  heap-size  == n \n2 error  <heap  over\u00fcow=  \n3 A:  heap-size  D A:  heap-size  C 1 \n4 k D x: key  \n5 x: key  D \ue0031  \n6 A\u0152A:  heap-size\ufffd D x \n7 map x to index heap-size  in the array \n8 MAX-HEAP-I NCREASE-KEY .A;x;k/  \nExercises  \n6.5-1  \nSuppose  that  the  objects  in a max-priority  queue  are  just  keys.  Illustrate  the  opera-  \ntion of M AX-HEAP-EXTRACT-MAX on the heap A D h15;13;9;5;12;8;7;4;0;  \n6;2;1 i. \n6.5-2  \nSuppose  that  the  objects  in a max-priority  queue  are  just  keys.  Illustrate  the  opera-  \ntion of M AX-HEAP-I NSERT .A;10/  on the heap A D h15;13;9;5;12;8;7;4;0;6;  \n2;1i. \n6.5-3  \nWrite  pseudocode  to implement  a min-priority  queue  with  a min-heap  by  writing  \nthe procedures M IN-HEAP-MINIMUM , MIN-HEAP-EXTRACT-MIN, MIN-HEAP- \nDECREASE-KEY, and M IN-HEAP-I NSERT . \n6.5-4  \nWrite pseudocode for the procedure M AX-HEAP-DECREASE-KEY .A;x;k/  in a \nmax-heap.  What  is the  running  time  of your  procedure?  6.5  Priority  queues  177 \n16  \n14  10  \n8 7 9 3 \n2 4 1 \n(a) i 16  \n14  10  \n8 7 9 3 \n2 15  1 \n(b) \n16  \n14  10  \n8 7 9 3 \n2 15  \n1 \n(c) i \ni 16  \n14  10  \n8 7 9 3 \n2 15  \n1 \n(d) i \nFigure  6.5  The operation of M AX-HEAP-I NCREASE-KEY. Only  the  key  of each  element  in the  \npriority queue is shown. The node indexed by i in each iteration is shown in blue. (a)  The  max-heap  \nof Figure  6.4(a)  with  i indexing the node whose key is about to be increase d. (b)  This node has its \nkey increased to 15. (c)  After one iteration of the while  loop  of lines  537,  the  node  and  its  parent  \nhave exchanged keys, and the index i moves up to the parent. (d)  The  max-heap  after  one  more  \niteration of the while  loop. At this point, A\u0152PARENT.i/\ufffd  \ue004 A\u0152i\ufffd. The  max-heap  property  now  holds  \nand the procedure terminates. \n6.5-5  \nWhy does M AX-HEAP-I NSERT bother setting the key of the inserted object to \ue0031  \nin line  5 given  that  line  8 will  set  the  object\u2019s  key  to the  desired  value?  \n6.5-6  \nProfessor Uriah suggests replacing the while  loop  of lines  537  in MAX-HEAP- \nI NCREASE-KEY by a call to M AX-HEAPIFY. Explain  the  \u00fcaw  in the  professor\u2019s  \nidea. \n6.5-7  \nArgue the correctness of M AX-HEAP-I NCREASE-KEY using the following loop \ninvariant: 178 Chapter 6 Heapsort \nAt the start of each iteration of the while  loop  of lines  537:  \na. If both nodes P ARENT.i/  and L EFT.i/  exist, then A\u0152PARENT.i/\ufffd:  key  \ue004 \nA\u0152LEFT.i/\ufffd:  key. \nb. If both nodes P ARENT.i/  and RIGHT.i/  exist, then A\u0152PARENT.i/\ufffd:  key  \ue004 \nA\u0152RIGHT.i/\ufffd:  key. \nc. The subarray A\u01521  W A:  heap-size\ufffd satis\u00fbes  the  max-heap  property,  except  \nthat there may be one violation, which is that A\u0152i\ufffd:  key  may be greater \nthan A\u0152PARENT.i/\ufffd:  key. \nYou may assume that the subarray A\u01521  W A:  heap-size\ufffd satis\u00fbes  the  max-heap  prop-  \nerty at the time M AX-HEAP-I NCREASE-KEY is called. \n6.5-8  \nEach  exchange  operation  on  line  6 of MAX-HEAP-I NCREASE-KEY typically  re-  \nquires three assignments, not counting the updating  of the mapping from objects \nto array indices. Show how to use the idea of the i nner loop of I NSERTION-SORT  \nto reduce the three assignments to just one assignm ent. \n6.5-9  \nShow  how  to implement  a \u00fbrst-in,  \u00fbrst-out  queue  with  a priori ty queue. Show \nhow  to implement  a stack  with  a priority  queue.  (Queues  and  stacks  are  de\u00fbned  in \nSection  10.1.3.)  \n6.5-10  \nThe operation M AX-HEAP-DELETE .A;x/  deletes the object x from  max-heap  A. \nGive  an implementation  of MAX-HEAP-DELETE for an n-element  max-heap  that  \nruns in O.lg n/ time plus the overhead for mapping priority queue o bjects to array \nindices. \n6.5-11  \nGive  an O.n  lg k/-time  algorithm  to merge  k sorted lists into one sorted list, \nwhere n is the total number of elements in all the input li sts. ( Hint: Use  a min-  \nheap for k-way  merging.)  \nProblems  \n6-1  Building  a heap  using  insertion  \nOne  way  to build  a heap  is by  repeatedly  calling  MAX-HEAP-I NSERT to insert the \nelements into the heap. Consider the procedure B UILD-MAX-HEAP 0 on the facing \npage. It assumes that the objects being inserted ar e just the heap elements. Problems for Chapter 6 179 \nBUILD-MAX-HEAP 0 .A;n/  \n1 A:  heap-size  D 1 \n2 for  i D 2 to n \n3 MAX-HEAP-I NSERT .A;A\u0152i\ufffd;n/  \na. Do the procedures B UILD-MAX-HEAP and B UILD-MAX-HEAP 0 always create \nthe  same  heap  when  run  on  the  same  input  array?  Prove  that  they  do, or provide \na counterexample. \nb. Show that in the worst case, B UILD-MAX-HEAP 0 requires \u201a.n  lg n/ time to \nbuild an n-element  heap.  \n6-2  Analysis  of d -ary  heaps  \nA d -ary  heap  is like a binary heap, but (with one possible excep tion) nonleaf nodes \nhave d children instead of two children. In all parts of t his problem, assume that \nthe time to maintain the mapping between objects an d heap elements is O.1/  per \noperation. \na. Describe how to represent a d -ary  heap  in an array.  \nb. Using \u201a-notation,  express  the  height  of a d -ary  heap  of n elements in terms of \nn and d . \nc. Give  an ef\u00fbcient  implementation  of EXTRACT-MAX in a d -ary  max-heap.  An-  \nalyze its running time in terms of d and n. \nd. Give  an ef\u00fbcient  implementation  of I NCREASE-KEY in a d -ary  max-heap.  An-  \nalyze its running time in terms of d and n. \ne. Give  an ef\u00fbcient  implementation  of I NSERT in a d -ary  max-heap.  Analyze  its  \nrunning time in terms of d and n. \n6-3  Young  tableaus  \nAn m \ue005 n Young  tableau  is an m \ue005 n matrix such that the entries of each row are \nin sorted order from left to right and the entries of each column are in sorted order \nfrom top to bottom. Some of the entries of a Young tableau may be 1, which we \ntreat as nonexistent elements. Thus, a Young tablea u can be used to hold r \u0dc4 mn  \n\u00fbnite  numbers.  \na. Draw a 4 \ue005 4 Young tableau containing the elements f9;16;3;2;4;8;5;14;12 g . 180 Chapter 6 Heapsort \nb. Argue that an m \ue005 n Young tableau Y is empty if Y\u01521;1\ufffd  D 1 . Argue that Y \nis full (contains mn  elements) if Y\u0152m;n\ufffd<  1. \nc. Give  an algorithm  to implement  EXTRACT-MIN on a nonempty m \ue005 n Young \ntableau that runs in O.m  C n/ time.  Your  algorithm  should  use  a recur-  \nsive subroutine that solves an m \ue005 n problem by recursively solving either \nan .m  \ue003 1/ \ue005 n or an m \ue005 .n \ue003 1/ subproblem. ( Hint: Think about M AX- \nHEAPIFY .) Explain why your implementation of E XTRACT-MIN runs in \nO.m  C n/ time. \nd. Show how to insert a new element into a nonfull m \ue005 n Young tableau in \nO.m  C n/ time. \ne. Using no other sorting method as a subroutine, show  how to use an n \ue005 n Young \ntableau to sort n 2 numbers in O.n  3 / time. \nf. Give  an O.m  C n/-time  algorithm  to determine  whether  a given  number  is \nstored in a given m \ue005 n Young tableau. \nChapter  notes  \nThe  heapsort  algorithm  was  invented  by  Williams  [456],  who  also described how \nto implement a priority queue with a heap. The B UILD-MAX-HEAP procedure was \nsuggested  by  Floyd  [145].  Schaffer  and  Sedgewick  [395]  show ed that in the best \ncase, the number of times elements move in the heap  during heapsort  is approxi-  \nmately .n=2/  lg n and that the average number of moves is approximate ly n lg n. \nWe  use  min-heaps  to implement  min-priority  queues  in Chapters  15,  21,  and  22.  \nOther,  more  complicated,  data  structures  give  better  time  bounds  for  certain  min-  \npriority  queue  operations.  Fredman  and  Tarjan  [156]  develo ped Fibonacci heaps, \nwhich support I NSERT and D ECREASE-KEY in O.1/  amortized  time  (see  Chap-  \nter  16).  That  is, the  average  worst-case  running  time  for  these operations is O.1/ . \nBrodal,  Lagogiannis,  and  Tarjan  [73]  subsequently  devised  strict Fibonacci heaps, \nwhich make these time bounds the actual running tim es. If the keys are unique \nand drawn from the set f0;1;:::;n  \ue003 1g of nonnegative integers, van Emde Boas \ntrees  [440,  441]  support  the  operations  I NSERT , DELETE , SEARCH , M INIMUM , \nMAXIMUM , PREDECESSOR , and SUCCESSOR  in O.lg lg n/ time. \nIf the data are b-bit  integers,  and  the  computer  memory  consists  of addressa ble \nb-bit  words,  Fredman  and  Willard  [157]  showed  how  to implemen t M INIMUM in \nO.1/  time and I NSERT and E XTRACT-MIN in O.  p \nlg n/ time.  Thorup  [436]  has  Notes for Chapter 6 181 \nimproved the O.  p \nlg n/ bound to O.lg lg n/ time by using randomized hashing, \nrequiring only linear space. \nAn important special case of priority queues occurs  when the sequence of \nEXTRACT-MIN operations is monotone, that  is, the  values  returned  by  succes-  \nsive E XTRACT-MIN operations are monotonically increasing over time. This case \narises in several important applications, such as D ijkstra\u2019s single-source  shortest-  \npaths algorithm, which we discuss in Chapter 22, an d in discrete-event  simula-  \ntion.  For  Dijkstra\u2019s  algorithm  it is particularly  importan t that the D ECREASE-KEY \noperation  be implemented  ef\u00fbciently.  For  the  monotone  case,  if the  data  are  in-  \ntegers in the range 1;2;:::;C  , Ahuja,  Mehlhorn,  Orlin,  and  Tarjan  [8]  describe  \nhow to implement E XTRACT-MIN and I NSERT in O.lg C/  amortized  time  (Chap-  \nter  16  presents  amortized  analysis)  and  DECREASE-KEY in O.1/  time, using a data \nstructure called a radix heap. The O.lg C/  bound can be improved to O.  p \nlg C/  \nusing Fibonacci heaps in conjunction with radix hea ps. Cherkassky,  Goldberg,  \nand Silverstein [90] further improved the bound to O.lg 1=3C\ue001 C/  expected time by \ncombining the multilevel bucketing structure of Den ardo and Fox  [112]  with  the  \nheap  of Thorup  mentioned  earlier.  Raman  [375]  further  impro ved these results to \nobtain a bound of O \u00e3 \nmin \u02da \nlg 1=4C\ue001 C;  lg 1=3C\ue001 n \ue009\u00e4 \n, for  any  \u00fbxed  \ufffd > 0 . \nMany  other  variants  of heaps  have  been  proposed.  Brodal  [72]  surveys some of \nthese developments. 7 Quicksort  \nThe  quicksort  algorithm  has  a worst-case  running  time  of \u201a.n  2 / on an input array \nof n numbers.  Despite  this  slow  worst-case  running  time,  quicks ort is often the \nbest practical choice for sorting because it is rem arkably ef\u00fbcient  on  average:  its  \nexpected running time is \u201a.n  lg n/ when all numbers are distinct, and the constant \nfactors hidden in the \u201a.n  lg n/ notation are small. Unlike merge sort, it also has \nthe  advantage  of sorting  in place  (see  page  158),  and  it works  well  even  in virtual-  \nmemory environments. \nOur  study  of quicksort  is broken  into  four  sections.  Section  7.1  describes  the  \nalgorithm and an important subroutine used by quick sort for partitioning. Because \nthe  behavior  of quicksort  is complex,  we\u2019ll  start  with  an intuitive discussion of \nits  performance  in Section  7.2  and  analyze  it precisely  at the end of the chapter. \nSection  7.3  presents  a randomized  version  of quicksort.  Whe n all elements are \ndistinct, 1 this randomized algorithm has a good expected runni ng time and  no  par-  \nticular  input  elicits  its  worst-case  behavior.  (See  Problem  7-2  for  the  case  in which  \nelements  may  be equal.)  Section  7.4  analyzes  the  randomized  algorithm, showing \nthat it runs in \u201a.n  2 / time in the worst case and, assuming distinct eleme nts, in \nexpected O.n  lg n/ time. \n1 You can enforce the assumption that the values in a n array A are distinct at the cost of \u201a.n/  \nadditional space and only constant overhead in runn ing time by converting each input value A\u0152i\ufffd  to \nan ordered pair .A\u0152i\ufffd;i/  with .A\u0152i\ufffd;i/<.A\u0152j\ufffd;j/  if A\u0152i\ufffd  < A\u0152j\ufffd  or if A\u0152i\ufffd  D A\u0152j\ufffd  and i < j  . \nThere are also more practical variants of quicksort  that work well when elements are not distinct. 7.1  Description  of quicksort  183 \n7.1  Description  of quicksort  \nQuicksort,  like  merge  sort,  applies  the  divide-and-conque r method introduced in \nSection  2.3.1.  Here  is the  three-step  divide-and-conquer  process  for  sorting  a sub-  \narray A\u0152p  W r\ufffd: \nDivide  by partitioning (rearranging) the array A\u0152p  W r\ufffd into two (possibly empty) \nsubarrays A\u0152p  W q \ue003 1\ufffd (the low  side) and A\u0152q  C 1 W r\ufffd (the high  side) such \nthat each element in the low side of the partition is less than or equal to the \npivot  A\u0152q\ufffd, which is, in turn, less than or equal to each ele ment in the high side. \nCompute the index q of the pivot as part of this partitioning procedure . \nConquer  by calling quicksort recursively to sort each of th e subarrays A\u0152p  W q \ue003 1\ufffd \nand A\u0152q  C 1 W r\ufffd. \nCombine  by doing nothing: because the two subarrays are alr eady sorted, no work \nis needed to combine them. All elements in A\u0152p  W q \ue003 1\ufffd are sorted and less than \nor equal to A\u0152q\ufffd, and all elements in A\u0152q  C 1 W r\ufffd are sorted and greater than or \nequal to the pivot A\u0152q\ufffd. The entire subarray A\u0152p  W r\ufffd cannot help but be sorted! \nThe  QUICKSORT  procedure implements quicksort. To sort an entire n-element  \narray A\u01521  W n\ufffd, the  initial  call  is QUICKSORT.A;1;n/ . \nQUICKSORT.A;p;r/  \n1 if p<r  \n2 / / Partition the subarray around the pivot, which ends  up in A\u0152q\ufffd. \n3 q D PARTITION.A;p;r/  \n4 QUICKSORT.A;p;q  \ue003 1/ / / recursively sort the low side \n5 QUICKSORT.A;q  C 1;r/  / / recursively sort the high side \nPartitioning  the  array  \nThe key to the algorithm is the P ARTITION  procedure on the next page, which \nrearranges the subarray A\u0152p  W r\ufffd in place, returning the index of the dividing point  \nbetween the two sides of the partition. \nFigure  7.1  shows  how  PARTITION  works on an 8-element  array.  PARTITION  \nalways selects the element x D A\u0152r\ufffd  as the pivot. As the procedure runs, each \nelement falls into exactly one of four regions, som e of which may be empty. At \nthe start of each iteration of the for  loop  in lines  336,  the  regions  satisfy  certain  \nproperties,  shown  in Figure  7.2.  We  state  these  properties  as a loop invariant: 184  Chapter  7 Quicksort  \nPARTITION.A;p;r/  \n1 x D A\u0152r\ufffd  / / the pivot \n2 i D p \ue003 1 / / highest index into the low side \n3 for  j D p to r \ue003 1 / / process each element other than the pivot \n4 if A\u0152j\ufffd  \u0dc4 x / / does  this  element  belong  on  the  low  side?  \n5 i D i C 1 / / index of a new slot in the low side \n6 exchange A\u0152i\ufffd  with A\u0152j\ufffd  / / put this element there \n7 exchange A\u0152i  C 1\ufffd with A\u0152r\ufffd  / / pivot goes just to the right of the low side \n8 return  i C 1 / / new index of the pivot \nAt  the  beginning  of each  iteration  of the  loop  of lines  336,  for any array \nindex k, the following conditions hold: \n1. if p \u0dc4 k \u0dc4 i , then A\u0152k\ufffd  \u0dc4 x (the  tan  region  of Figure  7.2);  \n2. if i C 1 \u0dc4 k \u0dc4 j \ue003 1, then A\u0152k\ufffd>x  (the blue region); \n3. if k D r , then A\u0152k\ufffd  D x (the yellow region). \nWe  need  to show  that  this  loop  invariant  is true  prior  to the  \u00fbrst iteration, that \neach iteration of the loop maintains the invariant,  that the loop terminates, and that \ncorrectness follows from the invariant when the loo p terminates. \nInitialization:  Prior  to the  \u00fbrst  iteration  of the  loop,  we  have  i D p \ue003 1 and \nj D p. Because no values lie between p and i and no values lie between i C 1 \nand j \ue003 1, the  \u00fbrst  two  conditions  of the  loop  invariant  are  trivially  satis\u00fbed.  \nThe  assignment  in line  1 satis\u00fbes  the  third  condition.  \nMaintenance:  As  Figure  7.3  shows,  we  consider  two  cases,  depending  on  the  \noutcome  of the  test  in line  4. Figure  7.3(a)  shows  what  happen s when A\u0152j\ufffd>x : \nthe only action in the loop is to increment j . After j has been incremented, the \nsecond condition holds for A\u0152j  \ue003 1\ufffd and all other entries remain unchanged. \nFigure  7.3(b)  shows  what  happens  when  A\u0152j\ufffd  \u0dc4 x : the loop increments i , \nswaps A\u0152i\ufffd  and A\u0152j\ufffd , and then increments j . Because of the swap, we now \nhave that A\u0152i\ufffd  \u0dc4 x , and condition 1 is satis\u00fbed.  Similarly,  we  also  have  that  \nA\u0152j  \ue003 1\ufffd >x  , since the item that was swapped into A\u0152j  \ue003 1\ufffd is, by the loop \ninvariant, greater than x . \nTermination:  Since the loop makes exactly r \ue003 p iterations,  it terminates,  where-  \nupon j D r . At that point, the unexamined subarray A\u0152j  W r \ue003 1\ufffd is empty, and \nevery entry in the array belongs to one of the othe r three sets described by the \ninvariant. Thus, the values in the array have been partitioned into three sets: \nthose less than or equal to x (the low side), those greater than x (the high side), \nand a singleton set containing x (the pivot). 7.1  Description  of quicksort  185 \n2 8 7 1 3 5 6 4 p,j r i \n(a) \n2 8 7 1 3 5 6 4 p,i r j \n(b) \n2 8 7 1 3 5 6 4 p,i r j \n(c) \n2 8 7 1 3 5 6 4 p,i r j \n(d) \n2 8 7 1 3 5 6 4 p r j \n(e) i \n2 8 7 1 3 5 6 4 p r j \n(f) i \n2 8 7 1 3 5 6 4 p r j \n(g) i \n2 8 7 1 3 5 6 4 p r \n(h) i \n2 8 7 1 3 5 6 4 p r \n(i) i \nFigure  7.1  The operation of P ARTITION  on a sample array. Array entry A\u0152r\ufffd  becomes the pivot \nelement x. Tan array elements all belong to the low side of the partition, with values at most x. \nBlue elements belong to the high side, with values greater than x. White elements have not yet been \nput into either side of the partition, and the yell ow element is the pivot x. (a)  The initial array and \nvariable settings. None of the elements have been p laced into either side of the partition. (b)  The \nvalue 2 is <swapped with itself= and put into the low side.  (c)\u2013(d)  The values 8 and 7 are placed into \nto high side. (e)  The values 1 and 8 are swapped, and the low side grows. (f)  The values 3 and 7 are \nswapped, and the low side grows. (g)\u2013(h)  The high side of the partition grows to include 5 and 6, \nand the loop terminates. (i)  Line  7 swaps  the  pivot  element  so that  it lies  between  the  two  sides of \nthe  partition,  and  line  8 returns  the  pivot\u2019s  new  index.  \nThe  \u00fbnal  two  lines  of PARTITION  \u00fbnish  up  by  swapping  the  pivot  with  the  left-  \nmost element greater than x , thereby moving the pivot into its correct place i n \nthe  partitioned  array,  and  then  returning  the  pivot\u2019s  new  index. The output of \nPARTITION  now  satis\u00fbes  the  speci\u00fbcations  given  for  the  divide  step.  In fact, it \nsatis\u00fbes  a slightly  stronger  condition:  after  line  3 of QUICKSORT , A\u0152q\ufffd  is strictly \nless than every element of A\u0152q  C 1 W r\ufffd. 186  Chapter  7 Quicksort  \n\u2264 x > x unknown x p i j r \nFigure  7.2  The four regions maintained by the procedure P ARTITION  on a subarray A\u0152p  W r\ufffd. The \ntan values in A\u0152p  W i\ufffd are all less than or equal to x, the blue values in A\u0152i  C 1 W j \ue003 1\ufffd are all greater \nthan x, the white values in A\u0152j  W r \ue003 1\ufffd have unknown relationships to x, and A\u0152r\ufffd  D x. \n\u2264 x > x x p i j r \n> x (a) \n\u2264 x > x x p i j r \n\u2264 x > x x p i j r \n\u2264 x (b) \n\u2264 x > x x p i j r \nFigure  7.3  The two cases for one iteration of procedure P ARTITION . (a)  If A\u0152j\ufffd  > x, the only \naction is to increment j , which maintains the loop invariant. (b)  If A\u0152j\ufffd  \u0dc4 x, index i is incremented, \nA\u0152i\ufffd  and A\u0152j\ufffd  are swapped, and then j is incremented. Again, the loop invariant is mainta ined. \nExercise  7.1-3  asks  you  to show  that  the  running  time  of PARTITION  on  a sub-  \narray A\u0152p  W r\ufffd of n D r \ue003 p C 1 elements is \u201a.n/ . \nExercises  \n7.1-1  \nUsing  Figure  7.1  as a model,  illustrate  the  operation  of PARTITION  on the array \nA D h13;19;9;5;12;8;7;4;21;2;6;11 i. 7.2  Performance  of quicksort  187 \n7.1-2  \nWhat value of q does PARTITION  return when all elements in the subarray A\u0152p  W r\ufffd \nhave  the  same  value?  Modify  PARTITION  so that q D b.p  C r/=2c when all \nelements in the subarray A\u0152p  W r\ufffd have the same value. \n7.1-3  \nGive  a brief  argument  that  the  running  time  of PARTITION  on a subarray of size n \nis \u201a.n/ . \n7.1-4  \nModify  QUICKSORT  to sort into monotonically decreasing order. \n7.2  Performance  of quicksort  \nThe running time of quicksort depends on how balanc ed each partitioning is, which \nin turn depends on which elements are used as pivot s. If the two sides  of a parti-  \ntion  are  about  the  same  size4the  partitioning  is balanced4t hen the algorithm runs \nasymptotically as fast as merge sort. If the partit ioning is unbalanced, however, it \ncan run asymptotically as slowly as insertion sort.  To allow you  to gain  some  intu-  \nition before diving into a formal analysis, this se ction informally investigates how \nquicksort performs under the assumptions of balance d versus unbalanced  partition-  \ning. \nBut  \u00fbrst,  let\u2019s  brie\u00fcy  look  at the  maximum  amount  of memory  that  quicksort  re-  \nquires. Although quicksort sorts in place according  to the de\u00fbnition  on  page  158,  \nthe  amount  of memory  it uses4aside  from  the  array  being  sorted4is  not  constant.  \nSince each recursive call requires a constant amoun t of space on the runtime stack, \noutside of the array being sorted, quicksort requir es space proportional  to the  max-  \nimum  depth  of the  recursion.  As  we\u2019ll  see  now,  that  could  be as bad as \u201a.n/  in the \nworst case. \nWorst-case  partitioning  \nThe  worst-case  behavior  for  quicksort  occurs  when  the  partitioning produces one \nsubproblem with n \ue003 1 elements and one with 0 elements.  (See  Section  7.4.1.)  \nLet us assume that this unbalanced partitioning ari ses in each recursive call. The \npartitioning costs \u201a.n/  time. Since the recursive call on an array of size 0 just \nreturns without doing anything, T.0/  D \u201a.1/ , and the recurrence for the running \ntime is 188  Chapter  7 Quicksort  \nT.n/  D T.n  \ue003 1/ C T.0/  C \u201a.n/  \nD T.n  \ue003 1/ C \u201a.n/:  \nBy summing the costs incurred at each level of the recursion, we obtain an \narithmetic  series  (equation  (A.3)  on  page  1141),  which  evaluates to \u201a.n  2 /. In-  \ndeed, the substitution method can be used to prove that the recurrence T.n/  D \nT.n  \ue003 1/ C \u201a.n/  has the solution T.n/  D \u201a.n  2 /. (See  Exercise  7.2-1.)  \nThus, if the partitioning is maximally unbalanced a t every recursive level of the \nalgorithm, the running time is \u201a.n  2 /. The  worst-case  running  time  of quicksort  is \ntherefore no better than that of insertion sort. Mo reover, the \u201a.n  2 / running time \noccurs  when  the  input  array  is already  completely  sorted4a  situation in which \ninsertion sort runs in O.n/  time. \nBest-case  partitioning  \nIn the most even possible split, P ARTITION  produces two subproblems, each of \nsize no more than n=2, since one is of size b.n \ue003 1/=2c \u0dc4  n=2  and one of size \nd.n \ue003 1/=2e \ue003  1 \u0dc4 n=2. In this case, quicksort runs much faster. An uppe r bound \non the running time can then be described by the re currence \nT.n/  D 2T.n=2/  C \u201a.n/:  \nBy  case  2 of the  master  theorem  (Theorem  4.1  on  page  102),  this  recurrence has the \nsolution T.n/  D \u201a.n  lg n/. Thus, if the partitioning is equally balanced at every \nlevel of the recursion, an asymptotically faster al gorithm results. \nBalanced  partitioning  \nAs  the  analyses  in Section  7.4  will  show,  the  average-case  running time of quicksort \nis much closer to the best case than to the worst c ase. By appreciating how the \nbalance of the partitioning affects the recurrence describing the running time, we \ncan gain an understanding of why. \nSuppose, for example, that the partitioning algorit hm always produces a 9-to-1 \nproportional  split,  which  at \u00fbrst  blush  seems  quite  unbalan ced. We then obtain the \nrecurrence \nT.n/  D T.9n=10/  C T.n=10/  C \u201a.n/;  \non  the  running  time  of quicksort.  Figure  7.4  shows  the  recursion  tree  for  this  re-  \ncurrence, where for simplicity the \u201a.n/  driving function has been replaced by n, \nwhich  won\u2019t  affect  the  asymptotic  solution  of the  recurrence  (as  Exercise  4.7-1  \non  page  118  justi\u00fbes).  Every  level  of the  tree  has  cost  n, until  the  recursion  bot-  \ntoms out in a base case at depth log 10  n D \u201a.lg n/, and then the levels have cost 7.2  Performance  of quicksort  189 \nn \nn n n n \n\u0dc4 n \u0dc4 n \n1 1 \nO.n  lg n/ log 10  n \nlog 10=9  n 1 \n10  n 9 \n10  n \n1 \n100  n 9 \n100  n 9 \n100  n 81  \n100  n \n81  \n1000  n 729  \n1000  n \nFigure  7.4  A recursion  tree  for  QUICKSORT  in which P ARTITION  always produces a 9-to-1 split, \nyielding a running time of O.n  lg n/. Nodes  show  subproblem  sizes,  with  per-level  costs  on  the  right. \nat most n. The recursion terminates at depth log 10=9  n D \u201a.lg n/. Thus, with a \n9-to-1 proportional split at every level of recursion, whi ch intuitively seems highly \nunbalanced, quicksort runs in O.n  lg n/ time4asymptotically  the  same  as if the  \nsplit were right down the middle. Indeed, even a 99-to-1 split yields an O.n  lg n/ \nrunning time. In fact, any split of constant  proportionality yields a recursion tree of \ndepth \u201a.lg n/, where the cost at each level is O.n/ . The running time is therefore \nO.n  lg n/ whenever the split has constant proportionality. Th e ratio of the split \naffects only the constant hidden in the O-notation.  \nIntuition  for  the  average  case  \nTo develop a clear notion of the expected behavior of quicksort, we must assume \nsomething about how its inputs are distributed. Bec ause quicksort determines the \nsorted order using only comparisons between input e lements, its behavior depends \non the relative ordering of the values in the array  elements given as the input, not \non the particular values in the array. As in the pr obabilistic analysis of the hiring \nproblem  in Section  5.2,  assume  that  all  permutations  of the  input numbers are \nequally likely and that the elements are distinct. \nWhen quicksort runs on a random input array, the pa rtitioning is highly unlikely \nto happen in the same way at every level, as our in formal analysis has assumed. 190  Chapter  7 Quicksort  \nn \n0 n31  \n(n31)/2  3 1 (n31)/2  n \n(n31)/2  \n(a) (b) (n31)/2  \u0398(n) \u0398(n) \nFigure  7.5  (a)  Two levels of a recursion tree for quicksort. The p artitioning at the root costs n \nand produces a <bad= split: two subarrays of sizes 0 and n \ue003 1. The partitioning of the subarray of \nsize n \ue003 1 costs n \ue003 1 and produces a <good= split: subarrays of size .n \ue003 1/=2  \ue003 1 and .n \ue003 1/=2 . \n(b)  A single level of a recursion tree that is well bal anced. In both parts, the partitioning cost for the  \nsubproblems shown with blue shading is \u201a.n/ . Yet the subproblems remaining to be solved in (a) , \nshown with tan shading, are no larger than the corr esponding subproblems remaining to be solved \nin (b). \nWe expect that some of the splits will be reasonabl y well balanced and that some \nwill  be fairly  unbalanced.  For  example,  Exercise  7.2-6  asks  you to show that about \n80% of the time P ARTITION  produces a split that is at least as balanced as 9 to 1, \nand about 20% of the time it produces a split that is less bala nced than 9 to 1. \nIn the average case, P ARTITION  produces a mix of <good= and <bad= splits. In a \nrecursion  tree  for  an average-case  execution  of PARTITION , the good and bad splits \nare distributed randomly throughout the tree. Suppo se for the sake of intuition that \nthe good and bad splits alternate levels in the tre e, and that the  good  splits  are  best-  \ncase  splits  and  the  bad  splits  are  worst-case  splits.  Figure  7.5(a)  shows  the  splits  \nat two consecutive levels in the recursion tree. At  the root of the tree, the cost is n \nfor partitioning, and the subarrays produced have s izes n \ue003 1 and 0: the worst case. \nAt the next level, the subarray of size n \ue003 1 undergoes  best-case  partitioning  into  \nsubarrays of size .n \ue003 1/=2  \ue003 1 and .n \ue003 1/=2. Let\u2019s  assume  that  the  base-case  cost  \nis 1 for the subarray of size 0. \nThe combination of the bad split followed by the go od split produces  three  sub-  \narrays of sizes 0, .n \ue003 1/=2  \ue003 1, and .n \ue003 1/=2  at a combined partitioning cost of \n\u201a.n/  C \u201a.n  \ue003 1/ D \u201a.n/ . This situation is at most a constant factor worse  than \nthat  in Figure  7.5(b),  namely,  where  a single  level  of partit ioning produces two \nsubarrays of size .n \ue003 1/=2 , at a cost of \u201a.n/ . Yet this latter situation is balanced! \nIntuitively, the \u201a.n  \ue003 1/ cost  of the  bad  split  in Figure  7.5(a)  can  be absorbed  \ninto the \u201a.n/  cost of the good split, and the resulting split is good. Thus, the  run-  \nning time of quicksort, when levels alternate betwe en good and bad splits, is like \nthe running time for good splits alone: still O.n  lg n/, but with a slightly larger \nconstant hidden by the O-notation.  We\u2019ll  analyze  the  expected  running  time  of a \nrandomized  version  of quicksort  rigorously  in Section  7.4.2. 7.3  A randomized  version  of quicksort  191 \nExercises  \n7.2-1  \nUse the substitution method to prove that the recur rence T.n/  D T.n  \ue003 1/ C \u201a.n/  \nhas the solution T.n/  D \u201a.n  2 /, as claimed  at the  beginning  of Section  7.2.  \n7.2-2  \nWhat  is the  running  time  of QUICKSORT  when all elements of array A have the \nsame  value?  \n7.2-3  \nShow  that  the  running  time  of QUICKSORT  is \u201a.n  2 / when the array A contains \ndistinct elements and is sorted in decreasing order . \n7.2-4  \nBanks often record transactions on an account in or der of the times  of the  trans-  \nactions, but many people like to receive their bank  statements with checks listed \nin order by check number. People usually write chec ks in order by  check  num-  \nber, and merchants usually cash them with reasonabl e dispatch. The problem of \nconverting  time-of-transaction  ordering  to check-number  ordering is therefore the \nproblem  of sorting  almost-sorted  input.  Explain  persuasiv ely why the procedure \nI NSERTION-SORT  might  tend  to beat  the  procedure  QUICKSORT  on this problem. \n7.2-5  \nSuppose that the splits at every level of quicksort  are in the constant proportion \u02db \nto \u02c7, where \u02db C \u02c7 D 1 and 0<\u02db  \u0dc4 \u02c7 <1 . Show that the minimum depth of a \nleaf in the recursion tree is approximately log 1=\u02db  n and that the maximum depth is \napproximately log 1=\u02c7  n. (Don\u2019t  worry  about  integer  round-off.)  \n7.2-6  \nConsider an array with distinct elements and for wh ich all permutations  of the  ele-  \nments are equally likely. Argue that for any consta nt 0<\u02db  \u0dc4 1=2, the probability \nis approximately 1 \ue003 2\u02db  that PARTITION  produces a split at least as balanced as \n1 \ue003 \u02db to \u02db. \n7.3  A randomized  version  of quicksort  \nIn exploring  the  average-case  behavior  of quicksort,  we  have  assumed  that  all  per-  \nmutations of the input numbers are equally likely. This assumption  does  not  al-  \nways hold, however, as, for example, in the situati on laid out in the premise for 192  Chapter  7 Quicksort  \nExercise  7.2-4.  Section  5.3  showed  that  judicious  randomiz ation can sometimes \nbe added to an algorithm to obtain good expected pe rformance over all inputs. For \nquicksort, randomization yields a fast and practica l algorithm.  Many  software  li- \nbraries provide a randomized version of quicksort a s their algorithm of choice for \nsorting large data sets. \nIn Section  5.3,  the  RANDOMIZED -HIRE-ASSISTANT procedure  explicitly  per-  \nmutes its input and then runs the deterministic H IRE-ASSISTANT procedure. We \ncould do the same for quicksort as well, but a diff erent randomization technique \nyields a simpler analysis. Instead of always using A\u0152r\ufffd  as the pivot, a randomized \nversion randomly chooses the pivot from the subarra y A\u0152p  W r\ufffd, where each element \nin A\u0152p  W r\ufffd has an equal probability of being chosen. It then e xchanges that element \nwith A\u0152r\ufffd  before partitioning. Because the pivot is chosen ra ndomly, we expect the \nsplit of the input array to be reasonably well bala nced on average. \nThe changes to P ARTITION  and  QUICKSORT  are  small.  The  new  partition-  \ning procedure, R ANDOMIZED -PARTITION , simply swaps before performing the \npartitioning. The new quicksort procedure, R ANDOMIZED -QUICKSORT , calls \nRANDOMIZED -PARTITION  instead of P ARTITION. We\u2019ll  analyze  this  algorithm  \nin the next section. \nRANDOMIZED -PARTITION  .A;p;r/  \n1 i D RANDOM.p;r/  \n2 exchange A\u0152r\ufffd  with A\u0152i\ufffd  \n3 return  PARTITION.A;p;r/  \nRANDOMIZED -QUICKSORT  .A;p;r/  \n1 if p<r  \n2 q D RANDOMIZED -PARTITION  .A;p;r/  \n3 RANDOMIZED -QUICKSORT  .A;p;q  \ue003 1/ \n4 RANDOMIZED -QUICKSORT  .A;q  C 1;r/  \nExercises  \n7.3-1  \nWhy do we analyze the expected running time of a ra ndomized algorithm and not \nits  worst-case  running  time?  7.4  Analysis  of quicksort  193 \n7.3-2  \nWhen RANDOMIZED -QUICKSORT  runs,  how  many  calls  are  made  to the  random-  \nnumber generator R ANDOM  in the  worst  case?  How  about  in the  best  case?  Give  \nyour answer in terms of \u201a-notation.  \n7.4  Analysis  of quicksort  \nSection  7.2  gave  some  intuition  for  the  worst-case  behavior  of quicksort and for \nwhy we expect the algorithm to run quickly. This se ction analyzes the behavior of \nquicksort  more  rigorously.  We  begin  with  a worst-case  analy sis, which applies to \neither  QUICKSORT  or RANDOMIZED -QUICKSORT , and conclude with an analysis \nof the expected running time of R ANDOMIZED -QUICKSORT . \n7.4.1  Worst-case  analysis  \nWe  saw  in Section  7.2  that  a worst-case  split  at every  level  of recursion in quicksort \nproduces a \u201a.n  2 / running  time,  which,  intuitively,  is the  worst-case  runnin g time \nof the algorithm. We now prove this assertion. \nWe\u2019ll  use  the  substitution  method  (see  Section  4.3)  to show  that the running \ntime of quicksort is O.n  2 /. Let T.n/  be the  worst-case  time  for  the  procedure  \nQUICKSORT  on an input of size n. Because the procedure P ARTITION  produces \ntwo subproblems with total size n \ue003 1, we obtain the recurrence \nT.n/  D max fT.q/  C T.n  \ue003 1 \ue003 q/ W 0 \u0dc4 q \u0dc4 n \ue003 1g C  \u201a.n/;  (7.1)  \nWe guess that T.n/  \u0dc4 cn  2 for some constant c >0 . Substituting this guess into \nrecurrence  (7.1)  yields  \nT.n/  \u0dc4 max \u02da \ncq  2 C c.n  \ue003 1 \ue003 q/ 2 W 0 \u0dc4 q \u0dc4 n \ue003 1 \ue009 \nC \u201a.n/  \nD c \ue001 max \u02da \nq 2 C .n \ue003 1 \ue003 q/ 2 W 0 \u0dc4 q \u0dc4 n \ue003 1 \ue009 \nC \u201a.n/:  \nLet\u2019s  focus  our  attention  on  the  maximization.  For  q D 0;1;:::;n  \ue003 1, we have \nq 2 C .n \ue003 1 \ue003 q/ 2 D q 2 C .n \ue003 1/ 2 \ue003 2q.n  \ue003 1/ C q 2 \nD .n \ue003 1/ 2 C 2q.q  \ue003 .n \ue003 1//  \n\u0dc4 .n \ue003 1/ 2 \nbecause q \u0dc4 n \ue003 1 implies that 2q.q  \ue003 .n \ue003 1//  \u0dc4 0. Thus every term in the \nmaximization is bounded by .n \ue003 1/ 2 . \nContinuing with our analysis of T.n/ , we obtain 194  Chapter  7 Quicksort  \nT.n/  \u0dc4 c.n  \ue003 1/ 2 C \u201a.n/  \n\u0dc4 cn  2 \ue003 c.2n  \ue003 1/ C \u201a.n/  \n\u0dc4 cn  2 ; \nby picking the constant c large enough that the c.2n  \ue003 1/ term dominates the \u201a.n/  \nterm. Thus T.n/  D O.n  2 /. Section  7.2  showed  a speci\u00fbc  case  where  quicksort  \ntakes \ufffd.n  2 / time: when partitioning is maximally unbalanced. Th us, the worst-  \ncase running time of quicksort is \u201a.n  2 /. \n7.4.2  Expected  running  time  \nWe have already seen the intuition behind why the e xpected running time of \nRANDOMIZED -QUICKSORT  is O.n  lg n/: if, in each level of recursion, the split \ninduced by R ANDOMIZED -PARTITION  puts any constant fraction of the elements \non one side of the partition, then the recursion tr ee has depth \u201a.lg n/ and O.n/  \nwork is performed at each level. Even if we add a f ew new levels with  the  most  un-  \nbalanced split possible between these levels, the t otal time remains O.n  lg n/. We \ncan analyze the expected running time of R ANDOMIZED -QUICKSORT  precisely \nby  \u00fbrst  understanding  how  the  partitioning  procedure  opera tes and then using this \nunderstanding to derive an O.n  lg n/ bound on the expected running time. This \nupper bound on the expected running time, combined with the \u201a.n  lg n/ best-case  \nbound  we  saw  in Section  7.2,  yields  a \u201a.n  lg n/ expected running time. We assume \nthroughout that the values of the elements being so rted are distinct. \nRunning  time  and  comparisons  \nThe  QUICKSORT  and RANDOMIZED -QUICKSORT  procedures differ only in how \nthey select pivot elements. They are the same in al l other respects.  We  can  there-  \nfore analyze R ANDOMIZED -QUICKSORT  by  considering  the  QUICKSORT  and \nPARTITION  procedures, but with the assumption that pivot elem ents are selected \nrandomly from the subarray passed to R ANDOMIZED -PARTITION. Let\u2019s  start  by  \nrelating  the  asymptotic  running  time  of QUICKSORT  to the  number  of times  ele-  \nments  are  compared  (all  in line  4 of PARTITION ), understanding that this analysis \nalso applies to R ANDOMIZED -QUICKSORT . Note that we are counting the number \nof times that array  elements  are compared, not comparisons of indices. \nLemma  7.1  \nThe  running  time  of QUICKSORT  on an n-element  array  is O.n  C X/, where X is \nthe number of element comparisons performed. 7.4  Analysis  of quicksort  195 \nProof  The  running  time  of QUICKSORT  is dominated by the time spent in the \nPARTITION  procedure. Each time P ARTITION  is called,  it selects  a pivot  ele-  \nment, which is never included in any future recursi ve calls to QUICKSORT  and \nPARTITION . Thus, there can be at most n calls to PARTITION  over  the  entire  ex-  \necution  of the  quicksort  algorithm.  Each  time  QUICKSORT  calls PARTITION , it \nalso recursively calls itself twice, so there are a t most 2n  calls  to the  QUICKSORT  \nprocedure itself. \nOne  call  to PARTITION  takes O.1/  time  plus  an amount  of time  that  is propor-  \ntional to the number of iterations of the for  loop  in lines  336.  Each  iteration  of this  \nfor  loop  performs  one  comparison  in line  4, comparing  the  pivot  element  to an-  \nother element of the array A. Therefore, the total time spent in the for  loop across \nall executions is proportional to X . Since there are at most n calls to PARTITION  \nand the time spent outside the for  loop is O.1/  for each call, the total time spent \nin PARTITION  outside of the for  loop is O.n/ . Thus the total time for quicksort is \nO.n  C X/. \nOur  goal  for  analyzing  RANDOMIZED -QUICKSORT , therefore, is to compute \nthe expected value E \u0152X\ufffd  of the random variable X denoting the total number of \ncomparisons performed in all calls to P ARTITION . To do so, we must understand \nwhen the quicksort algorithm compares two elements of the array and when it does \nnot.  For  ease  of analysis,  let\u2019s  index  the  elements  of the  array A by their position \nin the sorted output, rather than their position in  the input. That is, although the \nelements in A may  start  out  in any  order,  we\u2019ll  refer  to them  by  \u00b4 1 ;\u00b4  2 ;:::;\u00b4  n , \nwhere \u00b4 1 < \u00b4  2 < \ue001 \ue001 \ue001  < \u00b4  n , with strict inequality because we assume that all  \nelements are distinct. We denote the set f\u00b4 i ;\u00b4  i C1 ;:::;\u00b4  j g by Z ij . \nThe next lemma characterizes when two elements are compared. \nLemma  7.2  \nDuring the execution of R ANDOMIZED -QUICKSORT  on an array of n distinct  ele-  \nments \u00b4 1 <\u00b4  2 < \ue001 \ue001 \ue001  <\u00b4  n , an element \u00b4 i is compared with an element \u00b4 j , where \ni <j  , if and only if one of them is chosen as a pivot b efore any other element in \nthe set Z ij . Moreover, no two elements are ever compared twice . \nProof  Let\u2019s  look  at the  \u00fbrst  time  that  an element  x 2 Z ij is chosen as a pivot \nduring the execution of the algorithm. There are th ree cases to consider. If x is \nneither \u00b4 i nor \u00b4 j 4that  is, \u00b4 i <x <\u00b4  j 4then  \u00b4 i and \u00b4 j are not compared at any \nsubsequent time, because they fall into different s ides of the partition around x . \nIf x D \u00b4 i , then PARTITION  compares \u00b4 i with every other item in Z ij . Similarly, \nif x D \u00b4 j , then PARTITION  compares \u00b4 j with every other item in Z ij . Thus, \n\u00b4 i and \u00b4 j are  compared  if and  only  if the  \u00fbrst  element  to be chosen  as a pivot \nfrom Z ij is either \u00b4 i or \u00b4 j . In the latter two cases, where one of \u00b4 i and \u00b4 j is chosen 196  Chapter  7 Quicksort  \nas a pivot, since the pivot is removed from future comparisons, it is never compared \nagain with the other element. \nAs an example of this lemma, consider an input to q uicksort of the numbers 1 \nthrough 10  in some  arbitrary  order.  Suppose  that  the  \u00fbrst  pivot  element  is 7. Then \nthe  \u00fbrst  call  to PARTITION  separates the numbers into two sets: f1;2;3;4;5;6 g and \nf8;9;10 g. In the process, the pivot element 7 is compared with all other elements, \nbut  no  number  from  the  \u00fbrst  set  (e.g.,  2) is or ever will be compared with any \nnumber from the second set (e.g., 9). The values 7 and 9 are compared because 7 \nis the  \u00fbrst  item  from  Z 7;9  to be chosen as a pivot. In contrast, 2 and 9 are never \ncompared  because  the  \u00fbrst  pivot  element  chosen  from  Z 2;9  is 7. \nThe next lemma gives the probability that two eleme nts are compared. \nLemma  7.3  \nConsider an execution of the procedure R ANDOMIZED -QUICKSORT  on an array \nof n distinct elements \u00b4 1 <\u00b4  2 < \ue001 \ue001 \ue001  <\u00b4  n . Given  two  arbitrary  elements  \u00b4 i and \u00b4 j \nwhere i<j  , the probability that they are compared is 2=.j  \ue003 i C 1/. \nProof  Let\u2019s  look  at the  tree  of recursive  calls  that  RANDOMIZED -QUICKSORT  \nmakes, and consider the sets of elements provided a s input to each call. Initially, the \nroot set contains all the elements of Z ij , since the root set contains every element \nin A. The elements belonging to Z ij all stay together for each recursive call of \nRANDOMIZED -QUICKSORT  until PARTITION  chooses some element x 2 Z ij as a \npivot. From that point on, the pivot x appears  in no  subsequent  input  set.  The  \u00fbrst  \ntime that R ANDOMIZED -SELECT chooses a pivot x 2 Z ij from a set containing \nall the elements of Z ij , each element in Z ij is equally likely to be x because the \npivot is chosen uniformly at random. Since jZ ij j D  j \ue003 i C 1, the probability is \n1=.j  \ue003 i C 1/ that any given element in Z ij is the  \u00fbrst  pivot  chosen  from  Z ij . Thus, \nby  Lemma  7.2,  we  have  \nPr f\u00b4 i is compared with \u00b4 j g D  Pr f\u00b4 i or \u00b4 j is the  \u00fbrst  pivot  chosen  from  Z ij g \nD Pr f\u00b4 i is the  \u00fbrst  pivot  chosen  from  Z ij g \nC Pr f\u00b4 j is the  \u00fbrst  pivot  chosen  from  Z ij g \nD 2 \nj \ue003 i C 1 ; \nwhere  the  second  line  follows  from  the  \u00fbrst  because  the  two  events are mutually \nexclusive. \nWe can now complete the analysis of randomized quic ksort. 7.4  Analysis  of quicksort  197 \nTheorem  7.4  \nThe expected running time of R ANDOMIZED -QUICKSORT  on an input of n distinct \nelements is O.n  lg n/. \nProof  The  analysis  uses  indicator  random  variables  (see  Section  5.2). Let the n \ndistinct elements be \u00b4 1 < \u00b4  2 < \ue001 \ue001 \ue001  < \u00b4  n , and for 1 \u0dc4 i < j  \u0dc4 n, de\u00fbne  the  \nindicator random variable X ij D I f\u00b4 i is compared with \u00b4 j g. From  Lemma  7.2,  \neach pair is compared at most once, and so we can e xpress X as follows: \nX D n\ue0021 X  \ni D1 n X  \nj Di C1 X ij : \nBy taking expectations of both sides and using line arity of expectation  (equa-  \ntion  (C.24)  on  page  1192)  and  Lemma  5.1  on  page  130,  we  obtain  \nE \u0152X\ufffd  D E \" n\ue0021 X  \ni D1 n X  \nj Di C1 X ij # \nD n\ue0021 X  \ni D1 n X  \nj Di C1 E \u0152X  ij \ufffd (by linearity of expectation) \nD n\ue0021 X  \ni D1 n X  \nj Di C1 Pr f\u00b4 i is compared with \u00b4 j g (by  Lemma  5.1)  \nD n\ue0021 X  \ni D1 n X  \nj Di C1 2 \nj \ue003 i C 1 (by  Lemma  7.3)  . \nWe can evaluate this sum using a change of variable s (k D j \ue003 i ) and the bound \non  the  harmonic  series  in equation  (A.9)  on  page  1142:  \nE \u0152X\ufffd  D n\ue0021 X  \ni D1 n X  \nj Di C1 2 \nj \ue003 i C 1 \nD n\ue0021 X  \ni D1 n\ue002i X  \nkD1 2 \nk C 1 \n< n\ue0021 X  \ni D1 n X  \nkD1 2 \nk \nD n\ue0021 X  \ni D1 O.lg n/ \nD O.n  lg n/:  198  Chapter  7 Quicksort  \nThis  bound  and  Lemma  7.1  allow  us to conclude  that  the  expecte d running time \nof RANDOMIZED -QUICKSORT  is O.n  lg n/ (assuming that the element values are \ndistinct). \nExercises  \n7.4-1  \nShow that the recurrence \nT.n/  D max fT.q/  C T.n  \ue003 q \ue003 1/ W 0 \u0dc4 q \u0dc4 n \ue003 1g C  \u201a.n/  \nhas a lower bound of T.n/  D \ufffd.n  2 /. \n7.4-2  \nShow  that  quicksort\u2019s  best-case  running  time  is \ufffd.n  lg n/. \n7.4-3  \nShow that the expression q 2 C .n \ue003 q \ue003 1/ 2 achieves its maximum value over \nq D 0;1;:::;n  \ue003 1 when q D 0 or q D n \ue003 1. \n7.4-4  \nShow that R ANDOMIZED -QUICKSORT\u2019s expected  running  time  is \ufffd.n  lg n/. \n7.4-5  \nCoarsening  the  recursion,  as we  did  in Problem  2-1  for  merge  sort, is a common \nway to improve the running time of quicksort in pra ctice. We modify the base \ncase of the recursion so that if the array has fewe r than k elements, the subarray is \nsorted by insertion sort, rather than by continued recursive calls to quicksort. Argue \nthat the randomized version of this sorting algorit hm runs in O.nk  C n lg.n=k//  \nexpected time. How should you pick k, both  in theory  and  in practice?  \n? 7.4-6  \nConsider modifying the P ARTITION  procedure by randomly picking three elements \nfrom subarray A\u0152p  W r\ufffd and partitioning about their median (the middle val ue of the \nthree elements). Approximate the probability of get ting worse than an \u02db-to-.1 \ue003 \u02db/  \nsplit, as a function of \u02db in the range 0<\u02db<1=2 . Problems for Chapter 7 199 \nProblems  \n7-1  Hoare  partition  correctness  \nThe version of P ARTITION  given  in this  chapter  is not  the  original  partitioning  al-  \ngorithm. Here is the original partitioning algorith m, which is due to C. A. R. Hoare. \nHOARE-PARTITION  .A;p;r/  \n1 x D A\u0152p\ufffd  \n2 i D p \ue003 1 \n3 j D r C 1 \n4 while  TRUE \n5 repeat  \n6 j D j \ue003 1 \n7 until  A\u0152j\ufffd  \u0dc4 x \n8 repeat  \n9 i D i C 1 \n10  until  A\u0152i\ufffd  \ue004 x \n11  if i<j  \n12  exchange A\u0152i\ufffd  with A\u0152j\ufffd  \n13  else  return  j \na. Demonstrate the operation of H OARE-PARTITION  on the array A D h13;19;  \n9;5;12;8;7;4;11;2;6;21 i, showing the values of the array and the indices i \nand j after each iteration of the while  loop  in lines  4313.  \nb. Describe how the P ARTITION  procedure  in Section  7.1  differs  from  HOARE- \nPARTITION  when all elements in A\u0152p  W r\ufffd are  equal.  Describe  a practical  advan-  \ntage of HOARE-PARTITION  over PARTITION  for use in quicksort. \nThe next three questions ask you to give a careful argument that the procedure \nHOARE-PARTITION  is correct. Assuming that the subarray A\u0152p  W r\ufffd contains at \nleast two elements, prove the following: \nc. The indices i and j are such that the procedure never accesses an eleme nt of A \noutside the subarray A\u0152p  W r\ufffd. \nd. When HOARE-PARTITION  terminates, it returns a value j such that p \u0dc4 j <r  . \ne. Every element of A\u0152p  W j\ufffd is less than or equal to every element of A\u0152j  C 1 W r\ufffd \nwhen HOARE-PARTITION  terminates. 200  Chapter  7 Quicksort  \nThe PARTITION  procedure  in Section  7.1  separates  the  pivot  value  (origina lly \nin A\u0152r\ufffd) from the two partitions it forms. The H OARE-PARTITION  procedure, on \nthe other hand, always places the pivot value (orig inally in A\u0152p\ufffd ) into one of the \ntwo partitions A\u0152p  W j\ufffd and A\u0152j  C 1 W r\ufffd. Since p \u0dc4 j < r  , neither partition is \nempty. \nf. Rewrite  the  QUICKSORT  procedure to use H OARE-PARTITION . \n7-2  Quicksort  with  equal  element  values  \nThe analysis of the expected running time of random ized quicksort  in Section  7.4.2  \nassumes that all element values are distinct. This problem examines what happens \nwhen they are not. \na. Suppose that all element values are equal. What is randomized quicksort\u2019s  \nrunning  time  in this  case?  \nb. The PARTITION  procedure returns an index q such that each element of \nA\u0152p  W q \ue003 1\ufffd is less than or equal to A\u0152q\ufffd  and each element of A\u0152q  C 1 W r\ufffd is \ngreater than A\u0152q\ufffd. Modify the P ARTITION  procedure to produce a procedure \nPARTITION  0 .A;p;r/ , which permutes the elements of A\u0152p  W r\ufffd and returns two \nindices q and t , where p \u0dc4 q \u0dc4 t \u0dc4 r , such that \n\ue001 all elements of A\u0152q  W t\ufffd are equal, \n\ue001 each element of A\u0152p  W q \ue003 1\ufffd is less than A\u0152q\ufffd, and \n\ue001 each element of A\u0152t  C 1 W r\ufffd is greater than A\u0152q\ufffd. \nLike PARTITION , your PARTITION  0 procedure should take \u201a.r  \ue003 p/  time. \nc. Modify the R ANDOMIZED -PARTITION  procedure to call P ARTITION  0 , and \nname the new procedure R ANDOMIZED -PARTITION  0 . Then modify the \nQUICKSORT  procedure  to produce  a procedure  QUICKSORT  0 .A;p;r/  that calls \nRANDOMIZED -PARTITION  0 and recurses only on partitions where elements are \nnot known to be equal to each other. \nd. Using  QUICKSORT  0 , adjust  the  analysis  in Section  7.4.2  to avoid  the  assumptio n \nthat all elements are distinct. \n7-3  Alternative  quicksort  analysis  \nAn alternative analysis of the running time of rand omized quicksort focuses on \nthe expected running time of each individual recurs ive call to R ANDOMIZED - \nQUICKSORT , rather than on the number of comparisons performe d. As in the \nanalysis  of Section  7.4.2,  assume  that  the  values  of the  elem ents are distinct. Problems for Chapter 7 201 \na. Argue that, given an array of size n, the probability that any particular element \nis chosen as the pivot is 1=n. Use  this  probability  to de\u00fbne  indicator  random  \nvariables X i D I fi th smallest element is chosen as the pivot g. What is E \u0152X  i \ufffd? \nb. Let T.n/  be a random variable denoting the running time of q uicksort on an \narray of size n. Argue that \nE \u0152T.n/\ufffd  D E \" n X  \nqD1 X q .T.q  \ue003 1/ C T.n  \ue003 q/ C \u201a.n//  # \n: (7.2)  \nc. Show  how  to rewrite  equation  (7.2)  as \nE \u0152T.n/\ufffd  D 2 \nn n\ue0021 X  \nqD1 E \u0152T.q/\ufffd  C \u201a.n/:  (7.3)  \nd. Show that \nn\ue0021 X  \nqD1 q lg q \u0dc4 n 2 \n2 lg n \ue003 n 2 \n8 (7.4)  \nfor n \ue004 2. (Hint: Split the summation into two parts, one summation f or q D \n1;2;:::;  dn=2e \ue003  1 and one summation for q D dn=2e ;:::;n  \ue003 1.) \ne. Using  the  bound  from  equation  (7.4),  show  that  the  recurrence  in equation  (7.3)  \nhas the solution E \u0152T.n/\ufffd  D O.n  lg n/. (Hint: Show, by substitution, that \nE \u0152T.n/\ufffd  \u0dc4 an  lg n for  suf\u00fbciently  large  n and for some positive constant a.) \n7-4  Stooge  sort  \nProfessors Howard, Fine, and Howard have proposed a  deceptively simple sorting \nalgorithm, named stooge sort in their honor, appear ing on the following page. \na. Argue that the call S TOOGE-SORT.A;1;n/  correctly sorts the array A\u01521  W n\ufffd. \nb. Give  a recurrence  for  the  worst-case  running  time  of STOOGE-SORT  and a tight \nasymptotic (\u201a-notation)  bound  on  the  worst-case  running  time.  \nc. Compare  the  worst-case  running  time  of STOOGE-SORT  with that of insertion \nsort, merge sort, heapsort, and quicksort. Do the p rofessors deserve  tenure?  202  Chapter  7 Quicksort  \nSTOOGE-SORT.A;p;r/  \n1 if A\u0152p\ufffd>A\u0152r\ufffd  \n2 exchange A\u0152p\ufffd  with A\u0152r\ufffd  \n3 if p C 1<r  \n4 k D b.r \ue003 p C 1/=3c / / round down \n5 STOOGE-SORT.A;p;r  \ue003 k/  / / \u00fbrst  two-thirds  \n6 STOOGE-SORT.A;p  C k;r/  / / last  two-thirds  \n7 STOOGE-SORT.A;p;r  \ue003 k/  / / \u00fbrst  two-thirds  again  \n7-5  Stack  depth  for  quicksort  \nThe  QUICKSORT  procedure  of Section  7.1  makes  two  recursive  calls  to itself . After \nQUICKSORT  calls PARTITION , it recursively sorts the low side of the partitio n \nand then it recursively sorts the high side of the partition. The second recursive \ncall  in QUICKSORT  is not really necessary, because the procedure can instead use \nan iterative control structure. This transformation  technique, called tail-recursion  \nelimination , is provided automatically by good compilers. Appl ying tail-recursion  \nelimination  transforms  QUICKSORT  into  the  TRE-QUICKSORT  procedure. \nTRE-QUICKSORT  .A;p;r/  \n1 while  p<r  \n2 / / Partition and then sort the low side. \n3 q D PARTITION.A;p;r/  \n4 TRE-QUICKSORT.A;p;q  \ue003 1/ \n5 p D q C 1 \na. Argue  that  TRE-QUICKSORT  .A;1;n/  correctly sorts the array A\u01521  W n\ufffd. \nCompilers usually execute recursive procedures by u sing a stack  that  contains  per-  \ntinent information, including the parameter values,  for each recursive call. The \ninformation for the most recent call is at the top of the stack, and the information \nfor the initial call is at the bottom. When a proce dure is called, its information is \npushed  onto the stack, and when it terminates, its informa tion is popped . Since \nwe assume that array parameters are represented by pointers, the information for \neach procedure call on the stack requires O.1/  stack space. The stack  depth  is the \nmaximum amount of stack space used at any time duri ng a computation. \nb. Describe  a scenario  in which  TRE-QUICKSORT\u2019s stack  depth  is \u201a.n/  on an \nn-element  input  array.  Problems for Chapter 7 203 \nc. Modify  TRE-QUICKSORT  so that  the  worst-case  stack  depth  is \u201a.lg n/. Main-  \ntain the O.n  lg n/ expected running time of the algorithm. \n7-6  Median-of-3  partition  \nOne  way  to improve  the  RANDOMIZED -QUICKSORT  procedure is to partition \naround a pivot that is chosen more carefully than b y picking a random element \nfrom the subarray. A common approach is the median-of-3  method: choose the \npivot  as the  median  (middle  element)  of a set  of 3 elements  randomly selected \nfrom  the  subarray.  (See  Exercise  7.4-6.)  For  this  problem,  assume that the n ele-  \nments in the input subarray A\u0152p  W r\ufffd are distinct and that n \ue004 3. Denote the sorted \nversion of A\u0152p  W r\ufffd by \u00b4 1 ;\u00b4  2 ;:::;\u00b4  n . Using  the  median-of-3  method  to choose  the  \npivot element x , de\u00fbne  p i D Pr fx D \u00b4 i g. \na. Give  an exact  formula  for  p i as a function of n and i for i D 2;3;:::;n  \ue003 1. \n(Observe  that  p 1 D p n D 0.) \nb. By  what  amount  does  the  median-of-3  method  increase  the  likelihood  of choos-  \ning the pivot to be x D \u00b4 b.nC1/=2c , the median of A\u0152p  W r\ufffd, compared with the \nordinary  implementation?  Assume  that  n ! 1 , and give the limiting ratio of \nthese probabilities. \nc. Suppose  that  we  de\u00fbne  a <good=  split  to mean  choosing  the  pivot as x D \u00b4 i , \nwhere n=3  \u0dc4 i \u0dc4 2n=3. By  what  amount  does  the  median-of-3  method  in-  \ncrease the likelihood of getting a good split compa red with the ordinary  imple-  \nmentation?  (Hint: Approximate the sum by an integral.) \nd. Argue that in the \ufffd.n  lg n/ running  time  of quicksort,  the  median-of-3  method  \naffects only the constant factor. \n7-7  Fuzzy  sorting  of intervals  \nConsider a sorting problem in which you do not know  the numbers exactly.  In-  \nstead, for each number, you know an interval on the  real line to which it belongs. \nThat is, you are given n closed intervals of the form \u0152a i ;b  i \ufffd, where a i \u0dc4 b i . The \ngoal is to fuzzy-sort  these intervals: to produce a permutation hi 1 ;i 2 ;:::;i  n i of \nthe intervals such that for j D 1;2;:::;n , there exist c j 2 \u0152a i j ;b  i j \ufffd satisfying \nc 1 \u0dc4 c 2 \u0dc4 \ue001 \ue001 \ue001 \u0dc4  c n . \na. Design  a randomized  algorithm  for  fuzzy-sorting  n intervals. Your algorithm \nshould have the general structure of an algorithm t hat quicksorts  the  left  end-  \npoints (the a i values), but it should take advantage of overlappin g intervals to \nimprove the running time. (As the intervals overlap  more and more,  the  prob-  204  Chapter  7 Quicksort  \nlem  of fuzzy-sorting  the  intervals  becomes  progressively  easier. Your algorithm \nshould take advantage of such overlapping, to the e xtent that it exists.) \nb. Argue that your algorithm runs in \u201a.n  lg n/ expected time in general, but runs \nin \u201a.n/  expected time when all of the intervals overlap (i. e., when there exists a \nvalue x such that x 2 \u0152a i ;b  i \ufffd for all i ). Your algorithm should not be checking \nfor this case explicitly, but rather, its performan ce should naturally improve as \nthe amount of overlap increases. \nChapter  notes  \nQuicksort  was  invented  by  Hoare  [219],  and  his  version  of PARTITION  appears in \nProblem  7-1.  Bentley  [51,  p. 117]  attributes  the  PARTITION  procedure given in \nSection  7.1  to N.  Lomuto.  The  analysis  in Section  7.4  based  on  an analysis due \nto Motwani  and  Raghavan  [336].  Sedgewick  [401]  and  Bentley  [51]  provide  good  \nreferences on the details of implementation and how  they matter. \nMcIlroy  [323]  shows  how  to engineer  a <killer  adversary=  that produces an array \non which virtually any implementation of quicksort takes \u201a.n  2 / time. 8 Sorting  in Linear  Time  \nWe have now seen a handful of algorithms that can s ort n numbers in O.n  lg n/ \ntime. Whereas merge sort and heapsort achieve this upper bound in the worst case, \nquicksort achieves it on average. Moreover, for eac h of these algorithms, we can \nproduce a sequence of n input numbers that causes the algorithm to run in \ufffd.n  lg n/ \ntime. \nThese algorithms share an interesting property: the  sorted  order  they  determine  \nis based  only  on  comparisons  between  the  input  elements . We call such sorting \nalgorithms comparison  sorts . All the sorting algorithms introduced thus far ar e \ncomparison sorts. \nIn Section  8.1,  we\u2019ll  prove  that  any  comparison  sort  must  make \ufffd.n  lg n/ com-  \nparisons in the worst case to sort n elements. Thus, merge sort and heapsort are \nasymptotically optimal, and no comparison sort exis ts that is faster by more than a \nconstant factor. \nSections  8.2,  8.3,  and  8.4  examine  three  sorting  algorithms4counting  sort,  radix  \nsort,  and  bucket  sort4that  run  in linear  time  on  certain  types  of inputs.  Of  course,  \nthese algorithms use operations other than comparis ons to determine the sorted \norder. Consequently, the \ufffd.n  lg n/ lower bound does not apply to them. \n8.1  Lower  bounds  for  sorting  \nA comparison sort uses only comparisons between ele ments to gain  order  infor-  \nmation about an input sequence ha 1 ;a  2 ;:::;a  n i. That is, given two elements a i \nand a j , it performs one of the tests a i <a  j , a i \u0dc4 a j , a i D a j , a i \ue004 a j , or a i >a  j \nto determine their relative order. It may not inspe ct the values of the elements or \ngain order information about them in any other way.  \nSince we are proving a lower bound, we assume witho ut loss of generality in \nthis section that all the input elements are distin ct. After all, a lower bound for \ndistinct elements applies when elements may or may not be distinct. Consequently, 206 Chapter 8 Sorting in Linear Time \n\u2264 > \n\u2264 > 1:2  \n2:3  1:3  \n\u30081,2,3 \u3009 1:3  \u30082,1,3 \u3009 2:3  \n\u30081,3,2 \u3009 \u30083,1,2 \u3009 \u30083,2,1 \u3009 \u2264 > \n\u2264 > \n\u2264 > \n\u30082,3,1 \u3009 \nFigure  8.1  The decision tree for insertion sort operating on t hree elements. An internal node \n(shown in blue) annotated by i :j indicates a comparison between a i and a j . A leaf annotated by the \npermutation h\ufffd.1/;  \ufffd.2/;  : : : ; \ufffd.n/ i indicates the ordering a \ue003.1/  \u0dc4 a \ue003.2/  \u0dc4 \ue001 \ue001 \ue001 \u0dc4  a \ue003.n/  . The  high-  \nlighted path indicates the decisions made when sort ing the input sequence ha 1 D 6;a  2 D 8;a  3 D 5i. \nGoing  left  from  the  root  node,  labeled  1:2,  indicates  that  a 1 \u0dc4 a 2 . Going  right  from  the  node  labeled  \n2:3  indicates  that  a 2 >a  3 . Going  right  from  the  node  labeled  1:3  indicates  that  a 1 >a  3 . Therefore, \nwe have the ordering a 3 \u0dc4 a 1 \u0dc4 a 2 , as indicated in the leaf labeled h3;1;2 i. Because the three input \nelements have 3\u0160 D 6 possible permutations, the decision tree must have at least 6 leaves. \ncomparisons of the form a i D a j are useless, which means that we can assume \nthat no comparisons for exact equality occur. Moreo ver, the comparisons a i \u0dc4 a j , \na i \ue004 a j , a i > a  j , and a i < a  j are all equivalent in that they yield identical \ninformation about the relative order of a i and a j . We therefore assume that all \ncomparisons have the form a i \u0dc4 a j . \nThe  decision-tree  model  \nWe can view comparison sorts abstractly in terms of  decision trees. A decision  \ntree  is a full binary tree (each node is either a leaf o r has both chi ldren)  that  repre-  \nsents the comparisons between elements that are per formed by a particular sorting \nalgorithm operating on an input of a given size. Co ntrol, data movement, and all \nother  aspects  of the  algorithm  are  ignored.  Figure  8.1  shows  the  decision  tree  cor-  \nresponding  to the  insertion  sort  algorithm  from  Section  2.1  operating on an input \nsequence of three elements. \nA decision tree has each internal node annotated by  i :j for some i and j in the \nrange 1 \u0dc4 i;j  \u0dc4 n, where n is the number of elements in the input sequence. \nWe also annotate each leaf by a permutation h\ufffd.1/;  \ufffd.2/;  : : : ; \ufffd.n/ i. (See  Sec-  \ntion  C.1  for  background  on  permutations.)  Indices  in the  internal nodes and the \nleaves always refer to the original positions of th e array elements at the start of the \nsorting algorithm. The execution of the comparison sorting algorithm corresponds \nto tracing a simple path from the root of the decis ion tree down to a leaf. Each \ninternal node indicates a comparison a i \u0dc4 a j . The  left  subtree  then  dictates  sub-  8.1  Lower  bounds  for  sorting  207 \nsequent comparisons once we know that a i \u0dc4 a j , and the right subtree dictates \nsubsequent comparisons when a i > a  j . Arriving at a leaf, the sorting algorithm \nhas established the ordering a \ue003.1/  \u0dc4 a \ue003.2/  \u0dc4 \ue001 \ue001 \ue001 \u0dc4  a \ue003.n/  . Because  any  correct  sort-  \ning algorithm must be able to produce each permutat ion of its input, each of the n\u0160 \npermutations on n elements must appear as at least one of the leaves of the decision \ntree for a comparison sort to be correct. Furthermo re, each of these leaves must be \nreachable from the root by a downward path correspo nding to an actual execution \nof the comparison sort. (We call such leaves <reach able.=) Thus, we consider only \ndecision trees in which each permutation appears as  a reachable leaf. \nA lower  bound  for  the  worst  case  \nThe length of the longest simple path from the root  of a decision tree to any of \nits  reachable  leaves  represents  the  worst-case  number  of comparisons  that  the  cor-  \nresponding sorting algorithm performs. Consequently , the worst-case  number  of \ncomparisons for a given comparison sort algorithm e quals the height of its decision \ntree. A lower bound on the heights of all decision trees in which each permutation \nappears as a reachable leaf is therefore a lower bo und on the running time of any \ncomparison sort algorithm. The following theorem es tablishes such a lower bound. \nTheorem  8.1  \nAny comparison sort algorithm requires \ufffd.n  lg n/ comparisons in the worst case. \nProof  From  the  preceding  discussion,  it suf\u00fbces  to determine  the  height of a \ndecision tree in which each permutation appears as a reachable leaf. Consider \na decision tree of height h with l reachable leaves corresponding to a comparison \nsort on n elements. Because each of the n\u0160 permutations of the input appears as \none or more leaves, we have n\u0160 \u0dc4 l . Since a binary tree of height h has no more \nthan 2 h leaves, we have \nn\u0160 \u0dc4 l \u0dc4 2 h ; \nwhich, by taking logarithms, implies \nh \ue004 lg.n\u0160/  (since the lg function is monotonically increasing)  \nD \ufffd.n  lg n/ (by  equation  (3.28)  on  page  67)  . \nCorollary  8.2  \nHeapsort and merge sort are asymptotically optimal comparison sorts. \nProof  The O.n  lg n/ upper bounds on the running times for heapsort and merge \nsort match the \ufffd.n  lg n/ worst-case  lower  bound  from  Theorem  8.1.  208 Chapter 8 Sorting in Linear Time \nExercises  \n8.1-1  \nWhat is the smallest possible depth of a leaf in a decision tree for a comparison \nsort?  \n8.1-2  \nObtain  asymptotically  tight  bounds  on  lg.n\u0160/  without  using  Stirling\u2019s  approxi-  \nmation. Instead, evaluate the summation P  n \nkD1 lg k using  techniques  from  Sec-  \ntion A.2. \n8.1-3  \nShow that there is no comparison sort whose running  time is linear for at least half \nof the n\u0160 inputs of length n. What about a fraction of 1=n  of the inputs of length n? \nWhat about a fraction 1=2  n ? \n8.1-4  \nYou are given an n-element  input  sequence,  and  you  know  in advance  that  it is \npartly sorted in the following sense. Each element initially in position i such that \ni mod 4 D 0 is either already in its correct position, or it is  one place away from \nits correct position. For example, you know that af ter sorting, the element initially \nin position 12  belongs in position 11, 12, or 13. You have no advance information \nabout the other elements, in positions i where i mod 4 \u00a4 0. Show that an \ufffd.n  lg n/ \nlower  bound  on  comparison-based  sorting  still  holds  in this  case. \n8.2  Counting  sort  \nCounting  sort  assumes that each of the n input elements is an integer in the range \n0 to k, for some integer k. It runs in \u201a.n  C k/  time, so that when k D O.n/ , \ncounting sort runs in \u201a.n/  time. \nCounting  sort  \u00fbrst  determines,  for  each  input  element  x , the number of elements \nless than or equal to x . It then uses this information to place element x directly into \nits position in the output array. For example, if 17  elements are less than or equal \nto x , then x belongs in output position 17. We must modify this scheme slightly \nto handle the situation in which several elements h ave the same value, since we do \nnot want them all to end up in the same position. \nThe COUNTING-SORT  procedure on the facing page takes as input an arra y \nA\u01521  W n\ufffd, the size n of this array, and the limit k on the nonnegative integer values \nin A. It returns its sorted output in the array B\u01521  W n\ufffd and uses an array C\u01520  W k\ufffd for \ntemporary working storage. 8.2  Counting  sort  209 \nCOUNTING-SORT.A;n;k/  \n1 let B\u01521  W n\ufffd and C\u01520  W k\ufffd be new arrays \n2 for  i D 0 to k \n3 C\u0152i\ufffd  D 0 \n4 for  j D 1 to n \n5 C\u0152A\u0152j\ufffd\ufffd  D C\u0152A\u0152j\ufffd\ufffd  C 1 \n6 / / C\u0152i\ufffd  now contains the number of elements equal to i . \n7 for  i D 1 to k \n8 C\u0152i\ufffd  D C\u0152i\ufffd  C C\u0152i  \ue003 1\ufffd \n9 / / C\u0152i\ufffd  now contains the number of elements less than or eq ual to i . \n10  / / Copy A to B , starting from the end of A. \n11  for  j D n downto  1 \n12  B\u0152C\u0152A\u0152j\ufffd\ufffd\ufffd  D A\u0152j\ufffd  \n13  C\u0152A\u0152j\ufffd\ufffd  D C\u0152A\u0152j\ufffd\ufffd  \ue003 1 / / to handle duplicate values \n14  return  B \nFigure  8.2  illustrates  counting  sort.  After  the  for  loop  of lines  233  initializes  the  \narray C to all zeros, the for  loop  of lines  435  makes  a pass  over  the  array  A to \ninspect  each  input  element.  Each  time  it \u00fbnds  an input  elemen t whose value is i , it \nincrements C\u0152i\ufffd. Thus,  after  line  5, C\u0152i\ufffd  holds the number of input elements equal \nto i for each integer i D 0;1;:::;k. Lines  738  determine  for  each  i D 0;1;:::;k  \nhow many input elements are less than or equal to i by keeping a running sum of \nthe array C . \nFinally, the for  loop  of lines  11313  makes  another  pass  over  A, but in reverse, \nto place each element A\u0152j\ufffd  into its correct sorted position in the output arra y B . \nIf all n elements  are  distinct,  then  when  line  11  is \u00fbrst  entered,  for  each A\u0152j\ufffd , the \nvalue C\u0152A\u0152j\ufffd\ufffd  is the  correct  \u00fbnal  position  of A\u0152j\ufffd  in the output array, since there \nare C\u0152A\u0152j\ufffd\ufffd  elements less than or equal to A\u0152j\ufffd . Because the elements might not \nbe distinct, the loop decrements C\u0152A\u0152j\ufffd\ufffd  each time it places a value A\u0152j\ufffd  into B . \nDecrementing C\u0152A\u0152j\ufffd\ufffd  causes the previous element in A with a value equal to A\u0152j\ufffd , \nif one exists, to go to the position immediately be fore A\u0152j\ufffd  in the output array B . \nHow  much  time  does  counting  sort  require?  The  for  loop  of lines  233  takes  \u201a.k/  \ntime, the for  loop  of lines  435  takes  \u201a.n/  time, the for  loop  of lines  738  takes  \u201a.k/  \ntime, and the for  loop  of lines  11313  takes  \u201a.n/  time. Thus, the overall time is \n\u201a.k  C n/. In practice, we usually use counting sort when we  have k D O.n/ , in \nwhich case the running time is \u201a.n/ . \nCounting sort can beat the lower bound of \ufffd.n  lg n/ proved  in Section  8.1  be-  \ncause it is not a comparison sort. In fact, no comp arisons between input elements \noccur anywhere in the code. Instead, counting sort uses the actual values of the 210 Chapter 8 Sorting in Linear Time \n2 5 3 0 2 3 0 3 1 2 3 4 5 6 7 8 \n2 0 2 3 0 1 1 2 3 4 5 A \nC \n(a) 2 2 4 7 7 8 C \n(b) 3 1 2 3 4 5 6 7 8 \n2 2 4 6 7 8 B \nC \n(c) \n3 1 2 3 4 5 6 7 8 \n1 2 4 6 7 8 B \nC \n(d) 0 3 1 2 3 4 5 6 7 8 \n1 2 4 5 7 8 B \nC \n(e) 0 3 \n3 1 2 3 4 5 6 7 8 \nB \n(f) 0 3 0 2 2 3 5 0 1 2 3 4 5 0 \n1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 \nFigure  8.2  The operation of C OUNTING-SORT  on an input array A\u01521  W 8\ufffd, where each element of A \nis a nonnegative integer no larger than k D 5. (a)  The array A and the auxiliary array C after  line  5. \n(b)  The array C after  line  8. (c)\u2013(e)  The output array B and the auxiliary array C after one, two, and \nthree  iterations  of the  loop  in lines  11313,  respectively.  Only the tan elements of array B have been \n\u00fblled  in.  (f)  The  \u00fbnal  sorted  output  array  B. \nelements to index into an array. The \ufffd.n  lg n/ lower bound for sorting does not \napply when we depart from the comparison sort model . \nAn important property of counting sort is that it i s stable : elements with the same \nvalue appear in the output array in the same order as they do in the input array. That \nis, it breaks ties between two elements by the rule  that whichever element appears \n\u00fbrst  in the  input  array  appears  \u00fbrst  in the  output  array.  Norm ally, the property of \nstability is important only when satellite data are  carried around with the element \nbeing  sorted.  Counting  sort\u2019s  stability  is important  for  another reason: counting \nsort is often used as a subroutine in radix sort. A s we shall see in the next section, \nin order for radix sort to work correctly, counting  sort must be stable. \nExercises  \n8.2-1  \nUsing  Figure  8.2  as a model,  illustrate  the  operation  of COUNTING-SORT  on the \narray A D h6;0;2;0;1;3;4;6;1;3;2 i. \n8.2-2  \nProve that C OUNTING-SORT  is stable. 8.3 Radix sort 211 \n8.2-3  \nSuppose that we were to rewrite the for  loop  header  in line  11  of the  COUNTING- \nSORT  as \n11  for  j D 1 to n \nShow that the algorithm still works properly, but t hat it is not stable. Then rewrite \nthe pseudocode for counting sort so that elements w ith the same value are written \ninto the output array in order of increasing index and the algorithm is stable. \n8.2-4  \nProve the following loop invariant for C OUNTING-SORT: \nAt the start of each iteration of the for  loop  of lines  11313,  the  last  element  \nin A with value i that has not yet been copied into B belongs in B\u0152C\u0152i\ufffd\ufffd . \n8.2-5  \nSuppose that the array being sorted contains only i ntegers in the range 0 to k and \nthat there are no satellite data to move with those  keys. Modify counting sort to \nuse just the arrays A and C , putting the sorted result back into array A instead of \ninto a new array B . \n8.2-6  \nDescribe an algorithm that, given n integers in the range 0 to k, preprocesses its \ninput and then answers any query about how many of the n integers fall into a \nrange \u0152a W b\ufffd in O.1/  time. Your algorithm should use \u201a.n  C k/  preprocessing \ntime. \n8.2-7  \nCounting  sort  can  also  work  ef\u00fbciently  if the  input  values  have fractional parts, but \nthe number of digits in the fractional part is smal l. Suppose that you are given n \nnumbers in the range 0 to k, each with at most d decimal (base 10) digits to the \nright of the decimal point. Modify counting sort to  run in \u201a.n  C 10  d k/  time. \n8.3  Radix  sort  \nRadix  sort  is the  algorithm  used  by  the  card-sorting  machines  you  now  \u00fbnd only in \ncomputer  museums.  The  cards  have  80  columns,  and  in each  column a machine can \npunch  a hole  in one  of 12  places.  The  sorter  can  be mechanicall y <programmed= \nto examine a given column of each card in a deck an d distribute the card into one 212 Chapter 8 Sorting in Linear Time \n329  \n457  \n657  \n839  \n436  \n720  \n355  329  457  \n657  \n839  436  720  \n355  329  \n457  \n657  839  436  720  \n355  329  \n457  \n657  \n839  436  \n720  355  \nFigure  8.3  The operation of radix sort on seven 3-digit  numbers.  The  leftmost  column  is the  input.  \nThe remaining columns show the numbers after succes sive sorts on  increasingly  signi\u00fbcant  digit  \npositions. Tan shading indicates the digit position  sorted on to produce each list from the previous \none. \nof 12  bins  depending  on  which  place  has  been  punched.  An  opera tor can then \ngather  the  cards  bin  by  bin,  so that  cards  with  the  \u00fbrst  place  punched are on top of \ncards with the second place punched, and so on. \nFor  decimal  digits,  each  column  uses  only  10  places.  (The  other two places are \nreserved for encoding nonnumeric characters.) A d -digit  number  occupies  a \u00fbeld  \nof d columns. Since the card sorter can look at only one  column at a time, the \nproblem of sorting n cards on a d -digit  number  requires  a sorting  algorithm.  \nIntuitively, you might sort numbers on their most  signi\ufb01cant  (leftmost) digit, \nsort each of the resulting bins recursively, and th en combine the decks in order. \nUnfortunately, since the cards in 9 of the 10  bins must be put aside to sort each of \nthe bins, this procedure generates many intermediat e piles of cards that you would \nhave  to keep  track  of.  (See  Exercise  8.3-6.)  \nRadix  sort  solves  the  problem  of card  sorting4counterintuitively4by  sorting  on  \nthe least  signi\ufb01cant  digit  \u00fbrst.  The  algorithm  then  combines  the  cards  into  a single \ndeck, with the cards in the 0 bin preceding the cards in the 1 bin preceding the \ncards in the 2 bin, and so on. Then it sorts the entire deck again  on the secon d-least  \nsigni\u00fbcant  digit  and  recombines  the  deck  in a like  manner.  The process continues \nuntil the cards have been sorted on all d digits. Remarkably, at that point the cards \nare fully sorted on the d -digit  number.  Thus,  only  d passes through the deck are \nrequired  to sort.  Figure  8.3  shows  how  radix  sort  operates  on  a <deck= of seven \n3-digit  numbers.  \nIn order for radix sort to work correctly, the digi t sorts must be stable. The sort \nperformed by a card sorter is stable, but the opera tor must be careful not to change \nthe order of the cards as they come out of a bin, e ven though all the cards in a bin \nhave the same digit in the chosen column. \nIn a typical  computer,  which  is a sequential  random-access  machine,  we  some-  \ntimes use radix sort to sort records of information  that are keyed  by  multiple  \u00fbelds.  \nFor example, we might wish to sort dates by three k eys: year, month, and day. We \ncould run a sorting algorithm with a comparison fun ction that, given two dates, 8.3 Radix sort 213 \ncompares years, and if there is a tie, compares mon ths, and if another tie occurs, \ncompares days. Alternatively, we could sort the inf ormation three times with a \nstable  sort:  \u00fbrst  on  day  (the  <least  signi\u00fbcant=  part),  next  on  month,  and  \u00fbnally  on  \nyear. \nThe code for radix sort is straightforward. The R ADIX-SORT  procedure assumes \nthat each element in array A\u01521  W n\ufffd has d digits, where digit 1 is the  lowest-order  \ndigit and digit d is the  highest-order  digit.  \nRADIX-SORT.A;n;d/  \n1 for  i D 1 to d \n2 use a stable sort to sort array A\u01521  W n\ufffd on digit i \nAlthough the pseudocode for R ADIX-SORT  does not specify which stable sort to \nuse, COUNTING-SORT  is commonly used. If you use C OUNTING-SORT  as the  sta-  \nble sort, you can make R ADIX-SORT  a little  more  ef\u00fbcient  by  revising  COUNTING- \nSORT  to take a pointer to the output array as a paramete r, having R ADIX-SORT  \npreallocate this array, and alternating input and o utput between the two arrays in \nsuccessive iterations of the for  loop in R ADIX-SORT. \nLemma  8.3  \nGiven  nd  -digit  numbers  in which  each  digit  can  take  on  up  to k possible values, \nRADIX-SORT  correctly sorts these numbers in \u201a.d.n  C k//  time if the stable sort \nit uses takes \u201a.n  C k/  time. \nProof  The correctness of radix sort follows by induction on the column being \nsorted  (see  Exercise  8.3-3).  The  analysis  of the  running  time depends on the stable \nsort used as the intermediate sorting algorithm. Wh en each digit lies in the range 0 \nto k \ue003 1 (so that it can take on k possible values), and k is not too large, counting \nsort is the obvious choice. Each pass over nd  -digit  numbers  then  takes  \u201a.n  C k/  \ntime. There are d passes, and so the total time for radix sort is \u201a.d.n  C k//. \nWhen d is constant and k D O.n/ , we can make radix sort run in linear time. \nMore  generally,  we  have  some  \u00fcexibility  in how  to break  each  key into digits. \nLemma  8.4  \nGiven  nb-bit  numbers  and  any  positive  integer  r \u0dc4 b, RADIX-SORT  correctly sorts \nthese numbers in \u201a..b=r/.n  C 2 r // time if the stable sort it uses takes \u201a.n  C k/  \ntime for inputs in the range 0 to k. 214 Chapter 8 Sorting in Linear Time \nProof  For a value r \u0dc4 b, view each key as having d D db=r  e digits of r bits \neach. Each digit is an integer in the range 0 to 2 r \ue003 1, so that we can use counting \nsort with k D 2 r \ue003 1. (For  example,  we  can  view  a 32-bit  word  as having  four  8-bit  \ndigits, so that b D 32, r D 8, k D 2 r \ue003 1 D 255, and d D b=r  D 4.) Each pass of \ncounting sort takes \u201a.n  C k/  D \u201a.n  C 2 r / time and there are d passes, for a total \nrunning time of \u201a.d.n  C 2 r // D \u201a..b=r/.n  C 2 r //. \nGiven  n and b, what value of r \u0dc4 b minimizes the expression .b=r/.n  C 2 r /? \nAs r decreases, the factor b=r  increases, but as r increases so does 2 r . The answer \ndepends on whether b<  blg nc. If b<  blg nc, then r \u0dc4 b implies .nC2 r / D \u201a.n/ . \nThus, choosing r D b yields a running time of .b=b/.n  C 2 b / D \u201a.n/ , which is \nasymptotically optimal. If b \ue004 blg nc, then choosing r D blg nc gives the best \nrunning time to within a constant factor, which we can see as follows. 1 Choosing \nr D blg nc yields a running time of \u201a.bn=  lg n/. As r increases above blg nc, the \n2 r term in the numerator increases faster than the r term in the denominator, and so \nincreasing r above blg nc yields a running time of \ufffd.bn=  lg n/. If instead r were \nto decrease below blg nc, then the b=r  term increases and the n C 2 r term remains \nat \u201a.n/ . \nIs radix  sort  preferable  to a comparison-based  sorting  algorithm,  such  as quick-  \nsort?  If b D O.lg n/, as is often the case, and r \ue002 lg n, then  radix  sort\u2019s  running  \ntime is \u201a.n/, which  appears  to be better  than  quicksort\u2019s  expected  runni ng time \nof \u201a.n  lg n/. The constant factors hidden in the \u201a-notation  differ,  however.  Al-  \nthough radix sort may make fewer passes than quicks ort over the n keys, each \npass  of radix  sort  may  take  signi\u00fbcantly  longer.  Which  sorting algorithm to prefer \ndepends on the characteristics of the implementatio ns, of the underlying machine \n(e.g., quicksort often uses hardware caches more ef fectively than radix sort), and \nof the input data. Moreover, the version of radix s ort that uses counting sort as the \nintermediate stable sort does not sort in place, wh ich many of the \u201a.n  lg n/-time  \ncomparison sorts do. Thus, when primary memory stor age is at a premium, an \nin-place  algorithm  such  as quicksort  could  be the  better  choice. \nExercises  \n8.3-1  \nUsing  Figure  8.3  as a model,  illustrate  the  operation  of RADIX-SORT  on  the  fol-  \nlowing  list  of English  words:  COW,  DOG,SEA,  RUG,  ROW,  MOB,  BOX, TAB, \nBAR,  EAR,  TAR,  DIG,  BIG,  TEA,  NOW,  FOX.  \n1 The choice of r D blg nc assumes that n>1 . If n \u0dc4 1, there is nothing to sort. 8.4  Bucket  sort  215 \n8.3-2  \nWhich of the following sorting algorithms are stabl e: insertion sort, merge sort, \nheapsort,  and  quicksort?  Give  a simple  scheme  that  makes  any  comparison sort \nstable. How much additional time and space does you r scheme entail?  \n8.3-3  \nUse induction to prove that radix sort works. Where  does your proof need the \nassumption  that  the  intermediate  sort  is stable?  \n8.3-4  \nSuppose that C OUNTING-SORT  is used as the stable sort within R ADIX-SORT. If \nRADIX-SORT  calls COUNTING-SORT  d times, then since each call of C OUNTING- \nSORT  makes  two  passes  over  the  data  (lines  435  and  11313),  altoget her 2d  passes \nover the data occur. Describe how to reduce the tot al number of passes to d C 1. \n8.3-5  \nShow how to sort n integers in the range 0 to n 3 \ue003 1 in O.n/  time. \n? 8.3-6  \nIn the  \u00fbrst  card-sorting  algorithm  in this  section,  which  sorts  on  the  most  signi\u00fbcant  \ndigit  \u00fbrst,  exactly  how  many  sorting  passes  are  needed  to sort d -digit  decimal  \nnumbers  in the  worst  case?  How  many  piles  of cards  does  an operator need to keep \ntrack  of in the  worst  case?  \n8.4  Bucket  sort  \nBucket  sort  assumes that the input is drawn from a uniform dist ribution and has an \naverage-case  running  time  of O.n/ . Like counting sort, bucket sort is fast because \nit assumes something about the input. Whereas count ing sort assumes that the input \nconsists of integers in a small range, bucket sort assumes that the input is generated \nby a random process that distributes elements unifo rmly and independently over \nthe interval \u01520;1/. (See  Section  C.2  for  a de\u00fbnition  of a uniform  distribution. ) \nBucket sort divides the interval \u01520;1/  into n equal-sized  subintervals,  or buckets , \nand then distributes the n input  numbers  into  the  buckets.  Since  the  inputs  are  uni-  \nformly and independently distributed over \u01520;1/ , we do not expect many numbers \nto fall into each bucket. To produce the output, we  simply sort the numbers in each \nbucket and then go through the buckets in order, li sting the elements in each. \nThe BUCKET-SORT  procedure on the next page assumes that the input i s an \narray A\u01521  W n\ufffd and that each element A\u0152i\ufffd  in the  array  satis\u00fbes  0 \u0dc4 A\u0152i\ufffd<1 . The \ncode requires an auxiliary array B\u01520  W n \ue003 1\ufffd of linked lists (buckets) and assumes 216 Chapter 8 Sorting in Linear Time \n1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10  .78  \n.17  \n.39  \n.72  \n.94  \n.21  \n.12  \n.23  \n.68  A \n(a) 1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 B \n(b) 0 \n.12  .17  \n.21  .23  \n.26  .26  \n.39  \n.68  \n.72  .78  \n.94  \nFigure  8.4  The operation of B UCKET-SORT  for n D 10. (a)  The input array A\u01521  W 10\ufffd. (b)  The \narray B\u01520  W 9\ufffd of sorted  lists  (buckets)  after  line  7 of the  algorithm,  with  slashes indicating the end of \neach bucket. Bucket i holds  values  in the  half-open  interval  \u0152i=10;.i  C 1/=10/ . The sorted output \nconsists of a concatenation of the lists B\u01520\ufffd;B\u01521\ufffd;:::;B\u01529\ufffd  in order. \nthat there is a mechanism for maintaining such list s. (Section  10.2  describes  how  \nto implement  basic  operations  on  linked  lists.)  Figure  8.4  shows the operation of \nbucket sort on an input array of 10  numbers. \nBUCKET-SORT.A;n/  \n1 let B\u01520  W n \ue003 1\ufffd be a new array \n2 for  i D 0 to n \ue003 1 \n3 make B\u0152i\ufffd  an empty list \n4 for  i D 1 to n \n5 insert A\u0152i\ufffd  into list B\u0152bn \ue001 A\u0152i\ufffdc\ufffd \n6 for  i D 0 to n \ue003 1 \n7 sort list B\u0152i\ufffd  with insertion sort \n8 concatenate the lists B\u01520\ufffd;B\u01521\ufffd;:::;B\u0152n  \ue003 1\ufffd together in order \n9 return  the concatenated lists \nTo see that this algorithm works, consider two elem ents A\u0152i\ufffd  and A\u0152j\ufffd . Assume \nwithout loss of generality that A\u0152i\ufffd  \u0dc4 A\u0152j\ufffd . Since bn \ue001 A\u0152i\ufffdc \u0dc4 bn \ue001 A\u0152j\ufffdc, either \nelement A\u0152i\ufffd  goes into the same bucket as A\u0152j\ufffd  or it goes into a bucket with a lower \nindex. If A\u0152i\ufffd  and A\u0152j\ufffd  go into the same bucket, then the for  loop  of lines  637  puts  \nthem into the proper order. If A\u0152i\ufffd  and A\u0152j\ufffd  go  into  different  buckets,  then  line  8 \nputs them into the proper order. Therefore, bucket sort works correctly. 8.4  Bucket  sort  217 \nTo analyze the running time, observe that, together , all lines except  line  7 take  \nO.n/  time in the worst case. We need to analyze the tota l time taken by the n calls \nto insertion  sort  in line  7. \nTo analyze the cost of the calls to insertion sort,  let n i be the random variable \ndenoting the number of elements placed in bucket B\u0152i\ufffd. Since insertion sort runs \nin quadratic time (see Section 2.2), the running ti me of bucket sort is \nT.n/  D \u201a.n/  C n\ue0021 X  \ni D0 O.n  2 \ni /: (8.1)  \nWe  now  analyze  the  average-case  running  time  of bucket  sort,  by computing the \nexpected value of the running time, where we take t he expectation over the input \ndistribution. Taking expectations of both sides and  using linearity of expectation \n(equation  (C.24)  on  page  1192),  we  have  \nE \u0152T.n/\ufffd  D E \" \n\u201a.n/  C n\ue0021 X  \ni D0 O.n  2 \ni / # \nD \u201a.n/  C n\ue0021 X  \ni D0 E \u00ed \nO.n  2 \ni / \u00ee \n(by linearity of expectation) \nD \u201a.n/  C n\ue0021 X  \ni D0 O \u00e3 \nE \u00ed \nn 2 \ni \u00ee\u00e4 \n(by  equation  (C.25)  on  page  1193)  . (8.2)  \nWe claim that \nE \u00ed \nn 2 \ni \u00ee \nD 2 \ue003 1=n  (8.3)  \nfor i D 0;1;:::;n  \ue003 1. It is no surprise that each bucket i has the same value \nof E \u0152n 2 \ni \ufffd, since each value in the input array A is equally likely to fall in any \nbucket. \nTo  prove  equation  (8.3),  view  each  random  variable  n i as the  number  of suc-  \ncesses in n Bernoulli  trials  (see  Section  C.4).  Success  in a trial  occur s when \nan element goes into bucket B\u0152i\ufffd, with a probability p D 1=n  of success and \nq D 1 \ue003 1=n  of failure. A binomial distribution counts n i , the  number  of suc-  \ncesses, in the n trials.  By  equations  (C.41)  and  (C.44)  on  pages  119931200,  we \nhave E \u0152n i \ufffd D np  D n.1=n/  D 1 and Var \u0152n i \ufffd D npq  D 1 \ue003 1=n. Equation  (C.31)  \non  page  1194  gives  \nE \u00ed \nn 2 \ni \u00ee \nD Var \u0152n i \ufffd C E 2 \u0152n i \ufffd \nD .1 \ue003 1=n/  C 1 2 \nD 2 \ue003 1=n;  218 Chapter 8 Sorting in Linear Time \nwhich  proves  equation  (8.3).  Using  this  expected  value  in equation  (8.2),  we  get  \nthat  the  average-case  running  time  for  bucket  sort  is \u201a.n/  Cn \ue001 O.2  \ue0031=n/  D \u201a.n/ . \nEven if the input is not drawn from a uniform distr ibution, bucket sort may still \nrun in linear time. As long as the input has the pr operty that the sum of the squares \nof the bucket sizes is linear in the total number o f elements, equation  (8.1)  tells  us \nthat bucket sort runs in linear time. \nExercises  \n8.4-1  \nUsing  Figure  8.4  as a model,  illustrate  the  operation  of BUCKET-SORT  on the array \nA D h:79;  :13;  :16;  :64;  :39;  :20;  :89;  :53;  :71;  :42 i. \n8.4-2  \nExplain  why  the  worst-case  running  time  for  bucket  sort  is \u201a.n  2 /. What simple \nchange  to the  algorithm  preserves  its  linear  average-case  running time and makes \nits  worst-case  running  time  O.n  lg n/? \n8.4-3  \nLet X be a random variable that is equal to the number of  heads in two \u00fcips  of a \nfair coin. What is E \u0152X  2 \ufffd? What  is E 2 \u0152X\ufffd? \n8.4-4  \nAn array A of size n >10  is \u00fblled  in the  following  way.  For  each  element  A\u0152i\ufffd, \nchoose two random variables x i and y i uniformly and independently from \u01520;1/ . \nThen set \nA\u0152i\ufffd  D b10x  i c \n10  C y i \nn : \nModify bucket sort so that it sorts the array A in O.n/  expected time. \n? 8.4-5  \nYou are given n points in the unit disk, p i D .x i ;y  i /, such that 0<x  2 \ni C y 2 \ni \u0dc4 1 \nfor i D 1;2;:::;n . Suppose that the points are uniformly distributed , that is, the \nprobability  of \u00fbnding  a point  in any  region  of the  disk  is proportional to the area \nof that  region.  Design  an algorithm  with  an average-case  running time of \u201a.n/  to \nsort the n points by their distances d i D p \nx 2 \ni C y 2 \ni from the origin. ( Hint: Design \nthe bucket sizes in B UCKET-SORT  to re\u00fcect  the  uniform  distribution  of the  points  \nin the unit disk.) \n? 8.4-6  \nA probability  distribution  function  P.x/  for a random variable X is de\u00fbned  \nby P.x/  D Pr fX \u0dc4 x g. Suppose that you draw a list of n random variables Problems for Chapter 8 219 \nX 1 ;X  2 ;:::;X  n from a continuous probability distribution function  P that  is com-  \nputable in O.1/  time (given y you  can  \u00fbnd  x such that P.x/  D y in O.1/  time). \nGive  an algorithm  that  sorts  these  numbers  in linear  average-case  time.  \nProblems  \n8-1  Probabilistic  lower  bounds  on  comparison  sorting  \nIn this problem, you will prove a probabilistic \ufffd.n  lg n/ lower  bound  on  the  run-  \nning time of any deterministic or randomized compar ison sort on n distinct input \nelements.  You\u2019ll  begin  by  examining  a deterministic  compar ison sort A with  deci-  \nsion tree T A . Assume that every permutation of A\u2019s inputs  is equally  likely.  \na. Suppose that each leaf of T A is labeled with the probability that it is reached \ngiven a random input. Prove that exactly n\u0160 leaves are labeled 1=n\u0160  and that the \nrest are labeled 0. \nb. Let D.T/  denote the external path length of a decision tree T 4the  sum  of the  \ndepths of all the leaves of T . Let T be a decision tree with k > 1  leaves, \nand let LT and RT be the left and right subtrees of T . Show that D.T/  D \nD.LT / C D.RT / C k. \nc. Let d.k/  be the minimum value of D.T/  over all decision trees T with k>1  \nleaves. Show that d.k/  D min fd.i/  C d.k  \ue003 i/ C k W 1 \u0dc4 i \u0dc4 k \ue003 1g. (Hint: \nConsider a decision tree T with k leaves that achieves the minimum. Let i 0 be \nthe number of leaves in LT and k \ue003 i 0 the number of leaves in RT .) \nd. Prove that for a given value of k > 1  and i in the range 1 \u0dc4 i \u0dc4 k \ue003 1, the \nfunction i lg i C .k \ue003 i/ lg.k \ue003 i/ is minimized at i D k=2. Conclude that \nd.k/  D \ufffd.k  lg k/. \ne. Prove that D.T  A / D \ufffd.n\u0160  lg.n\u0160//, and  conclude  that  the  average-case  time  to \nsort n elements is \ufffd.n  lg n/. \nNow consider a randomized  comparison sort B . We  can  extend  the  decision-tree  \nmodel to handle randomization by incorporating two kinds of nodes:  ordinary  com-  \nparison nodes and <randomization= nodes. A randomiz ation node models a random \nchoice of the form R ANDOM.1;r/  made by algorithm B . The node has r children, \neach of which is equally likely to be chosen during  an execution of the algorithm. \nf. Show that for any randomized comparison sort B , there exists a deterministic \ncomparison sort A whose expected number of comparisons is no more tha n \nthose made by B . 220 Chapter 8 Sorting in Linear Time \n8-2  Sorting  in place  in linear  time  \nYou have an array of n data records to sort, each with a key of 0 or 1. An algorithm \nfor sorting such a set of records might possess som e subset of the following three \ndesirable characteristics: \n1. The  algorithm  runs  in O.n/  time. \n2. The algorithm is stable. \n3. The  algorithm  sorts  in place,  using  no  more  than  a constant  amount of storage \nspace in addition to the original array. \na. Give  an algorithm  that  satis\u00fbes  criteria  1 and  2 above.  \nb. Give  an algorithm  that  satis\u00fbes  criteria  1 and  3 above.  \nc. Give  an algorithm  that  satis\u00fbes  criteria  2 and  3 above.  \nd. Can you use any of your sorting algorithms from par ts (a)\u2013(c) as the sorting \nmethod used in line 2 of R ADIX-SORT, so that R ADIX-SORT  sorts n records \nwith b-bit  keys  in O.bn/  time?  Explain  how  or why  not.  \ne. Suppose that the n records have keys in the range from 1 to k. Show how to \nmodify counting sort so that it sorts the records i n place in O.n  C k/  time. You \nmay use O.k/  storage  outside  the  input  array.  Is your  algorithm  stable?  \n8-3  Sorting  variable-length  items  \na. You are given an array of integers, where different  integers may have different \nnumbers of digits, but the total number of digits o ver all the integers in the array \nis n. Show how to sort the array in O.n/  time. \nb. You are given an array of strings, where different strings may have different \nnumbers of characters, but the total number of char acters over all the strings \nis n. Show how to sort the strings in O.n/  time. (The desired order is the \nstandard alphabetical order: for example, a < ab  < b.) \n8-4  Water  jugs  \nYou are given n red and n blue water jugs, all of different shapes and sizes.  All the \nred jugs hold different amounts of water, as do all  the blue jugs, and you cannot \ntell from the size of a jug how much water it holds . Moreover, for every jug of one \ncolor, there is a jug of the other color that holds  the same amount of water. \nYour task is to group the jugs into pairs of red an d blue jugs that hold the same \namount of water. To do so, you may perform the foll owing operation: pick a pair Problems for Chapter 8 221 \nof jugs  in which  one  is red  and  one  is blue,  \u00fbll  the  red  jug  with  water, and then pour \nthe water into the blue jug. This operation tells y ou whether the red jug or the blue \njug can hold more water, or that they have the same  volume. Assume that such \na comparison  takes  one  time  unit.  Your  goal  is to \u00fbnd  an algori thm that makes a \nminimum number of comparisons to determine the grou ping. Remember that you \nmay not directly compare two red jugs or two blue j ugs. \na. Describe a deterministic algorithm that uses \u201a.n  2 / comparisons to group the \njugs into pairs. \nb. Prove a lower bound of \ufffd.n  lg n/ for  the  number  of comparisons  that  an algo-  \nrithm solving this problem must make. \nc. Give  a randomized  algorithm  whose  expected  number  of compar isons is \nO.n  lg n/, and  prove  that  this  bound  is correct.  What  is the  worst-case  num-  \nber  of comparisons  for  your  algorithm?  \n8-5  Average  sorting  \nSuppose that, instead of sorting an array, we just require that the elements increase \non average. More precisely, we call an n-element  array  A k-sorted  if, for all \ni D 1;2;:::;n  \ue003 k, the following holds: \nP  i Ck\ue0021 \nj Di A\u0152j\ufffd  \nk \u0dc4 P  i Ck \nj Di C1 A\u0152j\ufffd  \nk : \na. What  does  it mean  for  an array  to be 1-sorted?  \nb. Give  a permutation  of the  numbers  1;2;:::;10  that  is 2-sorted,  but  not  sorted.  \nc. Prove that an n-element  array  is k-sorted  if and  only  if A\u0152i\ufffd  \u0dc4 A\u0152i  C k\ufffd for all \ni D 1;2;:::;n  \ue003 k. \nd. Give  an algorithm  that  k-sorts  an n-element  array  in O.n  lg.n=k//  time. \nWe can also show a lower bound on the time to produ ce a k-sorted  array,  when  k \nis a constant. \ne. Show how to sort a k-sorted  array  of length  n in O.n  lg k/  time. ( Hint: Use the \nsolution  to Exercise  6.5-11.)  \nf. Show that when k is a constant, k-sorting  an n-element  array  requires  \ufffd.n  lg n/ \ntime. ( Hint: Use the solution to part (e) along with the lower b ound on comp ar-  \nison sorts.) 222 Chapter 8 Sorting in Linear Time \n8-6  Lower  bound  on  merging  sorted  lists  \nThe problem of merging two sorted lists arises freq uently. We have  seen  a proce-  \ndure for it as the subroutine M ERGE  in Section  2.3.1.  In this  problem,  you  will  \nprove a lower bound of 2n  \ue003 1 on  the  worst-case  number  of comparisons  required  \nto merge two sorted lists, each containing n items. First, you will show a lower \nbound of 2n  \ue003 o.n/  comparisons by using a decision tree. \na. Given  2n  numbers, compute the number of possible ways to div ide them into \ntwo sorted lists, each with n numbers. \nb. Using a decision tree and your answer to part (a), show that any algorithm that \ncorrectly merges two sorted lists must perform at l east 2n  \ue003 o.n/  comparisons. \nNow you will show a slightly tighter 2n  \ue003 1 bound. \nc. Show that if two elements are consecutive in the so rted order and from different \nlists, then they must be compared. \nd. Use your answer to part (c) to show a lower bound o f 2n  \ue003 1 comparisons for \nmerging two sorted lists. \n8-7  The  0-1  sorting  lemma  and  columnsort  \nA compare-exchange  operation on two array elements A\u0152i\ufffd  and A\u0152j\ufffd , where i <j  , \nhas the form \nCOMPARE-EXCHANGE  .A;i;j/  \n1 if A\u0152i\ufffd>A\u0152j\ufffd  \n2 exchange A\u0152i\ufffd  with A\u0152j\ufffd  \nAfter  the  compare-exchange  operation,  we  know  that  A\u0152i\ufffd  \u0dc4 A\u0152j\ufffd . \nAn oblivious  compare-exchange  algorithm  operates solely by a sequence of \nprespeci\u00fbed  compare-exchange  operations.  The  indices  of the positions compared \nin the sequence must be determined in advance, and although they can depend \non the number of elements being sorted, they cannot  depend on the values being \nsorted, nor can they depend on the result of any pr ior compare-exchange  operation.  \nFor example, the C OMPARE-EXCHANGE-I NSERTION-SORT  procedure  on  the  fac-  \ning page shows a variation of insertion sort as an oblivious compare-exchange  algo-  \nrithm. (Unlike the I NSERTION-SORT  procedure  on  page  19,  the  oblivious  version  \nruns in \u201a.n  2 / time in all cases.) \nThe 0-1  sorting  lemma  provides a powerful way to prove that an oblivious \ncompare-exchange  algorithm  produces  a sorted  result.  It states  that  if an oblivi-  \nous  compare-exchange  algorithm  correctly  sorts  all  input  sequences consisting of \nonly  0s and  1s,  then  it correctly  sorts  all  inputs  containing  arbitrary values. Problems for Chapter 8 223 \nCOMPARE-EXCHANGE-I NSERTION-SORT  .A;n/  \n1 for  i D 2 to n \n2 for  j D i \ue003 1 downto  1 \n3 COMPARE-EXCHANGE  .A;j;j  C 1/ \nYou  will  prove  the  0-1  sorting  lemma  by  proving  its  contrapositive:  if an oblivi-  \nous  compare-exchange  algorithm  fails  to sort  an input  conta ining arbitrary values, \nthen  it fails  to sort  some  0-1  input.  Assume  that  an oblivious  compare-exchange  \nalgorithm X fails to correctly sort the array A\u01521  W n\ufffd. Let A\u0152p\ufffd  be the smallest value \nin A that algorithm X puts into the wrong location, and let A\u0152q\ufffd  be the value that \nalgorithm X moves to the location into which A\u0152p\ufffd  should  have  gone.  De\u00fbne  an \narray B\u01521  W n\ufffd of 0s and  1s as follows:  \nB\u0152i\ufffd  D ( \n0 if A\u0152i\ufffd  \u0dc4 A\u0152p\ufffd;  \n1 if A\u0152i\ufffd>A\u0152p\ufffd:  \na. Argue that A\u0152q\ufffd>A\u0152p\ufffd , so that B\u0152p\ufffd  D 0 and B\u0152q\ufffd  D 1. \nb. To  complete  the  proof  of the  0-1  sorting  lemma,  prove  that  algorithm X fails to \nsort array B correctly. \nNow  you  will  use  the  0-1  sorting  lemma  to prove  that  a particular  sorting  algo-  \nrithm works correctly. The algorithm, columnsort , works on a rectangular array \nof n elements. The array has r rows and s columns (so that n D rs ), subject to \nthree restrictions: \n\ue001 r must be even, \n\ue001 s must be a divisor of r , and \n\ue001 r \ue004 2s  2 . \nWhen columnsort completes, the array is sorted in column-major  order : reading \ndown each column in turn, from left to right, the e lements monotonically increase. \nColumnsort operates in eight steps, regardless of t he value of n. The odd steps \nare all the same: sort each column individually. Ea ch even step is a \u00fbxed  permuta-  \ntion. Here are the steps: \n1. Sort  each  column.  \n2. Transpose the array, but reshape it back to r rows and s columns. In other \nwords, turn the leftmost column into the top r=s  rows, in order; turn the next \ncolumn into the next r=s  rows, in order; and so on. 224 Chapter 8 Sorting in Linear Time \n10  14  5 \n8 7 17  \n12  1 6 \n16  9 11  \n4 15  2 \n18  3 13  \n(a) 4 1 2  \n8 3 5  \n10  7 6 \n12  9 11  \n16  14  13  \n18  15  17  \n(b) 4 8 10  \n12  16  18  \n1 3 7  \n9 14  15  \n2 5 6  \n11  13  17  \n(c) 1 3 6  \n2 5 7  \n4 8 10  \n9 13  15  \n11  14  17  \n12  16  18  \n(d) 1 4 11  \n3 8 14  \n6 10  17  \n2 9 12  \n5 13  16  \n7 15  18  \n(e) \n1 4 11  \n2 8 12  \n3 9 14  \n5 10  16  \n6 13  17  \n7 15  18  \n(f) 5 10  16  \n6 13  17  \n7 15  18  \n1 4 11  \n2 8 12  \n3 9 14  \n(g) 4 10  16  \n5 11  17  \n6 12  18  \n1 7 13  \n2 8 14  \n3 9 15  \n(h) 1 7 13  \n2 8 14  \n3 9 15  \n4 10  16  \n5 11  17  \n6 12  18  \n(i) \nFigure  8.5  The steps of columnsort. (a)  The  input  array  with  6 rows  and  3 columns.  (This  example  \ndoes not obey the r \ue004 2s  2 requirement, but it works.) (b)  After  sorting  each  column  in step  1. \n(c)  After transposing and reshaping in step 2. (d)  After  sorting  each  column  in step  3. (e)  After \nperforming  step  4, which  inverts  the  permutation  from  step  2. (f)  After sorting each column in \nstep  5. (g)  After  shifting  by  half  a column  in step  6. (h)  After  sorting  each  column  in step  7. (i)  After \nperforming  step  8, which  inverts  the  permutation  from  step  6. Steps  638  sort  the  bottom  half  of each  \ncolumn  with  the  top  half  of the  next  column.  After  step  8, the  array  is sorted  in column-major  order.  \n3. Sort  each  column.  \n4. Perform  the  inverse  of the  permutation  performed  in step  2. \n5. Sort  each  column.  \n6. Shift  the  top  half  of each  column  into  the  bottom  half  of the  same column, and \nshift the bottom half of each column into the top h alf of the next column to the \nright. Leave the top half of the leftmost column em pty. Shift the bottom half \nof the last column into the top half of a new right most column, and leave the \nbottom half of this new column empty. \n7. Sort  each  column.  \n8. Perform  the  inverse  of the  permutation  performed  in step  6. \nYou  can  think  of steps  638  as a single  step  that  sorts  the  botto m half of each column \nand  the  top  half  of the  next  column.  Figure  8.5  shows  an exampl e of the steps \nof columnsort with r D 6 and s D 3. (Even though this example violates the \nrequirement that r \ue004 2s  2 , it happens to work.) \nc. Argue  that  we  can  treat  columnsort  as an oblivious  compare-exchange  algo-  \nrithm, even if we do not know what sorting method t he odd steps use. Notes for Chapter 8 225 \nAlthough it might seem hard to believe that columns ort actually sorts, you will \nuse  the  0-1  sorting  lemma  to prove  that  it does.  The  0-1  sortin g lemma applies \nbecause  we  can  treat  columnsort  as an oblivious  compare-exc hange algorithm. A \ncouple  of de\u00fbnitions  will  help  you  apply  the  0-1  sorting  lemm a. We say that an \narea of an array is clean  if we  know  that  it contains  either  all  0s or all  1s or if it is \nempty.  Otherwise,  the  area  might  contain  mixed  0s and  1s,  and  it is dirty . From \nhere  on,  assume  that  the  input  array  contains  only  0s and  1s,  and that we can treat \nit as an array with r rows and s columns. \nd. Prove  that  after  steps  133,  the  array  consists  of clean  rows  of 0s at the top, clean \nrows  of 1s at the  bottom,  and  at most  s dirty  rows  between  them.  (One  of the  \nclean rows could be empty.) \ne. Prove  that  after  step  4, the  array,  read  in column-major  order, starts with a clean \narea  of 0s,  ends  with  a clean  area  of 1s,  and  has  a dirty  area  of at most s 2 \nelements in the middle. (Again, one of the clean ar eas could be empty.) \nf. Prove  that  steps  538  produce  a fully  sorted  0-1  output.  Conclude  that  column-  \nsort correctly sorts all inputs containing arbitrar y values. \ng. Now suppose that s does not divide r . Prove  that  after  steps  133,  the  array  \nconsists  of clean  rows  of 0s at the  top,  clean  rows  of 1s at the  bottom, and at \nmost 2s  \ue003 1 dirty  rows  between  them.  (Once  again,  one  of the  clean  areas  could \nbe empty.) How large must r be, compared with s , for columnsort to correctly \nsort when s does not divide r ? \nh. Suggest  a simple  change  to step  1 that  allows  us to maintain  the requirement \nthat r \ue004 2s  2 even when s does not divide r , and prove that with your change, \ncolumnsort correctly sorts. \nChapter  notes  \nThe  decision-tree  model  for  studying  comparison  sorts  was  introduced by Ford \nand  Johnson  [150].  Knuth\u2019s  comprehensive  treatise  on  sorting  [261]  covers  many  \nvariations on the sorting problem, including the in formation-theoretic  lower  bound  \non  the  complexity  of sorting  given  here.  Ben-Or  [46]  studied  lower bounds for \nsorting  using  generalizations  of the  decision-tree  model.  \nKnuth  credits  H.  H.  Seward  with  inventing  counting  sort  in 1954,  as well  as with  \nthe idea of combining counting sort with radix sort . Radix sorting starting with the \nleast  signi\u00fbcant  digit  appears  to be a folk  algorithm  widely  used by operators of 226 Chapter 8 Sorting in Linear Time \nmechanical  card-sorting  machines.  According  to Knuth,  the  \u00fbrst  published  refer-  \nence  to the  method  is a 1929  document  by  L. J. Comrie  describing  punched-card  \nequipment.  Bucket  sorting  has  been  in use  since  1956,  when  the basic idea was \nproposed  by  Isaac  and  Singleton  [235].  \nMunro  and  Raman  [338]  give  a stable  sorting  algorithm  that  performs O.n  1C\ue001 / \ncomparisons in the worst case, where 0<\ufffd  \u0dc4 1 is any  \u00fbxed  constant.  Although  \nany of the O.n  lg n/-time  algorithms  make  fewer  comparisons,  the  algorithm  by  \nMunro and Raman moves data only O.n/  times and operates in place. \nThe case of sorting nb-bit  integers  in o.n  lg n/ time has been considered by \nmany researchers. Several positive results have bee n obtained, each under slightly \ndifferent assumptions about the model of computatio n and the restrictions placed \non the algorithm. All the results assume that the c omputer memory is divided into \naddressable b-bit  words.  Fredman  and  Willard  [157]  introduced  the  fusion  tree data \nstructure and used it to sort n integers in O.n  lg n=  lg lg n/ time. This bound was \nlater improved to O.n  p \nlg n/ time  by  Andersson  [17].  These  algorithms  require  \nthe use of multiplication and several precomputed c onstants. Andersson, Hagerup, \nNilsson,  and  Raman  [18]  have  shown  how  to sort  n integers in O.n  lg lg n/ time \nwithout using multiplication, but their method requ ires storage  that  can  be un-  \nbounded in terms of n. Using multiplicative hashing, we can reduce the s torage \nneeded to O.n/ , but then the O.n  lg lg n/ worst-case  bound  on  the  running  time  \nbecomes  an expected-time  bound.  Generalizing  the  exponent ial search trees of \nAndersson  [17],  Thorup  [434]  gave  an O.n. lg lg n/ 2 /-time  sorting  algorithm  that  \ndoes not use multiplication or randomization, and i t uses linear space. Combining \nthese  techniques  with  some  new  ideas,  Han  [207]  improved  the  bound for sorting \nto O.n  lg lg n lg lg lg n/ time. Although these algorithms are important theor etical \nbreakthroughs, they are all fairly complicated and at the present time seem unlikely \nto compete with existing sorting algorithms in prac tice. \nThe  columnsort  algorithm  in Problem  8-7  is by  Leighton  [286] . 9 Medians  and  Order  Statistics  \nThe i th order  statistic  of a set of n elements is the i th smallest element. For \nexample, the minimum  of a set  of elements  is the  \u00fbrst  order  statistic  (i D 1), \nand the maximum  is the nth order statistic ( i D n). A median , informally, is \nthe <halfway point= of the set. When n is odd, the median is unique, occurring at \ni D .n C1/=2 . When n is even, there are two medians, the lower  median  occurring \nat i D n=2  and the upper  median  occurring at i D n=2  C 1. Thus, regardless of \nthe parity of n, medians occur at i D b.n C 1/=2c and i D d.n C 1/=2e. For \nsimplicity in this text, however, we consistently u se the phrase <the median= to \nrefer to the lower median. \nThis chapter addresses the problem of selecting the  i th order statistic from a \nset of n distinct numbers. We assume for convenience that th e set contains  dis-  \ntinct numbers, although virtually everything that w e do extends to the situation in \nwhich a set contains repeated values. We formally s pecify the selection  problem  \nas follows: \nInput:  A set A of n distinct numbers 1 and an integer i , with 1 \u0dc4 i \u0dc4 n. \nOutput:  The element x 2 A that is larger than exactly i \ue003 1 other elements of A. \nWe can solve the selection problem in O.n  lg n/ time  simply  by  sorting  the  num-  \nbers using heapsort or merge sort and then outputti ng the i th element in the sorted \narray. This chapter presents asymptotically faster algorithms. \nSection  9.1  examines  the  problem  of selecting  the  minimum  and maximum of \na set of elements. More interesting is the general selection problem, which we \ninvestigate in the subsequent two sections. Section  9.2 analyzes  a practical  ran-  \ndomized algorithm that achieves an O.n/  expected  running  time,  assuming  dis-  \n1 As  in the  footnote  on  page  182,  you  can  enforce  the  assumption  that the numbers are distinct by \nconverting each input value A\u0152i\ufffd  to an ordered pair .A\u0152i\ufffd;i/  with .A\u0152i\ufffd;i/  < .A\u0152j\ufffd;j/  if either \nA\u0152i\ufffd<A\u0152j\ufffd  or A\u0152i\ufffd  D A\u0152j\ufffd  and i<j  . 228  Chapter  9 Medians  and  Order  Statistics  \ntinct  elements.  Section  9.3  contains  an algorithm  of more  theoretical interest that \nachieves the O.n/  running time in the worst case. \n9.1  Minimum  and  maximum  \nHow many comparisons are necessary to determine the  minimum of a set of n \nelements?  To  obtain  an upper  bound  of n \ue003 1 comparisons, just examine each \nelement of the set in turn and keep track of the sm allest element seen so far. The \nMINIMUM procedure assumes that the set resides in array A\u01521  W n\ufffd. \nMINIMUM.A;n/  \n1 min D A\u01521\ufffd  \n2 for  i D 2 to n \n3 if min >A\u0152i\ufffd  \n4 min D A\u0152i\ufffd  \n5 return  min \nIt\u2019s  no  more  dif\u00fbcult  to \u00fbnd  the  maximum  with  n \ue003 1 comparisons. \nIs this  algorithm  for  minimum  the  best  we  can  do?  Yes,  because  it turns out that \nthere\u2019s  a lower  bound  of n \ue003 1 comparisons for the problem of determining the \nminimum. Think of any algorithm that determines the  minimum as a tournament \namong the elements. Each comparison is a match in t he tournament in which the \nsmaller of the two elements wins. Since every eleme nt except the winner must \nlose at least one match, we can conclude that n \ue003 1 comparisons are necessary to \ndetermine the minimum. Hence the algorithm M INIMUM is optimal with respect \nto the number of comparisons performed. \nSimultaneous  minimum  and  maximum  \nSome  applications  need  to \u00fbnd  both  the  minimum  and  the  maximu m of a set of n \nelements. For example, a graphics program may need to scale a set of .x;y/  data \nto \u00fbt onto  a rectangular  display  screen  or other  graphical  output device. To do \nso,  the  program  must  \u00fbrst  determine  the  minimum  and  maximum  value of each \ncoordinate. \nOf  course,  we  can  determine  both  the  minimum  and  the  maximum  of n ele-  \nments using \u201a.n/  comparisons.  We  simply  \u00fbnd  the  minimum  and  maximum  in-  \ndependently, using n \ue003 1 comparisons for each, for a total of 2n  \ue003 2 D \u201a.n/  \ncomparisons. 9.1  Minimum  and  maximum  229 \nAlthough 2n  \ue003 2 comparisons is asymptotically optimal, it is possib le to improve \nthe  leading  constant.  We  can  \u00fbnd  both  the  minimum  and  the  maxi mum using at \nmost 3 bn=2c comparisons. The trick is to maintain both the mini mum and ma xi-  \nmum elements seen thus far. Rather than processing each element of the input by \ncomparing it against the current minimum and maximu m, at a cost of 2 compar-  \nisons per element, process elements in pairs. Compa re pairs of elements from the \ninput  \u00fbrst  with  each  other, and  then  compare  the  smaller  with  the  current  mini-  \nmum and the larger to the current maximum, at a cos t of 3 comparisons for every \n2 elements. \nHow you set up initial values for the current minim um and maximum depends \non whether n is odd or even. If n is odd, set both the minimum and maximum to \nthe  value  of the  \u00fbrst  element,  and  then  process  the  rest  of the  elements in pairs. \nIf n is even, perform 1 comparison  on  the  \u00fbrst  2 elements to determine the initial \nvalues of the minimum and maximum, and then process  the rest of the elements in \npairs as in the case for odd n. \nLet\u2019s  count  the  total  number  of comparisons.  If n is odd, then 3 bn=2c com-  \nparisons occur. If n is even, 1 initial comparison occurs, followed by another \n3.n  \ue003 2/=2  comparisons, for a total of 3n=2  \ue003 2. Thus, in either case, the total \nnumber of comparisons is at most 3 bn=2c. \nExercises  \n9.1-1  \nShow that the second smallest of n elements can be found with n C dlg ne \ue003  2 \ncomparisons in the worst case. ( Hint: Also  \u00fbnd  the  smallest  element.)  \n9.1-2  \nGiven  n>2  distinct  numbers,  you  want  to \u00fbnd  a number  that  is neither  the  min-  \nimum nor the maximum. What is the smallest number o f comparisons that you \nneed  to perform?  \n9.1-3  \nA racetrack  can  run  races  with  \u00fbve  horses  at a time  to determin e their relative \nspeeds. For 25  horses, it takes six races to determine the fastest  horse, assum-  \ning  transitivity  (see  page  1159).  What\u2019s  the  minimum  number  of races it takes to \ndetermine the fastest three horses out of 25? \n? 9.1-4  \nProve the lower bound of d3n=2 e \ue003  2 comparisons  in the  worst  case  to \u00fbnd  both  \nthe maximum and minimum of n numbers. ( Hint: Consider how many numbers \nare potentially either the maximum or minimum, and investigate how a comparison \naffects these counts.) 230  Chapter  9 Medians  and  Order  Statistics  \n9.2  Selection  in expected  linear  time  \nThe  general  selection  problem4\u00fbnding  the  i th order statistic for any value of i 4  \nappears  more  dif\u00fbcult  than  the  simple  problem  of \u00fbnding  a minimum.  Yet,  sur-  \nprisingly, the asymptotic running time for both pro blems is the same: \u201a.n/ . This \nsection  presents  a divide-and-conquer  algorithm  for  the  selection  problem.  The  al-  \ngorithm R ANDOMIZED -SELECT is modeled  after  the  quicksort  algorithm  of Chap-  \nter  7. Like  quicksort  it partitions  the  input  array  recursiv ely. But unlike quicksort, \nwhich recursively processes both sides of the parti tion, RANDOMIZED -SELECT \nworks on only one side of the partition. This diffe rence shows up in the analysis: \nwhereas quicksort has an expected running time of \u201a.n  lg n/, the expected running \ntime of RANDOMIZED -SELECT is \u201a.n/ , assuming that the elements are distinct. \nRANDOMIZED -SELECT uses the procedure R ANDOMIZED -PARTITION  intro-  \nduced  in Section  7.3.  Like  RANDOMIZED -QUICKSORT, it is a randomized  algo-  \nrithm, since its behavior is determined in part by the output of a random-number  \ngenerator. The R ANDOMIZED -SELECT procedure returns the i th smallest element \nof the array A\u0152p  W r\ufffd, where 1 \u0dc4 i \u0dc4 r \ue003 p C 1. \nRANDOMIZED -SELECT .A;p;r;i/  \n1 if p = = r \n2 return  A\u0152p\ufffd  / / 1 \u0dc4 i \u0dc4 r \ue003 p C 1 when p == r means that i D 1 \n3 q D RANDOMIZED -PARTITION  .A;p;r/  \n4 k D q \ue003 p C 1 \n5 if i == k \n6 return  A\u0152q\ufffd  / / the pivot value is the answer \n7 elseif  i<k  \n8 return  RANDOMIZED -SELECT .A;p;q  \ue003 1;i/  \n9 else  return  RANDOMIZED -SELECT .A;q  C 1;r;i  \ue003 k/  \nFigure  9.1  illustrates  how  the  RANDOMIZED -SELECT procedure  works.  Line  1 \nchecks for the base case of the recursion, in which  the subarray A\u0152p  W r\ufffd consists \nof just one element. In this case, i must equal 1, and line 2 simply returns A\u0152p\ufffd  \nas the i th smallest  element.  Otherwise,  the  call  to RANDOMIZED -PARTITION  in \nline  3 partitions  the  array  A\u0152p  W r\ufffd into two (possibly empty) subarrays A\u0152p  W q \ue003 1\ufffd \nand A\u0152q  C 1 W r\ufffd such that each element of A\u0152p  W q \ue003 1\ufffd is less than or equal to A\u0152q\ufffd, \nwhich in turn is less than each element of A\u0152q  C 1 W r\ufffd. (Although our analysis \nassumes that the elements are distinct, the procedu re still yields the correct result \neven  if equal  elements  are  present.)  As  in quicksort,  we\u2019ll  refer to A\u0152q\ufffd  as the pivot  \nelement.  Line  4 computes  the  number  k of elements in the subarray A\u0152p  W q\ufffd, that is, 9.2  Selection  in expected  linear  time  231 \n1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  \n6 19  4 12  14  9 15  7 8 11  3 13  2 5 10  \n1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  \n6 4 12  10  9 7 8 11  3 13  2 5 14  19  15  \n1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  \n3 2 4 10  9 7 8 11  6 13  5 12  14  19  15  \n1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  \n3 2 4 10  9 7 8 11  6 12  5 13  14  19  15  \n1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  \n3 2 4 5 6 7 8 11  9 12  10  13  14  19  15  \n1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  \n3 2 4 5 6 7 8 11  9 12  10  13  14  19  15  partitioning p r i helpful?  \n1 15  5 \n1 no  \n1 12  5 \n2 yes \n4 12  2 \n3 no  \n4 11  2 \n4 yes  \n4 5 2 \n5 yes  \n5 5 1 A .0/  \nA .1/  \nA .2/  \nA .3/  \nA .4/  \nA .5/  \nFigure  9.1  The action of R ANDOMIZED -SELECT as successive partitionings narrow the subarray \nA\u0152p  W r\ufffd, showing the values of the parameters p, r , and i at each recursive call. The subarray A\u0152p  W r\ufffd \nin each recursive step is shown in tan, with the da rk tan element selected as the pivot for the next \npartitioning. Blue elements are outside A\u0152p  W r\ufffd. The answer is the tan element in the bottom array , \nwhere p D r D 5 and i D 1. The array designations A .0/  ;A  .1/  ;:::;A  .5/  , the partitioning numbers, \nand whether the partitioning is helpful are explain ed on the following page. \nthe number of elements in the low side of the parti tion, plus 1 for the pivot element. \nLine  5 then  checks  whether  A\u0152q\ufffd  is the i th smallest  element.  If it is, then  line  6 \nreturns A\u0152q\ufffd. Otherwise,  the  algorithm  determines  in which  of the  two  subarrays \nA\u0152p  W q \ue003 1\ufffd and A\u0152q  C 1 W r\ufffd the i th smallest element lies. If i<k , then the desired \nelement  lies  on  the  low  side  of the  partition,  and  line  8 recur sively selects it from \nthe subarray. If i >k , however, then the desired element lies on the hig h side of \nthe partition. Since we already know k values that are smaller than the i th smallest \nelement of A\u0152p  W r\ufffd4namely,  the  elements  of A\u0152p  W q\ufffd4the  desired  element  is the  \n.i \ue003 k/th smallest element of A\u0152q  C 1 W r\ufffd, which  line  9 \u00fbnds  recursively.  The  code  \nappears to allow recursive calls to subarrays with 0 elements,  but  Exercise  9.2-1  \nasks you to show that this situation cannot happen.  \nThe  worst-case  running  time  for  RANDOMIZED -SELECT is \u201a.n  2 /, even to \n\u00fbnd  the  minimum,  because  it could  be extremely  unlucky  and  always partition \naround the largest remaining element before identif ying the i th smallest when \nonly one element remains. In this worst case, each recursive step removes only \nthe pivot from consideration. Because partitioning n elements takes \u201a.n/  time, \nthe  recurrence  for  the  worst-case  running  time  is the  same  as for  QUICKSORT : 232  Chapter  9 Medians  and  Order  Statistics  \nT.n/  D T.n  \ue003 1/ C \u201a.n/ , with the solution T.n/  D \u201a.n  2 /. We\u2019ll  see  that  the  al-  \ngorithm has a linear expected running time, however , and because it is randomized, \nno  particular  input  elicits  the  worst-case  behavior.  \nTo see the intuition behind the linear expected run ning time, suppose that each \ntime the algorithm randomly selects a pivot element , the pivot lies somewhere \nwithin  the  second  and  third  quartiles4the  <middle  half=4of  the  remaining  ele-  \nments in sorted order. If the i th smallest element is less than the pivot, then al l \nthe elements greater than the pivot are ignored in all future recursive calls. These \nignored elements include at least the uppermost qua rtile, and  possibly  more.  Like-  \nwise, if the i th smallest element is greater than the pivot, then  all the elements \nless  than  the  pivot4at  least  the  \u00fbrst  quartile4are  ignored  in all future recursive \ncalls. Either way, therefore, at least 1=4  of the remaining elements are ignored in \nall future recursive calls, leaving at most 3=4  of the remaining elements in play: \nresiding in the subarray A\u0152p  W r\ufffd. Since R ANDOMIZED -PARTITION  takes \u201a.n/  \ntime on a subarray of n elements,  the  recurrence  for  the  worst-case  running  time  \nis T.n/  D T.3n=4/  C \u201a.n/. By  case  3 of the  master  method  (Theorem  4.1  on  \npage  102),  this  recurrence  has  solution  T.n/  D \u201a.n/ . \nOf  course,  the  pivot  does  not  necessarily  fall  into  the  middl e half every time. \nSince the pivot is selected at random, the probabil ity that it falls into the middle \nhalf is about 1=2  each time. We can view the process of selecting the  pivot as a \nBernoulli  trial  (see  Section  C.4)  with  success  equating  to the pivot residing in the \nmiddle half. Thus the expected number of trials nee ded for success is given by a \ngeometric distribution: just two trials on average (equation  (C.36)  on  page  1197).  \nIn other words, we expect that half of the partitio nings reduce the  number  of ele-  \nments still in play by at least 3=4  and that half of the partitionings do not help as \nmuch. Consequently, the expected number of partitio nings at most doubles from \nthe case when the pivot always falls into the middl e half. The cost of each extra \npartitioning is less than the one that preceded it,  so that the expected running time \nis still \u201a.n/ . \nTo  make  the  above  argument  rigorous,  we  start  by  de\u00fbning  the  random  vari-  \nable A .j / as the set of elements of A that are still in play after j partitionings (that \nis, within the subarray A\u0152p  W r\ufffd after j calls of R ANDOMIZED -SELECT ), so that \nA .0/  consists of all the elements in A. Since each partitioning removes at least \none  element4the  pivot4from  being  in play,  the  sequence  jA .0/  j; jA .1/  j; jA .2/  j;:::  \nstrictly decreases. Set A .j \ue0021/  is in play before the j th partitioning, and set A .j / \nremains in play afterward. For convenience, assume that the initial set A .0/  is the \nresult of a 0th <dummy= partitioning. \nLet\u2019s  call  the  j th partitioning helpful  if jA .j / j \u0dc4  .3=4/ jA .j \ue0021/  j. Figure  9.1  \nshows the sets A .j / and whether partitionings are helpful for an exampl e array. \nA helpful partitioning corresponds to a successful Bernoulli trial. The following \nlemma shows that a partitioning is at least as like ly to be helpful as not. 9.2  Selection  in expected  linear  time  233 \nLemma  9.1  \nA partitioning is helpful with probability at least  1=2. \nProof  Whether a partitioning is helpful depends on the ra ndomly chosen pivot. \nWe discussed the <middle half= in the informal argu ment above. Let\u2019s  more  pre-  \ncisely  de\u00fbne  the  middle  half  of an n-element  subarray  as all  but  the  smallest  \ndn=4e \ue003  1 and greatest dn=4e \ue003  1 elements  (that  is, all  but  the  \u00fbrst  dn=4e \ue003  1 \nand last dn=4e \ue003  1 elements  if the  subarray  were  sorted).  We\u2019ll  prove  that  if the \npivot falls into the middle half, then the pivot le ads to a helpful partitioning, and \nwe\u2019ll  also  prove  that  the  probability  of the  pivot  falling  into the middle half is at \nleast 1=2. \nRegardless of where the pivot falls, either all the  elements greater than it or all \nthe elements less than it, along with the pivot its elf, will no longer be in play after \npartitioning. If the pivot falls into the middle ha lf, therefore, at least dn=4e \ue003  1 \nelements less than the pivot or dn=4e \ue003  1 elements greater than the pivot, plus \nthe pivot, will no longer be in play after partitio ning. That is, at least dn=4e ele-  \nments will no longer be in play. The number of elem ents remaining in play will \nbe at most n \ue003 dn=4e, which equals b3n=4 c by  Exercise  3.3-2  on  page  70.  Since  \nb3n=4 c \u0dc4  3n=4 , the partitioning is helpful. \nTo determine a lower bound on the probability that a randomly chosen pivot falls \ninto the middle half, we determine an upper bound o n the probability that it does \nnot. That probability is \n2.dn=4e \ue003  1/ \nn \u0dc4 2..n=4  C 1/ \ue003 1/ \nn (by  inequality  (3.2)  on  page  64)  \nD n=2  \nn \nD 1=2:  \nThus, the pivot has a probability of at least 1=2  of falling into the middle half, and \nso the probability is at least 1=2  that a partitioning is helpful. \nWe can now bound the expected running time of R ANDOMIZED -SELECT . \nTheorem  9.2  \nThe procedure R ANDOMIZED -SELECT on an input array of n distinct elements has \nan expected running time of \u201a.n/ . \nProof  Since  not  every  partitioning  is necessarily  helpful,  let\u2019s  give  each  parti-  \ntioning an index starting at 0 and denote by hh 0 ;h  1 ;h  2 ;:::;h  m i the sequence \nof partitionings that are helpful, so that the h k th partitioning is helpful for k D \n0;1;2;:::;m . Although the number m of helpful  partitionings  is a random  vari-  234  Chapter  9 Medians  and  Order  Statistics  \n\u2026 \u2026 \u2026 \ngeneration 0 generation  1 generation k \u2026 \u2026 A .0/  \nA .1/  A .2/  A .h  1 \ue0021/  \nA .h  1 / \nA .h  1 C1/  \nA .h  1 C2/  A .h  2 \ue0021/  \nA .h  2 / \nA .h  k \ue0021/  \nA .h  k / \nA .h  k C1/  \nA .h  k C2/  A .h  kC1 \ue0021/  \nA .h  kC1 / \nA .hm/ \nFigure  9.2  The sets within each generation in the proof of The orem 9.2. Vertical lines represent the \nsets, with the height of each line indicating the s ize of the set, which equals the number of elements  in \nplay. Each generation starts with a set A .h  k / , which is the result of a helpful partitioning. Th ese sets \nare drawn in black and are at most 3=4  the size of the sets to their immediate left. Sets drawn in orange \nare  not  the  \u00fbrst  within  a generation.  A generation  may  contai n just one set. The sets in generation k \nare A .h  k / ;A  .h  k C1/  ;:::;A  .h  kC1 \ue0021/  . The sets A .h  k / are  de\u00fbned  so that  jA .h  k / j \u0dc4  .3=4/ jA .h  k\ue0031 / j. \nIf the partitioning gets all the way to generation h m , set A .h  m  / has at most one element in play. \nable, we can bound it, since after at most dlog 4=3  ne helpful partitionings, only one \nelement remains in play. Consider the dummy 0th partitioning as helpful, so that \nh 0 D 0. Denote jA .h  k / j by n k , where n 0 D jA .0/  j is the original problem size. \nSince the h k th partitioning is helpful and the sizes of the set s A .j / strictly decrease, \nwe have n k D jA .h  k / j \u0dc4  .3=4/ jA .h  k \ue0021/  j D  .3=4/n  k\ue0021 for k D 1;2;:::;m . By \niterating n k \u0dc4 .3=4/n  k\ue0021 , we have that n k \u0dc4 .3=4/  k n 0 for k D 0;1;2;:::;m . \nAs Figure 9.2 depicts, we break up the sequence of sets A .j / into m genera-  \ntions  consisting of consecutively partitioned sets, start ing with the result A .h  k / of \na helpful partitioning and ending with the last set  A .h  kC1 \ue0021/  before  the  next  help-  \nful partitioning, so that the sets in generation k are A .h  k / ;A  .h  k C1/  ;:::;A  .h  kC1 \ue0021/  . \nThen for each set of elements A .j / in the kth generation, we have that jA .j / j \u0dc4  \njA .h  k / j D  n k \u0dc4 .3=4/  k n 0 . \nNext,  we  de\u00fbne  the  random  variable  \nX k D h kC1 \ue003 h k \nfor k D 0;1;2;:::;m  \ue003 1. That is, X k is the number of sets in the kth generation, \nso that the sets in the kth generation are A .h  k / ;A  .h  k C1/  ;:::;A  .h  k CX k \ue0021/  . \nBy  Lemma  9.1,  the  probability  that  a partitioning  is helpful  is at least 1=2. The \nprobability is actually even higher, since a partit ioning is helpful even if the pivot 9.2  Selection  in expected  linear  time  235 \ndoes not fall into the middle half but the i th smallest element happens to lie in the \nsmaller  side  of the  partitioning.  We\u2019ll  just  use  the  lower  bound of 1=2, however, \nand  then  equation  (C.36)  gives  that  E \u0152X  k \ufffd \u0dc4 2 for k D 0;1;2;:::;m  \ue003 1. \nLet\u2019s  derive  an upper  bound  on  how  many  comparisons  are  made  altogether  dur-  \ning partitioning, since the running time is dominat ed by the comparisons. Since \nwe are calculating an upper bound, assume that the recursion goes  all  the  way  un-  \ntil only one element remains in play. The j th partitioning takes the set A .j \ue0021/  of \nelements in play, and it compares the randomly chos en pivot with all the other \njA .j \ue0021/  j \ue003  1 elements, so that the j th partitioning makes fewer than jA .j \ue0021/  j \ncomparisons. The sets in the kth generation have sizes jA .h  k / j; jA .h  k C1/  j;:::;  \njA .h  k CX k \ue0021/  j. Thus, the total number of comparisons during part itioning is less \nthan \nm\ue0021 X  \nkD0 h k CX k \ue0021 X  \nj Dh k jA .j / j \u0dc4  m\ue0021 X  \nkD0 h k CX k \ue0021 X  \nj Dh k jA .h  k / j \nD m\ue0021 X  \nkD0 X k jA .h  k / j \n\u0dc4 m\ue0021 X  \nkD0 X k \u00cf 3 \n4 \u00d0 k \nn 0 : \nSince E \u0152X  k \ufffd \u0dc4 2, we have that the expected total number of compari sons during \npartitioning is less than \nE \" m\ue0021 X  \nkD0 X k \u00cf 3 \n4 \u00d0 k \nn 0 # \nD m\ue0021 X  \nkD0 E \" \nX k \u00cf 3 \n4 \u00d0 k \nn 0 # \n(by linearity of expectation) \nD n 0 m\ue0021 X  \nkD0 \u00cf 3 \n4 \u00d0 k \nE \u0152X  k \ufffd \n\u0dc4 2n  0 m\ue0021 X  \nkD0 \u00cf 3 \n4 \u00d0 k \n< 2n  0 1  X  \nkD0 \u00cf 3 \n4 \u00d0 k \nD 8n  0 (by  equation  (A.7)  on  page  1142)  . \nSince n 0 is the size of the original array A, we  conclude  that  the  expected  num-  \nber of comparisons, and thus the expected running t ime, for R ANDOMIZED - \nSELECT is O.n/ . All n elements  are  examined  in the  \u00fbrst  call  of RANDOMIZED - 236  Chapter  9 Medians  and  Order  Statistics  \nPARTITION , giving a lower bound of \ufffd.n/ . Hence the expected running time \nis \u201a.n/ . \nExercises  \n9.2-1  \nShow that R ANDOMIZED -SELECT never makes a recursive call to a 0-length  array.  \n9.2-2  \nWrite an iterative version of R ANDOMIZED -SELECT . \n9.2-3  \nSuppose that R ANDOMIZED -SELECT is used to select the minimum element of the \narray A D h2;3;0;5;7;9;1;8;6;4 i. Describe a sequence of partitions that results \nin a worst-case  performance  of RANDOMIZED -SELECT . \n9.2-4  \nArgue that the expected running time of R ANDOMIZED -SELECT does not depend \non the order of the elements in its input array A\u0152p  W r\ufffd. That is, the expected running \ntime is the same for any permutation of the input a rray A\u0152p  W r\ufffd. (Hint: Argue by \ninduction on the length n of the input array.) \n9.3  Selection  in worst-case  linear  time  \nWe\u2019ll  now  examine  a remarkable  and  theoretically  interesti ng selection algorithm \nwhose running time is \u201a.n/  in the worst case. Although the R ANDOMIZED - \nSELECT algorithm from Section 9.2 achieves linear expected  time, we saw that \nits running time in the worst case was quadratic. T he selection algorithm presented \nin this section achieves linear time in the worst c ase, but it is not nearly as practical \nas RANDOMIZED -SELECT . It is mostly of theoretical interest. \nLike  the  expected  linear-time  RANDOMIZED -SELECT, the  worst-case  linear-  \ntime algorithm S ELECT \u00fbnds  the  desired  element  by  recursively  partitioning  the  \ninput array. Unlike R ANDOMIZED -SELECT , however, S ELECT guarantees  a good \nsplit by choosing a provably good pivot when partit ioning the array. The cleverness \nin the  algorithm  is that  it \u00fbnds  the  pivot  recursively.  Thus,  there are two invocations \nof S ELECT: one  to \u00fbnd  a good  pivot,  and  a second  to recursively  \u00fbnd  the  desired \norder statistic. \nThe partitioning algorithm used by S ELECT is like the deterministic partitioning \nalgorithm P ARTITION  from  quicksort  (see  Section  7.1),  but  modi\u00fbed  to take  the  \nelement to partition around as an additional input parameter. Like P ARTITION , the 9.3  Selection  in worst-case  linear  time  237 \nPARTITION-AROUND  algorithm  returns  the  index  of the  pivot.  Since  it\u2019s  so simil ar \nto PARTITION , the pseudocode for P ARTITION-AROUND  is omitted. \nThe S ELECT procedure takes as input a subarray A\u0152p  W r ] of n D r \ue003 p C 1 \nelements and an integer i in the range 1 \u0dc4 i \u0dc4 n. It returns the i th smallest element \nof A. The pseudocode is actually more understandable th an it might appear  at \u00fbrst.  \nSELECT.A;p;r;i/  \n1 while  .r \ue003 p C 1/ mod 5 \u00a4 0 \n2 for  j D p C 1 to r / / put the minimum into A\u0152p\ufffd  \n3 if A\u0152p\ufffd>A\u0152j\ufffd  \n4 exchange A\u0152p\ufffd  with A\u0152j\ufffd  \n5 / / If we want the minimum of A\u0152p  W r\ufffd, we\u2019re  done.  \n6 if i == 1 \n7 return  A\u0152p\ufffd  \n8 / / Otherwise,  we  want  the  .i \ue003 1/st element of A\u0152p  C 1 W r\ufffd. \n9 p D p C 1 \n10  i D i \ue003 1 \n11  g D .r \ue003 p C 1/=5  / / number of 5-element  groups  \n12  for  j D p to p C g \ue003 1 / / sort each group \n13  sort hA\u0152j\ufffd;A\u0152j  C g\ufffd;A\u0152j  C 2g\ufffd;A\u0152j  C 3g\ufffd;A\u0152j  C 4g\ufffdi in place \n14  / / All  group  medians  now  lie  in the  middle  \u00fbfth  of A\u0152p  W r\ufffd. \n15  / / Find the pivot x recursively as the median of the group medians. \n16  x D SELECT .A;p  C 2g;p  C 3g  \ue003 1; dg=2e/ \n17  q D PARTITION-AROUND.A;p;r;x/  / / partition around the pivot \n18  / / The  rest  is just  like  lines  339  of RANDOMIZED -SELECT . \n19  k D q \ue003 p C 1 \n20 if i == k \n21  return  A\u0152q\ufffd  / / the pivot value is the answer \n22 elseif  i<k  \n23  return  SELECT.A;p;q  \ue003 1;i/  \n24  else  return  SELECT.A;q  C 1;r;i  \ue003 k/  \nThe pseudocode starts by executing the while  loop  in lines  1310  to reduce  the  \nnumber r \ue003 p C 1 of elements in the subarray until it is divisible b y 5. The while  \nloop executes 0 to 4 times, each time rearranging the elements of A\u0152p  W r\ufffd so that \nA\u0152p\ufffd  contains the minimum element. If i D 1, which means that we actually want \nthe minimum element, then the procedure simply retu rns it in line  7. Otherwise,  \nSELECT eliminates the minimum from the subarray A\u0152p  W r\ufffd and  iterates  to \u00fbnd  \nthe .i \ue003 1/st element in A\u0152p  C 1 W r\ufffd. Lines  9310  do  so by  incrementing  p and \ndecrementing i . If the while  loop completes all of its iterations without return ing a 238  Chapter  9 Medians  and  Order  Statistics  \nx \ng dg=2e bg=2c C  1 \nFigure  9.3  The relationships between elements (shown as circle s) immediately  after  line  17  of the  \nselection algorithm S ELECT . There are g D .r \ue003 p C 1/=5  groups of 5 elements,  each  of which  oc-  \ncupies a column. For example, the leftmost column c ontains elements A\u0152p\ufffd , A\u0152p  C g\ufffd, A\u0152p  C 2g\ufffd, \nA\u0152p  C 3g\ufffd, A\u0152p  C 4g\ufffd, and the next column contains A\u0152p  C 1\ufffd, A\u0152p  C g C 1\ufffd, A\u0152p  C 2g  C 1\ufffd, \nA\u0152p  C 3g  C 1\ufffd, A\u0152p  C 4g  C 1\ufffd. The medians of the groups are red, and the pivot x is labeled. \nArrows go from smaller elements to larger. The elem ents on the blue background are all known to \nbe less than or equal to x and cannot fall into the high side of the partition  around x. The elements \non the yellow background are known to be greater th an or equal to x and cannot fall into the low side \nof the partition around x. The pivot x belongs to both the blue and yellow regions and is shown on a \ngreen background. The elements on the white backgro und could lie on either side of the partition. \nresult, the procedure executes the core of the algo rithm in lines  11324,  assured  that  \nthe number r \ue003 p C 1 of elements in A\u0152p  W r\ufffd is evenly divisible by 5. \nThe next part of the algorithm implements the follo wing idea, illustrated  in Fig-  \nure  9.3.  Divide  the  elements  in A\u0152p  W r\ufffd into g D .r \ue003p C1/=5  groups of 5 elements \neach.  The  \u00fbrst  5-element  group  is \nhA\u0152p\ufffd;A\u0152p  C g\ufffd;A\u0152p  C 2g\ufffd;A\u0152p  C 3g\ufffd;A\u0152p  C 4g\ufffdi ; \nthe second is \nhA\u0152p  C 1\ufffd;A\u0152p  C g C 1\ufffd;A\u0152p  C 2g  C 1\ufffd;A\u0152p  C 3g  C 1\ufffd;A\u0152p  C 4g  C 1\ufffdi ; \nand so forth until the last, which is \nhA\u0152p  C g \ue003 1\ufffd;A\u0152p  C 2g  \ue003 1\ufffd;A\u0152p  C 3g  \ue003 1\ufffd;A\u0152p  C 4g  \ue003 1\ufffd;A\u0152r\ufffd i : \n(Note that r D p C 5g  \ue003 1.) Line  13  puts  each  group  in order  using,  for  example,  \ninsertion  sort  (Section  2.1),  so that  for  j D p;p  C 1;:::;p  C g \ue003 1, we have 9.3  Selection  in worst-case  linear  time  239 \nA\u0152j\ufffd  \u0dc4 A\u0152j  C g\ufffd \u0dc4 A\u0152j  C 2g\ufffd  \u0dc4 A\u0152j  C 3g\ufffd  \u0dc4 A\u0152j  C 4g\ufffd:  \nEach  vertical  column  in Figure  9.3  depicts  a sorted  group  of 5 elements. The \nmedian of each 5-element  group  is A\u0152j  C 2g\ufffd, and thus all the 5-element  medians,  \nshown in red, lie in the range A\u0152p  C 2g  W p C 3g  \ue003 1\ufffd. \nNext,  line  16  determines  the  pivot  x by recursively calling S ELECT to \u00fbnd  the  \nmedian  (speci\u00fbcally,  the  dg=2eth smallest) of the g group  medians.  Line  17  uses  \nthe  modi\u00fbed  PARTITION-AROUND  algorithm to partition the elements of A\u0152p  W r\ufffd \naround x , returning the index q of x , so that A\u0152q\ufffd  D x , elements in A\u0152p  W q\ufffd are all \nat most x , and elements in A\u0152q  W r\ufffd are greater than or equal to x . \nThe remainder of the code mirrors that of R ANDOMIZED -SELECT . If the pivot x \nis the i th largest,  the  procedure  returns  it. Otherwise,  the  proced ure recursively \ncalls itself on either A\u0152p  W q \ue003 1\ufffd or A\u0152q  C 1 W r\ufffd, depending on the value of i . \nLet\u2019s  analyze  the  running  time  of SELECT and see how the judicious choice of \nthe pivot x plays  into  a guarantee  on  its  worst-case  running  time.  \nTheorem  9.3  \nThe running time of S ELECT on an input of n elements is \u201a.n/ . \nProof  De\u00fbne  T.n/  as the  worst-case  time  to run  SELECT on any input subarray \nA\u0152p  W r\ufffd of size at most n, that is, for which r \ue003 p C 1 \u0dc4 n. By  this  de\u00fbnition,  T.n/  \nis monotonically increasing. \nWe  \u00fbrst  determine  an upper  bound  on  the  time  spent  outside  the  recursive calls \nin lines  16,  23,  and  24.  The  while  loop  in lines  1310  executes  0 to 4 times, \nwhich is O.1/  times. Since the dominant time within the loop is t he computa- \ntion  of the  minimum  in lines  234,  which  takes  \u201a.n/  time,  lines  1310  execute  in \nO.1/  \ue001 \u201a.n/  D O.n/  time. The sorting of the 5-element  groups  in lines  12313  \ntakes \u201a.n/  time because each 5-element  group  takes  \u201a.1/  time to sort (even using \nan asymptotically  inef\u00fbcient  sorting  algorithm  such  as insertion sort), and there are \ng elements to sort, where n=5  \ue003 1 < g  \u0dc4 n=5. Finally, the time to partition in \nline  17  is \u201a.n/, as Exercise  7.1-3  on  page  187  asks  you  to show.  Because  the  re-  \nmaining bookkeeping only costs \u201a.1/  time, the total amount of time spent outside \nof the recursive calls is O.n/  C \u201a.n/  C \u201a.n/  C \u201a.1/  D \u201a.n/ . \nNow  let\u2019s  determine  the  running  time  for  the  recursive  calls. The recursive call \nto \u00fbnd  the  pivot  in line  16  takes  T.g/  \u0dc4 T.n=5/  time, since g \u0dc4 n=5  and T.n/  \nmonotonically  increases.  Of  the  two  recursive  calls  in lines  23  and  24,  at most  \none  is executed.  But  we\u2019ll  see  that  no  matter  which  of these  two recursive calls \nto S ELECT actually executes, the number of elements in the re cursive call turns \nout to be at most 7n=10, and  hence  the  worst-case  cost  for  lines  23  and  24  is at \nmost T.7n=10/. Let\u2019s  now  show  that  the  machinations  with  group  medians  and  the \nchoice of the pivot x as the median of the group medians guarantees this property. 240  Chapter  9 Medians  and  Order  Statistics  \nFigure  9.3  helps  to visualize  what\u2019s  going  on.  There  are  g \u0dc4 n=5  groups of 5 el-  \nements, with each group shown as a column sorted fr om bottom to top. The arrows \nshow the ordering of elements within the columns. T he columns are ordered from \nleft to right with groups to the left of x \u2019s group  having  a group  median  less  than  x \nand those to the right of x \u2019s group  having  a group  median  greater  than  x . Although \nthe relative order within each group matters, the r elative order among groups to the \nleft of x \u2019s column  doesn\u2019t  really  matter,  and  neither  does  the  relati ve order among \ngroups to the right of x \u2019s column.  The  important  thing  is that  the  groups  to the  \nleft have group medians less than x (shown by the horizontal arrows entering x ), \nand that the groups to the right have group medians  greater than x (shown by the \nhorizontal arrows leaving x ). Thus, the yellow region contains elements that w e \nknow are greater than or equal to x , and the blue region contains elements that we \nknow are less than or equal to x . \nThese two regions each contain at least 3g=2  elements. The number of group \nmedians in the yellow region is bg=2c C  1, and  for  each  group  median,  two  ad-  \nditional elements are greater than it, making a tot al of 3.bg=2c C  1/ \ue004 3g=2  \nelements. Similarly, the number of group medians in  the blue region is dg=2e, and \nfor each group median, two additional elements are less than it, making a total of \n3 dg=2e \ue004  3g=2 . \nThe elements in the yellow region cannot fall into the low side of the partition \naround x , and those in the blue region cannot fall into the  high side. The elements \nin neither  region4those  lying  on  a white  background4could  fall into either side \nof the partition. But since the low side of the par tition excludes the elements in the \nyellow region, and there are a total of 5g  elements, we know that the low side of \nthe partition can contain at most 5g  \ue003 3g=2  D 7g=2  \u0dc4 7n=10  elements. Likewise, \nthe high side of the partition excludes the element s in the blue region, and a similar \ncalculation shows that it also contains at most 7n=10  elements. \nAll  of which  leads  to the  following  recurrence  for  the  worst- case running time \nof S ELECT : \nT.n/  \u0dc4 T.n=5/  C T.7n=10/  C \u201a.n/:  (9.1)  \nWe can show that T.n/  D O.n/  by substitution. 2 More  speci\u00fbcally,  we\u2019ll  prove  \nthat T.n/  \u0dc4 cn  for some suitably large constant c>0  and all n>0 . Substituting \nthis  inductive  hypothesis  into  the  right-hand  side  of recurrence  (9.1)  and  assuming  \nthat n \ue004 5 yields \n2 We  could  also  use  the  Akra-Bazzi  method  from  Section  4.7,  which involves calculus, to solve this \nrecurrence.  Indeed,  a similar  recurrence  (4.24)  on  page  117  was used to illustrate that method. 9.3  Selection  in worst-case  linear  time  241 \nT.n/  \u0dc4 c.n=5/  C c.7n=10/  C \u201a.n/  \n\u0dc4 9cn=10  C \u201a.n/  \nD cn  \ue003 cn=10  C \u201a.n/  \n\u0dc4 cn  \nif c is chosen large enough that c=10  dominates  the  upper-bound  constant  hidden  by  \nthe \u201a.n/ . In addition to this constraint, we can pick c large enough that T.n/  \u0dc4 cn  \nfor all n \u0dc4 4, which is the base case of the recursion within S ELECT . The running \ntime of S ELECT is therefore O.n/  in the  worst  case,  and  because  line  13  alone  \ntakes \u201a.n/  time, the total time is \u201a.n/ . \nAs  in a comparison  sort  (see  Section  8.1),  SELECT and RANDOMIZED -SELECT \ndetermine information about the relative order of e lements only  by  comparing  ele-  \nments.  Recall  from  Chapter  8 that  sorting  requires  \ufffd.n  lg n/ time  in the  compari-  \nson  model,  even  on  average  (see  Problem  8-1).  The  linear-tim e sorting algorithms \nin Chapter  8 make  assumptions  about  the  type  of the  input.  In contrast,  the  linear-  \ntime selection algorithms in this chapter do not re quire any assumptions about the \ninput\u2019s  type,  only  that  the  elements  are  distinct  and  can  be pairwise  compared  ac-  \ncording to a linear order. The algorithms in this c hapter are not subject to the \n\ufffd.n  lg n/ lower bound, because they manage to solve the selec tion problem  with-  \nout sorting all the elements. Thus, solving the sel ection problem by sorting and \nindexing, as presented in the introduction to this chapter, is asymptotically  inef\u00fb-  \ncient in the comparison model. \nExercises  \n9.3-1  \nIn the algorithm S ELECT , the input elements are divided into groups of 5. Show \nthat the algorithm works in linear time if the inpu t elements are divided into groups \nof 7 instead of 5. \n9.3-2  \nSuppose  that  the  preprocessing  in lines  1310  of SELECT is replaced by a base case \nfor n \ue004 n 0 , where n 0 is a suitable constant; that g is chosen as br \ue003 p C 1/=5c; \nand that the elements in A\u01525g  W n\ufffd belong to no group. Show that although the \nrecurrence for the running time becomes messier, it  still solves to \u201a.n/ . \n9.3-3  \nShow how to use S ELECT as a subroutine to make quicksort run in O.n  lg n/ time \nin the worst case, assuming that all elements are d istinct. 242  Chapter  9 Medians  and  Order  Statistics  \nFigure  9.4  Professor  Olay  needs  to determine  the  position  of the  east-west  oil  pipeline  that  mini-  \nmizes  the  total  length  of the  north-south  spurs.  \n? 9.3-4  \nSuppose  that  an algorithm  uses  only  comparisons  to \u00fbnd  the  i th smallest element \nin a set of n elements.  Show  that  it can  also  \u00fbnd  the  i \ue003 1 smaller elements and \nthe n \ue003 i larger elements without performing any additional c omparisons. \n9.3-5  \nShow how to determine the median of a 5-element  set  using  only  6 comparisons. \n9.3-6  \nYou  have  a <black-box=  worst-case  linear-time  median  subroutine.  Give  a sim-  \nple,  linear-time  algorithm  that  solves  the  selection  probl em for an arbitrary order \nstatistic. \n9.3-7  \nProfessor  Olay  is consulting  for  an oil  company,  which  is planning a large pipeline \nrunning  east  to west  through  an oil  \u00fbeld  of n wells. The company wants to connect \na spur pipeline from each well directly to the main  pipeline along a shortest route \n(either  north  or south),  as shown  in Figure  9.4.  Given  the  x - and  y -coordinates  of \nthe wells, how should the professor pick an optimal  location of the main pipeline to \nminimize  the  total  length  of the  spurs?  Show  how  to determine  an optimal location \nin linear time. \n9.3-8  \nThe kth quantiles  of an n-element  set  are  the  k \ue003 1 order statistics that divide the \nsorted set into k equal-sized  sets  (to  within  1). Give  an O.n  lg k/-time  algorithm  \nto list the kth quantiles of a set. Problems for Chapter 9 243 \n9.3-9  \nDescribe an O.n/-time  algorithm  that,  given  a set  S of n distinct numbers and \na positive integer k \u0dc4 n, determines the k numbers in S that are closest to the \nmedian of S . \n9.3-10  \nLet X\u01521  W n\ufffd and Y\u01521  W n\ufffd be two arrays, each containing n numbers already in sorted \norder.  Give  an O.lg n/-time  algorithm  to \u00fbnd  the  median  of all  2n  elements in \narrays X and Y . Assume that all 2n  numbers are distinct. \nProblems  \n9-1  Largest  i numbers  in sorted  order  \nYou are given a set of n numbers,  and  you  wish  to \u00fbnd  the  i largest in sorted order \nusing  a comparison-based  algorithm.  Describe  the  algorith m that implements each \nof the  following  methods  with  the  best  asymptotic  worst-cas e running time, and \nanalyze the running times of the algorithms in term s of n and i . \na. Sort the numbers, and list the i largest. \nb. Build  a max-priority  queue  from  the  numbers,  and  call  EXTRACT-MAX i times. \nc. Use  an order-statistic  algorithm  to \u00fbnd  the  i th largest number, partition around \nthat number, and sort the i largest numbers. \n9-2  Variant  of randomized  selection  \nProfessor Mendel has proposed simplifying R ANDOMIZED -SELECT by  eliminat-  \ning the check for whether i and k are  equal.  The  simpli\u00fbed  procedure  is SIMPLER- \nRANDOMIZED -SELECT . \nSIMPLER-RANDOMIZED -SELECT .A;p;r;i/  \n1 if p == r \n2 return  A\u0152p\ufffd  / / 1 \u0dc4 i \u0dc4 r \ue003 p C 1 means that i D 1 \n3 q D RANDOMIZED -PARTITION  .A;p;r/  \n4 k D q \ue003 p C 1 \n5 if i \u0dc4 k \n6 return  SIMPLER-RANDOMIZED -SELECT .A;p;q;i/  \n7 else  return  SIMPLER-RANDOMIZED -SELECT .A;q  C 1;r;i  \ue003 k/  244  Chapter  9 Medians  and  Order  Statistics  \na. Argue that in the worst case, S IMPLER-RANDOMIZED -SELECT never  termi-  \nnates. \nb. Prove that the expected running time of S IMPLER-RANDOMIZED -SELECT is \nstill O.n/ . \n9-3  Weighted  median  \nConsider n elements x 1 ;x  2 ;:::;x  n with positive weights w 1 ;w  2 ;:::;w  n such that P  n \ni D1 w i D 1. The weighted  (lower)  median  is an element x k satisfying \nX  \nx i <x  k w i < 1 \n2 \nand \nX  \nx i >x  k w i \u0dc4 1 \n2 : \nFor example, consider the following elements x i and weights w i : \ni 1 2 3 4 5 6 7 \nx i 3 8 2 5 4 1 6 \nw i 0:12  0:35  0:025  0:08  0:15  0:075  0:2  \nFor these elements, the median is x 5 D 4, but the weighted median is x 7 D 6. To \nsee why the weighted median is x 7 , observe that the elements less than x 7 are x 1 , \nx 3 , x 4 , x 5 , and x 6 , and the sum w 1 C w 3 C w 4 C w 5 C w 6 D 0:45, which is less \nthan 1=2. Furthermore, only element x 2 is greater than x 7 , and w 2 D 0:35, which \nis no greater than 1=2. \na. Argue that the median of x 1 ;x  2 ;:::;x  n is the weighted median of the x i with \nweights w i D 1=n  for i D 1;2;:::;n . \nb. Show how to compute the weighted median of n elements in O.n  lg n/ worst-  \ncase time using sorting. \nc. Show how to compute the weighted median in \u201a.n/  worst-case  time  using  a \nlinear-time  median  algorithm  such  as SELECT from  Section  9.3.  \nThe post-of\u00fbce  location  problem  is de\u00fbned  as follows.  The  input  is n points \np 1 ;p  2 ;:::;p  n with associated weights w 1 ;w  2 ;:::;w  n . A solution is a point p \n(not necessarily one of the input points) that mini mizes the sum P  n \ni D1 w i d.p;p  i /, \nwhere d.a;b/  is the distance between points a and b. Problems for Chapter 9 245 \nd. Argue  that  the  weighted  median  is a best  solution  for  the  one-dimensional  post-  \nof\u00fbce  location  problem,  in which  points  are  simply  real  numbers  and  the  dis-  \ntance between points a and b is d.a;b/  D ja \ue003 bj. \ne. Find  the  best  solution  for  the  two-dimensional  post-of\u00fbce  location problem, in \nwhich the points are .x;y/  coordinate pairs and the distance between points \na D .x 1 ;y  1 / and b D .x 2 ;y  2 / is the Manhattan  distance  given by d.a;b/  D \njx 1 \ue003 x 2 j C jy 1 \ue003 y 2 j. \n9-4  Small  order  statistics  \nLet\u2019s  denote  by  S.n/  the  worst-case  number  of comparisons  used  by  SELECT to \nselect the i th order statistic from n numbers. Although S.n/  D \u201a.n/ , the constant \nhidden by the \u201a-notation  is rather  large.  When  i is small relative to n, there is an \nalgorithm that uses S ELECT as a subroutine but makes fewer comparisons in the \nworst case. \na. Describe an algorithm that uses U i .n/  comparisons  to \u00fbnd  the  i th smallest of n \nelements, where \nU i .n/  D ( \nS.n/  if i \ue004 n=2;  \nbn=2c C  U i .dn=2e/ C S.2i/  otherwise : \n(Hint: Begin with bn=2c disjoint pairwise comparisons, and recurse on the s et \ncontaining the smaller element from each pair.) \nb. Show that, if i<n=2 , then U i .n/  D n C O.S.2i/  lg.n=i// . \nc. Show that if i is a constant less than n=2, then U i .n/  D n C O.lg n/. \nd. Show that if i D n=k  for k \ue004 2, then U i .n/  D n C O.S.2n=k/  lg k/. \n9-5  Alternative  analysis  of randomized  selection  \nIn this problem, you will use indicator random vari ables to analyze  the  proce-  \ndure RANDOMIZED -SELECT in a manner akin to our analysis of R ANDOMIZED - \nQUICKSORT  in Section  7.4.2.  \nAs in the quicksort analysis, we assume that all el ements are distinct, and we \nrename the elements of the input array A as \u00b4 1 ;\u00b4  2 ;:::;\u00b4  n , where \u00b4 i is the i th \nsmallest element. Thus the call R ANDOMIZED -SELECT .A;1;n;i/  returns \u00b4 i . \nFor 1 \u0dc4 j <k  \u0dc4 n, let \nX ij k D I f \u00b4 j is compared with \u00b4 k sometime during the execution of the algorithm \nto \u00fbnd  \u00b4 i g : 246  Chapter  9 Medians  and  Order  Statistics  \na. Give  an exact  expression  for  E \u0152X  ij k \ufffd. (Hint: Your  expression  may  have  differ-  \nent values, depending on the values of i , j , and k.) \nb. Let X i denote the total number of comparisons between elem ents of array A \nwhen  \u00fbnding  \u00b4 i . Show that \nE \u0152X  i \ufffd \u0dc4 2 \ue001 i X  \nj D1 n X  \nkDi 1 \nk \ue003 j C 1 C n X  \nkDi C1 k \ue003 i \ue003 1 \nk \ue003 i C 1 C i \ue0022 X  \nj D1 i \ue003 j \ue003 1 \ni \ue003 j C 1 ! \n: \nc. Show that E \u0152X  i \ufffd \u0dc4 4n. \nd. Conclude that, assuming all elements of array A are distinct, R ANDOMIZED - \nSELECT runs in O.n/  expected time. \n9-6  Select  with  groups  of 3 \nExercise  9.3-1  asks  you  to show  that  the  SELECT algorithm still runs in linear time \nif the elements are divided into groups of 7. This problem asks about dividing into \ngroups of 3. \na. Show that S ELECT runs in linear time if you divide the elements into  groups \nwhose size is any odd constant greater than 3. \nb. Show that S ELECT runs in O.n  lg n/ time if you divide the elements into groups \nof size 3. \nBecause the bound in part (b) is just an upper boun d, we do not know whether \nthe  groups-of-3 strategy actually runs in O.n/  time.  But  by  repeating  the  groups-  \nof-3 idea on the middle group of medians, we can pick a pivot that guarantees O.n/  \ntime. The S ELECT3 algorithm  on  the  next  page  determines  the  i th smallest of an \ninput array of n>1  distinct elements. \nc. Describe in English how the S ELECT3 algorithm  works.  Include  in your  de-  \nscription one or more suitable diagrams. \nd. Show that S ELECT3 runs  in O.n/  time in the worst case. \nChapter  notes  \nThe  worst-case  linear-time  median-\u00fbnding  algorithm  was  devised by Blum, Floyd, \nPratt,  Rivest,  and  Tarjan  [62].  The  fast  randomized  version  is due  to Hoare  [218].  \nFloyd  and  Rivest  [147]  have  developed  an improved  randomized  version  that  parti-  \ntions around an element recursively selected from a  small sample of the elements. Notes for Chapter 9 247 \nSELECT3 .A;p;r;i/  \n1 while  .r \ue003 p C 1/ mod 9 \u00a4 0 \n2 for  j D p C 1 to r / / put the minimum into A\u0152p\ufffd  \n3 if A\u0152p\ufffd>A\u0152j\ufffd  \n4 exchange A\u0152p\ufffd  with A\u0152j\ufffd  \n5 / / If we want the minimum of A\u0152p  W r\ufffd, we\u2019re  done.  \n6 if i == 1 \n7 return  A\u0152p\ufffd  \n8 / / Otherwise,  we  want  the  .i \ue003 1/st element of A\u0152p  C 1 W r\ufffd. \n9 p D p C 1 \n10  i D i \ue003 1 \n11  g D .r \ue003 p C 1/=3  / / number of 3-element  groups  \n12  for  j D p to p C g \ue003 1 / / run through the groups \n13  sort hA\u0152j\ufffd;A\u0152j  C g\ufffd;A\u0152j  C 2g\ufffdi in place \n14  / / All group medians now lie in the middle third of A\u0152p  W r\ufffd. \n15  g 0 D g=3  / / number of 3-element  subgroups  \n16  for  j D p C g to p C g C g 0 \ue003 1 / / sort the subgroups \n17  sort hA\u0152j\ufffd;A\u0152j  C g 0 \ufffd; A\u0152j  C 2g  0 \ufffdi in place \n18  / / All subgroup medians now lie in the middle ninth of  A\u0152p  W r\ufffd. \n19  / / Find the pivot x recursively as the median of the subgroup medians. \n20 x D SELECT3 .A;p  C 4g  0 ;p  C 5g  0 \ue003 1; dg 0 =2e/ \n21  q D PARTITION-AROUND.A;p;r;x/  / / partition around the pivot \n22 / / The  rest  is just  like  lines  19324  of SELECT . \n23  k D q \ue003 p C 1 \n24  if i == k \n25  return  A\u0152q\ufffd  / / the pivot value is the answer \n26  elseif  i<k  \n27  return  SELECT3 .A;p;q  \ue003 1;i/  \n28  else  return  SELECT3 .A;q  C 1;r;i  \ue003 k/  \nIt is still unknown exactly how many comparisons ar e needed to determine the \nmedian.  Bent  and  John  [48]  gave  a lower  bound  of 2n  comparisons for median \n\u00fbnding,  and  Sch\u00a8  onhage,  Paterson,  and  Pippenger  [397]  gave  an upper bound of 3n. \nDor and Zwick have improved on both of these bounds . Their upper bound  [123]  \nis slightly less than 2:95n, and  their  lower  bound  [124]  is .2 C \ufffd/n, for a small \npositive constant \ufffd , thereby  improving  slightly  on  related  work  by  Dor  et al.  [122]. \nPaterson  [354]  describes  some  of these  results  along  with  other related work. \nProblem  9-6  was  inspired  by  a paper  by  Chen  and  Dumitrescu  [84]. Part  III  Data  Structures  Introduction  \nSets are as fundamental to computer science as they  are to mathematics. Whereas \nmathematical sets are unchanging, the sets manipula ted by algorithms can grow, \nshrink, or otherwise change over time. We call such  sets dynamic . The next four \nchapters  present  some  basic  techniques  for  representing  \u00fbnite dynamic sets and \nmanipulating them on a computer. \nAlgorithms may require several types of operations to be performed on sets. For \nexample, many algorithms need only the ability to i nsert elements  into,  delete  el-  \nements from, and test membership in a set. We call a dynamic set that supports \nthese operations a dictionary. Other  algorithms  require  more  complicated  opera-  \ntions.  For  example,  min-priority  queues,  which  Chapter  6 introduced in the context \nof the heap data structure, support the operations of inserting an element into and \nextracting the smallest element from a set. The bes t way to implement a dynamic \nset depends upon the operations that you need to su pport. \nElements  of a dynamic  set  \nIn a typical implementation of a dynamic set, each element is represented by an \nobject whose attributes can be examined and manipul ated given a pointer to the \nobject. Some kinds of dynamic sets assume that one of the object\u2019s  attributes  is \nan identifying key. If the keys are all different, we can think of th e dynamic set as \nbeing a set of key values. The object may contain satellite  data, which are carried \naround in other object attributes but are otherwise  unused by the  set  implementa-  \ntion. It may also have attributes that are manipula ted by the set operations. These \nattributes may contain data or pointers to other ob jects in the set. \nSome dynamic sets presuppose that the keys are draw n from a totally ordered \nset, such as the real numbers, or the set of all wo rds under the usual alphabetic 250  Part  III  Data  Structures  \nordering.  A total  ordering  allows  us to de\u00fbne  the  minimum  element of the set, for \nexample, or to speak of the next element larger tha n a given element in a set. \nOperations  on  dynamic  sets  \nOperations  on  a dynamic  set  can  be grouped  into  two  categorie s: queries , which \nsimply return information about the set, and modifying  operations , which change \nthe  set.  Here  is a list  of typical  operations.  Any  speci\u00fbc  application will usually \nrequire only a few of these to be implemented. \nSEARCH.S;k/  \nA query that, given a set S and a key value k, returns a pointer x to an element \nin S such that x: key  D k, or NIL if no such element belongs to S . \nI NSERT.S;x/  \nA modifying operation that adds the element pointed  to by x to the set S . We \nusually assume that any attributes in element x needed  by  the  set  implementa-  \ntion have already been initialized. \nDELETE .S;x/  \nA modifying operation that, given a pointer x to an element in the set S , re-  \nmoves x from S . (Note that this operation takes a pointer to an e lement x , not \na key value.) \nMINIMUM.S/  and M AXIMUM.S/  \nQueries  on  a totally  ordered  set  S that return a pointer to the element of S with \nthe smallest (for M INIMUM ) or largest (for M AXIMUM ) key. \nSUCCESSOR.S;x/  \nA query that, given an element x whose key is from a totally ordered set S , \nreturns a pointer to the next larger element in S , or NIL if x is the maximum \nelement. \nPREDECESSOR  .S;x/  \nA query that, given an element x whose key is from a totally ordered set S , \nreturns a pointer to the next smaller element in S , or NIL if x is the minimum \nelement. \nIn some situations, we can extend the queries S UCCESSOR  and PREDECESSOR  \nso that they apply to sets with nondistinct keys. F or a set on n keys, the normal \npresumption is that a call to M INIMUM followed by n \ue003 1 calls to SUCCESSOR  \nenumerates the elements in the set in sorted order.  \nWe usually measure the time taken to execute a set operation in terms of the size \nof the  set.  For  example,  Chapter  13  describes  a data  structur e that can support any \nof the operations listed above on a set of size n in O.lg n/ time. Part  III  Data  Structures  251 \nOf  course,  you  can  always  choose  to implement  a dynamic  set  with an array. \nThe advantage of doing so is that the algorithms fo r the dynam ic-set  operations  \nare simple. The downside, however, is that many of these operations  have  a worst-  \ncase running time of \u201a.n/ . If the array is not sorted, I NSERT and D ELETE can \ntake \u201a.1/  time, but the remaining operations take \u201a.n/  time.  If instead  the  ar-  \nray is maintained in sorted order, then M INIMUM , M AXIMUM , SUCCESSOR , and \nPREDECESSOR  take \u201a.1/  time; S EARCH takes O.lg n/ time if implemented with \nbinary search; but I NSERT and D ELETE take \u201a.n/  time in the worst case. The data \nstructures studied in this part improve on the arra y implementation for many of the \ndynamic-set  operations.  \nOverview  of Part  III  \nChapters  10313  describe  several  data  structures  that  we  can  use  to implement  dy-  \nnamic  sets.  We\u2019ll  use  many  of these  data  structures  later  to construct  ef\u00fbcient  algo-  \nrithms for a variety of problems. We already saw an other important data structure \n4the  heap4in  Chapter  6. \nChapter  10  presents  the  essentials  of working  with  simple  data structures such \nas arrays, matrices, stacks, queues, linked lists, and rooted trees. If you have taken \nan introductory programming course, then much of th is material should be familiar \nto you. \nChapter  11  introduces  hash  tables,  a widely  used  data  struct ure supporting the \ndictionary operations I NSERT , DELETE , and S EARCH. In the  worst  case,  hash  ta-  \nbles require \u201a.n/  time to perform a S EARCH operation, but the expected time for \nhash-table  operations  is O.1/. We  rely  on  probability  to analyze  hash-table  opera-  \ntions, but you can understand how the operations wo rk even without probability. \nBinary  search  trees,  which  are  covered  in Chapter  12,  support  all  the  dynamic-  \nset operations listed above. In the worst case, eac h operation takes \u201a.n/  time on \na tree with n elements. Binary search trees serve as the basis fo r many other data \nstructures. \nChapter  13  introduces  red-black  trees,  which  are  a variant  of binary search trees. \nUnlike  ordinary  binary  search  trees,  red-black  trees  are  guaranteed to perform well: \noperations take O.lg n/ time  in the  worst  case.  A red-black  tree  is a balanced  search  \ntree.  Chapter  18  in Part  V presents  another  kind  of balanced  search tree, called a \nB-tree.  Although  the  mechanics  of red-black  trees  are  somew hat intricate, you can \nglean most of their properties from the chapter wit hout studying the mechanics \nin detail.  Nevertheless,  you  probably  will  \u00fbnd  walking  through the code to be \ninstructive. 10  Elementary  Data  Structures  \nIn this chapter, we examine the representation of d ynamic sets by  simple  data  struc-  \ntures that use pointers. Although you can construct  many complex data structures \nusing pointers, we present only the rudimentary one s: arrays, matrices, stacks, \nqueues, linked lists, and rooted trees. \n10.1  Simple  array-based  data  structures:  arrays,  matrices,  stacks,  queues  \n10.1.1  Arrays  \nWe assume that, as in most programming languages, a n array is stored  as a con-  \ntiguous  sequence  of bytes  in memory.  If the  \u00fbrst  element  of an array has index s \n(for example, in an array with 1-origin  indexing,  s D 1), the array starts at memory \naddress a, and each array element occupies b bytes, then the i th element occupies \nbytes a C b.i  \ue003 s/ through a C b.i  \ue003 s C 1/ \ue003 1. Since most of the arrays in this book \nare indexed starting at 1, and a few starting at 0, we can simplify these formulas a \nlittle. When s D 1, the i th element occupies bytes a C b.i  \ue003 1/ through a C bi \ue003 1, \nand when s D 0, the i th element occupies bytes a C bi through a C b.i  C 1/ \ue003 1. \nAssuming that the computer can access all memory lo cations in the same amount \nof time (as in the RAM model described in Section 2 .2), it takes constant time to \naccess any array element, regardless of the index. \nMost programming languages require each element of a particular array to be \nthe same size. If the elements of a given array mig ht occupy different numbers \nof bytes, then the above formulas fail to apply, si nce the element size b is not a \nconstant. In such cases, the array elements are usu ally objects of varying sizes, \nand what actually appears in each array element is a pointer to the object. The \nnumber of bytes occupied by a pointer is typically the same, no matter what the \npointer references, so that to access an object in an array, the above formulas give \nthe address of the pointer to the object and then t he pointer must be followed to \naccess the object itself. 10.1  Simple  array-based  data  structures:  arrays,  matrices,  stacks,  queues  253  \n1 2 3 4 5 6 \n(a) 1 4 2 5 3 6 \n(b) 1 2 3 \n4 5 6 \n(c) 2 5 \n3 6 1 4 \n(d) \nFigure  10.1  Four ways to store the 2 \ue005 3 matrix M  from  equation  (10.1).  (a)  In row-major  order,  \nin a single array. (b)  In column-major  order,  in a single  array.  (c)  In row-major  order,  with  one  array  \nper row (tan) and a single array (blue) of pointers  to the row arrays. (d)  In column-major  order,  with  \none array per column (tan) and a single array (blue ) of pointers to the column arrays. \n10.1.2  Matrices  \nWe  typically  represent  a matrix  or two-dimensional  array  by  one  or more  one-  \ndimensional arrays. The two most common ways to sto re a matrix are  row-major  \nand  column-major  order.  Let\u2019s  consider  an m\ue005n matrix4a  matrix  with  m rows and \nn columns. In row-major  order , the matrix is stored row by row, and in column-  \nmajor  order , the matrix is stored column by column. For exampl e, consider the \n2 \ue005 3 matrix \nM  D \u00cf 1 2 3  \n4 5 6  \u00d0 \n: (10.1)  \nRow-major  order  stores  the  two  rows  1 2 3  and 4 5 6, whereas  column-major  \norder stores the three columns 1 4; 2 5; and 3 6. \nParts  (a)  and  (b)  of Figure  10.1  show  how  to store  this  matrix  using a single \none-dimensional  array.  It\u2019s  stored  in row-major  order  in part  (a)  and  in column-  \nmajor order in part (b). If the rows, columns, and the single array all are indexed \nstarting at s , then M\u0152i;j\ufffd4the  element  in row  i and column j 4is  at array  in-  \ndex s C .n.i  \ue003 s//  C .j \ue003 s/ with  row-major  order  and  s C .m.j  \ue003 s//  C .i \ue003 s/ \nwith  column-major  order.  When  s D 1, the  single-array  indices  are  n.i  \ue003 1/ C j \nwith  row-major  order  and  i C m.j  \ue003 1/ with  column-major  order.  When  s D 0, \nthe  single-array  indices  are  simpler:  ni C j with  row-major  order  and  i C mj  \nwith  column-major  order.  For  the  example  matrix  M  with 1-origin  indexing,  ele-  \nment M\u01522;1\ufffd  is stored at index 3.2  \ue0031/ C1 D 4 in the  single  array  using  row-major  \norder and at index 2 C 2.1  \ue003 1/ D 2 using  column-major  order.  \nParts  (c)  and  (d)  of Figure  10.1  show  multiple-array  strateg ies for storing the \nexample matrix. In part (c), each row is stored in its own array of length n, shown \nin tan. Another array, with m elements, shown in blue, points to the m row arrays. \nIf we call the blue array A, then A\u0152i\ufffd  points to the array storing the entries for row i \nof M  , and array element A\u0152i\ufffd\u0152j\ufffd  stores matrix element M\u0152i;j\ufffd . Part (d) shows the \ncolumn-major  version  of the  multiple-array  representatio n, with n arrays, each of 254  Chapter  10  Elementary  Data  Structures  \nlength m, representing the n columns. Matrix element M\u0152i;j\ufffd  is stored in array \nelement A\u0152j\ufffd\u0152i\ufffd . \nSingle-array  representations  are  typically  more  ef\u00fbcient  on modern machines \nthan  multiple-array  representations.  But  multiple-array  representations  can  some-  \ntimes  be more  \u00fcexible,  for  example,  allowing  for  <ragged  arrays,= in which the \nrows  in the  row-major  version  may  have  different  lengths,  or symmetrically for the \ncolumn-major  version,  where  columns  may  have  different  lengths. \nOccasionally,  other  schemes  are  used  to store  matrices.  In the block  representa-  \ntion, the matrix is divided into blocks, and each block  is stored contiguously. For \nexample, a 4 \ue005 4 matrix that is divided into 2 \ue005 2 blocks, such as \ue001 1 2  3 4  \n5 6  7 8  \n9 10  11  12  \n13  14  15  16  \u02d8 \nmight be stored in a single array in the order h1;2;5;6;3;4;7;8;9;10;13;14;11;  \n12;15;16 i. \n10.1.3  Stacks  and  queues  \nStacks and queues are dynamic sets in which the ele ment removed from the set \nby the D ELETE operation  is prespeci\u00fbed.  In a stack , the element deleted from \nthe set is the one most recently inserted: the stac k implements a last-in,  \u00fbrst-out , \nor LIFO , policy. Similarly, in a queue , the element deleted is always the one that \nhas been in the set for the longest time: the queue  implements a \u00fbrst-in,  \u00fbrst-out , \nor FIFO, policy.  There  are  several  ef\u00fbcient  ways  to implement  stack s and queues \non a computer. Here, you will see how to use an arr ay with attributes to store them. \nStacks  \nThe I NSERT operation on a stack is often called P USH, and the D ELETE opera-  \ntion, which does not take an element argument, is o ften called P OP. These names \nare  allusions  to physical  stacks,  such  as the  spring-loaded  stacks of plates used \nin cafeterias. The order in which plates are popped  from the stack is the reverse \nof the order in which they were pushed onto the sta ck, since only the top plate is \naccessible. \nFigure  10.2  shows  how  to implement  a stack  of at most  n elements with an \narray S\u01521  W n\ufffd. The stack has attributes S: top, indexing the most recently inserted \nelement, and S: size, equaling the size n of the array. The stack consists of elements \nS\u01521  W S: top\ufffd, where S\u01521\ufffd  is the element at the bottom of the stack and S\u0152S:  top\ufffd is \nthe element at the top. 10.1  Simple  array-based  data  structures:  arrays,  matrices,  stacks,  queues  255  \n1 2 3 4 5 6 7 \nS 15  6 2 9 1 2 3 4 5 6 7 \nS 15  6 2 9 17  3 1 2 3 4 5 6 7 \nS 15  6 2 9 17  3 \n(a) (b) (c) S: top D 4 S: top D 6 S: top D 5 \nFigure  10.2  An array implementation of a stack S . Stack elements appear only in the tan positions. \n(a)  Stack S has 4 elements. The top element is 9. (b)  Stack S after the calls P USH.S;17/  and \nPUSH.S;3/ . (c)  Stack S after the call P OP.S/  has returned the element 3, which is the one most \nrecently pushed. Although element 3 still appears in the array, it is no longer in the stack. The top is \nelement 17. \nWhen S: top D 0, the stack contains no elements and is empty . We can test \nwhether the stack is empty with the query operation  STAC  K-EMPTY . Upon an \nattempt to pop an empty stack, the stack under\u00fcows , which is normally an error. If \nS: top exceeds S: size, the stack over\u00fcows . \nThe procedures S TAC  K-EMPTY , PUSH, and POP  implement each of the stack \noperations  with  just  a few  lines  of code.  Figure  10.2  shows  the effects of the \nmodifying operations P USH and POP. Each of the three stack operations takes \nO.1/  time. \nSTAC  K-EMPTY .S/  \n1 if S: top = = 0 \n2 return  TRUE \n3 else  return  FALSE \nPUSH.S;x/  \n1 if S: top = = S: size  \n2 error  <over\u00fcow=  \n3 else  S: top D S: top C 1 \n4 S\u0152S:  top\ufffd D x \nPOP.S/  \n1 if STAC  K-EMPTY .S/  \n2 error  <under\u00fcow=  \n3 else  S: top D S: top \ue003 1 \n4 return  S\u0152S:  top C 1\ufffd 256  Chapter  10  Elementary  Data  Structures  \n1 2 3 4 5 6 7 8 9 10  11  12  \nQ (a)  15  6 9 8 4 \n1 2 3 4 5 6 7 8 9 10  11  12  \nQ (b)  15  6 9 8 4 3 5 17  \n1 2 3 4 5 6 7 8 9 10  11  12  \nQ (c)  15  6 9 8 4 3 5 17  Q:  head D 7 Q:  head D 7 Q:  tail D 12  \nQ:  tail D 3 Q:  tail D 3 \nQ:  head D 8 \nFigure  10.3  A queue implemented using an array Q\u01521  W 12\ufffd. Queue  elements  appear  only  in the  tan  \npositions. (a)  The queue has 5 elements, in locations Q\u01527  W 11\ufffd. (b)  The  con\u00fbguration  of the  queue  \nafter the calls E NQUEUE.Q;17/ , ENQUEUE.Q;3/ , and ENQUEUE.Q;5/ . (c)  The  con\u00fbguration  of \nthe queue after the call D EQUEUE.Q/  returns the key value 15  formerly at the head of the queue. \nThe new head has key 6. \nQueues  \nWe call the I NSERT operation on a queue E NQUEUE , and we call the D ELETE \noperation D EQUEUE . Like the stack operation P OP, DEQUEUE  takes no element \nargument.  The  FIFO  property  of a queue  causes  it to operate  like  a line  of cus-  \ntomers waiting for service. The queue has a head  and a tail. When an element is \nenqueued, it takes its place at the tail of the que ue, just as a newly  arriving  cus-  \ntomer takes a place at the end of the line. The ele ment dequeued is always the one \nat the head of the queue, like the customer at the head of the line, who has waited \nthe longest. \nFigure  10.3  shows  one  way  to implement  a queue  of at most  n \ue003 1 elements \nusing an array Q\u01521  W n\ufffd, with the attribute Q:  size  equaling the size n of the array. \nThe queue has an attribute Q:  head that indexes, or points to, its head. The attribute  \nQ:  tail indexes the next location at which a newly arriving  element will be inserted \ninto the queue. The elements in the queue reside in  locations Q:  head ;Q:  head C 1; \n:::;Q:  tail \ue003 1, where we <wrap around= in the sense that location  1 immediately \nfollows location n in a circular order. When Q:  head D Q:  tail, the queue is empty. \nInitially, we have Q:  head D Q:  tail D 1. An attempt to dequeue an element from \nan empty  queue  causes  the  queue  to under\u00fcow.  When  Q:  head D Q:  tail C1 or both 10.1  Simple  array-based  data  structures:  arrays,  matrices,  stacks,  queues  257  \nQ:  head D 1 and Q:  tail D Q:  size, the queue is full, and an attempt to enqueue an \nelement  causes  the  queue  to over\u00fcow.  \nIn the procedures E NQUEUE  and DEQUEUE , we have omitted the error checking \nfor  under\u00fcow  and  over\u00fcow.  (Exercise  10.1-5  asks  you  to suppl y these checks.) \nFigure  10.3  shows  the  effects  of the  ENQUEUE  and DEQUEUE  operations. Each \noperation takes O.1/  time. \nENQUEUE.Q;x/  \n1 Q\u0152Q:  tail\ufffd D x \n2 if Q:  tail == Q:  size  \n3 Q:  tail D 1 \n4 else  Q:  tail D Q:  tail C 1 \nDEQUEUE.Q/  \n1 x D Q\u0152Q:  head \ufffd \n2 if Q:  head == Q:  size  \n3 Q:  head D 1 \n4 else  Q:  head D Q:  head C 1 \n5 return  x \nExercises  \n10.1-1  \nConsider an m \ue005 n matrix  in row-major  order,  where  both  m and n are powers of 2 \nand rows and columns are indexed from 0. We can represent a row index i in binary \nby the lg m bits hi lg m\ue0021 ;i lg m\ue0022 ;:::;i  0 i and a column index j in binary by the lg n \nbits hj lg n\ue0021 ;j lg n\ue0022 ;:::;j  0 i. Suppose that this matrix is a 2 \ue005 2 block matrix, where \neach block has m=2  rows and n=2  columns, and it is to be represented by a single \narray with 0-origin  indexing.  Show  how  to construct  the  binary  represen tation of \nthe .lg m C lg n/-bit  index  into  the  single  array  from  the  binary  representat ions of \ni and j . \n10.1-2  \nUsing  Figure  10.2  as a model,  illustrate  the  result  of each  operation in the sequence \nPUSH.S;4/ , PUSH.S;1/ , PUSH.S;3/ , POP.S/, PUSH.S;8/ , and POP.S/  on an \ninitially empty stack S stored in array S\u01521  W 6\ufffd 258  Chapter  10  Elementary  Data  Structures  \n10.1-3  \nExplain how to implement two stacks in one array A\u01521  W n\ufffd in such a way that neither \nstack  over\u00fcows  unless  the  total  number  of elements  in both  stacks together is n. \nThe P USH and POP  operations should run in O.1/  time. \n10.1-4  \nUsing  Figure  10.3  as a model,  illustrate  the  result  of each  operation in the \nsequence E NQUEUE.Q;4/ , ENQUEUE.Q;1/ , ENQUEUE.Q;3/ , DEQUEUE.Q/, \nENQUEUE.Q;8/ , and DEQUEUE.Q/  on an initially empty queue Q stored in \narray Q\u01521  W 6\ufffd. \n10.1-5  \nRewrite E NQUEUE  and DEQUEUE  to detect  under\u00fcow  and  over\u00fcow  of a queue.  \n10.1-6  \nWhereas a stack allows insertion and deletion of el ements at only one end, and a \nqueue allows insertion at one end and deletion at t he other end, a deque  (double-  \nended queue, pronounced like <deck=) allows inserti on and deletion at both ends. \nWrite four O.1/-time  procedures  to insert  elements  into  and  delete  element s from \nboth ends of a deque implemented by an array. \n10.1-7  \nShow how to implement a queue using two stacks. Ana lyze the running time of the \nqueue operations. \n10.1-8  \nShow how to implement a stack using two queues. Ana lyze the running time of the \nstack operations. \n10.2  Linked  lists  \nA linked  list  is a data structure in which the objects are arrang ed in a linear order. \nUnlike an array, however, in which the linear order  is determined by the array \nindices, the order in a linked list is determined b y a pointer in each object. Since the \nelements of linked lists often contain keys that ca n be searched for, linked lists are \nsometimes called search  lists. Linked  lists  provide  a simple,  \u00fcexible  representation  \nfor  dynamic  sets,  supporting  (though  not  necessarily  ef\u00fbci ently) all the operations \nlisted  on  page  250.  \nAs  shown  in Figure  10.4,  each  element  of a doubly  linked  list  L is an object \nwith an attribute key  and two pointer attributes: next and prev. The object may 10.2 Linked lists 259 \n9 16  4 1 prev  key  next  \n(a) \n9 16  4 1 (b) 25  \n9 4 1 (c) 25  \n9 (d) 25  36  16  \n36  16  1 L:  head L:  head L:  head L:  head \nFigure  10.4  (a)  A doubly linked list L representing the dynamic set f1;4;9;16 g. Each element in \nthe list is an object with attributes for the key a nd pointers (shown by arrows) to the next and previ ous \nobjects. The next attribute of the tail and the prev attribute of the head are NIL, indicated by a diagonal \nslash. The attribute L:  head points to the head. (b)  Following the execution of L IST-PREPEND.L;x/ , \nwhere x: key  D 25, the linked list has an object with key 25  as the new head. This new object points \nto the old head with key 9. (c)  The result of calling L IST-I NSERT.x;y/ , where x: key  D 36  and y \npoints to the object with key 9. (d)  The result of the subsequent call L IST-DELETE.L;x/ , where \nx points to the object with key 4. \nalso  contain  other  satellite  data.  Given  an element  x in the list, x: next points to its \nsuccessor in the linked list, and x: prev points to its predecessor. If x: prev D NIL, \nthe element x has  no  predecessor  and  is therefore  the  \u00fbrst  element,  or head , of \nthe list. If x: next D NIL, the element x has no successor and is therefore the last \nelement, or tail, of the list. An attribute L:  head points  to the  \u00fbrst  element  of the  \nlist. If L:  head D NIL, the list is empty. \nA list may have one of several forms. It may be eit her singly linked or doubly \nlinked, it may be sorted or not, and it may be circ ular or not. If a list is singly  \nlinked , each element has a next pointer but not a prev pointer. If a list is sorted , the \nlinear order of the list corresponds to the linear order of keys stored in elements \nof the list. The minimum element is then the head o f the list, and the maximum \nelement is the tail. If the list is unsorted , the elements can appear in any order. In \na circular  list, the prev pointer of the head of the list points to the tail,  and the next \npointer of the tail of the list points to the head.  You can think of a circular list as a \nring of elements. In the remainder of this section,  we assume that the lists we are \nworking with are unsorted and doubly linked. 260  Chapter  10  Elementary  Data  Structures  \nSearching  a linked  list  \nThe procedure L IST-SEARCH .L;k/  \u00fbnds  the  \u00fbrst  element  with  key  k in list L \nby a simple linear search, returning a pointer to t his element. If no object with \nkey k appears in the list, then the procedure returns NIL. For the linked list in \nFigure  10.4(a),  the  call  LIST-SEARCH .L;4/  returns a pointer to the third element, \nand the call L IST-SEARCH .L;7/  returns NIL. To search a list of n objects, the \nLIST-SEARCH procedure takes \u201a.n/  time in the worst case, since it may have to \nsearch the entire list. \nLIST-SEARCH .L;k/  \n1 x D L:  head \n2 while  x \u00a4 NIL and x: key  \u00a4 k \n3 x D x: next \n4 return  x \nInserting  into  a linked  list  \nGiven  an element  x whose key  attribute has already been set, the L IST-PREPEND \nprocedure adds x to the  front  of the  linked  list,  as shown  in Figure  10.4(b).  (Re-  \ncall that our attribute notation can cascade, so th at L:  head: prev denotes the prev \nattribute of the object that L:  head points to.) The running time for L IST-PREPEND \non a list of n elements is O.1/ . \nLIST-PREPEND .L;x/  \n1 x: next D L:  head \n2 x: prev D NIL \n3 if L:  head \u00a4 NIL \n4 L:  head: prev D x \n5 L:  head D x \nYou  can  insert  anywhere  within  a linked  list.  As  Figure  10.4( c) shows, if you \nhave a pointer y to an object in the list, the L IST-I NSERT procedure on the facing \npage <splices= a new element x into the list, immediately following y , in O.1/  \ntime. Since L IST-I NSERT never references the list object L, it is not supplied as a \nparameter. 10.2 Linked lists 261 \nLIST-I NSERT .x;y/  \n1 x: next D y: next \n2 x: prev D y \n3 if y: next \u00a4 NIL \n4 y: next: prev D x \n5 y: next D x \nDeleting  from  a linked  list  \nThe procedure L IST-DELETE removes an element x from a linked list L. It must \nbe given a pointer to x , and it then <\u2018splices= x out of the list by updating pointers. \nTo  delete  an element  with  a given  key,  \u00fbrst  call  LIST-SEARCH to retrieve a pointer \nto the  element.  Figure  10.4(d)  shows  how  an element  is delete d from a linked list. \nLIST-DELETE runs in O.1/  time, but to delete an element with a given key, th e call \nto L IST-SEARCH makes  the  worst-case  running  time  be \u201a.n/ . \nLIST-DELETE .L;x/  \n1 if x: prev \u00a4 NIL \n2 x: prev: next D x: next \n3 else  L:  head D x: next \n4 if x: next \u00a4 NIL \n5 x: next: prev D x: prev \nInsertion and deletion are faster operations on dou bly linked lists than on arrays. \nIf you  want  to insert  a new  \u00fbrst  element  into  an array  or delete  the  \u00fbrst  element  in \nan array, maintaining the relative order of all the  existing elements, then each of the \nexisting elements needs to be moved by one position . In the worst case, therefore, \ninsertion and deletion take \u201a.n/  time in an array, compared with O.1/  time for a \ndoubly  linked  list.  (Exercise  10.2-1  asks  you  to show  that  deleting an element from \na singly linked list takes \u201a.n/  time  in the  worst  case.)  If, however,  you  want  to \u00fbnd  \nthe kth element in the linear order, it takes just O.1/  time in an array regardless \nof k, but  in a linked  list,  you\u2019d  have  to traverse  k elements, taking \u201a.k/  time. \nSentinels  \nThe code for L IST-DELETE is simpler if you ignore the boundary conditions at  the \nhead and tail of the list: 262  Chapter  10  Elementary  Data  Structures  \n9 16  4 1 \n9 16  4 1 25  \n9 16  4 25  (a) \n(b) \n(c) \n(d) \n9 16  4 25  (e) 36  L:  nil L:  nil L:  nil L:  nil L:  nil \nFigure  10.5  A circular, doubly linked list with a sentinel. The  sentinel L:  nil, in blue, appears \nbetween the head and tail. The attribute L:  head is no longer needed, since the head of the list \nis L:  nil: next. (a)  An empty list. (b)  The  linked  list  from  Figure  10.4(a),  with  key  9 at the  head  and  \nkey  1 at the  tail.  (c)  The list after executing L IST-I NSERT 0 .x;L:  nil/, where x: key  D 25. The new \nobject becomes the head of the list. (d)  The  list  after  deleting  the  object  with  key  1. The  new  tail  \nis the  object  with  key  4. (e)  The list after executing L IST-I NSERT 0 .x;y/ , where x: key  D 36  and y \npoints to the object with key 9. \nLIST-DELETE 0 .x/  \n1 x: prev: next D x: next \n2 x: next : prev D x: prev \nA sentinel  is a dummy object that allows us to simplify bounda ry conditions. \nIn a linked list L, the sentinel is an object L:  nil that represents NIL but has all \nthe attributes of the other objects in the list. Re ferences to NIL are replaced by \nreferences to the sentinel L:  nil. As  shown  in Figure  10.5,  this  change  turns  a \nregular doubly linked list into a circular,  doubly  linked  list  with  a sentinel , in \nwhich the sentinel L:  nil lies between the head and tail. The attribute L:  nil: next \npoints to the head of the list, and L:  nil: prev points to the tail. Similarly, both the \nnext attribute of the tail and the prev attribute of the head point to L:  nil. Since \nL:  nil: next points to the head, the attribute L:  head is eliminated altogether, with \nreferences to it replaced by references to L:  nil: next . Figure  10.5(a)  shows  that  an \nempty list consists of just the sentinel, and both L:  nil: next and L:  nil: prev point \nto L:  nil. \nTo  delete  an element  from  the  list,  just  use  the  two-line  procedure L IST-DELETE 0 \nfrom  before.  Just  as LIST-I NSERT never references the list object L, neither does 10.2 Linked lists 263 \nLIST-DELETE 0 . You should never delete the sentinel L:  nil unless you are deleting \nthe entire list! \nThe L IST-I NSERT 0 procedure inserts an element x into  the  list  following  ob-  \nject y . No separate procedure for prepending is necessary : to insert at the head of \nthe list, let y be L:  nil; and to insert at the tail, let y be L:  nil: prev. Figure  10.5  \nshows the effects of L IST-I NSERT 0 and L IST-DELETE 0 on a sample list. \nLIST-I NSERT 0 .x;y/  \n1 x: next D y: next \n2 x: prev D y \n3 y: next: prev D x \n4 y: next D x \nSearching a circular, doubly linked list with a sen tinel has the same asymptotic \nrunning time as without a sentinel, but it is possi ble to decrease the constant factor. \nThe test in line 2 of L IST-SEARCH makes two comparisons: one to check whether \nthe search has run off the end of the list and, if not, one to check whether the key \nresides in the current element x . Suppose that you know that the key is somewhere \nin the list. Then you do not need to check whether the search runs off the end of \nthe list, thereby eliminating one comparison in eac h iteration of the while  loop. \nThe sentinel provides a place to put the key before  starting the search. The search \nstarts at the head L:  nil: next of list L, and  it stops  if it \u00fbnds  the  key  somewhere  in \nthe  list.  Now  the  search  is guaranteed  to \u00fbnd  the  key,  either  in the sentinel or before \nreaching the sentinel. If the key is found before r eaching the sentinel, then it really \nis in the element where the search stops. If, howev er, the search goes through all the \nelements  in the  list  and  \u00fbnds  the  key  only  in the  sentinel,  then the key is not really \nin the list, and the search returns NIL. The procedure L IST-SEARCH 0 embodies this \nidea. (If your sentinel requires its key  attribute to be NIL, then you might want to \nassign L:  nil: key  D NIL before  line  5.)  \nLIST-SEARCH 0 .L;k/  \n1 L:  nil: key  D k / / store the key in the sentinel to guarantee it is in  list \n2 x D L:  nil: next / / start at the head of the list \n3 while  x: key  \u00a4 k \n4 x D x: next \n5 if x == L:  nil / / found k in the sentinel \n6 return  NIL / / k was not really in the list \n7 else  return  x / / found k in element x 264  Chapter  10  Elementary  Data  Structures  \nSentinels often simplify code and, as in searching a linked list, they might speed \nup  code  by  a small  constant  factor,  but  they  don\u2019t  typically  improve the asymptotic \nrunning time. Use them judiciously. When there are many small lists, the extra \nstorage  used  by  their  sentinels  can  represent  signi\u00fbcant  wasted memory. In this \nbook,  we  use  sentinels  only  when  they  signi\u00fbcantly  simplify  the code. \nExercises  \n10.2-1  \nExplain  why  the  dynamic-set  operation  I NSERT on  a singly  linked  list  can  be im-  \nplemented in O.1/  time,  but  the  worst-case  time  for  DELETE is \u201a.n/ . \n10.2-2  \nImplement a stack using a singly linked list. The o perations P USH and POP  should \nstill take O.1/  time.  Do  you  need  to add  any  attributes  to the  list?  \n10.2-3  \nImplement a queue using a singly linked list. The o perations E NQUEUE  and \nDEQUEUE  should still take O.1/  time. Do you need to add any attributes to the \nlist?  \n10.2-4  \nThe  dynamic-set  operation  UNION  takes two disjoint sets S 1 and S 2 as input, and \nit returns a set S D S 1 [ S 2 consisting of all the elements of S 1 and S 2 . The \nsets S 1 and S 2 are usually destroyed by the operation. Show how to  support U NION  \nin O.1/  time using a suitable list data structure. \n10.2-5  \nGive  a \u201a.n/-time  nonrecursive  procedure  that  reverses  a singly  linked  list of n \nelements. The procedure should use no more than con stant storage beyond that \nneeded for the list itself. \n? 10.2-6  \nExplain how to implement doubly linked lists using only one pointer value x: np \nper item instead of the usual two ( next and prev). Assume that all pointer values \ncan be interpreted as k-bit  integers,  and  de\u00fbne  x: np D x: next XOR  x: prev, the \nk-bit  <exclusive-or=  of x: next and x: prev. The value NIL is represented by 0. Be \nsure to describe what information you need to acces s the head of the list. Show \nhow to implement the S EARCH , I NSERT , and D ELETE operations on such a list. \nAlso show how to reverse such a list in O.1/  time. 10.3 Representing rooted trees 265 \n10.3  Representing  rooted  trees  \nLinked lists work well for representing linear rela tionships, but not all relationships \nare  linear.  In this  section,  we  look  speci\u00fbcally  at the  probl em of representing rooted \ntrees  by  linked  data  structures.  We  \u00fbrst  look  at binary  trees , and then we present a \nmethod for rooted trees in which nodes can have an arbitrary number of children. \nWe represent each node of a tree by an object. As w ith linked lists, we assume \nthat each node contains a key  attribute. The remaining attributes of interest are  \npointers to other nodes, and they vary according to  the type of tree. \nBinary  trees  \nFigure  10.6  shows  how  to use  the  attributes  p, left , and right to store pointers to \nthe parent, left child, and right child of each nod e in a binary tree T . If x: p D NIL, \nthen x is the root. If node x has no left child, then x: left D NIL, and similarly for \nthe right child. The root of the entire tree T is pointed to by the attribute T: root . If \nT: root D NIL, then the tree is empty. \nRooted  trees  with  unbounded  branching  \nIt\u2019s  simple  to extend  the  scheme  for  representing  a binary  tree to any class of trees \nin which the number of children of each node is at most some constant k: replace \nthe left and right attributes by child  1 ; child  2 ;:::;  child  k . This scheme no longer \nworks when the number of children of a node is unbo unded, however, since we do \nnot know how many attributes to allocate in advance . Moreover, if k, the number \nof children, is bounded by a large constant but mos t nodes have a small number of \nchildren, we may waste a lot of memory. \nFortunately, there is a clever scheme to represent trees with arbitrary numbers of \nchildren. It has the advantage of using only O.n/  space for any n-node  rooted  tree.  \nThe left-child,  right-sibling  representation  appears  in Figure  10.7.  As  before,  each  \nnode contains a parent pointer p, and T: root points to the root of tree T . Instead \nof having a pointer to each of its children, howeve r, each node x has only two \npointers: \n1. x: left-child  points to the leftmost child of node x , and \n2. x: right-sibling points to the sibling of x immediately to its right. \nIf node x has no children, then x: left-child  D NIL, and if node x is the rightmost \nchild of its parent, then x: right-sibling D NIL. 266  Chapter  10  Elementary  Data  Structures  \nT: root \nFigure  10.6  The representation of a binary tree T . Each node x has the attributes x: p (top), x: left \n(lower left), and x: right (lower right). The key  attributes are not shown. \nT: root \nFigure  10.7  The  left-child,  right-sibling  representation  of a tree  T . Each node x has attributes x: p \n(top), x: left-child  (lower left), and x: right-sibling (lower right). The key  attributes are not shown. 10.3 Representing rooted trees 267 \nOther  tree  representations  \nWe sometimes represent rooted trees in other ways. In Chapter 6, for  example,  \nwe represented a heap, which is based on a complete  binary tree, by a single array \nalong with an attribute giving the index of the las t node in the heap. The trees that \nappear  in Chapter  19  are  traversed  only  toward  the  root,  and  so only the parent \npointers are present: there are no pointers to chil dren. Many other schemes are \npossible. Which scheme is best depends on the appli cation. \nExercises  \n10.3-1  \nDraw the binary tree rooted at index 6 that  is represented  by  the  following  at-  \ntributes: \nindex key  left  right  \n1 17  8 9 \n2 14  NIL NIL \n3 12  NIL NIL \n4 20  10  NIL \n5 33  2 NIL \n6 15  1 4 \n7 28  NIL NIL \n8 22  NIL NIL \n9 13  3 7 \n10  25  NIL 5 \n10.3-2  \nWrite an O.n/-time  recursive  procedure  that,  given  an n-node  binary  tree,  prints  \nout the key of each node in the tree. \n10.3-3  \nWrite an O.n/-time  nonrecursive  procedure  that,  given  an n-node  binary  tree,  \nprints out the key of each node in the tree. Use a stack as an auxiliary data structure. \n10.3-4  \nWrite an O.n/-time  procedure  that  prints  out  all  the  keys  of an arbitrary  rooted tree \nwith n nodes,  where  the  tree  is stored  using  the  left-child,  right-sibling  representa-  \ntion. \n? 10.3-5  \nWrite an O.n/-time  nonrecursive  procedure  that,  given  an n-node  binary  tree,  \nprints out the key of each node. Use no more than c onstant extra space outside 268  Chapter  10  Elementary  Data  Structures  \nof the tree itself and do not modify the tree, even  temporarily, during  the  proce-  \ndure. \n? 10.3-6  \nThe  left-child,  right-sibling  representation  of an arbitr ary rooted tree uses three \npointers in each node: left-child  , right-sibling , and parent . From any node, its \nparent can be accessed in constant time and all its  children can be accessed in \ntime linear in the number of children. Show how to use only two pointers and \none boolean value in each node x so that x \u2019s parent  or all  of x \u2019s children  can  be \naccessed in time linear in the number of x \u2019s children.  \nProblems  \n10-1  Comparisons  among  lists  \nFor each of the four types of lists in the followin g table, what is the asymptotic \nworst-case  running  time  for  each  dynamic-set  operation  listed?  \nunsorted, sorted, unsorted, sorted, \nsingly singly doubly doubly \nlinked linked linked linked \nSEARCH \nI NSERT \nDELETE \nSUCCESSOR  \nPREDECESSOR  \nMINIMUM \nMAXIMUM \n10-2  Mergeable  heaps  using  linked  lists  \nA mergeable  heap  supports the following operations: M AKE-HEAP (which creates \nan empty mergeable heap), I NSERT , M INIMUM , EXTRACT-MIN, and UNION . 1 \n1 Because  we  have  de\u00fbned  a mergeable  heap  to support  MINIMUM and E XTRACT-MIN, we can also \nrefer to it as a mergeable  min-heap . Alternatively, if it supports M AXIMUM and E XTRACT-MAX, it \nis a mergeable  max-heap . Problems for Chapter 10 269 \nShow how to implement mergeable heaps using linked lists in each of the following \ncases.  Try  to make  each  operation  as ef\u00fbcient  as possible.  Analyze the running \ntime of each operation in terms of the size of the dynamic set(s) being operated on. \na. Lists are sorted. \nb. Lists are unsorted. \nc. Lists are unsorted, and dynamic sets to be merged a re disjoint. \n10-3  Searching  a sorted  compact  list  \nWe can represent a singly linked list with two arra ys, key  and next . Given  the  \nindex i of an element, its value is stored in key\u0152i\ufffd, and the index of its successor is \ngiven by next \u0152i\ufffd, where next \u0152i\ufffd  D NIL for the last element. We also need the index \nhead of the  \u00fbrst  element  in the  list.  An  n-element  list  stored  in this  way  is compact  \nif it is stored only in positions 1 through n of the key  and next arrays. \nLet\u2019s  assume  that  all  keys  are  distinct  and  that  the  compact  list is also sorted, \nthat is, key\u0152i\ufffd<  key\u0152next \u0152i\ufffd\ufffd  for all i D 1;2;:::;n  such that next \u0152i\ufffd  \u00a4 NIL. Under \nthese assumptions, you will show that the randomize d algorithm C OMPACT  -LIST- \nSEARCH searches the list for key k in O.  p n/ expected time. \nCOMPACT  -LIST-SEARCH .key; next ; head ;n;k/  \n1 i D head \n2 while  i \u00a4 NIL and key\u0152i\ufffd<k  \n3 j D RANDOM.1;n/  \n4 if key\u0152i\ufffd<  key\u0152j\ufffd  and key\u0152j\ufffd  \u0dc4 k \n5 i D j \n6 if key\u0152i\ufffd  == k \n7 return  i \n8 i D next \u0152i\ufffd  \n9 if i == NIL or key\u0152i\ufffd>k  \n10  return  NIL \n11  else  return  i \nIf you  ignore  lines  337  of the  procedure,  you  can  see  that  it\u2019s  an ordinary  algo-  \nrithm for searching a sorted linked list, in which index i points to each position of \nthe list in turn. The search terminates once the in dex i <falls off= the end of the list \nor once key\u0152i\ufffd  \ue004 k. In the latter case, if key\u0152i\ufffd  D k, the procedure has found a key \nwith the value k. If, however, key\u0152i\ufffd>k, then  the  search  will  never  \u00fbnd  a key  with  \nthe value k, so that terminating the search was the correct ac tion. 270  Chapter  10  Elementary  Data  Structures  \nLines  337  attempt  to skip  ahead  to a randomly  chosen  position  j . Such a skip \nhelps if key\u0152j\ufffd  is larger than key\u0152i\ufffd  and no larger than k. In such a case, j marks \na position in the list that i would reach during an ordinary list search. Because  \nthe list is compact, we know that any choice of j between 1 and n indexes some \nelement in the list. \nInstead of analyzing the performance of C OMPACT  -LIST-SEARCH directly, you \nwill analyze a related algorithm, C OMPACT  -LIST-SEARCH 0 , which executes two \nseparate loops. This algorithm takes an additional parameter t , which  speci\u00fbes  an \nupper  bound  on  the  number  of iterations  of the  \u00fbrst  loop.  \nCOMPACT  -LIST-S EARCH 0 .key; next ; head ;n;k;t/  \n1 i D head \n2 for  q D 1 to t \n3 j D RANDOM.1;n/  \n4 if key\u0152i\ufffd<  key\u0152j\ufffd  and key\u0152j\ufffd  \u0dc4 k \n5 i D j \n6 if key\u0152i\ufffd  == k \n7 return  i \n8 while  i \u00a4 NIL and key\u0152i\ufffd<k  \n9 i D next \u0152i\ufffd  \n10  if i = = NIL or key\u0152i\ufffd>k  \n11  return  NIL \n12  else  return  i \nTo compare the execution of the two algorithms, ass ume that the sequence of \ncalls of RANDOM.1;n/  yields the same sequence of integers for both algor ithms. \na. Argue that for any value of t , COMPACT  -LIST-SEARCH .key; next ; head;n;k/  \nand COMPACT  -LIST-SEARCH 0 .key; next ; head;n;k;t/  return the same result \nand that the number of iterations of the while  loop  of lines  238  in COMPACT  - \nLIST-SEARCH is at most the total number of iterations of both t he for  and while  \nloops in C OMPACT  -LIST-SEARCH 0 . \nIn the call C OMPACT  -LIST-SEARCH 0 .key; next ; head;n;k;t/ , let X t be the random \nvariable that describes the distance in the linked list (that is, through the chain of \nnext pointers) from position i to the desired key k after t iterations of the for  loop \nof lines  237  have  occurred.  \nb. Argue that C OMPACT  -LIST-SEARCH 0 .key; next ; head ;n;k;t/  has an expected \nrunning time of O.t  C E \u0152X  t \ufffd/. \nc. Show that E \u0152X  t \ufffd D P  n \nr D1 .1\ue003r=n/  t . (Hint: Use  equation  (C.28)  on  page  1193.)  Notes for Chapter 10 271 \nd. Show that P  n\ue0021 \nr D0 r t \u0dc4 n t C1 =.t  C1/. (Hint: Use  inequality  (A.18)  on  page  1150.)  \ne. Prove that E \u0152X  t \ufffd \u0dc4 n=.t  C 1/. \nf. Show that C OMPACT  -LIST-SEARCH 0 .key; next ; head ;n;k;t/  has an expected \nrunning time of O.t  C n=t/. \ng. Conclude that C OMPACT  -LIST-SEARCH runs in O.  p n/ expected time. \nh. Why do we assume that all keys are distinct in C OMPACT  -LIST-SEARCH? Ar-  \ngue that random skips do not necessarily help asymp totically when  the  list  con-  \ntains repeated key values. \nChapter  notes  \nAho,  Hopcroft,  and  Ullman  [6]  and  Knuth  [259]  are  excellent  references  for  ele-  \nmentary data structures. Many other texts cover bot h basic data structures and their \nimplementation in a particular programming language . Examples of these types of \ntextbooks  include  Goodrich  and  Tamassia  [196],  Main  [311],  Shaffer  [406],  and  \nWeiss  [452,  453,  454].  The  book  by  Gonnet  and  Baeza-Yates  [193]  provides  ex-  \nperimental  data  on  the  performance  of many  data-structure  operations. \nThe origin of stacks and queues as data structures in computer science  is un-  \nclear, since corresponding notions already existed in mathematics  and  paper-based  \nbusiness practices before the introduction of digit al computers.  Knuth  [259]  cites  \nA. M. Turing for the development of stacks for subr outine linkage  in 1947.  \nPointer-based  data  structures  also  seem  to be a folk  inventi on. According to \nKnuth,  pointers  were  apparently  used  in early  computers  with drum memories. The \nA-1  language  developed  by  G.  M.  Hopper  in 1951  represented  algebraic formulas \nas binary  trees.  Knuth  credits  the  IPL-II  language,  developed  in 1956  by  A.  Newell,  \nJ. C. Shaw,  and  H.  A.  Simon,  for  recognizing  the  importance  and promoting the \nuse  of pointers.  Their  IPL-III  language,  developed  in 1957,  included explicit stack \noperations. 11  Hash  Tables  \nMany applications require a dynamic set that suppor ts only the dictionary  opera-  \ntions I NSERT , SEARCH , and D ELETE . For example, a compiler that translates a \nprogramming language maintains a symbol table, in w hich the keys of elements \nare  arbitrary  character  strings  corresponding  to identi\u00fbe rs in the language. A hash \ntable is an effective data structure for implementi ng dictionaries.  Although  search-  \ning for an element in a hash table can take as long  as searching for an element in a \nlinked  list4\u201a.n/  time  in the  worst  case4in  practice,  hashing  performs  extrem ely \nwell. Under reasonable assumptions, the average tim e to search for an element in \na hash table is O.1/. Indeed,  the  built-in  dictionaries  of Python  are  implement ed \nwith hash tables. \nA hash table generalizes the simpler notion of an o rdinary array.  Directly  ad-  \ndressing into an ordinary array takes advantage of the O.1/  access time for any \narray  element.  Section  11.1  discusses  direct  addressing  in more  detail.  To  use  di-  \nrect addressing, you must be able to allocate an ar ray that contains a position for \nevery possible key. \nWhen the number of keys actually stored is small re lative to the total number \nof possible keys, hash tables become an effective a lternative to directly  address-  \ning an array, since a hash table typically uses an array of size proportional to the \nnumber of keys actually stored. Instead of using th e key as an array index directly, \nwe compute  the  array  index  from  the  key.  Section  11.2  presents  the  main  ideas, \nfocusing on <chaining= as a way to handle <collisio ns,= in which more than one \nkey  maps  to the  same  array  index.  Section  11.3  describes  how  to compute array \nindices from keys using hash functions. We present and analyze several variations \non  the  basic  theme.  Section  11.4  looks  at <open  addressing,=  which is another way \nto deal with collisions. The bottom line is that ha shing is an extremely effective \nand practical technique: the basic dictionary opera tions require only O.1/  time on \nthe  average.  Section  11.5  discusses  the  hierarchical  memor y systems of modern \ncomputer systems have and illustrates how to design  hash tables that work well in \nsuch systems. 11.1  Direct-address  tables  273 \n11.1  Direct-address  tables  \nDirect addressing is a simple technique that works well when the universe U of \nkeys is reasonably small. Suppose that an applicati on needs a dynamic set in which \neach element has a distinct key drawn from the univ erse U D f0;1;:::;m  \ue003 1g, \nwhere m is not too large. \nTo represent the dynamic set, you can use an array,  or direct-address  table, de-  \nnoted by T\u01520  W m \ue003 1\ufffd, in which each position, or slot, corresponds to a key in the \nuniverse U . Figure  11.1  illustrates  this  approach.  Slot  k points to an element in the \nset with key k. If the set contains no element with key k, then T\u0152k\ufffd  D NIL. \nThe dictionary operations D IRECT-ADDRESS-SEARCH , D IRECT-ADDRESS- \nI NSERT , and D IRECT-ADDRESS-DELETE on  the  following  page  are  trivial  to im-  \nplement. Each takes only O.1/  time. \nFor  some  applications,  the  direct-address  table  itself  can  hold the elements in \nthe  dynamic  set.  That  is, rather  than  storing  an element\u2019s  key and satellite data in \nan object  external  to the  direct-address  table,  with  a point er from a slot in the table \nto the object, save space by storing the object dir ectly in the slot. To indicate an \nempty slot, use a special key. Then again, why stor e the key of the  object  at all?  \nThe index of the object is its  key!  Of  course,  then  you\u2019d  need  some  way  to tell  \nwhether slots are empty. \nT \nU \n(universe of keys) \nK \n(actual \nkeys) 2 \n3 \n5 8 1 9 4 0 \n7 6 2 \n3 \n5 \n8 key satellite data \n2 0 \n1 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \nFigure  11.1  How  to implement  a dynamic  set  by  a direct-address  table  T . Each key in the universe \nU D f0;1;:::;9 g corresponds to an index into the table. The set K D f2;3;5;8 g of actual keys \ndetermines the slots in the table that contain poin ters to elements. The other slots, in blue, contain  \nNIL. 274 Chapter 11 Hash Tables \nDIRECT-ADDRESS-SEARCH .T;k/  \n1 return  T\u0152k\ufffd  \nDIRECT-ADDRESS-I NSERT .T;x/  \n1 T\u0152x:  key\ufffd D x \nDIRECT-ADDRESS-DELETE .T;x/  \n1 T\u0152x:  key\ufffd D NIL \nExercises  \n11.1-1  \nA dynamic set S is represented  by  a direct-address  table  T of length m. Describe \na procedure  that  \u00fbnds  the  maximum  element  of S . What  is the  worst-case  perfor-  \nmance  of your  procedure?  \n11.1-2  \nA bit  vector  is simply an array of bits (each either 0 or 1). A bit vector of length m \ntakes much less space than an array of m pointers. Describe how to use a bit vector \nto represent a dynamic set of distinct elements dra wn from the set f0;1;:::;m  \ue003 1g \nand with no satellite data. Dictionary operations s hould run in O.1/  time. \n11.1-3  \nSuggest  how  to implement  a direct-address  table  in which  the  keys  of stored  el-  \nements do not need to be distinct and the elements can have satellite data. All \nthree dictionary operations (I NSERT , DELETE , and S EARCH ) should run in O.1/  \ntime.  (Don\u2019t  forget  that  DELETE takes as an argument a pointer to an object to be \ndeleted, not a key.) \n? 11.1-4  \nSuppose that you want to implement a dictionary by using direct addressing on \na huge  array. That is, if the array size is m and the dictionary contains at most \nn elements at any one time, then m \ue007  n. At the start, the array entries may \ncontain garbage, and initializing the entire array is impractical because of its size. \nDescribe  a scheme  for  implementing  a direct-address  dictio nary on a huge array. \nEach stored object should use O.1/  space; the operations S EARCH , I NSERT , and \nDELETE should take O.1/  time each; and initializing the data structure shou ld take \nO.1/  time. ( Hint: Use an additional array, treated somewhat like a st ack whose size \nis the number of keys actually stored in the dictio nary, to help determine whether \na given entry in the huge array is valid or not.) 11.2 Hash tables 275 \n11.2  Hash  tables  \nThe downside of direct addressing is apparent: if t he universe U is large  or in\u00fbnite,  \nstoring a table T of size jU j may be impractical, or even impossible, given the \nmemory available on a typical computer. Furthermore , the set K of keys actually  \nstored may be so small relative to U that most of the space allocated for T would \nbe wasted. \nWhen the set K of keys  stored  in a dictionary  is much  smaller  than  the  uni-  \nverse U of all possible keys, a hash table requires much le ss storage than  a direct-  \naddress  table.  Speci\u00fbcally,  the  storage  requirement  reduc es to \u201a.jKj/ while  main-  \ntaining  the  bene\u00fbt  that  searching  for  an element  in the  hash  table still requires only \nO.1/  time. The catch is that this bound is for the average-case  time, 1 whereas for \ndirect addressing it holds for the worst-case  time. \nWith direct addressing, an element with key k is stored in slot k, but  with  hash-  \ning, we use a hash  function  h to compute the slot number from the key k, so that \nthe element goes into slot h.k/ . The hash function h maps the universe U of keys \ninto the slots of a hash  table  T\u01520  W m \ue003 1\ufffd: \nh W U ! f0;1;:::;m  \ue003 1g ; \nwhere the size m of the hash table is typically much less than jU j. We say that \nan element with key k hashes  to slot h.k/ , and we also say that h.k/  is the hash  \nvalue  of key k. Figure  11.2  illustrates  the  basic  idea.  The  hash  function  reduces \nthe range of array indices and hence the size of th e array. Instead of a size of jU j, \nthe array can have size m. An example of a simple, but not particularly good , hash \nfunction is h.k/  D k mod m. \nThere is one hitch, namely that two keys may hash t o the same slot. We call this \nsituation a collision . Fortunately, there are effective techniques for r esolving the \ncon\u00fcict  created  by  collisions.  \nOf  course,  the  ideal  solution  is to avoid  collisions  altoget her. We might try to \nachieve this goal by choosing a suitable hash funct ion h. One  idea  is to make  h ap-  \npear to be <random,= thus avoiding collisions or at  least minimizing their number. \nThe very term <to hash,= evoking images of random m ixing and chopping,  cap-  \ntures  the  spirit  of this  approach.  (Of  course,  a hash  functio n h must  be determin-  \nistic in that a given input k must always produce the same output h.k/ .) Because \njU j >m , however, there must be at least two keys that hav e the same hash value, \n1 The  de\u00fbnition  of <average-case=  requires  care4are  we  assum ing an input distribution over the \nkeys, or are we randomizing the choice of hash func tion itself? We\u2019ll  consider  both  approaches,  but  \nwith an emphasis on the use of a randomly chosen ha sh function. 276 Chapter 11 Hash Tables \nT \nU \n(universe of keys) \nK \n(actual \nkeys) 0 \nm31  k 1 \nk 2 k 3 k 4 k 5 h(k 1 ) \nh(k 4 ) \nh(k 3 ) h(k 2 ) = h(k 5 ) \nFigure  11.2  Using a hash function h to map  keys  to hash-table  slots.  Because  keys  k 2 and k 5 map \nto the same slot, they collide. \nand avoiding collisions altogether is impossible. T hus, although  a well-designed,  \n<random=-looking  hash  function  can  reduce  the  number  of collisions, we still need \na method for resolving the collisions that do occur . \nThe  remainder  of this  section  \u00fbrst  presents  a de\u00fbnition  of <independent uniform \nhashing,= which captures the simplest notion of wha t it means for a hash function \nto be <random.= It then presents and analyzes the s implest collision  resolution  tech-  \nnique,  called  chaining.  Section  11.4  introduces  an alterna tive method for resolving \ncollisions, called open addressing. \nIndependent  uniform  hashing  \nAn <ideal= hashing function h would have, for each possible input k in the  do-  \nmain U , an output h.k/  that is an element randomly and independently chose n \nuniformly from the range f0;1;:::;m  \ue003 1g. Once  a value  h.k/  is randomly  cho-  \nsen, each subsequent call to h with the same input k yields the same output h.k/ . \nWe call such an ideal hash function an independent  uniform  hash  function . \nSuch a function is also often called a random  oracle  [43].  When  hash  tables  are  \nimplemented with an independent uniform hash functi on, we say we are using \nindependent  uniform  hashing . \nIndependent uniform hashing is an ideal theoretical  abstraction, but it is not \nsomething that can reasonably be implemented in pra ctice. Nonetheless,  we\u2019ll  \nanalyze  the  ef\u00fbciency  of hashing  under  the  assumption  of independent uniform \nhashing and then present ways of achieving useful p ractical approximations to this \nideal. 11.2 Hash tables 277 \nT \nU \n(universe of keys) \nK \n(actual \nkeys) k 1 \nk 2 k 3 k 4 k 5 \nk 6 k 7 \nk 8 k 1 \nk 2 \nk 3 k 4 \nk 5 \nk 6 k 7 \nk 8 \nFigure  11.3  Collision  resolution  by  chaining.  Each  nonempty  hash-tabl e slot T \u0152j \ufffd  points to a \nlinked list of all the keys whose hash value is j . For example, h.k  1 / D h.k  4 / and h.k  5 / D h.k  2 / D \nh.k  7 /. The list can be either singly or doubly linked. W e show it as doubly linked because deletion \nmay be faster that way when the deletion procedure knows which list element (not just which key) is \nto be deleted. \nCollision  resolution  by  chaining  \nAt a high level, you can think of hashing with chai ning as a nonrecursive form \nof divide-and-conquer:  the  input  set  of n elements is divided randomly into m \nsubsets, each of approximate size n=m . A hash function determines which subset \nan element belongs to. Each subset is managed indep endently as a list. \nFigure  11.3  shows  the  idea  behind  chaining : each nonempty slot points to a \nlinked list, and all the elements that hash to the same slot go into  that  slot\u2019s  linked  \nlist. Slot j contains a pointer to the head of the list of all s tored elements with hash \nvalue j . If there are no such elements, then slot j contains NIL. \nWhen collisions are resolved by chaining, the dicti onary operations  are  straight-  \nforward to implement. They appear on the next page and use the linked-list  pro-  \ncedures  from  Section  10.2.  The  worst-case  running  time  for  insertion is O.1/ . \nThe insertion procedure is fast in part because it assumes that the element x be-  \ning inserted is not already present in the table. T o enforce this assumption, you \ncan search (at additional cost) for an element whos e key is x: key  before inserting. \nFor  searching,  the  worst-case  running  time  is proportional  to the length of the list. \n(We\u2019ll  analyze  this  operation  more  closely  below.)  Deletio n takes O.1/  time if the \nlists  are  doubly  linked,  as in Figure  11.3.  (Since  CHAINED-HASH-DELETE takes \nas input an element x and not its key k, no search is needed. If the hash table \nsupports deletion, then its linked lists should be doubly linked in order to delete an \nitem quickly. If the lists were only singly linked,  then by Exercise  10.2-1,  deletion  278 Chapter 11 Hash Tables \nCHAINED-HASH-I NSERT .T; x/  \n1 LIST-PREPEND .T \u0152h.x:  key/\ufffd; x/  \nCHAINED-HASH-SEARCH .T; k/  \n1 return  LIST-SEARCH .T \u0152h.k/\ufffd; k/  \nCHAINED-HASH-DELETE .T; x/  \n1 LIST-DELETE .T \u0152h.x:  key/\ufffd; x/  \ncould take time proportional to the length of the l ist. With singly linked lists, both \ndeletion and searching would have the same asymptot ic running times.) \nAnalysis  of hashing  with  chaining  \nHow  well  does  hashing  with  chaining  perform?  In particular,  how long does it take \nto search  for  an element  with  a given  key?  \nGiven  a hash  table  T with m slots that stores n elements,  we  de\u00fbne  the  load  \nfactor  \u02db for T as n=m , that is, the average number of elements stored in  a chain. \nOur  analysis  will  be in terms  of \u02db, which can be less than, equal to, or greater \nthan 1. \nThe  worst-case  behavior  of hashing  with  chaining  is terribl e: all n keys hash \nto the same slot, creating a list of length n. The  worst-case  time  for  searching  is \nthus \u201a.n/  plus  the  time  to compute  the  hash  function4no  better  than  using one \nlinked  list  for  all  the  elements.  We  clearly  don\u2019t  use  hash  tables  for  their  worst-case  \nperformance. \nThe  average-case  performance  of hashing  depends  on  how  well  the  hash  func-  \ntion h distributes the set of keys to be stored among the m slots, on the average \n(meaning with respect to the distribution of keys t o be hashed and with respect to \nthe choice of hash function, if this choice is rand omized). Section  11.3  discusses  \nthese issues, but for now we assume that any given element is equally likely to \nhash into any of the m slots. That is, the hash function is uniform . We further \nassume that where a given element hashes to is independent of where  any  other  el-  \nements hash to. In other words, we assume that we a re using independent  uniform  \nhashing . \nBecause hashes of distinct keys are assumed to be i ndependent, independent  uni-  \nform hashing is universal : the chance that any two distinct keys k 1 and k 2 collide is \nat most 1=m. Universality is important in our analysis and als o in the speci\u00fbcation  \nof universal  families  of hash  functions,  which  we\u2019ll  see  in Section  11.3.2.  \nFor j D 0; 1; : : : ; m  \ue003 1, denote the length of the list T \u0152j \ufffd  by n j , so that 11.2 Hash tables 279 \nn D n 0 C n 1 C \ue001 \ue001 \ue001 C  n m\ue0021 ; (11.1)  \nand the expected value of n j is E \u0152n j \ufffd D \u02db D n=m . \nWe assume that O.1/  time  suf\u00fbces  to compute  the  hash  value  h.k/ , so that \nthe time required to search for an element with key  k depends linearly on the \nlength n h.k/  of the list T \u0152h.k/\ufffd . Setting aside the O.1/  time required to compute \nthe hash function and to access slot h.k/, we\u2019ll  consider  the  expected  number  of \nelements examined by the search algorithm, that is,  the number of elements in the \nlist T \u0152h.k/\ufffd  that the algorithm checks to see whether any have a  key equal to k. We \nconsider  two  cases.  In the  \u00fbrst,  the  search  is unsuccessful:  no element in the table \nhas key k. In the  second,  the  search  successfully  \u00fbnds  an element  with  key k. \nTheorem  11.1  \nIn a hash table in which collisions are resolved by  chaining, an unsuccessful search \ntakes \u201a.1  C \u02db/  time on average, under the assumption of independen t uniform \nhashing. \nProof  Under the assumption of independent uniform hashing , any key k not  al-  \nready stored in the table is equally likely to hash  to any of the m slots. The expected \ntime to search unsuccessfully for a key k is the expected time to search to the end of \nlist T \u0152h.k/\ufffd , which has expected length E \u0152n h.k/  \ufffd D \u02db. Thus, the expected number \nof elements examined in an unsuccessful search is \u02db, and the total time required \n(including the time for computing h.k/ ) is \u201a.1  C \u02db/. \nThe situation for a successful search is slightly d ifferent. An unsuccessful search \nis equally likely to go to any slot of the hash tab le. A successful search, however, \ncannot go to an empty slot, since it is for an elem ent that is present in one of the \nlinked lists. We assume that the element searched f or is equally likely to be any \none of the elements in the table, so the longer the  list, the more likely that the \nsearch is for one of its elements. Even so, the exp ected search time still turns out \nto be \u201a.1  C \u02db/. \nTheorem  11.2  \nIn a hash table in which collisions are resolved by  chaining, a successful search \ntakes \u201a.1  C \u02db/  time on average, under the assumption of independen t uniform \nhashing. \nProof  We assume that the element being searched for is eq ually likely to be any \nof the n elements stored in the table. The number of element s examined during \na successful search for an element x is 1 more than the number of elements that \nappear before x in x \u2019s list.  Because  new  elements  are  placed  at the  front  of the  list, 280 Chapter 11 Hash Tables \nelements before x in the list were all inserted after x was inserted. Let x i denote \nthe i th element inserted into the table, for i D 1;2;:::;n , and let k i D x i : key. \nOur  analysis  uses  indicator  random  variables  extensively.  For each slot q in the \ntable and for each pair of distinct keys k i and k j , we  de\u00fbne  the  indicator  random  \nvariable \nX ij q D I fthe search is for x i , h.k  i / D q, and h.k  j / D q g : \nThat is, X ij q D 1 when keys k i and k j collide at slot q and the search is for \nelement x i . Because Pr fthe search is for x i g D  1=n, Pr fh.k  i / D qg D  1=m, \nPr fh.k  j / D qg D  1=m, and these events are all independent, we have tha t \nPr fX ij q D 1g D  1=nm  2 . Lemma  5.1  on  page  130  gives  E \u0152X  ij q \ufffd D 1=nm  2 . \nNext,  we  de\u00fbne,  for  each  element  x j , the indicator random variable \nY j D I fx j appears in a list prior to the element being search ed for g \nD m\ue0021 X  \nqD0 j \ue0021 X  \ni D1 X ij q ; \nsince at most one of the X ij q equals 1, namely when the element x i being searched \nfor belongs to the same list as x j (pointed to by slot q), and i < j  (so that x i \nappears after x j in the list). \nOur  \u00fbnal  random  variable  is Z, which counts how many elements appear in the \nlist prior to the element being searched for: \nZ D n X  \nj D1 Y j : \nBecause we must count the element being searched fo r as well as all  those  pre-  \nceding it in its list, we wish to compute E \u0152Z  C 1\ufffd. Using linearity of expectation \n(equation  (C.24)  on  page  1192),  we  have  \nE \u0152Z  C 1\ufffd D E \" \n1 C n X  \nj D1 Y j # \nD 1 C E \" n X  \nj D1 m\ue0021 X  \nqD0 j \ue0021 X  \ni D1 X ij q # \nD 1 C E \" m\ue0021 X  \nqD0 n X  \nj D1 j \ue0021 X  \ni D1 X ij q # \nD 1 C m\ue0021 X  \nqD0 n X  \nj D1 j \ue0021 X  \ni D1 E \u0152X  ij q \ufffd (by linearity of expectation) 11.2 Hash tables 281 \nD 1 C m\ue0021 X  \nqD0 n X  \nj D1 j \ue0021 X  \ni D1 1 \nnm  2 \nD 1 C m \ue001 n.n  \ue003 1/ \n2 \ue001 1 \nnm  2 (by  equation  (A.2)  on  page  1141)  \nD 1 C n \ue003 1 \n2m  \nD 1 C n \n2m  \ue003 1 \n2m  \nD 1 C \u02db \n2 \ue003 \u02db \n2n  : \nThus, the total time required for a successful sear ch (including  the  time  for  com-  \nputing the hash function) is \u201a.2  C \u02db=2  \ue003 \u02db=2n/  D \u201a.1  C \u02db/. \nWhat  does  this  analysis  mean?  If the  number  of elements  in the  table is at \nmost  proportional  to the  number  of hash-table  slots,  we  have  n D O.m/  and, \nconsequently, \u02db D n=m  D O.m/=m  D O.1/ . Thus, searching takes constant time \non average. Since insertion takes O.1/  worst-case  time  and  deletion  takes  O.1/  \nworst-case  time  when  the  lists  are  doubly  linked  (assuming  that the list element to \nbe deleted is known, and not just its key), we can support all dictionary operations \nin O.1/  time on average. \nThe analysis in the preceding two theorems depends only on two essential  prop-  \nerties of independent uniform hashing: uniformity ( each key is equally likely to \nhash to any one of the m slots), and independence (so any two distinct keys collide \nwith probability 1=m). \nExercises  \n11.2-1  \nYou use a hash function h to hash n distinct keys into an array T of length m. \nAssuming independent uniform hashing, what is the e xpected number  of colli-  \nsions?  More  precisely,  what  is the  expected  cardinality  of \u02da \nfk 1 ;k  2 g W  k 1 \u00a4 k 2 \nand h.k  1 / D h.k  2 / \ue009 ? \n11.2-2  \nConsider a hash table with 9 slots and the hash function h.k/  D k mod 9. Demon-  \nstrate what happens upon inserting the keys 5;28;19;15;20;33;12;17;10  with \ncollisions resolved by chaining. 282 Chapter 11 Hash Tables \n11.2-3  \nProfessor Marley hypothesizes that he can obtain su bstantial performance gains by \nmodifying the chaining scheme to keep each list in sorted order.  How  does  the  pro-  \nfessor\u2019s  modi\u00fbcation  affect  the  running  time  for  successfu l searches, unsuccessful \nsearches,  insertions,  and  deletions?  \n11.2-4  \nSuggest how to allocate and deallocate storage for elements within the hash table \nitself by creating a <free list=: a linked list of all the unused slots. Assume that \none  slot  can  store  a \u00fcag  and  either  one  element  plus  a pointer  or two pointers. All \ndictionary  and  free-list  operations  should  run  in O.1/  expected time. Does the free \nlist need to be doubly linked, or does a singly lin ked free list suf\u00fbce?  \n11.2-5  \nYou need to store a set of n keys in a hash table of size m. Show that if the keys \nare drawn from a universe U with jU j >.n  \ue003 1/m, then U has a subset of size n \nconsisting of keys that all hash to the same slot, so that the w orst-case  searching  \ntime for hashing with chaining is \u201a.n/ . \n11.2-6  \nYou have stored n keys in a hash table of size m, with  collisions  resolved  by  chain-  \ning, and you know the length of each chain, includi ng the length L of the longest \nchain. Describe a procedure that selects a key unif ormly at random from among \nthe keys in the hash table and returns it in expect ed time O.L  \ue001 .1 C 1=\u02db// . \n11.3  Hash  functions  \nFor hashing to work well, it needs a good hash func tion. Along with  being  ef\u00fb-  \nciently computable, what properties does a good has h function  have?  How  do  you  \ndesign  good  hash  functions?  \nThis  section  \u00fbrst  attempts  to answer  these  questions  based  on  two  ad hoc  ap-  \nproaches for creating hash functions: hashing by di vision and  hashing  by  multipli-  \ncation. Although these methods work well for some s ets of input keys, they are \nlimited  because  they  try  to provide  a single  \u00fbxed  hash  functi on that works well on \nany  data4an  approach  called  static  hashing . \nWe  then  see  that  provably  good  average-case  performance  for  any  data can be \nobtained by designing a suitable family  of hash  functions  and  choosing  a hash  func-  \ntion at random from this family at runtime, indepen dent of the data to be hashed. \nThe approach we examine is called random hashing. A  particular kind of random 11.3  Hash  functions  283 \nhashing, universal hashing, works well. As we saw w ith quicksort  in Chapter  7, \nrandomization is a powerful algorithmic design tool . \nWhat  makes  a good  hash  function?  \nA good  hash  function  satis\u00fbes  (approximately)  the  assumption  of independent  uni-  \nform hashing: each key is equally likely to hash to  any of the m slots,  indepen-  \ndently of where any other keys have hashed to. What  does <equally likely= mean \nhere?  If the  hash  function  is \u00fbxed,  any  probabilities  would  have to be based on the \nprobability distribution of the input keys. \nUnfortunately, you typically have no way to check t his condition, unless you \nhappen to know the probability distribution from wh ich the keys  are  drawn.  More-  \nover, the keys might not be drawn independently. \nOccasionally  you  might  know  the  distribution.  For  example,  if you know that \nthe keys are random real numbers k independently and uniformly distributed in the \nrange 0 \u0dc4 k<1 , then the hash function \nh.k/  D bkmc \nsatis\u00fbes  the  condition  of independent  uniform  hashing.  \nA good static hashing approach derives the hash val ue in a way that you expect \nto be independent of any patterns that might exist in the data. For example, the \n<division  method=  (discussed  in Section  11.3.1)  computes  the hash value as the \nremainder  when  the  key  is divided  by  a speci\u00fbed  prime  number.  This method may \ngive good results, if you (somehow) choose a prime number that is unrelated to any \npatterns in the distribution of keys. \nRandom  hashing,  described  in Section  11.3.2,  picks  the  hash  function to be used \nat random from a suitable family of hashing functio ns. This approach removes \nany need to know anything about the probability dis tribution of the input keys, as \nthe  randomization  necessary  for  good  average-case  behavio r then comes from the \n(known) random process used to pick the hash functi on from the family of hash \nfunctions, rather than from the (unknown) process u sed to create the input keys. \nWe recommend that you use random hashing. \nKeys  are  integers,  vectors,  or strings  \nIn practice, a hash function is designed to handle keys that are one of the following \ntwo types: \n\ue001 A short  nonnegative  integer  that  \u00fbts  in a w-bit  machine  word.  Typical  values  \nfor w would be 32  or 64. 284 Chapter 11 Hash Tables \n\ue001 A short vector of nonnegative integers, each of bou nded size. For example, \neach element might be an 8-bit  byte,  in which  case  the  vector  is often  called  a \n(byte) string. The vector might be of variable leng th. \nTo begin, we assume that keys are short nonnegative  integers. Handling vector \nkeys  is more  complicated  and  discussed  in Sections  11.3.5  and  11.5.2.  \n11.3.1  Static  hashing  \nStatic  hashing  uses  a single,  \u00fbxed  hash  function.  The  only  randomization available \nis through the (usually unknown) distribution of in put keys. This section discusses \ntwo standard approaches for static hashing: the div ision method  and  the  multiplica-  \ntion method. Although static hashing is no longer r ecommended, the multiplication \nmethod also provides a good foundation for <nonstat ic= hashing4better  known  as \nrandom  hashing4where  the  hash  function  is chosen  at random  from a suitable \nfamily of hash functions. \nThe  division  method  \nThe division  method  for creating hash functions maps a key k into one of m slots \nby taking the remainder of k divided by m. That is, the hash function is \nh.k/  D k mod m:  \nFor example, if the hash table has size m D 12  and the key is k D 100, then \nh.k/  D 4. Since it requires only a single division operatio n, hashing by division is \nquite fast. \nThe division method may work well when m is a prime not too close to an exact \npower of 2. There is no guarantee that this method provides g ood average-case  \nperformance, however, and it may complicate applica tions since it constrains the \nsize of the hash tables to be prime. \nThe  multiplication  method  \nThe general multiplication  method  for creating hash functions operates in two \nsteps. First, multiply the key k by a constant A in the range 0<A<1  and extract \nthe fractional part of kA. Then, multiply this value by m and  take  the  \u00fcoor  of the  \nresult. That is, the hash function is \nh.k/  D bm.kA  mod 1/c ; \nwhere <kA  mod 1= means the fractional part of kA, that is, kA\ue003bkAc. The general \nmultiplication method has the advantage that the va lue of m is not critical and you \ncan choose it independently of how you choose the m ultiplicative constant A. 11.3  Hash  functions  285 \n\u00d7 a D A2  w w bits \nk \nr 0 r 1 \nh a .k/  extract ` bits \nFigure  11.4  The  multiply-shift  method  to compute  a hash  function.  The  w-bit  representation  of \nthe key k is multiplied by the w-bit  value  a D A \ue001 2 w . The ` highest-order  bits  of the  lower  w-bit  \nhalf of the product form the desired hash value h a .k/. \nThe  multiply-shift  method  \nIn practice, the multiplication method is best in t he special case  where  the  num-  \nber m of hash-table  slots  is an exact  power  of 2, so that m D 2 ` for some integer `, \nwhere ` \u0dc4 w and w is the  number  of bits  in a machine  word.  If you  choose  a \u00fbxed  \nw-bit  positive  integer  a D A2  w , where 0<A<1  as in the multiplication method \nso that a is in the range 0 < a < 2  w , you can implement the function on most \ncomputers as follows. We assume that a key k \u00fbts  into  a single  w-bit  word.  \nReferring  to Figure  11.4,  \u00fbrst  multiply  k by the w-bit  integer  a. The result is a \n2w-bit  value  r 1 2 w C r 0 , where r 1 is the  high-order  w-bit  word  of the  product  and  \nr 0 is the  low-order  w-bit  word  of the  product.  The  desired  `-bit  hash  value  consists  \nof the ` most  signi\u00fbcant  bits  of r 0 . (Since r 1 is ignored, the hash function can be \nimplemented on a computer that produces only a w-bit  product  given  two  w-bit  \ninputs, that is, where the multiplication operation  computes modulo 2 w .) \nIn other  words,  you  de\u00fbne  the  hash  function  h D h a , where \nh a .k/  D .ka  mod 2 w / o  .w  \ue003 `/ (11.2)  \nfor  a \u00fbxed  nonzero  w-bit  value  a. Since the product ka  of two w-bit  words  occu-  \npies 2w  bits, taking this product modulo 2 w zeroes  out  the  high-order  w bits (r 1 ), \nleaving  only  the  low-order  w bits (r 0 ). The o  operator performs a logical right \nshift by w \ue003 ` bits, shifting zeros into the vacated positions on the left, so that the \n` most  signi\u00fbcant  bits  of r 0 move into the ` rightmost  positions.  (It\u2019s  the  same  as \ndividing by 2 w\ue002` and  taking  the  \u00fcoor  of the  result.)  The  resulting  value  equal s the \n` most  signi\u00fbcant  bits  of r 0 . The hash function h a can be implemented with three \nmachine instructions: multiplication, subtraction, and logical right shift. \nAs an example, suppose that k D 123456 , ` D 14, m D 2 14  D 16384 , and \nw D 32. Suppose further that we choose a D 2654435769  (following a suggestion 286 Chapter 11 Hash Tables \nof Knuth  [261]).  Then  ka  D 327706022297664  D .76300  \ue001 2 32  / C 17612864 , and \nso r 1 D 76300  and r 0 D 17612864 . The 14  most  signi\u00fbcant  bits  of r 0 yield the \nvalue h a .k/  D 67. \nEven  though  the  multiply-shift  method  is fast,  it doesn\u2019t  provide any guarantee \nof good  average-case  performance.  The  universal  hashing  approach presented in \nthe next section provides such a guarantee. A simpl e randomized variant of the \nmultiply-shift  method  works  well  on  the  average,  when  the  program begins by \npicking a as a randomly chosen odd integer. \n11.3.2  Random  hashing  \nSuppose that a malicious adversary chooses the keys  to be hashed  by  some  \u00fbxed  \nhash function. Then the adversary can choose n keys that all hash to the same slot, \nyielding an average retrieval time of \u201a.n/ . Any static hash function is vulnerable to \nsuch  terrible  worst-case  behavior.  The  only  effective  way  to improve the situation \nis to choose the hash function randomly  in a way that is independent of the keys \nthat are actually going to be stored. This approach  is called random  hashing . A \nspecial case of this approach, called universal  hashing , can yield provably good \nperformance on average when collisions are handled by chaining, no matter which \nkeys the adversary chooses. \nTo use random hashing, at the beginning of program execution you select the \nhash function at random from a suitable family of f unctions. As in the case of \nquicksort, randomization guarantees that no single input always  evokes  worst-case  \nbehavior. Because you randomly select the hash func tion, the algorithm  can  be-  \nhave differently on each execution, even for the sa me set of keys to be hashed, \nguaranteeing  good  average-case  performance.  \nLet H be a \u00fbnite  family  of hash  functions  that  map  a given  universe  U of keys \ninto the range f0;1;:::;m  \ue003 1g. Such a family is said to be universal  if for each \npair of distinct keys k 1 ;k  2 2 U , the number of hash functions h 2 H for which \nh.k  1 / D h.k  2 / is at most jH j =m. In other words, with a hash function randomly \nchosen from H , the chance of a collision between distinct keys k 1 and k 2 is no \nmore than the chance 1=m  of a collision if h.k  1 / and h.k  2 / were randomly and \nindependently chosen from the set f0;1;:::;m  \ue003 1g. \nIndependent uniform hashing is the same as picking a hash function uniformly at \nrandom from a family of m n hash functions, each member of that family mapping \nthe n keys to the m hash values in a different way. \nEvery independent uniform random family of hash fun ction is universal, but the \nconverse need not be true: consider the case where U D f0;1;:::;m  \ue003 1g and the \nonly hash function in the family is the identity fu nction. The probability that two \ndistinct keys collide is zero, even though each key  is hashes to a \u00fbxed  value.  11.3  Hash  functions  287 \nThe  following  corollary  to Theorem  11.2  on  page  279  says  that  universal  hash-  \ning provides the desired payoff: it becomes impossi ble for an adversary to pick a \nsequence  of operations  that  forces  the  worst-case  running  time. \nCorollary  11.3  \nUsing universal hashing and collision resolution by  chaining in an initially empty \ntable with m slots, it takes \u201a.s/  expected time to handle any sequence of s I NSERT , \nSEARCH , and D ELETE operations containing n D O.m/  I NSERT operations. \nProof  The I NSERT and D ELETE operations  take  constant  time.  Since  the  num-  \nber n of insertions is O.m/ , we have that \u02db D O.1/ . Furthermore, the expected \ntime for each S EARCH operation is O.1/ , which can be seen by examining the \nproof  of Theorem  11.2.  That  analysis  depends  only  on  collisi on probabilities, \nwhich are 1=m  for any pair k 1 ;k  2 of keys by the choice of an independent uniform \nhash function in that theorem. Using a universal fa mily of hash functions here \ninstead of using independent uniform hashing change s the probability of collision \nfrom 1=m  to at most 1=m. By linearity of expectation, therefore, the expec ted time \nfor the entire sequence of s operations is O.s/ . Since each operation takes \ufffd.1/  \ntime, the \u201a.s/  bound follows. \n11.3.3  Achievable  properties  of random  hashing  \nThere is a rich literature on the properties a fami ly H of hash functions can have, \nand  how  they  relate  to the  ef\u00fbciency  of hashing.  We  summarize  a few of the most \ninteresting ones here. \nLet H be a family of hash functions, each with domain U and range f0;1;:::;  \nm \ue003 1g, and let h be any hash function that is picked uniformly at ra ndom from H . \nThe probabilities mentioned are probabilities over the picks of h. \n\ue001 The family H is uniform  if for any key k in U and any slot q in the range \nf0;1;:::;m  \ue003 1g, the probability that h.k/  D q is 1=m. \n\ue001 The family H is universal  if for any distinct keys k 1 and k 2 in U , the probability \nthat h.k  1 / D h.k  2 / is at most 1=m. \n\ue001 The family H of hash functions is \ue002-universal  if for any distinct keys k 1 and k 2 \nin U , the probability that h.k  1 / D h.k  2 / is at most \ufffd . Therefore, a universal \nfamily of hash functions is also 1=m-universal.  2 \n2 In the literature, a .c=m/-universal  hash  function  is sometimes  called  c-universal  or c-approxi-  \nmately  universal.  We\u2019ll  stick  with  the  notation  .c=m/-universal.  288 Chapter 11 Hash Tables \n\ue001 The family H is d -independent  if for any distinct keys k 1 , k 2 , . . . , k d in U \nand any slots q 1 , q 2 , . . . , q d , not necessarily distinct, in f0;1;:::;m  \ue003 1g the \nprobability that h.k  i / D q i for i D 1;2;:::;d  is 1=m  d . \nUniversal  hash-function  families  are  of particular  interest,  as they  are  the  sim-  \nplest  type  supporting  provably  ef\u00fbcient  hash-table  operat ions for any input data \nset. Many other interesting and desirable propertie s, such as those noted above, are \nalso  possible  and  allow  for  ef\u00fbcient  specialized  hash-tabl e operations. \n11.3.4  Designing  a universal  family  of hash  functions  \nThis section present two ways to design a universal  (or \ufffd -universal)  family  of hash  \nfunctions: one based on number theory and another b ased on a randomized variant \nof the  multiply-shift  method  presented  in Section  11.3.1.  The  \u00fbrst  method  is a bit  \neasier to prove universal, but the second method is  newer and faster in practice. \nA universal  family  of hash  functions  based  on  number  theory  \nWe can design a universal family of hash functions using a little number theory. \nYou  may  wish  to refer  to Chapter  31  if you  are  unfamiliar  with  basic concepts in \nnumber theory. \nBegin by choosing a prime number p large enough so that every possible key k \nlies in the range 0 to p \ue003 1, inclusive. We assume here that p has a <reasonable= \nlength.  (See  Section  11.3.5  for  a discussion  of methods  for  handling long input \nkeys,  such  as variable-length  strings.)  Let  Z p denote the set f0;1;:::;p  \ue003 1g, and \nlet Z \ue003 \np denote the set f1;2;:::;p  \ue003 1g. Since p is prime, we can solve equations \nmodulo p with  the  methods  given  in Chapter  31.  Because  the  size  of the  universe \nof keys is greater than the number of slots in the hash table (otherwise, just use \ndirect addressing), we have p>m . \nGiven  any  a 2 Z \ue003 \np and any b 2 Z p , de\u00fbne  the  hash  function  h ab  as a linear \ntransformation followed by reductions modulo p and then modulo m: \nh ab  .k/  D ..ak  C b/ mod p/  mod m:  (11.3)  \nFor example, with p D 17  and m D 6, we have \nh 3;4  .8/  D ..3  \ue001 8 C 4/ mod 17/  mod 6 \nD .28  mod 17/  mod 6 \nD 11  mod 6 \nD 5:  \nGiven  p and m, the family of all such hash functions is \nH pm  D \u02da \nh ab  W a 2 Z \ue003 \np and b 2 Z p \ue009 \n: (11.4)  11.3  Hash  functions  289 \nEach hash function h ab  maps Z p to Z m . This family of hash functions has the nice \nproperty that the size m of the output range (which is the size of the hash table) is \narbitrary4it  need  not  be prime.  Since  you  can  choose  from  among p \ue003 1 values \nfor a and p values for b, the family H pm  contains p.p  \ue003 1/ hash functions. \nTheorem  11.4  \nThe family H pm  of hash  functions  de\u00fbned  by  equations  (11.3)  and  (11.4)  is uni-  \nversal. \nProof  Consider two distinct keys k 1 and k 2 from Z p , so that k 1 \u00a4 k 2 . For a given \nhash function h ab  , let \nr 1 D .ak  1 C b/ mod p;  \nr 2 D .ak  2 C b/ mod p:  \nWe  \u00fbrst  note  that  r 1 \u00a4 r 2 . Why?  Since  we  have  r 1 \ue003 r 2 D a.k  1 \ue003 k 2 / .mod p/, \nit follows that r 1 \u00a4 r 2 because p is prime and both a and .k 1 \ue003 k 2 / are nonzero \nmodulo p. By  Theorem  31.6  on  page  908,  their  product  must  also  be nonze ro \nmodulo p. Therefore, when computing any h ab  2 H pm  , distinct inputs k 1 and k 2 \nmap to distinct values r 1 and r 2 modulo p, and there are no collisions yet at the \n<mod p level.= Moreover, each of the possible p.p  \ue003 1/ choices for the pair .a;b/  \nwith a \u00a4 0 yields a different resulting pair .r 1 ;r 2 / with r 1 \u00a4 r 2 , since we can solve \nfor a and b given r 1 and r 2 : \na D \u00e3 .r 1 \ue003 r 2 /..k  1 \ue003 k 2 / \ue0021 mod p/  \u00e4 mod p;  \nb D .r 1 \ue003 ak  1 / mod p;  \nwhere ..k  1 \ue003 k 2 / \ue0021 mod p/  denotes the unique multiplicative inverse, modulo p, \nof k 1 \ue003 k 2 . For each of the p possible values of r 1 , there are only p \ue003 1 possible \nvalues of r 2 that do not equal r 1 , making only p.p  \ue003 1/ possible pairs .r 1 ;r 2 / with \nr 1 \u00a4 r 2 . Therefore,  there  is a one-to-one  correspondence  between  pairs .a;b/  with \na \u00a4 0 and pairs .r 1 ;r 2 / with r 1 \u00a4 r 2 . Thus, for any given pair of distinct inputs \nk 1 and k 2 , if we pick .a;b/  uniformly at random from Z \ue003 \np \ue005 Z p , the resulting pair \n.r 1 ;r 2 / is equally likely to be any pair of distinct values  modulo p. \nTherefore, the probability that distinct keys k 1 and k 2 collide is equal to the \nprobability that r 1 D r 2 .mod m/  when r 1 and r 2 are randomly chosen as distinct \nvalues modulo p. For a given value of r 1 , of the p \ue003 1 possible remaining values \nfor r 2 , the number of values r 2 such that r 2 \u00a4 r 1 and r 2 D r 1 .mod m/  is at most \nl p \nm m \n\ue003 1 \u0dc4 p C m \ue003 1 \nm \ue003 1 (by  inequality  (3.7)  on  page  64)  \nD p \ue003 1 \nm : 290 Chapter 11 Hash Tables \nThe probability that r 2 collides with r 1 when reduced modulo m is at most \n..p  \ue003 1/=m/=.p  \ue003 1/ D 1=m, since r 2 is equally likely to be any of the p \ue003 1 \nvalues in Z p that are different from r 1 , but at most .p  \ue003 1/=m  of those values are \nequivalent to r 1 modulo m. \nTherefore, for any pair of distinct values k 1 ;k  2 2 Z p , \nPr fh ab  .k 1 / D h ab  .k 2 /g \u0dc4  1=m;  \nso that H pm  is indeed universal. \nA 2=m-universal  family  of hash  functions  based  on  the  multiply-shift  method  \nWe  recommend  that  in practice  you  use  the  following  hash-fun ction family based \non  the  multiply-shift  method.  It is exceptionally  ef\u00fbcient  and (although we omit \nthe proof) provably 2=m-universal.  De\u00fbne  H to be the  family  of multiply-shift  \nhash functions with odd constants a: \nH D fh a W a is odd, 1 \u0dc4 a<m , and h a is de\u00fbned  by  equation  (11.2) g : (11.5)  \nTheorem  11.5  \nThe family of hash functions H given  by  equation  (11.5)  is 2=m-universal.  \nThat is, the probability that any two distinct keys  collide is at most 2=m . In \nmany practical situations, the speed of computing t he hash function more than \ncompensates for the higher upper bound on the proba bility that two distinct keys \ncollide when compared with a universal hash functio n. \n11.3.5  Hashing  long  inputs  such  as vectors  or strings  \nSometimes hash function inputs are so long that the y cannot be easily encoded \nmodulo a reasonably sized prime number p or encoded within a single word of, \nsay, 64  bits. As an example, consider the class of vectors,  such as vectors of 8-bit  \nbytes (which is how strings in many programming lan guages are stored). A vector \nmight have an arbitrary nonnegative length, in whic h case the length of the input \nto the hash function may vary from input to input. \nNumber-theoretic  approaches  \nOne  way  to design  good  hash  functions  for  variable-length  inputs is to extend the \nideas  used  in Section  11.3.4  to design  universal  hash  functions.  Exercise  11.3-6  \nexplores one such approach. 11.3  Hash  functions  291 \nCryptographic  hashing  \nAnother  way  to design  a good  hash  function  for  variable-leng th inputs is to use a \nhash function designed for cryptographic applicatio ns. Cryptographic  hash  func-  \ntions  are complex pseudorandom functions, designed for ap plications requiring \nproperties beyond those needed here, but are robust , widely implemented,  and  us-  \nable as hash functions for hash tables. \nA cryptographic hash function takes as input an arb itrary byte string and returns \na \u00fbxed-length  output.  For  example,  the  NIST  standard  determ inistic cryptographic \nhash  function  SHA-256  [346]  produces  a 256-bit  (32-byte)  output  for  any  input.  \nSome chip manufacturers include instructions in the ir CPU architectures  to pro-  \nvide fast implementations of some cryptographic fun ctions. Of  particular  inter-  \nest  are  instructions  that  ef\u00fbciently  implement  rounds  of the Advanced Encryption \nStandard  (AES),  the  <AES-NI=  instructions.  These  instruct ions execute in a few \ntens of nanoseconds, which is generally fast enough  for use with hash tables. A \nmessage  authentication  code  such  as CBC-MAC  based  on  AES  and  the use of the \nAES-NI  instructions  could  be a useful  and  ef\u00fbcient  hash  function.  We  don\u2019t  pursue  \nthe potential use of specialized instruction sets f urther here. \nCryptographic hash functions are useful because the y provide a way  of imple-  \nmenting an approximate version of a random oracle. As noted earlier, a random \noracle is equivalent to an independent uniform hash  function family.  From  a the-  \noretical point of view, a random oracle is an unach ievable ideal: a deterministic \nfunction that provides a randomly selected output f or each input.  Because  it is de-  \nterministic, it provides the same output if queried  again for the same input. From \na practical point of view, constructions of hash fu nction families  based  on  crypto-  \ngraphic hash functions are sensible substitutes for  random oracles. \nThere are many ways to use a cryptographic hash fun ction as a hash function. \nFor  example,  we  could  de\u00fbne  \nh.k/  D SHA-256  .k/  mod m:  \nTo  de\u00fbne  a family  of such  hash  functions  one  may  prepend  a <salt= string a to the \ninput before hashing it, as in \nh a .k/  D SHA-256  .a k k/  mod m;  \nwhere a k k denotes the string formed by concatenating the stri ngs a and k. The  lit-  \nerature on message authentication codes (MACs) prov ides additional approaches. \nCryptographic  approaches  to hash-function  design  are  becoming  more  practi-  \ncal as computers arrange their memories in hierarch ies of differing capacities and \nspeeds.  Section  11.5  discusses  one  hash-function  design  based  on  the  RC6  encryp-  \ntion method. 292 Chapter 11 Hash Tables \nExercises  \n11.3-1  \nYou wish to search a linked list of length n, where each element contains a key \nk along with a hash value h.k/ . Each key is a long character string. How might \nyou take advantage of the hash values when searchin g the list for an element with \na given  key?  \n11.3-2  \nYou hash a string of r characters into m slots  by  treating  it as a radix-128  number  \nand then using the division method. You can represe nt the number m as a 32-bit  \ncomputer word, but the string of r characters,  treated  as a radix-128  number,  takes  \nmany words. How can you apply the division method t o compute the hash value of \nthe character string without using more than a cons tant number of words of storage \noutside  the  string  itself?  \n11.3-3  \nConsider a version of the division method in which h.k/  D k mod m, where \nm D 2 p \ue003 1 and k is a character string interpreted in radix 2 p . Show that if string x \ncan be converted to string y by permuting its characters, then x and y hash to the \nsame  value.  Give  an example  of an application  in which  this  property would be \nundesirable in a hash function. \n11.3-4  \nConsider a hash table of size m D 1000  and a corresponding hash function h.k/  D \nbm.kA  mod 1/c for A D . p \n5 \ue003 1/=2 . Compute the locations to which the keys \n61, 62, 63, 64, and 65  are mapped. \n? 11.3-5  \nShow that any \ufffd -universal  family  H of hash  functions  from  a \u00fbnite  set  U to a \u00fbnite  \nset Q has \ufffd \ue004 1=  jQj \ue003  1=  jU j. \n? 11.3-6  \nLet U be the set of d -tuples  of values  drawn  from  Z p , and let Q D Z p , where p \nis prime.  De\u00fbne  the  hash  function  h b W U !  Q for b 2 Z p on an input d -tuple  \nha 0 ;a  1 ;:::;a  d \ue0021 i from U as \nh b .ha 0 ;a  1 ;:::;a  d \ue0021 i/ D \ue001 d \ue0021 X  \nj D0 a j b j ! \nmod p;  \nand let H D fh b W b 2 Z p g. Argue that H is \ufffd -universal  for  \ufffd D .d \ue003 1/=p . (Hint: \nSee  Exercise  31.4-4.)  11.4 Open addressing 293 \n11.4  Open  addressing  \nThis section describes open addressing, a method fo r collision  resolution  that,  un-  \nlike chaining, does not make use of storage outside  of the hash table itself. In open  \naddressing , all elements occupy the hash table itself. That i s, each table entry  con-  \ntains either an element of the dynamic set or NIL. No lists or elements are stored \noutside the table, unlike in chaining. Thus, in ope n addressing, the hash table can \n<\u00fbll  up=  so that  no  further  insertions  can  be made.  One  conseq uence is that the \nload factor \u02db can never exceed 1. \nCollisions are handled as follows: when a new eleme nt is to be inserted into the \ntable,  it is placed  in its  <\u00fbrst-choice=  location  if possibl e. If that location is already \noccupied,  the  new  element  is placed  in its  <second-choice=  location. The process \ncontinues until an empty slot is found in which to place the new element. Different \nelements have different preference orders for the l ocations. \nTo search for an element, systematically examine th e preferred table slots for \nthat element, in order of decreasing preference, un til either you  \u00fbnd  the  desired  \nelement  or you  \u00fbnd  an empty  slot  and  thus  verify  that  the  eleme nt is not in the \ntable. \nOf  course,  you  could  use  chaining  and  store  the  linked  lists  inside the hash table, \nin the  otherwise  unused  hash-table  slots  (see  Exercise  11.2-4),  but  the  advantage  of \nopen addressing is that it avoids pointers altogeth er. Instead of following pointers, \nyou compute the sequence of slots to be examined. T he memory freed by not \nstoring pointers provides the hash table with a lar ger number of slots in the same \namount of memory, potentially yielding fewer collis ions and faster retrieval. \nTo perform insertion using open addressing, success ively examine, or probe , the \nhash  table  until  you  \u00fbnd  an empty  slot  in which  to put  the  key.  Instead of being \n\u00fbxed  in the  order  0;1;:::;m  \ue003 1 (which implies a \u201a.n/  search time), the sequence \nof positions probed depends upon the key being inse rted. To determine which slots \nto probe, the hash function includes the probe numb er (starting from 0) as a second \ninput. Thus, the hash function becomes \nh W U \ue005 f0;1;:::;m  \ue003 1g ! f0;1;:::;m  \ue003 1g : \nOpen  addressing  requires  that  for  every  key  k, the probe  sequence  hh.k;0/;h.k;1/;  \n:::;h.k;m  \ue003 1/i be a permutation of h0;1;:::;m  \ue003 1i, so that  every  hash-table  \nposition is eventually considered as a slot for a n ew key as th e table  \u00fblls  up.  The  \nHASH-I NSERT procedure on the following page assumes that the el ements in the \nhash table T are keys with no satellite information: the key k is identical to the \nelement containing key k. Each slot contains either a key or NIL (if the slot is \nempty). The H ASH-I NSERT procedure takes as input a hash table T and a key k 294 Chapter 11 Hash Tables \nthat is assumed to be not already present in the ha sh table. It either returns the slot \nnumber where it stores key k or \u00fcags  an error  because  the  hash  table  is already  full.  \nHASH-I NSERT .T;k/  \n1 i D 0 \n2 repeat  \n3 q D h.k;i/  \n4 if T \u0152q\ufffd  == NIL \n5 T \u0152q\ufffd  D k \n6 return  q \n7 else  i D i C 1 \n8 until  i = = m \n9 error  <hash  table  over\u00fcow=  \nHASH-SEARCH.T;k/  \n1 i D 0 \n2 repeat  \n3 q D h.k;i/  \n4 if T \u0152q\ufffd  == k \n5 return  q \n6 i D i C 1 \n7 until  T \u0152q\ufffd  = = NIL or i == m \n8 return  NIL \nThe algorithm for searching for key k probes the same sequence of slots that the \ninsertion algorithm examined when key k was inserted. Therefore, the search can \nterminate  (unsuccessfully)  when  it \u00fbnds  an empty  slot,  since k would have been \ninserted there and not later in its probe sequence.  The procedure H ASH-SEARCH \ntakes as input a hash table T and a key k, returning q if it \u00fbnds  that  slot  q contains \nkey k, or NIL if key k is not present in table T . \nDeletion  from  an open-address  hash  table  is tricky.  When  you  delete a key from \nslot q, it would be a mistake to mark that slot as empty by simply storing NIL in \nit. If you did, you might be unable to retrieve any  key k for which slot q was \nprobed and found occupied when k was  inserted.  One  way  to solve  this  problem  \nis by marking the slot, storing in it the special v alue DELETED instead of NIL. The \nHASH-I NSERT procedure then has to treat such a slot as empty so  that it can insert \na new key there. The H ASH-SEARCH procedure passes over DELETED values \nwhile searching, since slots containing DELETED were  \u00fblled  when  the  key  being  \nsearched for was inserted. Using the special value DELETED , however, means that \nsearch times no longer depend on the load factor \u02db, and for this reason chaining is 11.4 Open addressing 295 \nfrequently selected as a collision resolution techn ique when keys must be deleted. \nThere is a simple special case of open addressing, linear probing, that avoids the \nneed to mark slots with DELETED. Section  11.5.1  shows  how  to delete  from  a hash  \ntable when using linear probing. \nIn our analysis, we assume independent  uniform  permutation  hashing  (also \nconfusingly known as uniform  hashing  in the literature): the probe sequence of \neach key is equally likely to be any of the m\u0160  permutations of h0;1;:::;m  \ue003 1i. \nIndependent uniform permutation hashing generalizes  the notion of independent \nuniform  hashing  de\u00fbned  earlier  to a hash  function  that  produ ces not just a single \nslot number, but a whole probe sequence. True indep endent uniform permutation \nhashing  is dif\u00fbcult  to implement,  however,  and  in practice  suitable approximations \n(such  as double  hashing,  de\u00fbned  below)  are  used.  \nWe\u2019ll  examine  both  double  hashing  and  its  special  case,  linear probing. These \ntechniques guarantee that hh.k;0/;h.k;1/;:::;h.k;m  \ue003 1/i is a permutation \nof h0;1;:::;m  \ue003 1i for each key k. (Recall that the second parameter to the hash \nfunction h is the probe number.) Neither double hashing nor li near probing meets \nthe assumption of independent uniform permutation h ashing, however. Double \nhashing cannot generate more than m 2 different probe sequences (instead of the \nm\u0160  that independent uniform permutation hashing requir es). Nonetheless, double \nhashing has a large number of possible probe sequen ces and, as you might expect, \nseems to give good results. Linear probing is even more restricted, capable of \ngenerating only m different probe sequences. \nDouble  hashing  \nDouble hashing offers one of the best methods avail able for open  addressing  be-  \ncause the permutations produced have many of the ch aracteristics of randomly \nchosen permutations. Double  hashing  uses a hash function of the form \nh.k;i/  D .h 1 .k/  C ih  2 .k//  mod m;  \nwhere both h 1 and h 2 are auxiliary  hash  functions. The  initial  probe  goes  to posi-  \ntion T\u0152h  1 .k/\ufffd, and successive probe positions are offset from pr evious positions by \nthe amount h 2 .k/, modulo m. Thus, the probe sequence here depends in two ways  \nupon the key k, since the initial probe position h 1 .k/, the step size h 2 .k/, or both, \nmay  vary.  Figure  11.5  gives  an example  of insertion  by  double  hashing. \nIn order for the entire hash table to be searched, the value h 2 .k/  must  be rel-  \natively  prime  to the  hash-table  size  m. (See  Exercise  11.4-5.)  A convenient  way  \nto ensure this condition is to let m be an exact power of 2 and to design h 2 so \nthat it always produces an odd number. Another way is to let m be prime and to \ndesign h 2 so that it always returns a positive integer less t han m. For example, you 296 Chapter 11 Hash Tables \n0 \n1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10  \n11  \n12  79  \n69  \n98  \n72  \n14  \n50  \nFigure  11.5  Insertion by double hashing. The hash table has siz e 13  with h 1 .k/  D k mod 13  and \nh 2 .k/  D 1 C .k mod 11/. Since 14  D 1 .mod 13/  and 14  D 3 .mod 11/, the key 14  goes into \nempty slot 9, after slots 1 and 5 are examined and found to be occupied. \ncould choose m prime and let \nh 1 .k/  D k mod m;  \nh 2 .k/  D 1 C .k mod m 0 /; \nwhere m 0 is chosen to be slightly less than m (say, m \ue003 1). For example, if \nk D 123456 , m D 701, and m 0 D 700, then h 1 .k/  D 80  and h 2 .k/  D 257, so \nthat  the  \u00fbrst  probe  goes  to position  80, and successive probes examine every 257th \nslot (modulo m) until the key has been found or every slot has be en examined. \nAlthough values of m other than primes or exact powers of 2 can in principle \nbe used  with  double  hashing,  in practice  it becomes  more  dif\u00fbcult  to ef\u00fbciently  \ngenerate h 2 .k/  (other than choosing h 2 .k/  D 1, which gives linear probing) in a \nway that ensures that it is relatively prime to m, in part because the relative density \n\ufffd.m/=m  of such numbers for general m may  be small  (see  equation  (31.25)  on  \npage  921).  \nWhen m is prime or an exact power of 2, double hashing produces \u201a.m  2 / probe \nsequences, since each possible .h 1 .k/;h  2 .k//  pair yields a distinct probe sequence. \nAs a result, for such values of m, double hashing appears to perform close to the \n<ideal= scheme of independent uniform permutation h ashing. 11.4 Open addressing 297 \nLinear  probing  \nLinear  probing, a special  case  of double  hashing,  is the  simplest  open-addr essing \napproach to resolving collisions. As with double ha shing, an auxiliary  hash  func-  \ntion h 1 determines  the  \u00fbrst  probe  position  h 1 .k/  for inserting an element. If slot \nT\u0152h  1 .k/\ufffd  is already occupied, probe the next position T\u0152h  1 .k/  C 1\ufffd. Keep  going  as \nnecessary, on up to slot T\u0152m  \ue003 1\ufffd, and then wrap around to slots T \u01520\ufffd, T \u01521\ufffd, and so \non, but never going past slot T\u0152h  1 .k/  \ue003 1\ufffd. To view linear probing as a special case \nof double  hashing,  just  set  the  double-hashing  step  functio n h 2 to be \u00fbxed  at 1: \nh 2 .k/  D 1 for all k. That is, the hash function is \nh.k;i/  D .h 1 .k/  C i/ mod m (11.6)  \nfor i D 0;1;:::;m  \ue003 1. The value of h 1 .k/  determines the entire probe sequence, \nand so assuming that h 1 .k/  can take on any value in f0;1;:::;m  \ue003 1g, linear  prob-  \ning allows only m distinct probe sequences. \nWe\u2019ll  revisit  linear  probing  in Section  11.5.1.  \nAnalysis  of open-address  hashing  \nAs  in our  analysis  of chaining  in Section  11.2,  we  analyze  open addressing in terms \nof the load factor \u02db D n=m  of the hash table. With open addressing, at most on e \nelement occupies each slot, and thus n \u0dc4 m, which implies \u02db \u0dc4 1. The analysis \nbelow requires \u02db to be strictly less than 1, and so we assume that at least one slot \nis empty.  Because  deleting  from  an open-address  hash  table  does not really free up \na slot, we assume as well that no deletions occur. \nFor the hash function, we assume independent unifor m permutation hashing. In \nthis idealized scheme, the probe sequence hh.k;0/;h.k;1/;:::;h.k;m  \ue003 1/i used \nto insert or search for each key k is equally likely to be any permutation of h0;1;  \n:::;m  \ue003 1i. Of  course,  any  given  key  has  a unique  \u00fbxed  probe  sequence  associated \nwith it. What we mean here is that, considering the  probability distribution on the \nspace of keys and the operation of the hash functio n on the keys, each possible \nprobe sequence is equally likely. \nWe now analyze the expected number of probes for ha shing with open  address-  \ning under the assumption of independent uniform per mutation hashing, beginning \nwith the expected number of probes made in an unsuc cessful search (assuming, as \nstated above, that \u02db<1 ). \nThe bound proven, of 1=.1  \ue003 \u02db/  D 1 C \u02db C \u02db 2 C \u02db 3 C \ue001 \ue001 \ue001, has  an intuitive  in-  \nterpretation.  The  \u00fbrst  probe  always  occurs.  With  probabili ty approximately \u02db, the \n\u00fbrst  probe  \u00fbnds  an occupied  slot,  so that  a second  probe  happe ns. With probability \napproximately \u02db 2 , the  \u00fbrst  two  slots  are  occupied  so that  a third  probe  ensues,  and \nso on. 298 Chapter 11 Hash Tables \nTheorem  11.6  \nGiven  an open-address  hash  table  with  load  factor  \u02db D n=m  < 1, the expected \nnumber of probes in an unsuccessful search is at mo st 1=.1  \ue003 \u02db/, assuming  inde-  \npendent uniform permutation hashing and no deletion s. \nProof  In an unsuccessful search, every probe but the last  accesses an occupied \nslot that does not contain the desired key, and the  last slot probed is empty. Let the \nrandom variable X denote the number of probes made in an unsuccessful  search, \nand  de\u00fbne  the  event  A i , for i D 1;2;::: , as the event that an i th probe occurs \nand it is to an occupied slot. Then the event fX \ue004 i g is the intersection of events \nA 1 \\A 2 \\\ue001 \ue001 \ue001\\A i \ue0021 . We bound Pr fX \ue004 i g by bounding Pr fA 1 \\ A 2 \\ \ue001 \ue001 \ue001 \\  A i \ue0021 g. \nBy  Exercise  C.2-5  on  page  1190,  \nPr fA 1 \\ A 2 \\ \ue001 \ue001 \ue001 \\  A i \ue0021 g D  Pr fA 1 g \ue001 Pr fA 2 j A 1 g \ue001 Pr fA 3 j A 1 \\ A 2 g \ue001 \ue001 \ue001  \nPr fA i \ue0021 j A 1 \\ A 2 \\ \ue001 \ue001 \ue001 \\  A i \ue0022 g : \nSince there are n elements and m slots, Pr fA 1 g D  n=m . For j >1 , the probability \nthat there is a j th probe  and  it is to an occupied  slot,  given  that  the  \u00fbrst  j \ue003 1 \nprobes were to occupied slots, is .n \ue003 j C 1/=.m  \ue003 j C 1/. This probability follows \nbecause the j th probe  would  be \u00fbnding  one  of the  remaining  .n \ue003 .j \ue003 1//  elements \nin one of the .m  \ue003 .j \ue003 1//  unexamined slots, and by the assumption of independ ent \nuniform permutation hashing, the probability is the  ratio of these quantities. Since \nn<m  implies that .n \ue003 j/=.m  \ue003 j/  \u0dc4 n=m  for all j in the range 0 \u0dc4 j <m , it \nfollows that for all i in the range 1 \u0dc4 i \u0dc4 m, we have \nPr fX \ue004 i g D  n \nm \ue001 n \ue003 1 \nm \ue003 1 \ue001 n \ue003 2 \nm \ue003 2 \ue001 \ue001 \ue001  n \ue003 i C 2 \nm \ue003 i C 2 \n\u0dc4 \ue002 n \nm \u00cd i \ue0021 \nD \u02db i \ue0021 : \nThe  product  in the  \u00fbrst  line  has  i \ue003 1 factors. When i D 1, the product is 1, the \nidentity for multiplication, and we get Pr fX \ue004 1g D  1, which makes sense, since \nthere must always be at least 1 probe.  If each  of the  \u00fbrst  n probes is to an occupied \nslot, then all occupied slots have been probed. The n, the .n C 1/st probe must \nbe to an empty slot, which gives Pr fX \ue004 i g D  0 for i > n  C 1. Now, we use \nequation  (C.28)  on  page  1193  to bound  the  expected  number  of probes: \nE \u0152X\ufffd  D 1  X  \ni D1 Pr fX \ue004 i g \nD nC1 X  \ni D1 Pr fX \ue004 i g C  X  \ni>nC1 Pr fX \ue004 i g 11.4 Open addressing 299 \n\u0dc4 1  X  \ni D1 \u02db i \ue0021 C 0 \nD 1  X  \ni D0 \u02db i \nD 1 \n1 \ue003 \u02db (by  equation  (A.7)  on  page  1142  because  0 \u0dc4 \u02db<1 ) . \nIf \u02db is a constant,  Theorem  11.6  predicts  that  an unsuccessful  search runs in O.1/  \ntime. For example, if the hash table is half full, the average number of probes in an \nunsuccessful search is at most 1=.1  \ue003 :5/  D 2. If it is 90% full, the average number \nof probes is at most 1=.1  \ue003 :9/  D 10. \nTheorem  11.6  yields  almost  immediately  how  well  the  HASH-I NSERT procedure \nperforms. \nCorollary  11.7  \nInserting  an element  into  an open-address  hash  table  with  load factor \u02db, where \n\u02db<1 , requires at most 1=.1  \ue003 \u02db/  probes  on  average,  assuming  independent  uni-  \nform permutation hashing and no deletions. \nProof  An element is inserted only if there is room in the  table, and thus \u02db <1 . \nInserting a key requires an unsuccessful search fol lowed by placing the key into the \n\u00fbrst  empty  slot  found.  Thus,  the  expected  number  of probes  is at most 1=.1  \ue003 \u02db/. \nIt takes a little more work to compute the expected  number of p robes  for  a suc-  \ncessful search. \nTheorem  11.8  \nGiven  an open-address  hash  table  with  load  factor  \u02db<1 , the expected number of \nprobes in a successful search is at most \n1 \n\u02db ln 1 \n1 \ue003 \u02db ; \nassuming independent uniform permutation hashing wi th no deletions  and  assum-  \ning that each key in the table is equally likely to  be searched for. \nProof  A search for a key k reproduces the same probe sequence as when the \nelement with key k was inserted. If k was the .i C 1/st key inserted into the \nhash table, then the load factor at the time it was  inserted was i=m, and so by \nCorollary  11.7,  the  expected  number  of probes  made  in a searc h for k is at most \n1=.1  \ue003 i=m/  D m=.m  \ue003 i/. Averaging over all n keys in the hash table gives us 300 Chapter 11 Hash Tables \nthe expected number of probes in a successful searc h: \n1 \nn n\ue0021 X  \ni D0 m \nm \ue003 i D m \nn n\ue0021 X  \ni D0 1 \nm \ue003 i \nD 1 \n\u02db m X  \nkDm\ue002nC1 1 \nk \n\u0dc4 1 \n\u02db Z m \nm\ue002n 1 \nx dx  (by  inequality  (A.19)  on  page  1150)  \nD 1 \n\u02db .ln m \ue003 ln.m  \ue003 n//  \nD 1 \n\u02db ln m \nm \ue003 n \nD 1 \n\u02db ln 1 \n1 \ue003 \u02db : \nIf the hash table is half full, the expected number  of probes in a successful search \nis less than 1:387 . If the hash table is 90% full, the expected number of probes is \nless than 2:559 . If \u02db D 1, then in an unsuccessful search, all m slots must be \nprobed.  Exercise  11.4-4  asks  you  to analyze  a successful  search when \u02db D 1. \nExercises  \n11.4-1  \nConsider inserting the keys 10;22;31;4;15;28;17;88;59  into a hash table of \nlength m D 11  using open addressing. Illustrate the result of ins erting these keys \nusing linear probing with h.k;i/  D .k C i/ mod m and using double hashing with \nh 1 .k/  D k and h 2 .k/  D 1 C .k mod .m  \ue003 1//. \n11.4-2  \nWrite pseudocode for H ASH-DELETE that  \u00fblls  the  deleted  key\u2019s  slot  with  the  spe-  \ncial value DELETED , and modify H ASH-SEARCH and H ASH-I NSERT as needed to \nhandle DELETED . \n11.4-3  \nConsider  an open-address  hash  table  with  independent  uniform  permutation  hash-  \ning  and  no  deletions.  Give  upper  bounds  on  the  expected  numbe r of probes in an \nunsuccessful search and on the expected number of p robes in a successful search \nwhen the load factor is 3=4  and when it is 7=8. 11.5  Practical  considerations  301 \n11.4-4  \nShow that the expected number of probes required fo r a successful search when \n\u02db D 1 (that is, when n D m), is H m , the mth harmonic number. \n? 11.4-5  \nShow that, with double hashing, if m and h 2 .k/  have greatest common divisor \nd \ue004 1 for some key k, then an unsuccessful search for key k examines .1=d/ th \nof the hash table before returning to slot h 1 .k/. Thus, when d D 1, so that m \nand h 2 .k/  are relatively prime, the search may examine the en tire hash table. ( Hint: \nSee  Chapter  31.)  \n? 11.4-6  \nConsider  an open-address  hash  table  with  a load  factor  \u02db. Approximate the nonzero \nvalue \u02db for which the expected number of probes in an unsuc cessful search equals \ntwice the expected number of probes in a successful  search. Use the upper bounds \ngiven  by  Theorems  11.6  and  11.8  for  these  expected  numbers  of probes. \n11.5  Practical  considerations  \nEf\u00fbcient  hash  table  algorithms  are  not  only  of theoretical  interest,  but  also  of im-  \nmense practical importance. Constant factors can ma tter. For this reason, this \nsection discusses two aspects of modern CPUs that a re not included in the standard \nRAM model presented in Section 2.2: \nMemory  hierarchies:  The memory of modern CPUs has a number of levels, \nfrom the fast registers, through one or more levels  of cache  memory , to the \nmain-memory  level.  Each  successive  level  stores  more  data  than the previous \nlevel, but access is slower. As a consequence, a co mplex computation (such as \na complicated hash function) that works entirely wi thin the fast registers can \ntake less time than a single read operation from ma in memory. Furthermore, \ncache memory is organized in cache  blocks  of (say) 64  bytes each, which are \nalways fetched together from main memory. There is a substantial  bene\u00fbt  for  \nensuring that memory usage is local: reusing the sa me cache block is much \nmore  ef\u00fbcient  than  fetching  a different  cache  block  from  main memory. \nThe  standard  RAM  model  measures  ef\u00fbciency  of a hash-table  operation by \ncounting  the  number  of hash-table  slots  probed.  In practice , this metric is only \na crude approximation to the truth, since once a ca che block is in the cache, \nsuccessive probes to that cache block are much fast er than probes that must \naccess main memory. 302 Chapter 11 Hash Tables \nAdvanced  instruction  sets:  Modern CPUs may have sophisticated instruction \nsets that implement advanced primitives useful for encryption or other forms \nof cryptography. These instructions may be useful i n the design  of exception-  \nally  ef\u00fbcient  hash  functions.  \nSection  11.5.1  discusses  linear  probing,  which  becomes  the  collision-resolution  \nmethod of choice in the presence of a memory hierar chy. Section  11.5.2  suggests  \nhow to construct <advanced= hash functions based on  cryptographic primitives, \nsuitable for use on computers with hierarchical mem ory models. \n11.5.1  Linear  probing  \nLinear probing is often disparaged because of its p oor performance in the standard \nRAM model. But linear probing excels for hierarchic al memory models, because \nsuccessive probes are usually to the same cache blo ck of memory. \nDeletion  with  linear  probing  \nAnother reason why linear probing is often not used  in practice is that deletion \nseems complicated or impossible without using the s pecial DELETED value. Yet \nwe\u2019ll  now  see  that  deletion  from  a hash  table  based  on  linear  probing is not all \nthat  dif\u00fbcult,  even  without  the  DELETED marker. The deletion procedure works \nfor  linear  probing,  but  not  for  open-address  probing  in general,  because  with  lin-  \near probing keys all follow the same simple cyclic probing sequence (albeit with \ndifferent starting points). \nThe deletion procedure relies on an <inverse= funct ion to the linear-probing  hash  \nfunction h.k;i/  D .h 1 .k/  C i/ mod m, which maps a key k and a probe number i \nto a slot number in the hash table. The inverse fun ction g maps a key k and a slot \nnumber q, where 0 \u0dc4 q<m , to the probe number that reaches slot q: \ng.k;q/  D .q \ue003 h 1 .k//  mod m:  \nIf h.k;i/  D q, then g.k;q/  D i , and so h.k;g.k;q//  D q. \nThe procedure L INEAR-PROBING-HASH-DELETE on the facing page deletes \nthe key stored in position q from hash table T . Figure  11.6  shows  how  it works.  \nThe  procedure  \u00fbrst  deletes  the  key  in position  q by setting T \u0152q\ufffd  to NIL in line 2. It \nthen searches for a slot q 0 (if any) that contains a key that should be moved t o the \nslot q just vacated by key k. Line 9 asks the critical question: does the key k 0 in \nslot q 0 need to be moved to the vacated slot q in order to preserve the accessibility \nof k 0 ? If g.k  0 ;q/<g.k  0 ;q  0 /, then during the insertion of k 0 into the table, slot q \nwas examined but found to be already occupied. But now slot q, where a search \nwill look for k 0 , is empty. In this case, key k 0 moves to slot q in line  10,  and  the  11.5  Practical  considerations  303 \n0 \n1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 82  \n74  \n93  \n18  \n38  43  \n(a) 0 \n1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 82  \n74  93  \n(b) 92 92 \n18  \n38  \nFigure  11.6  Deletion in a hash table that uses linear probing. The hash table has size 10  with \nh 1 .k/  D k mod 10. (a)  The hash table after inserting keys in the order 74, 43, 93, 18, 82, 38, 92. \n(b)  The hash table after deleting the key 43  from slot 3. Key  93  moves up to slot 3 to keep it \naccessible, and then key 92  moves up to slot 5 just vacated by key 93. No other keys need to be \nmoved. \nsearch continues, to see whether any later key also  needs to be moved to the slot q 0 \nthat was just freed up when k 0 moved. \nLINEAR-PROBING-HASH-DELETE .T;q/  \n1 while  TRUE \n2 T \u0152q\ufffd  D NIL / / make slot q empty \n3 q 0 D q / / starting point for search \n4 repeat  \n5 q 0 D .q 0 C 1/ mod m / / next slot number with linear probing \n6 k 0 D T\u0152q  0 \ufffd / / next key to try to move \n7 if k 0 = = NIL \n8 return  / / return when an empty slot is found \n9 until  g.k  0 ;q/<g.k  0 ;q  0 / / / was empty slot q probed before q 0 ? \n10  T \u0152q\ufffd  D k 0 / / move k 0 into slot q \n11  q D q 0 / / free up slot q 0 \nAnalysis  of linear  probing  \nLinear probing is popular to implement, but it exhi bits a phenomenon known as \nprimary  clustering . Long runs of occupied slots build up, increasing the average 304 Chapter 11 Hash Tables \nsearch time. Clusters arise because an empty slot p receded by i full  slots  gets  \u00fblled  \nnext with probability .i C 1/=m . Long runs of occupied slots tend to get longer, \nand the average search time increases. \nIn the standard RAM model, primary clustering is a problem, and  general  dou-  \nble hashing usually performs better than linear pro bing. By contrast,  in a hierar-  \nchical  memory  model,  primary  clustering  is a bene\u00fbcial  property, as elements are \noften stored together in the same cache block. Sear ching proceeds through one \ncache block before advancing to search the next cac he block. With  linear  prob-  \ning, the running time for a key k of H ASH-I NSERT , HASH-SEARCH , or L INEAR- \nPROBING-HASH-DELETE is at most proportional to the distance from h 1 .k/  to the \nnext empty slot. \nThe  following  theorem  is due  to Pagh  et al.  [351].  A more  recen t proof is given \nby  Thorup  [438].  We  omit  the  proof  here.  The  need  for  5-independence  is by  no  \nmeans obvious; see the cited proofs. \nTheorem  11.9  \nIf h 1 is 5-independent  and  \u02db \u0dc4 2=3, then it takes expected constant time to search \nfor, insert, or delete a key in a hash table using linear probing. \n(Indeed, the expected operation time is O.1=\ufffd  2 / for \u02db D 1 \ue003 \ufffd .) \n? 11.5.2  Hash  functions  for  hierarchical  memory  models  \nThis  section  illustrates  an approach  for  designing  ef\u00fbcien t hash tables in a modern \ncomputer system having a memory hierarchy. \nBecause of the memory hierarchy, linear probing is a good choice for resolving \ncollisions, as probe sequences are sequential and t end to stay within cache blocks. \nBut  linear  probing  is most  ef\u00fbcient  when  the  hash  function  is complex  (for  exam-  \nple, 5-independent  as in Theorem  11.9).  Fortunately,  having  a mem ory hierarchy \nmeans  that  complex  hash  functions  can  be implemented  ef\u00fbcie ntly. \nAs  noted  in Section  11.3.5,  one  approach  is to use  a cryptographic  hash  func-  \ntion  such  as SHA-256.  Such  functions  are  complex  and  suf\u00fbcie ntly random for \nhash  table  applications.  On  machines  with  specialized  instructions, cryptographic \nfunctions  can  be quite  ef\u00fbcient.  \nInstead, we present here a simple hash function bas ed only on addition,  multi-  \nplication, and swapping the halves of a word. This function can be implemented \nentirely within the fast registers, and on a machin e with a memory hierarchy, its \nlatency is small compared with the time taken to ac cess a random slot of the hash \ntable.  It is related  to the  RC6  encryption  algorithm  and  can  f or practical purposes \nbe considered a <random oracle.= 11.5  Practical  considerations  305 \nThe  wee  hash  function  \nLet w denote the word size of the machine (e.g., w D 64), assumed to be even, \nand let a and b be w-bit  unsigned  (nonnegative)  integers  such  that  a is odd. Let \nswap.x/  denote the w-bit  result  of swapping  the  two  w=2-bit  halves  of w-bit  in-  \nput x . That is, \nswap.x/  D .x o  .w=2//  C .x n  .w=2//  \nwhere <o= is <logical  right  shift=  (as  in equation  (11.2))  and  <n  is <left shift.= \nDe\u00fbne  \nf a .k/  D swap..2k  2 C ak/  mod 2 w /: \nThus, to compute f a .k/, evaluate the quadratic function 2k  2 C ak  modulo 2 w and \nthen swap the left and right halves of the result. \nLet r denote a desired number of <rounds= for the computa tion of the hash  func-  \ntion.  We\u2019ll  use  r D 4, but  the  hash  function  is well  de\u00fbned  for  any  nonnegative  r . \nDenote by f .r/  \na .k/  the result of iterating f a a total of r times (that is, r rounds) \nstarting with input value k. For any odd a and any r \ue004 0, the function f .r/  \na , al-  \nthough  complicated,  is one-to-one  (see  Exercise  11.5-1).  A cryptographer would \nview f .r/  \na as a simple block cipher operating on w-bit  input  blocks,  with  r rounds \nand key a. \nWe  \u00fbrst  de\u00fbne  the  wee  hash  function  h for short inputs, where by <short= we \nmeans <whose length t is at most w-bits,=  so that  the  input  \u00fbts  within  one  computer  \nword. We would like inputs of different lengths to be hashed differently. The wee  \nhash  function  h a;b;t;r  .k/  for parameters a, b, and r on t -bit  input  k is de\u00fbned  as \nh a;b;t;r  .k/  D \u00e3 \nf .r/  \naC2t  .k C b/ \u00e4 \nmod m:  (11.7)  \nThat is, the hash value for t -bit  input  k is obtained by applying f .r/  \naC2t  to k C b, then \ntaking  the  \u00fbnal  result  modulo  m. Adding the value b provides  hash-dependent  \nrandomization of the input, in a way that ensures t hat for variable-length  inputs  the  \n0-length  input  does  not  have  a \u00fbxed  hash  value.  Adding  the  value 2t to a ensures \nthat the hash function acts differently for inputs of different lengths. (We use 2t \nrather than t to ensure that the key a C 2t is odd if a is odd.) We call this hash \nfunction  <wee=  because  it uses  a tiny  amount  of memory4more  precisely, it can \nbe implemented  ef\u00fbciently  using  only  the  computer\u2019s  fast  registers. (This hash \nfunction does not have a name in the literature; it  is a variant we developed for this \ntextbook.) \nSpeed  of the  wee  hash  function  \nIt is surprising  how  much  ef\u00fbciency  can  be bought  with  locality.  Experiments  (un-  \npublished, by the authors) suggest that evaluating the wee hash function takes less 306 Chapter 11 Hash Tables \ntime than probing a single randomly  chosen  slot  in a hash  table.  These  experi-  \nments  were  run  on  a laptop  (2019  MacBook  Pro)  with  w D 64  and a D 123. For \nlarge hash tables, evaluating the wee hash function  was 2 to 10  times faster than \nperforming a single probe of the hash table. \nThe  wee  hash  function  for  variable-length  inputs  \nSometimes  inputs  are  long4more  than  one  w-bit  word  in length4or  have  variable  \nlength,  as discussed  in Section  11.3.5.  We  can  extend  the  wee  hash  function,  de-  \n\u00fbned  above  for  inputs  that  are  at most  single  w-bit  word  in length,  to handle  long  \nor variable-length  inputs.  Here  is one  method  for  doing  so.  \nSuppose that an input k has length t (measured in bits). Break k into a sequence \nhk 1 ;k 2 ;:::;k  u i of w-bit  words,  where  u D dt=we, k 1 contains  the  least-signi\u00fbcant  \nw bits of k, and k u contains  the  most  signi\u00fbcant  bits.  If t is not a multiple of w, \nthen k u contains fewer than w bits,  in which  case,  pad  out  the  unused  high-order  \nbits of k u with 0-bits.  De\u00fbne  the  function  chop  to return  a sequence  of the  w-bit  \nwords in k: \nchop.k/  D hk 1 ;k  2 ;:::;k  u i : \nThe most important property of the chop operation i s that it is one-to-one,  given  t : \nfor any two t -bit  keys  k and k 0 , if k \u00a4 k 0 then chop.k/  \u00a4 chop.k 0 /, and k can be \nderived from chop .k/  and t . The chop operation also has the useful property t hat a \nsingle-word  input  key  yields  a single-word  output  sequence : chop.k/  D hki. \nWith the chop function in hand, we specify the wee hash function h a;b;t;r  .k/  for \nan input k of length t bits as follows: \nh a;b;t;r  .k/  D WEE.k;a;b;t;r;m/;  \nwhere the procedure W EE de\u00fbned  on  the  facing  page  iterates  through  the  elements  \nof the w-bit  words  returned  by  chop.k/, applying f r \na to the sum of the current \nword k i and  the  previously  computed  hash  value  so far,  \u00fbnally  return ing the result \nobtained modulo m. This  de\u00fbnition  for  variable-length  and  long  (multiple-wo rd) \ninputs  is a consistent  extension  of the  de\u00fbnition  in equation  (11.7)  for  short  (single-  \nword) inputs. For practical use, we recommend that a be a randomly chosen odd \nw-bit  word,  b be a randomly chosen w-bit  word,  and  that  r D 4. \nNote that the wee hash function is really a hash fu nction family,  with  individ-  \nual hash functions determined by parameters a;b;t;r;  and m. The (approximate) \n5-independence  of the  wee  hash  function  family  for  variable- length inputs can be \nargued based on the assumption that the 1-word  wee  hash  function  is a random  or-  \nacle  and  on  the  security  of the  cipher-block-chaining  messa ge authentication code \n(CBC-MAC),  as studied  by  Bellare  et al.  [42].  The  case  here  is actually simpler \nthan that studied in the literature, since if two m essages have different lengths t \nand t 0 , then their <keys= are different: a C 2t \u00a4 a C 2t 0 . We omit the details. 11.5  Practical  considerations  307 \nWEE.k;a;b;t;r;m/  \n1 u D dt=we \n2 hk 1 ;k  2 ;:::;k  u i D  chop.k/  \n3 q D b \n4 for  i D 1 to u \n5 q D f .r/  \naC2t  .k i C q/ \n6 return  q mod m \nThis  de\u00fbnition  of a cryptographically  inspired  hash-funct ion family is meant \nto be realistic, yet only illustrative, and many va riations and improvements are \npossible. See the chapter notes for suggestions. \nIn summary, we see that when the memory system is h ierarchical, it becomes \nadvantageous to use linear probing (a special case of double hashing),  since  suc-  \ncessive probes tend to stay in the same cache block . Furthermore, hash functions \nthat  can  be implemented  using  only  the  computer\u2019s  fast  regis ters are exceptionally \nef\u00fbcient,  so they  can  be quite  complex  and  even  cryptographically  inspired,  pro-  \nviding the high degree of independence needed for l inear probing to work most \nef\u00fbciently.  \nExercises  \n? 11.5-1  \nComplete the argument that for any odd positive int eger a and any integer r \ue004 0, \nthe function f .r/  \na is one-to-one.  Use  a proof  by  contradiction  and  make  use  of the \nfact that the function f a works modulo 2 w . \n? 11.5-2  \nArgue that a random oracle is 5-independent.  \n? 11.5-3  \nConsider what happens to the value f .r/  \na .k/  as we  \u00fcip  a single  bit  k i of the input \nvalue k, for various values of r . Let k D P  w\ue0021 \ni D0 k i 2 i and g a .k/  D P  w\ue0021 \nj D0 b j 2 j \nde\u00fbne  the  bit  values  k i in the input (with k 0 the  least-signi\u00fbcant  bit)  and  the  bit  \nvalues b j in g a .k/  D .2k  2 C ak/  mod 2 w (where g a .k/  is the value that, when \nits halves are swapped, becomes f a .k/). Suppose  that  \u00fcipping  a single  bit  k i of \nthe input k may cause any bit b j of g a .k/  to \u00fcip,  for  j \ue004 i . What is the least \nvalue of r for  which  \u00fcipping  the  value  of any  single  bit  k i may cause any  bit of the \noutput f .r/  \na .k/  to \u00fcip?  Explain.  308 Chapter 11 Hash Tables \nProblems  \n11-1  Longest-probe  bound  for  hashing  \nSuppose  you  are  using  an open-addressed  hash  table  of size  m to store n \u0dc4 m=2  \nitems. \na. Assuming independent uniform permutation hashing, s how that for i D \n1;2;:::;n , the probability is at most 2 \ue002p that the i th insertion requires strictly \nmore than p probes. \nb. Show that for i D 1;2;:::;n , the probability is O.1=n  2 / that the i th insertion \nrequires more than 2 lg n probes. \nLet the random variable X i denote the number of probes required by the i th inser-  \ntion. You have shown in part (b) that Pr fX i >2  lg ng D  O.1=n  2 /. Let the random \nvariable X D max fX i W 1 \u0dc4 i \u0dc4 ng denote  the  maximum  number  of probes  re-  \nquired by any of the n insertions. \nc. Show that Pr fX>2  lg ng D  O.1=n/ . \nd. Show that the expected length E \u0152X\ufffd  of the longest probe sequence is O.lg n/. \n11-2  Searching  a static  set  \nYou are asked to implement a searchable set of n elements in which the keys are \nnumbers. The set is static (no I NSERT or D ELETE operations),  and  the  only  opera-  \ntion required is S EARCH . You are given an arbitrary amount of time to prep rocess \nthe n elements so that S EARCH operations run quickly. \na. Show how to implement S EARCH in O.lg n/ worst-case  time  using  no  extra  \nstorage beyond what is needed to store the elements  of the set themselves. \nb. Consider  implementing  the  set  by  open-address  hashing  on  m slots, and assume \nindependent uniform permutation hashing. What is th e minimum  amount  of ex-  \ntra storage m \ue003 n required to make the average performance of an unsu ccessful \nSEARCH operation  be at least  as good  as the  bound  in part  (a)?  Your  answer \nshould be an asymptotic bound on m \ue003 n in terms of n. \n11-3  Slot-size  bound  for  chaining  \nGiven  a hash  table  with  n slots, with collisions resolved by chaining, suppos e that \nn keys are inserted into the table. Each key is equal ly likely to be hashed to each \nslot. Let M  be the maximum number of keys in any slot after all  the keys have Problems for Chapter 11 309 \nbeen inserted. Your mission is to prove an O.lg n=  lg lg n/ upper bound on E \u0152M \ufffd, \nthe expected value of M  . \na. Argue that the probability Q k that exactly k keys hash to a particular slot is \ngiven by \nQ k D \u00ce 1 \nn \u00cf k \u00ce \n1 \ue003 1 \nn \u00cf n\ue002k \ue001 \nn \nk ! \n: \nb. Let P k be the probability that M  D k, that is, the probability that the slot \ncontaining the most keys contains k keys. Show that P k \u0dc4 nQ  k . \nc. Show that Q k < e  k =k  k . Hint: Use  Stirling\u2019s  approximation,  equation  (3.25)  \non  page  67.  \nd. Show that there exists a constant c > 1  such that Q k 0 < 1=n  3 for k 0 D \nc lg n=  lg lg n. Conclude that P k <1=n  2 for k \ue004 k 0 D c lg n=  lg lg n. \ne. Argue that \nE \u0152M \ufffd  \u0dc4 Pr \u00ef \nM >  c lg n \nlg lg n \u00f0 \n\ue001 n C Pr \u00ef \nM  \u0dc4 c lg n \nlg lg n \u00f0 \n\ue001 c lg n \nlg lg n : \nConclude that E \u0152M \ufffd  D O.lg n=  lg lg n/. \n11-4  Hashing  and  authentication  \nLet H be a family of hash functions in which each hash fu nction h 2 H maps the \nuniverse U of keys to f0;1;:::;m  \ue003 1g. \na. Show that if the family H of hash functions is 2-independent,  then  it is univer-  \nsal. \nb. Suppose that the universe U is the set of n-tuples  of values  drawn  from  \nZ p D f0;1;:::;p  \ue003 1g, where p is prime. Consider an element x D \nhx 0 ;x  1 ;:::;x  n\ue0021 i 2  U . For any n-tuple  a D ha 0 ;a  1 ;:::;a  n\ue0021 i 2  U , de-  \n\u00fbne  the  hash  function  h a by \nh a .x/  D \ue001 n\ue0021 X  \nj D0 a j x j ! \nmod p:  \nLet H D fh a W a 2 U g. Show that H is universal, but not 2-independent.  \n(Hint: Find a key for which all hash functions in H produce the same value.) 310 Chapter 11 Hash Tables \nc. Suppose that we modify H slightly from part (b): for any a 2 U and for any \nb 2 Z p , de\u00fbne  \nh 0 \nab  .x/  D \ue001 n\ue0021 X  \nj D0 a j x j C b ! \nmod p \nand H 0 D fh 0 \nab  W a 2 U and b 2 Z p g. Argue that H 0 is 2-independent.  (Hint: \nConsider  \u00fbxed  n-tuples  x 2 U and y 2 U , with x i \u00a4 y i for some i . What \nhappens to h 0 \nab  .x/  and h 0 \nab  .y/  as a i and b range over Z p ?) \nd. Alice and Bob secretly agree on a hash function h from a 2-independent  fam-  \nily H of hash functions. Each h 2 H maps from a universe of keys U to Z p , \nwhere p is prime. Later, Alice sends a message m to Bob over the internet, \nwhere m 2 U . She  authenticates  this  message  to Bob  by  also  sending  an au-  \nthentication tag t D h.m/ , and Bob checks that the pair .m;t/  he receives \nindeed  satis\u00fbes  t D h.m/ . Suppose that an adversary intercepts .m;t/  en route \nand tries to fool Bob by replacing the pair .m;t/  with a different pair .m  0 ;t 0 /. \nArgue that the probability that the adversary succe eds in fooling  Bob  into  ac-  \ncepting .m  0 ;t 0 / is at most 1=p, no  matter  how  much  computing  power  the  ad-  \nversary has, even if the adversary knows the family  H of hash functions used. \nChapter  notes  \nThe  books  by  Knuth  [261]  and  Gonnet  and  Baeza-Yates  [193]  are  excellent  ref-  \nerences  for  the  analysis  of hashing  algorithms.  Knuth  credits  H.  P. Luhn  (1953)  \nfor inventing hash tables, along with the chaining method for resolving collisions. \nAt  about  the  same  time,  G.  M.  Amdahl  originated  the  idea  of open addressing. \nThe notion of a random oracle was introduced by Bel lare et al. [43].  Carter  and  \nWegman  [80]  introduced  the  notion  of universal  families  of hash  functions  in 1979.  \nDietzfelbinger  et al.  [113]  invented  the  multiply-shift  hash function and gave a \nproof  of Theorem  11.5.  Thorup  [437]  provides  extensions  and  additional analysis. \nThorup  [438]  gives  a simple  proof  that  linear  probing  with  5-independent  hashing  \ntakes constant expected time per operation. Thorup also describes the method for \ndeletion in a hash table using linear probing. \nFredman,  Koml\u00b4  os,  and  Szemer\u00b4  edi  [154]  developed  a perfect  hashing scheme \nfor  static  sets4<perfect=  because  all  collisions  are  avoid ed. An extension of their \nmethod to dynamic sets, handling insertions and del etions in amortized expected \ntime O.1/, has  been  given  by  Dietzfelbinger  et al.  [114].  \nThe  wee  hash  function  is based  on  the  RC6  encryption  algorithm  [379].  Leiser-  \nson  et al.  [292]  propose  an <RC6 MIX= function that is essentially the same as the Notes for Chapter 11 311 \nwee hash function. They give experimental evidence that it has good randomness, \nand they also give a <D OTMIX= function  for  dealing  with  variable-length  inputs.  \nBellare  et al.  [42]  provide  an analysis  of the  security  of the  cipher-block-chaining  \nmessage authentication code. This analysis implies that the wee hash function has \nthe desired pseudorandomness properties. 12  Binary  Search  Trees  \nThe  search  tree  data  structure  supports  each  of the  dynamic- set operations listed \non  page  250:  SEARCH , M INIMUM , M AXIMUM , PREDECESSOR , SUCCESSOR , \nI NSERT , and D ELETE . Thus, you can use a search tree both as a diction ary and as \na priority queue. \nBasic operations on a binary search tree take time proportional to the height of \nthe tree. For a complete binary tree with n nodes, such operations run in \u201a.lg n/ \nworst-case  time.  If the  tree  is a linear  chain  of n nodes,  however,  the  same  oper-  \nations take \u201a.n/  worst-case  time.  In Chapter  13,  we\u2019ll  see  a variation  of binary \nsearch  trees,  red-black  trees,  whose  operations  guarantee  a height of O.lg n/. We \nwon\u2019t  prove  it here,  but  if you  build  a binary  search  tree  on  a random set of n keys, \nits expected height is O.lg n/ even  if you  don\u2019t  try  to limit  its  height.  \nAfter presenting the basic properties of binary sea rch trees, the  following  sec-  \ntions show how to walk a binary search tree to prin t its values in sorted order, how \nto search  for  a value  in a binary  search  tree,  how  to \u00fbnd  the  minimum or maximum \nelement,  how  to \u00fbnd  the  predecessor  or successor  of an elemen t, and how to insert \ninto or delete from a binary search tree. The basic  mathematical properties of trees \nappear in Appendix B. \n12.1  What  is a binary  search  tree?  \nA binary search tree is organized, as the name sugg ests, in a binary tree, as shown \nin Figure  12.1.  You  can  represent  such  a tree  with  a linked  data structure, as in \nSection  10.3.  In addition  to a key  and satellite data, each node object contains \nattributes left , right , and p that point to the nodes corresponding to its left c hild, \nits right child, and its parent, respectively. If a  child or the parent is missing, the \nappropriate attribute contains the value NIL. The tree itself has an attribute root 12.1  What  is a binary  search  tree?  313 \n5 2 5 5 \n8 7 6 \n(a) 6 8 7 5 2 \n(b) 6 \n5 7 \n2 5 8 2 \n5 \n7 \n6 8 \n5 T: root T: root \nFigure  12.1  Binary search trees. For any node x, the keys in the left subtree of x are at most x: key, \nand the keys in the right subtree of x are at least x: key. Different binary search trees can represent \nthe  same  set  of values.  The  worst-case  running  time  for  most  search-tree  operations  is proportional  \nto the height of the tree. (a)  A binary search tree on 6 nodes with height 2. The  top  \u00fbgure  shows  how  \nto view  the  tree  conceptually,  and  the  bottom  \u00fbgure  shows  the  left, right , and p attributes in each \nnode,  in the  style  of Figure  10.6  on  page  266.  (b)  A less  ef\u00fbcient  binary  search  tree,  with  height  4, \nthat contains the same keys. \nthat points to the root node, or NIL if the tree is empty. The root node T: root is the \nonly node in a tree T whose parent is NIL. \nThe keys in a binary search tree are always stored in such a way as to satisfy the \nbinary-search-tree  property : 314  Chapter  12  Binary  Search  Trees  \nLet x be a node in a binary search tree. If y is a node in the left subtree \nof x , then y: key  \u0dc4 x: key. If y is a node in the right subtree of x , then \ny: key  \ue004 x: key. \nThus,  in Figure  12.1(a),  the  key  of the  root  is 6, the keys 2, 5, and 5 in its left \nsubtree are no larger than 6, and the keys 7 and 8 in its right subtree are no smaller \nthan 6. The same property holds for every node in the tre e. For example, looking \nat the  root\u2019s  left  child  as the  root  of a subtree,  this  subtree  root has the key 5, the \nkey 2 in its left subtree is no larger than 5, and the key 5 in its right subtree is no \nsmaller than 5. \nBecause  of the  binary-search-tree  property,  you  can  print  out all the keys in a \nbinary search tree in sorted order by a simple recu rsive algorithm, called an inorder  \ntree  walk , given by the procedure I NORDER-TREE-WALK. This algorithm is so \nnamed because it prints the key of the root of a su btree between printing the values \nin its left subtree and printing those in its right  subtree. (Similarly, a preorder  tree  \nwalk  prints the root before the values in either subtree , and a postorder  tree  walk  \nprints the root after the values in its subtrees.) To print all the elements in a binary \nsearch tree T , call I NORDER-TREE-WALK  .T:  root /. For example, the inorder tree \nwalk prints the keys in each of the two binary sear ch trees from Figure  12.1  in the  \norder 2;5;5;6;7;8 . The correctness of the algorithm follows by induc tion directly \nfrom  the  binary-search-tree  property.  \nI NORDER-TREE-WALK  .x/  \n1 if x \u00a4 NIL \n2 I NORDER-TREE-WALK  .x:  left/ \n3 print x: key  \n4 I NORDER-TREE-WALK  .x:  right / \nIt takes \u201a.n/  time to walk an n-node  binary  search  tree,  since  after  the  initial  \ncall, the procedure calls itself recursively exactl y twice for  each  node  in the  tree4  \nonce for its left child and once for its right chil d. The following theorem gives a \nformal proof that it takes linear time to perform a n inorder tree walk. \nTheorem  12.1  \nIf x is the root of an n-node  subtree,  then  the  call  I NORDER-TREE-WALK  .x/  \ntakes \u201a.n/  time. \nProof  Let T.n/  denote the time taken by I NORDER-TREE-WALK  when it is \ncalled on the root of an n-node  subtree.  Since  I NORDER-TREE-WALK  visits all n \nnodes of the subtree, we have T.n/  D \ufffd.n/ . It remains to show that T.n/  D O.n/ . 12.1  What  is a binary  search  tree?  315 \nSince I NORDER-TREE-WALK  takes a small, constant amount of time on an \nempty subtree (for the test x \u00a4 NIL), we have T.0/  D c for some constant c>0 . \nFor n > 0 , suppose that I NORDER-TREE-WALK  is called on a node x whose \nleft subtree has k nodes and whose right subtree has n \ue003 k \ue003 1 nodes. The time to \nperform I NORDER-TREE-WALK  .x/  is bounded by T.n/  \u0dc4 T.k/ CT.n\ue003k \ue0031/Cd \nfor some constant d > 0  that  re\u00fcects  an upper  bound  on  the  time  to execute  the  \nbody of I NORDER-TREE-WALK  .x/, exclusive of the time spent in recursive calls. \nWe use the substitution method to show that T.n/  D O.n/  by proving that \nT.n/  \u0dc4 .c C d/n  C c . For n D 0, we have .c C d/  \ue001 0 C c D c D T.0/ . For n>0 , \nwe have \nT.n/  \u0dc4 T.k/  C T.n  \ue003 k \ue003 1/ C d \n\u0dc4 ..c  C d/k  C c/ C ..c  C d/.n  \ue003 k \ue003 1/ C c/ C d \nD .c C d/n  C c \ue003 .c C d/  C c C d \nD .c C d/n  C c;  \nwhich completes the proof. \nExercises  \n12.1-1  \nFor the set f1;4;5;10;16;17;21 g of keys, draw binary search trees of heights 2, 3, \n4, 5, and 6. \n12.1-2  \nWhat  is the  difference  between  the  binary-search-tree  property  and  the  min-heap  \nproperty  on  page  163?  Can  the  min-heap  property  be used  to print out the keys of \nan n-node  tree  in sorted  order  in O.n/  time?  Show  how,  or explain  why  not.  \n12.1-3  \nGive  a nonrecursive  algorithm  that  performs  an inorder  tree  walk. ( Hint: An easy \nsolution uses a stack as an auxiliary data structur e. A more c omplicated,  but  ele-  \ngant, solution uses no stack but assumes that you c an test two pointers for equality.) \n12.1-4  \nGive  recursive  algorithms  that  perform  preorder  and  postor der tree walks in \u201a.n/  \ntime on a tree of n nodes. \n12.1-5  \nArgue that since sorting n elements takes \ufffd.n  lg n/ time in the worst case in \nthe  comparison  model,  any  comparison-based  algorithm  for  constructing a binary \nsearch tree from an arbitrary list of n elements takes \ufffd.n  lg n/ time in the worst \ncase. 316  Chapter  12  Binary  Search  Trees  \n12.2  Querying  a binary  search  tree  \nBinary search trees can support the queries M INIMUM , MAXIMUM , SUCCESSOR , \nand PREDECESSOR , as well as S EARCH . This section examines these operations \nand shows how to support each one in O.h/  time on any binary search tree of \nheight h. \nSearching  \nTo search for a node with a given key in a binary s earch tree, call the T REE- \nSEARCH procedure.  Given  a pointer  x to the root of a subtree and a key k, \nTREE-SEARCH .x;k/  returns a pointer to a node with key k if one exists in the \nsubtree; otherwise, it returns NIL. To search for key k in the entire binary search \ntree T , call T REE-SEARCH .T:  root ;k/. \nTREE-SEARCH .x;k/  \n1 if x = = NIL or k == x: key  \n2 return  x \n3 if k<x:  key  \n4 return  TREE-SEARCH.x:  left;k/  \n5 else  return  TREE-SEARCH.x:  right ;k/  \nI TERATIVE-TREE-SEARCH .x;k/  \n1 while  x \u00a4 NIL and k \u00a4 x: key  \n2 if k<x:  key  \n3 x D x: left \n4 else  x D x: right \n5 return  x \nThe T REE-SEARCH procedure begins its search at the root and traces a simple \npath  downward  in the  tree,  as shown  in Figure  12.2(a).  For  each node x it encoun-  \nters, it compares the key k with x: key. If the  two  keys  are  equal,  the  search  termi-  \nnates. If k is smaller than x: key, the search continues in the left subtree of x , since \nthe  binary-search-tree  property  implies  that  k cannot reside in the right subtree. \nSymmetrically, if k is larger than x: key, the search continues in the right subtree. \nThe nodes encountered during the recursion form a s imple path downward from \nthe root of the tree, and thus the running time of TREE-SEARCH is O.h/ , where h \nis the height of the tree. 12.2  Querying  a binary  search  tree  317 \n2 4 3 \n13  7 6 \n17  20 18  15  \n9 \n(a) 2 4 3 \n13  7 6 \n17  20 18  15  \n9 \n(b) \n2 4 3 \n13  7 6 \n17  20 18  15  \n9 \n(c) 2 4 3 \n13  7 6 \n17  20 18  15  \n9 \n(d) \nFigure  12.2  Queries  on  a binary  search  tree.  Nodes  and  paths  followed  in each query are colored \nblue. (a)  A search for the key 13  in the tree follows the path 15  !  6 !  7 !  13  from the root. \n(b)  The minimum key in the tree is 2, which is found by following left pointers from the root. The \nmaximum key 20  is found by following right pointers from the root. (c)  The successor of the node \nwith key 15  is the node with key 17, since it is the minimum key in the right subtree of 15. (d)  The \nnode with key 13  has no right subtree, and thus its successor is its  lowest ancestor whose left child is \nalso an ancestor. In this case, the node with key 15  is its successor. \nSince the T REE-SEARCH procedure recurses on either the left subtree or th e \nright subtree, but not both, we can rewrite the alg orithm to <unroll= the recursion \ninto a while  loop.  On  most  computers,  the  I TERATIVE-TREE-SEARCH procedure \non  the  facing  page  is more  ef\u00fbcient.  \nMinimum  and  maximum  \nTo  \u00fbnd  an element  in a binary  search  tree  whose  key  is a minimum , just follow left \nchild pointers from the root until you encounter a NIL, as shown  in Figure  12.2(b).  318  Chapter  12  Binary  Search  Trees  \nThe T REE-MINIMUM procedure returns a pointer to the minimum element in the \nsubtree rooted at a given node x , which  we  assume  to be non- NIL. \nTREE-MINIMUM.x/  \n1 while  x: left \u00a4 NIL \n2 x D x: left \n3 return  x \nTREE-MAXIMUM.x/  \n1 while  x: right \u00a4 NIL \n2 x D x: right \n3 return  x \nThe  binary-search-tree  property  guarantees  that  TREE-MINIMUM is correct. If \nnode x has no left subtree, then since every key in the ri ght subtree of x is at least as \nlarge as x: key, the minimum key in the subtree rooted at x is x: key. If node x has \na left subtree, then since no key in the right subt ree is smaller than x: key  and every \nkey in the left subtree is not larger than x: key, the minimum key in the subtree \nrooted at x resides in the subtree rooted at x: left. \nThe pseudocode for T REE-MAXIMUM is symmetric. Both T REE-MINIMUM \nand T REE-MAXIMUM run in O.h/  time on a tree of height h since, as in T REE- \nSEARCH , the sequence of nodes encountered forms a simple path downward from \nthe root. \nSuccessor  and  predecessor  \nGiven  a node  in a binary  search  tree,  how  can  you  \u00fbnd  its  succes sor in the sorted \norder  determined  by  an inorder  tree  walk?  If all  keys  are  distinct, the successor of a \nnode x is the node with the smallest key greater than x: key. Regardless of whether \nthe  keys  are  distinct,  we  de\u00fbne  the  successor  of a node as the next node visited in an \ninorder tree walk. The structure of a binary search  tree allows you to determine the \nsuccessor of a node without comparing keys. The T REE-SUCCESSOR  procedure \non the facing page returns the successor of a node x in a binary search tree if it \nexists, or NIL if x is the last node that would be visited during an in order walk. \nThe code for T REE-SUCCESSOR  has two cases. If the right subtree of node x \nis nonempty, then the successor of x is just the leftmost node in x \u2019s right  subtree,  \nwhich  line  2 \u00fbnds  by  calling  TREE-MINIMUM.x:  right /. For  example,  the  succes-  \nsor of the node with key 15  in Figure  12.2(c)  is the  node  with  key  17. \nOn  the  other  hand,  as Exercise  12.2-6  asks  you  to show,  if the  right subtree of \nnode x is empty and x has a successor y , then y is the lowest ancestor of x whose 12.2  Querying  a binary  search  tree  319 \nTREE-SUCCESSOR.x/  \n1 if x: right \u00a4 NIL \n2 return  TREE-MINIMUM.x:  right / / / leftmost node in right subtree \n3 else  / / \u00fbnd  the  lowest  ancestor  of x whose left child is an ancestor of x \n4 y D x: p \n5 while  y \u00a4 NIL and x = = y: right \n6 x D y \n7 y D y: p \n8 return  y \nleft child is also an ancestor of x . In Figure  12.2(d),  the  successor  of the  node  \nwith key 13  is the node with key 15. To  \u00fbnd  y , go up the tree from x until you \nencounter either the root or a node that is the lef t child of its parent.  Lines  438  of \nTREE-SUCCESSOR  handle this case. \nThe running time of T REE-SUCCESSOR  on a tree of height h is O.h/ , since it \neither follows a simple path up the tree or follows  a simple path down the tree. The \nprocedure T REE-PREDECESSOR , which is symmetric to T REE-SUCCESSOR , also \nruns in O.h/  time. \nIn summary, we have proved the following theorem. \nTheorem  12.2  \nThe  dynamic-set  operations  SEARCH , M INIMUM , M AXIMUM , SUCCESSOR , and \nPREDECESSOR  can be implemented so that each one runs in O.h/  time on a binary \nsearch tree of height h. \nExercises  \n12.2-1  \nYou are searching for the number 363  in a binary search tree containing numbers \nbetween 1 and 1000 . Which of the following sequences cannot  be the sequence of \nnodes  examined?  \na. 2, 252,  401,  398,  330,  344,  397,  363.  \nb. 924,  220,  911,  244,  898,  258,  362,  363.  \nc. 925,  202,  911,  240,  912,  245,  363.  \nd. 2, 399,  387,  219,  266,  382,  381,  278,  363.  \ne. 935,  278,  347,  621,  299,  392,  358,  363.  320  Chapter  12  Binary  Search  Trees  \n12.2-2  \nWrite recursive versions of T REE-MINIMUM and T REE-MAXIMUM . \n12.2-3  \nWrite the T REE-PREDECESSOR  procedure. \n12.2-4  \nProfessor  Kilmer  claims  to have  discovered  a remarkable  property of binary search \ntrees. Suppose that the search for key k in a binary search tree ends up at a leaf. \nConsider three sets: A, the keys to the left of the search path; B , the keys on \nthe search path; and C , the  keys  to the  right  of the  search  path.  Professor  Kilmer  \nclaims that any three keys a 2 A, b 2 B , and c 2 C must satisfy a \u0dc4 b \u0dc4 c . Give  \na smallest  possible  counterexample  to the  professor\u2019s  claim. \n12.2-5  \nShow that if a node in a binary search tree has two  children, then its successor has \nno left child and its predecessor has no right chil d. \n12.2-6  \nConsider a binary search tree T whose keys are distinct. Show that if the right \nsubtree of a node x in T is empty and x has a successor y , then y is the lowest \nancestor of x whose left child is also an ancestor of x . (Recall that every node is \nits own ancestor.) \n12.2-7  \nAn alternative method of performing an inorder tree  walk of an n-node  binary  \nsearch  tree  \u00fbnds  the  minimum  element  in the  tree  by  calling  TREE-MINIMUM and \nthen making n \ue003 1 calls to T REE-SUCCESSOR . Prove that this algorithm runs \nin \u201a.n/  time. \n12.2-8  \nProve  that  no  matter  what  node  you  start  at in a height-h binary search tree, k \nsuccessive calls to T REE-SUCCESSOR  take O.k  C h/ time. \n12.2-9  \nLet T be a binary search tree whose keys are distinct, le t x be a leaf node, and let y \nbe its parent. Show that y: key  is either the smallest key in T larger than x: key  or \nthe largest key in T smaller than x: key. 12.3 Insertion and deletion 321 \n12.3  Insertion  and  deletion  \nThe operations of insertion and deletion cause the dynamic set represented by a \nbinary search tree to change. The data structure mu st be modi\u00fbed  to re\u00fcect  this  \nchange,  but  in such  a way  that  the  binary-search-tree  proper ty continues to hold. \nWe\u2019ll  see  that  modifying  the  tree  to insert  a new  element  is relatively  straightfor-  \nward, but deleting a node from a binary search tree  is more complicated. \nInsertion  \nThe T REE-I NSERT procedure inserts a new node into a binary search t ree. The \nprocedure takes a binary search tree T and a node \u00b4 for which \u00b4: key  has already \nbeen  \u00fblled  in,  \u00b4: left D NIL, and \u00b4: right D NIL. It modi\u00fbes  T and some of the \nattributes of \u00b4 so as to insert \u00b4 into an appropriate position in the tree. \nTREE-I NSERT .T;\u00b4/  \n1 x D T: root / / node being compared with \u00b4 \n2 y D NIL / / y will be parent of \u00b4 \n3 while  x \u00a4 NIL / / descend until reaching a leaf \n4 y D x \n5 if \u00b4: key  <x:  key  \n6 x D x: left \n7 else  x D x: right \n8 \u00b4: p D y / / found  the  location4insert  \u00b4 with parent y \n9 if y == NIL \n10  T: root D \u00b4 / / tree T was empty \n11  elseif  \u00b4: key  <y:  key  \n12  y: left D \u00b4 \n13  else  y: right D \u00b4 \nFigure  12.3  shows  how  TREE-I NSERT works.  Just  like  the  procedures  TREE- \nSEARCH and I TERATIVE-T  REE-SEARCH , TREE-I NSERT begins at the root of the \ntree and the pointer x traces a simple path downward looking for a NIL to replace \nwith the input node \u00b4. The procedure maintains the trailing  pointer  y as the parent \nof x . After initialization, the while  loop  in lines  337  causes  these  two  pointers  \nto move down the tree, going left or right dependin g on the comparison of \u00b4: key  \nwith x: key, until x becomes NIL. This NIL occupies the position where node \u00b4 will \ngo. More precisely, this NIL is a left or right attribute of the node that will become \n\u00b4\u2019s parent,  or it is T: root if tree T is currently empty. The procedure needs the 322  Chapter  12  Binary  Search  Trees  \n2 9 5 \n13  17  15  19  18  12  \nFigure  12.3  Inserting a node with key 13  into a binary search tree. The simple path from the  root \ndown to the position where the node is inserted is shown in blue. The new node and the link to its \nparent are highlighted in orange. \ntrailing pointer y , because  by  the  time  it \u00fbnds  the  NIL where \u00b4 belongs, the search \nhas proceeded one step beyond the node that needs t o be changed. Lines  8313  set  \nthe pointers that cause \u00b4 to be inserted. \nLike the other primitive operations on search trees , the procedure T REE-I NSERT \nruns in O.h/  time on a tree of height h. \nDeletion  \nThe overall strategy for deleting a node \u00b4 from a binary search tree T has three \nbasic  cases  and,  as we\u2019ll  see,  one  of the  cases  is a bit  tricky.  \n\ue001 If \u00b4 has no children, then simply remove it by modifying  its parent to replace \u00b4 \nwith NIL as its child. \n\ue001 If \u00b4 has just one child, then elevate that child to take  \u00b4\u2019s position  in the  tree  by  \nmodifying \u00b4\u2019s parent  to replace  \u00b4 by \u00b4\u2019s child.  \n\ue001 If \u00b4 has  two  children,  \u00fbnd  \u00b4\u2019s successor  y 4which  must  belong  to \u00b4\u2019s right  \nsubtree4and  move  y to take \u00b4\u2019s position  in the  tree.  The  rest  of \u00b4\u2019s original  \nright subtree becomes y \u2019s new  right  subtree,  and  \u00b4\u2019s left  subtree  becomes  y \u2019s \nnew left subtree. Because y is \u00b4\u2019s successor,  it cannot  have  a left  child,  and  y \u2019s \noriginal right child moves into y \u2019s original  position,  with  the  rest  of y \u2019s original  \nright subtree following automatically. This case is  the tricky one because, as \nwe\u2019ll  see,  it matters  whether  y is \u00b4\u2019s right  child.  \nThe procedure for deleting a given node \u00b4 from a binary search tree T takes as \narguments pointers to T and \u00b4. It organizes its cases a bit differently from the  three \ncases outlined previously by considering the four c ases shown  in Figure  12.4.  \n\ue001 If \u00b4 has  no  left  child,  then  as in part  (a)  of the  \u00fbgure,  replace  \u00b4 by its right child, \nwhich may or may not be NIL. When \u00b4\u2019s right  child  is NIL, this case deals with 12.3 Insertion and deletion 323 \nq q \nz (a) r \nq q \nz \nl (b) \nq \nz \nl (c) q \ny \nl y \nq \nz \nl (d) \nr q \nz \nl r y q \nl r y r \nl \nx \nx \nx y \nx x \nNIL NIL NIL NIL NIL \nFigure  12.4  Deleting a node \u00b4, in blue, from a binary search tree. Node \u00b4 may be the root, a left \nchild of node q, or a right child of q. The node that will replace node \u00b4 in its position in the tree \nis colored orange. (a)  Node \u00b4 has no left child. Replace \u00b4 by its right child r , which may or may \nnot be NIL. (b)  Node \u00b4 has a left child l but no right child. Replace \u00b4 by l . (c)  Node \u00b4 has two \nchildren. Its left child is node l , its right child is its successor y (which has no left child), and y\u2019s \nright child is node x. Replace \u00b4 by y, updating y\u2019s left  child  to become  l , but leaving x as y\u2019s right  \nchild. (d)  Node \u00b4 has two children (left child l and right child r ), and its successor y \u00a4 r lies within \nthe subtree rooted at r . First replace y by its own right child x, and set y to be r \u2019s parent.  Then  set  y \nto be q\u2019s child  and  the  parent  of l . 324  Chapter  12  Binary  Search  Trees  \nthe situation in which \u00b4 has no children. When \u00b4\u2019s right  child  is non- NIL, this \ncase handles the situation in which \u00b4 has just one child, which is its right child. \n\ue001 Otherwise,  if \u00b4 has just one child, then that child is a left child . As in part (b) \nof the  \u00fbgure,  replace  \u00b4 by its left child. \n\ue001 Otherwise,  \u00b4 has both a left and a right child. Find \u00b4\u2019s successor  y , which lies \nin \u00b4\u2019s right  subtree  and  has  no  left  child  (see  Exercise  12.2-5).  Splice node y \nout of its current location and replace \u00b4 by y in the tree. How to do so depends \non whether y is \u00b4\u2019s right  child:  \nB If y is \u00b4\u2019s right  child,  then  as in part  (c)  of the  \u00fbgure,  replace  \u00b4 by y , leaving \ny \u2019s right  child  alone.  \nB Otherwise,  y lies within \u00b4\u2019s right  subtree  but  is not  \u00b4\u2019s right  child.  In this  \ncase,  as in part  (d)  of the  \u00fbgure,  \u00fbrst  replace  y by its own right child, and \nthen replace \u00b4 by y . \nAs part of the process of deleting a node, subtrees  need to move around within \nthe binary search tree. The subroutine T RANSPLANT replaces one subtree as a \nchild of its parent with another subtree. When T RANSPLANT replaces  the  sub-  \ntree rooted at node u with the subtree rooted at node v, node u\u2019s parent  be-  \ncomes node v\u2019s parent,  and  u\u2019s parent  ends  up  having  v as its appropriate child. \nTRANSPLANT allows v to be NIL instead of a pointer to a node. \nTRANSPLANT .T;u;v/  \n1 if u: p = = NIL \n2 T: root D v \n3 elseif  u = = u: p: left \n4 u: p: left D v \n5 else  u: p: right D v \n6 if v \u00a4 NIL \n7 v: p D u: p \nHere is how T RANSPLANT works.  Lines  132  handle  the  case  in which  u is the \nroot of T . Otherwise,  u is either  a left  child  or a right  child  of its  parent.  Lines  334  \ntake care of updating u: p: left if u is a left  child,  and  line  5 updates  u: p: right if u \nis a right child. Because v may be NIL, lines  637  update  v: p only if v is non- NIL. \nThe procedure T RANSPLANT does not attempt to update v: left and v: right . Doing \nso, or not doing so, is the responsibility of T RANSPLANT \u2019s caller.  \nThe procedure T REE-DELETE on the facing page uses T RANSPLANT to delete \nnode \u00b4 from binary search tree T . It executes  the  four  cases  as follows.  Lines  132  \nhandle the case in which node \u00b4 has  no  left  child  (Figure  12.4(a)),  and  lines  334  12.3 Insertion and deletion 325 \nhandle the case in which \u00b4 has  a left  child  but  no  right  child  (Figure  12.4(b)).  Lines  \n5312  deal  with  the  remaining  two  cases,  in which  \u00b4 has  two  children.  Line  5 \u00fbnds  \nnode y , which is the successor of \u00b4. Because \u00b4 has a nonempty right subtree, its \nsuccessor must be the node in that subtree with the  smallest key; hence the call to \nTREE-MINIMUM.\u00b4:  right /. As we noted before, y has no left child. The procedure \nneeds to splice y out of its current location and replace \u00b4 by y in the tree. If y is \n\u00b4\u2019s right  child  (Figure  12.4(c)),  then  lines  10312  replace  \u00b4 as a child of its parent \nby y and replace y \u2019s left  child  by  \u00b4\u2019s left  child.  Node  y retains its right child \n(x in Figure  12.4(c)),  and  so no  change  to y: right needs to occur. If y is not \u00b4\u2019s \nright  child  (Figure  12.4(d)),  then  two  nodes  have  to move.  Lines  739  replace  y as a \nchild of its parent by y \u2019s right  child  (x in Figure  12.4(c))  and  make  \u00b4\u2019s right  child  \n(r in the  \u00fbgure)  become  y \u2019s right  child  instead.  Finally,  lines  10312  replace  \u00b4 as a \nchild of its parent by y and replace y \u2019s left  child  by  \u00b4\u2019s left  child.  \nTREE-DELETE .T;\u00b4/  \n1 if \u00b4: left == NIL \n2 TRANSPLANT .T;\u00b4;\u00b4:  right / / / replace \u00b4 by its right child \n3 elseif  \u00b4: right == NIL \n4 TRANSPLANT .T;\u00b4;\u00b4:  left / / / replace \u00b4 by its left child \n5 else  y D TREE-MINIMUM.\u00b4:  right / / / y is \u00b4\u2019s successor  \n6 if y \u00a4 \u00b4: right / / is y farther  down  the  tree?  \n7 TRANSPLANT .T;y;y:  right / / / replace y by its right child \n8 y: right D \u00b4: right / / \u00b4\u2019s right  child  becomes  \n9 y: right : p D y / / y \u2019s right  child  \n10  TRANSPLANT .T;\u00b4;y/  / / replace \u00b4 by its successor y \n11  y: left D \u00b4: left / / and give \u00b4\u2019s left  child  to y, \n12  y: left: p D y / / which had no left child \nEach line of T REE-DELETE , including the calls to T RANSPLANT , takes constant \ntime, except for the call to T REE-MINIMUM in line  5. Thus,  TREE-DELETE runs \nin O.h/  time on a tree of height h. \nIn summary, we have proved the following theorem. \nTheorem  12.3  \nThe  dynamic-set  operations  I NSERT and D ELETE can be implemented so that each \none runs in O.h/  time on a binary search tree of height h. 326  Chapter  12  Binary  Search  Trees  \nExercises  \n12.3-1  \nGive  a recursive  version  of the  TREE-I NSERT procedure. \n12.3-2  \nSuppose that you construct a binary search tree by repeatedly inserting distinct \nvalues into the tree. Argue that the number of node s examined in searching for a \nvalue in the tree is 1 plus  the  number  of nodes  examined  when  the  value  was  \u00fbrst  \ninserted into the tree. \n12.3-3  \nYou can sort a given set of n numbers  by  \u00fbrst  building  a binary  search  tree  contain-  \ning these numbers (using T REE-I NSERT repeatedly to insert the numbers one by \none) and then printing the numbers by an inorder tr ee walk. Wh at are  the  worst-  \ncase  and  best-case  running  times  for  this  sorting  algorithm?  \n12.3-4  \nWhen T REE-DELETE calls T RANSPLANT , under  what  circumstances  can  the  pa-  \nrameter v of T RANSPLANT be NIL? \n12.3-5  \nIs the operation of deletion <commutative= in the s ense that deleting x and then y \nfrom a binary search tree leaves the same tree as d eleting y and then x ? Argue  why  \nit is or give a counterexample. \n12.3-6  \nSuppose that instead of each node x keeping the attribute x: p, pointing to x \u2019s \nparent, it keeps x: succ, pointing to x \u2019s successor.  Give  pseudocode  for  TREE- \nSEARCH , TREE-I NSERT , and T REE-DELETE on a binary search tree T using this \nrepresentation. These procedures should operate in O.h/  time, where h is the \nheight of the tree T . You may assume that all keys in the binary search  tree are \ndistinct. ( Hint: You might wish to implement a subroutine that retur ns the parent \nof a node.) \n12.3-7  \nWhen node \u00b4 in T REE-DELETE has two children, you can choose node y to be \nits predecessor rather than its successor. What oth er changes to T REE-DELETE \nare  necessary  if you  do  so?  Some  have  argued  that  a fair  strate gy, giving equal \npriority to predecessor and successor, yields bette r empirical performance. How \nmight T REE-DELETE be minimally  changed  to implement  such  a fair  strategy?  Problems for Chapter 12 327 \nProblems  \n12-1  Binary  search  trees  with  equal  keys  \nEqual keys pose a problem for the implementation of  binary search trees. \na. What is the asymptotic performance of T REE-I NSERT when used to insert n \nitems with identical keys into an initially empty b inary search  tree?  \nConsider changing T REE-I NSERT to test whether \u00b4: key  D x: key  before  line  5 and  \nto test whether \u00b4: key  D y: key  before  line  11.  If equality  holds,  implement  one  \nof the  following  strategies.  For  each  strategy,  \u00fbnd  the  asym ptotic performance of \ninserting n items with identical keys into an initially empty b inary search tree. (The \nstrategies  are  described  for  line  5, which  compares  the  keys  of \u00b4 and x . Substitute \ny for x to arrive  at the  strategies  for  line  11.)  \nb. Keep  a boolean  \u00fcag  x: b at node x , and set x to either x: left or x: right based on \nthe value of x: b, which alternates between FALSE and TRUE each time T REE- \nI NSERT visits x while inserting a node with the same key as x . \nc. Keep  a list  of nodes  with  equal  keys  at x , and insert \u00b4 into the list. \nd. Randomly set x to either x: left or x: right. (Give  the  worst-case  performance  \nand informally derive the expected running time.) \n12-2  Radix  trees  \nGiven  two  strings  a D a 0 a 1 :::a  p and b D b 0 b 1 :::b  q , where each a i and each b j \nbelongs to some ordered set of characters, we say t hat string a is lexicographically  \nless  than  string b if either \n1. there  exists  an integer  j , where 0 \u0dc4 j \u0dc4 min fp;qg, such that a i D b i for all \ni D 0;1;:::;j  \ue003 1 and a j <b  j , or \n2. p<q  and a i D b i for all i D 0;1;:::;p . \nFor example, if a and b are bit strings, then 10100  < 10110  by  rule  1 (letting  \nj D 3) and 10100  < 101000  by rule 2. This ordering is similar to that used in  \nEnglish-language  dictionaries.  \nThe radix  tree  data  structure  shown  in Figure  12.5  (also  known  as a trie) stores \nthe bit strings 1011 , 10, 011, 100, and 0. When searching for a key a D a 0 a 1 :::a  p , \ngo left at a node of depth i if a i D 0 and right if a i D 1. Let S be a set of \ndistinct bit strings whose lengths sum to n. Show how to use a radix tree to sort S \nlexicographically in \u201a.n/  time.  For  the  example  in Figure  12.5,  the  output  of the  \nsort should be the sequence 0, 011, 10, 100, 1011 . 328  Chapter  12  Binary  Search  Trees  \n011  0 \n100  10  \n1011  0 1 \n1 0 \n1 0 1 \n1 \nFigure  12.5  A radix tree storing the bit strings 1011 , 10, 011, 100, and 0. To  determine  each  node\u2019s  \nkey, traverse the simple path from the root to that  node. There is no need, therefore, to store the ke ys \nin the nodes. The keys appear here for illustrative  purposes only.  Keys  corresponding  to blue  nodes  \nare not in the tree. Such nodes are present only to  establish a path to other nodes. \n12-3  Average  node  depth  in a randomly  built  binary  search  tree  \nA randomly  built  binary  search  tree  on n keys is a binary search tree created by \nstarting with an empty tree and inserting the keys in random order, where each of \nthe n\u0160 permutations of the keys is equally likely. In this  problem, you will prove \nthat the average depth of a node in a randomly buil t binary search tree with n nodes \nis O.lg n/. The technique reveals a surprising similarity bet ween the building of \na binary search tree and the execution of R ANDOMIZED -QUICKSORT  from  Sec-  \ntion  7.3.  \nDenote the depth of any node x in tree T by d.x;T/ . Then the total  path  \nlength  P.T/  of a tree T is the sum, over all nodes x in T , of d.x;T/ . \na. Argue that the average depth of a node in T is \n1 \nn X  \nx2T d.x;T/  D 1 \nn P.T/:  \nThus, you need to show that the expected value of P.T/  is O.n  lg n/. \nb. Let T L and T R denote the left and right subtrees of tree T , respectively. Argue \nthat if T has n nodes, then \nP.T/  D P.T  L / C P.T  R / C n \ue003 1:  \nc. Let P.n/  denote the average total path length of a randomly built binary search \ntree with n nodes. Show that Problems for Chapter 12 329 \nP.n/  D 1 \nn n\ue0021 X  \ni D0 .P.i/  C P.n  \ue003 i \ue003 1/ C n \ue003 1/:  \nd. Show how to rewrite P.n/  as \nP.n/  D 2 \nn n\ue0021 X  \nkD1 P.k/  C \u201a.n/:  \ne. Recalling the alternative analysis of the randomize d version of quicksort given \nin Problem  7-3,  conclude  that  P.n/  D O.n  lg n/. \nEach recursive invocation of randomized quicksort c hooses a random pivot element \nto partition the set of elements being sorted. Each  node of a binary search tree \npartitions the set of elements that fall into the s ubtree rooted at that node. \nf. Describe an implementation of quicksort in which th e comparisons to sort a set \nof elements are exactly the same as the comparisons  to insert the elements into \na binary search tree. (The order in which compariso ns are made may differ, but \nthe same comparisons must occur.) \n12-4  Number  of different  binary  trees  \nLet b n denote the number of different binary trees with n nodes. In this problem, \nyou  will  \u00fbnd  a formula  for  b n , as well as an asymptotic estimate. \na. Show that b 0 D 1 and that, for n \ue004 1, \nb n D n\ue0021 X  \nkD0 b k b n\ue0021\ue002k : \nb. Referring  to Problem  4-5  on  page  121  for  the  de\u00fbnition  of a generating function, \nlet B.x/  be the generating function \nB.x/  D 1  X  \nnD0 b n x n : \nShow that B.x/  D xB.x/  2 C 1, and hence one way to express B.x/  in closed \nform is \nB.x/  D 1 \n2x  \u00e3 1 \ue003 p \n1 \ue003 4x  \u00e4 : \nThe Taylor  expansion  of f.x/  around the point x D a is given by 330  Chapter  12  Binary  Search  Trees  \nf.x/  D 1  X  \nkD0 f .k/  .a/  \nk\u0160 .x \ue003 a/ k ; \nwhere f .k/  .x/  is the kth derivative of f evaluated at x . \nc. Show that \nb n D 1 \nn C 1 \ue001 \n2n  \nn ! \n(the nth Catalan  number ) by using the Taylor expansion of p \n1 \ue003 4x  around \nx D 0. (If you wish, instead of using the Taylor expansi on, you may use \nthe  generalization  of the  binomial  theorem,  equation  (C.4)  on  page  1181,  to \nnoninteger exponents n, where for any real number n and for any integer k, you \ncan interpret \u00e3 n \nk \u00e4 \nto be n.n  \ue003 1/ \ue001\ue001\ue001  .n \ue003 k C 1/=k\u0160  if k \ue004 0, and 0 otherwise.) \nd. Show that \nb n D 4 n \np \ufffdn  3=2  .1 C O.1=n//  : \nChapter  notes  \nKnuth  [261]  contains  a good  discussion  of simple  binary  search trees as well as \nmany variations. Binary search trees seem to have b een independently discovered \nby  a number  of people  in the  late  1950s.  Radix  trees  are  often  called <tries,= which \ncomes from the middle letters in the word retrieval. Knuth  [261]  also  discusses  \nthem. \nMany  texts,  including  the  \u00fbrst  two  editions  of this  book,  describe a somewhat \nsimpler method of deleting a node from a binary sea rch tree when both  of its  chil-  \ndren are present. Instead of replacing node \u00b4 by its successor y , delete node y but \ncopy its key and satellite data into node \u00b4. The downside of this approach is that \nthe node actually deleted might not be the node pas sed to the delete procedure. If \nother components of a program maintain pointers to nodes in the tree, they could \nmistakenly end up with <stale= pointers to nodes th at have been deleted. Although \nthe deletion method presented in this edition of th is book is a bit more complicated, \nit guarantees that a call to delete node \u00b4 deletes node \u00b4 and only node \u00b4. \nSection  14.5  will  show  how  to construct  an optimal  binary  search tree when \nyou know the search frequencies before constructing  the tree. That is, given the \nfrequencies of searching for each key and the frequ encies of searching for values \nthat fall between keys in the tree, a set of search es in the constructed binary search \ntree examines the minimum number of nodes. 13  Red-Black  Trees  \nChapter  12  showed  that  a binary  search  tree  of height  h can support any of the basic \ndynamic-set  operations4such  as SEARCH , PREDECESSOR , SUCCESSOR , M INI - \nMUM , MAXIMUM , I NSERT , and D ELETE4in  O.h/  time. Thus, the set operations \nare fast if the height of the search tree is small.  If its height is large, however, the \nset  operations  may  run  no  faster  than  with  a linked  list.  Red- black trees are one \nof many  search-tree  schemes  that  are  <balanced=  in order  to guarantee that basic \ndynamic-set  operations  take  O.lg n/ time in the worst case. \n13.1  Properties  of red-black  trees  \nA red-black  tree  is a binary search tree with one extra bit of stora ge per node: its \ncolor , which can be either RED or BLACK . By constraining the node colors on \nany  simple  path  from  the  root  to a leaf,  red-black  trees  ensur e that no such path is \nmore than twice as long as any other, so that the t ree is approximately balanced . \nIndeed,  as we\u2019re  about  to see,  the  height  of a red-black  tree  with n keys is at most \n2 lg.n C 1/, which is O.lg n/. \nEach node of the tree now contains the attributes color  , key, left , right , and p. If \na child or the parent of a node does not exist, the  corresponding pointer attribute of \nthe node contains the value NIL. Think of these NILs as pointers to leaves (external \nnodes)  of the  binary  search  tree  and  the  normal,  key-bearing  nodes as internal nodes \nof the tree. \nA red-black  tree  is a binary  search  tree  that  satis\u00fbes  the  following red-black  \nproperties : \n1. Every  node  is either  red  or black.  \n2. The root is black. \n3. Every  leaf  (NIL) is black. 332  Chapter  13  Red-Black  Trees  \n4. If a node  is red,  then  both  its  children  are  black.  \n5. For  each  node,  all  simple  paths  from  the  node  to descendant  leaves contain the \nsame number of black nodes. \nFigure  13.1(a)  shows  an example  of a red-black  tree.  \nAs a matter of convenience in dealing with boundary  conditions in red-black  \ntree code, we use a single sentinel to represent NIL (see  page  262).  For  a red-black  \ntree T , the sentinel T: nil is an object with the same attributes as an ordinar y node \nin the tree. Its color  attribute is BLACK, and  its  other  attributes4p, left , right , \nand key4can  take  on  arbitrary  values.  As  Figure  13.1(b)  shows,  all  pointers to NIL \nare replaced by pointers to the sentinel T: nil. \nWhy  use  the  sentinel?  The  sentinel  makes  it possible  to treat  a NIL child of a \nnode x as an ordinary node whose parent is x . An alternative design would use a \ndistinct sentinel node for each NIL in the tree, so that the parent of each NIL is well \nde\u00fbned.  That  approach  needlessly  wastes  space,  however.  Instead, just the one \nsentinel T: nil represents all the NILs4all  leaves  and  the  root\u2019s  parent.  The  values  \nof the attributes p, left, right , and key  of the  sentinel  are  immaterial.  The  red-black  \ntree procedures can place whatever values in the se ntinel that yield simpler code. \nWe  generally  con\u00fbne  our  interest  to the  internal  nodes  of a red-black  tree,  since  \nthey hold the key values. The remainder of this cha pter omits the leaves in drawings \nof red-black  trees,  as shown  in Figure  13.1(c).  \nWe call the number of black nodes on any simple pat h from, but not including, a \nnode x down to a leaf the black-height  of the node, denoted bh .x/. By  property  5, \nthe  notion  of black-height  is well  de\u00fbned,  since  all  descend ing simple paths from \nthe  node  have  the  same  number  of black  nodes.  The  black-height  of a red-black  \ntree  is the  black-height  of its  root.  \nThe  following  lemma  shows  why  red-black  trees  make  good  search trees. \nLemma  13.1  \nA red-black  tree  with  n internal nodes has height at most 2 lg.n C 1/. \nProof  We start by showing that the subtree rooted at any node x contains at least \n2 bh.x/  \ue003 1 internal nodes. We prove this claim by induction on  the height of x . If \nthe height of x is 0, then x must be a leaf ( T: nil), and the subtree rooted at x indeed \ncontains at least 2 bh.x/  \ue003 1 D 2 0 \ue003 1 D 0 internal nodes. For the inductive step, \nconsider a node x that has positive height and is an internal node. T hen node x \nhas two children, either or both of which may be a leaf. If a child is black, then \nit contributes 1 to x \u2019s black-height  but  not  to its  own.  If a child  is red,  then  it \ncontributes to neither x \u2019s black-height  nor  its  own.  Therefore,  each  child  has  a \nblack-height  of either  bh.x/  \ue003 1 (if  it\u2019s  black)  or bh.x/  (if  it\u2019s  red).  Since  the  \nheight of a child of x is less than the height of x itself, we can apply the inductive 13.1  Properties  of red-black  trees  333 \nNIL  NIL  NIL  NIL  NIL  NIL  NIL  NIL  NIL  \nNIL  NIL  NIL  NIL  NIL  NIL  \nNIL  NIL  NIL  NIL  NIL  NIL  26  \n41  \n47  30  \n28  38  \n35  39  17  \n21  \n23  19  \n20  14  \n16  \n15  10  \n12  7 \n3 1 1 1 2 \n1 1 2 \n1 1 1 2 3 \n1 1 1 1 2 1 2 3 \n(a) \n26  \n41  \n47  30  \n28  38  \n35  39  17  \n21  \n23  19  \n20  14  \n16  \n15  10  \n12  7 \n3 \n(b) \n26  \n41  \n47  30  \n28  38  \n35  39  17  \n21  \n23  19  \n20  14  \n16  \n15  10  \n12  7 \n3 (c) T: nil \nFigure  13.1  A red-black  tree.  Every  node  in a red-black  tree  is either  red  or black, the children \nof a red node are both black, and every simple path  from a node to a descendant leaf contains the \nsame number of black nodes. (a)  Every leaf, shown as a NIL, is black.  Each  non- NIL node is marked \nwith  its  black-height,  where  NILs have  black-height  0. (b)  The  same  red-black  tree  but  with  each  NIL \nreplaced by the single sentinel T: nil, which  is always  black,  and  with  black-heights  omitted.  The  \nroot\u2019s  parent  is also  the  sentinel.  (c)  The  same  red-black  tree  but  with  leaves  and  the  root\u2019s  parent  \nomitted entirely. The remainder of this chapter use s this drawing style. 334  Chapter  13  Red-Black  Trees  \nhypothesis to conclude that each child has at least  2 bh.x/\ue0021 \ue003 1 internal nodes. Thus, \nthe subtree rooted at x contains at least .2 bh.x/\ue0021 \ue0031/ C.2 bh.x/\ue0021 \ue0031/ C1 D 2 bh.x/  \ue0031 \ninternal nodes, which proves the claim. \nTo complete the proof of the lemma, let h be the height of the tree. According \nto property  4, at least  half  the  nodes  on  any  simple  path  from  the root to a leaf, not \nincluding  the  root,  must  be black.  Consequently,  the  black- height of the root must \nbe at least h=2, and thus, \nn \ue004 2 h=2  \ue003 1:  \nMoving the 1 to the  left-hand  side  and  taking  logarithms  on  both  sides  yields \nlg.n C 1/ \ue004 h=2, or h \u0dc4 2 lg.n C 1/. \nAs an immediate consequence of this lemma, each of the dynamic-set  opera-  \ntions S EARCH , M INIMUM , M AXIMUM , SUCCESSOR , and PREDECESSOR  runs \nin O.lg n/ time  on  a red-black  tree,  since  each  can  run  in O.h/  time  on  a bi-  \nnary search tree of height h (as  shown  in Chapter  12)  and  any  red-black  tree  on  \nn nodes is a binary search tree with height O.lg n/. (Of  course,  references  to NIL \nin the  algorithms  of Chapter  12  have  to be replaced  by  T: nil.) Although  the  pro-  \ncedures T REE-I NSERT and T REE-DELETE from  Chapter  12  run  in O.lg n/ time \nwhen  given  a red-black  tree  as input,  you  cannot  just  use  them  to implement the \ndynamic-set  operations  I NSERT and D ELETE . They do not necessarily maintain \nthe  red-black  properties,  so you  might  not  end  up  with  a legal  red-black  tree.  The  \nremainder of this chapter shows how to insert into and delete from  a red-black  tree  \nin O.lg n/ time. \nExercises  \n13.1-1  \nIn the  style  of Figure  13.1(a),  draw  the  complete  binary  search tree of height 3 on \nthe keys f1;2;:::;15 g. Add the NIL leaves and color the nodes in three different \nways  such  that  the  black-heights  of the  resulting  red-black  trees are 2, 3, and 4. \n13.1-2  \nDraw  the  red-black  tree  that  results  after  TREE-I NSERT is called on the tree in \nFigure  13.1  with  key  36. If the inserted node is colored red, is the resul ting tree a \nred-black  tree?  What  if it is colored  black?  \n13.1-3  \nDe\u00fbne  a relaxed  red-black  tree  as a binary  search  tree  that  satis\u00fbes  red-black  prop-  \nerties  1, 3, 4, and  5, but  whose  root  may  be either  red  or black.  Consider a relaxed \nred-black  tree  T whose root is red. If the root of T is changed to black but no other \nchanges  occur,  is the  resulting  tree  a red-black  tree?  13.2 Rotations 335 \n13.1-4  \nSuppose  that  every  black  node  in a red-black  tree  <absorbs=  all of its red children, \nso that the children of any red node become childre n of the black parent. (Ignore \nwhat happens to the keys.) What are the possible de grees of a black node after all \nits  red  children  are  absorbed?  What  can  you  say  about  the  depths of the leaves of \nthe  resulting  tree?  \n13.1-5  \nShow that the longest simple path from a node x in a red-black  tree  to a descendant  \nleaf has length at most twice that of the shortest simple path from node x to a \ndescendant leaf. \n13.1-6  \nWhat is the largest possible number of internal nod es in a red-black  tree  with  black-  \nheight k? What  is the  smallest  possible  number?  \n13.1-7  \nDescribe  a red-black  tree  on  n keys  that  realizes  the  largest  possible  ratio  of red  in-  \nternal  nodes  to black  internal  nodes.  What  is this  ratio?  Wha t tree has the smallest \npossible  ratio,  and  what  is the  ratio?  \n13.1-8  \nArgue  that  in a red-black  tree,  a red  node  cannot  have  exactly  one  non- NIL child. \n13.2  Rotations  \nThe  search-tree  operations  TREE-I NSERT and T REE-DELETE, when  run  on  a red-  \nblack tree with n keys, take O.lg n/ time. Because they modify the tree, the result \nmay  violate  the  red-black  properties  enumerated  in Section  13.1.  To  restore  these  \nproperties, colors and pointers within nodes need t o change. \nThe pointer structure changes through rotation , which is a local operation in a \nsearch  tree  that  preserves  the  binary-search-tree  property.  Figure  13.2  shows  the  \ntwo kinds of rotations: left rotations and right ro tations. Let\u2019s  look  at a left  rotation  \non a node x , which  transforms  the  structure  on  the  right  side  of the  \u00fbgur e to the \nstructure on the left. Node x has a right child y , which must not be T: nil. The left \nrotation changes the subtree originally rooted at x by <twisting= the link between x \nand y to the left. The new root of the subtree is node y , with x as y \u2019s left  child  and  \ny \u2019s original  left  child  (the  subtree  represented  by  \u02c7 in the  \u00fbgure)  as x \u2019s right  child.  \nThe pseudocode for L EFT-ROTATE  appearing on the following page assumes \nthat x: right \u00a4 T: nil and  that  the  root\u2019s  parent  is T: nil. Figure  13.3  shows  an 336  Chapter  13  Red-Black  Trees  \ny \nx \n\u00b3 \u00b4 \u00b5 x \ny \u00b3 \n\u00b4 \u00b5 LEFT-ROTATE (T, x) \nRIGHT-ROTATE (T, y) \nFigure  13.2  The rotation operations on a binary search tree. Th e operation L EFT-ROTATE.T;x/  \ntransforms  the  con\u00fbguration  of the  two  nodes  on  the  right  into  the  con\u00fbguration  on  the  left  by  chang-  \ning a constant number of pointers. The inverse oper ation RIGHT-ROTATE.T;y/  transforms  the  con-  \n\u00fbguration  on  the  left  into  the  con\u00fbguration  on  the  right.  The  letters \u02db, \u02c7, and \ufffd represent arbitrary \nsubtrees.  A rotation  operation  preserves  the  binary-search-tree  property:  the  keys  in \u02db precede x: key, \nwhich precedes the keys in \u02c7, which precede y: key, which precedes the keys in \ufffd . \nexample of how L EFT-ROTATE  modi\u00fbes  a binary  search  tree.  The  code  for  RIGHT- \nROTATE  is symmetric. Both L EFT-ROTATE  and RIGHT-ROTATE  run in O.1/  time. \nOnly  pointers  are  changed  by  a rotation,  and  all  other  attrib utes in a node remain \nthe same. \nLEFT-ROTATE  .T;x/  \n1 y D x: right \n2 x: right D y: left / / turn y \u2019s left  subtree  into  x \u2019s right  subtree  \n3 if y: left \u00a4 T: nil / / if y \u2019s left  subtree  is not  empty  . . . \n4 y: left: p D x / / . . . then x becomes  the  parent  of the  subtree\u2019s  root  \n5 y: p D x: p / / x \u2019s parent  becomes  y \u2019s parent  \n6 if x: p == T: nil / / if x was the root . . . \n7 T: root D y / / . . . then y becomes the root \n8 elseif  x == x: p: left / / otherwise, if x was a left child . . . \n9 x: p: left D y / / . . . then y becomes a left child \n10  else  x: p: right D y / / otherwise, x was a right child, and now y is \n11  y: left D x / / make x become y \u2019s left  child  \n12  x: p D y \nExercises  \n13.2-1  \nWrite pseudocode for R IGHT-ROTATE . 13.2 Rotations 337 \n2 3 4 \n6 7 \n11  \n9 18  \n14  \n12  17  19  \n22 \n20 x \ny \n2 3 4 \n6 7 \n18  \n19  \n14  \n12  17  22 \n20 x y \n11  \n9 LEFT-ROTATE (T, x) \nFigure  13.3  An example of how the procedure L EFT-ROTATE.T;x/  modi\u00fbes  a binary  search  tree.  \nInorder  tree  walks  of the  input  tree  and  the  modi\u00fbed  tree  prod uce the same listing of key values. \n13.2-2  \nArgue that in every n-node  binary  search  tree,  there  are  exactly  n \ue003 1 possible \nrotations. \n13.2-3  \nLet a, b, and c be arbitrary nodes in subtrees \u02db, \u02c7, and \ufffd , respectively, in the right \ntree  of Figure  13.2.  How  do  the  depths  of a, b, and c change when a left rotation \nis performed on node x in the  \u00fbgure?  \n13.2-4  \nShow that any arbitrary n-node  binary  search  tree  can  be transformed  into  any  other  \narbitrary n-node  binary  search  tree  using  O.n/  rotations. ( Hint: First show that at \nmost n \ue003 1 right  rotations  suf\u00fbce  to transform  the  tree  into  a right-go ing chain.) \n? 13.2-5  \nWe say that a binary search tree T 1 can be right-converted  to binary search tree T 2 \nif it is possible to obtain T 2 from T 1 via a series of calls to R IGHT-ROTATE. Give  \nan example of two trees T 1 and T 2 such that T 1 cannot  be right-converted  to T 2 . \nThen, show that if a tree T 1 can  be right-converted  to T 2 , it can  be right-converted  \nusing O.n  2 / calls to RIGHT-ROTATE . 338  Chapter  13  Red-Black  Trees  \n13.3  Insertion  \nIn order  to insert  a node  into  a red-black  tree  with  n internal nodes in O.lg n/ time \nand  maintain  the  red-black  properties,  we\u2019ll  need  to slight ly modify the T REE- \nI NSERT procedure  on  page  321.  The  procedure  RB-I  NSERT starts by inserting \nnode \u00b4 into the tree T as if it were  an ordinary  binary  search  tree,  and  then  it col-  \nors \u00b4 red.  (Exercise  13.3-1  asks  you  to explain  why  to make  node  \u00b4 red rather \nthan  black.)  To  guarantee  that  the  red-black  properties  are  preserved, an auxiliary \nprocedure  RB-I  NSERT-FIXUP on  the  facing  page  recolors  nodes  and  performs  ro-  \ntations.  The  call  RB-I  NSERT .T;\u00b4/  inserts node \u00b4, whose key  is assumed to have \nalready  been  \u00fblled  in,  into  the  red-black  tree  T . \nRB-I  NSERT .T;\u00b4/  \n1 x D T: root / / node being compared with \u00b4 \n2 y D T: nil / / y will be parent of \u00b4 \n3 while  x \u00a4 T: nil / / descend until reaching the sentinel \n4 y D x \n5 if \u00b4: key  <x:  key  \n6 x D x: left \n7 else  x D x: right \n8 \u00b4: p D y / / found  the  location4insert  \u00b4 with parent y \n9 if y = = T: nil \n10  T: root D \u00b4 / / tree T was empty \n11  elseif  \u00b4: key  <y:  key  \n12  y: left D \u00b4 \n13  else  y: right D \u00b4 \n14  \u00b4: left D T: nil / / both of \u00b4\u2019s children  are  the  sentinel  \n15  \u00b4: right D T: nil \n16  \u00b4: color  D RED / / the new node starts out red \n17  RB-I  NSERT-FIXUP .T;\u00b4/  / / correct  any  violations  of red-black  properties  \nThe procedures T REE-I NSERT and  RB-I  NSERT differ in four ways. First, all \ninstances of NIL in T REE-I NSERT are replaced by T: nil. Second,  lines  14315  of \nRB-I  NSERT set \u00b4: left and \u00b4: right to T: nil, in order to maintain the proper tree \nstructure. (T REE-I NSERT assumed that \u00b4\u2019s children  were  already  NIL.) Third, \nline  16  colors  \u00b4 red. Fourth, because coloring \u00b4 red may cause a violation of one \nof the  red-black  properties,  line  17  of RB-I  NSERT calls  RB-I  NSERT-FIXUP .T;\u00b4/  \nin order  to restore  the  red-black  properties.  13.3 Insertion 339 \nRB-I  NSERT-FIXUP .T;\u00b4/  \n1 while  \u00b4: p: color  == RED \n2 if \u00b4: p = = \u00b4: p: p: left / / is \u00b4\u2019s parent  a left  child?  \n3 y D \u00b4: p: p: right / / y is \u00b4\u2019s uncle  \n4 if y: color  == RED / / are \u00b4\u2019s parent  and  uncle  both  red?  \n5 \u00b4: p: color  D BLACK  * \ncase  1 6 y: color  D BLACK  \n7 \u00b4: p: p: color  D RED \n8 \u00b4 D \u00b4: p: p \n9 else  \n10  if \u00b4 == \u00b4: p: right \n11  \u00b4 D \u00b4: p \u00f0 \ncase 2 12  LEFT-ROTATE  .T;\u00b4/  \n13  \u00b4: p: color  D BLACK  ) \ncase  3 14  \u00b4: p: p: color  D RED \n15  RIGHT-ROTATE  .T;\u00b4:  p: p/ \n16  else  / / same  as lines  3315,  but  with  <right=  and  <left=  exchanged  \n17  y D \u00b4: p: p: left \n18  if y: color  == RED \n19  \u00b4: p: color  D BLACK  \n20 y: color  D BLACK  \n21  \u00b4: p: p: color  D RED \n22 \u00b4 D \u00b4: p: p \n23  else  \n24  if \u00b4 == \u00b4: p: left \n25  \u00b4 D \u00b4: p \n26  RIGHT-ROTATE  .T;\u00b4/  \n27  \u00b4: p: color  D BLACK  \n28  \u00b4: p: p: color  D RED \n29 LEFT-ROTATE  .T;\u00b4:  p: p/ \n30  T: root : color  D BLACK  \nTo  understand  how  RB-I  NSERT-FIXUP works,  let\u2019s  examine  the  code  in three  \nmajor  steps.  First,  we\u2019ll  determine  which  violations  of the  red-black  properties  \nmight  arise  in RB-I  NSERT upon inserting node \u00b4 and  coloring  it red.  Second,  we\u2019ll  \nconsider the overall goal of the while  loop  in lines  1329.  Finally,  we\u2019ll  explore  each  \nof the three cases within the while  loop\u2019s  body  (case  2 falls  through  into  case  3, so \nthese two cases are not mutually exclusive) and see  how they accomplish the goal. 340  Chapter  13  Red-Black  Trees  \nIn describing  the  structure  of a red-black  tree,  we\u2019ll  often  need to refer to the \nsibling  of a node\u2019s  parent.  We  use  the  term  uncle  for such a node. 1 Figure  13.4  \nshows  how  RB-I  NSERT-FIXUP operates  on  a sample  red-black  tree,  with  cases  \ndepending in part on the colors of a node, its pare nt, and its uncle. \nWhat  violations  of the  red-black  properties  might  occur  upon the call to \nRB-I  NSERT-FIXUP ? Property  1 certainly  continues  to hold  (every  node  is eithe r \nred  or black),  as does  property  3 (every  leaf  is black),  since  both children of the \nnewly inserted red node are the sentinel T: nil. Property  5, which  says  that  the  \nnumber of black nodes is the same on every simple p ath from a gi ven  node,  is sat-  \nis\u00fbed  as well,  because  node  \u00b4 replaces the (black) sentinel, and node \u00b4 is red with \nsentinel children. Thus, the only properties that m ight be violated are property 2, \nwhich  requires  the  root  to be black,  and  property  4, which  says that a red node \ncannot have a red child. Both possible violations m ay arise because \u00b4 is colored \nred. Property 2 is violated if \u00b4 is the  root,  and  property  4 is violated  if \u00b4\u2019s parent  \nis red.  Figure  13.4(a)  shows  a violation  of property  4 after  the node \u00b4 has been \ninserted. \nThe while  loop  of lines  1329  has  two  symmetric  possibilities:  lines  3315  deal  \nwith the situation in which node \u00b4\u2019s parent  \u00b4: p is a left child of \u00b4\u2019s grandpar-  \nent \u00b4: p: p, and  lines  17329  apply  when  \u00b4\u2019s parent  is a right  child.  Our  proof  will  \nfocus  only  on  lines  3315,  relying  on  the  symmetry  in lines  17329. \nWe\u2019ll  show  that  the  while  loop  maintains  the  following  three-part  invariant  at \nthe start of each iteration of the loop: \na. Node \u00b4 is red. \nb. If \u00b4: p is the root, then \u00b4: p is black. \nc. If the  tree  violates  any  of the  red-black  properties,  then  it violates at most \none of them, and the violation is of either propert y 2 or prope rty  4, but  \nnot both. If the tree violates property 2, it is be cause \u00b4 is the root and is \nred.  If the  tree  violates  property  4, it is because  both  \u00b4 and \u00b4: p are red. \nPart  (c),  which  deals  with  violations  of red-black  properti es, is more central to \nshowing  that  RB-I  NSERT-FIXUP restores  the  red-black  properties  than  parts  (a)  \nand  (b),  which  we\u2019ll  use  along  the  way  to understand  situations  in the  code.  Be-  \ncause  we\u2019ll  be focusing  on  node  \u00b4 and nodes near it in the tree, it helps to know \nfrom part (a) that \u00b4 is red. Part (b) will help show that \u00b4\u2019s grandparent  \u00b4: p: p exists \nwhen  it\u2019s  referenced  in lines  2, 3, 7, 8, 14,  and  15  (recall  that  we\u2019re  focusing  only  \non  lines  3315).  \n1 Although we try to avoid gendered language in this book, the English  language  lacks  a gender-  \nneutral  word  for  a parent\u2019s  sibling.  13.3 Insertion 341 \nz y 11  \n2 \n1 7 \n5 \n4 8 14  \n15  \nz y 11  \n2 \n1 7 \n5 \n4 8 14  \n15  (a) \n(b) Case  1 \nz y 11  \n7 \n2 8 \n4 14  \n15  (c) Case 2 \n1 5 4 \nz 7 \n2 \n1 5 11  \n14  (d) Case  3 \n4 8 \n15  \nFigure  13.4  The  operation  of RB-I  NSERT-FIXUP . (a)  A node \u00b4 after insertion. Because both \u00b4 \nand its parent \u00b4: p are  red,  a violation  of property  4 occurs.  Since  \u00b4\u2019s uncle  y is red,  case  1 in the  code  \napplies. Node \u00b4\u2019s grandparent  \u00b4: p: p must be black, and its blackness transfers down one  level to \u00b4\u2019s \nparent  and  uncle.  Once  the  pointer  \u00b4 moves up two levels in the tree, the tree shown in (b)  results. \nOnce  again,  \u00b4 and its parent are both red, but this time \u00b4\u2019s uncle  y is black. Since \u00b4 is the right child \nof \u00b4: p, case 2 applies. Performing a left rotation results in the tree in (c). Now \u00b4 is the left child \nof its  parent,  and  case  3 applies.  Recoloring  and  right  rotat ion yield the tree in (d), which is a legal \nred-black  tree.  342  Chapter  13  Red-Black  Trees  \nRecall that to use a loop invariant, we need to sho w that the invariant is true \nupon  entering  the  \u00fbrst  iteration  of the  loop,  that  each  iteration maintains it, that \nthe loop terminates, and that the loop invariant gi ves us a useful property at loop \ntermination.  We\u2019ll  see  that  each  iteration  of the  loop  has  two possible outcomes: \neither the pointer \u00b4 moves up the tree, or some rotations occur and then  the loop \nterminates. \nInitialization:  Before  RB-I  NSERT is called,  the  red-black  tree  has  no  violations.  \nRB-I  NSERT adds a red node \u00b4 and  calls  RB-I  NSERT-FIXUP. We\u2019ll  show  that  \neach  part  of the  invariant  holds  at the  time  RB-I  NSERT-FIXUP is called: \na. When  RB-I  NSERT-FIXUP is called, \u00b4 is the red node that was added. \nb. If \u00b4: p is the root, then \u00b4: p started out black and did not change before the \ncall  of RB-I  NSERT-FIXUP . \nc. We  have  already  seen  that  properties  1, 3, and  5 hold  when  RB-I  NSERT- \nFIXUP is called. \nIf the tree violates property 2 (the root must be b lack), then the red root \nmust be the newly added node \u00b4, which is the only internal node in the tree. \nBecause the parent and both children of \u00b4 are the sentinel, which is black, the \ntree  does  not  also  violate  property  4 (both  children  of a red  node are black). \nThus this violation of property 2 is the only viola tion of red-black  properties  \nin the entire tree. \nIf the  tree  violates  property  4, then,  because  the  children  of node \u00b4 are black \nsentinels and the tree had no other violations prio r to \u00b4 being added, the \nviolation must be because both \u00b4 and \u00b4: p are red. Moreover, the tree violates \nno  other  red-black  properties.  \nMaintenance:  There are six cases within the while  loop,  but  we\u2019ll  examine  only  \nthe  three  cases  in lines  3315,  when  node  \u00b4\u2019s parent  \u00b4: p is a left child of \u00b4\u2019s \ngrandparent \u00b4: p: p. The  proof  for  lines  17329  is symmetric.  The  node  \u00b4: p: p \nexists, since by part (b) of the loop invariant, if  \u00b4: p is the root, then \u00b4: p is \nblack.  Since  RB-I  NSERT-FIXUP enters a loop iteration only if \u00b4: p is red, we \nknow that \u00b4: p cannot be the root. Hence, \u00b4: p: p exists. \nCase  1 differs  from  cases  2 and  3 by  the  color  of \u00b4\u2019s uncle  y . Line  3 makes  \ny point to \u00b4\u2019s uncle  \u00b4: p: p: right , and  line  4 tests  y \u2019s color.  If y is red, then \ncase  1 executes.  Otherwise,  control  passes  to cases  2 and  3. In all three cases, \n\u00b4\u2019s grandparent  \u00b4: p: p is black, since its parent \u00b4: p is red,  and  property  4 is \nviolated only between \u00b4 and \u00b4: p. 13.3 Insertion 343 \nz y C \nD A \nB \u00b3 \n\u00b4 \u00b5 \u00b6 \u03b5 (a) C \nD A \nB \u00b3 \n\u00b4 \u00b5 \u00b6 \u03b5 new z \ny C \nD B \n\u00b6 \u03b5 C \nD B \nA \n\u00b3 \u00b4 \u00b5 \u00b6 \u03b5 new z \n(b) \nA \n\u00b3 \u00b4 \u00b5 z \nFigure  13.5  Case  1 of the  procedure  RB-I  NSERT-FIXUP . Both \u00b4 and its parent \u00b4: p are  red,  violat-  \ning  property  4. In case  1, \u00b4\u2019s uncle  y is red. The same action occurs regardless of whethe r (a)  \u00b4 is a \nright child or (b)  \u00b4 is a left child. Each of the subtrees \u02db, \u02c7, \ufffd , \u0131, and \" has  a black  root4possibly  \nthe  sentinel4and  each  has  the  same  black-height.  The  code  for  case  1 moves  the  blackness  of \u00b4\u2019s \ngrandparent down to \u00b4\u2019s parent  and  uncle,  preserving  property  5: all  downward  simple paths from a \nnode to a leaf have the same number of blacks. The while  loop continues with node \u00b4\u2019s grandpar-  \nent \u00b4: p: p as the new \u00b4. If the  action  of case  1 causes  a new  violation  of property  4 to occur, it must \nbe only between the new \u00b4, which is red, and its parent, if it is red as wel l. \nCase  1: \u00b4\u2019s uncle  y is red  \nFigure  13.5  shows  the  situation  for  case  1 (lines  538),  which  occurs when \nboth \u00b4: p and y are red. Because \u00b4\u2019s grandparent  \u00b4: p: p is black, its blackness \ncan transfer down one level to both \u00b4: p and y , thereby  \u00fbxing  the  problem  of \u00b4 \nand \u00b4: p both being red. Having had its blackness transferre d down one level, \n\u00b4\u2019s grandparent  becomes  red,  thereby  maintaining  property  5. The while  loop \nrepeats with \u00b4: p: p as the new node \u00b4, so that the pointer \u00b4 moves up two levels \nin the tree. \nNow,  we  show  that  case  1 maintains  the  loop  invariant  at the  start of the next \niteration. We use \u00b4 to denote node \u00b4 in the current iteration, and \u00b4 0 D \u00b4: p: p \nto denote the node that will be called node \u00b4 at the  test  in line  1 upon  the  next  \niteration. \na. Because this iteration colors \u00b4: p: p red, node \u00b4 0 is red at the start of the next \niteration. \nb. The node \u00b4 0 : p is \u00b4: p: p: p in this iteration, and the color of this node does not \nchange. If this node is the root, it was black prio r to this iteration, and it \nremains black at the start of the next iteration. 344  Chapter  13  Red-Black  Trees  \nC \nA \nB \u00b3 \n\u00b4 \u00b5 \u00b6 \nCase 2 z y B \nA \n\u00b3 \u00b4 \u00b5 \u00b6 \nCase  3 z y z A B \nC \n\u00b3 \u00b4 \u00b5 \u00b6 C \nFigure  13.6  Cases  2 and  3 of the  procedure  RB-I  NSERT-FIXUP. As  in case  1, property  4 is violated  \nin either  case  2 or case  3 because  \u00b4 and its parent \u00b4: p are both red. Each of the subtrees \u02db, \u02c7, \ufffd , \nand \u0131 has a black root ( \u02db, \u02c7, and \ufffd from  property  4, and  \u0131 because  otherwise  case  1 would  apply),  \nand  each  has  the  same  black-height.  Case  2 transforms  into  case  3 by  a left  rotation,  which  preserves  \nproperty  5: all  downward  simple  paths  from  a node  to a leaf  have  the  same  number  of blacks.  Case  3 \ncauses some color changes and a right rotation, whi ch also preserve  property  5. The  while  loop then \nterminates,  because  property  4 is satis\u00fbed:  there  are  no  longer two red nodes in a row. \nc. We  have  already  argued  that  case  1 maintains  property  5, and it does not \nintroduce  a violation  of properties  1 or 3. \nIf node \u00b4 0 is the  root  at the  start  of the  next  iteration,  then  case  1 corrected \nthe  lone  violation  of property  4 in this  iteration.  Since  \u00b4 0 is red and it is the \nroot, property 2 becomes the only one that is viola ted, and this violation is \ndue to \u00b4 0 . \nIf node \u00b4 0 is not  the  root  at the  start  of the  next  iteration,  then  case  1 has \nnot  created  a violation  of property  2. Case  1 corrected  the  lone violation \nof property  4 that  existed  at the  start  of this  iteration.  It then made \u00b4 0 red \nand left \u00b4 0 : p alone. If \u00b4 0 : p was  black,  there  is no  violation  of property  4. \nIf \u00b4 0 : p was red, coloring \u00b4 0 red  created  one  violation  of property  4, between  \u00b4 0 \nand \u00b4 0 : p. \nCase  2: \u00b4\u2019s uncle  y is black  and  \u00b4 is a right  child  \nCase  3: \u00b4\u2019s uncle  y is black  and  \u00b4 is a left  child  \nIn cases  2 and  3, the  color  of \u00b4\u2019s uncle  y is black. We distinguish the two cases, \nwhich assume that \u00b4\u2019s parent  \u00b4: p is red and a left child, according to whether \u00b4 \nis a right or left child of \u00b4: p. Lines  11312  constitute  case  2, which  is shown  in \nFigure  13.6  together  with  case  3. In case  2, node  \u00b4 is a right child of its parent. \nA left rotation immediately transforms the situatio n into case  3 (lines  13315),  in \nwhich node \u00b4 is a left child. Because both \u00b4 and \u00b4: p are red, the rotation affects \nneither  the  black-heights  of nodes  nor  property  5. Whether  case  3 executes  \ndirectly or through case 2, \u00b4\u2019s uncle  y is black,  since  otherwise  case  1 would  \nhave run. Additionally, the node \u00b4: p: p exists, since we have argued that this 13.3 Insertion 345 \nnode  existed  at the  time  that  lines  2 and  3 were  executed,  and  after moving \u00b4 \nup  one  level  in line  11  and  then  down  one  level  in line  12,  the  identity of \u00b4: p: p \nremains  unchanged.  Case  3 performs  some  color  changes  and  a right rotation, \nwhich  preserve  property  5. At  this  point,  there  are  no  longer  two red nodes in \na row. The while  loop  terminates  upon  the  next  test  in line  1, since  \u00b4: p is now \nblack. \nWe  now  show  that  cases  2 and  3 maintain  the  loop  invariant.  (As  we have just \nargued, \u00b4: p will  be black  upon  the  next  test  in line  1, and  the  loop  body  will not \nexecute again.) \na. Case 2 makes \u00b4 point to \u00b4: p, which is red. No further change to \u00b4 or its color \noccurs  in cases  2 and  3. \nb. Case  3 makes  \u00b4: p black, so that if \u00b4: p is the root at the start of the next \niteration, it is black. \nc. As  in case  1, properties  1, 3, and  5 are  maintained  in cases  2 and  3. \nSince node \u00b4 is not  the  root  in cases  2 and  3, we  know  that  there  is no  viola-  \ntion  of property  2. Cases  2 and  3 do  not  introduce  a violation  of property 2, \nsince the only node that is made red becomes a chil d of a black node by the \nrotation  in case  3. \nCases  2 and  3 correct  the  lone  violation  of property  4, and  they  do  not  intro-  \nduce another violation. \nTermination:  To  see  that  the  loop  terminates,  observe  that  if only  case  1 occurs, \nthen the node pointer \u00b4 moves  toward  the  root  in each  iteration,  so that  eventu-  \nally \u00b4: p is black. (If \u00b4 is the root, then \u00b4: p is the sentinel T: nil, which is black.) \nIf either  case  2 or case  3 occurs,  then  we\u2019ve  seen  that  the  loop  terminates. Since \nthe loop terminates because \u00b4: p is black,  the  tree  does  not  violate  property  4 \nat loop termination. By the loop invariant, the onl y property that might fail to \nhold  is property  2. Line  30  restores  this  property  by  colorin g the root black, so \nthat  when  RB-I  NSERT-FIXUP terminates,  all  the  red-black  properties  hold.  \nThus,  we  have  shown  that  RB-I  NSERT-FIXUP correctly  restores  the  red-black  \nproperties. \nAnalysis  \nWhat  is the  running  time  of RB-I  NSERT? Since  the  height  of a red-black  tree  on  n \nnodes is O.lg n/, lines  1316  of RB-I  NSERT take O.lg n/ time.  In RB-I  NSERT- \nFIXUP , the while  loop  repeats  only  if case  1 occurs,  and  then  the  pointer  \u00b4 moves \ntwo levels up the tree. The total number of times t he while  loop can be executed \nis therefore O.lg n/. Thus,  RB-I  NSERT takes a total of O.lg n/ time. Moreover, it 346  Chapter  13  Red-Black  Trees  \nnever performs more than two rotations, since the while  loop terminates if case 2 \nor case  3 is executed.  \nExercises  \n13.3-1  \nLine  16  of RB-I  NSERT sets the color of the newly inserted node \u00b4 to red.  If in-  \nstead \u00b4\u2019s color  were  set  to black,  then  property  4 of a red-black  tree  would not be \nviolated. Why not set \u00b4\u2019s color  to black?  \n13.3-2  \nShow  the  red-black  trees  that  result  after  successively  inserting the keys 41;38;31;  \n12;19;8  into  an initially  empty  red-black  tree.  \n13.3-3  \nSuppose  that  the  black-height  of each  of the  subtrees  \u02db; \u02c7; \ufffd; \u0131; \"  in Figures  13.5  \nand  13.6  is k. Label  each  node  in each  \u00fbgure  with  its  black-height  to verif y that \nthe  indicated  transformation  preserves  property  5. \n13.3-4  \nProfessor  Teach  is concerned  that  RB-I  NSERT-FIXUP might set T: nil: color  to \nRED, in which  case  the  test  in line  1 would  not  cause  the  loop  to terminate when \u00b4 \nis the  root.  Show  that  the  professor\u2019s  concern  is unfounded  by  arguing  that  RB-  \nI NSERT-FIXUP never sets T: nil: color  to RED. \n13.3-5  \nConsider  a red-black  tree  formed  by  inserting  n nodes  with  RB-I  NSERT . Argue \nthat if n>1 , the tree has at least one red node. \n13.3-6  \nSuggest  how  to implement  RB-I  NSERT ef\u00fbciently  if the  representation  for  red-  \nblack trees includes no storage for parent pointers . \n13.4  Deletion  \nLike the other basic operations on an n-node  red-black  tree,  deletion  of a node  \ntakes O.lg n/ time.  Deleting  a node  from  a red-black  tree  is more  complicat ed \nthan inserting a node. \nThe  procedure  for  deleting  a node  from  a red-black  tree  is based on the T REE- \nDELETE procedure  on  page  325.  First,  we  need  to customize  the  TRANSPLANT 13.4 Deletion 347 \nsubroutine  on  page  324  that  TREE-DELETE calls  so that  it applies  to a red-black  \ntree. Like T RANSPLANT , the  new  procedure  RB-T RANSPLANT replaces  the  sub-  \ntree rooted at node u by the subtree rooted at node v. The  RB-T RANSPLANT pro-  \ncedure differs from T RANSPLANT in two  ways.  First,  line  1 references  the  sentinel  \nT: nil instead of NIL. Second, the assignment to v: p in line  6 occurs  uncondition-  \nally: the procedure can assign to v: p even if v points  to the  sentinel.  We\u2019ll  take  \nadvantage of the ability to assign to v: p when v D T: nil. \nRB-T RANSPLANT .T;u;v/  \n1 if u: p == T: nil \n2 T: root D v \n3 elseif  u == u: p: left \n4 u: p: left D v \n5 else  u: p: right D v \n6 v: p D u: p \nThe  procedure  RB-D ELETE on the next page is like the T REE-DELETE proce-  \ndure, but with additional lines of pseudocode. The additional lines deal with nodes \nx and y that  may  be involved  in violations  of the  red-black  properti es. When the \nnode \u00b4 being deleted has at most one child, then y will be \u00b4. When \u00b4 has two \nchildren, then, as in T REE-DELETE , y will be \u00b4\u2019s successor,  which  has  no  left  \nchild and moves into \u00b4\u2019s position  in the  tree.  Additionally,  y takes on \u00b4\u2019s color.  \nIn either case, node y has at most one child: node x , which takes y \u2019s place  in the  \ntree. (Node x will be the sentinel T: nil if y has no children.) Since node y will \nbe either removed from the tree or moved within the  tree, the procedure needs to \nkeep track of y \u2019s original  color.  If the  red-black  properties  might  be violated after \ndeleting node \u00b4, RB-D ELETE calls  the  auxiliary  procedure  RB-D ELETE-FIXUP , \nwhich changes colors and performs rotations to rest ore the red-black  properties.  \nAlthough  RB-D ELETE contains almost twice as many lines of pseudocode a s \nTREE-DELETE, the  two  procedures  have  the  same  basic  structure.  You  can  \u00fbnd \neach line of T REE-DELETE within  RB-D ELETE (with the changes of replacing \nNIL by T: nil and replacing calls to T RANSPLANT by  calls  to RB-T RANSPLANT ), \nexecuted under the same conditions. \nIn detail, here are the other differences between t he two procedures: \n\ue001 Lines  1 and  9 set  node  y as described  above:  line  1 when  node  \u00b4 has at most \none child and line 9 when \u00b4 has two children. \n\ue001 Because node y \u2019s color  might  change,  the  variable  y-original-color  stores y \u2019s \ncolor  before  any  changes  occur.  Lines  2 and  10  set  this  variab le immediately \nafter assignments to y . When node \u00b4 has two children, then nodes y and \u00b4 are 348  Chapter  13  Red-Black  Trees  \nRB-D ELETE .T;\u00b4/  \n1 y D \u00b4 \n2 y-original-color  D y: color  \n3 if \u00b4: left = = T: nil \n4 x D \u00b4: right \n5 RB-T RANSPLANT .T;\u00b4;\u00b4:  right / / / replace \u00b4 by its right child \n6 elseif  \u00b4: right = = T: nil \n7 x D \u00b4: left \n8 RB-T RANSPLANT .T;\u00b4;\u00b4:  left / / / replace \u00b4 by its left child \n9 else  y D TREE-MINIMUM.\u00b4:  right / / / y is \u00b4\u2019s successor  \n10  y-original-color  D y: color  \n11  x D y: right \n12  if y \u00a4 \u00b4: right / / is y farther  down  the  tree?  \n13  RB-T RANSPLANT .T;y;y:  right / / / replace y by its right child \n14  y: right D \u00b4: right / / \u00b4\u2019s right  child  becomes  \n15  y: right : p D y / / y \u2019s right  child  \n16  else  x: p D y / / in case x is T: nil \n17  RB-T RANSPLANT .T;\u00b4;y/  / / replace \u00b4 by its successor y \n18  y: left D \u00b4: left / / and give \u00b4\u2019s left  child  to y , \n19  y: left: p D y / / which had no left child \n20 y: color  D \u00b4: color  \n21  if y-original-color  = = BLACK  / / if any  red-black  violations  occurred,  \n22 RB-D ELETE-FIXUP .T;x/  / / correct them \ndistinct.  In this  case,  line  17  moves  y into \u00b4\u2019s original  position  in the  tree  (that  \nis, \u00b4\u2019s location  in the  tree  at the  time  RB-D ELETE was called), and line 20 gives \ny the same color as \u00b4. When node y was originally black, removing or moving \nit could  cause  violations  of the  red-black  properties,  whic h are corrected by the \ncall  of RB-D ELETE-FIXUP in line 22. \n\ue001 As discussed, the procedure keeps track of the node  x that moves into node y \u2019s \noriginal position at the time of call. The assignme nts in lines 4, 7, and  11  set  x \nto point to either y \u2019s only  child  or,  if y has no children, the sentinel T: nil. \n\ue001 Since node x moves into node y \u2019s original  position,  the  attribute  x: p must be set \ncorrectly. If node \u00b4 has two children and y is \u00b4\u2019s right  child,  then  y just moves \ninto \u00b4\u2019s position,  with  x remaining a child of y . Line  12  checks  for  this  case.  \nAlthough you might think that setting x: p to y in line  16  is unnecessary  since  \nx is a child of y , the  call  of RB-D ELETE-FIXUP relies on x: p being y even if \nx is T: nil. Thus, when \u00b4 has two children and y is \u00b4\u2019s right  child,  executing  13.4 Deletion 349 \nline  16  is necessary  if y \u2019s right  child  is T: nil, and otherwise it does not change \nanything. \nOtherwise,  node  \u00b4 is either the same as node y or it is a proper ancestor of \ny \u2019s original  parent.  In these  cases,  the  calls  of RB-T RANSPLANT in lines  5, \n8, and  13  set  x: p correctly  in line  6 of RB-T RANSPLANT . (In these calls of \nRB-T RANSPLANT , the third parameter passed is the same as x .) \n\ue001 Finally, if node y was  black,  one  or more  violations  of the  red-black  propertie s \nmight  arise.  The  call  of RB-D ELETE-FIXUP in line  22  restores  the  red-black  \nproperties. If y was  red,  the  red-black  properties  still  hold  when  y is removed \nor moved, for the following reasons: \n1. No  black-heights  in the  tree  have  changed.  (See  Exercise  13.4-1.)  \n2. No red nodes have been made adjacent. If \u00b4 has at most one child, then y \nand \u00b4 are the same node. That node is removed, with a chi ld taking its place. \nIf the removed node was red, then neither its paren t nor its children can also \nbe red, so moving a child to take its place cannot cause two red nodes to \nbecome adjacent. If, on the other hand, \u00b4 has two children, then y takes \u00b4\u2019s \nplace in the tree, along with \u00b4\u2019s color,  so there  cannot  be two  adjacent  red  \nnodes at y \u2019s new  position  in the  tree.  In addition,  if y was not \u00b4\u2019s right  child,  \nthen y \u2019s original  right  child  x replaces y in the tree. Since y is red, x must \nbe black, and so replacing y by x cannot cause two red nodes to become \nadjacent. \n3. Because  y could not have been the root if it was red, the roo t remains black. \nIf node y was  black,  three  problems  may  arise,  which  the  call  of RB-D ELETE- \nFIXUP will remedy. First, if y was the root and a red child of y became the new \nroot, property 2 is violated. Second, if both x and its new parent are red, then a \nviolation  of property  4 occurs.  Third,  moving  y within the tree causes any simple \npath that previously contained y to have  one  less  black  node.  Thus,  property  5 is \nnow violated by any ancestor of y in the  tree.  We  can  correct  the  violation  of prop-  \nerty  5 by  saying  that  when  the  black  node  y is removed or moved, its blackness \ntransfers to the node x that moves into y \u2019s original  position,  giving  x an <extra= \nblack. That is, if we add 1 to the  count  of black  nodes  on  any  simple  path  that  con-  \ntains x , then  under  this  interpretation,  property  5 holds.  But  now  another problem \nemerges: node x is neither  red  nor  black,  thereby  violating  property  1. Instead, \nnode x is either  <doubly  black=  or <red-and-black,=  and  it contrib utes either 2 or 1, \nrespectively, to the count of black nodes on simple  paths containing x . The color  \nattribute of x will still be either RED (if x is red-and-black)  or BLACK  (if x is dou-  \nbly  black).  In other  words,  the  extra  black  on  a node  is re\u00fcect ed in x \u2019s pointing  to \nthe node rather than in the color  attribute. 350  Chapter  13  Red-Black  Trees  \nThe  procedure  RB-D ELETE-FIXUP on  the  next  page  restores  properties  1, 2, \nand  4. Exercises  13.4-2  and  13.4-3  ask  you  to show  that  the  procedure restores \nproperties  2 and  4, and  so in the  remainder  of this  section,  we  focus  on  property  1. \nThe goal of the while  loop  in lines  1343  is to move  the  extra  black  up  the  tree  until  \n1. x points  to a red-and-black  node,  in which  case  line  44  colors  x (singly) black; \n2. x points to the root, in which case the extra black s imply vanishes; or \n3. having  performed  suitable  rotations  and  recolorings,  the loop exits. \nLike  RB-I  NSERT-FIXUP, the  RB-D ELETE-FIXUP procedure  handles  two  sym-  \nmetric  situations:  lines  3322  for  when  node  x is a left  child,  and  lines  24343  for  \nwhen x is a right  child.  Our  proof  focuses  on  the  four  cases  shown  in lines  3322.  \nWithin the while  loop, x always points to a nonroot doubly black node. Line 2 \ndetermines whether x is a left child or a right child of its parent x: p so that either \nlines  3322  or 24343  will  execute  in a given  iteration.  The  sibling of x is always \ndenoted by a pointer w. Since node x is doubly black, node w cannot be T: nil, \nbecause otherwise, the number of blacks on the simp le path from x: p to the (singly \nblack) leaf w would be smaller than the number on the simple path  from x: p to x . \nRecall  that  the  RB-D ELETE procedure always assigns to x: p before  calling  RB-  \nDELETE-FIXUP (either  within  the  call  of RB-T RANSPLANT in line  13  or the  as-  \nsignment  in line  16),  even  when  node  x is the sentinel T: nil. That is because \nRB-D ELETE-FIXUP references x \u2019s parent  x: p in several places, and this attribute \nmust point to the node that became x \u2019s parent  in RB-D ELETE4even  if x is T: nil. \nFigure  13.7  demonstrates  the  four  cases  in the  code  when  node  x is a left child. \n(As  in RB-I  NSERT-FIXUP, the  cases  in RB-D ELETE-FIXUP are  not  mutually  ex-  \nclusive.)  Before  examining  each  case  in detail,  let\u2019s  look  more generally at how \nwe can verify that the transformation in each of th e cases preserves  property  5. \nThe key idea is that in each case, the transformati on applied preserves  the  num-  \nber of black nodes (including x \u2019s extra  black)  from  (and  including)  the  root  of the  \nsubtree shown to the roots of each of the subtrees \u02db; \u02c7; : : : ; \ufffd  . Thus,  if property  5 \nholds prior to the transformation, it continues to hold afterward. For example, in \nFigure  13.7(a),  which  illustrates  case  1, the  number  of black nodes from the root \nto the root of either subtree \u02db or \u02c7 is 3, both before and after the transformation. \n(Again, remember that node x adds an extra black.) Similarly, the number of blac k \nnodes from the root to the root of any of \ufffd , \u0131 , \", and \ufffd is 2, both before and after \nthe transformation. 2 In Figure  13.7(b),  the  counting  must  involve  the  value  c of the \ncolor  attribute of the root of the subtree shown, which c an be either RED or BLACK . \n2 If property  5 holds,  we  can  assume  that  paths  from  the  roots  of \ufffd , \u0131, \", and \ufffd down to leaves contain \none more black than do paths from the roots of \u02db and \u02c7 down to leaves. 13.4 Deletion 351 \nRB-D ELETE-FIXUP .T;x/  \n1 while  x \u00a4 T: root and x: color  == BLACK  \n2 if x == x: p: left / / is x a left  child?  \n3 w D x: p: right / / w is x\u2019s sibling  \n4 if w:  color  == RED \n5 w:  color  D BLACK  * \ncase  1 6 x: p: color  D RED \n7 LEFT-ROTATE  .T;x:  p/ \n8 w D x: p: right \n9 if w:  left: color  == BLACK  and w:  right: color  == BLACK  \n10  w:  color  D RED \u00f0 \ncase 2 11  x D x: p \n12  else  \n13  if w:  right: color  == BLACK  \n14  w:  left: color  D BLACK  * \ncase  3 15  w:  color  D RED \n16  RIGHT-ROTATE  .T;w/  \n17  w D x: p: right \n18  w:  color  D x: p: color  \u2026 \ncase  4 19  x: p: color  D BLACK  \n20 w:  right: color  D BLACK  \n21  LEFT-ROTATE  .T;x:  p/ \n22 x D T: root \n23  else  / / same  as lines  3322,  but  with  <right=  and  <left=  exchanged  \n24  w D x: p: left \n25  if w:  color  == RED \n26  w:  color  D BLACK  \n27  x: p: color  D RED \n28  RIGHT-ROTATE  .T;x:  p/ \n29 w D x: p: left \n30  if w:  right: color  == BLACK  and w:  left: color  == BLACK  \n31  w:  color  D RED \n32  x D x: p \n33  else  \n34  if w:  left: color  == BLACK  \n35  w:  right: color  D BLACK  \n36  w:  color  D RED \n37  LEFT-ROTATE  .T;w/  \n38  w D x: p: left \n39  w:  color  D x: p: color  \n40  x: p: color  D BLACK  \n41  w:  left: color  D BLACK  \n42  RIGHT-ROTATE  .T;x:  p/ \n43  x D T: root \n44  x: color  D BLACK  352  Chapter  13  Red-Black  Trees  \nA B \nD \nC E \u00b3 \u00b4 \n\u00b5 \u00b6 \u03b5 \u03b6 x w \nA B \nC D \nE \nx new w \n\u00b3 \u00b4 \u00b5 \u00b6 \u03b5 \u03b6 \nA B \nD \nC E \u00b3 \u00b4 \n\u00b5 \u00b6 \u03b5 \u03b6 x w c \nA B \nD \nC E \u00b3 \u00b4 \n\u00b5 \u00b6 \u03b5 \u03b6 c new x \nA B \nD \nC E \u00b3 \u00b4 \n\u00b5 \u00b6 \u03b5 \u03b6 x w c \nA B \nC \nD \u00b3 \u00b4 \u00b5 \n\u00b6 \n\u03b5 \u03b6 x c \nnew w \nA B \nD \nC E \u00b3 \u00b4 \n\u00b5 \u00b6 \u03b5 \u03b6 x w c c \n\u00b3 \u00b4 A B \nC D \nE (d) (c) (b) (a) \n\u00b5 \u00b6 \u03b5 \u03b6 Case  4 Case  3 Case 2 Case  1 \nE \nc\u02b9 c\u02b9 \nnew x D T: root \nFigure  13.7  The  cases  in lines  3322  of the  procedure  RB-D ELETE-FIXUP . Brown nodes have \ncolor  attributes represented by c and c 0 , which may be either RED or BLACK . The letters \u02db; \u02c7; : : : ; \ufffd  \nrepresent arbitrary subtrees. Each case transforms the con\u00fbguration  on  the  left  into  the  con\u00fbguration  \non the right by changing some colors and/or perform ing a rotation. Any node pointed to by x has \nan  extra  black  and  is either  doubly  black  or red-and-black.  Only case 2 causes the loop to repeat. \n(a)  Case  1 is transformed  into  case  2, 3, or 4 by  exchanging  the  colors of nodes B and D and \nperforming a left rotation. (b)  In case 2, the extra black represented by the point er x moves up the \ntree by coloring node D red and setting x to point to node B. If case  2 is entered  through  case  1, the  \nwhile  loop terminates because the new node x is red-and-black,  and  therefore  the  value  c of its color  \nattribute is RED. (c)  Case  3 is transformed  to case  4 by  exchanging  the  colors  of nodes C and D and \nperforming a right rotation. (d)  Case  4 removes  the  extra  black  represented  by  x by changing some \ncolors and performing a left rotation (without viol ating the red-black  properties),  and  then  the  loop  \nterminates. 13.4 Deletion 353 \nIf we  de\u00fbne  count.RED/ D 0 and count.BLACK/ D 1, then the number of black \nnodes from the root to \u02db is 2 C count.c/, both before and after the transformation. \nIn this case, after the transformation, the new nod e x has color  attribute c , but this \nnode  is really  either  red-and-black  (if  c D RED) or doubly black (if c D BLACK ). \nYou  can  verify  the  other  cases  similarly  (see  Exercise  13.4-6).  \nCase  1: x\u2019s sibling  w is red  \nCase  1 (lines  538  and  Figure  13.7(a))  occurs  when  node  w, the sibling of node x , \nis red. Because w is red, it must have black children. This case swit ches the colors \nof w and x: p and  then  performs  a left-rotation  on  x: p without violating any of the \nred-black  properties.  The  new  sibling  of x , which is one of w\u2019s children  prior  to \nthe  rotation,  is now  black,  and  thus  case  1 converts  into  one  of cases  2, 3, or 4. \nCases  2, 3, and  4 occur  when  node  w is black and are distinguished by the colors \nof w\u2019s children.  \nCase  2: x\u2019s sibling  w is black,  and  both  of w\u2019s children  are  black  \nIn case  2 (lines  10311  and  Figure  13.7(b)),  both  of w\u2019s children  are  black.  Since  w \nis also black, this case removes one black from bot h x and w, leaving x with only \none black and leaving w red. To compensate for x and w each losing one black, \nx \u2019s parent  x: p can  take  on  an extra  black.  Line  11  does  so by  moving  x up one \nlevel, so that the while  loop repeats with x: p as the new node x . If case 2 enters \nthrough  case  1, the  new  node  x is red-and-black,  since  the  original  x: p was red. \nHence, the value c of the color  attribute of the new node x is RED, and the loop \nterminates  when  it tests  the  loop  condition.  Line  44  then  colors the new node x \n(singly) black. \nCase  3: x\u2019s sibling  w is black,  w\u2019s left  child  is red,  and  w\u2019s right  child  is black  \nCase  3 (lines  14317  and  Figure  13.7(c))  occurs  when  w is black, its left child is \nred, and its right child is black. This case switch es the colors of w and its left \nchild w:  left and then performs a right rotation on w without violating any of the \nred-black  properties.  The  new  sibling  w of x is now a black node with a red right \nchild,  and  thus  case  3 falls  through  into  case  4. \nCase  4: x\u2019s sibling  w is black,  and  w\u2019s right  child  is red  \nCase  4 (lines  18322  and  Figure  13.7(d))  occurs  when  node  x \u2019s sibling  w is black \nand w\u2019s right  child  is red.  Some  color  changes  and  a left  rotation  on x: p allow \nthe extra black on x to vanish, making it singly black, without violatin g any of the \nred-black  properties.  Line  22  sets  x to be the root, and the while  loop terminates \nwhen it next tests the loop condition. 354  Chapter  13  Red-Black  Trees  \nAnalysis  \nWhat  is the  running  time  of RB-D ELETE? Since  the  height  of a red-black  tree  of n \nnodes is O.lg n/, the  total  cost  of the  procedure  without  the  call  to RB-D ELETE- \nFIXUP takes O.lg n/ time.  Within  RB-D ELETE-FIXUP, each  of cases  1, 3, and  4 \nlead to termination after performing a constant num ber of color changes and at \nmost three rotations. Case 2 is the only case in wh ich the while  loop  can  be re-  \npeated, and then the pointer x moves up the tree at most O.lg n/ times, performing \nno  rotations.  Thus,  the  procedure  RB-D ELETE-FIXUP takes O.lg n/ time  and  per-  \nforms  at most  three  rotations,  and  the  overall  time  for  RB-D ELETE is therefore \nalso O.lg n/. \nExercises  \n13.4-1  \nShow that if node y in RB-D ELETE is red,  then  no  black-heights  change.  \n13.4-2  \nArgue  that  after  RB-D ELETE-FIXUP executes, the root of the tree must be black. \n13.4-3  \nArgue  that  if in RB-D ELETE both x and x: p are  red,  then  property  4 is restored  by  \nthe  call  to RB-D ELETE-FIXUP .T;x/ . \n13.4-4  \nIn Exercise  13.3-2  on  page  346,  you  found  the  red-black  tree  that  results  from  suc-  \ncessively inserting the keys 41;38;31;12;19;8  into an initially empty tree. Now \nshow  the  red-black  trees  that  result  from  the  successive  deletion of the keys in the \norder 8;12;19;31;38;41 . \n13.4-5  \nWhich  lines  of the  code  for  RB-D ELETE-FIXUP might examine or modify the \nsentinel T: nil? \n13.4-6  \nIn each  of the  cases  of Figure  13.7,  give  the  count  of black  nodes from the root of \nthe subtree shown to the roots of each of the subtr ees \u02db; \u02c7; : : : ; \ufffd  , and verify that \neach count remains the same after the transformatio n. When a node has a color  \nattribute c or c 0 , use the notation count .c/  or count.c 0 / symbolically in your count. \n13.4-7  \nProfessors  Skelton  and  Baron  worry  that  at the  start  of case  1 of RB-D ELETE- \nFIXUP , the node x: p might not be black. If x: p is not  black,  then  lines  536  are  Problems for Chapter 13 355 \nwrong. Show that x: p must  be black  at the  start  of case  1, so that  the  professors  \nneed not be concerned. \n13.4-8  \nA node x is inserted  into  a red-black  tree  with  RB-I  NSERT and then is immediately \ndeleted  with  RB-D ELETE. Is the  resulting  red-black  tree  always  the  same  as the  \ninitial  red-black  tree?  Justify  your  answer.  \n? 13.4-9  \nConsider  the  operation  RB-E NUMERATE .T;r;a;b/ , which outputs all the keys k \nsuch that a \u0dc4 k \u0dc4 b in a subtree rooted at node r in an n-node  red-black  tree  T . \nDescribe  how  to implement  RB-E NUMERATE in \u201a.m  C lg n/ time, where m is \nthe number of keys that are output. Assume that the  keys in T are unique and that \nthe values a and b appear as keys in T . How does your solution change if a and b \nmight not appear in T ? \nProblems  \n13-1  Persistent  dynamic  sets  \nDuring  the  course  of an algorithm,  you  sometimes  \u00fbnd  that  you  need to maintain \npast versions of a dynamic set as it is updated. We  call such a set persistent. One  \nway to implement a persistent set is to copy the en tire set whenever  it is modi-  \n\u00fbed,  but  this  approach  can  slow  down  a program  and  also  consum e a lot of space. \nSometimes, you can do much better. \nConsider a persistent set S with the operations I NSERT , DELETE , and S EARCH , \nwhich you implement using binary search trees as sh own in Figure  13.8(a).  Main-  \ntain a separate root for every version of the set. In order to insert the key 5 into the \nset, create a new node with key 5. This node becomes the left child of a new node \nwith key 7, since you cannot modify the existing node with ke y 7. Similarly, the \nnew node with key 7 becomes the left child of a new node with key 8 whose right \nchild is the existing node with key 10. The new node with key 8 becomes, in turn, \nthe right child of a new root r 0 with key 4 whose left child is the existing node with \nkey 3. Thus, you copy only part of the tree and share so me of the nodes with the \noriginal  tree,  as shown  in Figure  13.8(b).  \nAssume that each tree node has the attributes key, left , and right but no parent. \n(See  also  Exercise  13.3-6  on  page  346.)  \na. For  a persistent  binary  search  tree  (not  a red-black  tree,  just a binary search \ntree), identify the nodes that need to change to in sert or delete a node. 356  Chapter  13  Red-Black  Trees  \n4 \n3 \n2 8 \n7 10  4 \n8 \n7 \n5 \n(b) r r \u02b9 4 \n3 \n2 8 \n7 10  \n(a) r \nFigure  13.8  (a)  A binary search tree with keys 2;3;4;7;8;10 . (b)  The persistent binary search \ntree that results from the insertion of key 5. The most recent version of the set consists of th e nodes \nreachable from the root r 0 , and the previous version consists of the nodes re achable from r . Blue \nnodes are added when key 5 is inserted. \nb. Write a procedure P ERSISTENT-TREE-I NSERT .T;\u00b4/  that, given a persistent \nbinary search tree T and a node \u00b4 to insert, returns a new persistent tree T 0 \nthat is the result of inserting \u00b4 into T . Assume that you have a procedure \nCOPY-NODE.x/  that makes a copy of node x , including all of its attributes. \nc. If the height of the persistent binary search tree T is h, what are the time and \nspace requirements of your implementation of P ERSISTENT-TREE-I NSERT? \n(The space requirement is proportional to the numbe r of nodes that are copied.) \nd. Suppose that you include the parent attribute in ea ch node. In this case, the \nPERSISTENT-TREE-I NSERT procedure needs to perform additional copying. \nProve that P ERSISTENT-TREE-I NSERT then requires \ufffd.n/  time and space, \nwhere n is the number of nodes in the tree. \ne. Show  how  to use  red-black  trees  to guarantee  that  the  worst-c ase running time \nand space are O.lg n/ per insertion or deletion. You may assume that all keys \nare distinct. \n13-2  Join  operation  on  red-black  trees  \nThe join  operation takes two dynamic sets S 1 and S 2 and an element x such that \nfor any x 1 2 S 1 and x 2 2 S 2 , we have x 1 : key  \u0dc4 x: key  \u0dc4 x 2 : key. It returns a set \nS D S 1 [ fx g [  S 2 . In this problem, we investigate how to implement the join \noperation  on  red-black  trees.  \na. Suppose  that  you  store  the  black-height  of a red-black  tree  T as the  new  at-  \ntribute T: bh. Argue  that  RB-I  NSERT and  RB-D ELETE can maintain the bh Problems for Chapter 13 357 \nattribute without requiring extra storage in the no des of the tree and without \nincreasing the asymptotic running times. Show how t o determine  the  black-  \nheight of each node visited while descending throug h T , using O.1/  time per \nnode visited. \nLet T 1 and T 2 be red-black  trees  and  x be a key value such that for any nodes \nx 1 in T 1 and x 2 in T 2 , we have x 1 : key  \u0dc4 x: key  \u0dc4 x 2 : key. You will show how \nto implement  the  operation  RB-J  OIN.T  1 ;x;T  2 /, which destroys T 1 and T 2 and \nreturns  a red-black  tree  T D T 1 [ fx g [  T 2 . Let n be the total number of nodes in \nT 1 and T 2 . \nb. Assume that T 1 : bh \ue004 T 2 : bh. Describe an O.lg n/-time  algorithm  that  \u00fbnds  a \nblack node y in T 1 with  the  largest  key  from  among  those  nodes  whose  black-  \nheight is T 2 : bh. \nc. Let T y be the subtree rooted at y . Describe how T y [ fx g [  T 2 can replace T y \nin O.1/  time  without  destroying  the  binary-search-tree  property.  \nd. What color should you make x so that  red-black  properties  1, 3, and  5 are  \nmaintained?  Describe  how  to enforce  properties  2 and  4 in O.lg n/ time. \ne. Argue that no generality is lost by making the assu mption in part (b). Describe \nthe symmetric situation that arises when T 1 : bh \u0dc4 T 2 : bh. \nf. Argue  that  the  running  time  of RB-J  OIN  is O.lg n/. \n13-3  AVL  trees  \nAn AVL  tree  is a binary search tree that is height  balanced : for each node x , the \nheights of the left and right subtrees of x differ by at most 1. To implement an \nA VL tree, maintain an extra attribute h in each node such that x: h is the height of \nnode x . As for any other binary search tree T , assume that T: root points to the root \nnode. \na. Prove that an A VL tree with n nodes has height O.lg n/. (Hint: Prove that \nan A VL tree of height h has at least F h nodes, where F h is the hth Fibonacci \nnumber.) \nb. To  insert  into  an AVL  tree,  \u00fbrst  place  a node  into  the  appropriate  place  in bi-  \nnary search tree order. Afterward, the tree might n o longer be height balanced. \nSpeci\u00fbcally,  the  heights  of the  left  and  right  children  of some node might differ \nby 2. Describe a procedure B ALANCE.x/, which takes a subtree rooted at x \nwhose left and right children are height balanced a nd have heights that differ 358  Chapter  13  Red-Black  Trees  \nby at most 2, so that jx: right : h \ue003 x: left: hj \u0dc4  2, and alters the subtree rooted \nat x to be height balanced. The procedure should return a pointer to the node \nthat is the root of the subtree after alterations o ccur. ( Hint: Use rotations.) \nc. Using  part  (b),  describe  a recursive  procedure  AVL-I  NSERT .T;\u00b4/  that takes \nan A VL tree T and a newly created node \u00b4 (whose  key  has  already  been  \u00fblled  \nin), and adds \u00b4 into T , maintaining the property that T is an A VL tree. As in \nTREE-I NSERT from  Section  12.3,  assume  that  \u00b4: key  has  already  been  \u00fblled  in \nand that \u00b4: left D NIL and \u00b4: right D NIL. Assume as well that \u00b4: h D 0. \nd. Show  that  AVL-I  NSERT , run on an n-node  AVL  tree,  takes  O.lg n/ time and \nperforms O.lg n/ rotations. \nChapter  notes  \nThe  idea  of balancing  a search  tree  is due  to Adel\u2019son-Vel\u2019ski\u02d8  \u0131 and  Landis  [2],  who  \nintroduced a class of balanced search trees called <A VL trees= in 1962,  described  in \nProblem  13-3.  Another  class  of search  trees,  called  <2-3  trees,= was introduced by \nJ. E. Hopcroft  (unpublished)  in 1970.  A 2-3  tree  maintains  balance by manipulating \nthe degrees of nodes in the tree, where each node h as either two or three children. \nChapter  18  covers  a generalization  of 2-3  trees  introduced  by Bayer and McCreight \n[39],  called  <B-trees.=  \nRed-black  trees  were  invented  by  Bayer  [38]  under  the  name  <symmetric binary \nB-trees.=  Guibas  and  Sedgewick  [202]  studied  their  properties  at length  and  in-  \ntroduced  the  red/black  color  convention.  Andersson  [16]  gives  a simpler-to-code  \nvariant  of red-black  trees.  Weiss  [451]  calls  this  variant  AA-trees.  An  AA-tree  is \nsimilar  to a red-black  tree  except  that  left  children  can  never be red. \nSedgewick  and  Wayne  [402]  present  red-black  trees  as a modi\u00fbed  version  of 2-3  \ntrees in which a node with three children is split into two nodes with two children \neach.  One  of these  nodes  becomes  the  left  child  of the  other,  and only left children \ncan  be red.  They  call  this  structure  a <left-leaning  red-bla ck binary search tree.= \nAlthough  the  code  for  left-leaning  red-black  binary  search  trees is more concise \nthan  the  red-black  tree  pseudocode  in this  chapter,  operations  on  left-leaning  red-  \nblack binary search trees do not limit the number o f rotations per operation to a \nconstant.  This  distinction  will  matter  in Chapter  17.  \nTreaps, a hybrid of binary search trees and heaps, were proposed by Seidel and \nAragon  [404].  They  are  the  default  implementation  of a dictionary  in LEDA  [324],  \nwhich  is a well-implemented  collection  of data  structures  and algorithms. \nThere are many other variations on balanced binary trees, including  weight-  \nbalanced  trees  [344],  k-neighbor  trees  [318],  and  scapegoat  trees  [174].  Perhaps  Notes for Chapter 13 359 \nthe most intriguing are the <splay trees= introduce d by Sleator  and  Tarjan  [418],  \nwhich  are  <self-adjusting.=  (See  Tarjan  [429]  for  a good  description of splay trees.) \nSplay trees maintain balance without any explicit b alance condition such as color. \nInstead, <splay operations= (which involve rotation s) are performed within the tree \nevery time an access is made. The amortized cost (s ee Chapter 16)  of each  oper-  \nation on an n-node  tree  is O.lg n/. Splay trees have been conjectured to perform \nwithin  a constant  factor  of the  best  of\u00fcine  rotation-based  tree. The best known \ncompetitive  ratio  (see  Chapter  27)  for  a rotation-based  tree is the Tango Tree of \nDemaine  et al.  [109].  \nSkip  lists  [369]  provide  an alternative  to balanced  binary  trees. A skip list is a \nlinked list that is augmented with a number of addi tional pointers. Each dictionary \noperation runs in O.lg n/ expected time on a skip list of n items. Part  IV  Advanced  Design  and  Analysis  Techniques  Introduction  \nThis part covers three important techniques used in  designing  and  analyzing  ef\u00fb-  \ncient  algorithms:  dynamic  programming  (Chapter  14),  greedy  algorithms  (Chap-  \nter  15),  and  amortized  analysis  (Chapter  16).  Earlier  parts  have presented other \nwidely  applicable  techniques,  such  as divide-and-conquer  , randomization, and how \nto solve recurrences. The techniques in this part a re somewhat more sophisticated, \nbut you will be able to use them solve many computa tional problems. The themes \nintroduced in this part will recur later in this bo ok. \nDynamic programming typically applies to optimizati on problems in which you \nmake a set of choices in order to arrive at an opti mal solution, each choice generates \nsubproblems of the same form as the original proble m, and the same subproblems \narise repeatedly. The key strategy is to store the solution to each such subproblem \nrather  than  recompute  it. Chapter  14  shows  how  this  simple  idea can sometimes \ntransform  exponential-time  algorithms  into  polynomial-t ime algorithms. \nLike  dynamic-programming  algorithms,  greedy  algorithms  typically apply to \noptimization problems in which you make a set of ch oices in order to arrive at an \noptimal solution. The idea of a greedy algorithm is  to make each choice in a locally \noptimal manner, resulting in a faster algorithm tha n you get with  dynamic  program-  \nming.  Chapter  15  will  help  you  determine  when  the  greedy  approach works. \nThe technique of amortized analysis applies to cert ain algorithms that perform \na sequence of similar operations. Instead of boundi ng the cost of the sequence of \noperations by bounding the actual cost of each oper ation separately, an amortized \nanalysis  provides  a worst-case  bound  on  the  actual  cost  of the  entire  sequence.  One  \nadvantage of this approach is that although some op erations might be expensive, \nmany others might be cheap. You can use amortized a nalysis when designing \nalgorithms, since the design of an algorithm and th e analysis of its running time \nare  often  closely  intertwined.  Chapter  16  introduces  three  ways to perform an \namortized analysis of an algorithm. 14  Dynamic  Programming  \nDynamic  programming,  like  the  divide-and-conquer  method,  solves problems by \ncombining the solutions to subproblems. (<Programmi ng= in this context refers \nto a tabular method, not to writing computer code.)  As we saw in Chapters 2 \nand  4, divide-and-conquer  algorithms  partition  the  problem  into  disjoint  subprob-  \nlems, solve the subproblems recursively, and then c ombine their solutions to solve \nthe original problem. In contrast, dynamic programm ing applies  when  the  subprob-  \nlems  overlap4that  is, when  subproblems  share  subsubproble ms. In this context, \na divide-and-conquer  algorithm  does  more  work  than  necessary,  repeatedly  solv-  \ning  the  common  subsubproblems.  A dynamic-programming  algorithm solves each \nsubsubproblem just once and then saves its answer i n a table, thereby avoiding the \nwork of recomputing the answer every time it solves  each subsubproblem. \nDynamic programming typically applies to optimization  problems. Such  prob-  \nlems can have many possible solutions. Each solutio n has a value, and you want \nto \u00fbnd  a solution  with  the  optimal  (minimum  or maximum)  value . We call such \na solution an optimal solution to the problem, as opposed to the optimal solution, \nsince there may be several solutions that achieve t he optimal value. \nTo  develop  a dynamic-programming  algorithm,  follow  a seque nce of four steps: \n1. Characterize  the  structure  of an optimal  solution.  \n2. Recursively  de\u00fbne  the  value  of an optimal  solution.  \n3. Compute  the  value  of an optimal  solution,  typically  in a bottom-up  fashion.  \n4. Construct  an optimal  solution  from  computed  information . \nSteps  133  form  the  basis  of a dynamic-programming  solution  to a problem. If you \nneed only the value of an optimal solution, and not  the solution itself, then you \ncan  omit  step  4. When  you  do  perform  step  4, it often  pays  to maintain additional \ninformation  during  step  3 so that  you  can  easily  construct  an optimal solution. \nThe  sections  that  follow  use  the  dynamic-programming  metho d to solve some \noptimization  problems.  Section  14.1  examines  the  problem  of cutting a rod into 14.1  Rod  cutting  363 \nrods of smaller length in a way that maximizes thei r total value.  Section  14.2  \nshows how to multiply a chain of matrices while per forming the fewest total scalar \nmultiplications.  Given  these  examples  of dynamic  programming,  Section  14.3  dis-  \ncusses two key characteristics that a problem must have for dynamic programming \nto be a viable  solution  technique.  Section  14.4  then  shows  how  to \u00fbnd  the  longest  \ncommon subsequence of two sequences via dynamic pro gramming. Finally,  Sec-  \ntion  14.5  uses  dynamic  programming  to construct  binary  search  trees  that  are  opti-  \nmal, given a known distribution of keys to be looke d up. \n14.1  Rod  cutting  \nOur  \u00fbrst  example  uses  dynamic  programming  to solve  a simple  problem  in decid-  \ning where to cut steel rods. Serling Enterprises bu ys long steel rods and cuts them \ninto shorter rods, which it then sells. Each cut is  free. The management of Serling \nEnterprises wants to know the best way to cut up th e rods. \nSerling Enterprises has a table giving, for i D 1;2;::: , the price p i in dollars \nthat they charge for a rod of length i inches. The length of each rod in inches is \nalways  an integer.  Figure  14.1  gives  a sample  price  table.  \nThe rod-cutting  problem  is the  following.  Given  a rod  of length  n inches and \na table of prices p i for i D 1;2;:::;n , determine the maximum revenue r n ob-  \ntainable by cutting up the rod and selling the piec es. If the price p n for a rod of \nlength n is large enough, an optimal solution might require no cutting at all. \nConsider the case when n D 4. Figure  14.2  shows  all  the  ways  to cut  up  a rod  \nof 4 inches in length, including the way with no cuts at  all. Cutting a 4-inch  rod  \ninto two 2-inch  pieces  produces  revenue  p 2 C p 2 D 5 C 5 D 10, which is optimal. \nSerling Enterprises can cut up a rod of length n in 2 n\ue0021 different ways, since they \nhave an independent option of cutting, or not cutti ng, at distance i inches from the \nleft end, for i D 1;2;:::;n  \ue003 1. 1 We denote a decomposition into pieces using \nordinary additive notation, so that 7 D 2 C 2 C 3 indicates that a rod of length 7 is \ncut  into  three  pieces4two  of length  2 and one of length 3. If an optimal solution \ncuts the rod into k pieces, for some 1 \u0dc4 k \u0dc4 n, then an optimal decomposition \nn D i 1 C i 2 C \ue001 \ue001 \ue001 C  i k \n1 If pieces are required to be cut in order of monoto nically increasing size, there are fewer ways to \nconsider. For n D 4, only 5 such ways are possible: parts (a), (b), (c), (e), a nd (h) in Figure  14.2.  The  \nnumber of ways is called the partition  function , which is approximately equal to e \ue003 p  \n2n=3  =4n  p \n3. \nThis quantity is less than 2 n\ue0021 , but still much greater than any polynomial in n. We  won\u2019t  pursue  \nthis line of inquiry further, however. 364  Chapter  14  Dynamic  Programming  \nlength i 1 2 3 4 5 6 7 8 9 10  \nprice p i 1 5 8 9 10  17  17  20  24  30  \nFigure  14.1  A sample price table for rods. Each rod of length i inches earns the company p i \ndollars of revenue. \n9 \n(a) 1 \n(b) 8 \n(c) (d) \n(e) (f) (g) 1 \n(h) 1 1 1 5 5 1 8 \n5 1 1 5 1 1 5 1 1 \nFigure  14.2  The 8 possible ways of cutting up a rod of length 4. Above each piece is the value \nof that  piece,  according  to the  sample  price  chart  of Figure  14.1.  The  optimal  strategy  is part  (c)4  \ncutting the rod into two pieces of length 24which  has  total  value  10. \nof the rod into pieces of lengths i 1 , i 2 , . . . , i k provides maximum corresponding \nrevenue \nr n D p i 1 C p i 2 C \ue001 \ue001 \ue001 C  p i k : \nFor  the  sample  problem  in Figure  14.1,  you  can  determine  the  optimal revenue \n\u00fbgures  r i , for i D 1;2;:::;10 , by inspection, with the corresponding optimal \ndecompositions \nr 1 D 1 from solution 1 D 1 (no cuts) ; \nr 2 D 5 from solution 2 D 2 (no cuts) ; \nr 3 D 8 from solution 3 D 3 (no cuts) ; \nr 4 D 10  from solution 4 D 2 C 2;  \nr 5 D 13  from solution 5 D 2 C 3;  \nr 6 D 17  from solution 6 D 6 (no cuts) ; \nr 7 D 18  from solution 7 D 1 C 6 or 7 D 2 C 2 C 3;  \nr 8 D 22  from solution 8 D 2 C 6;  \nr 9 D 25  from solution 9 D 3 C 6;  \nr 10  D 30  from solution 10  D 10  (no cuts) : 14.1  Rod  cutting  365 \nMore generally, we can express the values r n for n \ue004 1 in terms of optimal \nrevenues from shorter rods: \nr n D max fp n ;r 1 C r n\ue0021 ;r 2 C r n\ue0022 ;:::;r  n\ue0021 C r 1 g : (14.1)  \nThe  \u00fbrst  argument,  p n , corresponds to making no cuts at all and selling the rod of \nlength n as is. The other n \ue003 1 arguments  to max  correspond  to the  maximum  rev-  \nenue obtained by making an initial cut of the rod i nto two pieces of size i and n \ue003 i , \nfor each i D 1;2;:::;n  \ue003 1, and  then  optimally  cutting  up  those  pieces  further,  ob-  \ntaining revenues r i and r n\ue002i from  those  two  pieces.  Since  you  don\u2019t  know  ahead  of \ntime which value of i optimizes revenue, you have to consider all possibl e values \nfor i and pick the one that maximizes revenue. You also h ave the option of picking \nno i at all if the greatest revenue comes from selling t he rod uncut. \nTo solve the original problem of size n, you solve smaller problems of the same \ntype.  Once  you  make  the  \u00fbrst  cut,  the  two  resulting  pieces  form  independent  in-  \nstances  of the  rod-cutting  problem.  The  overall  optimal  solution  incorporates  op-  \ntimal solutions to the two resulting subproblems, m aximizing revenue from each \nof those  two  pieces.  We  say  that  the  rod-cutting  problem  exhibits optimal  sub-  \nstructure : optimal solutions to a problem incorporate optima l solutions to related \nsubproblems, which you may solve independently. \nIn a related, but slightly simpler, way to arrange a recursive structure for the \nrod-cutting  problem,  let\u2019s  view  a decomposition  as consisting  of a \u00fbrst  piece  of \nlength i cut  off  the  left-hand  end,  and  then  a right-hand  remainder  of length n \ue003 i . \nOnly  the  remainder,  and  not  the  \u00fbrst  piece,  may  be further  divided. Think of every \ndecomposition  of a length-n rod  in this  way:  as a \u00fbrst  piece  followed  by  some  \ndecomposition of the remainder. Then we can express  the solution with no cuts \nat all  by  saying  that  the  \u00fbrst  piece  has  size  i D n and revenue p n and that the \nremainder has size 0 with corresponding revenue r 0 D 0. We thus obtain the \nfollowing  simpler  version  of equation  (14.1):  \nr n D max fp i C r n\ue002i W 1 \u0dc4 i \u0dc4 ng : (14.2)  \nIn this formulation, an optimal solution embodies t he solution to only one related \nsubproblem4the  remainder4rather  than  two.  \nRecursive  top-down  implementation  \nThe C UT-ROD  procedure on the following page implements the comp utation im-  \nplicit  in equation  (14.2)  in a straightforward,  top-down,  recursive manner. It takes \nas input an array p\u01521  W n\ufffd of prices and an integer n, and  it returns  the  maxi-  \nmum revenue possible for a rod of length n. For length n D 0, no revenue \nis possible, and so C UT-ROD  returns 0 in line  2. Line  3 initializes  the  max-  \nimum revenue q to \ue0031, so that the for  loop  in lines  435  correctly  computes  366  Chapter  14  Dynamic  Programming  \nq D max fp i C CUT-ROD.p;n  \ue003 i/ W 1 \u0dc4 i \u0dc4 ng. Line  6 then  returns  this  value.  \nA simple induction on n proves that this answer is equal to the desired ans wer r n , \nusing  equation  (14.2).  \nCUT-ROD.p;n/  \n1 if n == 0 \n2 return  0 \n3 q D \ue0031  \n4 for  i D 1 to n \n5 q D max fq;p\u0152i\ufffd  C CUT-ROD.p;n  \ue003 i/g \n6 return  q \nIf you code up C UT-ROD  in your favorite programming language and run it on  \nyour  computer,  you\u2019ll  \u00fbnd  that  once  the  input  size  becomes  moderately large, your \nprogram takes a long time to run. For n D 40, your program may take several \nminutes and possibly more than an hour. For large v alues of n, you\u2019ll  also  discover  \nthat each time you increase n by 1, your  program\u2019s  running  time  approximately  \ndoubles. \nWhy is C UT-ROD  so inef\u00fbcient?  The  problem  is that  CUT-ROD  calls  itself  re-  \ncursively over and over again with the same paramet er values, which means that \nit solves  the  same  subproblems  repeatedly.  Figure  14.3  show s a recursion tree \ndemonstrating what happens for n D 4: CUT-ROD.p;n/  calls C UT-ROD.p;n  \ue003 i/ \nfor i D 1;2;:::;n . Equivalently, C UT-ROD.p;n/  calls C UT-ROD.p;j/  for each \nj D 0;1;:::;n  \ue003 1. When this process unfolds recursively, the amount  of work \ndone, as a function of n, grows explosively. \nTo analyze the running time of C UT-ROD, let T.n/  denote the total number of \ncalls made to C UT-ROD.p;n/  for a particular value of n. This expression equals \nthe number of nodes in a subtree whose root is labe led n in the recursion tree. The \ncount includes the initial call at its root. Thus, T.0/  D 1 and \nT.n/  D 1 C n\ue0021 X  \nj D0 T.j/:  (14.3)  \nThe initial 1 is for the call at the root, and the term T.j/  counts the number of calls \n(including recursive calls) due to the call C UT-ROD.p;n  \ue003 i/, where j D n \ue003 i . \nAs  Exercise  14.1-1  asks  you  to show,  \nT.n/  D 2 n ; (14.4)  \nand so the running time of C UT-ROD  is exponential in n. \nIn retrospect, this exponential running time is not  so surprising. C UT-ROD  ex-  \nplicitly considers all possible ways of cutting up a rod of length n. How many ways 14.1  Rod  cutting  367 \n3 \n1 0 \n0 \n0 0 1 2 0 \n0 1 2 \n0 1 0 4 \nFigure  14.3  The recursion tree showing recursive calls resultin g from a call C UT-ROD.p;n/  for \nn D 4. Each node label gives the size n of the corresponding subproblem, so that an edge fr om \na parent with label s to a child with label t corresponds to cutting off an initial piece of size  s \ue003 t \nand leaving a remaining subproblem of size t . A path from the root to a leaf corresponds to one  of \nthe 2 n\ue0021 ways of cutting up a rod of length n. In general, this recursion tree has 2 n nodes and 2 n\ue0021 \nleaves. \nare  there?  A rod  of length  n has n \ue003 1 potential locations to cut. Each possible way \nto cut up the rod makes a cut at some subset of the se n \ue003 1 locations, including the \nempty set, which makes for no cuts. Viewing each cu t location as a distinct  mem-  \nber of a set of n \ue003 1 elements, you can see that there are 2 n\ue0021 subsets. Each leaf \nin the  recursion  tree  of Figure  14.3  corresponds  to one  possi ble way to cut up the \nrod. Hence, the recursion tree has 2 n\ue0021 leaves. The labels on the simple path from \nthe  root  to a leaf  give  the  sizes  of each  remaining  right-hand  piece before making \neach cut. That is, the labels give the correspondin g cut points, measured from the \nright-hand  end  of the  rod.  \nUsing  dynamic  programming  for  optimal  rod  cutting  \nNow,  let\u2019s  see  how  to use  dynamic  programming  to convert  CUT-ROD  into an \nef\u00fbcient  algorithm.  \nThe  dynamic-programming  method  works  as follows.  Instead  of solving the \nsame subproblems repeatedly, as in the naive recurs ion solution, arrange for each \nsubproblem to be solved only  once. There\u2019s  actually  an obvious  way  to do  so:  the  \n\u00fbrst  time  you  solve  a subproblem,  save  its  solution . If you need to refer to this \nsubproblem\u2019s  solution  again  later,  just  look  it up,  rather  than recomputing it. \nSaving subproblem solutions comes with a cost: the additional memory needed \nto store solutions. Dynamic programming thus serves  as an example of a time-  \nmemory  trade-off  . The  savings  may  be dramatic.  For  example,  we\u2019re  about  to use  \ndynamic  programming  to go  from  the  exponential-time  algori thm for rod cutting 368  Chapter  14  Dynamic  Programming  \ndown to a \u201a.n  2 /-time  algorithm.  A dynamic-programming  approach  runs  in poly-  \nnomial time when the number of distinct  subproblems involved is polynomial in \nthe input size and you can solve each such subprobl em in polynomial time. \nThere are usually two equivalent ways to implement a dynamic-programming  \napproach.  Solutions  to the  rod-cutting  problem  illustrate  both of them. \nThe  \u00fbrst  approach  is top-down  with memoization . 2 In this approach, you write \nthe  procedure  recursively  in a natural  manner,  but  modi\u00fbed  to save the result of \neach subproblem (usually in an array or hash table) . The procedure  now  \u00fbrst  checks  \nto see whether it has previously solved this subpro blem. If so, it returns the saved \nvalue, saving further computation at this level. If  not, the procedure computes the \nvalue in the usual manner but also saves it. We say  that the recursive procedure has \nbeen memoized : it <remembers= what results it has computed previ ously. \nThe second approach is the bottom-up  method. This  approach  typically  de-  \npends on some natural notion of the <size= of a sub problem, such that solving any \nparticular subproblem depends only on solving <smal ler= subproblems. Solve the \nsubproblems  in size  order,  smallest  \u00fbrst,  storing  the  solut ion to each subproblem \nwhen  it is \u00fbrst  solved.  In this  way,  when  solving  a particular  subproblem, there \nare already saved solutions for all of the smaller subproblems its solution depends \nupon. You need to solve each subproblem only once, and when yo u \u00fbrst  see  it, you  \nhave already solved all of its prerequisite subprob lems. \nThese two approaches yield algorithms with the same  asymptotic running time, \nexcept  in unusual  circumstances  where  the  top-down  approac h does not actually \nrecurse  to examine  all  possible  subproblems.  The  bottom-up  approach often has \nmuch better constant factors, since it has lower ov erhead for procedure calls. \nThe procedures M EMOIZED-CUT-ROD  and MEMOIZED-CUT-ROD-AUX on \nthe  facing  page  demonstrate  how  to memoize  the  top-down  CUT-ROD  proce-  \ndure. The main procedure M EMOIZED-CUT-ROD  initializes a new auxiliary array \nr\u01520  W n\ufffd with the value \ue0031  which,  since  known  revenue  values  are  always  nonneg-  \native, is a convenient choice for denoting <unknown .= MEMOIZED-CUT-ROD  then \ncalls its helper procedure, M EMOIZED-CUT-ROD-AUX, which  is just  the  memo-  \nized  version  of the  exponential-time  procedure,  CUT-ROD. It \u00fbrst  checks  in line  1 \nto see whether the desired value is already known a nd, if it is, then line 2 returns it. \nOtherwise,  lines  337  compute  the  desired  value  q in the  usual  manner,  line  8 saves  \nit in r\u0152n\ufffd, and line 9 returns it. \nThe  bottom-up  version,  BOTTOM-UP-CUT-ROD  on  the  next  page,  is even  sim-  \npler.  Using  the  bottom-up  dynamic-programming  approach,  BOTTOM-UP-CUT- \nROD  takes advantage of the natural ordering of the subp roblems: a subproblem of \n2 The technical term <memoization= is not a misspelli ng of <memorization.=  The  word  <memoiza-  \ntion= comes from <memo,= since the technique consis ts of recording a value to be looked up later. 14.1  Rod  cutting  369 \nMEMOIZED-CUT-ROD  .p;n/  \n1 let r\u01520  W n\ufffd be a new array / / will remember solution values in r \n2 for  i D 0 to n \n3 r\u0152i\ufffd  D \ue0031  \n4 return  MEMOIZED-CUT-ROD-AUX .p;n;r/  \nMEMOIZED-CUT-ROD-AUX .p;n;r/  \n1 if r\u0152n\ufffd  \ue004 0 / / already have a solution for length n? \n2 return  r\u0152n\ufffd  \n3 if n = = 0 \n4 q D 0 \n5 else  q D \ue0031  \n6 for  i D 1 to n / / i is the  position  of the  \u00fbrst  cut  \n7 q D max fq;p\u0152i\ufffd  C MEMOIZED-CUT-ROD-AUX .p;n  \ue003 i;r/g \n8 r\u0152n\ufffd  D q / / remember the solution value for length n \n9 return  q \nBOTTOM-UP-CUT-ROD  .p;n/  \n1 let r\u01520  W n\ufffd be a new array / / will remember solution values in r \n2 r\u01520\ufffd  D 0 \n3 for  j D 1 to n / / for increasing rod length j \n4 q D \ue0031  \n5 for  i D 1 to j / / i is the  position  of the  \u00fbrst  cut  \n6 q D max fq;p\u0152i\ufffd  C r\u0152j  \ue003 i\ufffdg \n7 r\u0152j\ufffd  D q / / remember the solution value for length j \n8 return  r\u0152n\ufffd  \nsize i is <smaller= than a subproblem of size j if i<j  . Thus, the procedure solves \nsubproblems of sizes j D 0;1;:::;n , in that order. \nLine  1 of BOTTOM-UP-CUT-ROD  creates a new array r\u01520  W n\ufffd in which to save \nthe results of the subproblems, and line 2 initiali zes r\u01520\ufffd  to 0, since a rod of length 0 \nearns  no  revenue.  Lines  336  solve  each  subproblem  of size  j , for j D 1;2;:::;n , \nin order of increasing size. The approach used to s olve a problem of a particular \nsize j is the same as that used by C UT-ROD, except  that  line  6 now  directly  refer-  \nences array entry r\u0152j  \ue003i\ufffd instead of making a recursive call to solve the sub problem \nof size j \ue003 i . Line  7 saves  in r\u0152j\ufffd  the solution to the subproblem of size j . Finally, \nline  8 returns  r\u0152n\ufffd, which equals the optimal value r n . \nThe  bottom-up  and  top-down  versions  have  the  same  asymptoti c running time. \nThe running time of B OTTOM-UP-CUT-ROD  is \u201a.n  2 /, due to its doubly nested 370  Chapter  14  Dynamic  Programming  \n3 \n0 1 2 4 \nFigure  14.4  The  subproblem  graph  for  the  rod-cutting  problem  with  n D 4. The vertex labels give \nthe sizes of the corresponding subproblems. A direc ted edge .x;y/  indicates  that  solving  subprob-  \nlem x requires a solution to subproblem y. This graph is a reduced version of the recursion tree of \nFigure  14.3,  in which  all  nodes  with  the  same  label  are  collap sed into a single vertex and all edges \ngo from parent to child. \nloop structure. The number of iterations of its inn er for  loop,  in lines  536,  forms  \nan arithmetic  series.  The  running  time  of its  top-down  count erpart, MEMOIZED- \nCUT-ROD, is also \u201a.n  2 /, although this running time may be a little harder  to see. \nBecause a recursive call to solve a previously solv ed subproblem  returns  immedi-  \nately, MEMOIZED-CUT-ROD  solves  each  subproblem  just  once.  It solves  subprob-  \nlems for sizes 0;1;:::;n . To solve a subproblem of size n, the for  loop  of lines  637  \niterates n times. Thus, the total number of iterations of this  for  loop,  over  all  re-  \ncursive calls of M EMOIZED-CUT-ROD, forms an arithmetic series, giving a total \nof \u201a.n  2 / iterations, just like the inner for  loop of BOTTOM-UP-CUT-ROD. (We \nactually  are  using  a form  of aggregate  analysis  here.  We\u2019ll  see aggregate analysis \nin detail  in Section  16.1.)  \nSubproblem  graphs  \nWhen  you  think  about  a dynamic-programming  problem,  you  need to understand \nthe set of subproblems involved and how subproblems  depend on one another. \nThe subproblem  graph  for  the  problem  embodies  exactly  this  information.  Fig-  \nure  14.4  shows  the  subproblem  graph  for  the  rod-cutting  problem with n D 4. It \nis a directed graph, containing one vertex for each  distinct subproblem.  The  sub-  \nproblem graph has a directed edge from the vertex f or subproblem x to the vertex \nfor subproblem y if determining an optimal solution for subproblem x involves \ndirectly considering an optimal solution for subpro blem y . For  example,  the  sub-  \nproblem graph contains an edge from x to y if a top-down  recursive  procedure  for  \nsolving x directly calls itself to solve y . You can think of the subproblem graph as 14.1  Rod  cutting  371 \na <reduced= or <collapsed= version of the recursion  tree for the  top-down  recursive  \nmethod, with all nodes for the same subproblem coal esced into a single vertex and \nall edges directed from parent to child. \nThe  bottom-up  method  for  dynamic  programming  considers  the  vertices of the \nsubproblem graph in such an order that you solve th e subproblems y adjacent to \na given subproblem x before you solve subproblem x . (As  Section  B.4  notes,  the  \nadjacency relation in a directed graph is not neces sarily symmetric.)  Using  ter-  \nminology  that  we\u2019ll  see  in Section  20.4,  in a bottom-up  dynamic-programming  \nalgorithm, you consider the vertices of the subprob lem graph in an order that is a \n<reverse topological sort,= or a <topological sort of the transpose=  of the  subprob-  \nlem graph. In other words, no subproblem is conside red until all  of the  subprob-  \nlems it depends upon have been solved. Similarly, u sing notions  that  we\u2019ll  visit  in \nSection  20.3,  you  can  view  the  top-down  method  (with  memoiza tion) for dynamic \nprogramming  as a <depth-\u00fbrst  search=  of the  subproblem  graph. \nThe size of the subproblem graph G D .V;E/  can help you determine the \nrunning  time  of the  dynamic-programming  algorithm.  Since  you  solve  each  sub-  \nproblem just once, the running time is the sum of t he times needed to solve each \nsubproblem. Typically, the time to compute the solu tion to a subproblem  is propor-  \ntional to the degree (number of outgoing edges) of the corresponding vertex in the \nsubproblem graph, and the number of subproblems is equal to the number  of ver-  \ntices in the subproblem graph. In this common case,  the running time of dynamic \nprogramming is linear in the number of vertices and  edges. \nReconstructing  a solution  \nThe procedures M EMOIZED-CUT-ROD  and BOTTOM-UP-CUT-ROD  return the \nvalue  of an optimal  solution  to the  rod-cutting  problem,  but  they  do not return \nthe solution itself : a list of piece sizes. \nLet\u2019s  see  how  to extend  the  dynamic-programming  approach  to record not only \nthe optimal value  computed for each subproblem, but also a choice  that led to the \noptimal value. With this information, you can readi ly print an optimal solution. \nThe procedure E XTENDED-BOTTOM-UP-CUT-ROD  on the next page computes, \nfor each rod size j , not only the maximum revenue r j , but also s j , the optimal size \nof the  \u00fbrst  piece  to cut  off.  It\u2019s  similar  to BOTTOM-UP-CUT-ROD, except that it \ncreates the array s in line  1, and  it updates  s\u0152j\ufffd  in line  8 to hold  the  optimal  size  i \nof the  \u00fbrst  piece  to cut  off  when  solving  a subproblem  of size  j . \nThe procedure P RINT-CUT-ROD-SOLUTION  on  the  following  page  takes  as in-  \nput an array p\u01521  W n\ufffd of prices and a rod size n. It calls E XTENDED-BOTTOM- \nUP-CUT-ROD  to compute the array s\u01521  W n\ufffd of optimal  \u00fbrst-piece  sizes.  Then  \nit prints out the complete list of piece sizes in a n optimal decomposition of a 372  Chapter  14  Dynamic  Programming  \nrod of length n. For  the  sample  price  chart  appearing  in Figure  14.1,  the  call \nEXTENDED-BOTTOM-UP-CUT-ROD  .p;10/  returns the following arrays: \ni 0 1 2 3 4 5 6 7 8 9 10  \nr\u0152i\ufffd  0 1 5 8 10  13  17  18  22  25  30  \ns\u0152i\ufffd  1 2 3 2 2 6 1 2 3 10  \nA call to P RINT-CUT-ROD-SOLUTION  .p;10/  prints just 10, but a call with n D 7 \nprints the cuts 1 and 6, which  correspond  to the  \u00fbrst  optimal  decomposition  for  r 7 \ngiven earlier. \nEXTENDED-BOTTOM-UP-CUT-ROD  .p;n/  \n1 let r\u01520  W n\ufffd and s\u01521  W n\ufffd be new arrays \n2 r\u01520\ufffd  D 0 \n3 for  j D 1 to n / / for increasing rod length j \n4 q D \ue0031  \n5 for  i D 1 to j / / i is the  position  of the  \u00fbrst  cut  \n6 if q<p\u0152i\ufffd  C r\u0152j  \ue003 i\ufffd \n7 q D p\u0152i\ufffd  C r\u0152j  \ue003 i\ufffd \n8 s\u0152j\ufffd  D i / / best cut location so far for length j \n9 r\u0152j\ufffd  D q / / remember the solution value for length j \n10  return  r and s \nPRINT-CUT-ROD-SOLUTION  .p;n/  \n1 .r;s/  D EXTENDED-BOTTOM-UP-CUT-ROD  .p;n/  \n2 while  n>0  \n3 print s\u0152n\ufffd  / / cut location for length n \n4 n D n \ue003 s\u0152n\ufffd  / / length of the remainder of the rod \nExercises  \n14.1-1  \nShow  that  equation  (14.4)  follows  from  equation  (14.3)  and  the initial condition \nT.0/  D 1. \n14.1-2  \nShow, by means of a counterexample, that the follow ing <greedy= strategy does \nnot  always  determine  an optimal  way  to cut  rods.  De\u00fbne  the  density  of a rod of \nlength i to be p i =i , that is, its value per inch. The greedy strategy for a rod of \nlength n cuts  off  a \u00fbrst  piece  of length  i , where 1 \u0dc4 i \u0dc4 n, having maximum 14.2  Matrix-chain  multiplication  373 \ndensity. It then continues by applying the greedy s trategy to the remaining piece of \nlength n \ue003 i . \n14.1-3  \nConsider  a modi\u00fbcation  of the  rod-cutting  problem  in which,  in addition to a \nprice p i for  each  rod,  each  cut  incurs  a \u00fbxed  cost  of c . The revenue associated with \na solution is now the sum of the prices of the piec es minus the costs of making the \ncuts.  Give  a dynamic-programming  algorithm  to solve  this  modi\u00fbed  problem.  \n14.1-4  \nModify C UT-ROD  and MEMOIZED-CUT-ROD-AUX so that their for  loops go up \nto only bn=2c, rather than up to n. What other changes to the procedures do you \nneed  to make?  How  are  their  running  times  affected?  \n14.1-5  \nModify M EMOIZED-CUT-ROD  to return not only the value but the actual solutio n. \n14.1-6  \nThe  Fibonacci  numbers  are  de\u00fbned  by  recurrence  (3.31)  on  page  69.  Give  an \nO.n/-time  dynamic-programming  algorithm  to compute  the  nth Fibonacci number. \nDraw the subproblem graph. How many vertices and ed ges does the graph  contain?  \n14.2  Matrix-chain  multiplication  \nOur  next  example  of dynamic  programming  is an algorithm  that  solves the problem \nof matrix-chain  multiplication.  Given  a sequence  (chain)  hA 1 ;A  2 ;:::;A  n i of n \nmatrices  to be multiplied,  where  the  matrices  aren\u2019t  necess arily square, the goal is \nto compute the product \nA 1 A 2 \ue001 \ue001 \ue001  A n : (14.5)  \nusing the standard algorithm 3 for  multiplying  rectangular  matrices,  which  we\u2019ll  see  \nin a moment, while minimizing the number of scalar multiplications. \nYou  can  evaluate  the  expression  (14.5)  using  the  algorithm  for multiplying pairs \nof rectangular matrices as a subroutine once you ha ve parenthesized it to resolve \nall ambiguities in how the matrices are multiplied together. Matrix multiplication \nis associative, and so all parenthesizations yield the same product. A product of \n3 None  of the  three  methods  from  Sections  4.1  and  Section  4.2  can be used directly, because they \napply only to square matrices. 374  Chapter  14  Dynamic  Programming  \nmatrices is fully  parenthesized  if it is either a single matrix or the product of t wo \nfully parenthesized matrix products, surrounded by parentheses. For example, if \nthe chain of matrices is hA 1 ;A  2 ;A  3 ;A  4 i, then  you  can  fully  parenthesize  the  prod-  \nuct A 1 A 2 A 3 A 4 in \u00fbve  distinct  ways:  \n.A  1 .A  2 .A  3 A 4 ///;  \n.A  1 ..A  2 A 3 /A  4 //;  \n..A  1 A 2 /.A  3 A 4 //;  \n..A  1 .A  2 A 3 //A  4 /; \n...A  1 A 2 /A  3 /A  4 /: \nHow you parenthesize a chain of matrices can have a  dramatic impact on the \ncost  of evaluating  the  product.  Consider  \u00fbrst  the  cost  of multiplying  two  rectangu-  \nlar matrices. The standard algorithm is given by th e procedure R ECTANGULAR - \nMATRIX-MULTIPLY, which  generalizes  the  square-matrix  multiplication  proce-  \ndure M ATRIX-MULTIPLY on  page  81.  The  RECTANGULAR -MATRIX-MULTIPLY \nprocedure computes C D C C A \ue001 B for three matrices A D .a ij /, B D .b ij /, and \nC D .c ij /, where A is p \ue005 q, B is q \ue005 r , and C is p \ue005 r . \nRECTANGULAR -MATRIX-MULTIPLY .A;B;C;p;q;r/  \n1 for  i D 1 to p \n2 for  j D 1 to r \n3 for  k D 1 to q \n4 c ij D c ij C a ik  \ue001 b kj  \nThe running time of R ECTANGULAR -MATRIX-MULTIPLY is dominated by the \nnumber  of scalar  multiplications  in line  4, which  is pqr  . Therefore,  we\u2019ll  consider  \nthe cost of multiplying matrices to be the number o f scalar multiplications. (The \nnumber of scalar multiplications dominates even if we consider initializing C D 0 \nto perform just C D A \ue001 B .) \nTo illustrate the different costs incurred by diffe rent parenthesizations  of a ma-  \ntrix product, consider the problem of a chain hA 1 ;A  2 ;A  3 i of three  matrices.  Sup-  \npose that the dimensions of the matrices are 10  \ue005 100, 100  \ue005 5, and 5 \ue005 50, re-  \nspectively. Multiplying according to the parenthesi zation ..A  1 A 2 /A  3 / performs \n10  \ue001 100  \ue001 5 D 5000  scalar multiplications to compute the 10  \ue005 5 matrix  prod-  \nuct A 1 A 2 , plus another 10  \ue001 5 \ue001 50  D 2500  scalar multiplications to multiply this \nmatrix by A 3 , for  a total  of 7500  scalar  multiplications.  Multiplying  according \nto the alternative parenthesization .A  1 .A  2 A 3 // performs 100  \ue001 5 \ue001 50  D 25,000  \nscalar multiplications to compute the 100  \ue005 50  matrix product A 2 A 3 , plus another \n10  \ue001 100  \ue001 50  D 50,000  scalar  multiplications  to multiply  A 1 by this matrix, for a 14.2  Matrix-chain  multiplication  375 \ntotal  of 75,000  scalar  multiplications.  Thus,  computing  the product according to \nthe  \u00fbrst  parenthesization  is 10  times faster. \nWe state the matrix-chain  multiplication  problem  as follows: given a chain \nhA 1 ;A  2 ;:::;A  n i of n matrices, where for i D 1;2;:::;n , matrix A i has dimension \np i \ue0021 \ue005 p i , fully parenthesize the product A 1 A 2 \ue001 \ue001 \ue001  A n in a way that minimizes \nthe number of scalar multiplications. The input is the sequence of dimensions \nhp 0 ;p  1 ;p  2 ;:::;p  n i. \nThe  matrix-chain  multiplication  problem  does  not  entail  actually multiplying \nmatrices. The goal is only to determine an order fo r multiplying matrices that \nhas the lowest cost. Typically, the time invested i n determining this optimal order \nis more than paid for by the time saved later on wh en actually performing the \nmatrix  multiplications  (such  as performing  only  7500  scala r multiplications instead \nof 75,000).  \nCounting  the  number  of parenthesizations  \nBefore  solving  the  matrix-chain  multiplication  problem  by  dynamic programming, \nlet us convince ourselves that exhaustively checkin g all possible parenthesizations \nis not  an ef\u00fbcient  algorithm.  Denote  the  number  of alternati ve parenthesizations \nof a sequence of n matrices by P.n/ . When n D 1, the sequence consists of just \none matrix, and therefore there is only one way to fully parenthesize the matrix \nproduct. When n \ue004 2, a fully parenthesized matrix product is the produ ct of two \nfully parenthesized matrix subproducts, and the spl it between the two subproducts \nmay occur between the kth and .k C 1/st matrices for any k D 1;2;:::;n  \ue003 1. \nThus, we obtain the recurrence \nP.n/  D ) \n1 if n D 1;  \nn\ue0021 X  \nkD1 P.k/P.n  \ue003 k/  if n \ue004 2:  (14.6)  \nProblem  12-4  on  page  329  asked  you  to show  that  the  solution  to a similar  recur-  \nrence is the sequence of Catalan  numbers , which grows as \ufffd.4  n =n  3=2  /. A simpler \nexercise  (see  Exercise  14.2-3)  is to show  that  the  solution  to the  recurrence  (14.6)  \nis \ufffd.2  n /. The number of solutions is thus exponential in n, and  the  brute-force  \nmethod of exhaustive search makes for a poor strate gy when determining how to \noptimally parenthesize a matrix chain. \nApplying  dynamic  programming  \nLet\u2019s  use  the  dynamic-programming  method  to determine  how  to optimally  paren-  \nthesize  a matrix  chain,  by  following  the  four-step  sequence  that we stated at the \nbeginning of this chapter: 376  Chapter  14  Dynamic  Programming  \n1. Characterize  the  structure  of an optimal  solution.  \n2. Recursively  de\u00fbne  the  value  of an optimal  solution.  \n3. Compute  the  value  of an optimal  solution.  \n4. Construct  an optimal  solution  from  computed  information . \nWe\u2019ll  go  through  these  steps  in order,  demonstrating  how  to apply each step to the \nproblem. \nStep  1: The  structure  of an  optimal  parenthesization  \nIn the  \u00fbrst  step  of the  dynamic-programming  method,  you  \u00fbnd  the  optimal  sub-  \nstructure and then use it to construct an optimal s olution to the  problem  from  opti-  \nmal solutions to subproblems. To perform this step for the matrix-chain  multipli-  \ncation  problem,  it\u2019s  convenient  to \u00fbrst  introduce  some  notation. Let A i Wj , where \ni \u0dc4 j , denote the matrix that results from evaluating th e product A i A i C1 \ue001 \ue001 \ue001  A j . \nIf the problem is nontrivial, that is, i < j  , then to parenthesize the product \nA i A i C1 \ue001 \ue001 \ue001  A j , the product must split between A k and A kC1 for some integer k \nin the range i \u0dc4 k <j  . That is, for some value of k, \u00fbrst  compute  the  matrices  \nA i Wk and A kC1Wj , and  then  multiply  them  together  to produce  the  \u00fbnal  product  A i Wj . \nThe cost of parenthesizing this way is the cost of computing the matrix A i Wk , plus \nthe cost of computing A kC1Wj , plus the cost of multiplying them together. \nThe optimal substructure of this problem is as foll ows. Suppose  that  to op-  \ntimally parenthesize A i A i C1 \ue001 \ue001 \ue001  A j , you split the product between A k and A kC1 . \nThen  the  way  you  parenthesize  the  <pre\u00fbx=  subchain  A i A i C1 \ue001 \ue001 \ue001  A k within this \noptimal parenthesization of A i A i C1 \ue001 \ue001 \ue001  A j must be an optimal parenthesization of \nA i A i C1 \ue001 \ue001 \ue001  A k . Why?  If there  were  a less  costly  way  to parenthesize  A i A i C1 \ue001 \ue001 \ue001  A k , \nthen you could substitute that parenthesization in the optimal parenthesization \nof A i A i C1 \ue001 \ue001 \ue001  A j to produce another way to parenthesize A i A i C1 \ue001 \ue001 \ue001  A j whose cost \nis lower than the optimum: a contradiction. A simil ar observation holds for how \nto parenthesize the subchain A kC1 A kC2 \ue001 \ue001 \ue001  A j in the optimal parenthesization of \nA i A i C1 \ue001 \ue001 \ue001  A j : it must be an optimal parenthesization of A kC1 A kC2 \ue001 \ue001 \ue001  A j . \nNow  let\u2019s  use  the  optimal  substructure  to show  how  to constru ct an optimal \nsolution to the problem from optimal solutions to s ubproblems. Any solution to a \nnontrivial  instance  of the  matrix-chain  multiplication  problem requires splitting the \nproduct, and any optimal solution contains within i t optimal solutions  to subprob-  \nlem instances. Thus, to build an optimal solution t o an instance  of the  matrix-chain  \nmultiplication problem, split the problem into two subproblems  (optimally  paren-  \nthesizing A i A i C1 \ue001 \ue001 \ue001  A k and A kC1 A kC2 \ue001 \ue001 \ue001  A j ), \u00fbnd  optimal  solutions  to the  two  \nsubproblem instances, and then combine these optima l subproblem solutions. To \nensure  that  you\u2019ve  examined  the  optimal  split,  you  must  consider all possible splits. 14.2  Matrix-chain  multiplication  377 \nStep  2: A recursive  solution  \nThe  next  step  is to de\u00fbne  the  cost  of an optimal  solution  recur sively in terms of the \noptimal  solutions  to subproblems.  For  the  matrix-chain  multiplication problem, a \nsubproblem is to determine the minimum cost of pare nthesizing A i A i C1 \ue001 \ue001 \ue001  A j for \n1 \u0dc4 i \u0dc4 j \u0dc4 n. Given  the  input  dimensions  hp 0 ;p  1 ;p  2 ;:::;p  n i, an index pair \ni;j  speci\u00fbes  a subproblem.  Let  m\u0152i;j\ufffd  be the  minimum  number  of scalar  multi-  \nplications needed to compute the matrix A i Wj . For  the  full  problem,  the  lowest-cost  \nway to compute A 1Wn is thus m\u01521;n\ufffd . \nWe  can  de\u00fbne  m\u0152i;j\ufffd  recursively as follows. If i D j , the problem is trivial: \nthe chain consists of just one matrix A i Wi D A i , so that no scalar multiplications \nare necessary to compute the product. Thus, m\u0152i;i\ufffd  D 0 for i D 1;2;:::;n . To \ncompute m\u0152i;j\ufffd  when i < j  , we take advantage of the structure of an optimal \nsolution  from  step  1. Suppose  that  an optimal  parenthesizat ion splits the product \nA i A i C1 \ue001 \ue001 \ue001  A j between A k and A kC1 , where i \u0dc4 k < j  . Then, m\u0152i;j\ufffd  equals \nthe minimum cost m\u0152i;k\ufffd  for computing the subproduct A i Wk , plus the minimum \ncost m\u0152k  C 1;j\ufffd  for computing the subproduct, A kC1Wj , plus the cost of multiplying \nthese two matrices together. Because each matrix A i is p i \ue0021 \ue005 p i , computing the \nmatrix product A i Wk A kC1Wj takes p i \ue0021 p k p j scalar multiplications. Thus, we obtain \nm\u0152i;j\ufffd  D m\u0152i;k\ufffd  C m\u0152k  C 1;j\ufffd  C p i \ue0021 p k p j : \nThis recursive equation assumes that you know the v alue of k. But  you  don\u2019t,  \nat least not yet. You have to try all possible valu es of k. How  many  are  there?  \nJust  j \ue003 i , namely k D i;i  C 1;:::;j  \ue003 1. Since the optimal parenthesization \nmust use one of these values for k, you  need  only  check  them  all  to \u00fbnd  the  best.  \nThus,  the  recursive  de\u00fbnition  for  the  minimum  cost  of parent hesizing the product \nA i A i C1 \ue001 \ue001 \ue001  A j becomes \nm\u0152i;j\ufffd  D ( \n0 if i D j ;  \nmin fm\u0152i;k\ufffd  C m\u0152k  C 1;j\ufffd  C p i \ue0021 p k p j W i \u0dc4 k<j  g if i<j :  \n(14.7)  \nThe m\u0152i;j\ufffd  values give the costs of optimal solutions to subpr oblems, but they \ndo not provide all the information you need to cons truct an optimal solution. To \nhelp  you  do  so,  let\u2019s  de\u00fbne  s\u0152i;j\ufffd  to be a value of k at which you split the product \nA i A i C1 \ue001 \ue001 \ue001  A j in an optimal parenthesization. That is, s\u0152i;j\ufffd  equals a value k such \nthat m\u0152i;j\ufffd  D m\u0152i;k\ufffd  C m\u0152k  C 1;j\ufffd  C p i \ue0021 p k p j . \nStep  3: Computing  the  optimal  costs  \nAt this point, you could write a recursive algorith m based on recurrence  (14.7)  to \ncompute the minimum cost m\u01521;n\ufffd  for multiplying A 1 A 2 \ue001 \ue001 \ue001  A n . But as we saw 378  Chapter  14  Dynamic  Programming  \nfor  the  rod-cutting  problem,  and  as we  shall  see  in Section  14.3,  this  recursive  \nalgorithm  takes  exponential  time.  That\u2019s  no  better  than  the  brute-force  method  of \nchecking each way of parenthesizing the product. \nFortunately,  there  aren\u2019t  all  that  many  distinct  subproble ms: just one subproblem \nfor each choice of i and j satisfying 1 \u0dc4 i \u0dc4 j \u0dc4 n, or \u00e3 n \n2 \u00e4 \nC n D \u201a.n  2 / in all. 4 \nA recursive algorithm may encounter each subproblem  many times in different \nbranches of its recursion tree. This property of ov erlapping subproblems is the \nsecond  hallmark  of when  dynamic  programming  applies  (the  \u00fbrst hallmark being \noptimal substructure). \nInstead  of computing  the  solution  to recurrence  (14.7)  recursively,  let\u2019s  com-  \npute  the  optimal  cost  by  using  a tabular,  bottom-up  approach , as in the procedure \nMATRIX-CHAIN-ORDER. (The  corresponding  top-down  approach  using  memo-  \nization  appears  in Section  14.3.)  The  input  is a sequence  p D hp 0 ;p  1 ;:::;p  n i \nof matrix dimensions, along with n, so that for i D 1;2;:::;n , matrix A i has  di-  \nmensions p i \ue0021 \ue005 p i . The procedure uses an auxiliary table m\u01521  W n;1  W n\ufffd to store \nthe m\u0152i;j\ufffd  costs and another auxiliary table s\u01521  W n \ue003 1;2  W n\ufffd that records which \nindex k achieved the optimal cost in computing m\u0152i;j\ufffd . The table s will help in \nconstructing an optimal solution. \nMATRIX-CHAIN-ORDER .p;n/  \n1 let m\u01521  W n;1  W n\ufffd and s\u01521  W n \ue003 1;2  W n\ufffd be new tables \n2 for  i D 1 to n / / chain length 1 \n3 m\u0152i;i\ufffd  D 0 \n4 for  l D 2 to n / / l is the chain length \n5 for  i D 1 to n \ue003 l C 1 / / chain begins at A i \n6 j D i C l \ue003 1 / / chain ends at A j \n7 m\u0152i;j\ufffd  D 1  \n8 for  k D i to j \ue003 1 / / try A i Wk A kC1Wj \n9 q D m\u0152i;k\ufffd  C m\u0152k  C 1;j\ufffd  C p i \ue0021 p k p j \n10  if q<m\u0152i;j\ufffd  \n11  m\u0152i;j\ufffd  D q / / remember this cost \n12  s\u0152i;j\ufffd  D k / / remember this index \n13  return  m and s \nIn what  order  should  the  algorithm  \u00fbll  in the  table  entries?  To  answer  this  ques-  \ntion,  let\u2019s  see  which  entries  of the  table  need  to be accessed  when computing the \n4 The \u00e3 n \n2 \u00e4 term counts all pairs in which i <j  . Because i and j may be equal, we need to add in \nthe n term. 14.2  Matrix-chain  multiplication  379 \ncost m\u0152i;j\ufffd. Equation  (14.7)  tells  us that  to compute  the  cost  of matrix  prod-  \nuct A i Wj , \u00fbrst  the  costs  of the  products  A i Wk and A kC1Wj need  to have  been  com-  \nputed for all k D i;i  C 1;:::;j  \ue003 1. The chain A i A i C1 \ue001 \ue001 \ue001  A j consists of j \ue003 i C 1 \nmatrices, and the chains A i A i C1 :::A  k and A kC1 A kC2 :::A  j consist of k \ue003 i C 1 \nand j \ue003 k matrices, respectively. Since k < j  , a chain of k \ue003 i C 1 matrices \nconsists of fewer than j \ue003 i C 1 matrices. Likewise, since k \ue004 i , a chain of j \ue003 k \nmatrices consists of fewer than j \ue003 i C 1 matrices.  Thus,  the  algorithm  should  \u00fbll  \nin the table m from shorter matrix chains to longer matrix chains.  That is, for the \nsubproblem of optimally parenthesizing the chain A i A i C1 \ue001 \ue001 \ue001  A j , it makes sense to \nconsider the subproblem size as the length j \ue003 i C 1 of the chain. \nNow,  let\u2019s  see  how  the  MATRIX-CHAIN-ORDER procedure  \u00fblls  in the  m\u0152i;j\ufffd  \nentries  in order  of increasing  chain  length.  Lines  233  initialize m\u0152i;i\ufffd  D 0 for \ni D 1;2;:::;n , since any matrix chain with just one matrix requi res no scalar \nmultiplications. In the for  loop  of lines  4312,  the  loop  variable  l denotes the length \nof matrix chains whose minimum costs are being comp uted. Each iteration of this \nloop  uses  recurrence  (14.7)  to compute  m\u0152i;i  C l \ue003 1\ufffd for i D 1;2;:::;n  \ue003 l C 1. In \nthe  \u00fbrst  iteration,  l D 2, and so the loop computes m\u0152i;i  C1\ufffd for i D 1;2;:::;n \ue0031: \nthe minimum costs for chains of length l D 2. The second time through the loop, \nit computes m\u0152i;i  C 2\ufffd for i D 1;2;:::;n  \ue003 2: the minimum costs for chains of \nlength l D 3. And so on, ending with a single matrix chain of l ength l D n and \ncomputing m\u01521;n\ufffd. When  lines  7312  compute  an m\u0152i;j\ufffd  cost, this cost depends \nonly on table entries m\u0152i;k\ufffd  and m\u0152k  C 1;j\ufffd, which have already been computed. \nFigure  14.5  illustrates  the  m and s tables,  as \u00fblled  in by  the  MATRIX-CHAIN- \nORDER procedure on a chain of n D 6 matrices. Since m\u0152i;j\ufffd  is de\u00fbned  only  \nfor i \u0dc4 j , only the portion of the table m on or above the main diagonal is used. \nThe  \u00fbgure  shows  the  table  rotated  to make  the  main  diagonal  run horizontally. The \nmatrix chain is listed along the bottom. Using this  layout, the minimum cost m\u0152i;j\ufffd  \nfor multiplying a subchain A i A i C1 \ue001 \ue001 \ue001  A j of matrices appears at the intersection of \nlines running northeast from A i and northwest from A j . Reading across, each \ndiagonal in the table contains the entries for matr ix chains of the same length. \nMATRIX-CHAIN-ORDER computes the rows from bottom to top and from left to \nright within each row. It computes each entry m\u0152i;j\ufffd  using the products p i \ue0021 p k p j \nfor k D i;i  C 1;:::;j  \ue003 1 and all entries southwest and southeast from m\u0152i;j\ufffd . \nA simple inspection of the nested loop structure of  MATRIX-CHAIN-ORDER \nyields a running time of O.n  3 / for the algorithm. The loops are nested three deep,  \nand each loop index ( l , i , and k) takes on at most n \ue003 1 values.  Exercise  14.2-5  asks  \nyou to show that the running time of this algorithm  is in fact also \ufffd.n  3 /. The  al-  \ngorithm requires \u201a.n  2 / space to store the m and s tables. Thus, M ATRIX-CHAIN- \nORDER is much  more  ef\u00fbcient  than  the  exponential-time  method  of enumerating \nall possible parenthesizations and checking each on e. 380  Chapter  14  Dynamic  Programming  \nA 6 A 5 A 4 A 3 A 2 A 1 0 0 0 0 0 0 15,750  2,625  750  1,000  5,000  7,875  4,375  2,500  3,500  9,375  7,125  5,375  11,875  10,500  15,125  \n1 2 3 4 5 6 1 \n2 \n3 \n4 \n5 \n6 j i m \n1 2 3 4 5 1 3 3 5 3 3 3 3 3 3 \n2 3 4 5 6 1 \n2 \n3 \n4 \n5 j i s \nFigure  14.5  The m and s tables computed by M ATRIX-CHAIN-ORDER for n D 6 and  the  follow-  \ning matrix dimensions: \nmatrix A 1 A 2 A 3 A 4 A 5 A 6 \ndimension 30  \ue005 35  35  \ue005 15  15  \ue005 5 5  \ue005 10  10  \ue005 20  20  \ue005 25  \nThe tables are rotated so that the main diagonal ru ns horizontally. The m table uses only the main \ndiagonal and upper triangle, and the s table uses only the upper triangle. The minimum num ber of \nscalar  multiplications  to multiply  the  6 matrices  is m\u01521;6\ufffd  D 15,125.  Of  the  entries  that  are  not  tan,  \nthe pairs that have the same color are taken togeth er in line 9 when computing \nm\u01522;5\ufffd  D min 8 \n\u02c6 < \n\u02c6 : m\u01522;2\ufffd  C m\u01523;5\ufffd  C p 1 p 2 p 5 D 0 C 2500  C 35  \ue001 15  \ue001 20  D 13,000  ; \nm\u01522;3\ufffd  C m\u01524;5\ufffd  C p 1 p 3 p 5 D 2625  C 1000  C 35  \ue001 5 \ue001 20  D 7125;  \nm\u01522;4\ufffd  C m\u01525;5\ufffd  C p 1 p 4 p 5 D 4375  C 0 C 35  \ue001 10  \ue001 20  D 11,375  \nD 7125:  \nStep  4: Constructing  an  optimal  solution  \nAlthough M ATRIX-CHAIN-ORDER determines  the  optimal  number  of scalar  mul-  \ntiplications  needed  to compute  a matrix-chain  product,  it does not directly show \nhow to multiply the matrices. The table s\u01521  W n \ue003 1;2  W n\ufffd provides the information \nneeded to do so. Each entry s\u0152i;j\ufffd  records a value of k such  that  an optimal  paren-  \nthesization of A i A i C1 \ue001 \ue001 \ue001  A j splits the product between A k and A kC1 . The  \u00fbnal  \nmatrix multiplication in computing A 1Wn optimally is A 1Ws\u01521;n\u0141  A s\u01521;n\u0141 C1Wn . The s ta-  \nble contains the information needed to determine th e earlier matrix multiplications \nas well, using recursion: s\u01521;s\u01521;n\ufffd\ufffd  determines the last matrix multiplication when \ncomputing A 1Ws\u01521;n\u0141  and s\u0152s\u01521;n\ufffd  C 1;n\ufffd  determines the last matrix multiplication \nwhen computing A s\u01521;n\u0141 C1Wn . The recursive procedure P RINT-OPTIMAL-PARENS \non the facing page prints an optimal parenthesizati on of the matrix chain product \nA i A i C1 \ue001 \ue001 \ue001  A j , given the s table computed by M ATRIX-CHAIN-ORDER and  the  in-  14.2  Matrix-chain  multiplication  381 \ndices i and j . The initial call P RINT-OPTIMAL-PARENS .s;1;n/  prints an optimal \nparenthesization of the full matrix chain product A 1 A 2 \ue001 \ue001 \ue001  A n . In the example of \nFigure  14.5,  the  call  PRINT-OPTIMAL-PARENS .s;1;6/  prints  the  optimal  paren-  \nthesization ..A  1 .A  2 A 3 //..A  4 A 5 /A  6 //. \nPRINT-OPTIMAL-PARENS .s;i;j/  \n1 if i = = j \n2 print <A= i \n3 else  print <(= \n4 PRINT-OPTIMAL-PARENS .s;i;s\u0152i;j\ufffd/  \n5 PRINT-OPTIMAL-PARENS .s;s\u0152i;j\ufffd  C 1;j/  \n6 print <)= \nExercises  \n14.2-1  \nFind  an optimal  parenthesization  of a matrix-chain  product  whose sequence of \ndimensions is h5;10;3;12;5;50;6 i. \n14.2-2  \nGive  a recursive  algorithm  MATRIX-CHAIN-MULTIPLY .A;s;i;j/  that actually \nperforms  the  optimal  matrix-chain  multiplication,  given  the  sequence  of matri-  \nces hA 1 ;A  2 ;:::;A  n i, the s table computed by M ATRIX-CHAIN-ORDER , and the \nindices i and j . (The initial call is M ATRIX-CHAIN-MULTIPLY .A;s;1;n/.) As-  \nsume that the call R ECTANGULAR -MATRIX-MULTIPLY .A;B/  returns the product \nof matrices A and B . \n14.2-3  \nUse the substitution method to show that the soluti on to the recurrence  (14.6)  \nis \ufffd.2  n /. \n14.2-4  \nDescribe  the  subproblem  graph  for  matrix-chain  multiplica tion with an input chain \nof length n. How  many  vertices  does  it have?  How  many  edges  does  it have,  and \nwhich  edges  are  they?  \n14.2-5  \nLet R.i;j/  be the number of times that table entry m\u0152i;j\ufffd  is referenced while \ncomputing other table entries in a call of M ATRIX-CHAIN-ORDER . Show that the \ntotal number of references for the entire table is 382  Chapter  14  Dynamic  Programming  \nn X  \ni D1 n X  \nj Di R.i;j/  D n 3 \ue003 n \n3 : \n(Hint: You  may  \u00fbnd  equation  (A.4)  on  page  1141  useful.)  \n14.2-6  \nShow that a full parenthesization of an n-element  expression  has  exactly  n \ue003 1 pairs \nof parentheses. \n14.3  Elements  of dynamic  programming  \nAlthough you have just seen two complete examples o f the dynamic-programming  \nmethod, you might still be wondering just when the method applies.  From  an engi-  \nneering  perspective,  when  should  you  look  for  a dynamic-pro gramming solution to \na problem?  In this  section,  we\u2019ll  examine  the  two  key  ingredients  that  an optimiza-  \ntion problem must have in order for dynamic program ming to apply:  optimal  sub-  \nstructure  and  overlapping  subproblems.  We\u2019ll  also  revisit  and discuss more fully \nhow memoization might help you take advantage of th e overlapping-subproblems  \nproperty  in a top-down  recursive  approach.  \nOptimal  substructure  \nThe  \u00fbrst  step  in solving  an optimization  problem  by  dynamic  programming is to \ncharacterize the structure of an optimal solution. Recall that a problem exhibits \noptimal  substructure  if an optimal solution to the problem contains with in it opti- \nmal solutions to subproblems. When a problem exhibi ts optimal substructure, that \ngives you a good clue that dynamic programming migh t apply. (As  Chapter  15  \ndiscusses, it also might mean that a greedy strateg y applies, however.) Dynamic \nprogramming builds an optimal solution to the probl em from optimal solutions to \nsubproblems. Consequently, you must take care to en sure that the  range  of sub-  \nproblems you consider includes those used in an opt imal solution. \nOptimal  substructure  was  key  to solving  both  of the  previous  problems in this \nchapter.  In Section  14.1,  we  observed  that  the  optimal  way  of cutting up a rod of \nlength n (if Serling Enterprises makes any cuts at all) invo lves optimally cutting \nup  the  two  pieces  resulting  from  the  \u00fbrst  cut.  In Section  14.2, we noted that an \noptimal parenthesization of the matrix chain produc t A i A i C1 \ue001 \ue001 \ue001  A j that splits the \nproduct between A k and A kC1 contains within it optimal solutions to the problem s \nof parenthesizing A i A i C1 \ue001 \ue001 \ue001  A k and A kC1 A kC2 \ue001 \ue001 \ue001  A j . 14.3  Elements  of dynamic  programming  383 \nYou  will  \u00fbnd  yourself  following  a common  pattern  in discovering  optimal  sub-  \nstructure: \n1. You  show  that  a solution  to the  problem  consists  of making  a choice, such as \nchoosing an initial cut in a rod or choosing an ind ex at which to split the matrix \nchain. Making this choice leaves one or more subpro blems to be solved. \n2. You suppose that for a given problem, you are gi ven the choice that leads to an \noptimal solution. You do not concern yourself yet w ith how to determine this \nchoice. You just assume that it has been given to y ou. \n3. Given  this  choice,  you  determine  which  subproblems  ensue  and how to best \ncharacterize the resulting space of subproblems. \n4. You  show  that  the  solutions  to the  subproblems  used  within  an optimal solution \nto the  problem  must  themselves  be optimal  by  using  a <cut-and-paste=  tech-  \nnique. You do so by supposing that each of the subp roblem solutions is not \noptimal and then deriving a contradiction. In parti cular, by <cutting out= the \nnonoptimal solution to each subproblem and <pasting  in= the optimal one, you \nshow that you can get a better solution to the orig inal problem,  thus  contradict-  \ning your supposition that you already had an optima l solution. If an optimal \nsolution gives rise to more than one subproblem, th ey are typically so similar \nthat  you  can  modify  the  cut-and-paste  argument  for  one  to apply to the others \nwith little effort. \nTo characterize the space of subproblems, a good ru le of thumb says to try to \nkeep the space as simple as possible and then expan d it as necessary. For example, \nthe  space  of subproblems  for  the  rod-cutting  problem  contai ned the problems of \noptimally cutting up a rod of length i for each size i . This subproblem space \nworked well, and it was not necessary to try a more  general space of subproblems. \nConversely, suppose that you tried to constrain the  subproblem  space  for  matrix-  \nchain multiplication to matrix products of the form  A 1 A 2 \ue001 \ue001 \ue001  A j . As before, an \noptimal parenthesization must split this product be tween A k and A kC1 for some \n1 \u0dc4 k<j  . Unless you can guarantee that k always equals j \ue003 1, you  will  \u00fbnd  that  \nyou have subproblems of the form A 1 A 2 \ue001 \ue001 \ue001  A k and A kC1 A kC2 \ue001 \ue001 \ue001  A j . Moreover, \nthe latter subproblem does not have the form A 1 A 2 \ue001 \ue001 \ue001  A j . To solve this problem by \ndynamic programming, you need to allow the subprobl ems to vary at <both ends.= \nThat is, both i and j need to vary in the subproblem of parenthesizing th e product \nA i A i C1 \ue001 \ue001 \ue001  A j . \nOptimal  substructure  varies  across  problem  domains  in two  ways: \n1. how  many  subproblems  an optimal  solution  to the  original  problem uses, and \n2. how many choices you have in determining which s ubproblem(s) to use in an \noptimal solution. 384  Chapter  14  Dynamic  Programming  \nIn the  rod-cutting  problem,  an optimal  solution  for  cutting  up a rod of size n uses \njust one subproblem (of size n \ue003 i ), but we have to consider n choices for i in order \nto determine  which  one  yields  an optimal  solution.  Matrix-c hain multiplication for \nthe subchain A i A i C1 \ue001 \ue001 \ue001  A j serves an example with two subproblems and j \ue003 i \nchoices. For a given matrix A k where  the  product  splits,  two  subproblems  arise4  \nparenthesizing A i A i C1 \ue001 \ue001 \ue001  A k and parenthesizing A kC1 A kC2 \ue001 \ue001 \ue001  A j 4and  we  have  \nto solve both of them  optimally.  Once  we  determine  the  optimal  solutions  to sub-  \nproblems, we choose from among j \ue003 i candidates for the index k. \nInformally,  the  running  time  of a dynamic-programming  algorithm depends on \nthe product of two factors: the number of subproble ms overall and how many \nchoices you look at for each subproblem. In rod cut ting, we had \u201a.n/  subproblems \noverall, and at most n choices to examine for each, yielding an O.n  2 / running time. \nMatrix-chain  multiplication  had  \u201a.n  2 / subproblems overall, and each had at most \nn \ue003 1 choices, giving an O.n  3 / running time (actually, a \u201a.n  3 / running time, by \nExercise  14.2-5).  \nUsually, the subproblem graph gives an alternative way to perform the same \nanalysis. Each vertex corresponds to a subproblem, and the choices  for  a subprob-  \nlem are the edges incident from that subproblem. Re call that in rod cutting, the \nsubproblem graph has n vertices and at most n edges per vertex, yielding an O.n  2 / \nrunning  time.  For  matrix-chain  multiplication,  if you  were  to draw  the  subprob-  \nlem graph, it would have \u201a.n  2 / vertices and each vertex would have degree at \nmost n \ue003 1, giving a total of O.n  3 / vertices and edges. \nDynamic programming often uses optimal substructure  in a bottom-up  fashion.  \nThat  is, you  \u00fbrst  \u00fbnd  optimal  solutions  to subproblems  and,  having solved the \nsubproblems,  you  \u00fbnd  an optimal  solution  to the  problem.  Finding  an optimal  so-  \nlution to the problem entails making a choice among  subproblems as to which you \nwill use in solving the problem. The cost of the pr oblem solution is usually the \nsubproblem costs plus a cost that is directly attri butable to the choice itself. In \nrod  cutting,  for  example,  \u00fbrst  we  solved  the  subproblems  of determining optimal \nways to cut up rods of length i for i D 0;1;:::;n  \ue003 1, and then we determined \nwhich of these subproblems yielded an optimal solut ion for a rod of length n, us-  \ning  equation  (14.2).  The  cost  attributable  to the  choice  itself is the term p i in \nequation  (14.2).  In matrix-chain  multiplication,  we  determined  optimal  parenthe-  \nsizations of subchains of A i A i C1 \ue001 \ue001 \ue001  A j , and then we chose the matrix A k at which \nto split the product. The cost attributable to the choice itself is the term p i \ue0021 p k p j . \nChapter  15  explores  <greedy  algorithms,=  which  have  many  similarities  to dy-  \nnamic programming. In particular, problems to which  greedy algorithms apply \nhave  optimal  substructure.  One  major  difference  between  greedy algorithms and \ndynamic  programming  is that  instead  of \u00fbrst  \u00fbnding  optimal  solutions  to subprob-  \nlems  and  then  making  an informed  choice,  greedy  algorithms  \u00fbrst make a <greedy= \nchoice4the  choice  that  looks  best  at the  time4and  then  solve  a resulting  subprob-  14.3  Elements  of dynamic  programming  385 \nlem, without bothering to solve all possible relate d smaller subproblems.  Surpris-  \ningly, in some cases this strategy works! \nSubtleties  \nYou should be careful not to assume that optimal su bstructure applies when it does \nnot. Consider the following two problems whose inpu t consists of a directed graph \nG D .V;E/  and vertices u;v  2 V . \nUnweighted  shortest  path:  5 Find a path from u to v consisting of the fewest \nedges. Such a path must be simple, since removing a  cycle from a path produces \na path with fewer edges. \nUnweighted  longest  simple  path:  Find a simple path from u to v consisting of \nthe most edges. (Without the requirement that the p ath must be simple, the \nproblem  is unde\u00fbned,  since  repeatedly  traversing  a cycle  creates paths with an \narbitrarily large number of edges.) \nThe  unweighted  shortest-path  problem  exhibits  optimal  substructure.  Here\u2019s  \nhow. Suppose that u \u00a4 v, so that the problem is nontrivial. Then, any path  p \nfrom u to v must contain an intermediate vertex, say w. (Note that w may be u \nor v.) Then, we can decompose the path u p \u2740  v into subpaths u p 1 \u2740  w p 2 \u2740  v. The \nnumber of edges in p equals the number of edges in p 1 plus the number of edges \nin p 2 . We claim that if p is an optimal (i.e., shortest) path from u to v, then p 1 \nmust be a shortest path from u to w. Why?  As  suggested  earlier,  use  a <cut-and-  \npaste= argument: if there were another path, say p 0 \n1 , from u to w with fewer edges \nthan p 1 , then we could cut out p 1 and paste in p 0 \n1 to produce a path u p 0 \n1 \u2740  w p 2 \u2740  v \nwith fewer edges than p, thus contradicting p\u2019s optimality.  Likewise,  p 2 must be \na shortest path from w to v. Thus,  to \u00fbnd  a shortest  path  from  u to v, consider \nall intermediate vertices w, \u00fbnd  a shortest  path  from  u to w and a shortest path \nfrom w to v, and choose an intermediate vertex w that yields the overall shortest \npath.  Section  23.2  uses  a variant  of this  observation  of optimal  substructure  to \u00fbnd  \na shortest path between every pair of vertices on a  weighted, directed graph. \nYou  might  be tempted  to assume  that  the  problem  of \u00fbnding  an unweighted \nlongest simple path exhibits optimal substructure a s well. After  all,  if we  decom-  \npose a longest simple path u p \u2740  v into subpaths u p 1 \u2740  w p 2 \u2740  v, then  mustn\u2019t  p 1 \nbe a longest simple path from u to w, and  mustn\u2019t  p 2 be a longest simple path \nfrom w to v? The  answer  is no!  Figure  14.6  supplies  an example.  Consider  the \n5 We use the term <unweighted= to distinguish this pr oblem from that  of \u00fbnding  shortest  paths  with  \nweighted  edges,  which  we  shall  see  in Chapters  22  and  23.  You  can  use  the  breadth-\u00fbrst  search  \ntechnique of Chapter 20 to solve the unweighted pro blem. 386  Chapter  14  Dynamic  Programming  \nq r \ns t \nFigure  14.6  A directed  graph  showing  that  the  problem  of \u00fbnding  a longest  simple path in an \nunweighted directed graph does not have optimal sub structure. The path q !  r !  t is a longest \nsimple path from q to t , but the subpath q !  r is not a longest simple path from q to r , nor is the \nsubpath r !  t a longest simple path from r to t . \npath q !  r !  t , which is a longest simple path from q to t . Is q !  r a longest \nsimple path from q to r ? No,  for  the  path  q !  s !  t !  r is a simple path \nthat is longer. Is r !  t a longest simple path from r to t ? No  again,  for  the  path  \nr !  q !  s !  t is a simple path that is longer. \nThis example shows that for longest simple paths, n ot only does the problem \nlack optimal substructure, but you cannot necessari ly assemble a <legal= solution \nto the problem from solutions to subproblems. If yo u combine the longest simple \npaths q !  s !  t !  r and r !  q !  s !  t , you get the path q !  s !  t !  r !  \nq !  s !  t , which  is not  simple.  Indeed,  the  problem  of \u00fbnding  an unweig hted \nlongest simple path does not appear to have any sor t of optimal substructure. No \nef\u00fbcient  dynamic-programming  algorithm  for  this  problem  has ever been found. In \nfact,  this  problem  is NP-complete,  which4as  we  shall  see  in Chapter  344means  \nthat  we  are  unlikely  to \u00fbnd  a way  to solve  it in polynomial  time. \nWhy is the substructure of a longest simple path so  different from  that  of a short-  \nest  path?  Although  a solution  to a problem  for  both  longest  and shortest paths uses \ntwo  subproblems,  the  subproblems  in \u00fbnding  the  longest  simp le path are not inde-  \npendent , whereas for shortest paths they are. What do we m ean by subproblems \nbeing  independent?  We  mean  that  the  solution  to one  subprobl em does not affect \nthe solution to another subproblem of the same prob lem. For the example  of Fig-  \nure  14.6,  we  have  the  problem  of \u00fbnding  a longest  simple  path  from q to t with \ntwo  subproblems:  \u00fbnding  longest  simple  paths  from  q to r and from r to t . For \nthe  \u00fbrst  of these  subproblems,  we  chose  the  path  q !  s !  t !  r , which used \nthe vertices s and t . These vertices cannot appear in a solution to the  second sub- \nproblem, since the combination of the two solutions  to subproblems yields a path \nthat is not simple. If vertex t cannot be in the solution to the second problem, th en \nthere is no way to solve it, since t is required  to be on  the  path  that  forms  the  solu-  \ntion, and it is not the vertex where the subproblem  solutions are <spliced= together \n(that vertex being r ). Because vertices s and t appear in one subproblem solution, \nthey  cannot  appear  in the  other  subproblem  solution.  One  of them must be in the \nsolution to the other subproblem, however, and an o ptimal solution requires both. 14.3  Elements  of dynamic  programming  387 \nThus, we say that these subproblems are not indepen dent. Looked at another way, \nusing resources in solving one subproblem (those re sources being vertices) renders \nthem unavailable for the other subproblem. \nWhy,  then,  are  the  subproblems  independent  for  \u00fbnding  a shortest  path?  The  \nanswer is that by nature, the subproblems do not sh are resources. We claim that \nif a vertex w is on a shortest path p from u to v, then we can splice together any  \nshortest path u p 1 \u2740  w and any  shortest path w p 2 \u2740  v to produce a shortest path from u \nto v. We are assured that, other than w, no vertex can appear in both paths p 1 \nand p 2 . Why?  Suppose  that  some  vertex  x \u00a4 w appears in both p 1 and p 2 , so that \nwe can decompose p 1 as u p ux  \u2740  x \u2740  w and p 2 as w \u2740  x p xv  \u2740  v. By the optimal \nsubstructure of this problem, path p has as many edges as p 1 and p 2 together.  Let\u2019s  \nsay that p has e edges. Now let us construct a path p 0 D u p ux  \u2740  x p xv  \u2740  v from u to v. \nBecause we have excised the paths from x to w and from w to x , each of which \ncontains at least one edge, path p 0 contains at most e \ue003 2 edges, which contradicts \nthe assumption that p is a shortest path. Thus, we are assured that the s ubproblems \nfor  the  shortest-path  problem  are  independent.  \nThe  two  problems  examined  in Sections  14.1  and  14.2  have  independent  sub-  \nproblems.  In matrix-chain  multiplication,  the  subproblems  are  multiplying  sub-  \nchains A i A i C1 \ue001 \ue001 \ue001  A k and A kC1 A kC2 \ue001 \ue001 \ue001  A j . These subchains are disjoint, so that \nno matrix could possibly be included in both of the m. In rod cutting, to determine \nthe best way to cut up a rod of length n, we looked at the best ways of cutting up \nrods of length i for i D 0;1;:::;n  \ue003 1. Because  an optimal  solution  to the  length-n \nproblem includes just one of these subproblem solut ions (after  cutting  off  the  \u00fbrst  \npiece), independence of subproblems is not an issue . \nOverlapping  subproblems  \nThe second ingredient that an optimization problem must have for  dynamic  pro-  \ngramming to apply is that the space of subproblems must be <small= in the sense \nthat a recursive algorithm for the problem solves t he same subproblems over and \nover, rather than always generating new subproblems . Typically, the total number \nof distinct subproblems is a polynomial in the inpu t size. When a recursive  algo-  \nrithm revisits the same problem repeatedly, we say that the optimization problem \nhas overlapping  subproblems . 6 In contrast,  a problem  for  which  a divide-and-  \n6 It may seem strange that dynamic programming relies  on subproblems being both independent \nand overlapping. Although these requirements may so und contradictory, they describe two different \nnotions, rather than two points on the same axis. T wo subproblems  of the  same  problem  are  inde-  \npendent if they do not share resources. Two subprob lems are overlapping if they are really the same \nsubproblem that occurs as a subproblem of different  problems. 388  Chapter  14  Dynamic  Programming  \n1,4  \n1,1  2,4  1,2  3,4  1,3  4,4  \n2,2  3,4  2,3  4,4  1,1  2,2  3,3  4,4  1,1  2,3  1,2  3,3  \n3,3  4,4  2,2  3,3  2,2  3,3  1,1  2,2  \nFigure  14.7  The recursion tree for the computation of R ECURSIVE-MATRIX-CHAIN.p;1;4/ . \nEach node contains the parameters i and j . The computations performed in a subtree shaded bl ue \nare replaced by a single table lookup in M EMOIZED-MATRIX-CHAIN . \nconquer  approach  is suitable  usually  generates  brand-new  problems at each step \nof the  recursion.  Dynamic-programming  algorithms  typical ly take advantage of \noverlapping subproblems by solving each subproblem once and then storing the \nsolution in a table where it can be looked up when needed, using constant time per \nlookup. \nIn Section  14.1,  we  brie\u00fcy  examined  how  a recursive  solution  to rod cutting \nmakes  exponentially  many  calls  to \u00fbnd  solutions  of smaller  subproblems. The \ndynamic-programming  solution  reduces  the  running  time  from the exponential \ntime of the recursive algorithm down to quadratic t ime. \nTo  illustrate  the  overlapping-subproblems  property  in greater  detail,  let\u2019s  revisit  \nthe  matrix-chain  multiplication  problem.  Referring  back  to Figure  14.5,  observe  \nthat M ATRIX-CHAIN-ORDER repeatedly looks up the solution to subproblems in \nlower rows when solving subproblems in higher rows.  For example, it references \nentry m\u01523;4\ufffd  four times: during the computations of m\u01522;4\ufffd , m\u01521;4\ufffd , m\u01523;5\ufffd , \nand m\u01523;6\ufffd . If the algorithm were to recompute m\u01523;4\ufffd  each time, rather than \njust looking it up, the running time would increase  dramatically.  To  see  how,  con-  \nsider  the  inef\u00fbcient  recursive  procedure  RECURSIVE-MATRIX-CHAIN on  the  fac-  \ning page, which determines m\u0152i;j\ufffd , the minimum number of scalar multiplications \nneeded  to compute  the  matrix-chain  product  A i Wj D A i A i C1 \ue001 \ue001 \ue001  A j . The procedure \nis based  directly  on  the  recurrence  (14.7).  Figure  14.7  show s the recursion tree \nproduced by the call R ECURSIVE-MATRIX-CHAIN.p;1;4/ . Each node is labeled \nby the values of the parameters i and j . Observe  that  some  pairs  of values  occur  \nmany times. \nIn fact, the time to compute m\u01521;n\ufffd  by  this  recursive  procedure  is at least  expo-  \nnential in n. To see why, let T.n/  denote the time taken by R ECURSIVE-MATRIX- 14.3  Elements  of dynamic  programming  389 \nRECURSIVE-MATRIX-CHAIN .p;i;j/  \n1 if i = = j \n2 return  0 \n3 m\u0152i;j\ufffd  D 1  \n4 for  k D i to j \ue003 1 \n5 q D RECURSIVE-MATRIX-CHAIN .p;i;k/  \nC RECURSIVE-MATRIX-CHAIN .p;k  C 1;j/  \nC p i \ue0021 p k p j \n6 if q<m\u0152i;j\ufffd  \n7 m\u0152i;j\ufffd  D q \n8 return  m\u0152i;j\ufffd  \nCHAIN to compute an optimal parenthesization of a chain o f n matrices. Because \nthe  execution  of lines  132  and  of lines  637  each  take  at least  unit time, as does the \nmultiplication  in line  5, inspection  of the  procedure  yield s the recurrence \nT.n/  \ue004 \u0128 \n1 if n D 1;  \n1 C n\ue0021 X  \nkD1 .T.k/  C T.n  \ue003 k/  C 1/ if n>1:  \nNoting that for i D 1;2;:::;n  \ue003 1, each term T.i/  appears once as T.k/  and once \nas T.n  \ue003 k/, and collecting the n \ue003 11s in the summation together with the 1 out \nfront, we can rewrite the recurrence as \nT.n/  \ue004 2 n\ue0021 X  \ni D1 T.i/  C n:  (14.8)  \nLet\u2019s  prove  that  T.n/  D \ufffd.2  n / using  the  substitution  method.  Speci\u00fbcally,  we\u2019ll  \nshow that T.n/  \ue004 2 n\ue0021 for all n \ue004 1. For the base case n D 1, the summation is \nempty, and we get T.1/  \ue004 1 D 2 0 . Inductively, for n \ue004 2 we have \nT.n/  \ue004 2 n\ue0021 X  \ni D1 2 i \ue0021 C n \nD 2 n\ue0022 X  \nj D0 2 j C n (letting j D i \ue003 1) \nD 2.2  n\ue0021 \ue003 1/ C n (by  equation  (A.6)  on  page  1142)  \nD 2 n \ue003 2 C n \n\ue004 2 n\ue0021 ; 390  Chapter  14  Dynamic  Programming  \nwhich completes the proof. Thus, the total amount o f work performed by the call \nRECURSIVE-MATRIX-CHAIN .p;1;n/  is at least exponential in n. \nCompare  this  top-down,  recursive  algorithm  (without  memoi zation) with the \nbottom-up  dynamic-programming  algorithm.  The  latter  is more  ef\u00fbcient  because  it \ntakes  advantage  of the  overlapping-subproblems  property.  Matrix-chain  multipli-  \ncation has only \u201a.n  2 / distinct  subproblems,  and  the  dynamic-programming  algo-  \nrithm solves each exactly once. The recursive algor ithm, on the other hand, must \nsolve each subproblem every time it reappears in th e recursion tree. Whenever a \nrecursion tree for the natural recursive solution t o a problem  contains  the  same  sub-  \nproblem repeatedly, and the total number of distinc t subproblems is small, dynamic \nprogramming  can  improve  ef\u00fbciency,  sometimes  dramaticall y. \nReconstructing  an  optimal  solution  \nAs  a practical  matter,  you\u2019ll  often  want  to store  in a separat e table which choice you \nmade in each subproblem so that you do not have to reconstruct this information \nfrom the table of costs. \nFor  matrix-chain  multiplication,  the  table  s\u0152i;j\ufffd  saves  a signi\u00fbcant  amount  of \nwork when we need to reconstruct an optimal solutio n. Suppose that the M ATRIX- \nCHAIN-ORDER procedure  on  page  378  did  not  maintain  the  s\u0152i;j\ufffd  table, so that it \n\u00fblled  in only  the  table  m\u0152i;j\ufffd  containing optimal subproblem costs. The procedure \nchooses from among j \ue003 i possibilities when determining which subproblems to  \nuse in an optimal solution to parenthesizing A i A i C1 \ue001 \ue001 \ue001  A j , and j \ue003 i is not  a con-  \nstant. Therefore, it would take \u201a.j  \ue003i/ D !.1/  time  to reconstruct  which  subprob-  \nlems it chose for a solution to a given problem. Be cause M ATRIX-CHAIN-ORDER \nstores in s\u0152i;j\ufffd  the index of the matrix at which it split the produ ct A i A i C1 \ue001 \ue001 \ue001  A j , \nthe P RINT-OPTIMAL-PARENS procedure  on  page  381  can  look  up  each  choice  in \nO.1/  time. \nMemoization  \nAs  we  saw  for  the  rod-cutting  problem,  there  is an alternative  approach  to dy-  \nnamic  programming  that  often  offers  the  ef\u00fbciency  of the  bottom-up  dynamic-  \nprogramming  approach  while  maintaining  a top-down  strateg y. The idea is to \nmemoize  the  natural,  but  inef\u00fbcient,  recursive  algorithm.  As  in the  bottom-up  ap-  \nproach, you maintain a table with subproblem soluti ons, but the control structure \nfor  \u00fblling  in the  table  is more  like  the  recursive  algorithm.  \nA memoized recursive algorithm maintains an entry i n a table for the solution to \neach subproblem. Each table entry initially contain s a special value to indicate that \nthe  entry  has  yet  to be \u00fblled  in.  When  the  subproblem  is \u00fbrst  encountered as the \nrecursive algorithm unfolds, its solution is comput ed and then stored in the table. 14.3  Elements  of dynamic  programming  391 \nEach subsequent encounter of this subproblem simply  looks up the value stored in \nthe table and returns it. 7 \nThe procedure M EMOIZED-MATRIX-CHAIN is a memoized  version  of the  pro-  \ncedure R ECURSIVE-MATRIX-CHAIN on  page  389.  Note  where  it resembles  the  \nmemoized  top-down  method  on  page  369  for  the  rod-cutting  problem. \nMEMOIZED-MATRIX-CHAIN .p;n/  \n1 let m\u01521  W n;1  W n\ufffd be a new table \n2 for  i D 1 to n \n3 for  j D i to n \n4 m\u0152i;j\ufffd  D 1  \n5 return  LOOKUP-CHAIN.m;p;1;n/  \nLOOKUP-CHAIN.m;p;i;j/  \n1 if m\u0152i;j\ufffd<  1  \n2 return  m\u0152i;j\ufffd  \n3 if i = = j \n4 m\u0152i;j\ufffd  D 0 \n5 else  for  k D i to j \ue003 1 \n6 q D LOOKUP-CHAIN.m;p;i;k/  \nC LOOKUP-CHAIN.m;p;k  C 1;j/  C p i \ue0021 p k p j \n7 if q<m\u0152i;j\ufffd  \n8 m\u0152i;j\ufffd  D q \n9 return  m\u0152i;j\ufffd  \nThe MEMOIZED-MATRIX-CHAIN procedure,  like  the  bottom-up  MATRIX- \nCHAIN-ORDER procedure  on  page  378,  maintains  a table  m\u01521  W n;1  W n\ufffd of com-  \nputed values of m\u0152i;j\ufffd , the minimum number of scalar multiplications need ed to \ncompute the matrix A i Wj . Each table entry initially contains the value 1  to indicate \nthat  the  entry  has  yet  to be \u00fblled  in.  Upon  calling  LOOKUP-CHAIN.m;p;i;j/ , \nif line  1 \u00fbnds  that  m\u0152i;j\ufffd<  1, then  the  procedure  simply  returns  the  pre-  \nviously computed cost m\u0152i;j\ufffd  in line  2. Otherwise,  the  cost  is computed  \nas in R ECURSIVE-MATRIX-CHAIN , stored in m\u0152i;j\ufffd , and returned. Thus, \nLOOKUP-CHAIN.m;p;i;j/  always returns the value of m\u0152i;j\ufffd , but it computes \nit only  upon  the  \u00fbrst  call  of LOOKUP-CHAIN with  these  speci\u00fbc  values  of i and j . \n7 This approach presupposes that you know the set of all possible subproblem parameters and that \nyou have established the relationship between table  positions  and  subproblems.  Another,  more  gen-  \neral, approach is to memoize by using hashing with the subproblem parameters as keys. 392  Chapter  14  Dynamic  Programming  \nFigure  14.7  illustrates  how  MEMOIZED-MATRIX-CHAIN saves time compared \nwith R ECURSIVE-MATRIX-CHAIN . Subtrees shaded blue represent values that \nare looked up rather than recomputed. \nLike  the  bottom-up  procedure  MATRIX-CHAIN-ORDER, the  memoized  proce-  \ndure MEMOIZED-MATRIX-CHAIN runs in O.n  3 / time.  To  begin  with,  line  4 of \nMEMOIZED-MATRIX-CHAIN executes \u201a.n  2 / times, which dominates the running \ntime outside of the call to L OOKUP-CHAIN in line  5. We  can  categorize  the  calls  \nof LOOKUP-CHAIN into two types: \n1. calls  in which  m\u0152i;j\ufffd  D 1, so that  lines  339  execute,  and  \n2. calls in which m\u0152i;j\ufffd<  1, so that L OOKUP-CHAIN simply returns in line 2. \nThere are \u201a.n  2 / calls  of the  \u00fbrst  type,  one  per  table  entry.  All  calls  of the  sec-  \nond  type  are  made  as recursive  calls  by  calls  of the  \u00fbrst  type.  Whenever a given \ncall of LOOKUP-CHAIN makes recursive calls, it makes O.n/  of them.  There-  \nfore, there are O.n  3 / calls of the second type in all. Each call of the s econd type \ntakes O.1/  time,  and  each  call  of the  \u00fbrst  type  takes  O.n/  time plus the time spent \nin its recursive calls. The total time, therefore, is O.n  3 /. Memoization thus turns \nan \ufffd.2  n /-time  algorithm  into  an O.n  3 /-time  algorithm.  \nWe  have  seen  how  to solve  the  matrix-chain  multiplication  problem by either a \ntop-down,  memoized  dynamic-programming  algorithm  or a bottom-up  dynamic-  \nprogramming algorithm in O.n  3 / time.  Both  the  bottom-up  and  memoized  meth-  \nods  take  advantage  of the  overlapping-subproblems  propert y. There are only \u201a.n  2 / \ndistinct subproblems in total, and either of these methods computes the solution to \neach subproblem only once. Without memoization, the  natural recursive algorithm \nruns in exponential time, since solved subproblems are repeatedly solved. \nIn general practice, if all subproblems must be sol ved at least once,  a bottom-up  \ndynamic-programming  algorithm  usually  outperforms  the  corresponding  top-down  \nmemoized algorithm by a constant factor, because th e bottom-up  algorithm  has  no  \noverhead for recursion and less overhead for mainta ining the table. Moreover, for \nsome problems you can exploit the regular pattern o f table accesses  in the  dynamic-  \nprogramming algorithm to reduce time or space requi rements even  further.  On  the  \nother hand, in certain situations, some of the subp roblems in the subproblem space \nmight not need to be solved at all. In that case, t he memoized solution has the \nadvantage  of solving  only  those  subproblems  that  are  de\u00fbnit ely required. \nExercises  \n14.3-1  \nWhich  is a more  ef\u00fbcient  way  to determine  the  optimal  number  of multiplications \nin a matrix-chain  multiplication  problem:  enumerating  all  the  ways  of parenthesiz-  14.4  Longest  common  subsequence  393 \ning the product and computing the number of multipl ications for each, or running \nRECURSIVE-MATRIX-CHAIN? Justify  your  answer.  \n14.3-2  \nDraw the recursion tree for the M ERGE-SORT  procedure  from  Section  2.3.1  on  an \narray of 16  elements. Explain why memoization fails to speed up  a good divide-  \nand-conquer  algorithm  such  as MERGE-SORT. \n14.3-3  \nConsider  the  antithetical  variant  of the  matrix-chain  multiplication problem where \nthe goal is to parenthesize the sequence of matrice s so as to maximize, rather than \nminimize, the number of scalar multiplications. Doe s this problem exhibit optimal \nsubstructure?  \n14.3-4  \nAs  stated,  in dynamic  programming,  you  \u00fbrst  solve  the  subpro blems and then \nchoose which of them to use in an optimal solution to the problem. Professor \nCapulet claims that she does not always need to sol ve all the subproblems  in or-  \nder  to \u00fbnd  an optimal  solution.  She  suggests  that  she  can  \u00fbnd  an optimal solution \nto the  matrix-chain  multiplication  problem  by  always  choos ing the matrix A k at \nwhich to split the subproduct A i A i C1 \ue001 \ue001 \ue001  A j (by selecting k to minimize  the  quan-  \ntity p i \ue0021 p k p j ) before solving the subproblems. Find an instance of the matrix-  \nchain multiplication problem for which this greedy approach yields a suboptimal \nsolution. \n14.3-5  \nSuppose  that  the  rod-cutting  problem  of Section  14.1  also  had a limit l i on the \nnumber of pieces of length i allowed to be produced, for i D 1;2;:::;n . Show \nthat  the  optimal-substructure  property  described  in Section  14.1  no  longer  holds.  \n14.4  Longest  common  subsequence  \nBiological applications often need to compare the D NA of two (or  more)  dif-  \nferent organisms. A strand of DNA consists of a str ing of molecules called \nbases , where the possible bases are adenine, cytosine, g uanine, and thymine. \nRepresenting each of these bases by its initial let ter, we can express a strand \nof DNA as a string over the 4-element  set  fA; C; G; Tg. (See  Section  C.1  for  \nthe  de\u00fbnition  of a string.)  For  example,  the  DNA  of one  organi sm may be \nS 1 D ACCGGTCGAGTGCGCGGAAGCCGGCCGAA  , and  the  DNA  of another  organ-  \nism may be S 2 D GTCGTTCGGAATGCCGTTGCTCTGTAAA  . One  reason  to com-  394  Chapter  14  Dynamic  Programming  \npare two strands of DNA is to determine how <simila r= the two strands are, as some \nmeasure of how closely related the two organisms ar e. We can, and  do,  de\u00fbne  sim-  \nilarity in many different ways. For example, we can  say that two DNA strands are \nsimilar  if one  is a substring  of the  other.  (Chapter  32  explor es algorithms to solve \nthis problem.) In our example, neither S 1 nor S 2 is a substring  of the  other.  Alter-  \nnatively, we could say that two strands are similar  if the number of changes needed \nto turn  one  into  the  other  is small.  (Problem  14-5  looks  at this notion.) Yet another \nway to measure the similarity of strands S 1 and S 2 is by  \u00fbnding  a third  strand  S 3 \nin which the bases in S 3 appear in each of S 1 and S 2 . These bases must appear \nin the same order, but not necessarily consecutivel y. The longer the strand S 3 we \ncan  \u00fbnd,  the  more  similar  S 1 and S 2 are. In our example, the longest strand S 3 is \nGTCGTCGGAAGCCGGCCGAA  . \nWe  formalize  this  last  notion  of similarity  as the  longest-common-subsequence  \nproblem. A subsequence of a given sequence is just the given sequence with 0 or \nmore elements left out. Formally, given a sequence X D hx 1 ;x  2 ;:::;x  m i, another \nsequence Z D h\u00b4 1 ;\u00b4  2 ;:::;\u00b4  k i is a subsequence  of X if there exists a strictly \nincreasing sequence hi 1 ;i 2 ;:::;i  k i of indices of X such that for all j D 1;2;:::;k , \nwe have x i j D \u00b4 j . For example, Z D hB;C;D;B  i is a subsequence of X D \nhA;B;C;B;D;A;B  i with corresponding index sequence h2;3;5;7 i. \nGiven  two  sequences  X and Y , we say that a sequence Z is a common  sub-  \nsequence  of X and Y if Z is a subsequence of both X and Y . For example, if \nX D hA;B;C;B;D;A;B  i and Y D hB;D;C;A;B;A i, the sequence hB;C;A i is \na common subsequence of both X and Y . The sequence hB;C;A i is not a longest \ncommon subsequence ( LCS) of X and Y , however, since it has length 3 and the \nsequence hB;C;B;A i, which is also common to both sequences X and Y , has \nlength 4. The sequence hB;C;B;A i is an LCS of X and Y , as is the sequence \nhB;D;A;B  i, since X and Y have no common subsequence of length 5 or greater. \nIn the longest-common-subsequence  problem , the input is two sequences X D \nhx 1 ;x  2 ;:::;x  m i and Y D hy 1 ;y  2 ;:::;y  n i, and  the  goal  is to \u00fbnd  a maximum-  \nlength common subsequence of X and Y . This  section  shows  how  to ef\u00fbciently  \nsolve the LCS problem using dynamic programming. \nStep  1: Characterizing  a longest  common  subsequence  \nYou  can  solve  the  LCS  problem  with  a brute-force  approach:  enumerate  all  subse-  \nquences of X and check each subsequence to see whether it is als o a subsequence \nof Y , keeping  track  of the  longest  subsequence  you  \u00fbnd.  Each  subsequence of X \ncorresponds to a subset of the indices f1;2;:::;m g of X . Because X has 2 m sub-  \nsequences, this approach requires exponential time,  making it impractical for long \nsequences. 14.4  Longest  common  subsequence  395 \nThe  LCS  problem  has  an optimal-substructure  property,  however,  as the  fol-  \nlowing  theorem  shows.  As  we\u2019ll  see,  the  natural  classes  of subproblems  corre-  \nspond  to pairs  of <pre\u00fbxes=  of the  two  input  sequences.  To  be precise, given a \nsequence X D hx 1 ;x  2 ;:::;x  m i, we  de\u00fbne  the  i th pre\u00fbx  of X , for i D 0;1;:::;m , \nas X i D hx 1 ;x  2 ;:::;x  i i. For example, if X D hA;B;C;B;D;A;B  i, then \nX 4 D hA;B;C;B  i and X 0 is the empty sequence. \nTheorem  14.1  (Optimal  substructure  of an  LCS)  \nLet X D hx 1 ;x  2 ;:::;x  m i and Y D hy 1 ;y  2 ;:::;y  n i be sequences, and let Z D \nh\u00b4 1 ;\u00b4  2 ;:::;\u00b4  k i be any LCS of X and Y . \n1. If x m D y n , then \u00b4 k D x m D y n and Z k\ue0021 is an LCS of X m\ue0021 and Y n\ue0021 . \n2. If x m \u00a4 y n and \u00b4 k \u00a4 x m , then Z is an LCS of X m\ue0021 and Y . \n3. If x m \u00a4 y n and \u00b4 k \u00a4 y n , then Z is an LCS of X and Y n\ue0021 . \nProof  (1)  If \u00b4 k \u00a4 x m , then we could append x m D y n to Z to obtain a common \nsubsequence of X and Y of length k C 1, contradicting the supposition that Z is \na longest common subsequence of X and Y . Thus, we must have \u00b4 k D x m D y n . \nNow,  the  pre\u00fbx  Z k\ue0021 is a length-.k \ue003 1/ common subsequence of X m\ue0021 and Y n\ue0021 . \nWe wish to show that it is an LCS. Suppose for the purpose of contradiction \nthat there exists a common subsequence W of X m\ue0021 and Y n\ue0021 with length greater \nthan k \ue003 1. Then, appending x m D y n to W produces a common subsequence of \nX and Y whose length is greater than k, which is a contradiction. \n(2) If \u00b4 k \u00a4 x m , then Z is a common subsequence of X m\ue0021 and Y . If there were a \ncommon subsequence W of X m\ue0021 and Y with length greater than k, then W would \nalso be a common subsequence of X m and Y , contradicting the assumption that Z \nis an LCS of X and Y . \n(3)  The  proof  is symmetric  to (2).  \nThe  way  that  Theorem  14.1  characterizes  longest  common  subsequences says \nthat  an LCS  of two  sequences  contains  within  it an LCS  of pre\u00fbxes  of the  two  se-  \nquences.  Thus,  the  LCS  problem  has  an optimal-substructure  property. A recursive \nsolution  also  has  the  overlapping-subproblems  property,  as we\u2019ll  see  in a moment.  \nStep  2: A recursive  solution  \nTheorem  14.1  implies  that  you  should  examine  either  one  or two subproblems \nwhen  \u00fbnding  an LCS  of X D hx 1 ;x  2 ;:::;x  m i and Y D hy 1 ;y  2 ;:::;y  n i. If \nx m D y n , you  need  to \u00fbnd  an LCS  of X m\ue0021 and Y n\ue0021 . Appending x m D y n to \nthis LCS yields an LCS of X and Y . If x m \u00a4 y n , then you have to solve two \nsubproblems:  \u00fbnding  an LCS  of X m\ue0021 and Y and  \u00fbnding  an LCS  of X and Y n\ue0021 . 396  Chapter  14  Dynamic  Programming  \nWhichever of these two LCSs is longer is an LCS of X and Y . Because these \ncases exhaust all possibilities, one of the optimal  subproblem solutions must appear \nwithin an LCS of X and Y . \nThe  LCS  problem  has  the  overlapping-subproblems  property.  Here\u2019s  how.  To  \n\u00fbnd  an LCS  of X and Y , you  might  need  to \u00fbnd  the  LCSs  of X and Y n\ue0021 and of \nX m\ue0021 and Y . But  each  of these  subproblems  has  the  subsubproblem  of \u00fbndi ng an \nLCS of X m\ue0021 and Y n\ue0021 . Many other subproblems share subsubproblems. \nAs  in the  matrix-chain  multiplication  problem,  solving  the  LCS  problem  recur-  \nsively involves establishing a recurrence for the v alue of an optimal  solution.  Let\u2019s  \nde\u00fbne  c\u0152i;j\ufffd  to be the length of an LCS of the sequences X i and Y j . If either i D 0 \nor j D 0, one of the sequences has length 0, and so the LCS  has length 0. The \noptimal substructure of the LCS problem gives the r ecursive formula \nc\u0152i;j\ufffd  D \u0128 \n0 if i D 0 or j D 0;  \nc\u0152i  \ue003 1;j  \ue003 1\ufffd C 1 if i;j >0  and x i D y j ; \nmax fc\u0152i;j  \ue003 1\ufffd;c\u0152i  \ue003 1;j\ufffdg if i;j >0  and x i \u00a4 y j : (14.9)  \nIn this recursive formulation, a condition in the p roblem restricts  which  sub-  \nproblems to consider. When x i D y j , you can and should consider the subproblem \nof \u00fbnding  an LCS  of X i \ue0021 and Y j \ue0021 . Otherwise,  you  instead  consider  the  two  \nsubproblems  of \u00fbnding  an LCS  of X i and Y j \ue0021 and of X i \ue0021 and Y j . In the  pre-  \nvious  dynamic-programming  algorithms  we  have  examined4fo r rod cutting and \nmatrix-chain  multiplication4we  didn\u2019t  rule  out  any  subpro blems due to conditions \nin the  problem.  Finding  an LCS  is not  the  only  dynamic-progra mming algorithm \nthat rules out subproblems based on conditions in t he problem. For example, the \nedit-distance  problem  (see  Problem  14-5)  has  this  characte ristic. \nStep  3: Computing  the  length  of an  LCS  \nBased  on  equation  (14.9),  you  could  write  an exponential-ti me recursive algorithm \nto compute the length of an LCS of two sequences. S ince the LCS problem has only \n\u201a.mn/  distinct subproblems (computing c\u0152i;j\ufffd  for 0 \u0dc4 i \u0dc4 m and 0 \u0dc4 j \u0dc4 n), \ndynamic programming can compute the solutions botto m up. \nThe  procedure  LCS-LENGTH  on the next page takes two sequences X D hx 1 ; \nx 2 ;:::;x  m i and Y D hy 1 ;y  2 ;:::;y  n i as inputs, along with their lengths. It \nstores the c\u0152i;j\ufffd  values in a table c\u01520  W m;0  W n\ufffd, and it computes the entries in row-  \nmajor  order.  That  is, the  procedure  \u00fblls  in the  \u00fbrst  row  of c from left to right, then \nthe second row, and so on. The procedure also maint ains the table b\u01521  W m;1  W n\ufffd to \nhelp in constructing an optimal solution. Intuitive ly, b\u0152i;j\ufffd  points to the table entry \ncorresponding to the optimal subproblem solution ch osen when computing c\u0152i;j\ufffd . \nThe procedure returns the b and c tables, where c\u0152m;n\ufffd  contains the length of an \nLCS of X and Y . Figure  14.8  shows  the  tables  produced  by  LCS-LENGTH  on the 14.4  Longest  common  subsequence  397 \nsequences X D hA;B;C;B;D;A;B  i and Y D hB;D;C;A;B;A i. The running \ntime of the procedure is \u201a.mn/ , since each table entry takes \u201a.1/  time to compute. \nLCS-LENGTH.X;Y;m;n/  \n1 let b\u01521  W m;1  W n\ufffd and c\u01520  W m;0  W n\ufffd be new tables \n2 for  i D 1 to m \n3 c\u0152i;0\ufffd  D 0 \n4 for  j D 0 to n \n5 c\u01520;j\ufffd  D 0 \n6 for  i D 1 to m / / compute  table  entries  in row-major  order  \n7 for  j D 1 to n \n8 if x i = = y j \n9 c\u0152i;j\ufffd  D c\u0152i  \ue003 1;j  \ue003 1\ufffd C 1 \n10  b\u0152i;j\ufffd  D <-= \n11  elseif  c\u0152i  \ue003 1;j\ufffd  \ue004 c\u0152i;j  \ue003 1\ufffd \n12  c\u0152i;j\ufffd  D c\u0152i  \ue003 1;j\ufffd  \n13  b\u0152i;j\ufffd  D <\"= \n14  else  c\u0152i;j\ufffd  D c\u0152i;j  \ue003 1\ufffd \n15  b\u0152i;j\ufffd  D <\ue009= \n16  return  c and b \nPRINT-LCS.b;X;i;j/  \n1 if i == 0 or j == 0 \n2 return  / / the LCS has length 0 \n3 if b\u0152i;j\ufffd  == <-= \n4 PRINT-LCS.b;X;i  \ue003 1;j  \ue003 1/ \n5 print x i / / same as y j \n6 elseif  b\u0152i;j\ufffd  == <\"= \n7 PRINT-LCS.b;X;i  \ue003 1;j/  \n8 else  PRINT-LCS.b;X;i;j  \ue003 1/ \nStep  4: Constructing  an  LCS  \nWith the b table  returned  by  LCS-LENGTH , you can quickly construct an LCS of \nX D hx 1 ;x 2 ;:::;x  m i and Y D hy 1 ;y  2 ;:::;y  n i. Begin at b\u0152m;n\ufffd  and trace through \nthe table by following the arrows. Each < -= encountered in an entry b\u0152i;j\ufffd  im-  \nplies that x i D y j is an element  of the  LCS  that  LCS-LENGTH  found. This \nmethod gives you the elements of this LCS in revers e order. The recursive  pro-  \ncedure P RINT-LCS  prints  out  an LCS  of X and Y in the proper, forward order. 398  Chapter  14  Dynamic  Programming  \n0 0 0 0 0 0 0 \n0 0 0 0 1 1 1 \n0 1 1 1 2 2 \n0 1 1 2 2 2 \n0 1 1 2 2 3 \n0 1 2 2 2 3 3 \n0 1 2 2 3 3 \n0 1 2 2 3 4 4 1 \n2 \n3 \n4 B D C A B A 1 2 3 4 5 6 0 \nA \nB \nC \nB \nD \nA \nB 1 \n2 \n3 \n4 \n5 \n6 \n7 0 j \ni \nx i y j \nFigure  14.8  The c and b tables  computed  by  LCS-LENGTH  on the sequences X D hA;B;C;B;  \nD;A;B i and Y D hB;D;C;A;B;A i. The square in row i and column j contains the value of c\u0152i;j\ufffd  \nand the appropriate arrow for the value of b\u0152i;j\ufffd . The entry 4 in c\u01527;6\ufffd4the  lower  right-hand  corner  \nof the  table4is  the  length  of an  LCS  hB;C;B;A i of X and Y . For i;j >0 , entry c\u0152i;j\ufffd  depends \nonly on whether x i D y j and the values in entries c\u0152i  \ue003 1;j\ufffd, c\u0152i;j  \ue003 1\ufffd, and c\u0152i  \ue003 1;j  \ue003 1\ufffd, which \nare computed before c\u0152i;j\ufffd . To reconstruct the elements of an LCS, follow the  b\u0152i;j\ufffd  arrows from \nthe  lower  right-hand  corner,  as shown  by  the  sequence  shaded  blue. Each < -= on  the  shaded-blue  \nsequence corresponds to an entry (highlighted) for which x i D y j is a member of an LCS. \nThe initial call is P RINT-LCS.b;X;m;n/ . For the b table  in Figure  14.8,  this  pro-  \ncedure prints BCBA . The procedure takes O.m  C n/ time, since it decrements at \nleast one of i and j in each recursive call. \nImproving  the  code  \nOnce  you  have  developed  an algorithm,  you  will  often  \u00fbnd  that  you can improve \non the time or space it uses. Some changes can simp lify the code and improve \nconstant factors but otherwise yield no asymptotic improvement in performance. \nOthers  can  yield  substantial  asymptotic  savings  in time  and  space. \nIn the LCS algorithm, for example, you can eliminat e the b table altogether. \nEach c\u0152i;j\ufffd  entry depends on only three other c table entries: c\u0152i  \ue003 1;j  \ue003 1\ufffd, \nc\u0152i  \ue003 1;j\ufffd, and c\u0152i;j  \ue003 1\ufffd. Given  the  value  of c\u0152i;j\ufffd , you can determine in O.1/  \ntime which of these three values was used to comput e c\u0152i;j\ufffd , without inspecting \ntable b. Thus, you can reconstruct an LCS in O.m Cn/ time  using  a procedure  sim-  \nilar to P RINT-LCS.  (Exercise  14.4-2  asks  you  to give  the  pseudocode.)  Alt  hough \nthis method saves \u201a.mn/  space, the auxiliary space requirement for computin g 14.4  Longest  common  subsequence  399 \nan LCS does not asymptotically decrease, since the c table takes \u201a.mn/  space \nanyway. \nYou can, however, reduce the asymptotic space requi rements for  LCS-LENGTH , \nsince it needs only two rows of table c at a time: the row being computed and the \nprevious  row.  (In  fact,  as Exercise  14.4-4  asks  you  to show,  you can use only \nslightly more than the space for one row of c to compute the length of an LCS.) \nThis improvement works if you need only the length of an LCS. If you need \nto reconstruct the elements of an LCS, the smaller table does not keep enough \ninformation  to retrace  the  algorithm\u2019s  steps  in O.m  C n/ time. \nExercises  \n14.4-1  \nDetermine an LCS of h1;0;0;1;0;1;0;1 i and h0;1;0;1;1;0;1;1;0 i. \n14.4-2  \nGive  pseudocode  to reconstruct  an LCS  from  the  completed  c table and the original \nsequences X D hx 1 ;x  2 ;:::;x  m i and Y D hy 1 ;y  2 ;:::;y  n i in O.m  C n/ time, \nwithout using the b table. \n14.4-3  \nGive  a memoized  version  of LCS-LENGTH  that runs in O.mn/  time. \n14.4-4  \nShow how to compute the length of an LCS using only  2 \ue001 min fm;ng entries in the \nc table plus O.1/  additional space. Then show how to do the same thin g, but using \nmin fm;ng entries plus O.1/  additional space. \n14.4-5  \nGive  an O.n  2 /-time  algorithm  to \u00fbnd  the  longest  monotonically  increasing  subse-  \nquence of a sequence of n numbers. \n? 14.4-6  \nGive  an O.n  lg n/-time  algorithm  to \u00fbnd  the  longest  monotonically  increasing  sub-  \nsequence of a sequence of n numbers. ( Hint: The  last  element  of a candidate  subse-  \nquence of length i is at least as large as the last element of a candi date subsequence \nof length i \ue003 1. Maintain candidate subsequences by linking them t hrough the input \nsequence.) 400  Chapter  14  Dynamic  Programming  \n14.5  Optimal  binary  search  trees  \nSuppose that you are designing a program to transla te text from English to Latvian. \nFor each occurrence of each English word in the tex t, you need to look up its \nLatvian equivalent. You can perform these lookup op erations by building a binary \nsearch tree with n English words as keys and their Latvian equivalents  as satellite \ndata. Because you will search the tree for each ind ividual word in the text, you want \nthe total time spent searching to be as low as poss ible. You can ensure an O.lg n/ \nsearch  time  per  occurrence  by  using  a red-black  tree  or any  other balanced binary \nsearch tree. Words appear with different frequencie s, however, and a frequently \nused word such as the can end up appearing far from the root while a rare ly used \nword such as naumachia  appears near the root. Such an organization would s low \ndown the translation, since the number of nodes vis ited when searching for a key \nin a binary search tree equals 1 plus the depth of the node containing the key. You \nwant words that occur frequently in the text to be placed nearer the root. 8 Moreover, \nsome words in the text might have no Latvian transl ation, 9 and such words would \nnot appear in the binary search tree at all. How ca n you organize a binary search \ntree so as to minimize the number of nodes visited in all searches, given that you \nknow  how  often  each  word  occurs?  \nWhat you need is an optimal  binary  search  tree. Formally, given a sequence \nK D hk 1 ;k  2 ;:::;k  n i of n distinct keys such that k 1 <k  2 < \ue001 \ue001 \ue001  <k  n , build a \nbinary search tree containing them. For each key k i , you  are  given  the  probabil-  \nity p i that any given search is for key k i . Since some searches may be for values \nnot in K, you also have n C 1 <dummy= keys d 0 ;d  1 ;d  2 ;:::;d  n representing those \nvalues. In particular, d 0 represents all values less than k 1 , d n represents  all  val-  \nues greater than k n , and for i D 1;2;:::;n  \ue003 1, the dummy key d i represents all \nvalues between k i and k i C1 . For each dummy key d i , you have the probability q i \nthat a search corresponds to d i . Figure  14.9  shows  two  binary  search  trees  for  a \nset of n D 5 keys. Each key k i is an internal node, and each dummy key d i is a \nleaf.  Since  every  search  is either  successful  (\u00fbnding  some  key k i ) or unsuccessful \n(\u00fbnding  some  dummy  key  d i ), we have \nn X  \ni D1 p i C n X  \ni D0 q i D 1:  (14.10)  \n8 If the subject of the text is ancient Rome, you mig ht want naumachia  to appear near the root. \n9 Yes, naumachia  has a Latvian counterpart: noma\u02c7  cija. 14.5  Optimal  binary  search  trees  401 \nk 2 \nk 1 k 4 \nk 3 k 5 d 0 d 1 \nd 2 d 3 d 4 d 5 k 2 \nk 1 \nk 4 \nk 3 k 5 \nd 0 d 1 \nd 2 d 3 d 4 d 5 \nnode depth probability contribution \nk 1 1 0.15  0.30  \nk 2 0 0.10  0.10  \nk 3 2 0.05  0.15  \nk 4 1 0.10  0.20  \nk 5 2 0.20  0.60  \nd 0 2 0.05  0.15  \nd 1 2 0.10  0.30  \nd 2 3 0.05  0.20  \nd 3 3 0.05  0.20  \nd 4 3 0.05  0.20  \nd 5 3 0.10  0.40  \nTotal  2.80  \n(a) node depth probability contribution \nk 1 1 0.15  0.30  \nk 2 0 0.10  0.10  \nk 3 3 0.05  0.20  \nk 4 2 0.10  0.30  \nk 5 1 0.20  0.40  \nd 0 2 0.05  0.15  \nd 1 2 0.10  0.30  \nd 2 4 0.05  0.25  \nd 3 4 0.05  0.25  \nd 4 3 0.05  0.20  \nd 5 2 0.10  0.30  \nTotal  2.75  \n(b) \nFigure  14.9  Two binary search trees for a set of n D 5 keys with the following probabilities: \ni 0 1 2 3 4 5 \np i 0.15  0.10  0.05  0.10  0.20  \nq i 0.05  0.10  0.05  0.05  0.05  0.10  \n(a)  A binary  search  tree  with  expected  search  cost  2.80.  (b)  A binary search tree with expected search \ncost  2.75.  This  tree  is optimal.  \nKnowing  the  probabilities  of searches  for  each  key  and  each  dummy key allows \nus to determine the expected cost of a search in a given binary search tree T . Let \nus assume that the actual cost of a search equals t he number of nodes examined, \nwhich is the depth of the node found by the search in T , plus  1. Then  the  expected  \ncost of a search in T is \nE \u0152search cost in T\ufffd  D n X  \ni D1 .depth T .k i / C 1/ \ue001 p i C n X  \ni D0 .depth T .d i / C 1/ \ue001 q i \nD 1 C n X  \ni D1 depth T .k i / \ue001 p i C n X  \ni D0 depth T .d i / \ue001 q i ; (14.11)  402  Chapter  14  Dynamic  Programming  \nwhere depth T denotes  a node\u2019s  depth  in the  tree  T . The last equation follows from \nequation  (14.10).  Figure  14.9  shows  how  to calculate  the  expected search cost node \nby node. \nFor a given set of probabilities, your goal is to c onstruct a binary search tree \nwhose expected search cost is smallest. We call suc h a tree an optimal  binary  \nsearch  tree. Figure  14.9(a)  shows  one  binary  search  tree,  with  expected  cost 2:80, \nfor  the  probabilities  given  in the  \u00fbgure  caption.  Part  (b)  of the  \u00fbgure  displays  an \noptimal binary search tree, with expected cost 2:75. This example demonstrates \nthat an optimal binary search tree is not necessari ly a tree whose overall height \nis smallest. Nor does an optimal binary search tree  always have the key with the \ngreatest probability at the root. Here, key k 5 has the greatest search probability of \nany key, yet the root of the optimal binary search tree shown is k 2 . (The lowest \nexpected cost of any binary search tree with k 5 at the  root  is 2.85.)  \nAs  with  matrix-chain  multiplication,  exhaustive  checking  of all possibilities fails \nto yield  an ef\u00fbcient  algorithm.  You  can  label  the  nodes  of any  n-node  binary  tree  \nwith the keys k 1 ;k  2 ;:::;k  n to construct a binary search tree, and then add in the \ndummy  keys  as leaves.  In Problem  12-4  on  page  329,  we  saw  that  the number \nof binary trees with n nodes is \ufffd.4  n =n  3=2  /. Thus you would need to examine an \nexponential number of binary search trees to perfor m an exhaustive  search.  We\u2019ll  \nsee  how  to solve  this  problem  more  ef\u00fbciently  with  dynamic  programming. \nStep  1: The  structure  of an  optimal  binary  search  tree  \nTo characterize the optimal substructure of optimal  binary search trees, we start \nwith an observation about subtrees. Consider any su btree of a binary search tree. \nIt must contain keys in a contiguous range k i ;:::;k  j , for some 1 \u0dc4 i \u0dc4 j \u0dc4 n. \nIn addition, a subtree that contains keys k i ;:::;k  j must also have as its leaves the \ndummy keys d i \ue0021 ;:::;d  j . \nNow we can state the optimal substructure: if an op timal binary search tree T \nhas a subtree T 0 containing keys k i ;:::;k  j , then this subtree T 0 must be optimal as \nwell for the subproblem with keys k i ;:::;k  j and dummy keys d i \ue0021 ;:::;d  j . The \nusual  cut-and-paste  argument  applies.  If there  were  a subtr ee T 00 whose expected \ncost is lower than that of T 0 , then cutting T 0 out of T and pasting in T 00 would \nresult in a binary search tree of lower expected co st than T , thus contradicting the \noptimality of T . \nWith the optimal substructure in hand, here is how to construct an optimal  solu-  \ntion  to the  problem  from  optimal  solutions  to subproblems.  Given keys k i ;:::;k  j , \none of these keys, say k r (i \u0dc4 r \u0dc4 j ), is the  root  of an optimal  subtree  contain-  \ning these keys. The left subtree of the root k r contains the keys k i ;:::;k  r \ue0021 (and \ndummy keys d i \ue0021 ;:::;d  r \ue0021 ), and the right subtree contains the keys k r C1 ;:::;k  j \n(and dummy keys d r ;:::;d  j ). As long as you examine all candidate roots k r , 14.5  Optimal  binary  search  trees  403 \nwhere i \u0dc4 r \u0dc4 j , and  you  determine  all  optimal  binary  search  trees  contain-  \ning k i ;:::;k  r \ue0021 and those containing k r C1 ;:::;k  j , you  are  guaranteed  to \u00fbnd  an \noptimal binary search tree. \nThere is one technical detail worth understanding a bout <empty=  subtrees.  Sup-  \npose that in a subtree with keys k i ;:::;k  j , you select k i as the root. By the above \nargument, k i \u2019s left  subtree  contains  the  keys  k i ;:::;k  i \ue0021 : no keys at all. Bear in \nmind, however, that subtrees also contain dummy key s. We adopt the convention \nthat a subtree containing keys k i ;:::;k  i \ue0021 has no actual keys but does contain the \nsingle dummy key d i \ue0021 . Symmetrically, if you select k j as the root, then k j \u2019s right  \nsubtree contains the keys k j C1 ;:::;k  j . This right subtree contains no actual keys, \nbut it does contain the dummy key d j . \nStep  2: A recursive  solution  \nTo  de\u00fbne  the  value  of an optimal  solution  recursively,  the  subproblem domain is \n\u00fbnding  an optimal  binary  search  tree  containing  the  keys  k i ;:::;k  j , where i \ue004 1, \nj \u0dc4 n, and j \ue004 i \ue003 1. (When j D i \ue003 1, there is just the dummy key d i \ue0021 , \nbut no actual keys.) Let e\u0152i;j\ufffd  denote the expected cost of searching an optimal \nbinary search tree containing the keys k i ;:::;k  j . Your goal is to compute e\u01521;n\ufffd , \nthe expected cost of searching an optimal binary se arch tree for all the actual and \ndummy keys. \nThe easy case occurs when j D i \ue003 1. Then the subproblem consists of just the \ndummy key d i \ue0021 . The expected search cost is e\u0152i;i  \ue003 1\ufffd D q i \ue0021 . \nWhen j \ue004 i , you need to select a root k r from among k i ;:::;k  j and then \nmake an optimal binary search tree with keys k i ;:::;k  r \ue0021 as its left subtree and \nan optimal binary search tree with keys k r C1 ;:::;k  j as its right subtree. What \nhappens to the expected search cost of a subtree wh en it becomes a subtree of a \nnode?  The  depth  of each  node  in the  subtree  increases  by  1. By  equation  (14.11),  \nthe expected search cost of this subtree increases by the sum of all the probabilities \nin the subtree. For a subtree with keys k i ;:::;k  j , denote this sum of probabilities \nas \nw.i;j/  D j X  \nl Di p l C j X  \nl Di \ue0021 q l : (14.12)  \nThus, if k r is the root of an optimal subtree containing keys k i ;:::;k  j , we have \ne\u0152i;j\ufffd  D p r C .e\u0152i;r  \ue003 1\ufffd C w.i;r  \ue003 1//  C .e\u0152r  C 1;j\ufffd  C w.r  C 1;j//:  \nNoting that \nw.i;j/  D w.i;r  \ue003 1/ C p r C w.r  C 1;j/;  \nwe rewrite e\u0152i;j\ufffd  as 404  Chapter  14  Dynamic  Programming  \ne\u0152i;j\ufffd  D e\u0152i;r  \ue003 1\ufffd C e\u0152r  C 1;j\ufffd  C w.i;j/:  (14.13)  \nThe  recursive  equation  (14.13)  assumes  that  you  know  which  node k r to use as \nthe  root.  Of  course,  you  choose  the  root  that  gives  the  lowest  expected search cost, \ngiving  the  \u00fbnal  recursive  formulation:  \ne\u0152i;j\ufffd  D ( \nq i \ue0021 if j D i \ue003 1;  \nmin fe\u0152i;r  \ue003 1\ufffd C e\u0152r  C 1;j\ufffd  C w.i;j/  W i \u0dc4 r \u0dc4 j g if i \u0dc4 j :  \n(14.14)  \nThe e\u0152i;j\ufffd  values give the expected search costs in optimal bi nary search trees. \nTo help keep track of the structure of optimal bina ry search trees,  de\u00fbne  root \u0152i;j\ufffd , \nfor 1 \u0dc4 i \u0dc4 j \u0dc4 n, to be the index r for which k r is the root of an optimal binary \nsearch tree containing keys k i ;:::;k  j . Although  we\u2019ll  see  how  to compute  the  \nvalues of root \u0152i;j\ufffd , the construction of an optimal binary search tree  from these \nvalues  is left  as Exercise  14.5-1.  \nStep  3: Computing  the  expected  search  cost  of an  optimal  binary  search  tree  \nAt this point, you may have noticed some similariti es between our characterizations \nof optimal  binary  search  trees  and  matrix-chain  multiplica tion. For both problem \ndomains, the subproblems consist of contiguous inde x subranges.  A direct,  recur-  \nsive  implementation  of equation  (14.14)  would  be just  as inef\u00fbcient  as a direct,  \nrecursive  matrix-chain  multiplication  algorithm.  Instea d, you can store the e\u0152i;j\ufffd  \nvalues in a table e\u01521  W n C 1;0  W n\ufffd. The  \u00fbrst  index  needs  to run  to n C 1 rather than n \nbecause in order to have a subtree containing only the dummy key d n , you need to \ncompute and store e\u0152n  C 1;n\ufffd. The second index needs to start from 0 because in \norder to have a subtree containing only the dummy k ey d 0 , you need to compute \nand store e\u01521;0\ufffd. Only  the  entries  e\u0152i;j\ufffd  for which j \ue004 i \ue003 1 are  \u00fblled  in.  The  \ntable root \u0152i;j\ufffd  records the root of the subtree containing keys k i ;:::;k  j and uses \nonly the entries for which 1 \u0dc4 i \u0dc4 j \u0dc4 n. \nOne  other  table  makes  the  dynamic-programming  algorithm  a little  faster.  In-  \nstead of computing the value of w.i;j/  from scratch every time you compute \ne\u0152i;j\ufffd , which would take \u201a.j  \ue003 i/ additions, store these values in a table \nw\u01521  W n C 1;0  W n\ufffd. For the base case, compute w\u0152i;i  \ue003 1\ufffd D q i \ue0021 for 1 \u0dc4 i \u0dc4 n C 1. \nFor j \ue004 i , compute \nw\u0152i;j\ufffd  D w\u0152i;j  \ue003 1\ufffd C p j C q j : (14.15)  \nThus, you can compute the \u201a.n  2 / values of w\u0152i;j\ufffd  in \u201a.1/  time each. \nThe  OPTIMAL-BST  procedure  on  the  next  page  takes  as inputs  the  probabili ties \np 1 ;:::;p  n and q 0 ;:::;q  n and the size n, and it returns the tables e and root . From \nthe description above and the similarity to the M ATRIX-CHAIN-ORDER procedure 14.5  Optimal  binary  search  trees  405 \nin Section  14.2,  you  should  \u00fbnd  the  operation  of this  procedure  to be fairly  straight-  \nforward. The for  loop  of lines  234  initializes  the  values  of e\u0152i;i  \ue003 1\ufffd and w\u0152i;i  \ue003 1\ufffd. \nThen the for  loop  of lines  5314  uses  the  recurrences  (14.14)  and  (14.15)  to com-  \npute e\u0152i;j\ufffd  and w\u0152i;j\ufffd  for all 1 \u0dc4 i \u0dc4 j \u0dc4 n. In the  \u00fbrst  iteration,  when  l D 1, \nthe loop computes e\u0152i;i\ufffd  and w\u0152i;i\ufffd  for i D 1;2;:::;n . The second iteration, with \nl D 2, computes e\u0152i;i  C 1\ufffd and w\u0152i;i  C 1\ufffd for i D 1;2;:::;n  \ue003 1, and so on. The \ninnermost for  loop,  in lines  10314,  tries  each  candidate  index  r to determine which \nkey k r to use as the root of an optimal binary search tree  containing keys k i ;:::;k  j . \nThis for  loop saves the current value of the index r in root \u0152i;j\ufffd  whenever  it \u00fbnds  a \nbetter key to use as the root. \nOPTIMAL-BST  .p;q;n/  \n1 let e\u01521  W n C 1;0  W n\ufffd, w\u01521  W n C 1;0  W n\ufffd, \nand root \u01521 W n;1  W n\ufffd be new tables \n2 for  i D 1 to n C 1 / / base cases \n3 e\u0152i;i  \ue003 1\ufffd D q i \ue0021 / / equation  (14.14)  \n4 w\u0152i;i  \ue003 1\ufffd D q i \ue0021 \n5 for  l D 1 to n \n6 for  i D 1 to n \ue003 l C 1 \n7 j D i C l \ue003 1 \n8 e\u0152i;j\ufffd  D 1  \n9 w\u0152i;j\ufffd  D w\u0152i;j  \ue003 1\ufffd C p j C q j / / equation  (14.15)  \n10  for  r D i to j / / try all possible roots r \n11  t D e\u0152i;r  \ue003 1\ufffd C e\u0152r  C 1;j\ufffd  C w\u0152i;j\ufffd  / / equation  (14.14)  \n12  if t <e\u0152i;j\ufffd  / / new  minimum?  \n13  e\u0152i;j\ufffd  D t \n14  root \u0152i;j\ufffd  D r \n15  return  e and root \nFigure  14.10  shows  the  tables  e\u0152i;j\ufffd , w\u0152i;j\ufffd , and root \u0152i;j\ufffd  computed by the \nprocedure  OPTIMAL-BST  on  the  key  distribution  shown  in Figure  14.9.  As  in the  \nmatrix-chain  multiplication  example  of Figure  14.5,  the  tables are rotated to make \nthe  diagonals  run  horizontally.  OPTIMAL-BST  computes  the  rows  from  bottom  to \ntop and from left to right within each row. \nThe  OPTIMAL-BST  procedure  takes  \u201a.n  3 / time, just like M ATRIX-CHAIN- \nORDER . Its running time is O.n  3 /, since its for  loops are nested three deep and \neach loop index takes on at most n values.  The  loop  indices  in OPTIMAL-BST  do  \nnot have exactly the same bounds as those in M ATRIX-CHAIN-ORDER , but they \nare  within  at most  1 in all  directions.  Thus,  like  MATRIX-CHAIN-ORDER , the \nOPTIMAL-BST  procedure  takes  \ufffd.n  3 / time. 406  Chapter  14  Dynamic  Programming  \n2.75  \n1.75  \n1.25  \n0.90 \n0.45  \n0.05  2.00 \n1.20  \n0.70  \n0.40  \n0.10  1.30  \n0.60  \n0.25  \n0.05  0.90 \n0.30  \n0.05  0.50  \n0.05  0.10  e \n0 1 2 3 4 5 \n6 5 4 3 2 1 \nj i 1.00  \n0.70  \n0.55  \n0.45  \n0.30  \n0.05  0.80  \n0.50  \n0.35  \n0.25  \n0.10  0.60  \n0.30  \n0.15  \n0.05  0.50  \n0.20 \n0.05  0.35  \n0.05  0.10  w \n0 1 2 3 4 5 \n6 5 4 3 2 1 \nj i \n2 \n2 \n2 \n1 \n1 4 \n2 \n2 \n2 5 \n4 \n3 5 \n4 5 root \n1 2 3 4 5 \n5 4 3 2 1 \nj i \nFigure  14.10  The tables e\u0152i;j\ufffd , w\u0152i;j\ufffd , and root\u0152i;j\ufffd  computed  by  OPTIMAL-BST  on  the  key  \ndistribution  shown  in Figure  14.9.  The  tables  are  rotated  so that the diagonals run horizontally. \nExercises  \n14.5-1  \nWrite pseudocode for the procedure C ONSTRUCT-OPTIMAL-BST  .root ;n/  which, \ngiven the table root \u01521 W n;1  W n\ufffd, outputs the structure of an optimal binary search  \ntree.  For  the  example  in Figure  14.10,  your  procedure  should  print out the structure \nk 2 is the root \nk 1 is the left child of k 2 \nd 0 is the left child of k 1 \nd 1 is the right child of k 1 \nk 5 is the right child of k 2 \nk 4 is the left child of k 5 \nk 3 is the left child of k 4 \nd 2 is the left child of k 3 \nd 3 is the right child of k 3 \nd 4 is the right child of k 4 \nd 5 is the right child of k 5 \ncorresponding to the optimal binary search tree sho wn in Figure  14.9(b).  Problems for Chapter 14 407 \n14.5-2  \nDetermine the cost and structure of an optimal bina ry search tree for a set of n D 7 \nkeys with the following probabilities: \ni 0 1 2 3 4 5 6 7 \np i 0.04  0.06  0.08  0.02  0.10  0.12  0.14  \nq i 0.06  0.06  0.06  0.06  0.05  0.05  0.05  0.05  \n14.5-3  \nSuppose that instead of maintaining the table w\u0152i;j\ufffd , you computed the value \nof w.i;j/  directly  from  equation  (14.12)  in line  9 of OPTIMAL-BST  and  used  this  \ncomputed  value  in line  11.  How  would  this  change  affect  the  asymptotic running \ntime  of OPTIMAL-BST?  \n? 14.5-4  \nKnuth  [264]  has  shown  that  there  are  always  roots  of optimal  subtrees such that \nroot \u0152i;j  \ue003 1\ufffd \u0dc4 root \u0152i;j\ufffd  \u0dc4 root \u0152i C 1;j\ufffd  for all 1 \u0dc4 i <j  \u0dc4 n. Use this fact to \nmodify  the  OPTIMAL-BST  procedure  to run  in \u201a.n  2 / time. \nProblems  \n14-1  Longest  simple  path  in a directed  acyclic  graph  \nYou are given a directed acyclic graph G D .V;E/  with  real-valued  edge  weights  \nand two distinguished vertices s and t . The weight  of a path is the sum of the \nweights  of the  edges  in the  path.  Describe  a dynamic-program ming approach for \n\u00fbnding  a longest  weighted  simple  path  from  s to t . What is the running time of \nyour  algorithm?  \n14-2  Longest  palindrome  subsequence  \nA palindrome  is a nonempty string over some alphabet that reads the same for- \nward and backward. Examples of palindromes are all strings of length 1, civic , \nracecar , and aibohphobia  (fear of palindromes). \nGive  an ef\u00fbcient  algorithm  to \u00fbnd  the  longest  palindrome  that is a subsequence \nof a given input string. For example, given the inp ut character , your algorithm \nshould return carac. What  is the  running  time  of your  algorithm?  \n14-3  Bitonic  euclidean  traveling-salesperson  problem  \nIn the euclidean  traveling-salesperson  problem , you are given a set of n points in \nthe  plane,  and  your  goal  is to \u00fbnd  the  shortest  closed  tour  that connects all n points. 408  Chapter  14  Dynamic  Programming  \n(a) (b) \nFigure  14.11  Seven points in the plane, shown on a unit grid. (a)  The shortest closed tour, with \nlength approximately 24:89 . This tour is not bitonic. (b)  The shortest bitonic tour for the same set of \npoints. Its length is approximately 25:58 . \nFigure  14.11(a)  shows  the  solution  to a 7-point  problem.  The  general  problem  is \nNP-hard,  and  its  solution  is therefore  believed  to require  more than polynomial \ntime  (see  Chapter  34).  \nJ. L. Bentley  has  suggested  simplifying  the  problem  by  consi dering only bitonic  \ntours , that is, tours that start at the leftmost point, go strictly rightward  to the  right-  \nmost point, and then go strictly leftward back to t he starting point.  Figure  14.11(b)  \nshows the shortest bitonic tour of the same 7 points.  In this  case,  a polynomial-time  \nalgorithm is possible. \nDescribe an O.n  2 /-time  algorithm  for  determining  an optimal  bitonic  tour.  You \nmay assume that no two points have the same x -coordinate  and  that  all  operations  \non real numbers take unit time. ( Hint: Scan  left  to right,  maintaining  optimal  pos-  \nsibilities for the two parts of the tour.) \n14-4  Printing  neatly  \nConsider the problem of neatly printing a paragraph  with a monospaced font (all \ncharacters having the same width). The input text i s a sequence of n words of \nlengths l 1 ;l 2 ;:::;l  n , measured in characters, which are to be printed n eatly on a \nnumber of lines that hold a maximum of M  characters each. No word exceeds \nthe line length, so that l i \u0dc4 M  for i D 1;2;:::;n . The criterion of <neatness= is \nas follows. If a given line contains words i through j , where i \u0dc4 j , and exactly \none space appears between words, then the number of  extra space characters at the \nend of the line is M  \ue003 j C i \ue003 P  j \nkDi l k , which must be nonnegative so that the \nwords  \u00fbt on  the  line.  The  goal  is to minimize  the  sum,  over  all  lines except the last, \nof the cubes of the numbers of extra space characte rs at the ends of lines.  Give  a \ndynamic-programming  algorithm  to print  a paragraph  of n words neatly. Analyze \nthe running time and space requirements of your alg orithm. Problems for Chapter 14 409 \n14-5  Edit  distance  \nIn order to transform a source string of text x\u01521  W m\ufffd  to a target string y\u01521  W n\ufffd, you \ncan perform various transformation operations. The goal is, given x and y , to \nproduce a series of transformations that changes x to y . An array \u00b44assumed  \nto be large  enough  to hold  all  the  characters  it needs4holds  the  intermediate  re-  \nsults. Initially, \u00b4 is empty, and at termination, you should have \u00b4\u0152j\ufffd  D y\u0152j\ufffd  for \nj D 1;2;:::;n . The procedure for solving this problem maintains current indices \ni into x and j into \u00b4, and the operations are allowed to alter \u00b4 and these indices. \nInitially, i D j D 1. Every character in x must  be examined  during  the  transfor-  \nmation, which means that at the end of the sequence  of transformation operations, \ni D m C 1. \nYou may choose from among six transformation operat ions, each of which has \na constant cost that depends on the operation: \nCopy  a character from x to \u00b4 by setting \u00b4\u0152j\ufffd  D x\u0152i\ufffd  and then incrementing both i \nand j . This operation examines x\u0152i\ufffd  and has cost Q C . \nReplace  a character from x by another character c , by setting \u00b4\u0152j\ufffd  D c , and then \nincrementing both i and j . This operation examines x\u0152i\ufffd  and has cost Q R . \nDelete  a character from x by incrementing i but leaving j alone. This operation \nexamines x\u0152i\ufffd  and has cost Q D  . \nInsert  the character c into \u00b4 by setting \u00b4\u0152j\ufffd  D c and then incrementing j , but \nleaving i alone. This operation examines no characters of x and has cost Q I . \nTwiddle  (i.e., exchange) the next two characters by copying  them from x to \u00b4 but \nin the opposite order: setting \u00b4\u0152j\ufffd  D x\u0152i  C 1\ufffd and \u00b4\u0152j  C 1\ufffd D x\u0152i\ufffd, and then \nsetting i D i C 2 and j D j C 2. This operation examines x\u0152i\ufffd  and x\u0152i  C 1\ufffd \nand has cost Q T . \nKill  the remainder of x by setting i D m C 1. This  operation  examines  all  char-  \nacters in x that have not yet been examined. This operation, if  performed, must \nbe the  \u00fbnal  operation.  It has  cost  Q K . \nFigure  14.12  gives  one  way  to transform  the  source  string  algorithm  to the \ntarget string altruistic . Several other sequences of transformation operati ons \ncan transform algorithm  to altruistic . \nAssume that Q C < Q  D  C Q I and Q R < Q  D  C Q I , since otherwise, the \ncopy and replace operations would not be used. The cost of a given sequence of \ntransformation operations is the sum of the costs o f the individual operations in \nthe sequence. For the sequence above, the cost of t ransforming algorithm  to \naltruistic  is 3Q  C C Q R C Q D  C 4Q  I C Q T C Q K . \na. Given  two  sequences  x\u01521  W m\ufffd  and y\u01521  W n\ufffd and the costs of the transformation \noperations, the edit  distance  from x to y is the  cost  of the  least  expensive  op-  410  Chapter  14  Dynamic  Programming  \nOperation  x \u00b4 \ninitial strings a lgorithm  \ncopy al  gorithm  a \ncopy alg  orithm  al  \nreplace by t algo  rithm  alt  \ndelete algor  ithm  alt  \ncopy algori  thm  altr  \ninsert u algori  thm  altru  \ninsert i algori  thm  altrui  \ninsert s algori  thm  altruis  \ntwiddle algorith  m altruisti  \ninsert c algorith  m altruistic  \nkill algorithm  altruistic  \nFigure  14.12  A sequence of operations that transforms the source  algorithm  to the target string \naltruistic . The underlined characters are x\u0152i\ufffd  and \u00b4\u0152j\ufffd  after the operation. \neration sequence that transforms x to y . Describe  a dynamic-programming  \nalgorithm  that  \u00fbnds  the  edit  distance  from  x\u01521  W m\ufffd  to y\u01521  W n\ufffd and  prints  an op-  \ntimal operation sequence. Analyze the running time and space requirements of \nyour algorithm. \nThe  edit-distance  problem  generalizes  the  problem  of align ing two DNA sequences \n(see,  for  example,  Setubal  and  Meidanis  [405,  Section  3.2]) . There are several \nmethods for measuring the similarity of two DNA seq uences by aligning them. \nOne  such  method  to align  two  sequences  x and y consists of inserting spaces at \narbitrary locations in the two sequences (including  at either end)  so that  the  result-  \ning sequences x 0 and y 0 have the same length but do not have a space in the  same \nposition (i.e., for no position j are both x 0 \u0152j\ufffd  and y 0 \u0152j\ufffd  a space). Then we assign a \n<score= to each position. Position j receives a score as follows: \n\ue001 C1 if x 0 \u0152j\ufffd  D y 0 \u0152j\ufffd  and neither is a space, \n\ue001 \ue0031 if x 0 \u0152j\ufffd  \u00a4 y 0 \u0152j\ufffd  and neither is a space, \n\ue001 \ue0032 if either x 0 \u0152j\ufffd  or y 0 \u0152j\ufffd  is a space. \nThe score for the alignment is the sum of the score s of the individual positions. For \nexample, given the sequences x D GATCGGCAT  and y D CAATGTGAATC , one \nalignment is \nG ATCG  GCAT  \nCAAT  GTGAATC  \n- * ++  * + * +-++  * Problems for Chapter 14 411 \nA + under a position indicates a score of C1 for that position, a - indicates a score \nof \ue0031, and a * indicates a score of \ue0032, so that this alignment has a total score of \n6 \ue001 1 \ue003 2 \ue001 1 \ue003 4 \ue001 2 D \ue0034. \nb. Explain  how  to cast  the  problem  of \u00fbnding  an optimal  alignment  as an edit-  \ndistance problem using a subset of the transformati on operations copy, replace, \ndelete, insert, twiddle, and kill. \n14-6  Planning  a company  party  \nProfessor Blutarsky is consulting for the president  of a corporation that is planning \na company party. The company has a hierarchical str ucture, that is, the supervisor \nrelation forms a tree rooted at the president. The human resources department has \nranked each employee with a conviviality rating, wh ich is a real number. In order to \nmake the party fun for all attendees, the president  does not want both an employee \nand his or her immediate supervisor to attend. \nProfessor Blutarsky is given the tree that describe s the structure  of the  corpo-  \nration,  using  the  left-child,  right-sibling  representation  described  in Section  10.3.  \nEach node of the tree holds, in addition to the poi nters, the name of an employee \nand  that  employee\u2019s  conviviality  ranking.  Describe  an algorithm to make up a guest \nlist that maximizes the sum of the conviviality rat ings of the guests. Analyze the \nrunning time of your algorithm. \n14-7  Viterbi  algorithm  \nDynamic programming on a directed graph can play a part in speech  recogni-  \ntion. A directed graph G D .V;E/  with labeled edges forms a formal model \nof a person speaking a restricted language. Each ed ge .u;v/  2 E is labeled with \na sound \ufffd .u; v/  from  a \u00fbnite  set  \u2020 of sounds. Each directed path in the graph \nstarting from a distinguished vertex v 0 2 V corresponds to a possible sequence of \nsounds produced by the model, with the label of a p ath being the concatenation of \nthe labels of the edges on that path. \na. Describe  an ef\u00fbcient  algorithm  that,  given  an edge-labeled  directed graph G \nwith distinguished vertex v 0 and a sequence s D h \ufffd 1 ; \ufffd  2 ; : : : ; \ufffd  k i of sounds \nfrom \u2020, returns a path in G that begins at v 0 and has s as its label, if any such \npath  exists.  Otherwise,  the  algorithm  should  return  NO- SUCH- PATH . Analyze \nthe running time of your algorithm. ( Hint: You  may  \u00fbnd  concepts  from  Chap-  \nter 20 useful.) \nNow suppose that every edge .u;v/  2 E has  an associated  nonnegative  probabil-  \nity p.u;v/  of being traversed, so that the corresponding sound  is produced. The \nsum of the probabilities of the edges leaving any v ertex equals 1. The probability \nof a path  is de\u00fbned  to be the  product  of the  probabilities  of its edges. Think of 412  Chapter  14  Dynamic  Programming  \nthe probability of a path beginning at vertex v 0 as the probability that a <random \nwalk= beginning at v 0 follows  the  speci\u00fbed  path,  where  the  edge  leaving  a vertex  u \nis taken randomly, according to the probabilities o f the available edges leaving u. \nb. Extend your answer to part (a) so that if a path is  returned, it is a most probable \npath starting at vertex v 0 and having label s . Analyze the running time of your \nalgorithm. \n14-8  Image  compression  by seam  carving  \nSuppose that you are given a color picture consisti ng of an m\ue005n array A\u01521  W m;1  W n\ufffd \nof pixels,  where  each  pixel  speci\u00fbes  a triple  of red,  green,  and  blue  (RGB)  intensi-  \nties. You want to compress this picture slightly, b y removing one pixel from each \nof the m rows, so that the whole picture becomes one pixel n arrower. To avoid \nincongruous visual effects, however, the pixels rem oved in two adjacent rows must \nlie in either the same column or adjacent columns. In this way, the pixels removed \nform a <seam= from the top row to the bottom row, w here successive pixels in the \nseam are adjacent vertically or diagonally. \na. Show that the number of such possible seams grows a t least exponentially in m, \nassuming that n>1 . \nb. Suppose now that along with each pixel A\u0152i;j\ufffd, you  are  given  a real-valued  \ndisruption measure d\u0152i;j\ufffd , indicating how disruptive it would be to remove \npixel A\u0152i;j\ufffd. Intuitively,  the  lower  a pixel\u2019s  disruption  measure,  the  more  sim-  \nilar  the  pixel  is to its  neighbors.  De\u00fbne  the  disruption  meas ure of a seam as the \nsum of the disruption measures of its pixels. \nGive  an algorithm  to \u00fbnd  a seam  with  the  lowest  disruption  measure. How \nef\u00fbcient  is your  algorithm?  \n14-9  Breaking  a string  \nA certain  string-processing  programming  language  allows  you to break a string \ninto two pieces. Because this operation copies the string, it costs n time units to \nbreak a string of n characters into two pieces. Suppose that you want t o break a \nstring into many pieces. The order in which the bre aks occur can affect the total \namount of time used. For example, suppose that you want to break a 20-character  \nstring after characters 2, 8, and 10  (numbering the characters in ascending order \nfrom  the  left-hand  end,  starting  from  1). If you program the breaks to occur in \nleft-to-right  order,  then  the  \u00fbrst  break  costs  20  time units, the second break costs \n18  time units (breaking the string from characters 3 to 20  at character 8), and the \nthird break costs 12  time units, totaling 50  time units. If you program the breaks \nto occur  in right-to-left  order,  however,  then  the  \u00fbrst  break costs 20  time units, the Problems for Chapter 14 413 \nsecond break costs 10  time units, and the third break costs 8 time units, totaling 38  \ntime  units.  In yet  another  order,  you  could  break  \u00fbrst  at 8 (costing 20), then break \nthe left piece at 2 (costing another 8), and  \u00fbnally  the  right  piece  at 10  (costing 12), \nfor a total cost of 40. \nDesign an algorithm that, given the numbers of char acters after which to break, \ndetermines  a least-cost  way  to sequence  those  breaks.  More  formally, given an \narray L\u01521  W m\ufffd  containing the break points for a string of n characters, compute the \nlowest cost for a sequence of breaks, along with a sequence of breaks that achieves \nthis cost. \n14-10  Planning  an  investment  strategy  \nYour knowledge of algorithms helps you obtain an ex citing job with a hot startup, \nalong  with  a $10,000  signing  bonus.  You  decide  to invest  this  money with the \ngoal of maximizing your return at the end of 10  years. You decide to use your \ninvestment  manager,  G.  I. Luvcache,  to manage  your  signing  bonus. The company \nthat Luvcache works with requires you to observe th e following rules. It offers n \ndifferent investments, numbered 1 through n. In each year j , investment i provides \na return rate of r ij . In other words, if you invest d dollars in investment i in year j , \nthen at the end of year j , you have dr  ij dollars. The return rates are guaranteed, \nthat is, you are given all the return rates for the  next 10  years for each investment. \nYou make investment decisions only once per year. A t the end of each year, you can \nleave the money made in the previous year in the sa me investments, or you can shift \nmoney to other investments, by either shifting mone y between existing investments \nor moving money to a new investment. If you do not move your money between \ntwo consecutive years, you pay a fee of f 1 dollars, whereas if you switch your \nmoney, you pay a fee of f 2 dollars, where f 2 >f  1 . You pay the fee once per year \nat the end of the year, and it is the same amount, f 2 , whether you move money in \nand out of only one investment, or in and out of ma ny investments. \na. The problem, as stated, allows you to invest your m oney in multiple investments \nin each year. Prove that there exists an optimal in vestment strategy that, in \neach year, puts all the money into a single investm ent. (Recall that an optimal \ninvestment strategy maximizes the amount of money a fter 10  years and is not \nconcerned with any other objectives, such as minimi zing risk.) \nb. Prove that the problem of planning your optimal inv estment strategy exhibits \noptimal substructure. \nc. Design an algorithm that plans your optimal investm ent strategy. What is the \nrunning  time  of your  algorithm?  414  Chapter  14  Dynamic  Programming  \nd. Suppose  that  Luvcache\u2019s  company  imposes  the  additional  restriction that, at \nany  point,  you  can  have  no  more  than  $15,000  in any  one  investm ent. Show \nthat the problem of maximizing your income at the e nd of 10  years no longer \nexhibits optimal substructure. \n14-11  Inventory  planning  \nThe Rinky Dink Company makes machines that resurfac e ice rinks. The demand \nfor such products varies from month to month, and s o the compa ny  needs  to de-  \nvelop  a strategy  to plan  its  manufacturing  given  the  \u00fcuctuat ing, but predictable, \ndemand. The company wishes to design a plan for the  next n months. For each \nmonth i , the company knows the demand d i , that is, the number of machines that it \nwill sell. Let D D P  n \ni D1 d i be the total demand over the next n months.  The  com-  \npany  keeps  a full-time  staff  who  provide  labor  to manufactur e up to m machines \nper month. If the company needs to make more than m machines in a given month, \nit can  hire  additional,  part-time  labor,  at a cost  that  works  out to c dollars  per  ma-  \nchine. Furthermore, if the company is holding any u nsold machines at the end of a \nmonth, it must pay inventory costs. The company can  hold up to D machines, with \nthe cost for holding j machines given as a function h.j/  for j D 1;2;:::;D  that \nmonotonically increases with j . \nGive  an algorithm  that  calculates  a plan  for  the  company  that  minimizes its costs \nwhile  ful\u00fblling  all  the  demand.  The  running  time  should  be polynomial in n and D. \n14-12  Signing  free-agent  baseball  players  \nSuppose  that  you  are  the  general  manager  for  a major-league  baseball team. During \nthe  off-season,  you  need  to sign  some  free-agent  players  for  your team. The team \nowner has given you a budget of $ X to spend on free agents. You are allowed to \nspend less than $ X , but  the  owner  will  \u00fbre  you  if you  spend  any  more  than  $X . \nYou are considering N different positions, and for each position, P free-agent  \nplayers who play that position are available. 10  Because you do not want to overload \nyour roster with too many players at any position, for each position you may sign \nat most one free agent who plays that position. (If  you do not sign any players at a \nparticular position, then you plan to stick with th e players you already have at that \nposition.) \n10  Although there are nine positions on a baseball tea m, N is not necessarily equal to 9 because some \ngeneral managers have particular ways of thinking a bout positions. For example, a general manager \nmight  consider  right-handed  pitchers  and  left-handed  pitchers to be separate <positions,= as well as \nstarting pitchers, long relief pitchers (relief pit chers who can pitch several innings), and short rel ief \npitchers (relief pitchers who normally pitch at mos t only one inning). Notes for Chapter 14 415 \nTo determine how valuable a player is going to be, you decide t o use  a saber-  \nmetric statistic 11  known as <WAR,= or <wins above replacement.= A playe r with a \nhigher WAR is more valuable than a player with a lo wer WAR. It is not necessarily \nmore expensive to sign a player with a higher WAR t han a player with a lower \nWAR,  because  factors  other  than  a player\u2019s  value  determine  how much it costs to \nsign them. \nFor  each  available  free-agent  player  p, you have three pieces of information: \n\ue001 the  player\u2019s  position,  \n\ue001 p: cost  , the amount of money it costs to sign the player, and \n\ue001 p: war, the  player\u2019s  WAR.  \nDevise an algorithm that maximizes the total WAR of  the players you sign while \nspending no more than $ X . You may assume that each player signs for a multi ple \nof $100,000.  Your  algorithm  should  output  the  total  WARof  the players you sign, \nthe total amount of money you spend, and a list of which players you sign. Analyze \nthe running time and space requirement of your algo rithm. \nChapter  notes  \nBellman  [44]  began  the  systematic  study  of dynamic  programming  in 1955,  pub-  \nlishing  a book  about  it in 1957.  The  word  <programming,=  both  here and in linear \nprogramming, refers to using a tabular solution met hod. Although optimization \ntechniques incorporating elements of dynamic progra mming were known earlier, \nBellman provided the area with a solid mathematical  basis. \nGalil  and  Park  [172]  classify  dynamic-programming  algorit hms according to the \nsize of the table and the number of other table ent ries each entry depends on. They \ncall  a dynamic-programming  algorithm  tD=eD  if its table size is O.n  t / and each \nentry depends on O.n  e / other  entries.  For  example,  the  matrix-chain  multiplica-  \ntion  algorithm  in Section  14.2  is 2D=1D, and  the  longest-common-subsequence  \nalgorithm  in Section  14.4  is 2D=0D . \nThe M ATRIX-CHAIN-ORDER algorithm  on  page  378  is by  Muraoka  and  Kuck  \n[339].  Hu  and  Shing  [230,  231]  give  an O.n  lg n/-time  algorithm  for  the  matrix-  \nchain multiplication problem. \nThe O.mn/-time  algorithm  for  the  longest-common-subsequence  problem  ap-  \npears  to be a folk  algorithm.  Knuth  [95]  posed  the  question  of whether subquadratic \n11  Sabermetrics  is the application of statistical analysis to baseb all records. It provides several ways \nto compare the relative values of individual player s. 416  Chapter  14  Dynamic  Programming  \nalgorithms  for  the  LCS  problem  exist.  Masek  and  Paterson  [316]  answered  this  \nquestion  in the  af\u00fbrmative  by  giving  an algorithm  that  runs  in O.mn=  lg n/ time, \nwhere n \u0dc4 m and the sequences are drawn from a set of bounded s ize. For the \nspecial case in which no element appears more than once in an input sequence, \nSzymanski  [425]  shows  how  to solve  the  problem  in O..n  C m/  lg.n C m//  time. \nMany of these results extend to the problem of comp uting string edit distances \n(Problem  14-5).  \nAn  early  paper  on  variable-length  binary  encodings  by  Gilbert  and  Moore  [181],  \nwhich had applications to constructing optimal bina ry search trees for the case in \nwhich all probabilities p i are 0, contains an O.n  3 /-time  algorithm.  Aho,  Hopcroft,  \nand  Ullman  [5]  present  the  algorithm  from  Section  14.5.  Splay  trees  [418],  which  \nmodify the tree in response to the search queries, come within a constant factor of \nthe optimal bounds without being initialized with t he frequencies.  Exercise  14.5-4  \nis due  to Knuth  [264].  Hu  and  Tucker  [232]  devised  an algorith m for the case \nin which all probabilities p i are 0 that uses O.n  2 / time and O.n/  space.  Subse-  \nquently,  Knuth  [261]  reduced  the  time  to O.n  lg n/. \nProblem  14-8  is due  to Avidan  and  Shamir  [30],  who  have  posted  on the web a \nwonderful  video  illustrating  this  image-compression  technique. 15  Greedy  Algorithms  \nAlgorithms for optimization problems typically go t hrough a sequence of steps, \nwith a set of choices at each step. For many optimi zation problems,  using  dy-  \nnamic programming to determine the best choices is overkill, and simpler, more \nef\u00fbcient  algorithms  will  do.  A greedy  algorithm  always makes the choice that \nlooks best at the moment. That is, it makes a local ly optimal choice in the hope \nthat this choice leads to a globally optimal soluti on. This chapter  explores  opti-  \nmization problems for which greedy algorithms provi de optimal solutions. Before \nreading this chapter, you should read about dynamic  programming  in Chapter  14,  \nparticularly  Section  14.3.  \nGreedy  algorithms  do  not  always  yield  optimal  solutions,  but  for  many  prob-  \nlems  they  do.  We  \u00fbrst  examine,  in Section  15.1,  a simple  but  nontrivial problem, \nthe  activity-selection  problem,  for  which  a greedy  algorithm  ef\u00fbciently  computes  \nan optimal  solution.  We\u2019ll  arrive  at the  greedy  algorithm  by  \u00fbrst  considering  a \ndynamic-programming  approach  and  then  showing  that  an optimal  solution  can  re-  \nsult  from  always  making  greedy  choices.  Section  15.2  review s the basic elements \nof the greedy approach, giving a direct approach fo r proving greedy  algorithms  cor-  \nrect.  Section  15.3  presents  an important  application  of greedy  techniques:  design-  \ning  data-compression  (Huffman)  codes.  Finally,  Section  15.4  shows  that  in order  \nto decide which blocks to replace when a miss occur s in a cache, the  <furthest-in-  \nfuture= strategy is optimal if the sequence of bloc k accesses is known in advance. \nThe greedy method is quite powerful and works well for a wide range  of prob-  \nlems. Later chapters will present many algorithms t hat you can view as applications \nof the  greedy  method,  including  minimum-spanning-tree  algorithms  (Chapter  21),  \nDijkstra\u2019s  algorithm  for  shortest  paths  from  a single  source  (Section  22.3),  and  a \ngreedy  set-covering  heuristic  (Section  35.3).  Minimum-spanning-tree  algorithms  \nfurnish a classic example of the greedy method. Alt hough you can read this chapter \nand  Chapter  21  independently  of each  other,  you  might  \u00fbnd  it useful to read them \ntogether. 418  Chapter  15  Greedy  Algorithms  \n15.1  An  activity-selection  problem  \nOur  \u00fbrst  example  is the  problem  of scheduling  several  competing  activities  that  re-  \nquire exclusive use of a common resource, with a go al of selecting  a maximum-size  \nset of mutually compatible activities. Imagine that  you are in charge of scheduling \na conference room. You are presented with a set S D fa 1 ;a  2 ;:::;a  n g of n pro-  \nposed activities  that wish to reserve the conference room, and the r oom can serve \nonly one activity at a time. Each activity a i has a start  time  s i and a \u00fbnish  time  f i , \nwhere 0 \u0dc4 s i <f  i < 1. If selected, activity a i takes  place  during  the  half-open  \ntime interval \u0152s i ;f  i /. Activities a i and a j are compatible  if the intervals \u0152s i ;f  i / \nand \u0152s j ;f  j / do not overlap. That is, a i and a j are compatible if s i \ue004 f j or s j \ue004 f i . \n(Assume that if your staff needs time to change ove r the room from one activity to \nthe next, the changeover time is built into the int ervals.) In the activity-selection  \nproblem, your  goal  is to select  a maximum-size  subset  of mutually  compatible  ac-  \ntivities. Assume that the activities are sorted in monotonically increasing order of \n\u00fbnish  time:  \nf 1 \u0dc4 f 2 \u0dc4 f 3 \u0dc4 \ue001 \ue001 \ue001 \u0dc4  f n\ue0021 \u0dc4 f n : (15.1)  \n(We\u2019ll  see  later  the  advantage  that  this  assumption  provides.)  For  example,  con-  \nsider  the  set  of activities  in Figure  15.1.  The  subset  fa 3 ;a  9 ;a  11  g consists  of mutu-  \nally compatible activities. It is not a maximum sub set, however, since the subset \nfa 1 ;a  4 ;a  8 ;a  11  g is larger. In fact, fa 1 ;a  4 ;a  8 ;a  11  g is a largest subset of mutually \ncompatible activities, and another largest subset i s fa 2 ;a  4 ;a  9 ;a  11  g. \nWe\u2019ll  see  how  to solve  this  problem,  proceeding  in several  steps.  First  we\u2019ll  \nexplore  a dynamic-programming  solution,  in which  you  consi der several choices \nwhen determining which subproblems to use in an opt imal solution.  We\u2019ll  then  \nobserve  that  you  need  to consider  only  one  choice4the  greedy  choice4and  that  \nwhen you make the greedy choice, only one subproble m remains. Based on these \nobservations,  we\u2019ll  develop  a recursive  greedy  algorithm  to solve  the  activity-  \nselection  problem.  Finally,  we\u2019ll  complete  the  process  of developing a greedy \nsolution by converting the recursive algorithm to a n iterative one. Although the \nsteps we go through in this section are slightly mo re involved than is typical when \ndeveloping a greedy algorithm, they illustrate the relationship  between  greedy  al-  \ngorithms and dynamic programming. \ni 1 2 3 4 5 6 7 8 9 10  11  \ns i 1 3 0 5 3 5 6 7 8 2 12  \nf i 4 5 6 7 9 9 10  11  12  14  16  \nFigure  15.1  A set fa 1 ;a  2 ;:::;a  11  g of activities. Activity a i has start time s i and  \u00fbnish  time  f i . 15.1  An  activity-selection  problem  419 \nThe  optimal  substructure  of the  activity-selection  problem  \nLet\u2019s  verify  that  the  activity-selection  problem  exhibits  optimal  substructure.  De-  \nnote by S ij the set of activities that start after activity a i \u00fbnishes  and  that  \u00fbnish  \nbefore activity a j starts.  Suppose  that  you  want  to \u00fbnd  a maximum  set  of mutually  \ncompatible activities in S ij , and suppose further that such a maximum set is A ij , \nwhich includes some activity a k . By including a k in an optimal solution, you are \nleft  with  two  subproblems:  \u00fbnding  mutually  compatible  activities in the set S ik  \n(activities that start after activity a i \u00fbnishes  and  that  \u00fbnish  before  activity  a k starts) \nand  \u00fbnding  mutually  compatible  activities  in the  set  S kj  (activities that start after \nactivity a k \u00fbnishes  and  that  \u00fbnish  before  activity  a j starts). Let A ik  D A ij \\ S ik  \nand A kj  D A ij \\ S kj  , so that A ik  contains the activities in A ij that  \u00fbnish  before  a k \nstarts and A kj  contains the activities in A ij that start after a k \u00fbnishes.  Thus,  we  \nhave A ij D A ik  [ fa k g [  A kj  , and  so the  maximum-size  set  A ij of mutually  com-  \npatible activities in S ij consists of jA ij j D jA ik  j C jA kj  j C  1 activities. \nThe  usual  cut-and-paste  argument  shows  that  an optimal  solution A ij must also \ninclude optimal solutions to the two subproblems fo r S ik  and S kj  . If you could \n\u00fbnd  a set  A 0 \nkj  of mutually compatible activities in S kj  where jA 0 \nkj  j > jA kj  j, then \nyou could use A 0 \nkj  , rather than A kj  , in a solution to the subproblem for S ij . You \nwould have constructed a set of jA ik  j C jA 0 \nkj  j C  1>  jA ik  j C jA kj  j C  1 D jA ij j \nmutually compatible activities, which contradicts t he assumption that A ij is an \noptimal solution. A symmetric argument applies to t he activities in S ik  . \nThis way of characterizing optimal substructure sug gests that you can solve the \nactivity-selection  problem  by  dynamic  programming.  Let\u2019s  denote the size of an \noptimal solution for the set S ij by c\u0152i;j\ufffd. Then,  the  dynamic-programming  ap-  \nproach gives the recurrence \nc\u0152i;j\ufffd  D c\u0152i;k\ufffd  C c\u0152k;j\ufffd  C 1:  \nOf  course,  if you  do  not  know  that  an optimal  solution  for  the  set S ij includes \nactivity a k , you must examine all activities in S ij to \u00fbnd  which  one  to choose,  so \nthat \nc\u0152i;j\ufffd  D ( \n0 if S ij D ;  ; \nmax fc\u0152i;k\ufffd  C c\u0152k;j\ufffd  C 1 W a k 2 S ij g if S ij \u00a4 ;  : (15.2)  \nYou can then develop a recursive algorithm and memo ize it, or you can work \nbottom-up  and  \u00fbll  in table  entries  as you  go  along.  But  you  would be overlooking \nanother  important  characteristic  of the  activity-selecti on problem that you can use \nto great advantage. 420  Chapter  15  Greedy  Algorithms  \nMaking  the  greedy  choice  \nWhat if you could choose an activity to add to an o ptimal solution without having \nto \u00fbrst  solve  all  the  subproblems?  That  could  save  you  from  having to consider all \nthe  choices  inherent  in recurrence  (15.2).  In fact,  for  the  activity-selection  problem,  \nyou need to consider only one choice: the greedy ch oice. \nWhat  is the  greedy  choice  for  the  activity-selection  problem?  Intuition  suggests  \nthat you should choose an activity that leaves the resource available for as many \nother  activities  as possible.  Of  the  activities  you  end  up  choosing, one of them \nmust  be the  \u00fbrst  one  to \u00fbnish.  Intuition  says,  therefore,  choose the activity in S \nwith  the  earliest  \u00fbnish  time,  since  that  leaves  the  resource  available for as many \nof the activities that follow it as possible. (If m ore than one activity in S has \nthe  earliest  \u00fbnish  time,  then  choose  any  such  activity.)  In other words, since the \nactivities are sorted in monotonically increasing o rder by \u00fbnish  time,  the  greedy  \nchoice is activity a 1 . Choosing  the  \u00fbrst  activity  to \u00fbnish  is not  the  only  way  to \nthink  of making  a greedy  choice  for  this  problem.  Exercise  15.1-3  asks  you  to \nexplore other possibilities. \nOnce  you  make  the  greedy  choice,  you  have  only  one  remaining  subproblem to \nsolve:  \u00fbnding  activities  that  start  after  a 1 \u00fbnishes.  Why  don\u2019t  you  have  to consider  \nactivities  that  \u00fbnish  before  a 1 starts?  Because  s 1 < f  1 , and because f 1 is the \nearliest  \u00fbnish  time  of any  activity,  no  activity  can  have  a \u00fbnish time less than or \nequal to s 1 . Thus, all activities that are compatible with act ivity a 1 must start \nafter a 1 \u00fbnishes.  \nFurthermore, we have already established that the a ctivity-selection  problem  ex-  \nhibits optimal substructure. Let S k D fa i 2 S W s i \ue004 f k g be the set of activities that \nstart after activity a k \u00fbnishes.  If you  make  the  greedy  choice  of activity  a 1 , then \nS 1 remains as the only subproblem to solve. 1 Optimal  substructure  says  that  if a 1 \nbelongs to an optimal solution, then an optimal sol ution to the original problem \nconsists of activity a 1 and  all  the  activities  in an optimal  solution  to the  subprob-  \nlem S 1 . \nOne  big  question  remains:  Is this  intuition  correct?  Is the  greedy  choice4in  \nwhich  you  choose  the  \u00fbrst  activity  to \u00fbnish4always  part  of some  optimal  solution?  \nThe following theorem shows that it is. \n1 We sometimes refer to the sets S k as subproblems rather than as just sets of activiti es. The context \nwill make it clear whether we are referring to S k as a set of activities or as a subproblem whose inp ut \nis that set. 15.1  An  activity-selection  problem  421 \nTheorem  15.1  \nConsider any nonempty subproblem S k , and let a m be an activity in S k with the \nearliest  \u00fbnish  time.  Then  a m is included  in some  maximum-size  subset  of mutually  \ncompatible activities of S k . \nProof  Let A k be a maximum-size  subset  of mutually  compatible  activities  in S k , \nand let a j be the activity in A k with  the  earliest  \u00fbnish  time.  If a j D a m , we are \ndone, since we have shown that a m belongs  to some  maximum-size  subset  of mutu-  \nally compatible activities of S k . If a j \u00a4 a m , let the set A 0 \nk D .A  k \ue003 fa j g/ [ fa m g \nbe A k but substituting a m for a j . The activities in A 0 \nk are  compatible,  which  fol-  \nlows because the activities in A k are compatible, a j is the  \u00fbrst  activity  in A k to \n\u00fbnish,  and  f m \u0dc4 f j . Since jA 0 \nk j D jA k j, we conclude that A 0 \nk is a maximum-size  \nsubset of mutually compatible activities of S k , and it includes a m . \nAlthough  you  might  be able  to solve  the  activity-selection  problem with dynamic \nprogramming,  Theorem  15.1  says  that  you  don\u2019t  need  to.  Instead,  you  can  repeat-  \nedly  choose  the  activity  that  \u00fbnishes  \u00fbrst,  keep  only  the  activities compatible with \nthis activity, and repeat until no activities remai n. Moreover, because you always \nchoose  the  activity  with  the  earliest  \u00fbnish  time,  the  \u00fbnish  times of the activities that \nyou choose must strictly increase. You can consider  each activity just once overall, \nin monotonically  increasing  order  of \u00fbnish  times.  \nAn  algorithm  to solve  the  activity-selection  problem  does  not need to work \nbottom-up,  like  a table-based  dynamic-programming  algori thm. Instead, it can \nwork  top-down,  choosing  an activity  to put  into  the  optimal  solution  that  it con-  \nstructs and then solving the subproblem of choosing  activities from those that are \ncompatible  with  those  already  chosen.  Greedy  algorithms  typically  have  this  top-  \ndown design: make a choice and then solve a subprob lem, rather than  the  bottom-  \nup technique of solving subproblems before making a  choice. \nA recursive  greedy  algorithm  \nNow  that  you  know  you  can  bypass  the  dynamic-programming  approach  and  in-  \nstead  use  a top-down,  greedy  algorithm,  let\u2019s  see  a straight forward, recursive \nprocedure  to solve  the  activity-selection  problem.  The  procedure R ECURSIVE- \nACTIVITY-SELECTOR  on  the  following  page  takes  the  start  and  \u00fbnish  times  of the  \nactivities, represented as arrays s and f , 2 the index k that  de\u00fbnes  the  subprob-  \nlem S k it is to solve, and the size n of the  original  problem.  It returns  a maximum-  \n2 Because the pseudocode takes s and f as arrays, it indexes into them with square bracket s rather \nthan with subscripts. 422  Chapter  15  Greedy  Algorithms  \nsize set of mutually compatible activities in S k . The procedure assumes that the \nn input activities are already ordered by monotonical ly increasing  \u00fbnish  time,  ac-  \ncording  to equation  (15.1).  If not,  you  can  \u00fbrst  sort  them  into this order in O.n  lg n/ \ntime,  breaking  ties  arbitrarily.  In order  to start,  add  the  \u00fbctitious activity a 0 with \nf 0 D 0, so that subproblem S 0 is the entire set of activities S . The initial call, \nwhich solves the entire problem, is R ECURSIVE-ACTIVITY-SELECTOR  .s;f;0;n/ . \nRECURSIVE-ACTIVITY-SELECTOR  .s;f;k;n/  \n1 m D k C 1 \n2 while  m \u0dc4 n and s\u0152m\ufffd<f\u0152k\ufffd  / / \u00fbnd  the  \u00fbrst  activity  in S k to \u00fbnish  \n3 m D m C 1 \n4 if m \u0dc4 n \n5 return  fa m g [  RECURSIVE-ACTIVITY-SELECTOR  .s;f;m;n/  \n6 else  return  ; \nFigure  15.2  shows  how  the  algorithm  operates  on  the  activities  in Figure  15.1.  \nIn a given recursive call R ECURSIVE-ACTIVITY-SELECTOR  .s;f;k;n/ , the while  \nloop  of lines  233  looks  for  the  \u00fbrst  activity  in S k to \u00fbnish.  The  loop  examines  \na kC1 ;a  kC2 ;:::;a  n , until  it \u00fbnds  the  \u00fbrst  activity  a m that is compatible with a k , \nwhich means that s m \ue004 f k . If the  loop  terminates  because  it \u00fbnds  such  an activity,  \nline  5 returns  the  union  of fa m g and  the  maximum-size  subset  of S m returned by the \nrecursive call R ECURSIVE-ACTIVITY-SELECTOR  .s;f;m;n/ . Alternatively, the \nloop may terminate because m > n , in which case the procedure has examined \nall activities in S k without  \u00fbnding  one  that  is compatible  with  a k . In this case, \nS k D ;, and  so line  6 returns  ;. \nAssuming  that  the  activities  have  already  been  sorted  by  \u00fbnish  times,  the  run-  \nning time of the call R ECURSIVE-ACTIVITY-SELECTOR  .s;f;0;n/  is \u201a.n/ . To \nsee why, observe that over all recursive calls, eac h activity is examined exactly \nonce in the while  loop test of line 2. In particular, activity a i is examined in the \nlast call made in which k<i  . \nAn  iterative  greedy  algorithm  \nThe recursive procedure can be converted to an iter ative one because the procedure \nRECURSIVE-ACTIVITY-SELECTOR  is almost  <tail  recursive=  (see  Problem  7-5):  \nit ends with a recursive call to itself followed by  a union operation. It is usually \na straightforward  task  to transform  a tail-recursive  proce dure to an iterative form. \nIn fact, some compilers for certain programming lan guages perform  this  task  auto-  \nmatically. 15.1  An  activity-selection  problem  423 \n0 1 2 3 4 5 6 7 8 9 10  11  12  13  14  time 2 3 5 \n3 0 6 \n4 5 7 \n5 3 9 \n6 5 9 \n7 6 10  \n8 7 11  \n9 8 12  \n10  2 14  \n11  12  16  1 1 4 i s i f i \na 1 a 2 \na 1 a 3 \na 1 a 4 \na 1 a 4 a 5 \na 1 a 4 a 6 \na 1 a 4 a 7 \na 1 a 4 a 8 \na 1 a 4 a 8 a 9 \na 1 a 4 a 8 a 10  \na 1 a 4 a 8 a 11  \na 1 a 4 a 8 a 11  0 \u2013 0 \na 1 \na 0 a 0 \nRECURSIVE-ACTIVITY-SELECTOR (s, f, 0, 11)  \nRECURSIVE-ACTIVITY-SELECTOR (s, f, 1, 11)  \nRECURSIVE-ACTIVITY-SELECTOR (s, f, 4, 11)  \nRECURSIVE-ACTIVITY-SELECTOR (s, f, 8, 11)  m = 1 \nm = 4 \nm = 8 \nm = 11  \nRECURSIVE-ACTIVITY-SELECTOR (s, f, 11,  11)  \n15  16  \nFigure  15.2  The operation of R ECURSIVE-ACTIVITY-SELECTOR  on the 11  activities  from  Fig-  \nure  15.1.  Activities  considered  in each  recursive  call  appear  between  horizontal  lines.  The  \u00fbctitious  \nactivity a 0 \u00fbnishes  at time  0, and the initial call R ECURSIVE-ACTIVITY-SELECTOR.s;f;0;11/ , \nselects activity a 1 . In each recursive call, the activities that have already been selected are blue, \nand the activity shown in tan is being considered. If the starting time of an activity occurs before \nthe  \u00fbnish  time  of the  most  recently  added  activity  (the  arrow  between  them  points  left),  it is re-  \njected.  Otherwise  (the  arrow  points  directly  up  or to the  right), it is selected. The last recursive call, \nRECURSIVE-ACTIVITY-SELECTOR.s;f;11;11/ , returns ;. The resulting set of selected activities is \nfa 1 ;a  4 ;a  8 ;a  11  g. 424  Chapter  15  Greedy  Algorithms  \nThe  procedure  GREEDY-ACTIVITY-S ELECTOR  is an iterative  version  of the  pro-  \ncedure R ECURSIVE-ACTIVITY-SELECTOR. It, too,  assumes  that  the  input  activi-  \nties  are  ordered  by  monotonically  increasing  \u00fbnish  time.  It collects  selected  activ-  \nities into a set A and returns this set when it is done. \nGREEDY-ACTIVITY-SELECTOR  .s;f;n/  \n1 A D fa 1 g \n2 k D 1 \n3 for  m D 2 to n \n4 if s\u0152m\ufffd  \ue004 f\u0152k\ufffd  / / is a m in S k ? \n5 A D A [ fa m g / / yes, so choose it \n6 k D m / / and continue from there \n7 return  A \nThe procedure works as follows. The variable k indexes  the  most  recent  ad-  \ndition to A, corresponding to the activity a k in the recursive version. Since the \nprocedure considers the activities in order of mono tonically increasing  \u00fbnish  time,  \nf k is always  the  maximum  \u00fbnish  time  of any  activity  in A. That is, \nf k D max ff i W a i 2 Ag : (15.3)  \nLines  132  select  activity  a 1 , initialize A to contain just this activity, and initialize k \nto index this activity. The for  loop  of lines  336  \u00fbnds  the  earliest  activity  in S k to \n\u00fbnish.  The  loop  considers  each  activity  a m in turn and adds a m to A if it is compat-  \nible with all previously selected activities. Such an activity is the earliest in S k to \n\u00fbnish.  To  see  whether  activity  a m is compatible with every activity currently in A, \nit suf\u00fbces  by  equation  (15.3)  to check  (in  line  4) that  its  start time s m is not earlier \nthan  the  \u00fbnish  time  f k of the activity most recently added to A. If activity a m is \ncompatible,  then  lines  536  add  activity  a m to A and set k to m. The set A returned \nby  the  call  GREEDY-ACTIVITY-SELECTOR  .s;f/  is precisely the set returned by \nthe initial call R ECURSIVE-ACTIVITY-SELECTOR  .s;f;0;n/ . \nLike  the  recursive  version,  GREEDY-ACTIVITY-SELECTOR  schedules a set of n \nactivities in \u201a.n/  time, assuming that the activities were already sor ted initially by \ntheir  \u00fbnish  times.  \nExercises  \n15.1-1  \nGive  a dynamic-programming  algorithm  for  the  activity-sel ection problem, based \non  recurrence  (15.2).  Have  your  algorithm  compute  the  sizes  c\u0152i;j\ufffd  as de\u00fbned  \nabove  and  also  produce  the  maximum-size  subset  of mutually  compatible activities. 15.1  An  activity-selection  problem  425 \nAssume  that  the  inputs  have  been  sorted  as in equation  (15.1) . Compare the running \ntime  of your  solution  to the  running  time  of GREEDY-ACTIVITY-SELECTOR . \n15.1-2  \nSuppose  that  instead  of always  selecting  the  \u00fbrst  activity  to \u00fbnish,  you  instead  \nselect the last activity to start that is compatibl e with all previously  selected  activi-  \nties. Describe how this approach is a greedy algori thm, and prove that it yields an \noptimal solution. \n15.1-3  \nNot  just  any  greedy  approach  to the  activity-selection  problem  produces  a max-  \nimum-size  set  of mutually  compatible  activities.  Give  an example to show that \nthe approach of selecting the activity of least dur ation from among those that are \ncompatible with previously selected activities does  not work. Do the same for \nthe approaches of always selecting the compatible a ctivity that overlaps the fewest \nother remaining activities and always selecting the  compatible remaining activity \nwith the earliest start time. \n15.1-4  \nYou are given a set of activities to schedule among  a large number of lecture halls, \nwhere any activity can take place in any lecture ha ll. You wish to schedule all the \nactivities  using  as few  lecture  halls  as possible.  Give  an ef\u00fbcient  greedy  algorithm  \nto determine which activity should use which lectur e hall. \n(This problem is also known as the interval-graph  coloring  problem. It is mod-  \neled by an interval graph whose vertices are the gi ven activities and whose edges \nconnect incompatible activities. The smallest numbe r of colors required to color \nevery vertex so that no two adjacent vertices have the same color corresponds to \n\u00fbnding  the  fewest  lecture  halls  needed  to schedule  all  of the  given activities.) \n15.1-5  \nConsider  a modi\u00fbcation  to the  activity-selection  problem  in which each activity a i \nhas,  in addition  to a start  and  \u00fbnish  time,  a value  v i . The objective is no longer \nto maximize the number of activities scheduled, but  instead to maximize the total \nvalue of the activities scheduled. That is, the goa l is to choose a set A of compatible \nactivities such that P  \na k 2A v k is maximized.  Give  a polynomial-time  algorithm  for  \nthis problem. 426  Chapter  15  Greedy  Algorithms  \n15.2  Elements  of the  greedy  strategy  \nA greedy algorithm obtains an optimal solution to a  problem by making a sequence \nof choices. At each decision point, the algorithm m akes the choice that seems best \nat the moment. This heuristic strategy does not alw ays produce an optimal solution, \nbut  as in the  activity-selection  problem,  sometimes  it does. This section discusses \nsome of the general properties of greedy methods. \nThe  process  that  we  followed  in Section  15.1  to develop  a greedy algorithm was \na bit more involved than is typical. It consisted o f the following steps: \n1. Determine  the  optimal  substructure  of the  problem.  \n2. Develop  a recursive  solution.  (For  the  activity-selection  problem,  we  formu-  \nlated  recurrence  (15.2),  but  bypassed  developing  a recursi ve algorithm based \nsolely on this recurrence.) \n3. Show  that  if you  make  the  greedy  choice,  then  only  one  subpr oblem remains. \n4. Prove  that  it is always  safe  to make  the  greedy  choice.  (Steps  3 and  4 can  occur  \nin either order.) \n5. Develop  a recursive  algorithm  that  implements  the  greedy  strategy. \n6. Convert  the  recursive  algorithm  to an iterative  algorith m. \nThese  steps  highlighted  in great  detail  the  dynamic-progra mming underpinnings \nof a greedy  algorithm.  For  example,  the  \u00fbrst  cut  at the  activity-selection  problem  \nde\u00fbned  the  subproblems  S ij , where both i and j varied. We then found that if \nyou always make the greedy choice, you can restrict  the subproblems to be of the \nform S k . \nAn alternative approach is to fashion optimal subst ructure with a greedy choice \nin mind, so that the choice leaves just one subprob lem to solve. In the  activity-  \nselection problem, start by dropping the second sub script and  de\u00fbning  subproblems  \nof the form S k . Then  prove  that  a greedy  choice  (the  \u00fbrst  activity  a m to \u00fbnish  \nin S k ), combined with an optimal solution to the remaini ng set S m of compatible \nactivities, yields an optimal solution to S k . More generally, you can design greedy \nalgorithms according to the following sequence of s teps: \n1. Cast  the  optimization  problem  as one  in which  you  make  a choice and are left \nwith one subproblem to solve. \n2. Prove that there is always an optimal solution t o the original problem that makes \nthe greedy choice, so that the greedy choice is alw ays safe. \n3. Demonstrate  optimal  substructure  by  showing  that,  havin g made the greedy \nchoice, what remains is a subproblem with the prope rty that if you combine an 15.2  Elements  of the  greedy  strategy  427 \noptimal solution to the subproblem with the greedy choice you have made, you \narrive at an optimal solution to the original probl em. \nLater sections of this chapter will use this more d irect process.  Nevertheless,  be-  \nneath every greedy algorithm, there is almost alway s a more cumbersome  dynamic-  \nprogramming solution. \nHow can you tell whether a greedy algorithm will so lve a particular optimization \nproblem?  No  way  works  all  the  time,  but  the  greedy-choice  property and optimal \nsubstructure are the two key ingredients. If you ca n demonstrate that the problem \nhas these properties, then you are well on the way to developing a greedy algorithm \nfor it. \nGreedy-choice  property  \nThe  \u00fbrst  key  ingredient  is the  greedy-choice  property : you can assemble a globally \noptimal solution by making locally optimal (greedy)  choices. In other words, when \nyou are considering which choice to make, you make the choice that looks best in \nthe current problem, without considering results fr om subproblems. \nHere is where greedy algorithms differ from dynamic  programming. In dynamic \nprogramming, you make a choice at each step, but th e choice usually depends \non the solutions to subproblems. Consequently, you typically solve  dynamic-  \nprogramming  problems  in a bottom-up  manner,  progressing  from  smaller  sub-  \nproblems to larger subproblems. (Alternatively, you  can solve them top down, \nbut  memoizing.  Of  course,  even  though  the  code  works  top  down , you still must \nsolve the subproblems before making a choice.) In a  greedy algorithm, you make \nwhatever choice seems best at the moment and then s olve the subproblem  that  re-  \nmains. The choice made by a greedy algorithm may de pend on choices so far, but it \ncannot depend on any future choices or on the solut ions to subproblems.  Thus,  un-  \nlike dynamic programming, which solves the subprobl ems before  making  the  \u00fbrst  \nchoice,  a greedy  algorithm  makes  its  \u00fbrst  choice  before  solving any subproblems. \nA dynamic-programming  algorithm  proceeds  bottom  up,  whereas  a greedy  strat-  \negy usually progresses top down, making one greedy choice after another, reducing \neach given problem instance to a smaller one. \nOf  course,  you  need  to prove  that  a greedy  choice  at each  step  yields a globally \noptimal  solution.  Typically,  as in the  case  of Theorem  15.1,  the proof examines \na globally optimal solution to some subproblem. It then shows how to modify \nthe solution to substitute the greedy choice for so me other choice, resulting in one \nsimilar, but smaller, subproblem. \nYou  can  usually  make  the  greedy  choice  more  ef\u00fbciently  than  when you have \nto consider a wider set of choices. For example, in  the activity-selection  problem,  \nassuming that the activities were already sorted in  monotonically increasing order \nby  \u00fbnish  times,  each  activity  needed  to be examined  just  once . By preprocessing 428  Chapter  15  Greedy  Algorithms  \nthe input or by using an appropriate data structure  (often a priority queue), you \noften  can  make  greedy  choices  quickly,  thus  yielding  an ef\u00fbcient algorithm. \nOptimal  substructure  \nAs  we  saw  in Chapter  14,  a problem  exhibits  optimal  substructure  if an optimal \nsolution to the problem contains within it optimal solutions to subproblems. This \nproperty is a key ingredient of assessing whether d ynamic programming applies, \nand  it\u2019s  also  essential  for  greedy  algorithms.  As  an example  of optimal  substruc-  \nture,  recall  how  Section  15.1  demonstrated  that  if an optimal  solution  to subprob-  \nlem S ij includes an activity a k , then it must also contain optimal solutions to th e \nsubproblems S ik  and S kj  . Given  this  optimal  substructure,  we  argued  that  if you  \nknow which activity to use as a k , you can construct an optimal solution to S ij by \nselecting a k along with all activities in optimal solutions to t he subproblems S ik  \nand S kj  . This observation of optimal substructure gave ris e to the recurrence  (15.2)  \nthat describes the value of an optimal solution. \nYou will usually use a more direct approach regardi ng optimal substructure when \napplying it to greedy algorithms. As mentioned abov e, you have the luxury of \nassuming that you arrived at a subproblem by having  made the greedy choice in \nthe original problem. All you really need to do is argue that an optimal solution to \nthe subproblem, combined with the greedy choice alr eady made, yields an optimal \nsolution to the original problem. This scheme impli citly uses induction on the \nsubproblems to prove that making the greedy choice at every step produces an \noptimal solution. \nGreedy  versus  dynamic  programming  \nBecause  both  the  greedy  and  dynamic-programming  strategies  exploit  optimal  sub-  \nstructure,  you  might  be tempted  to generate  a dynamic-progr amming solution to \na problem  when  a greedy  solution  suf\u00fbces  or,  conversely,  you  might mistakenly \nthink  that  a greedy  solution  works  when  in fact  a dynamic-pro gramming solution \nis required. To illustrate the subtle differences b etween the two  techniques,  let\u2019s  \ninvestigate two variants of a classical optimizatio n problem. \nThe 0-1  knapsack  problem  is the following. A thief robbing a store wants to \ntake the most valuable load that can be carried in a knapsack capable of carrying \nat most W pounds of loot. The thief can choose to take any su bset of n items in \nthe store. The i th item is worth v i dollars and weighs w i pounds, where v i and w i \nare  integers.  Which  items  should  the  thief  take?  (We  call  this  the  0-1  knapsack  \nproblem because for each item, the thief must eithe r take it or leave it behind. The \nthief cannot take a fractional amount of an item or  take an item more than once.) 15.2  Elements  of the  greedy  strategy  429 \nIn the fractional  knapsack  problem , the setup is the same, but the thief can take \nfractions  of items,  rather  than  having  to make  a binary  (0-1)  choice for each item. \nYou  can  think  of an item  in the  0-1  knapsack  problem  as being  like a gold ingot \nand an item in the fractional knapsack problem as m ore like gold dust. \nBoth  knapsack  problems  exhibit  the  optimal-substructure  property.  For  the  0-1  \nproblem, if the most valuable load weighing at most  W pounds includes item j , \nthen the remaining load must be the most valuable l oad weighing at most W \ue003 w j \npounds that the thief can take from the n \ue003 1 original items excluding item j . For \nthe comparable fractional problem, if if the most v aluable load weighing at most \nW pounds includes weight w of item j , then the remaining load must be the most \nvaluable load weighing at most W \ue003 w pounds that the thief can take from the n \ue003 1 \noriginal items plus w j \ue003 w pounds of item j . \nAlthough the problems are similar, a greedy strateg y works to solve  the  frac-  \ntional  knapsack  problem,  but  not  the  0-1  problem.  To  solve  the fractional problem, \n\u00fbrst  compute  the  value  per  pound  v i =w  i for  each  item.  Obeying  a greedy  strategy,  \nthe thief begins by taking as much as possible of t he item with the greatest value \nper pound. If the supply of that item is exhausted and the thief can still carry more, \nthen the thief takes as much as possible of the ite m with the next greatest value per \npound, and so forth, until reaching the weight limi t W . Thus, by sorting the items \nby value per pound, the greedy algorithm runs in O.n  lg n/ time. You are asked \nto prove that the fractional knapsack problem has t he greedy-choice  property  in \nExercise  15.2-1.  \nTo  see  that  this  greedy  strategy  does  not  work  for  the  0-1  knap sack problem, \nconsider  the  problem  instance  illustrated  in Figure  15.3(a ). This example has three \nitems and a knapsack that can hold 50  pounds. Item 1 weighs 10  pounds and is \nworth $60. Item 2 weighs 20  pounds and is worth $ 100. Item 3 weighs 30  pounds \nand is worth $ 120. Thus, the value per pound of item 1 is $6 per pound, which is \ngreater than the value per pound of either item 2 ($5 per pound) or item 3 ($4 per \npound). The greedy strategy, therefore, would take item 1 \u00fbrst.  As  you  can  see  \nfrom  the  case  analysis  in Figure  15.3(b),  however,  the  optim al solution takes items \n2 and 3, leaving item 1 behind. The two possible solutions that take item 1 are both \nsuboptimal. \nFor the comparable fractional problem, however, the  greedy strategy, which \ntakes item 1 \u00fbrst,  does  yield  an optimal  solution,  as shown  in Figure  15.3(c).  Tak-  \ning item 1 doesn\u2019t  work  in the  0-1  problem,  because  the  thief  is unable  to \u00fbll  the  \nknapsack to capacity, and the empty space lowers th e effective value per pound of \nthe  load.  In the  0-1  problem,  when  you  consider  whether  to include an item in the \nknapsack, you must compare the solution to the subp roblem that includes the item \nwith the solution to the subproblem that excludes t he item before you can make the \nchoice. The problem formulated in this way gives ri se to many overlapping  sub-  430  Chapter  15  Greedy  Algorithms  \n10  \n$60  item 1 20 \n$100  item 2 \n30  \n$120  item 3 \n50  \nknapsack  \n(a) + $120  \n$100  \n= $220 + \n$60  $100  \n= $160  + \n$60  $120  \n= $180  \n(b) + \n$60  $100  \n= $240  $80  \n+ \n(c) 20 30  \n10  20 \n10  30  \n10  20 20 \n30  \nFigure  15.3  An example showing that the greedy strategy does no t work for the  0-1  knapsack  \nproblem. (a)  The thief must select a subset of the three items s hown whose weight must not exceed \n50  pounds. (b)  The optimal subset includes items 2 and 3. Any solution with item 1 is suboptimal, \neven though item 1 has the greatest value per pound. (c)  For the fractional knapsack problem, taking \nthe items in order of greatest value per pound yiel ds an optimal solution. \nproblems4a  hallmark  of dynamic  programming,  and  indeed,  as Exercise  15.2-2  \nasks you to show, you can use dynamic programming t o solve the 0-1  problem.  \nExercises  \n15.2-1  \nProve  that  the  fractional  knapsack  problem  has  the  greedy-c hoice property. \n15.2-2  \nGive  a dynamic-programming  solution  to the  0-1  knapsack  problem that runs in \nO.nW/  time, where n is the number of items and W is the maximum weight of \nitems that the thief can put in the knapsack. \n15.2-3  \nSuppose  that  in a 0-1  knapsack  problem,  the  order  of the  items  when sorted by \nincreasing weight is the same as their order when s orted by decreasing  value.  Give  \nan ef\u00fbcient  algorithm  to \u00fbnd  an optimal  solution  to this  variant of the knapsack \nproblem, and argue that your algorithm is correct. \n15.2-4  \nProfessor  Gekko  has  always  dreamed  of inline  skating  across  North Dakota. The \nprofessor plans to cross the state on highway U.S. 2, which runs from  Grand  Forks,  \non the eastern border with Minnesota, to Williston,  near the western border with \nMontana. The professor can carry two liters of wate r and can skate m miles before 15.3  Huffman  codes  431 \nrunning  out  of water.  (Because  North  Dakota  is relatively  \u00fcat, the professor does \nnot have to worry about drinking water at a greater  rate on uphill sections than on \n\u00fcat  or downhill  sections.)  The  professor  will  start  in Grand  Forks with two full \nliters  of water.  The  professor  has  an of\u00fbcial  North  Dakota  state map, which shows \nall  the  places  along  U.S.  2 to re\u00fbll  water  and  the  distances  between these locations. \nThe  professor\u2019s  goal  is to minimize  the  number  of water  stops  along the route \nacross  the  state.  Give  an ef\u00fbcient  method  by  which  the  profes sor can determine \nwhich water stops to make. Prove that your strategy  yields an optimal solution, \nand give its running time. \n15.2-5  \nDescribe  an ef\u00fbcient  algorithm  that,  given  a set  fx 1 ;x  2 ;:::;x  n g of points on the \nreal  line,  determines  the  smallest  set  of unit-length  close d intervals that contains \nall of the given points. Argue that your algorithm is correct. \n? 15.2-6  \nShow how to solve the fractional knapsack problem i n O.n/  time. \n15.2-7  \nYou are given two sets A and B , each containing n positive integers. You can \nchoose to reorder each set however you like. After reordering, let a i be the i th \nelement of set A, and let b i be the i th element of set B . You then receive a payoff \nof Q  n \ni D1 a i b i . Give  an algorithm  that  maximizes  your  payoff.  Prove  that  your \nalgorithm maximizes the payoff, and state its runni ng time, omitting the time for \nreordering the sets. \n15.3  Huffman  codes  \nHuffman codes compress data well: savings of 20% to 90% are typical, depending \non the characteristics of the data being compressed . The data arrive as a sequence \nof characters.  Huffman\u2019s  greedy  algorithm  uses  a table  giving how often each \ncharacter occurs (its frequency) to build up an opt imal way of representing each \ncharacter as a binary string. \nSuppose  that  you  have  a 100,000-character  data  \u00fble  that  you  wish  to store  com-  \npactly and you know that the 6 distinct  characters  in the  \u00fble  occur  with  the  frequen-  \ncies  given  by  Figure  15.4.  The  character  a occurs  45,000  times,  the  character  b \noccurs  13,000  times,  and  so on.  \nYou  have  many  options  for  how  to represent  such  a \u00fble  of inform ation. Here, \nwe consider the problem of designing a binary  character  code  (or code  for short) 432  Chapter  15  Greedy  Algorithms  \na b c d e f \nFrequency  (in  thousands)  45  13  12  16  9 5 \nFixed-length  codeword  000  001  010  011  100  101  \nVariable-length  codeword  0 101  100  111  1101  1100  \nFigure  15.4  A character-coding  problem.  A data  \u00fble  of 100,000  characters  contains  only  the  char-  \nacters a\u2013f, with the frequencies indicated. With each charact er represented  by  a 3-bit  codeword,  \nencoding  the  \u00fble  requires  300,000  bits.  With  the  variable-l ength code shown, the encoding requires \nonly  224,000  bits.  \nin which each character is represented by a unique binary string, which we call a \ncodeword . If you use a \u00fbxed-length  code, you need dlg ne bits to represent n \ue004 2 \ncharacters. For 6 characters, therefore, you need 3 bits: a = 000, b = 001,  c = 010,  \nd = 011,  e = 100,  and  f = 101.  This  method  requires  300,000  bits  to encode  the  \nentire  \u00fble.  Can  you  do  better?  \nA variable-length  code  can  do  considerably  better  than  a \u00fbxed-length  code.  The  \nidea is simple: give frequent characters short code words and infrequent characters \nlong  codewords.  Figure  15.4  shows  such  a code.  Here,  the  1-bit string 0 represents \na, and  the  4-bit  string  1100  represents f. This code requires \n.45  \ue001 1 C 13  \ue001 3 C 12  \ue001 3 C 16  \ue001 3 C 9 \ue001 4 C 5 \ue001 4/ \ue001 1,000  D 224,000  bits  \nto represent  the  \u00fble,  a savings  of approximately  25%. In fact, this is an optimal \ncharacter  code  for  this  \u00fble,  as we  shall  see.  \nPre\u00fbx-free  codes  \nWe  consider  here  only  codes  in which  no  codeword  is also  a pre\u00fbx of some other \ncodeword. Such codes are called pre\u00fbx-free  codes. Although  we  won\u2019t  prove  it \nhere,  a pre\u00fbx-free  code  can  always  achieve  the  optimal  data  compression among \nany character code, and so we suffer no loss of gen erality by restricting  our  atten-  \ntion  to pre\u00fbx-free  codes.  \nEncoding is always simple for any binary character code: just concatenate the \ncodewords  representing  each  character  of the  \u00fble.  For  example,  with  the  variable-  \nlength  pre\u00fbx-free  code  of Figure  15.4,  the  4-character  \u00fble  face  has the encoding \n1100  \ue001 0 \ue001 100  \ue001 1101  D 110001001101 , where < \ue001= denotes concatenation. \nPre\u00fbx-free  codes  are  desirable  because  they  simplify  decoding.  Since  no  code-  \nword  is a pre\u00fbx  of any  other,  the  codeword  that  begins  an encoded  \u00fble  is unambigu-  \nous. You can simply identify the initial codeword, translate it back to the original \ncharacter, and repeat the decoding process on the r emainder of the  encoded  \u00fble.  \nIn our example, the string 100011001101  parses uniquely as 100  \ue001 0 \ue001 1100  \ue001 1101 , \nwhich decodes to cafe . 15.3  Huffman  codes  433 \na:45  b:13  c:12  d:16  e:9 f:5 58  28  14  86  14  100  \n0 1 0 1 0 1 0 1 0 0 1 \ne:9 f:5 14  \n0 1 c:12  b:13  25  \n0 1 \nd:16  30  \n0 1 55  \n0 1 a:45  100  \n0 1 \n(a) (b) \nFigure  15.5  Trees  corresponding  to the  coding  schemes  in Figure  15.4.  Each leaf is labeled with a \ncharacter and its frequency of occurrence. Each int ernal node is labeled  with  the  sum  of the  frequen-  \ncies of the leaves in its subtree. All frequencies are in thousands. (a)  The tree corresponding to the \n\u00fbxed-length  code  a = 000, b = 001,  c = 010,  d = 011,  e = 100,  f = 101.  (b)  The tree corresponding \nto the  optimal  pre\u00fbx-free  code  a = 0, b = 101,  c = 100,  d = 111,  e = 1101,  f = 1100.  \nThe decoding process needs a convenient representat ion for the  pre\u00fbx-free  code  \nso that you can easily pick off the initial codewor d. A binary tree whose leaves \nare the given characters provides one such represen tation. Interpret the binary \ncodeword for a character as the simple path from th e root to that character, where 0 \nmeans <go to the left child= and 1 means  <go  to the  right  child.=  Figure  15.5  shows  \nthe trees for the two codes of our example. Note th at these are not binary search \ntrees, since the leaves need not appear in sorted o rder and internal nodes do not \ncontain character keys. \nAn  optimal  code  for  a \u00fble  is always  represented  by  a full  binary tree, in which \nevery  nonleaf  node  has  two  children  (see  Exercise  15.3-2).  The  \u00fbxed-length  code  \nin our  example  is not  optimal  since  its  tree,  shown  in Figure  15.5(a),  is not  a full  \nbinary  tree:  it contains  codewords  beginning  with  10,  but  none  beginning  with  11.  \nSince we can now restrict our attention to full bin ary trees, we can say that if C is \nthe alphabet from which the characters are drawn an d all character frequencies are \npositive,  then  the  tree  for  an optimal  pre\u00fbx-free  code  has  exactly jC j leaves, one for \neach letter of the alphabet, and exactly jC j \ue003  1 internal  nodes  (see  Exercise  B.5-3  \non  page  1175).  \nGiven  a tree  T corresponding  to a pre\u00fbx-free  code,  we  can  compute  the  numbe r \nof bits  required  to encode  a \u00fble.  For  each  character  c in the alphabet C , let the \nattribute c: freq denote the frequency of c in the  \u00fble  and  let  d T .c/  denote the depth \nof c \u2019s leaf  in the  tree.  Note  that  d T .c/  is also the length of the codeword for \ncharacter c . The  number  of bits  required  to encode  a \u00fble  is thus  434  Chapter  15  Greedy  Algorithms  \nB.T/  D X  \nc2C c: freq \ue001 d T .c/;  (15.4)  \nwhich  we  de\u00fbne  as the  cost  of the tree T . \nConstructing  a Huffman  code  \nHuffman invented a greedy algorithm that constructs  an optimal  pre\u00fbx-free  code,  \ncalled a Huffman  code  in his  honor.  In line  with  our  observations  in Section  15.2,  \nits  proof  of correctness  relies  on  the  greedy-choice  property  and  optimal  substruc-  \nture. Rather than demonstrating that these properti es hold and then developing \npseudocode,  we  present  the  pseudocode  \u00fbrst.  Doing  so will  help clarify how the \nalgorithm makes greedy choices. \nThe procedure H UFFMAN assumes that C is a set of n characters and that each \ncharacter c 2 C is an object with an attribute c: freq giving  its  frequency.  The  algo-  \nrithm builds the tree T corresponding  to an optimal  code  in a bottom-up  manner.  It \nbegins with a set of jC j leaves and performs a sequence of jC j \ue003  1 <merging=  op-  \nerations  to create  the  \u00fbnal  tree.  The  algorithm  uses  a min-pr iority queue Q, keyed \non the freq attribute,  to identify  the  two  least-frequent  objects  to merge together. \nThe result of merging two objects is a new object w hose frequency is the sum of \nthe frequencies of the two objects that were merged . \nHUFFMAN.C/  \n1 n D jC j \n2 Q D C \n3 for  i D 1 to n \ue003 1 \n4 allocate a new node \u00b4 \n5 x D EXTRACT-MIN .Q/  \n6 y D EXTRACT-MIN .Q/  \n7 \u00b4: left D x \n8 \u00b4: right D y \n9 \u00b4: freq D x: freq C y: freq \n10  I NSERT.Q;\u00b4/  \n11  return  EXTRACT-MIN.Q/  / / the root of the tree is the only node left \nFor  our  example,  Huffman\u2019s  algorithm  proceeds  as shown  in Figure  15.6.  Since  \nthe alphabet contains 6 letters, the initial queue size is n D 6, and 5 merge steps \nbuild  the  tree.  The  \u00fbnal  tree  represents  the  optimal  pre\u00fbx-f ree code. The codeword \nfor a letter is the sequence of edge labels on the simple path from the root to the \nletter. 15.3  Huffman  codes  435 \ne:9 f:5 14  \n0 1 c:12  b:13  25  \n0 1 \nd:16  30  \n0 1 55  \n0 1 a:45  100  \n0 1 \ne:9 f:5 14  \n0 1 c:12  b:13  25  \n0 1 \nd:16  30  \n0 1 55  \n0 1 a:45  e:9 f:5 14  \n0 1 c:12  b:13  25  \n0 1 \nd:16  30  \n0 1 a:45  \ne:9 f:5 14  \n0 1 \nc:12  b:13  25  \n0 1 d:16  a:45  e:9 f:5 14  \n0 1 c:12  b:13  d:16  a:45  e:9 f:5 c:12  b:13  d:16  a:45  (a) \n(c) \n(e) (b) \n(d) \n(f) \nFigure  15.6  The  steps  of Huffman\u2019s  algorithm  for  the  frequencies  given  in Figure  15.4.  Each  part  \nshows the contents of the queue sorted into increas ing order by frequency. Each step merges the \ntwo trees with the lowest frequencies. Leaves are s hown as rectangles containing a character and \nits frequency. Internal nodes are shown as circles containing the sum of the frequencies of their \nchildren. An edge connecting an internal node with its children is labeled 0 if it is an edge to a left \nchild and 1 if it is an edge to a right child. The codeword for  a letter is the sequence of labels on the \nedges connecting the root to the leaf for that lett er. (a)  The initial set of n D 6 nodes, one for each \nletter. (b)\u2013(e)  Intermediate stages. (f)  The  \u00fbnal  tree.  \nThe H UFFMAN procedure  works  as follows.  Line  2 initializes  the  min-prio rity \nqueue Q with the characters in C . The for  loop  in lines  3310  repeatedly  extracts  \nthe two nodes x and y of lowest frequency from the queue and replaces the m in \nthe queue with a new node \u00b4 representing their merger. The frequency of \u00b4 is \ncomputed as the sum of the frequencies of x and y in line 9. The node \u00b4 has x \nas its left child and y as its right child. (This order is arbitrary. Switc hing the left \nand right child of any node yields a different code  of the same cost.) After n \ue003 1 \nmergers,  line  11  returns  the  one  node  left  in the  queue,  which  is the root of the code \ntree. 436  Chapter  15  Greedy  Algorithms  \nThe algorithm produces the same result without the variables x and y , assigning \nthe values returned by the E XTRACT-MIN calls directly to \u00b4: left and \u00b4: right in \nlines  7 and  8, and  changing  line  9 to \u00b4: freq D \u00b4: left : freq C \u00b4: right : freq. We\u2019ll  use  \nthe node names x and y in the proof of correctness, however, so we leave t hem in. \nThe  running  time  of Huffman\u2019s  algorithm  depends  on  how  the  min-priority  \nqueue Q is implemented.  Let\u2019s  assume  that  it\u2019s  implemented  as a binary  min-heap  \n(see  Chapter  6).  For  a set  C of n characters, the B UILD-MIN-HEAP procedure  dis-  \ncussed  in Section  6.3  can  initialize  Q in line 2 in O.n/  time. The for  loop in lines \n3310  executes  exactly  n \ue003 1 times, and since each heap operation runs in O.lg n/ \ntime, the loop contributes O.n  lg n/ to the running time. Thus, the total running \ntime of H UFFMAN on a set of n characters is O.n  lg n/. \nCorrectness  of Huffman\u2019s  algorithm  \nTo prove that the greedy algorithm H UFFMAN is correct,  we\u2019ll  show  that  the  prob-  \nlem  of determining  an optimal  pre\u00fbx-free  code  exhibits  the  greedy-choice  and  \noptimal-substructure  properties.  The  next  lemma  shows  that  the  greedy-choice  \nproperty holds. \nLemma  15.2  (Optimal  pre\u00fbx-free  codes  have  the  greedy-choice property)  \nLet C be an alphabet in which each character c 2 C has frequency c: freq. Let x \nand y be two characters in C having the lowest frequencies. Then there exists an  \noptimal  pre\u00fbx-free  code  for  C in which the codewords for x and y have the same \nlength and differ only in the last bit. \nProof  The idea of the proof is to take the tree T representing an arbitrary optimal \npre\u00fbx-free  code  and  modify  it to make  a tree  representing  another  optimal  pre\u00fbx-  \nfree code such that the characters x and y appear as sibling leaves of maximum \ndepth in the new tree. In such a tree, the codeword s for x and y have the same \nlength and differ only in the last bit. \nLet a and b be any two characters that are sibling leaves of ma ximum depth \nin T . Without loss of generality, assume that a: freq \u0dc4 b: freq and x: freq \u0dc4 y: freq. \nSince x: freq and y: freq are the two lowest leaf frequencies, in order, and a: freq \nand b: freq are two arbitrary frequencies, in order, we have x: freq \u0dc4 a: freq and \ny: freq \u0dc4 b: freq. \nIn the remainder of the proof, it is possible that we could have x: freq D a: freq \nor y: freq D b: freq, but x: freq D b: freq implies that a: freq D b: freq D x: freq D \ny: freq (see  Exercise  15.3-1),  and  the  lemma  would  be trivially  true. Therefore, \nassume that x: freq \u00a4 b: freq, which means that x \u00a4 b. \nAs  Figure  15.7  shows,  imagine  exchanging  the  positions  in T of a and x to \nproduce a tree T 0 , and then exchanging the positions in T 0 of b and y to produce a 15.3  Huffman  codes  437 \nx \ny \na b x y a \nb x y a \nb T T 0 T 00 \nFigure  15.7  An  illustration  of the  key  step  in the  proof  of Lemma  15.2.  In the optimal tree T , \nleaves a and b are two siblings of maximum depth. Leaves x and y are the two characters with the \nlowest frequencies. They appear in arbitrary positi ons in T . Assuming that x \u00a4 b, swapping leaves \na and x produces tree T 0 , and then swapping leaves b and y produces tree T 00 . Since each swap does \nnot increase the cost, the resulting tree T 00 is also an optimal tree. \ntree T 00 in which x and y are sibling leaves of maximum depth. (Note that if x D b \nbut y \u00a4 a, then tree T 00 does not have x and y as sibling leaves of maximum depth. \nBecause we assume that x \u00a4 b, this  situation  cannot  occur.)  By  equation  (15.4),  \nthe difference in cost between T and T 0 is \nB.T/  \ue003 B.T  0 / \nD X  \nc2C c: freq \ue001 d T .c/  \ue003 X  \nc2C c: freq \ue001 d T 0 .c/  \nD x: freq \ue001 d T .x/  C a: freq \ue001 d T .a/  \ue003 x: freq \ue001 d T 0 .x/  \ue003 a: freq \ue001 d T 0 .a/  \nD x: freq \ue001 d T .x/  C a: freq \ue001 d T .a/  \ue003 x: freq \ue001 d T .a/  \ue003 a: freq \ue001 d T .x/  \nD .a:  freq \ue003 x: freq/.d  T .a/  \ue003 d T .x//  \n\ue004 0;  \nbecause both a: freq \ue003 x: freq and d T .a/  \ue003 d T .x/  are  nonnegative.  More  speci\u00fb-  \ncally, a: freq \ue003 x: freq is nonnegative because x is a minimum-frequency  leaf,  and  \nd T .a/  \ue003 d T .x/  is nonnegative because a is a leaf of maximum depth in T . Sim-  \nilarly, exchanging y and b does not increase the cost, and so B.T  0 / \ue003 B.T  00 / is \nnonnegative. Therefore, B.T  00 / \u0dc4 B.T  0 / \u0dc4 B.T/ , and since T is optimal, we \nhave B.T/  \u0dc4 B.T  00 /, which implies B.T  00 / D B.T/ . Thus, T 00 is an optimal \ntree in which x and y appear as sibling leaves of maximum depth, from whi ch the \nlemma follows. \nLemma  15.2  implies  that  the  process  of building  up  an optimal  tree by mergers \ncan, without loss of generality, begin with the gre edy choice of merging together \nthose two characters of lowest frequency. Why is th is a greedy choice?  We  can  \nview the cost of a single merger as being the sum o f the frequencies of the two items \nbeing  merged.  Exercise  15.3-4  shows  that  the  total  cost  of the tree constructed \nequals  the  sum  of the  costs  of its  mergers.  Of  all  possible  mergers at each step, \nHUFFMAN chooses the one that incurs the least cost. 438  Chapter  15  Greedy  Algorithms  \nThe next lemma shows that the problem of constructi ng optimal pre\u00fbx-free  \ncodes  has  the  optimal-substructure  property.  \nLemma  15.3  (Optimal  pre\u00fbx-free  codes  have  the  optimal-substructure  property)  \nLet C be a given alphabet with frequency c: freq de\u00fbned  for  each  character  c 2 C . \nLet x and y be two characters in C with minimum frequency. Let C 0 be the  alpha-  \nbet C with the characters x and y removed and a new character \u00b4 added, so that \nC 0 D .C  \ue003 fx;y  g/ [ f\u00b4g. De\u00fbne  freq for all characters in C 0 with the same values \nas in C , along with \u00b4: freq D x: freq C y: freq. Let T 0 be any tree representing \nan optimal  pre\u00fbx-free  code  for  alphabet  C 0 . Then the tree T , obtained from T 0 \nby replacing the leaf node for \u00b4 with an internal node having x and y as children, \nrepresents  an optimal  pre\u00fbx-free  code  for  the  alphabet  C . \nProof  We  \u00fbrst  show  how  to express  the  cost  B.T/  of tree T in terms of the \ncost B.T  0 / of tree T 0 , by  considering  the  component  costs  in equation  (15.4).  \nFor each character c 2 C \ue003 fx;y  g, we have that d T .c/  D d T 0 .c/, and hence \nc: freq \ue001 d T .c/  D c: freq \ue001 d T 0 .c/. Since d T .x/  D d T .y/  D d T 0 .\u00b4/  C 1, we have \nx: freq \ue001 d T .x/  C y: freq \ue001 d T .y/  D .x:  freq C y: freq/.d  T 0 .\u00b4/  C 1/ \nD \u00b4: freq \ue001 d T 0 .\u00b4/  C .x:  freq C y: freq/; \nfrom which we conclude that \nB.T/  D B.T  0 / C x: freq C y: freq \nor, equivalently, \nB.T  0 / D B.T/  \ue003 x: freq \ue003 y: freq : \nWe now prove the lemma by contradiction. Suppose th at T does not represent \nan optimal  pre\u00fbx-free  code  for  C . Then there exists an optimal tree T 00 such that \nB.T  00 /<B.T/. Without  loss  of generality  (by  Lemma  15.2),  T 00 has x and y as \nsiblings. Let T 000 be the tree T 00 with the common parent of x and y replaced by a \nleaf \u00b4 with frequency \u00b4: freq D x: freq C y: freq. Then \nB.T  000 / D B.T  00 / \ue003 x: freq \ue003 y: freq \n< B.T/  \ue003 x: freq \ue003 y: freq \nD B.T  0 /; \nyielding a contradiction to the assumption that T 0 represents  an optimal  pre\u00fbx-free  \ncode for C 0 . Thus, T must  represent  an optimal  pre\u00fbx-free  code  for  the  alpha-  \nbet C . \nTheorem  15.4  \nProcedure H UFFMAN produces  an optimal  pre\u00fbx-free  code.  15.3  Huffman  codes  439 \nProof  Immediate  from  Lemmas  15.2  and  15.3.  \nExercises  \n15.3-1  \nExplain  why,  in the  proof  of Lemma  15.2,  if x: freq D b: freq, then we must have \na: freq D b: freq D x: freq D y: freq. \n15.3-2  \nProve  that  a non-full  binary  tree  cannot  correspond  to an optimal  pre\u00fbx-free  code.  \n15.3-3  \nWhat is an optimal Huffman code for the following s et of frequencies, based on \nthe  \u00fbrst  8 Fibonacci  numbers?  \na:1 b:1 c:2 d:3 e:5 f:8 g:13  h:21  \nCan  you  generalize  your  answer  to \u00fbnd  the  optimal  code  when  the frequencies are \nthe  \u00fbrst  n Fibonacci  numbers?  \n15.3-4  \nProve that the total cost B.T/  of a full binary tree T for a code equals the sum, over \nall internal nodes, of the combined frequencies of the two children of the node. \n15.3-5  \nGiven  an optimal  pre\u00fbx-free  code  on  a set  C of n characters, you wish to transmit \nthe code itself using as few bits as possible. Show  how to represent any optimal \npre\u00fbx-free  code  on  C using only 2n  \ue003 1 C n dlg ne bits. ( Hint: Use 2n  \ue003 1 bits to \nspecify the structure of the tree, as discovered by  a walk of the tree.) \n15.3-6  \nGeneralize  Huffman\u2019s  algorithm  to ternary  codewords  (i.e., codewords using the \nsymbols 0, 1, and 2), and prove that it yields optimal ternary codes. \n15.3-7  \nA data  \u00fble  contains  a sequence  of 8-bit  characters  such  that  all  256  characters  are  \nabout equally common: the maximum character frequen cy is less than twice the \nminimum character frequency. Prove that Huffman cod ing in this case is no more \nef\u00fbcient  than  using  an ordinary  8-bit  \u00fbxed-length  code.  \n15.3-8  \nShow that no lossless (invertible) compression sche me can guarantee that for every \ninput  \u00fble,  the  corresponding  output  \u00fble  is shorter.  (Hint: Compare the number of \npossible  \u00fbles  with  the  number  of possible  encoded  \u00fbles.)  440  Chapter  15  Greedy  Algorithms  \n15.4  Of\u00fcine  caching  \nComputer systems can decrease the time to access da ta by storing a subset of the \nmain memory in the cache : a small but faster memory. A cache organizes data  into \ncache  blocks  typically comprising 32, 64, or 128  bytes. You can also think of main \nmemory  as a cache  for  disk-resident  data  in a virtual-memory  system. Here, the \nblocks are called pages , and 4096  bytes is a typical size. \nAs a computer program executes, it makes a sequence  of memory requests. Say \nthat there are n memory requests, to data in blocks b 1 ;b  2 ;:::;b  n , in that order. The \nblocks in the access sequence might not be distinct , and indeed, any given block is \nusually accessed multiple times. For example, a pro gram that accesses four distinct \nblocks p;q;r;s  might make a sequence of requests to blocks s;q;s;q;q;s;p;p;r;  \ns;s;q;p;r;q . The  cache  can  hold  up  to some  \u00fbxed  number  k of cache blocks. It \nstarts  out  empty  before  the  \u00fbrst  request.  Each  request  cause s at most one block to \nenter the cache and at most one block to be evicted  from the cache. Upon a request \nfor block b i , any one of three scenarios may occur: \n1. Block  b i is already in the cache, due to a previous request for the same block. \nThe cache remains unchanged. This situation is know n as a cache  hit. \n2. Block b i is not in the cache at that time, but the cache con tains fewer than k \nblocks. In this case, block b i is placed into the cache, so that the cache contain s \none more block than it did before the request. \n3. Block  b i is not in the cache at that time and the cache is f ull: it contains k \nblocks. Block b i is placed into the cache, but before that happens, some other \nblock in the cache must be evicted from the cache i n order to make room. \nThe latter two situations, in which the requested b lock is not already in the cache, \nare called cache  misses . The goal is to minimize the number of cache misse s or, \nequivalently, to maximize the number of cache hits,  over the entire sequence of n \nrequests. A cache miss that occurs while the cache holds fewer than k blocks4  \nthat  is, as the  cache  is \u00fbrst  being  \u00fblled  up4is  known  as a compulsory  miss, since \nno prior decision could have kept the requested blo ck in the cache. When a cache \nmiss occurs and the cache is full, ideally the choi ce of which block to evict should \nallow for the smallest possible number of cache mis ses over the entire sequence of \nfuture requests. \nTypically, caching is an online problem. That is, t he computer has to decide \nwhich blocks to keep in the cache without knowing t he future requests. Here, \nhowever,  let\u2019s  consider  the  of\u00fcine  version  of this  problem,  in which the computer \nknows in advance the entire sequence of n requests and the cache size k, with a \ngoal of minimizing the total number of cache misses . 15.4  Of\ufb02ine  caching  441 \nTo  solve  this  of\u00fcine  problem,  you  can  use  a greedy  strategy  called furthest-in-  \nfuture , which chooses to evict the block in the cache who se next access in the  re-  \nquest sequence comes furthest in the future. Intuit ively, this strategy makes sense: \nif you\u2019re  not  going  to need  something  for  a while,  why  keep  it around?  We\u2019ll  show  \nthat  the  furthest-in-future  strategy  is indeed  optimal  by  showing  that  the  of\u00fcine  \ncaching problem exhibits optimal substructure and t hat furthest-in-future  has  the  \ngreedy-choice  property.  \nNow, you might be thinking that since the computer usually doesn\u2019t  know  the  \nsequence of requests in advance, there is no point in studying the  of\u00fcine  problem.  \nActually, there is. In some situations, you do know  the sequence of requests in \nadvance. For example, if you view the main memory a s the cache and the full set \nof data  as residing  on  disk  (or  a solid-state  drive),  there  are algorithms that plan out \nthe entire set of reads and writes in advance. Furt hermore, we can use the number \nof cache misses produced by an optimal algorithm as  a baseline for comparing how \nwell  online  algorithms  perform.  We\u2019ll  do  just  that  in Section  27.3.  \nOf\u00fcine  caching  can  even  model  real-world  problems.  For  exam ple, consider a \nscenario  where  you  know  in advance  a \u00fbxed  schedule  of n events  at known  loca-  \ntions. Events may occur at a location multiple time s, not necessarily consecutively. \nYou are managing a group of k agents, you need to ensure that you have one agent \nat each location when an event occurs, and you want  to minimize the number of \ntimes that agents have to move. Here, the agents ar e like the blocks, the events are \nlike the requests, and moving an agent is akin to a  cache miss. \nOptimal  substructure  of of\u00fcine  caching  \nTo  show  that  the  of\u00fcine  problem  exhibits  optimal  substructure,  let\u2019s  de\u00fbne  the  \nsubproblem .C;i/  as processing requests for blocks b i ;b  i C1 ;:::;b  n with cache \ncon\u00fbguration  C at the time that the request for block b i occurs, that is, C is a \nsubset of the set of blocks such that jC j \u0dc4  k. A solution to subproblem .C;i/  is a \nsequence  of decisions  that  speci\u00fbes  which  block  to evict  (if  any) upon each request \nfor blocks b i ;b  i C1 ;:::;b  n . An optimal solution to subproblem .C;i/  minimizes \nthe number of cache misses. \nConsider an optimal solution S to subproblem .C;i/ , and let C 0 be the contents \nof the cache after processing the request for block  b i in solution S . Let S 0 be the \nsubsolution of S for the resulting subproblem .C  0 ;i C 1/. If the request for b i \nresults in a cache hit, then the cache remains unch anged, so that C 0 D C . If the \nrequest for block b i results in a cache miss, then the contents of the c ache change, \nso that C 0 \u00a4 C . We claim that in either case, S 0 is an optimal  solution  to subprob-  \nlem .C  0 ;i C 1/. Why?  If S 0 is not an optimal solution to subproblem .C  0 ;i C 1/, \nthen there exists another solution S 00 to subproblem .C  0 ;i C 1/ that makes fewer \ncache misses than S 0 . Combining S 00 with the decision of S at the request for 442  Chapter  15  Greedy  Algorithms  \nblock b i yields another solution that makes fewer cache miss es than S , which  con-  \ntradicts the assumption that S is an optimal solution to subproblem .C;i/ . \nTo quantify a recursive solution, we need a little more notation. Let R C;i  be the \nset  of all  cache  con\u00fbgurations  that  can  immediately  follow  con\u00fbguration  C after \nprocessing a request for block b i . If the request results in a cache hit, then the \ncache remains unchanged, so that R C;i  D fC g. If the request for b i results in a \ncache miss, then there are two possibilities. If th e cache is not full ( jC j <k), then \nthe  cache  is \u00fblling  up  and  the  only  choice  is to insert  b i into the cache, so that \nR C;i  D fC [ fb i gg. If the cache is full ( jC j D  k) upon a cache miss, then R C;i  \ncontains k potential  con\u00fbgurations:  one  for  each  candidate  block  in C that could be \nevicted and replaced by block b i . In this case, R C;i  D f.C  \ue003 fx g/ [ fb i g W  x 2 C g. \nFor example, if C D fp;q;r  g, k D 3, and block s is requested, then R C;i  D \nffp;q;s  g ; fp;r;s  g ; fq;r;s  gg. \nLet miss.C;i/  denote the minimum number of cache misses in a solu tion for \nsubproblem .C;i/ . Here is a recurrence for miss.C;i/ : \nmiss.C;i/  D \u201e \n0 if i D n and b n 2 C ;  \n1 if i D n and b n 62 C ;  \nmiss.C;i  C 1/ if i<n  and b i 2 C ;  \n1 C min fmiss.C  0 ;i C 1/ W C 0 2 R C;i  g if i<n  and b i 62 C :  \nGreedy-choice  property  \nTo  prove  that  the  furthest-in-future  strategy  yields  an optimal solution, we need to \nshow  that  optimal  of\u00fcine  caching  exhibits  the  greedy-choic e property. Combined \nwith  the  optimal-substructure  property,  the  greedy-choic e property will prove that \nfurthest-in-future  produces  the  minimum  possible  number  of cache misses. \nTheorem  15.5  (Optimal  of\u00fcine  caching  has  the  greedy-choice  property)  \nConsider a subproblem .C;i/  when the cache C contains k blocks, so that it is \nfull, and a cache miss occurs. When block b i is requested, let \u00b4 D b m be the block \nin C whose next access is furthest in the future. (If so me block in the cache will \nnever again be referenced, then consider any such b lock to be block \u00b4, and add a \ndummy request for block \u00b4 D b m D b nC1 .) Then evicting block \u00b4 upon a request \nfor block b i is included in some optimal solution for the subpro blem .C;i/ . \nProof  Let S be an optimal solution to subproblem .C;i/ . If S evicts block \u00b4 \nupon the request for block b i , then we are done, since we have shown that some \noptimal solution includes evicting \u00b4. \nSo now suppose that optimal solution S evicts some other block x when block b i \nis requested.  We\u2019ll  construct  another  solution  S 0 to subproblem .C;i/  which, upon 15.4  Of\ufb02ine  caching  443 \nthe request for b i , evicts block \u00b4 instead of x and induces no more cache misses \nthan S does, so that S 0 is also optimal. Because different solutions may yi eld \ndifferent  cache  con\u00fbgurations,  denote  by  C S;j  the  con\u00fbguration  of the  cache  under  \nsolution S just before the request for some block b j , and likewise for solution S 0 \nand C S 0 ;j . We\u2019ll  show  how  to construct  S 0 with the following properties: \n1. For  j D i C 1;:::;m , let D j D C S;j  \\ C S 0 ;j . Then, jD j j \ue004  k \ue003 1, so that the \ncache  con\u00fbgurations  C S;j  and C S 0 ;j differ by at most one block. If they differ, \nthen C S;j  D D j [ f\u00b4g and C S 0 ;j D D j [ fy g for some block y \u00a4 \u00b4. \n2. For each request of blocks b i ;:::;b  m\ue0021 , if solution S has a cache hit, then \nsolution S 0 also has a cache hit. \n3. For  all  j >m, the  cache  con\u00fbgurations  C S;j  and C S 0 ;j are identical. \n4. Over  the  sequence  of requests  for  blocks  b i ;:::;b  m , the number of cache misses \nproduced by solution S 0 is at most  the  number  of cache  misses  produced  by  so-  \nlution S . \nWe\u2019ll  prove  inductively  that  these  properties  hold  for  each  request. \n1. We  proceed  by  induction  on  j , for j D i C 1;:::;m. For  the  base  case,  the  ini-  \ntial caches C S;i  and C S 0 ;i are identical. Upon the request for block b i , solution S \nevicts x and solution S 0 evicts \u00b4. Thus,  cache  con\u00fbgurations  C S;i  C1 and C S 0 ;i C1 \ndiffer by just one block, C S;i  C1 D D i C1 [ f\u00b4g, C S 0 ;i C1 D D i C1 [ fx g, and \nx \u00a4 \u00b4. \nThe  inductive  step  de\u00fbnes  how  solution  S 0 behaves upon a request for block b j \nfor i C 1 \u0dc4 j \u0dc4 m \ue003 1. The  inductive  hypothesis  is that  property  1 holds  when  \nb j is requested. Because \u00b4 D b m is the block in C S;i  whose next reference is \nfurthest in the future, we know that b j \u00a4 \u00b4. We consider several scenarios: \n\ue001 If C S;j  D C S 0 ;j (so that jD j j D  k), then solution S 0 makes the same decision \nupon the request for b j as S makes, so that C S;j  C1 D C S 0 ;j C1 . \n\ue001 If jD j j D  k \ue003 1 and b j 2 D j , then both caches already contain block b j , \nand both solutions S and S 0 have cache hits. Therefore, C S;j  C1 D C S;j  and \nC S 0 ;j C1 D C S 0 ;j . \n\ue001 If jD j j D  k \ue003 1 and b j \u2026 D j , then because C S;j  D D j [ f\u00b4g and b j \u00a4 \u00b4, \nsolution S has a cache miss. It evicts either block \u00b4 or some block w 2 D j . \nB If solution S evicts block \u00b4, then C S;j  C1 D D j [ fb j g. There are two \ncases, depending on whether b j D y : \n\u02d8 If b j D y , then solution S 0 has a cache hit, so that C S 0 ;j C1 D \nC S 0 ;j D D j [ fb j g. Thus, C S;j  C1 D C S 0 ;j C1 . \n\u02d8 If b j \u00a4 y , then solution S 0 has a cache miss. It evicts block y , so \nthat C S 0 ;j C1 D D j [ fb j g, and again C S;j  C1 D C S 0 ;j C1 . 444  Chapter  15  Greedy  Algorithms  \nB If solution S evicts some block w 2 D j , then C S;j  C1 D .D  j \ue003 fwg/ [ \nfb j ;\u00b4g. Once  again,  there  are  two  cases,  depending  on  whether  b j D y : \n\u02d8 If b j D y , then solution S 0 has a cache hit, so that C S 0 ;j C1 D \nC S 0 ;j D D j [ fb j g. Since w 2 D j and w was  not  evicted  by  solu-  \ntion S 0 , we have w 2 C S 0 ;j C1 . Therefore, w \u2026 D j C1 and b j 2 D j C1 , \nso that D j C1 D .D  j \ue003 fwg/ [ fb j g. Thus, C S;j  C1 D D j C1 [ f\u00b4g, \nC S 0 ;j C1 D D j C1 [ fwg, and because w \u00a4 \u00b4, property  1 holds  when  \nblock b j C1 is requested. (In other words, block w replaces block y \nin property  1.)  \n\u02d8 If b j \u00a4 y , then solution S 0 has a cache miss. It evicts block w, \nso that C S 0 ;j C1 D .D  j \ue003 fwg/ [ fb j ;y  g. Therefore, we have that \nD j C1 D .D  j \ue003 fwg/ [ fb j g and so C S;j  C1 D D j C1 [ f\u00b4g and \nC S 0 ;j C1 D D j C1 [ fy g. \n2. In the  above  discussion  about  maintaining  property  1, solution S may have a \ncache  hit  in only  the  \u00fbrst  two  cases,  and  solution  S 0 has a cache hit in these \ncases if and only if S does. \n3. If C S;m  D C S 0 ;m  , then solution S 0 makes the same decision upon the request for \nblock \u00b4 D b m as S makes, so that C S;mC1 D C S 0 ;mC1 . If C S;m  \u00a4 C S 0 ;m  , then by \nproperty  1, C S;m  D D m [f\u00b4g and C S 0 ;m  D D m [fy g, where y \u00a4 \u00b4. In this case, \nsolution S has a cache hit, so that C S;mC1 D C S;m  D D m [ f\u00b4g. Solution S 0 \nevicts block y and brings in block \u00b4, so that C S 0 ;mC1 D D m [ f\u00b4g D  C S;mC1 . \nThus, regardless of whether or not C S;m  D C S 0 ;m  , we have C S;mC1 D C S 0 ;mC1 , \nand starting with the request for block b mC1 , solution S 0 simply makes the same \ndecisions as S . \n4. By  property  2, upon  the  requests  for  blocks  b i ;:::;b  m\ue0021 , whenever solution S \nhas a cache hit, so does S 0 . Only  the  request  for  block  b m D \u00b4 remains to be \nconsidered. If S has a cache miss upon the request for b m , then regardless of \nwhether S 0 has a cache hit or a cache miss, we are done: S 0 has at most the \nsame number of cache misses as S . \nSo now suppose that S has a cache hit and S 0 has  a cache  miss  upon  the  re-  \nquest for b m . We\u2019ll  show  that  there  exists  a request  for  at least  one  of blocks \nb i C1 ;:::;b  m\ue0021 in which the request results in a cache miss for S and a cache hit \nfor S 0 , thereby compensating for what happens upon the re quest for block b m . \nThe proof is by contradiction. Assume that no reque st for blocks b i C1 ;:::;b  m\ue0021 \nresults in a cache miss for S and a cache hit for S 0 . \nWe start by observing that once the caches C S;j  and C S 0 j are equal for some \nj > i  , they  remain  equal  thereafter.  Observe  also  that  if b m 2 C S;m  and \nb m \u2026 C S 0 ;m  , then C S;m  \u00a4 C S 0 ;m  . Therefore, solution S cannot have evicted \nblock \u00b4 upon the requests for blocks b i ;:::;b  m\ue0021 , for if it had, then these two 15.4  Of\ufb02ine  caching  445 \ncache  con\u00fbgurations  would  be equal.  The  remaining  possibil ity is that upon \neach of these requests, we had C S;j  D D j [ f\u00b4g, C S 0 ;j D D j [ fy g for some \nblock y \u00a4 \u00b4, and solution S evicted some block w 2 D j . Moreover, since none \nof these requests resulted in a cache miss for S and a cache hit for S 0 , the case of \nb j D y never occurred. That is, for every request of block s b i C1 ;:::;b  m\ue0021 , the \nrequested block b j was never the block y 2 C S 0 ;j \ue003 C S;j  . In these cases, after \nprocessing the request, we had C S 0 ;j C1 D D j C1 [ fy g: the difference between \nthe  two  caches  did  not  change.  Now,  let\u2019s  go  back  to the  reques t for block b i , \nwhere afterward, we had C S 0 ;i C1 D D i C1 [ fx g. Because every succeeding \nrequest until requesting block b m did not change the difference between the \ncaches, we had C S 0 ;j D D j [ fx g for j D i C 1;:::;m . \nBy  de\u00fbnition,  block  \u00b4 D b m is requested after block x . That means at least \none of blocks b i C1 ;:::;b  m\ue0021 is block x . But for j D i C 1;:::;m , we have \nx 2 C S 0 ;j and x \u2026 C S;j  , so that at least one of these requests had a cach e hit \nfor S 0 and a cache miss for S , a contradiction. We conclude that if solution S \nhas a cache hit and solution S 0 has a cache miss upon the request for block b m , \nthen some earlier request had the opposite result, and so solution S 0 produces \nno more cache misses than solution S . Since S is assumed to be optimal, S 0 is \noptimal as well. \nAlong  with  the  optimal-substructure  property,  Theorem  15.5  tells  us that  the  \nfurthest-in-future  strategy  yields  the  minimum  number  of cache misses. \nExercises  \n15.4-1  \nWrite  pseudocode  for  a cache  manager  that  uses  the  furthest-in-future  strategy.  It \nshould take as input a set C of blocks in the cache, the number of blocks k that the \ncache can hold, a sequence b 1 ;b  2 ;:::;b  n of requested blocks, and the index i into \nthe sequence for the block b i being requested. For each request, it should print out \nwhether a cache hit or cache miss occurs, and for e ach cache miss, it should also \nprint out which block, if any, is evicted. \n15.4-2  \nReal cache managers do not know the future requests , and so they often use the \npast to decide which block to evict. The least-recently-used , or LRU , strategy \nevicts the block that, of all blocks currently in t he cache, was the least recently \nrequested.  (You  can  think  of LRU  as <furthest-in-past.=)  Give an example of a \nrequest sequence in which the LRU strategy is not o ptimal, by showing that it \ninduces  more  cache  misses  than  the  furthest-in-future  strategy does on the same \nrequest sequence. 446  Chapter  15  Greedy  Algorithms  \n15.4-3  \nProfessor  Croesus  suggests  that  in the  proof  of Theorem  15.5, the last clause in \nproperty  1 can  change  to C S 0 ;j D D j [ fx g or, equivalently, require the block y \ngiven  in property  1 to always  be the  block  x evicted by solution S upon the request \nfor block b i . Show where the proof breaks down with this requir ement. \n15.4-4  \nThis section has assumed that at most one block is placed into the cache whenever a \nblock is requested. You can imagine, however, a str ategy in which multiple blocks \nmay enter the cache upon a single request. Show tha t for every solution that allows \nmultiple blocks to enter the cache upon each reques t, there is another solution that \nbrings in only one block upon each request and is a t least as good. \nProblems  \n15-1  Coin  changing  \nConsider the problem of making change for n cents using the smallest number of \ncoins.  Assume  that  each  coin\u2019s  value  is an integer.  \na. Describe a greedy algorithm to make change consisti ng of quarters, dimes, \nnickels, and pennies. Prove that your algorithm yie lds an optimal solution. \nb. Suppose that the available coins are in denominatio ns that are powers of c : the \ndenominations are c 0 ;c 1 ;:::;c  k for some integers c>1  and k \ue004 1. Show that \nthe greedy algorithm always yields an optimal solut ion. \nc. Give  a set  of coin  denominations  for  which  the  greedy  algorit hm does not yield \nan optimal solution. Your set should include a penn y so that there is a solution \nfor every value of n. \nd. Give  an O.nk/-time  algorithm  that  makes  change  for  any  set  of k different \ncoin denominations using the smallest number of coi ns, assuming that one of \nthe coins is a penny. \n15-2  Scheduling  to minimize  average  completion  time  \nYou are given a set S D fa 1 ;a  2 ;:::;a  n g of tasks, where task a i requires p i units of \nprocessing time to complete. Let C i be the completion  time  of task a i , that is, the \ntime at which task a i completes processing. Your goal is to minimize the average \ncompletion time, that is, to minimize .1=n/  P  n \ni D1 C i . For example, suppose that \nthere are two tasks a 1 and a 2 with p 1 D 3 and p 2 D 5, and consider the schedule Notes for Chapter 15 447 \nin which a 2 runs  \u00fbrst,  followed  by  a 1 . Then we have C 2 D 5, C 1 D 8, and the \naverage completion time is .5 C 8/=2  D 6:5. If task a 1 runs  \u00fbrst,  however,  then  we  \nhave C 1 D 3, C 2 D 8, and the average completion time is .3 C 8/=2  D 5:5. \na. Give  an algorithm  that  schedules  the  tasks  so as to minimize  the  average  com-  \npletion time. Each task must run nonpreemptively, t hat is, once task a i starts, it \nmust run continuously for p i units  of time  until  it is done.  Prove  that  your  al-  \ngorithm minimizes the average completion time, and analyze the running time \nof your algorithm. \nb. Suppose now that the tasks are not all available at  once. That is, each task \ncannot start until its release  time  b i . Suppose also that tasks may be preempted , \nso that a task can be suspended and restarted at a later time. For example, a \ntask a i with processing time p i D 6 and release time b i D 1 might start running \nat time  1 and  be preempted  at time  4. It might  then  resume  at time  10  but  be \npreempted  at time  11,  and  it might  \u00fbnally  resume  at time  13  and  complete at \ntime  15.  Task  a i has  run  for  a total  of 6 time  units,  but  its  running  time  has  \nbeen  divided  into  three  pieces.  Give  an algorithm  that  sched ules the tasks so as \nto minimize the average completion time in this new  scenario. Prove that your \nalgorithm minimizes the average completion time, an d analyze the running time \nof your algorithm. \nChapter  notes  \nMuch more material on greedy algorithms can be foun d in Lawler [276]  and  Pa-  \npadimitriou  and  Steiglitz  [353].  The  greedy  algorithm  \u00fbrst  appeared  in the  combi-  \nnatorial  optimization  literature  in a 1971  article  by  Edmonds  [131].  \nThe proof of correctness of the greedy algorithm fo r the activity-selection  prob-  \nlem  is based  on  that  of Gavril  [179].  \nHuffman  codes  were  invented  in 1952  [233].  Lelewer  and  Hirschberg  [294]  \nsurveys  data-compression  techniques  known  as of 1987.  \nThe  furthest-in-future  strategy  was  proposed  by  Belady  [41], who suggested it \nfor  virtual-memory  systems.  Alternative  proofs  that  furthest-in-future  is optimal  \nappear  in articles  by  Lee  et al.  [284]  and  Van  Roy  [443].  16  Amortized  Analysis  \nImagine  that  you  join  Buff\u2019s  Gym.  Buff  charges  a membership  fee of $60  per \nmonth, plus $ 3 for every time you use the gym. Because you are dis ciplined, \nyou  visit  Buff\u2019s  Gym  every  day  during  the  month  of November.  On top of the \n$60  monthly charge for November, you pay another 3 \ue005 $30  D $90  that month. \nAlthough  you  can  think  of your  fees  as a \u00fcat  fee  of $60  and another $90  in daily \nfees, you can think about it in another way. All to gether, you pay $ 150  over 30  \ndays, or an average of $ 5 per day. When you look at your fees in this way, yo u are \namortizing  the monthly fee over the 30  days of the month, spreading it out at $ 2 \nper day. \nYou can do the same thing when you analyze running times. In an amortized  \nanalysis, you  average  the  time  required  to perform  a sequence  of data- structure \noperations over all the operations performed. With amortized analysis, you show \nthat if you average over a sequence of operations, then the average  cost  of an oper-  \nation is small, even though a single operation with in the sequence  might  be expen-  \nsive.  Amortized  analysis  differs  from  average-case  analys is in that probability is \nnot involved. An amortized analysis guarantees the average  performance  of each  \noperation  in the  worst  case. \nThe  \u00fbrst  three  sections  of this  chapter  cover  the  three  most  common techniques \nused  in amortized  analysis.  Section  16.1  starts  with  aggreg ate analysis, in which \nyou determine an upper bound T.n/  on the total cost of a sequence of n operations. \nThe average cost per operation is then T.n/=n . You take the average cost as the \namortized cost of each operation, so that all opera tions have the same amortized \ncost. \nSection  16.2  covers  the  accounting  method,  in which  you  determine  an amor-  \ntized cost of each operation. When there is more th an one type of operation, each \ntype of operation may have a different amortized co st. The accounting method \novercharges some operations early in the sequence, storing the  overcharge  as <pre-  16.1  Aggregate  analysis  449 \npaid  credit=  on  speci\u00fbc  objects  in the  data  structure.  Later  in the sequence, the \ncredit pays for operations that are charged less th an they actually cost. \nSection  16.3  discusses  the  potential  method,  which  is like  the accounting method \nin that you determine the amortized cost of each op eration and may  overcharge  op-  \nerations early on to compensate for undercharges la ter. The potential  method  main-  \ntains the credit as the <potential energy= of the d ata structure as a whole instead of \nassociating the credit with individual objects with in the data structure. \nWe\u2019ll  use  use  two  examples  in this  chapter  to examine  each  of these  three  meth-  \nods.  One  is a stack  with  the  additional  operation  MULTIPOP , which pops several \nobjects at once. The other is a binary counter that  counts up from 0 by means of \nthe single operation I NCREMENT . \nWhile reading this chapter, bear in mind that the c harges assigned during an \namortized analysis are for analysis purposes only. They need not4and  should  not  \n4appear  in the  code.  If, for  example,  you  assign  a credit  to an object x when using \nthe accounting method, you have no need to assign a n appropriate amount to some \nattribute, such as x: credit  , in the code. \nWhen you perform an amortized analysis, you often g ain insight into a particular \ndata structure, and this insight can help you optim ize the design. For example, \nSection  16.4  will  use  the  potential  method  to analyze  a dynam ically expanding and \ncontracting table. \n16.1  Aggregate  analysis  \nIn aggregate  analysis , you show that for all n, a sequence of n operations takes \nT.n/  worst-case  time in total. In the worst case, the average cost,  or amortized  cost, \nper operation is therefore T.n/=n . This amortized cost applies to each operation, \neven when there are several types of operations in the sequence. The other two \nmethods we shall study in this chapter, the account ing method and the potential \nmethod, may assign different amortized costs to dif ferent types of operations. \nStack  operations  \nAs  the  \u00fbrst  example  of aggregate  analysis,  let\u2019s  analyze  stacks  that  have  been  aug-  \nmented  with  a new  operation.  Section  10.1.3  presented  the  two fundamental stack \noperations, each of which takes O.1/  time: \nPUSH.S;x/  pushes object x onto stack S . \nPOP.S/  pops the top of stack S and returns the popped object. Calling P OP  on an \nempty stack generates an error. 450  Chapter  16  Amortized  Analysis  \n23  \n17  \n6 \n39  \n10  \n47  \n(a) top \n10  \n47  \n(b) top \n(c) \nFigure  16.1  The action of M ULTIPOP  on a stack S , shown initially in (a). The top 4 objects are \npopped by M ULTIPOP.S;4/ , whose result is shown in (b). The next operation is M ULTIPOP.S;7/ , \nwhich  empties  the  stack4shown  in (c)4since  fewer  than  7 objects remained. \nSince each of these operations runs in O.1/  time, let us consider the cost of each \nto be 1. The total cost of a sequence of n PUSH and POP  operations is therefore n, \nand the actual running time for n operations is therefore \u201a.n/ . \nNow  let\u2019s  add  the  stack  operation  MULTIPOP  .S;k/ , which removes the k top  ob-  \njects of stack S , popping the entire stack if the stack contains fe wer than k objects. \nOf  course,  the  procedure  assumes  that  k is positive, and otherwise, the M ULTIPOP  \noperation leaves the stack unchanged. In the pseudo code for M ULTIPOP, the  op-  \neration STAC  K-EMPTY returns TRUE if there are no objects currently on the stack, \nand FALSE otherwise.  Figure  16.1  shows  an example  of MULTIPOP . \nMULTIPOP  .S;k/  \n1 while  not STAC  K-EMPTY .S/  and k>0  \n2 POP.S/  \n3 k D k \ue003 1 \nWhat is the running time of M ULTIPOP  .S;k/  on a stack of s objects?  The  \nactual running time is linear in the number of P OP  operations actually executed, \nand thus we can analyze M ULTIPOP  in terms of the abstract costs of 1 each for \nPUSH and POP. The number of iterations of the while  loop is the number min fs;kg \nof objects popped off the stack. Each iteration of the loop makes one call to P OP  in \nline 2. Thus, the total cost of M ULTIPOP  is min fs;kg, and the actual running time \nis a linear function of this cost. \nNow  let\u2019s  analyze  a sequence  of n PUSH, POP, and MULTIPOP  operations on \nan initially  empty  stack.  The  worst-case  cost  of a MULTIPOP  operation in the \nsequence is O.n/ , since the stack size is at most n. The  worst-case  time  of any  stack  \noperation is therefore O.n/ , and hence a sequence of n operations costs O.n  2 /, \nsince the sequence contains at most n MULTIPOP  operations costing O.n/  each. 16.1  Aggregate  analysis  451 \nAlthough this analysis is correct, the O.n  2 / result, which came from considering \nthe  worst-case  cost  of each  operation  individually,  is not  tight. \nYes, a single M ULTIPOP  might be expensive, but an aggregate analysis shows  \nthat any sequence of n PUSH, POP, and MULTIPOP  operations on an initially empty \nstack has an upper bound on its cost of O.n/. Why?  An  object  cannot  be popped  \nfrom  the  stack  unless  it was  \u00fbrst  pushed.  Therefore,  the  numb er of times that P OP  \ncan be called on a nonempty stack, including calls within MULTIPOP , is at most the \nnumber of P USH operations, which is at most n. For any value of n, any sequence \nof n PUSH, POP, and MULTIPOP  operations takes a total of O.n/  time. Averaging \nover the n operations gives an average cost per operation of O.n/=n  D O.1/ . \nAggregate analysis assigns the amortized cost of ea ch operation to be the average \ncost. In this example, therefore, all three stack o perations have an amortized cost \nof O.1/ . \nTo recap: although the average cost, and hence the running time, of a stack \noperation is O.1/ , the analysis did not rely on probabilistic reason ing. Instead, \nthe analysis yielded a worst-case  bound of O.n/  on a sequence of n operations. \nDividing this total cost by n yielded  that  the  average  cost  per  operation4that  is, \nthe  amortized  cost4is  O.1/ . \nIncrementing  a binary  counter  \nAs another example of aggregate analysis, consider the problem of implementing \na k-bit  binary  counter  that  counts  upward  from  0. An array A\u01520  W k \ue003 1\ufffd of bits  rep-  \nresents the counter. A binary number x that  is stored  in the  counter  has  its  lowest-  \norder bit in A\u01520\ufffd  and  its  highest-order  bit  in A\u0152k  \ue003 1\ufffd, so that x D P  k\ue0021 \ni D0 A\u0152i\ufffd  \ue001 2 i . \nInitially, x D 0, and thus A\u0152i\ufffd  D 0 for i D 0;1;:::;k  \ue003 1. To add 1 (modulo 2 k ) \nto the value in the counter, call the I NCREMENT procedure. \nI NCREMENT.A;k/  \n1 i D 0 \n2 while  i<k  and A\u0152i\ufffd  == 1 \n3 A\u0152i\ufffd  D 0 \n4 i D i C 1 \n5 if i<k  \n6 A\u0152i\ufffd  D 1 \nFigure  16.2  shows  what  happens  to a binary  counter  when  I NCREMENT is called \n16  times, starting with the initial value 0 and ending with the value 16. Each \niteration of the while  loop  in lines  234  adds  a 1 into position i . If A\u0152i\ufffd  D 1, then \nadding 1 \u00fcips  the  bit  to 0 in position i and yields a carry of 1, to be added into 452  Chapter  16  Amortized  Analysis  \n0 0 0 0 0 0 0 0 0 \n0 0 0 0 0 0 0 1  1 \n0 0 0 0 0 0 1 0  2 \n0 0 0 0 0 0 1 1  3 \n0 0 0 0 0 1 0 0  4 \n0 0 0 0 0 1 0 1  5 \n0 0 0 0 0 1 1 0  6 \n0 0 0 0 0 1 1 1  7 \n0 0 0 0 1 0 0 0  8 \n0 0 0 0 1 0 0 1  9 \n0 0 0 0 1 0 1 0  10  \n0 0 0 0 1 0 1 1  11  \n0 0 0 0 1 1 0 0  12  \n0 0 0 0 1 1 0 1  13  \n0 0 0 0 1 1 1 0  14  \n0 0 0 0 1 1 1 1  15  \n0 0 0 1 0 0 0 0  16  A[0] A[1] \nA[2] A[3] \nA[4] \nA[5] \nA[6] \nA[7] Counter \nvalue Total \ncost \n1 \n3 \n4 \n7 \n8 \n10  \n11  \n15  \n16  \n18  \n19  \n22 \n23  \n25  \n26  \n31  0 \nFigure  16.2  An 8-bit  binary  counter  as its  value  goes  from  0 to 16  by a sequence of 16  I NCREMENT \noperations.  Bits  that  \u00fcip  to achieve  the  next  value  are  shaded  in blue.  The  running  cost  for  \u00fcipping  \nbits is shown at the right. The total cost is alway s less than twice the total number of I NCREMENT \noperations. \nposition i C 1 during  the  next  iteration  of the  loop.  Otherwise,  the  loop  ends, and \nthen, if i <k , A\u0152i\ufffd  must be 0, so that  line  6 adds  a 1 into position i , \u00fcipping  the  0 \nto a 1. If the loop ends with i D k, then the call of I NCREMENT \u00fcipped  all  k bits \nfrom 1 to 0. The cost of each I NCREMENT operation is linear in the number of bits \n\u00fcipped.  \nAs with the stack example, a cursory analysis yield s a bound that is correct but \nnot tight. A single execution of I NCREMENT takes \u201a.k/  time in the worst case, in \nwhich all the bits in array A are 1. Thus, a sequence of n I NCREMENT operations \non an initially zero counter takes O.nk/  time in the worst case. \nAlthough a single call of I NCREMENT might  \u00fcip  all  k bits,  not  all  bits  \u00fcip  upon  \neach call. (Note the similarity to M ULTIPOP , where a single call might pop many \nobjects,  but  not  every  call  pops  many  objects.)  As  Figure  16.2 shows, A\u01520\ufffd  does  \u00fcip  \neach time I NCREMENT is called. The next bit up, A\u01521\ufffd, \u00fcips  only  every  other  time:  \na sequence of n I NCREMENT operations on an initially zero counter causes A\u01521\ufffd  to \n\u00fcip  bn=2c times. Similarly, bit A\u01522\ufffd  \u00fcips  only  every  fourth  time,  or bn=4c times in a \nsequence of n I NCREMENT operations. In general, for i D 0;1;:::;k  \ue003 1, bit A\u0152i\ufffd  \n\u00fcips  bn=2  i c times in a sequence of n I NCREMENT operations on an initially zero \ncounter. For i \ue004 k, bit A\u0152i\ufffd  does  not  exist,  and  so it cannot  \u00fcip.  The  total  number  16.2  The  accounting  method  453 \nof \u00fcips  in the  sequence  is thus  \nk\ue0021 X  \ni D0 j n \n2 i k \n< n  1  X  \ni D0 1 \n2 i \nD 2n;  \nby  equation  (A.7)  on  page  1142.  Thus,  a sequence  of n I NCREMENT operations \non an initially zero counter takes O.n/  time in the worst case. The average cost of \neach operation, and therefore the amortized cost pe r operation, is O.n/=n  D O.1/ . \nExercises  \n16.1-1  \nIf the set of stack operations includes a M ULTIPUSH operation, which pushes k \nitems onto the stack, does the O.1/  bound on the amortized cost of stack operations \ncontinue  to hold?  \n16.1-2  \nShow that if a D ECREMENT operation is included in the k-bit  counter  example,  n \noperations can cost as much as \u201a.nk/  time. \n16.1-3  \nUse aggregate analysis to determine the amortized c ost per operation for a sequence \nof n operations on a data structure in which the i th operation costs i if i is an exact \npower of 2, and 1 otherwise. \n16.2  The  accounting  method  \nIn the accounting  method  of amortized analysis, you assign differing charges  to \ndifferent operations, with some operations charged more or less  than  they  actu-  \nally cost. The amount that you charge an operation is its amortized  cost. When \nan operation\u2019s  amortized  cost  exceeds  its  actual  cost,  you  assign the difference to \nspeci\u00fbc  objects  in the  data  structure  as credit. Credit  can  help  pay  for  later  oper-  \nations whose amortized cost is less than their actu al cost. Thus, you can view the \namortized cost of an operation as being split betwe en its actual cost and credit that \nis either deposited or used up. Different operation s may have different amortized \ncosts. This method differs from aggregate analysis,  in which all operations have \nthe same amortized cost. \nYou must choose the amortized costs of operations c arefully. If you want to use \namortized costs to show that in the worst case the average cost per operation is 454  Chapter  16  Amortized  Analysis  \nsmall, you must ensure that the total amortized cos t of a sequence of operations \nprovides an upper bound on the total actual cost of  the sequence. Moreover, as \nin aggregate analysis, the upper bound must apply t o all sequences of operations. \nLet\u2019s  denote  the  actual  cost  of the  i th operation by c i and the amortized cost of the \ni th operation by y c i . Then you need to have \nn X  \ni D1 y c i \ue004 n X  \ni D1 c i (16.1)  \nfor all sequences of n operations. The total credit stored in the data str ucture \nis the difference between the total amortized cost and the total actual cost, or P  n \ni D1 y c i \ue003 P  n \ni D1 c i . By  inequality  (16.1),  the  total  credit  associated  with  the  data \nstructure must be nonnegative at all times. If you ever allowed the total credit to \nbecome negative (the result of undercharging early operations with the promise of \nrepaying the account later on), then the total amor tized costs incurred at that time \nwould be below the total actual costs incurred. In that case, for the sequence of \noperations up to that time, the total amortized cos t would not be an upper bound \non the total actual cost. Thus, you must take care that the total credit in the data \nstructure never becomes negative. \nStack  operations  \nTo illustrate the accounting method of amortized an alysis, we return to the stack \nexample. Recall that the actual costs of the operat ions were \nPUSH 1,  \nPOP  1,  \nMULTIPOP  min fs;kg , \nwhere k is the argument supplied to M ULTIPOP  and s is the stack size when it is \ncalled. Let us assign the following amortized costs : \nPUSH 2 , \nPOP  0 , \nMULTIPOP  0 . \nThe amortized cost of M ULTIPOP  is a constant (0), whereas  the  actual  cost  is vari-  \nable, and thus all three amortized costs are consta nt. In general, the amortized \ncosts of the operations under consideration may dif fer from each other, and they \nmay even differ asymptotically. \nNow  let\u2019s  see  how  to pay  for  any  sequence  of stack  operations  by charging the \namortized costs. Let $ 1 represent  each  unit  of cost.  At  \u00fbrst,  the  stack  is empty.  \nRecall  the  analogy  of Section  10.1.3  between  the  stack  data  structure and a stack \nof plates in a cafeteria. Upon pushing a plate onto  the stack, use $ 1 to pay the 16.2  The  accounting  method  455 \nactual cost of the push, leaving a credit of $ 1 (out of the $2 charged). Place that $ 1 \nof credit on top of the plate. At any point in time , every plate on the stack has $ 1 \nof credit on it. \nThe $1 stored on the plate serves to prepay the cost of po pping the plate from \nthe stack. A P OP  operation incurs no charge: pay the actual cost of popping a plate \nby taking the $ 1 of credit off the plate. Thus, by charging the P USH operation a \nlittle bit more, we can view the P OP  operation as free. \nMoreover, the M ULTIPOP  operation  also  incurs  no  charge,  since  it\u2019s  just  repeated  \nPOP  operations, each of which is free. If a M ULTIPOP  operation pops k plates, then \nthe actual cost is paid by the k dollars stored on the k plates. Because each plate \non the stack has $ 1 of credit on it, and the stack always has a nonnega tive number \nof plates, the amount of credit is always nonnegati ve. Thus, for any  sequence of n \nPUSH, POP, and MULTIPOP  operations, the total amortized cost is an upper bo und \non the total actual cost. Since the total amortized  cost is O.n/ , so is the total actual \ncost. \nIncrementing  a binary  counter  \nAs  another  illustration  of the  accounting  method,  let\u2019s  analyze the I NCREMENT \noperation on a binary counter that starts at 0. Recall that the running time of this \noperation  is proportional  to the  number  of bits  \u00fcipped,  whic h serves as the cost for \nthis  example.  Again,  we\u2019ll  use  $1 to represent  each  unit  of cost  (the  \u00fcipping  of a \nbit in this example). \nFor the amortized analysis, the amortized cost to s et a 0-bit  to 1 is $2. When a \nbit is set to 1, $1 of the $2 pays to actually set the bit. The second $ 1 resides on the \nbit as credit to be used later if and when the bit is reset to 0. At any point in time, \nevery 1-bit  in the  counter  has  $1 of credit on it, and thus resetting a bit to 0 can be \nviewed as costing nothing, and the $ 1 on the bit prepays for the reset. \nHere is how to determine the amortized cost of I NCREMENT. The  cost  of reset-  \nting the bits to 0 within the while  loop is paid for by the dollars on the bits that ar e \nreset. The I NCREMENT procedure sets at most one bit to 1, in line  6, and  there-  \nfore the amortized cost of an I NCREMENT operation is at most $ 2. The number of \n1-bits  in the  counter  never  becomes  negative,  and  thus  the  amount of credit stays \nnonnegative at all times. Thus, for n I NCREMENT operations, the total amortized \ncost is O.n/ , which bounds the total actual cost. \nExercises  \n16.2-1  \nYou perform a sequence of P USH and POP  operations on a stack whose size never \nexceeds k. After every k operations,  a copy  of the  entire  stack  is made  automat-  456  Chapter  16  Amortized  Analysis  \nically, for backup purposes. Show that the cost of n stack operations, including \ncopying the stack, is O.n/  by assigning suitable amortized costs to the variou s \nstack operations. \n16.2-2  \nRedo  Exercise  16.1-3  using  an accounting  method  of analysis . \n16.2-3  \nYou wish not only to increment a counter but also t o reset it to 0 (i.e., make all \nbits in it 0). Counting the time to examine or modify a bit as \u201a.1/ , show how \nto implement a counter as an array of bits so that any sequence of n I NCREMENT \nand R ESET operations takes O.n/  time on an initially zero counter. ( Hint: Keep  a \npointer  to the  high-order  1.) \n16.3  The  potential  method  \nInstead of representing prepaid work as credit stor ed with speci\u00fbc  objects  in the  \ndata structure, the potential  method  of amortized analysis represents the prepaid \nwork as <potential energy,= or just <potential,= wh ich can be released to pay for \nfuture operations. The potential applies to the dat a structure as a whole rather than \nto speci\u00fbc  objects  within  the  data  structure.  \nThe potential method works as follows. Starting wit h an initial data structure D 0 , \na sequence of n operations occurs. For each i D 1;2;:::;n , let c i be the actual \ncost of the i th operation and D i be the data structure that results after applying \nthe i th operation to data structure D i \ue0021 . A potential  function  \u02c6 maps each data \nstructure D i to a real number \u02c6.D  i /, which is the potential  associated with D i . \nThe amortized  cost  y c i of the i th operation with respect to potential function \u02c6 is \nde\u00fbned  by  \ny c i D c i C \u02c6.D  i / \ue003 \u02c6.D  i \ue0021 /: (16.2)  \nThe amortized cost of each operation is therefore i ts actual cost plus the change in \npotential  due  to the  operation.  By  equation  (16.2),  the  total amortized cost of the n \noperations is \nn X  \ni D1 y c i D n X  \ni D1 .c i C \u02c6.D  i / \ue003 \u02c6.D  i \ue0021 // \nD n X  \ni D1 c i C \u02c6.D  n / \ue003 \u02c6.D  0 /: (16.3)  16.3 The potential method 457 \nThe  second  equation  follows  from  equation  (A.12)  on  page  1143  because  the  \n\u02c6.D  i / terms telescope. \nIf you  can  de\u00fbne  a potential  function  \u02c6 so that \u02c6.D  n / \ue004 \u02c6.D  0 /, then the total \namortized cost P  n \ni D1 y c i gives an upper bound on the total actual cost P  n \ni D1 c i . \nIn practice,  you  don\u2019t  always  know  how  many  operations  might  be performed. \nTherefore, if you require that \u02c6.D  i / \ue004 \u02c6.D  0 / for all i , then you guarantee, as in \nthe  accounting  method,  that  you\u2019ve  paid  in advance.  It\u2019s  usually simplest to just \nde\u00fbne  \u02c6.D  0 / to be 0 and then show that \u02c6.D  i / \ue004 0 for all i . (See  Exercise  16.3-1  \nfor an easy way to handle cases in which \u02c6.D  0 / \u00a4 0.) \nIntuitively, if the potential difference \u02c6.D  i / \ue003 \u02c6.D  i \ue0021 / of the i th operation is \npositive, then the amortized cost y c i represents an overcharge to the i th operation, \nand the potential of the data structure increases. If the potential  difference  is neg-  \native, then the amortized cost represents an underc harge to the i th operation, and \nthe decrease in the potential pays for the actual c ost of the operation. \nThe  amortized  costs  de\u00fbned  by  equations  (16.2)  and  (16.3)  depend on the choice \nof the potential function \u02c6. Different  potential  functions  may  yield  different  amor-  \ntized costs, yet still be upper bounds on the actua l costs. You will  often  \u00fbnd  trade-  \noffs that you can make in choosing a potential func tion. The best potential function \nto use depends on the desired time bounds. \nStack  operations  \nTo illustrate the potential method, we return once again to the example of the stack \noperations P USH, POP, and MULTIPOP. We  de\u00fbne  the  potential  function  \u02c6 on a \nstack to be the number of objects in the stack. The  potential of the empty initial \nstack D 0 is \u02c6.D  0 / D 0. Since the number of objects in the stack is never  negative, \nthe stack D i that results after the i th operation has nonnegative potential, and thus \n\u02c6.D  i / \ue004 0 \nD \u02c6.D  0 /: \nThe total amortized cost of n operations with respect to \u02c6 therefore represents an \nupper bound on the actual cost. \nNow  let\u2019s  compute  the  amortized  costs  of the  various  stack  operations. If the i th \noperation on a stack containing s objects is a P USH operation, then the potential \ndifference is \n\u02c6.D  i / \ue003 \u02c6.D  i \ue0021 / D .s C 1/ \ue003 s \nD 1:  \nBy  equation  (16.2),  the  amortized  cost  of this  PUSH operation is 458  Chapter  16  Amortized  Analysis  \ny c i D c i C \u02c6.D  i / \ue003 \u02c6.D  i \ue0021 / \nD 1 C 1 \nD 2:  \nSuppose that the i th operation on the stack of s objects is M ULTIPOP  .S;k/ , which \ncauses k 0 D min fs;kg objects to be popped off the stack. The actual cost  of the \noperation is k 0 , and the potential difference is \n\u02c6.D  i / \ue003 \u02c6.D  i \ue0021 / D \ue003k 0 : \nThus, the amortized cost of the M ULTIPOP  operation is \ny c i D c i C \u02c6.D  i / \ue003 \u02c6.D  i \ue0021 / \nD k 0 \ue003 k 0 \nD 0:  \nSimilarly, the amortized cost of an ordinary P OP  operation is 0. \nThe amortized cost of each of the three operations is O.1/ , and thus the total \namortized cost of a sequence of n operations is O.n/ . Since \u02c6.D  i / \ue004 \u02c6.D  0 /, the \ntotal amortized cost of n operations is an upper bound on the total actual co st. The \nworst-case  cost  of n operations is therefore O.n/ . \nIncrementing  a binary  counter  \nAs another example of the potential method, we revi sit incrementing a k-bit  binary  \ncounter. This time, the potential of the counter af ter the i th I NCREMENT operation \nis de\u00fbned  to be the  number  of 1-bits  in the  counter  after  the  i th operation, which \nwe\u2019ll  denote  by  b i . \nHere is how to compute the amortized cost of an I NCREMENT operation.  Sup-  \npose that the i th I NCREMENT operation resets t i bits to 0. The actual cost c i of the \noperation is therefore at most t i C 1, since in addition to resetting t i bits, it sets at \nmost one bit to 1. If b i D 0, then the i th operation had reset all k bits to 0, and so \nb i \ue0021 D t i D k. If b i >0, then b i D b i \ue0021 \ue003 t i C 1. In either case, b i \u0dc4 b i \ue0021 \ue003 t i C 1, \nand the potential difference is \n\u02c6.D  i / \ue003 \u02c6.D  i \ue0021 / \u0dc4 .b i \ue0021 \ue003 t i C 1/ \ue003 b i \ue0021 \nD 1 \ue003 t i : \nThe amortized cost is therefore \ny c i D c i C \u02c6.D  i / \ue003 \u02c6.D  i \ue0021 / \n\u0dc4 .t i C 1/ C .1 \ue003 t i / \nD 2:  16.3 The potential method 459 \nIf the counter starts at 0, then \u02c6.D  0 / D 0. Since \u02c6.D  i / \ue004 0 for all i , the total \namortized cost of a sequence of n I NCREMENT operations is an upper bound on the \ntotal  actual  cost,  and  so the  worst-case  cost  of n I NCREMENT operations is O.n/ . \nThe potential method provides a simple and clever w ay to analyze the counter \neven when it does not start at 0. The counter starts with b 0 1-bits,  and  after  n \nI NCREMENT operations it has b n 1-bits,  where  0 \u0dc4 b 0 ;b  n \u0dc4 k. Rewrite  equa-  \ntion  (16.3)  as \nn X  \ni D1 c i D n X  \ni D1 y c i \ue003 \u02c6.D  n / C \u02c6.D  0 /: \nSince \u02c6.D  0 / D b 0 , \u02c6.D  n / D b n , and y c i \u0dc4 2 for all 1 \u0dc4 i \u0dc4 n, the total actual \ncost of n I NCREMENT operations is \nn X  \ni D1 c i \u0dc4 n X  \ni D1 2 \ue003 b n C b 0 \nD 2n  \ue003 b n C b 0 : \nIn particular, b 0 \u0dc4 k means that as long as k D O.n/ , the total actual cost is O.n/ . \nIn other words, if at least n D \ufffd.k/  I NCREMENT operations occur, the total actual \ncost is O.n/ , no matter what initial value the counter contains . \nExercises  \n16.3-1  \nSuppose you have a potential function \u02c6 such that \u02c6.D  i / \ue004 \u02c6.D  0 / for all i , but \n\u02c6.D  0 / \u00a4 0. Show that there exists a potential function \u02c6 0 such that \u02c6 0 .D  0 / D 0, \n\u02c6 0 .D  i / \ue004 0 for all i \ue004 1, and the amortized costs using \u02c6 0 are the same as the \namortized costs using \u02c6. \n16.3-2  \nRedo  Exercise  16.1-3  using  a potential  method  of analysis.  \n16.3-3  \nConsider  an ordinary  binary  min-heap  data  structure  suppor ting the instructions \nI NSERT and E XTRACT-MIN that, when there are n items in the heap, implements \neach operation in O.lg n/ worst-case  time.  Give  a potential  function  \u02c6 such that \nthe amortized cost of I NSERT is O.lg n/ and the amortized cost of E XTRACT-MIN \nis O.1/ , and show that your potential function yields thes e amortized time bounds. \nNote that in the analysis, n is the number of items currently in the heap, and y ou \ndo not know a bound on the maximum number of items that can ever be stored in \nthe heap. 460  Chapter  16  Amortized  Analysis  \n16.3-4  \nWhat is the total cost of executing n of the stack operations P USH, POP, and \nMULTIPOP  , assuming that the stack begins with s 0 objects  and  \u00fbnishes  with  s n \nobjects?  \n16.3-5  \nShow how to implement a queue with two ordinary sta cks (Exercise  10.1-7)  so that  \nthe amortized cost of each E NQUEUE  and each D EQUEUE  operation is O.1/ . \n16.3-6  \nDesign a data structure to support the following tw o operations for a dynamic \nmultiset S of integers, which allows duplicate values: \nI NSERT.S;x/  inserts x into S . \nDELETE-LARGER-HALF .S/  deletes the largest djS j =2e elements from S . \nExplain how to implement this data structure so tha t any sequence of m I NSERT \nand D ELETE-LARGER-HALF operations runs in O.m/  time. Your implementation \nshould also include a way to output the elements of  S in O.jS j/ time. \n16.4  Dynamic  tables  \nWhen you design an application that uses a table, y ou do not always know in \nadvance how many items the table will hold. You mig ht allocate space for the \ntable,  only  to \u00fbnd  out  later  that  it is not  enough.  The  program  must then reallocate \nthe table with a larger size and copy all items sto red in the original table over into \nthe new, larger table. Similarly, if many items hav e been deleted from the table, \nit might be worthwhile to reallocate the table with  a smaller size. This section \nstudies this problem of dynamically expanding and c ontracting a table. Amortized \nanalyses will show that the amortized cost of inser tion and deletion is only O.1/ , \neven though the actual cost of an operation is larg e when it triggers an expansion \nor a contraction.  Moreover,  you\u2019ll  see  how  to guarantee  that  the unused space in a \ndynamic table never exceeds a constant fraction of the total space. \nLet\u2019s  assume  that  the  dynamic  table  supports  the  operations  TABLE-I NSERT and \nTABLE-DELETE . TABLE-I NSERT inserts  into  the  table  an item  that  occupies  a sin-  \ngle slot, that is, a space for one item. Likewise, T ABLE-DELETE removes an item \nfrom the table, thereby freeing a slot. The details  of the data-structuring  method  \nused to organize the table are unimportant: it coul d be a stack (Section  10.1.3),  a \nheap  (Chapter  6),  a hash  table  (Chapter  11),  or something  else. 16.4  Dynamic  tables  461 \nIt is convenient  to use  a concept  introduced  in Section  11.2,  where we analyzed \nhashing. The load  factor  \u02db.T/  of a nonempty table T is de\u00fbned  as the  number  \nof items stored in the table divided by the size (n umber of slots) of the table. An \nempty table (one with no slots) has size 0, and  its  load  factor  is de\u00fbned  to be 1. If \nthe load factor of a dynamic table is bounded below  by a constant, the unused space \nin the table is never more than a constant fraction  of the total amount of space. \nWe start by analyzing a dynamic table that allows o nly insertion and then move \non to the more general case that supports both inse rtion and deletion. \n16.4.1  Table  expansion  \nLet\u2019s  assume  that  storage  for  a table  is allocated  as an array  of slots.  A table  \u00fblls  up  \nwhen all slots have been used or, equivalently, whe n its load factor is 1. 1 In some \nsoftware environments, upon an attempt to insert an  item into a full table, the only \nalternative is to abort with an error. The scenario  in this section  assumes,  how-  \never, that the software environment, like many mode rn ones, provides  a memory-  \nmanagement system that can allocate and free blocks  of storage on request. Thus, \nupon inserting an item into a full table, the syste m can expand  the  table  by  allo-  \ncating a new table with more slots than the old tab le had. Because the table must \nalways reside in contiguous memory, the system must  allocate a new array for the \nlarger table and then copy items from the old table  into the new table. \nA common heuristic allocates a new table with twice  as many slots as the old \none. If the only table operations are insertions, t hen the load factor of the table is \nalways at least 1=2, and thus the amount of wasted space never exceeds  half the \ntotal space in the table. \nThe T ABLE-I NSERT procedure on the following page assumes that T is an object \nrepresenting the table. The attribute T: table contains a pointer to the block of \nstorage representing the table, T: num  contains the number of items in the table, \nand T: size  gives the total number of slots in the table. Initi ally, the table is empty: \nT: num  D T: size  D 0. \nThere are two types of insertion here: the T ABLE-I NSERT procedure itself and \nthe elementary  insertion  into  a table  in lines  6 and  10.  We  can  analyze  the  running  \ntime of T ABLE-I NSERT in terms  of the  number  of elementary  insertions  by  assign-  \ning a cost of 1 to each elementary insertion. In most computing env ironments, the \noverhead for allocating an initial table in line 2 is constant and the overhead for \nallocating  and  freeing  storage  in lines  5 and  7 is dominated  by  the  cost  of transfer-  \n1 In some  situations,  such  as an  open-address  hash  table,  it\u2019s  better to consider a table to be full if its \nload factor equals some constant strictly less than  1. (See  Exercise  16.4-2.)  462  Chapter  16  Amortized  Analysis  \nTABLE-I NSERT .T;x/  \n1 if T: size  = = 0 \n2 allocate T: table with 1 slot \n3 T: size  D 1 \n4 if T: num  == T: size  \n5 allocate new-table with 2 \ue001 T: size  slots \n6 insert all items in T: table into new-table \n7 free T: table \n8 T: table D new-table \n9 T: size  D 2 \ue001 T: size  \n10  insert x into T: table \n11  T: num  D T: num  C 1 \nring  items  in line  6. Thus,  the  actual  running  time  of TABLE-I NSERT is linear in the \nnumber of elementary insertions. An expansion  occurs  when  lines  539  execute.  \nNow,  we\u2019ll  use  all  three  amortized  analysis  techniques  to analyze a sequence of \nn TABLE-I NSERT operations on an initially empty table. First, we n eed to deter-  \nmine the actual cost c i of the i th operation. If the current table has room for the  \nnew  item  (or  if this  is the  \u00fbrst  operation),  then  c i D 1, since the only elementary \ninsertion  performed  is the  one  in line  10.  If the  current  table is full, however, and an \nexpansion occurs, then c i D i : the cost is 1 for  the  elementary  insertion  in line  10  \nplus i \ue003 1 for the items copied from the old table to the new table in line 6. For  \nn operations,  the  worst-case  cost  of an operation  is O.n/ , which leads to an upper \nbound of O.n  2 / on the total running time for n operations. \nThis bound is not tight, because the table rarely e xpands in the course of n \nTABLE-I NSERT operations.  Speci\u00fbcally,  the  i th operation causes an expansion \nonly when i \ue003 1 is an exact power of 2. The amortized cost of an operation is in \nfact O.1/ , as an aggregate analysis shows. The cost of the i th operation is \nc i D ( \ni if i \ue003 1 is an exact power of 2;  \n1 otherwise : \nThe total cost of n TABLE-I NSERT operations is therefore \nn X  \ni D1 c i \u0dc4 n C blg nc X  \nj D0 2 j \n< n  C 2n  (by  equation  (A.6)  on  page  1142)  \nD 3n;  16.4  Dynamic  tables  463 \n(a) \n(b)  $1  $1  \n(c)  $1  $1  $1  $1  \n(d)  $1  $1  $1  $1  $1  $1  \n(e)  $1  $1  $1  $1  $1  $1  $1  $1  \n(f) \nFigure  16.3  Analysis of table expansion by the accounting metho d. Each call of T ABLE-I NSERT \ncharges $3 as follows: $1 to pay for the elementary insertion, $ 1 on the item inserted as prepayment \nfor it to be reinserted later, and $ 1 on an item that was already in the table, also as p repayment for \nreinsertion. (a)  The table immediately after an expansion, with 8 slots, 4 items (tan slots), and no \nstored credit. (b)\u2013(e)  After each of 4 calls to T ABLE-I NSERT , the table has one more item, with $ 1 \nstored on the new item and $ 1 stored on one of the 4 items that were present immediately after the \nexpansion. Slots with these new items are blue. (f)  Upon the next call to T ABLE-I NSERT , the table \nis full, and so it expands again. Each item had $ 1 to pay for it to be reinserted. Now the table looks  \nas it did in part (a), with no stored credit but 16  slots and 8 items. \nbecause at most n operations cost 1 each and the costs of the remaining operations \nform a geometric series. Since the total cost of n TABLE-I NSERT operations is \nbounded by 3n, the amortized cost of a single operation is at mo st 3. \nThe accounting method can provide some intuition fo r why the amortized cost \nof a T ABLE-I NSERT operation should be 3. You can think of each item paying for \nthree elementary insertions: inserting itself into the current table, moving itself the \nnext time that the table expands, and moving some o ther item that was already in \nthe table the next time that the table expands. For  example, suppose that the size of \nthe table is m immediately  after  an expansion,  as shown  in Figure  16.3  for  m D 8. \nThen the table holds m=2  items, and it contains no credit. Each call of T ABLE- \nI NSERT charges $3. The elementary insertion that occurs immediately costs $1. \nAnother $1 resides on the item inserted as credit. The third $ 1 resides as credit \non one of the m=2  items  already  in the  table.  The  table  will  not  \u00fbll  again  until  \nanother m=2  \ue003 1 items have been inserted, and thus, by the time the  table contains \nm items and is full, each item has $ 1 on it to pay for it to be reinserted it during the \nexpansion. \nNow,  let\u2019s  see  how  to use  the  potential  method.  We\u2019ll  use  it again  in Sec-  \ntion  16.4.2  to design  a TABLE-DELETE operation that has an O.1/  amortized cost 464  Chapter  16  Amortized  Analysis  \nas well.  Just  as the  accounting  method  had  no  stored  credit  immediately after an \nexpansion4that  is, when  T: num  D T: size=24let\u2019s  de\u00fbne  the  potential  to be 0 \nwhen T: num  D T: size=2. As elementary insertions occur, the potential nee ds to \nincrease enough to pay for all the reinsertions tha t will happen when the table \nnext  expands.  The  table  \u00fblls  after  another  T: size=2  calls of T ABLE-I NSERT , when \nT: num  D T: size. The next call of T ABLE-I NSERT after these T: size=2  calls  trig-  \ngers an expansion with a cost of T: size  to reinsert all the items. Therefore, over \nthe course of T: size=2  calls of T ABLE-I NSERT , the potential must increase from 0 \nto T: size. To  achieve  this  increase,  let\u2019s  design  the  potential  so that each call of \nTABLE-I NSERT increases it by \nT: size  \nT: size=2  D 2;  \nuntil the table expands. You can see that the poten tial function \n\u02c6.T/  D 2.T:  num  \ue003 T: size=2/  (16.4)  \nequals 0 immediately after the table expands, when T: num  D T: size=2, and it \nincreases by 2 upon  each  insertion  until  the  table  \u00fblls.  Once  the  table  \u00fblls, that is, \nwhen T: num  D T: size, the potential \u02c6.T/  equals T: size. The initial value of the \npotential is 0, and since the table is always at least half full,  T: num  \ue004 T: size=2, \nwhich implies that \u02c6.T/  is always nonnegative. Thus, the sum of the amortiz ed \ncosts of n TABLE-I NSERT operations gives an upper bound on the sum of the a ctual \ncosts. \nTo analyze the amortized costs of table operations,  it is convenient to think in \nterms of the change in potential due to each operat ion. Letting \u02c6 i denote the \npotential after the i th operation,  we  can  rewrite  equation  (16.2)  as \ny c i D c i C \u02c6 i \ue003 \u02c6 i \ue0021 \nD c i C \ufffd\u02c6  i ; \nwhere \ufffd\u02c6  i is the change in potential due to the i th operation. First, consider the \ncase when the i th insertion does not cause the table to expand. In  this case, \ufffd\u02c6  i \nis 2. Since the actual cost c i is 1, the amortized cost is \ny c i D c i C \ufffd\u02c6  i \nD 1 C 2 \nD 3:  \nNow, consider the change in potential when the tabl e does expand during the i th \ninsertion because it was full immediately before th e insertion. Let num  i denote \nthe number of items stored in the table after the i th operation and size  i denote the \ntotal size of the table after the i th operation, so that size  i \ue0021 D num  i \ue0021 D i \ue003 1 16.4  Dynamic  tables  465 \n0 8 16  24  32  0 8 16  24  32  \ni size  i num  i \n\u02c6 i \nFigure  16.4  The effect of a sequence of n TABLE-I NSERT operations on the number num  i of items \nin the table (the brown line), the number size  i of slots in the table (the blue line), and the pote ntial \n\u02c6 i D 2.num  i \ue003 size  i =2/  (the red line), each being measured after the i th operation. Immediately \nbefore an expansion, the potential has built up to the number of items in the table, and therefore it can \npay for moving all the items to the new table. Afte rward, the potential drops to 0, but it immediately \nincreases by 2 upon insertion of the item that caused the expansio n. \nand therefore \u02c6 i \ue0021 D 2.size  i \ue0021 \ue003 size  i \ue0021 =2/  D size  i \ue0021 D i \ue003 1. Immediately \nafter the expansion, the potential goes down to 0, and then the new item is inserted, \ncausing the potential to increase to \u02c6 i D 2. Thus, when the i th insertion triggers \nan expansion, \ufffd\u02c6  i D 2 \ue003 .i \ue003 1/ D 3 \ue003 i . When the table expands in the i th \nTABLE-I NSERT operation, the actual cost c i equals i (to reinsert i \ue003 1 items and \ninsert the i th item), giving an amortized cost of \ny c i D c i C \ufffd\u02c6  i \nD i C .3 \ue003 i/ \nD 3:  \nFigure  16.4  plots  the  values  of num  i , size  i , and \u02c6 i against i . Notice how the \npotential builds to pay for expanding the table. \n16.4.2  Table  expansion  and  contraction  \nTo implement a T ABLE-DELETE operation,  it is simple  enough  to remove  the  spec-  \ni\u00fbed  item  from  the  table.  In order  to limit  the  amount  of waste d space, however, \nyou might want to contract  the  table  when  the  load  factor  becomes  too  small.  Ta-  466  Chapter  16  Amortized  Analysis  \nble contraction is analogous to table expansion: wh en the number of items in the \ntable drops too low, allocate a new, smaller table and then copy the items from the \nold table into the new one. You can then free the s torage for the old  table  by  return-  \ning  it to the  memory-management  system.  In order  to not  waste  space, yet keep \nthe amortized costs low, the insertion and deletion  procedures should preserve two \nproperties: \n\ue001 the load factor of the dynamic table is bounded bel ow by a positive constant, as \nwell as above by 1, and \n\ue001 the amortized cost of a table operation is bounded above by a constant. \nThe actual cost of each operation equals the number  of elementary insertions or \ndeletions. \nYou might think that if you double the table size u pon inserting an item into a \nfull table, then you should halve the size when del eting an item that would cause \nthe table to become less than half full. This strat egy does indeed guarantee that the \nload factor of the table never drops below 1=2. Unfortunately, it can also cause the \namortized cost of an operation to be quite large. C onsider the following scenario. \nPerform n operations on a table T of size n=2, where n is an exact power of 2. \nThe  \u00fbrst  n=2  operations are insertions, which by our previous an alysis cost a total \nof \u201a.n/ . At the end of this sequence of insertions, T: num  D T: size  D n=2. For \nthe second n=2  operations, perform the following sequence: \ninsert, delete, delete, insert, insert, delete, del ete, insert, insert, . . . . \nThe  \u00fbrst  insertion  causes  the  table  to expand  to size  n. The two deletions that follow \ncause the table to contract back to size n=2. Two further insertions cause another \nexpansion, and so forth. The cost of each expansion  and contraction is \u201a.n/ , and \nthere are \u201a.n/  of them. Thus, the total cost of the n operations is \u201a.n  2 /, making \nthe amortized cost of an operation \u201a.n/ . \nThe problem with this strategy is that after the ta ble expands, not  enough  dele-  \ntions occur to pay for a contraction. Likewise, aft er the table contracts, not enough \ninsertions take place to pay for an expansion. \nHow  can  we  solve  this  problem?  Allow  the  load  factor  of the  table to drop \nbelow 1=2. Speci\u00fbcally,  continue  to double  the  table  size  upon  insert ing an item \ninto a full table, but halve the table size when de leting an item causes the table to \nbecome less than 1=4  full, rather than 1=2  full as before. The load factor of the \ntable is therefore bounded below by the constant 1=4, and the load factor is 1=2  \nimmediately after a contraction. \nAn  expansion  or contraction  should  exhaust  all  the  built-up  potential, so that \nimmediately after expansion or contraction, when th e load factor is 1=2, the  table\u2019s  \npotential is 0. Figure  16.5  shows  the  idea.  As  the  load  factor  deviates  from  1=2, the 16.4  Dynamic  tables  467 \n0 1 \n1/2  \n1/4  0 \n31  per  insertion  \n+1  per  deletion  +2 per insertion \n\u20132 per deletion \u02db \u02c6 \ufffd\u02c6  per operation T: num  \nT: size  \nT: size=2  \nT: size=4  T: size=2  \nT: size=4  T: size  \nT: size=4  \nFigure  16.5  How to think about the potential function \u02c6 for table insertion and deletion. When the \nload factor \u02db is 1=2, the potential is 0. In order  to accumulate  suf\u00fbcient  potential  to pay  for  reins erting \nall T: size  items  when  the  table  \u00fblls,  the  potential  needs  to increase  by  2 upon each insertion when \n\u02db \ue004 1=2. Correspondingly, the potential decreases by 2 upon each deletion that leaves \u02db \ue004 1=2. \nIn order to accrue enough potential to cover the co st of reinserting all T: size=4  items when the table \ncontracts, the potential needs to increase by 1 upon each deletion when \u02db<1=2 , and correspondingly \nthe potential decreases by 1 upon each insertion that leaves \u02db < 1=2 . The red area represents load \nfactors less than 1=4, which are not allowed. \npotential increases so that by the time an expansio n or contraction occurs, the table \nhas  garnered  suf\u00fbcient  potential  to pay  for  copying  all  the  items into the newly \nallocated table. Thus, the potential function shoul d grow to T: num  by the time that \nthe load factor has either increased to 1 or decreased to 1=4. Immediately after \neither expanding or contracting the table, the load  factor goes back to 1=2  and the \ntable\u2019s  potential  reduces  back  to 0. \nWe omit the code for T ABLE-DELETE , since it is analogous to T ABLE-I NSERT . \nWe assume that if a contraction occurs during T ABLE-DELETE , it occurs after the \nitem is deleted from the table. The analysis assume s that whenever the number of \nitems in the table drops to 0, the table occupies no storage. That is, if T: num  D 0, \nthen T: size  D 0. \nHow do we design a potential function that gives co nstant amortized time for \nboth  insertion  and  deletion?  When  the  load  factor  is at least  1=2, the same potential \nfunction, \u02c6.T/  D 2.T:  num  \ue003 T: size=2/, that we used for insertion still works. \nWhen the table is at least half full, each insertio n increases the potential by 2 if the \ntable does not expand, and each deletion reduces th e potential by 2 if it does not \ncause the load factor to drop below 1=2. \nWhat about when the load factor is less than 1=2, that is, when 1=4  \u0dc4 \u02db.T/<  \n1=2? As  before,  when  \u02db.T/  D 1=2, so that T: num  D T: size=2, the potential \u02c6.T/  \nshould be 0. To get the load factor from 1=2  down to 1=4, T: size=4  deletions need 468  Chapter  16  Amortized  Analysis  \nto occur, at which time T: num  D T: size=4. To pay for all the reinsertions, the \npotential must increase from 0 to T: size=4  over these T: size=4  deletions.  There-  \nfore, for each call of T ABLE-DELETE until the table contracts, the potential should \nincrease by \nT: size=4  \nT: size=4  D 1:  \nLikewise, when \u02db<1=2 , each call of T ABLE-I NSERT should  decrease  the  poten-  \ntial by 1. When 1=4  \u0dc4 \u02db.T/<1=2 , the potential function \n\u02c6.T/  D T: size=2  \ue003 T: num  \nproduces this desired behavior. \nPutting the two cases together, we get the potentia l function \n\u02c6.T/  D ( \n2.T:  num  \ue003 T: size=2/  if \u02db.T/  \ue004 1=2;  \nT: size=2  \ue003 T: num  if \u02db.T/<1=2:  (16.5)  \nThe potential of an empty table is 0 and the potential is never negative. Thus, \nthe total amortized cost of a sequence of operation s with respect to \u02c6 provides an \nupper  bound  on  the  actual  cost  of the  sequence.  Figure  16.6  illustrates how the \npotential function behaves over a sequence of inser tions and deletions. \nNow,  let\u2019s  determine  the  amortized  costs  of each  operation.  As before, let num  i \ndenote the number of items stored in the table afte r the i th operation, size  i denote \nthe total size of the table after the i th operation, \u02db i D num  i =size  i denote the load \nfactor after the i th operation, \u02c6 i denote the potential after the i th operation, and \n\ufffd\u02c6  i denote the change in potential due to the i th operation. Initially, num  0 D 0, \nsize  0 D 0, and \u02c6 0 D 0. \nThe cases in which the table does not expand or con tract and the load factor does \nnot cross \u02db D 1=2  are straightforward. As we have seen, if \u02db i \ue0021 \ue004 1=2  and the \ni th operation is an insertion that does not cause th e table to expand, then \ufffd\u02c6  i D 2. \nLikewise, if the i th operation is a deletion and \u02db i \ue004 1=2, then \ufffd\u02c6  i D \ue0032. Fur-  \nthermore, if \u02db i \ue0021 < 1=2  and the i th operation is a deletion that does not trigger a \ncontraction, then \ufffd\u02c6  i D 1, and if the i th operation is an insertion and \u02db i < 1=2 , \nthen \ufffd\u02c6  i D \ue0031. In other words, if no expansion or contraction oc curs and the \nload factor does not cross \u02db D 1=2, then \n\ue001 if the load factor stays at or above 1=2, then the potential increases by 2 for an \ninsertion and decreases by 2 for a deletion, and \n\ue001 if the load factor stays below 1=2, then the potential increases by 1 for a deletion \nand decreases by 1 for an insertion. \nIn each of these cases, the actual cost c i of the i th operation is just 1, and so 16.4  Dynamic  tables  469 \n0 8 16  24  32  0 8 16  24  32  \n40  48  i size  i \nnum  i \n\u02c6 i \nFigure  16.6  The effect of a sequence of n TABLE-I NSERT and T ABLE-DELETE operations on the \nnumber num  i of items in the table (the brown line), the number size  i of slots in the table (the blue \nline), and the potential (the red line) \n\u02c6 i D \ue00f \n2.num  i \ue003 size  i =2/  if \u02db i \ue004 1=2;  \nsize  i =2  \ue003 num  i if \u02db i <1=2;  \nwhere \u02db i D num  i =size  i , each measured after the i th operation. Immediately before an expansion or \ncontraction, the potential has built up to the numb er of items in the table, and therefore it can pay for \nmoving all the items to the new table. \n\ue001 if the i th operation is an insertion, its amortized cost y c i is c i C \ufffd\u02c6  i , which \nis 1 C 2 D 3 if the load factor stays at or above 1=2, and 1 C .\ue0031/ D 0 if the \nload factor stays below 1=2, and \n\ue001 if the i th operation is a deletion, its amortized cost y c i is c i C \ufffd\u02c6  i , which \nis 1 C .\ue0032/ D \ue0031 if the load factor stays at or above 1=2, and 1 C 1 D 2 \nif the load factor stays below 1=2. \nFour cases remain: an insertion that takes the load  factor from below 1=2  to 1=2, \na deletion that takes the load factor from 1=2  to below 1=2, a deletion that causes \nthe table to contract, and an insertion that causes  the table to expand. We analyzed \nthat  last  case  at the  end  of Section  16.4.1  to show  that  its  amortized cost is 3. \nWhen the i th operation is a deletion that causes the table to  contract, we have \nnum  i \ue0021 D size  i \ue0021 =4  before  the  contraction,  then  the  item  is deleted,  and  \u00fbnally  \nnum  i D size  i =2  \ue003 1 after  the  contraction.  Thus,  by  equation  (16.5)  we  have  470  Chapter  16  Amortized  Analysis  \n\u02c6 i \ue0021 D size  i \ue0021 =2  \ue003 num  i \ue0021 \nD size  i \ue0021 =2  \ue003 size  i \ue0021 =4  \nD size  i \ue0021 =4;  \nwhich also equals the actual cost c i of deleting one item and copying size  i \ue0021 =4  \ue003 1 \nitems into the new, smaller table. Since num  i D size  i =2  \ue003 1 after the operation has \ncompleted, \u02db i <1=2 , and so \n\u02c6 i D size  i =2  \ue003 num  i \nD 1;  \ngiving \ufffd\u02c6  i D 1 \ue003 size  i \ue0021 =4. Therefore, when the i th operation is a deletion that \ntriggers a contraction, its amortized cost is \ny c i D c i C \ufffd\u02c6  i \nD size  i \ue0021 =4  C .1 \ue003 size  i \ue0021 =4/  \nD 1:  \nFinally,  we  handle  the  cases  where  the  load  factor  \u00fbts  one  case  of equation  (16.5)  \nbefore the operation and the other case afterward. We start with deletion, where we \nhave num  i \ue0021 D size  i \ue0021 =2, so that \u02db i \ue0021 D 1=2, beforehand, and num  i D size  i =2\ue0031, \nso that \u02db i <1=2  afterward. Because \u02db i \ue0021 D 1=2, we have \u02c6 i \ue0021 D 0, and because \n\u02db i <1=2 , we have \u02c6 i D size  i =2  \ue003 num  i D 1. Thus we get that \ufffd\u02c6  i D 1 \ue003 0 D 1. \nSince the i th operation is a deletion that does not cause a co ntraction, the actual \ncost c i equals 1, and the amortized cost y c i is c i C \ufffd\u02c6  i D 1 C 1 D 2. \nConversely, if the i th operation is an insertion that takes the load fa ctor from \nbelow 1=2  to equaling 1=2, the change in potential \ufffd\u02c6  i equals \ue0031. Again, the \nactual cost c i is 1, and now the amortized cost y c i is c i C \ufffd\u02c6  i D 1 C .\ue0031/ D 0. \nIn summary, since the amortized cost of each operat ion is bounded above by \na constant, the actual time for any sequence of n operations on a dynamic table \nis O.n/ . \nExercises  \n16.4-1  \nUsing the potential method, analyze the amortized c ost of the \u00fbrst  table  insertion.  \n16.4-2  \nYou  wish  to implement  a dynamic,  open-address  hash  table.  Why  might  you  con-  \nsider the table to be full when its load factor rea ches some value \u02db that is strictly \nless than 1? Describe  brie\u00fcy  how  to make  insertion  into  a dynamic,  open- address \nhash table run in such a way that the expected valu e of the amortized cost per Problems for Chapter 16 471 \ninsertion is O.1/ . Why is the expected value of the actual cost per insertion not \nnecessarily O.1/  for  all  insertions?  \n16.4-3  \nDiscuss how to use the accounting method to analyze  both the insertion  and  dele-  \ntion operations, assuming that the table doubles in  size when its  load  factor  ex-  \nceeds 1 and the table halves in size when its load factor g oes below 1=4. \n16.4-4  \nSuppose that instead of contracting a table by halv ing its size when its load factor \ndrops below 1=4, you contract the table by multiplying its size by  2=3  when its \nload factor drops below 1=3. Using the potential function \n\u02c6.T/  D j2.T:  num  \ue003 T: size=2/j ; \nshow that the amortized cost of a T ABLE-DELETE that uses this strategy is bounded \nabove by a constant. \nProblems  \n16-1  Binary  re\u00fcected  Gray  code  \nA binary  Gray  code  represents a sequence of nonnegative integers in bi nary such \nthat  to go  from  one  integer  to the  next,  exactly  one  bit  \u00fcips  every time. The binary  \nre\u00fcected  Gray  code  represents a sequence of the integers 0 to 2 k \ue003 1 for some \npositive integer k according to the following recursive method: \n\ue001 For k D 1, the  binary  re\u00fcected  Gray  code  is h0;1i. \n\ue001 For k \ue004 2, \u00fbrst  form  the  binary  re\u00fcected  Gray  code  for  k \ue003 1, giving the 2 k\ue0021 \nintegers 0 to 2 k\ue0021 \ue003 1. Then  form  the  re\u00fcection  of this  sequence,  which  is just  \nthe sequence in reverse. (That is, the j th integer in the sequence becomes the \n.2 k\ue0021 \ue003 j \ue003 1/st integer  in the  re\u00fcection).  Next,  add  2 k\ue0021 to each of the 2 k\ue0021 \nintegers  in the  re\u00fcected  sequence.  Finally,  concatenate  the two sequences. \nFor example, for k D 2, \u00fbrst  form  the  binary  re\u00fcected  Gray  code  h0;1i for \nk D 1. Its  re\u00fcection  is the  sequence  h1;0i. Adding 2 k\ue0021 D 2 to each integer in the \nre\u00fcection  gives  the  sequence  h3;2i. Concatenating the two sequences gives h0;1;  \n3;2i or, in binary, h00;01;11;10 i, so that each integer differs from its predecessor  \nby exactly one bit. For k D 3, the  re\u00fcection  of the  binary  re\u00fcected  Gray  code  for  \nk D 2 is h2;3;1;0 i and adding 2 k\ue0021 D 4 gives h6;7;5;4 i. Concatenating produces \nthe sequence h0;1;3;2;6;7;5;4 i, which in binary is h000;001;011;010;110;111;  \n101;100 i. In the  binary  re\u00fcected  Gray  code,  only  one  bit  \u00fcips  even  when  wrapping \naround  from  the  last  integer  to the  \u00fbrst.  472  Chapter  16  Amortized  Analysis  \na. Index  the  integers  in a binary  re\u00fcected  Gray  code  from  0 to 2 k \ue003 1, and consider \nthe i th integer  in the  binary  re\u00fcected  Gray  code.  To  go  from  the  .i \ue003 1/st integer \nto the i th integer  in the  binary  re\u00fcected  Gray  code,  exactly  one  bit  \u00fcips. Show \nhow  to determine  which  bit  \u00fcips,  given  the  index  i . \nb. Assuming that given a bit number j , you  can  \u00fcip  bit  j of an integer in constant \ntime,  show  how  to compute  the  entire  binary  re\u00fcected  Gray  code sequence of \n2 k numbers in \u201a.2  k / time. \n16-2  Making  binary  search  dynamic  \nBinary search of a sorted array takes logarithmic s earch time, but the time to insert \na new element is linear in the size of the array. Y ou can improve the time for \ninsertion by keeping several sorted arrays. \nSpeci\u00fbcally,  suppose  that  you  wish  to support  SEARCH and I NSERT on a set \nof n elements. Let k D dlg.n C 1/e, and let the binary representation of n be \nhn k\ue0021 ;n  k\ue0022 ;:::;n  0 i. Maintain k sorted arrays A 0 ;A  1 ;:::;A  k\ue0021 , where for i D \n0;1;:::;k  \ue003 1, the length of array A i is 2 i . Each  array  is either  full  or empty,  de-  \npending on whether n i D 1 or n i D 0, respectively. The total number of elements \nheld in all k arrays is therefore P  k\ue0021 \ni D0 n i 2 i D n. Although each individual array is \nsorted, elements in different arrays bear no partic ular relationship to each other. \na. Describe how to perform the S EARCH operation for this data structure. Analyze \nits  worst-case  running  time.  \nb. Describe how to perform the I NSERT operation.  Analyze  its  worst-case  and  \namortized running times, assuming that the only ope rations are I NSERT and \nSEARCH . \nc. Describe how to implement D ELETE. Analyze  its  worst-case  and  amortized  \nrunning times, assuming that there can be D ELETE , I NSERT , and S EARCH op-  \nerations. \n16-3  Amortized  weight-balanced  trees  \nConsider an ordinary binary search tree augmented b y adding to each node x the \nattribute x: size, which gives the number of keys stored in the subt ree rooted at x . \nLet \u02db be a constant in the range 1=2  \u0dc4 \u02db < 1 . We say that a given node x is \n\u02db-balanced  if x: left: size  \u0dc4 \u02db \ue001 x: size  and x: right : size  \u0dc4 \u02db \ue001 x: size. The tree \nas a whole is \u02db-balanced  if every node in the tree is \u02db-balanced.  The  follow-  \ning  amortized  approach  to maintaining  weight-balanced  trees was suggested by \nG.  Varghese.  Problems for Chapter 16 473 \na. A 1=2-balanced  tree  is, in a sense,  as balanced  as it can  be.  Given  a node x \nin an arbitrary binary search tree, show how to reb uild the subtree rooted at x \nso that it becomes 1=2-balanced.  Your  algorithm  should  run  in \u201a.x:  size/ time, \nand it can use O.x:  size/ auxiliary storage. \nb. Show that performing a search in an n-node  \u02db-balanced  binary  search  tree  takes  \nO.lg n/ worst-case  time.  \nFor the remainder of this problem, assume that the constant \u02db is strictly greater \nthan 1=2. Suppose that you implement I NSERT and D ELETE as usual for an n-node  \nbinary search tree, except that after every such op eration, if any node in the tree \nis no longer \u02db-balanced,  then  you  <rebuild=  the  subtree  rooted  at the  highest such \nnode in the tree so that it becomes 1=2-balanced.  \nWe\u2019ll  analyze  this  rebuilding  scheme  using  the  potential  method. For a node x \nin a binary search tree T , de\u00fbne  \n\ufffd.x/  D jx: left: size  \ue003 x: right : sizej : \nDe\u00fbne  the  potential  of T as \n\u02c6.T/  D c X  \nx2T W\u0129.x/\ue0042 \ufffd.x/  ; \nwhere c is a suf\u00fbciently  large  constant  that  depends  on  \u02db. \nc. Argue that any binary search tree has nonnegative p otential and also that a \n1=2-balanced  tree  has  potential  0. \nd. Suppose that m units of potential can pay for rebuilding an m-node  subtree.  \nHow large must c be in terms of \u02db in order for it to take O.1/  amortized time \nto rebuild a subtree that is not \u02db-balanced?  \ne. Show that inserting a node into or deleting a node from an n-node  \u02db-balanced  \ntree costs O.lg n/ amortized time. \n16-4  The  cost  of restructuring  red-black  trees  \nThere  are  four  basic  operations  on  red-black  trees  that  perform structural  modi-  \n\u00fbcations : node insertions, node deletions, rotations, and c olor changes. We have \nseen  that  RB-I  NSERT and  RB-D ELETE use only O.1/  rotations, node insertions, \nand  node  deletions  to maintain  the  red-black  properties,  but they may make many \nmore color changes. \na. Describe  a legal  red-black  tree  with  n nodes  such  that  calling  RB-I  NSERT to \nadd the .n C 1/st node causes \ufffd.lg n/ color changes. Then describe a legal 474  Chapter  16  Amortized  Analysis  \nred-black  tree  with  n nodes  for  which  calling  RB-D ELETE on a particular node \ncauses \ufffd.lg n/ color changes. \nAlthough  the  worst-case  number  of color  changes  per  operati on can be logarithmic, \nyou will prove that any sequence of m RB-I  NSERT and  RB-D ELETE operations on \nan initially  empty  red-black  tree  causes  O.m/  structural  modi\u00fbcations  in the  worst  \ncase. \nb. Some of the cases handled by the main loop of the c ode of both RB -I NSERT- \nFIXUP and  RB-D ELETE-FIXUP are terminating : once encountered, they cause \nthe loop to terminate after a constant number of ad ditional operations. For each \nof the  cases  of RB-I  NSERT-FIXUP and  RB-D ELETE-F IXUP , specify which are \nterminating and which are not. ( Hint: Look  at Figures  13.5,  13.6,  and  13.7  in \nSections  13.3  and  13.4.)  \nYou  will  \u00fbrst  analyze  the  structural  modi\u00fbcations  when  only  insertions  are  per-  \nformed. Let T be a red-black  tree,  and  de\u00fbne  \u02c6.T/  to be the number of red nodes \nin T . Assume that one unit of potential can pay for the  structural modi\u00fbcations  \nperformed  by  any  of the  three  cases  of RB-I  NSERT-FIXUP . \nc. Let T 0 be the  result  of applying  Case  1 of RB-I  NSERT-FIXUP to T . Argue that \n\u02c6.T  0 / D \u02c6.T/  \ue003 1. \nd. We  can  break  the  operation  of the  RB-I  NSERT procedure into three parts. List \nthe  structural  modi\u00fbcations  and  potential  changes  resulting  from  lines  1316  \nof RB-I  NSERT, from  nonterminating  cases  of RB-I  NSERT-FIXUP , and from \nterminating  cases  of RB-I  NSERT-FIXUP . \ne. Using part (d), argue that the amortized number of structural modi\u00fbcations  per-  \nformed  by  any  call  of RB-I  NSERT is O.1/ . \nNext you will prove that there are O.m/  structural  modi\u00fbcations  when  both  inser-  \ntions  and  deletions  occur.  De\u00fbne,  for  each  node  x , \nw.x/  D \u201e \n0 if x is red ; \n1 if x is black and has no red children ; \n0 if x is black and has one red child ; \n2 if x is black and has two red children : \nNow  rede\u00fbne  the  potential  of a red-black  tree  T as \n\u02c6.T/  D X  \nx2T w.x/;  Notes for Chapter 16 475 \nand let T 0 be the tree that results from applying any nontermi nating case of RB-  \nI NSERT-FIXUP or RB-D ELETE-FIXUP to T . \nf. Show that \u02c6.T  0 / \u0dc4 \u02c6.T /  \ue003 1 for  all  nonterminating  cases  of RB-I  NSERT- \nFIXUP. Argue  that  the  amortized  number  of structural  modi\u00fbcation s performed \nby  any  call  of RB-I  NSERT-FIXUP is O.1/ . \ng. Show that \u02c6.T  0 / \u0dc4 \u02c6.T /  \ue003 1 for  all  nonterminating  cases  of RB-D ELETE- \nFIXUP. Argue  that  the  amortized  number  of structural  modi\u00fbcation s performed \nby  any  call  of RB-D ELETE-FIXUP is O.1/ . \nh. Complete the proof that in the worst case, any sequ ence of m RB-I  NSERT and \nRB-D ELETE operations performs O.m/  structural  modi\u00fbcations.  \nChapter  notes  \nAho,  Hopcroft,  and  Ullman  [5]  used  aggregate  analysis  to determine the running \ntime  of operations  on  a disjoint-set  forest.  We\u2019ll  analyze  this data structure using \nthe  potential  method  in Chapter  19.  Tarjan  [430]  surveys  the  accounting  and  poten-  \ntial methods of amortized analysis and presents sev eral applications. He attributes \nthe accounting method to several authors, including  M. R. Brown, R. E. Tarjan, S. \nHuddleston,  and  K.  Mehlhorn.  He  attributes  the  potential  method to D. D. Sleator. \nThe term <amortized= is due to D. D. Sleator and R.  E. Tarjan. \nPotential functions are also useful for proving low er bounds for certain types \nof problems.  For  each  con\u00fbguration  of the  problem,  de\u00fbne  a potential function \nthat  maps  the  con\u00fbguration  to a real  number.  Then  determine  the potential \u02c6 init \nof the  initial  con\u00fbguration,  the  potential  \u02c6 \u00fbnal  of the  \u00fbnal  con\u00fbguration,  and  the  \nmaximum change in potential \ufffd\u02c6  max due to any step. The number of steps must \ntherefore be at least j\u02c6 \u00fbnal  \ue003 \u02c6 init j = j\ufffd\u02c6  max j. Examples of potential functions to \nprove  lower  bounds  in I/O  complexity  appear  in works  by  Corme n, Sundquist, and \nWisniewski  [105],  Floyd  [146],  and  Aggarwal  and  Vitter  [3].  Krumme,  Cybenko,  \nand  Venkataraman  [271]  applied  potential  functions  to prove lower bounds on gos-  \nsiping : communicating a unique item from each vertex in a  graph to every other \nvertex. Part  V Advanced  Data  Structures  Introduction  \nThis part returns to studying data structures that support operations on dynamic \nsets,  but  at a more  advanced  level  than  Part  III.  One  of the  chapters, for example, \nmakes extensive use of the amortized analysis techn iques from  Chapter  16.  \nChapter  17  shows  how  to augment  red-black  trees4adding  additional  informa-  \ntion  in each  node4to  support  dynamic-set  operations  in addition to those covered \nin Chapters  12  and  13.  The  \u00fbrst  example  augments  red-black  trees to dynamically \nmaintain order statistics for a set of keys. Anothe r example augments them in a \ndifferent way to maintain intervals of real numbers . Chapter 17  includes  a theo-  \nrem  giving  suf\u00fbcient  conditions  for  when  a red-black  tree  can be augmented while \nmaintaining the O.lg n/ running times for insertion and deletion. \nChapter  18  presents  B-trees,  which  are  balanced  search  trees  speci\u00fbcally  de-  \nsigned to be stored on disks. Since disks operate m uch more slowly  than  random-  \naccess  memory,  B-tree  performance  depends  not  only  on  how  much computing \ntime  the  dynamic-set  operations  consume  but  also  on  how  many  disk accesses they \nperform.  For  each  B-tree  operation,  the  number  of disk  acces ses increases with the \nheight  of the  B-tree,  but  B-tree  operations  keep  the  height  low. \nChapter  19  examines  data  structures  for  disjoint  sets.  Starting with a universe \nof n elements, each initially in its own singleton set, the operation U NION  unites \ntwo sets. At all times, the n elements are partitioned into disjoint sets, even a s \ncalls to the U NION  operation change the members of a set dynamically. The query \nFIND-SET identi\u00fbes  the  unique  set  that  contains  a given  element  at the  moment. \nRepresenting each set as a simple rooted tree yield s surprisingly fast operations: \na sequence of m operations runs in O.m \u02db.n//  time, where \u02db.n/  is an incredibly \nslowly  growing  function4 \u02db.n/  is at most 4 in any conceivable application. The \namortized analysis that proves this time bound is a s complex as the data structure \nis simple. 478  Part  V Advanced  Data  Structures  \nThe topics covered in this part are by no means the  only examples of <advanced= \ndata  structures.  Other  advanced  data  structures  include  the following: \n\ue001 Fibonacci  heaps  [156]  implement  mergeable  heaps  (see  Problem  10-2  on  \npage  268)  with  the  operations  I NSERT , M INIMUM , and UNION  taking only \nO.1/  actual and amortized time, and the operations E XTRACT-MIN and \nDELETE taking O.lg n/ amortized  time.  The  most  signi\u00fbcant  advantage  of \nthese data structures, however, is that D ECREASE-KEY takes only O.1/  amor-  \ntized time. Strict  Fibonacci  heaps  [73],  developed  later,  made  all  of these  time  \nbounds actual. Because the D ECREASE-KEY operation  takes  constant  amor-  \ntized time, (strict) Fibonacci heaps constitute key  components of some of the \nasymptotically fastest algorithms to date for graph  problems. \n\ue001 Dynamic  trees  [415,  429]  maintain  a forest  of disjoint  rooted  trees.  Each  edge \nin each  tree  has  a real-valued  cost.  Dynamic  trees  support  queries  to \u00fbnd  par-  \nents, roots, edge costs, and the minimum edge cost on a simple path from a node \nup to a root. Trees may be manipulated by cutting e dges, updating all edge costs \non a simple path from a node up to a root, linking a root into another tree, and \nmaking  a node  the  root  of the  tree  it appears  in.  One  implement ation of dynamic \ntrees gives an O.lg n/ amortized time bound for each operation, while a mo re \ncomplicated implementation yields O.lg n/ worst-case  time  bounds.  Dynamic  \ntrees are used in some of the asymptotically fastes t network-\u00fcow  algorithms.  \n\ue001 Splay  trees  [418,  429]  are  a form  of binary  search  tree  on  which  the  standa rd \nsearch-tree  operations  run  in O.lg n/ amortized  time.  One  application  of splay  \ntrees  simpli\u00fbes  dynamic  trees.  \n\ue001 Persistent  data structures allow queries, and sometimes update s as well, on past \nversions of a data structure. For example, linked d ata structures can be made \npersistent  with  only  a small  time  and  space  cost  [126].  Problem  13-1  gives  a \nsimple example of a persistent dynamic set. \n\ue001 Several data structures allow a faster implementati on of dictionary operations \n(I NSERT , DELETE , and S EARCH) for  a restricted  universe  of keys.  By  tak-  \ning advantage of these restrictions, they are able to achieve better  worst-case  \nasymptotic  running  times  than  comparison-based  data  struc tures. If the keys \nare unique integers drawn from the set f0; 1; 2; : : : ; u  \ue003 1g, where u is an ex-  \nact power of 2, then a recursive data structure known as a van  Emde  Boas  \ntree  [440,  441]  supports  each  of the  operations  SEARCH , I NSERT , DELETE , \nMINIMUM , M AXIMUM , SUCCESSOR , and PREDECESSOR  in O.lg lg u/  time. \nFusion  trees  [157]  were  the  \u00fbrst  data  structure  to allow  faster  dictionary  opera-  \ntions when the universe is restricted to integers, implementing these operations \nin O.lg n=  lg lg n/ time. Several subsequent data structures, including  expo-  \nnential  search  trees  [17],  have  also  given  improved  bounds  on  some  or all  of Part  V Advanced  Data  Structures  479 \nthe dictionary operations and are mentioned in the chapter notes throughout this \nbook. \n\ue001 Dynamic  graph  data  structures  support various queries while allowing the \nstructure of a graph to change through operations t hat insert or delete vertices \nor edges. Examples of the queries that they support  include vertex connectivity \n[214],  edge  connectivity,  minimum  spanning  trees  [213],  biconnectivity, and \ntransitive  closure  [212].  \nChapter notes throughout this book mention addition al data structures. 17  Augmenting  Data  Structures  \nSome solutions require no more than a <textbook= da ta structure4such  as a doubly  \nlinked  list,  a hash  table,  or a binary  search  tree4but  many  others require a dash \nof creativity. Rarely will you need to create an en tirely new type of data structure, \nthough. More often, you can augment a textbook data  structure by  storing  addi-  \ntional information in it. You can then program new operations for the data structure \nto support your application. Augmenting a data stru cture is not  always  straightfor-  \nward, however, since the added information must be updated and maintained by \nthe ordinary operations on the data structure. \nThis  chapter  discusses  two  data  structures  based  on  red-black  trees  that  are  aug-  \nmented  with  additional  information.  Section  17.1  describe s a data structure that \nsupports  general  order-statistic  operations  on  a dynamic  set:  quickly  \u00fbnding  the  \ni th smallest  number  or the  rank  of a given  element.  Section  17.2  abstracts  the  pro-  \ncess of augmenting a data structure and provides a theorem that you can use when \naugmenting  red-black  trees.  Section  17.3  uses  this  theorem  to help design a data \nstructure for maintaining a dynamic set of interval s, such as time intervals. You \ncan  use  this  data  structure  to quickly  \u00fbnd  an interval  that  overlaps a given query \ninterval. \n17.1  Dynamic  order  statistics  \nChapter 9 introduced the notion of an order statist ic. Speci\u00fbcally,  the  i th order \nstatistic of a set of n elements, where i 2 f1;2;:::;n g, is simply the element in \nthe set with the i th smallest key. In Chapter 9, you saw how to deter mine any order \nstatistic in O.n/  time from an unordered set. This section shows how to modify \nred-black  trees  so that  you  can  determine  any  order  statisti c for a dynamic set in \nO.lg n/ time and also compute the rank  of an element4its  position  in the  linear  \norder  of the  set4in  O.lg n/ time. 17.1  Dynamic  order  statistics  481 \n1 3 7 12  10  \n14  16  14  \n2 1 1 2 4 7 \n20  19  21  21  17  \n28  \n35  39  38  47  30  41  26  \n1 2 1 4 12  \n1 \n1 1 3 5 1 7 20  \nkey  \nsize  \nFigure  17.1  An  order-statistic  tree,  which  is an  augmented  red-black  tree. In addition to its usual \nattributes, each node x has an attribute x: size, which is the number of nodes, other than the sent inel, \nin the subtree rooted at x. \nFigure  17.1  shows  a data  structure  that  can  support  fast  order-statistic  operations.  \nAn order-statistic  tree  T is simply  a red-black  tree  with  additional  information  \nstored in each node. Each node x contains  the  usual  red-black  tree  attributes  x: key, \nx: color , x: p, x: left, and x: right , along with a new attribute, x: size. This attribute \ncontains the number of internal nodes in the subtre e rooted at x (including x itself, \nbut not including any sentinels), that is, the size  of the subtree.  If we  de\u00fbne  the  \nsentinel\u2019s  size  to be 04that  is, we  set  T: nil: size  to be 04then  we  have  the  identity  \nx: size  D x: left: size  C x: right: size  C 1:  \nKeys  need  not  be distinct  in an order-statistic  tree.  For  example,  the  tree  in Fig-  \nure  17.1  has  two  keys  with  value  14  and two keys with value 21. When equal keys \nare  present,  the  above  notion  of rank  is not  well  de\u00fbned.  We  remove this ambiguity \nfor  an order-statistic  tree  by  de\u00fbning  the  rank  of an element  as the position at which \nit would  be printed  in an inorder  walk  of the  tree.  In Figure  17.1,  for  example,  the  \nkey 14  stored in a black node has rank 5, and the key 14  stored in a red node has \nrank 6. \nRetrieving  the  element  with  a given  rank  \nBefore we show how to maintain the size information  during insertion  and  dele-  \ntion,  let\u2019s  see  how  to implement  two  order-statistic  querie s that use this additional \ninformation. We begin with an operation that retrie ves the element with a given \nrank.  The  procedure  OS-S ELECT .x;i/  on the following page returns a pointer to \nthe node containing the i th smallest key in the subtree rooted at x . To  \u00fbnd  the  node  \nwith the i th smallest  key  in an order-statistic  tree  T , call  OS-S ELECT .T:  root ;i/. \nHere  is how  OS-S ELECT works.  Line  1 computes  r , the rank of node x within \nthe subtree rooted at x . The value of x: left: size  is the number of nodes that come 482  Chapter  17  Augmenting  Data  Structures  \nOS-S ELECT .x;i/  \n1 r D x: left: size  C 1 / / rank of x within the subtree rooted at x \n2 if i == r \n3 return  x \n4 elseif  i<r  \n5 return  OS-S ELECT .x:  left;i/  \n6 else  return  OS-S ELECT .x:  right;i \ue003 r/ \nbefore x in an inorder tree walk of the subtree rooted at x . Thus, x: left: size  C 1 \nis the rank of x within the subtree rooted at x . If i D r , then node x is the i th \nsmallest  element,  and  so line  3 returns  x . If i <r  , then the i th smallest element \nresides in x \u2019s left  subtree,  and  therefore,  line  5 recurses  on  x: left. If i >r  , then \nthe i th smallest element resides in x \u2019s right  subtree.  Since  the  subtree  rooted  at x \ncontains r elements that come before x \u2019s right  subtree  in an inorder  tree  walk,  the  \ni th smallest element in the subtree rooted at x is the .i \ue003 r/th smallest element in \nthe subtree rooted at x: right. Line  6 determines  this  element  recursively.  \nAs  an example  of how  OS-S ELECT operates,  consider  a search  for  the  17th  \nsmallest  element  in the  order-statistic  tree  of Figure  17.1. The search starts with x \nas the  root,  whose  key  is 26,  and  with  i D 17. Since  the  size  of 26\u2019s  left  subtree  \nis 12,  its  rank  is 13.  Thus,  the  node  with  rank  17  is the  17  \ue003 13  D 4th smallest \nelement  in 26\u2019s  right  subtree.  In the  recursive  call,  x is the  node  with  key  41,  and  \ni D 4. Since  the  size  of 41\u2019s  left  subtree  is 5, its  rank  within  its  subtree  is 6. \nTherefore,  the  node  with  rank  4 is the  4th  smallest  element  in 41\u2019s  left  subtree.  In \nthe recursive call, x is the  node  with  key  30,  and  its  rank  within  its  subtree  is 2. \nThe  procedure  recurses  once  again  to \u00fbnd  the  4 \ue003 2 D 2nd smallest element in the \nsubtree  rooted  at the  node  with  key  38.  Its  left  subtree  has  size  1, which  means  it \nis the second smallest element. Thus, the procedure  returns a pointer to the node \nwith  key  38.  \nBecause  each  recursive  call  goes  down  one  level  in the  order- statistic tree, the \ntotal  time  for  OS-S ELECT is at worst proportional to the height of the tree.  Since \nthe  tree  is a red-black  tree,  its  height  is O.lg n/, where n is the number of nodes. \nThus,  the  running  time  of OS-S ELECT is O.lg n/ for a dynamic set of n elements. \nDetermining  the  rank  of an  element  \nGiven  a pointer  to a node  x in an order-statistic  tree  T , the  procedure  OS-RANK  \non the facing page returns the position of x in the linear order determined by an \ninorder tree walk of T . 17.1  Dynamic  order  statistics  483 \nOS-RANK.T;x/  \n1 r D x: left: size  C 1 / / rank of x within the subtree rooted at x \n2 y D x / / root of subtree being examined \n3 while  y \u00a4 T: root \n4 if y == y: p: right / / if root of a right subtree . . . \n5 r D r C y: p: left: size  C 1 / / . . . add in parent and its left subtree \n6 y D y: p / / move y toward the root \n7 return  r \nThe  OS-RANK  procedure works as follows. You can think of node x \u2019s rank  \nas the number of nodes preceding x in an inorder tree walk, plus 1 for x itself. \nOS-RANK  maintains the following loop invariant: \nAt the start of each iteration of the while  loop  of lines  336,  r is the rank \nof x: key  in the subtree rooted at node y . \nWe  use  this  loop  invariant  to show  that  OS-RANK  works correctly as follows: \nInitialization:  Prior  to the  \u00fbrst  iteration,  line  1 sets  r to be the rank of x: key  \nwithin the subtree rooted at x . Setting y D x in line 2 makes the invariant true \nthe  \u00fbrst  time  the  test  in line  3 executes.  \nMaintenance:  At the end of each iteration of the while  loop,  line  6 sets  y D y: p. \nThus, we must show that if r is the rank of x: key  in the subtree rooted at y at the \nstart of the loop body, then r is the rank of x: key  in the subtree rooted at y: p \nat the end of the loop body. In each iteration of t he while  loop, consider the \nsubtree rooted at y: p. The value of r already includes the number of nodes \nin the subtree rooted at node y that precede x in an inorder walk, and so the \nprocedure must add the nodes in the subtree rooted at y \u2019s sibling  that  precede  x \nin an inorder walk, plus 1 for y: p if it, too, precedes x . If y is a left child, then \nneither y: p nor any node in y: p\u2019s right  subtree  precedes  x , and  so OS-RANK  \nleaves r alone.  Otherwise,  y is a right child and all the nodes in y: p\u2019s left  \nsubtree precede x , as does y: p itself.  In this  case,  line  5 adds  y: p: left: size  C 1 \nto the current value of r . \nTermination:  Because each iteration of the loop moves y toward the root and the \nloop terminates when y D T: root , the loop eventually terminates. Moreover, \nthe subtree rooted at y is the entire tree. Thus, the value of r is the rank of \nx: key  in the entire tree. \nAs  an example,  when  OS-RANK  runs  on  the  order-statistic  tree  of Figure  17.1  \nto \u00fbnd  the  rank  of the  node  with  key  38,  the  following  sequence  of values of y: key  \nand r occurs at the top of the while  loop: 484  Chapter  17  Augmenting  Data  Structures  \niteration y: key  r \n1 38  2 \n2 30  4 \n3 41  4 \n4 26  17  \nThe  procedure  returns  the  rank  17.  \nSince each iteration of the while  loop takes O.1/  time, and y goes up one level in \nthe  tree  with  each  iteration,  the  running  time  of OS-RANK  is at worst proportional \nto the height of the tree: O.lg n/ on an n-node  order-statistic  tree.  \nMaintaining  subtree  sizes  \nGiven  the  size  attribute  in each  node,  OS-S ELECT and  OS-RANK  can quickly \ncompute  order-statistic  information.  But  if the  basic  modifying  operations  on  red-  \nblack  trees  cannot  ef\u00fbciently  maintain  the  size  attribute, our work will have been \nfor  naught.  Let\u2019s  see  how  to maintain  subtree  sizes  for  both  insertion and deletion \nwithout affecting the asymptotic running time of ei ther operation. \nRecall  from  Section  13.3  that  insertion  into  a red-black  tree consists of two \nphases.  The  \u00fbrst  phase  goes  down  the  tree  from  the  root,  inser ting the new node \nas a child of an existing node. The second phase go es up the tree, changing colors \nand  performing  rotations  to maintain  the  red-black  propert ies. \nTo  maintain  the  subtree  sizes  in the  \u00fbrst  phase,  simply  incre ment x: size  for each \nnode x on the simple path traversed from the root down tow ard the leaves. The \nnew node added gets a size  of 1. Since  there  are  O.lg n/ nodes on the traversed \npath, the additional cost of maintaining the size  attributes is O.lg n/. \nIn the second phase, the only structural changes to  the underlying  red-black  tree  \nare caused by rotations, of which there are at most  two. Moreover, a rotation is \na local operation: only two nodes have their size  attributes invalidated. The link \naround which the rotation is performed is incident on these two nodes. Referring \nto the code for L EFT-ROTATE  .T;x/  on  page  336,  add  the  following  lines:  \n13  y: size  D x: size  \n14  x: size  D x: left: size  C x: right : size  C 1 \nFigure  17.2  illustrates  how  the  attributes  are  updated.  The  change to R IGHT- \nROTATE  is symmetric. \nSince  inserting  into  a red-black  tree  requires  at most  two  rotations, updating the \nsize  attributes in the second phase costs only O.1/  additional time. Thus, the total \ntime for insertion into an n-node  order-statistic  tree  is O.lg n/, which  is asymptot-  \nically  the  same  as for  an ordinary  red-black  tree.  17.1  Dynamic  order  statistics  485 \nLEFT-ROTATE (T, x) \nRIGHT-ROTATE (T, y) 93  \n19  y \n42  \n11  x \n6 4 7 93  42  \n19  \n12  \n6 \n4 7 x \ny \nFigure  17.2  Updating subtree sizes during rotations. The update s are local, requiring only the size  \ninformation stored in x, y, and the roots of the subtrees shown as triangles.  \nDeletion  from  a red-black  tree  also  consists  of two  phases:  the  \u00fbrst  operates  \non the underlying search tree, and the second cause s at most three rotations and \notherwise  performs  no  structural  changes.  (See  Section  13.4.)  The  \u00fbrst  phase  \nremoves one node \u00b4 from the tree and could move at most two other node s within \nthe tree (nodes y and x in Figure  12.4  on  page  323).  To  update  the  subtree  sizes,  \nsimply traverse a simple path from the lowest node that moves (starting from its \noriginal position within the tree) up to the root, decrementing the size  attribute \nof each node on the path. Since this path has lengt h O.lg n/ in an n-node  red-  \nblack tree, the additional time spent maintaining size  attributes  in the  \u00fbrst  phase  \nis O.lg n/. For the O.1/  rotations in the second phase of deletion, handle t hem \nin the same manner as for insertion. Thus, both ins ertion and deletion, including \nmaintaining the size  attributes, take O.lg n/ time for an n-node  order-statistic  tree.  \nExercises  \n17.1-1  \nShow  how  OS-S ELECT .T:  root ;10/  operates  on  the  red-black  tree  T shown in \nFigure  17.1.  \n17.1-2  \nShow  how  OS-RANK.T;x/  operates  on  the  red-black  tree  T shown  in Figure  17.1  \nand the node x with x: key  D 35. \n17.1-3  \nWrite  a nonrecursive  version  of OS-S ELECT . \n17.1-4  \nWrite  a procedure  OS-K EY-RANK.T;k/  that  takes  an order-statistic  tree  T and a \nkey k and returns the rank of k in the dynamic set represented by T . Assume that \nthe keys of T are distinct. 486  Chapter  17  Augmenting  Data  Structures  \n17.1-5  \nGiven  an element  x in an n-node  order-statistic  tree  and  a natural  number  i , show \nhow to determine the i th successor of x in the linear order of the tree in O.lg n/ \ntime. \n17.1-6  \nThe  procedures  OS-S ELECT and  OS-RANK  use the size  attribute of a node only \nto compute a rank. Suppose that you store in each n ode its rank in the subtree \nof which it is the root instead of the size  attribute. Show how to maintain this \ninformation during insertion and deletion. (Remembe r that these two operations \ncan cause rotations.) \n17.1-7  \nShow  how  to use  an order-statistic  tree  to count  the  number  of inversions (see \nProblem  2-4  on  page  47)  in an array  of n distinct elements in O.n  lg n/ time. \n? 17.1-8  \nConsider n chords  on  a circle,  each  de\u00fbned  by  its  endpoints.  Describe  an O.n  lg n/- \ntime algorithm to determine the number of pairs of chords that intersect inside the \ncircle. (For example, if the n chords are all diameters that meet at the center, t hen \nthe answer is \u00e3 n \n2 \u00e4 \n.) Assume that no two chords share an endpoint. \n17.2  How  to augment  a data  structure  \nThe process of augmenting a basic data structure to  support additional functionality \noccurs  quite  frequently  in algorithm  design.  We\u2019ll  use  it again in the next section to \ndesign a data structure that supports operations on  intervals. This section examines \nthe steps involved in such augmentation. It include s a useful theorem that allows \nyou  to augment  red-black  trees  easily  in many  cases.  \nYou can break the process of augmenting a data stru cture into four steps: \n1. Choose  an underlying  data  structure.  \n2. Determine additional information to maintain in the underlying data structure. \n3. Verify  that  you  can  maintain  the  additional  information  for the basic modifying \noperations on the underlying data structure. \n4. Develop  new  operations.  \nAs  with  any  prescriptive  design  method,  you\u2019ll  rarely  be able to follow the steps \nprecisely in the order given. Most design work cont ains an element of trial and \nerror, and progress on all steps usually proceeds i n parallel. There is no point, 17.2  How  to augment  a data  structure  487 \nfor example, in determining additional information and developing new operations \n(steps  2 and  4) if you  cannot  maintain  the  additional  information  ef\u00fbciently.  Never-  \ntheless,  this  four-step  method  provides  a good  focus  for  your efforts in augmenting \na data structure, and it is also a good framework f or documenting an augmented \ndata structure. \nWe  followed  these  four  steps  in Section  17.1  to design  order- statistic trees. For \nstep  1, we  chose  red-black  trees  as the  underlying  data  structure.  Red-black  trees  \nseemed  like  a good  starting  point  because  they  ef\u00fbciently  support  other  dynamic-  \nset operations on a total order, such as M INIMUM , M AXIMUM , SUCCESSOR , and \nPREDECESSOR . \nIn Step 2, we added the size  attribute, so that each node x stores the size of the \nsubtree rooted at x . Generally,  the  additional  information  makes  operations  more \nef\u00fbcient.  For  example,  it is possible  to implement  OS-S ELECT and  OS-RANK  \nusing just the keys stored in the tree, but then th ey would not run in O.lg n/ time. \nSometimes, the additional information is pointer in formation rather than data, as \nin Exercise  17.2-1.  \nFor  step  3, we  ensured  that  insertion  and  deletion  can  mainta in the size  attributes \nwhile still running in O.lg n/ time. Ideally, you would like to update only a few \nelements of the data structure in order to maintain  the additional information. For \nexample,  if each  node  simply  stores  its  rank  in the  tree,  the  OS-S ELECT and \nOS-RANK  procedures run quickly, but inserting a new minimum  element might \ncause a change to this information in every node of  the tree. Because we chose to \nstore subtree sizes instead, inserting a new elemen t causes information to change \nin only O.lg n/ nodes. \nIn Step  4, we  developed  the  operations  OS-S ELECT and  OS-RANK. After all, \nthe need for new operations is why anyone bothers t o augment a data structure in \nthe  \u00fbrst  place.  Occasionally,  rather  than  developing  new  operations, you can use \nthe additional information to expedite existing one s, as in Exercise  17.2-1.  \nAugmenting  red-black  trees  \nWhen  red-black  trees  underlie  an augmented  data  structure,  we  can  prove  that  in-  \nsertion  and  deletion  can  always  ef\u00fbciently  maintain  certain  kinds  of additional  in-  \nformation,  thereby  simplifying  step  3. The  proof  of the  following  theorem  is sim-  \nilar  to the  argument  from  Section  17.1  that  we  can  maintain  the size  attribute for \norder-statistic  trees.  \nTheorem  17.1  (Augmenting  a red-black  tree)  \nLet f be an attribute  that  augments  a red-black  tree  T of n nodes, and suppose that \nthe value of f for each node x depends only the information in nodes x , x: left, and \nx: right (possibly including x: left: f and x: right : f ), and that the value of x: f can 488  Chapter  17  Augmenting  Data  Structures  \nbe computed from this information in O.1/  time. Then, the insertion and deletion \noperations can maintain the values of f in all nodes of T without asymptotically \naffecting the O.lg n/ running times of these operations. \nProof  The main idea of the proof is that a change to an f attribute in a node x \npropagates only to ancestors of x in the tree. That is, changing x: f may require \nx: p: f to be updated, but nothing else; updating x: p: f may require x: p: p: f to be \nupdated, but nothing else; and so on up the tree. A fter updating T: root : f , no other \nnode depends on the new value, and so the process t erminates. Since the height of \na red-black  tree  is O.lg n/, changing an f attribute in a node costs O.lg n/ time in \nupdating all nodes that depend on the change. \nAs  we  saw  in Section  13.3,  insertion  of a node  x into  red-black  tree  T consists \nof two phases. If the tree T is empty,  then  the  \u00fbrst  phase  simply  makes  x be the \nroot of T . If T is not  empty,  then  the  \u00fbrst  phase  inserts  x as a child of an existing \nnode. Because we assume that the value of x: f depends only on information in \nthe other attributes of x itself and the information in x \u2019s children,  and  because  x \u2019s \nchildren are both the sentinel T: nil, it takes only O.1/  time to compute the value \nof x: f . Having computed x: f , the change propagates up the tree. Thus, the tota l \ntime  for  the  \u00fbrst  phase  of insertion  is O.lg n/. During the second phase, the only \nstructural changes to the tree come from rotations.  Since only two nodes change in \na rotation, but a change to an attribute might need  to propagate up to the root, the \ntotal time for updating the f attributes is O.lg n/ per rotation. Since the number \nof rotations during insertion is at most two, the t otal time for insertion is O.lg n/. \nLike  insertion,  deletion  has  two  phases,  as Section  13.4  discusses.  In the  \u00fbrst  \nphase, changes to the tree occur when a node is del eted, and at most two other \nnodes could move within the tree. Propagating the u pdates to f caused by these \nchanges costs at most O.lg n/, since the changes modify the tree locally along a  \nsimple path from the lowest changed node to the roo t. Fixing up the  red-black  tree  \nduring the second phase requires at most three rota tions, and each rotation requires \nat most O.lg n/ time to propagate the updates to f . Thus, like insertion, the total \ntime for deletion is O.lg n/. \nIn many cases, such as maintaining the size  attributes  in order-statistic  trees,  the  \ncost of updating after a rotation is O.1/ , rather than the O.lg n/ derived in the proof \nof Theorem  17.1.  Exercise  17.2-3  gives  an example.  \nOn  the  other  hand,  when  an update  after  a rotation  requires  a traversal all the way \nup to the root, it is important that insertion into  and deletion  from  a red-black  tree  \nrequire a constant number of rotations. The chapter  notes for Chapter  13  list  other  \nschemes for balancing search trees that do not boun d the number of rotations per \ninsertion or deletion by a constant. If each operat ion might require \u201a.lg n/ rota-  17.3 Interval trees 489 \ntions and each rotation traverses a path up to the root, then a single operation could \nrequire \u201a.lg 2 n/ time, rather than the O.lg n/ time  bound  given  by  Theorem  17.1.  \nExercises  \n17.2-1  \nShow, by adding pointers to the nodes, how to suppo rt each of the dynamic-set  \nqueries M INIMUM , MAXIMUM , SUCCESSOR , and PREDECESSOR  in O.1/  worst-  \ncase  time  on  an augmented  order-statistic  tree.  The  asympto tic performance of \nother  operations  on  order-statistic  trees  should  not  be affected. \n17.2-2  \nCan  you  maintain  the  black-heights  of nodes  in a red-black  tree as attributes in the \nnodes of the tree without affecting the asymptotic performance  of any  of the  red-  \nblack  tree  operations?  Show  how,  or argue  why  not.  How  about  maintaining the \ndepths  of nodes?  \n17.2-3  \nLet \u02dd be an associative binary operator, and let a be an attribute maintained in each \nnode  of a red-black  tree.  Suppose  that  you  want  to include  in each node x an addi-  \ntional attribute f such that x: f D x 1 : a \u02dd x 2 : a \u02dd \ue001 \ue001 \ue001 \u02dd  x m : a, where x 1 ;x  2 ;:::;x  m \nis the inorder listing of nodes in the subtree root ed at x . Show how to update the f \nattributes in O.1/  time after a rotation. Modify your argument slightl y to apply it \nto the size  attributes  in order-statistic  trees.  \n17.3  Interval  trees  \nThis  section  shows  how  to augment  red-black  trees  to support  operations  on  dy-  \nnamic  sets  of intervals.  In this  section,  we\u2019ll  assume  that  intervals  are  closed.  Ex-  \ntending  the  results  to open  and  half-open  intervals  is conce ptually straightforward. \n(See  page  1157  for  de\u00fbnitions  of closed,  open,  and  half-open  intervals.) \nIntervals are convenient for representing events th at each occupy a continuous \nperiod of time. For example, you could query a data base of time intervals  to \u00fbnd  \nout which events occurred during a given interval. The data structure in this section \nprovides  an ef\u00fbcient  means  for  maintaining  such  an interval  database. \nA simple way to represent an interval \u0152t 1 ;t 2 \ufffd is as an object i with attributes \ni: low D t 1 (the low  endpoint ) and i: high D t 2 (the high  endpoint). We  say  that  in-  \ntervals i and i 0 overlap  if i \\ i 0 \u00a4 ;, that is, if i: low \u0dc4 i 0 : high and i 0 : low \u0dc4 i: high. 490  Chapter  17  Augmenting  Data  Structures  \ni i i i \n(a) \ni \n(b) i \n(c) i\u02b9 i\u02b9 i\u02b9 i\u02b9 \ni\u02b9 i\u02b9 \nFigure  17.3  The interval trichotomy for two closed intervals i and i 0 . (a)  If i and i 0 overlap, there \nare four situations, and in each, i: low \u0dc4 i 0 : high and i 0 : low \u0dc4 i: high. (b)  The intervals do not \noverlap, and i: high <i  0 : low. (c)  The intervals do not overlap, and i 0 : high <i:  low. \nAs  Figure  17.3  shows,  any  two  intervals  i and i 0 satisfy the interval  trichotomy , \nthat is, exactly one of the following three propert ies holds: \na. i and i 0 overlap, \nb. i is to the left of i 0 (i.e., i: high <i  0 : low), \nc. i is to the right of i 0 (i.e., i 0 : high <i:  low). \nAn interval  tree  is a red-black  tree  that  maintains  a dynamic  set  of elements,  with \neach element x containing an interval x: int. Interval trees support the following \noperations: \nI NTERVAL-I NSERT .T;x/  adds the element x , whose int attribute is assumed to \ncontain an interval, to the interval tree T . \nI NTERVAL-DELETE .T;x/  removes the element x from the interval tree T . \nI NTERVAL-SEARCH .T;i/  returns a pointer to an element x in the interval tree T \nsuch that x: int overlaps interval i , or a pointer to the sentinel T: nil if no such \nelement belongs to the set. \nFigure  17.4  shows  how  an interval  tree  represents  a set  of intervals.  The  four-  \nstep  method  from  Section  17.2  will  guide  our  design  of an interval tree and the \noperations that run on it. \nStep  1: Underlying  data  structure  \nA red-black  tree  serves  as the  underlying  data  structure.  Each node x contains an \ninterval x: int. The key of x is the low endpoint, x: int: low, of the interval. Thus, \nan inorder tree walk of the data structure lists th e intervals in sorted order by low \nendpoint. 17.3 Interval trees 491 \n0 5 10  15  20  25  30  0 5 6 8 15  16  17  19  25  26  26  \n30  \n20 \n19  \n21  \n23  \n9 \n10  \n8 \n3 (a) \n[0,3]  \n3 [6,10]  \n10  [5,8]  \n10  [8,9]  \n23  \n[15,23]  \n23  [16,21]  \n30  \n[17,19]  \n20  [26,26]  \n26  \n[19,20]  \n20  (b) [25,30]  \n30  int \nmax \nFigure  17.4  An interval tree. (a)  A set  of 10  intervals,  shown  sorted  bottom  to top  by  left  endpo int. \n(b)  The interval tree that represents them. Each node x contains an interval, shown above the dashed \nline, and the maximum value of any interval endpoin t in the subtree rooted at x, shown below the \ndashed line. An inorder tree walk of the tree lists  the nodes in sorted order by left endpoint. \nStep  2: Additional  information  \nIn addition to the intervals themselves, each node x contains a value x: max, which \nis the maximum value of any interval endpoint store d in the subtree rooted at x . \nStep  3: Maintaining  the  information  \nWe must verify that insertion and deletion take O.lg n/ time on an interval tree of n \nnodes. It is simple enough to determine x: max in O.1/  time, given interval x: int \nand the max values of node x \u2019s children:  \nx: max D max fx: int: high;x:  left : max;x:  right : maxg : 492  Chapter  17  Augmenting  Data  Structures  \nThus,  by  Theorem  17.1,  insertion  and  deletion  run  in O.lg n/ time. In fact, you can \nuse  either  Exercise  17.2-3  or 17.3-1  to show  how  to update  all  the max attributes \nthat change after a rotation in just O.1/  time. \nStep  4: Developing  new  operations  \nThe only new operation is I NTERVAL-SEARCH .T;i/, which  \u00fbnds  a node  in tree  T \nwhose interval overlaps interval i . If there is no interval in the tree that overlaps  i , \nthe procedure returns a pointer to the sentinel T: nil. \nI NTERVAL-SEARCH .T;i/  \n1 x D T: root \n2 while  x \u00a4 T: nil and i does not overlap x: int \n3 if x: left \u00a4 T: nil and x: left: max \ue004 i: low \n4 x D x: left / / overlap in left subtree or no overlap in right subt ree \n5 else  x D x: right / / no overlap in left subtree \n6 return  x \nThe search for an interval that overlaps i starts at the root of the tree and proceeds \ndownward.  It terminates  when  either  it \u00fbnds  an overlapping  interval or it reaches \nthe sentinel T: nil. Since each iteration of the basic loop takes O.1/  time, and \nsince the height of an n-node  red-black  tree  is O.lg n/, the I NTERVAL-SEARCH \nprocedure takes O.lg n/ time. \nBefore we see why I NTERVAL-SEARCH is correct,  let\u2019s  examine  how  it works  \non  the  interval  tree  in Figure  17.4.  Let\u2019s  look  for  an interva l that overlaps the \ninterval i D \u015222; 25\ufffd . Begin with x as the root, which contains \u015216; 21\ufffd  and does \nnot overlap i . Since x: left: max D 23  is greater than i: low D 22, the loop continues \nwith x as the  left  child  of the  root4the  node  containing  \u01528; 9\ufffd , which also does not \noverlap i . This time, x: left: max D 10  is less than i: low D 22, and so the loop \ncontinues with the right child of x as the new x . Because the interval \u015215; 23\ufffd  \nstored in this node overlaps i , the procedure returns this node. \nNow  let\u2019s  try  an unsuccessful  search,  for  an interval  that  overlaps i D \u015211; 14\ufffd  \nin the  interval  tree  of Figure  17.4.  Again,  begin  with  x as the root. Since the \nroot\u2019s  interval  \u015216; 21\ufffd  does not overlap i , and since x: left: max D 23  is greater \nthan i: low D 11, go left to the node containing \u01528; 9\ufffd . Interval \u01528; 9\ufffd  does  not  over-  \nlap i , and x: left: max D 10  is less than i: low D 11, and so the search goes right. \n(No interval in the left subtree overlaps i .) Interval \u015215; 23\ufffd  does not overlap i , \nand its left child is T: nil, so again the search goes right, the loop terminat es, and \nI NTERVAL-SEARCH returns the sentinel T: nil. 17.3 Interval trees 493 \nTo see why I NTERVAL-SEARCH is correct,  we  must  understand  why  it suf\u00fbces  \nto examine a single path from the root. The basic i dea is that at any node x , \nif x: int does not overlap i , the search always proceeds in a safe direction: t he \nsearch  will  de\u00fbnitely  \u00fbnd  an overlapping  interval  if the  tree contains one. The \nfollowing theorem states this property more precise ly. \nTheorem  17.2  \nAny execution of I NTERVAL-SEARCH .T;i/  either returns a node whose interval \noverlaps i , or it returns T: nil and the tree T contains  no  node  whose  interval  over-  \nlaps i . \nProof  The while  loop  of lines  235  terminates  when  either  x D T: nil or i overlaps \nx: int. In the latter case, it is certainly correct to re turn x . Therefore, we focus on \nthe former case, in which the while  loop terminates because x D T: nil, which is \nthe node that I NTERVAL-SEARCH returns. \nWe\u2019ll  prove  that  if the  procedure  returns  T: nil, then it did not miss any intervals \nin T that overlap i . The  idea  is to show  that  whether  the  search  goes  left  in line  4 or \nright  in line  5, it always  heads  toward  a node  containing  an interval overlapping i , \nif any  such  interval  exists.  In particular,  we\u2019ll  prove  that  \n1. If the  search  goes  left  in line  4, then  the  left  subtree  of node x contains  an inter-  \nval that overlaps i or the right subtree of x contains no interval that overlaps i . \nTherefore, even if x \u2019s left  subtree  contains  no  interval  that  overlaps  i but the \nsearch goes left, it does not make a mistake, becau se x \u2019s right  subtree  does  not  \ncontain an interval overlapping i , either. \n2. If the  search  goes  right  in line  5, then  the  left  subtree  of x contains no interval \nthat overlaps i . Thus, if the search goes right, it does not make a mistake. \nFor  both  cases,  we  rely  on  the  interval  trichotomy.  Let\u2019s  start with the case \nwhere the search goes right, whose proof is simpler . By the tests  in line  3, we  \nknow that x: left D T: nil or x: left: max < i:  low. If x: left D T: nil, then x \u2019s left  \nsubtree contains no interval that overlaps i , since it contains no intervals at all. Now \nsuppose that x: left \u00a4 T: nil, so that we must have x: left: max <i:  low. Consider \nany interval i 0 in x \u2019s left  subtree.  Because  x: left : max is the maximum endpoint in \nx \u2019s left  subtree,  we  have  i 0 : high \u0dc4 x: left: max. Thus,  as Figure  17.5(a)  shows,  \ni 0 : high \u0dc4 x: left: max \n< i: low : \nBy the interval trichotomy, therefore, intervals i and i 0 do not overlap, and so x \u2019s \nleft subtree contains no interval that overlaps i . \nNow we examine the case in which the search goes le ft. If the left subtree of \nnode x contains an interval that overlaps i , we\u2019re  done,  so let\u2019s  assume  that  no  node  494  Chapter  17  Augmenting  Data  Structures  \ni \n(a) (b) i\u02b9 \ni\u02b9 i i \u02b9 i\u02b9\u02b9 i\u02b9\u02b9 i\u02b9\u02b9 \nFigure  17.5  Intervals  in the  proof  of Theorem  17.2.  The  value  of x: left: max is shown in each case \nas a dashed line. (a)  The search goes right. No interval i 0 in x\u2019s left  subtree  can  overlap  i . (b)  The \nsearch goes left. The left subtree of x contains an interval that overlaps i (situation not shown), \nor x\u2019s left  subtree  contains  an  interval  i 0 such that i 0 : high D x: left: max. Since i does not overlap i 0 , \nneither does it overlap any interval i 00 in x\u2019s right  subtree,  since  i 0 : low \u0dc4 i 00 : low. \nin x \u2019s left  subtree  overlaps  i . We need to show that in this case, no node in x \u2019s right  \nsubtree overlaps i , so that going left will not miss any overlaps in x \u2019s right  subtree.  \nBy  the  tests  in line  3, the  left  subtree  of x is not empty and x: left: max \ue004 i: low. By \nthe  de\u00fbnition  of the  max attribute, x \u2019s left  subtree  contains  some  interval  i 0 such \nthat \ni 0 : high D x: left: max \n\ue004 i: low ; \nas illustrated  in Figure  17.5(b).  Since  i 0 is in x \u2019s left  subtree,  it does  not  overlap  i , \nand since i 0 : high \ue004 i: low, the interval trichotomy tells us that i: high < i  0 : low. \nNow we bring in the property that interval trees ar e keyed on the low endpoints \nof intervals. Because i 0 is in x \u2019s left  subtree,  we  have  i 0 : low \u0dc4 x: int: low. Now \nconsider any interval i 00 in x \u2019s right  subtree,  so that  x: int: low \u0dc4 i 00 : low. Putting \ninequalities together, we get \ni: high < i  0 : low \n\u0dc4 x: int: low \n\u0dc4 i 00 : low : \nBecause i: high < i  00 : low, the interval trichotomy tells us that i and i 00 do not \noverlap. Since we chose i 00 as any interval in x \u2019s right  subtree,  no  node  in x \u2019s right  \nsubtree overlaps i . \nThus, the I NTERVAL-SEARCH procedure works correctly. 17.3 Interval trees 495 \nExercises  \n17.3-1  \nWrite pseudocode for L EFT-ROTATE  that operates on nodes in an interval tree and \nupdates all the max attributes that change in O.1/  time. \n17.3-2  \nDescribe  an ef\u00fbcient  algorithm  that,  given  an interval  i , returns  an interval  over-  \nlapping i that has the minimum low endpoint, or T: nil if no such interval exists. \n17.3-3  \nGiven  an interval  tree  T and an interval i , describe how to list all intervals in T \nthat overlap i in O.min fn;k  lg ng/ time, where k is the number of intervals in the \noutput list. ( Hint: One  simple  method  makes  several  queries,  modifying  the  tree  \nbetween queries. A slightly more complicated method  does not modify the tree.) \n17.3-4  \nSuggest  modi\u00fbcations  to the  interval-tree  procedures  to support  the  new  opera-  \ntion I NTERVAL-SEARCH-E  XACTLY .T;i/ , where T is an interval tree and i is \nan interval. The operation should return a pointer to a node x in T such that \nx: int: low D i: low and x: int: high D i: high, or T: nil if T contains no such node. \nAll operations, including I NTERVAL-SEARCH-EXACTLY , should run in O.lg n/ \ntime on an n-node  interval  tree.  \n17.3-5  \nShow how to maintain a dynamic set Q of numbers that supports the operation \nMIN-GAP, which gives the absolute value of the difference of the two closest  num-  \nbers in Q. For example, if we have Q D f1;5;9;15;18;22 g , then M IN-GAP.Q/  \nreturns 3, since 15  and 18  are the two closest numbers in Q. Make the operations \nI NSERT , DELETE , SEARCH , and M IN-GAP as ef\u00fbcient  as possible,  and  analyze  \ntheir running times. \n? 17.3-6  \nVLSI databases commonly represent an integrated cir cuit as a list  of rectan-  \ngles. Assume that each rectangle is rectilinearly o riented (sides parallel to the \nx - and  y -axes),  so that  each  rectangle  is represented  by  four  values : its minimum \nand maximum x - and  y -coordinates.  Give  an O.n  lg n/-time  algorithm  to decide  \nwhether a set of n rectangles so represented contains two rectangles t hat overlap. \nYour algorithm need not report all intersecting pai rs, but it must  report  that  an over-  \nlap exists if one rectangle entirely covers another , even if the boundary lines do not \nintersect. ( Hint: Move a <sweep= line across the set of rectangles.) 496  Chapter  17  Augmenting  Data  Structures  \nProblems  \n17-1  Point  of maximum  overlap  \nYou wish to keep track of a point  of maximum  overlap  in a set  of intervals4a  \npoint with the largest number of intervals in the s et that overlap it. \na. Show that there is always a point of maximum overla p that is an endpoint of \none of the intervals. \nb. Design  a data  structure  that  ef\u00fbciently  supports  the  operat ions I NTERVAL- \nI NSERT , I NTERVAL-DELETE , and F IND-POM,  which  returns  a point  of max-  \nimum overlap. ( Hint: Keep  a red-black  tree  of all  the  endpoints.  Associate  \na value of C1 with each left endpoint, and associate a value of \ue0031 with each \nright endpoint. Augment each node of the tree with some extra information to \nmaintain the point of maximum overlap.) \n17-2  Josephus  permutation  \nWe  de\u00fbne  the  Josephus  problem  as follows. A group of n people form a circle, \nand we are given a positive integer m \u0dc4 n. Beginning  with  a designated  \u00fbrst  \nperson, proceed around the circle, removing every mth person. After each person is \nremoved, counting continues around the circle that remains. This process continues \nuntil nobody remains in the circle. The order in wh ich the people are removed from \nthe  circle  de\u00fbnes  the  .n;  m/-Josephus  permutation  of the integers 1;2;:::;n . For \nexample, the .7;3/-Josephus  permutation  is h3;6;2;7;5;1;4 i. \na. Suppose that m is a constant. Describe an O.n/-time  algorithm  that,  given  an \ninteger n, outputs the .n;m/-Josephus  permutation.  \nb. Suppose that m is not necessarily a constant. Describe an O.n  lg n/-time  algo-  \nrithm that, given integers n and m, outputs the .n;m/-Josephus  permutation.  \nChapter  notes  \nIn their  book,  Preparata  and  Shamos  [364]  describe  several  of the interval trees \nthat appear in the literature, citing work by H. Ed elsbrunner (1980)  and  E. M.  \nMcCreight  (1981).  The  book  details  an interval  tree  that,  gi ven a static database \nof n intervals, allows us to enumerate all k intervals that overlap a given query \ninterval in O.k  C lg n/ time. 18  B-Trees  \nB-trees  are  balanced  search  trees  designed  to work  well  on  disk drives or other \ndirect-access  secondary  storage  devices.  B-trees  are  similar  to red-black  trees  \n(Chapter  13),  but  they  are  better  at minimizing  the  number  of operations that access \ndisks. (We often say just <disk= instead of <disk d rive.=) Many database systems \nuse  B-trees,  or variants  of B-trees,  to store  information.  \nB-trees  differ  from  red-black  trees  in that  B-tree  nodes  may  have many children, \nfrom a few to thousands. That is, the <branching fa ctor= of a B-tree  can  be quite  \nlarge, although it usually depends on characteristi cs of the disk  drive  used.  B-trees  \nare  similar  to red-black  trees  in that  every  n-node  B-tree  has  height  O.lg n/, so that \nB-trees  can  implement  many  dynamic-set  operations  in O.lg n/ time.  But  a B-tree  \nhas  a larger  branching  factor  than  a red-black  tree,  so the  base of the logarithm that \nexpresses its height is larger, and hence its heigh t can be considerably lower. \nB-trees  generalize  binary  search  trees  in a natural  manner.  Figure  18.1  shows  a \nsimple  B-tree.  If an internal  B-tree  node  x contains x:n  keys, then x has x:n  C 1 \nchildren. The keys in node x serve as dividing points separating the range of ke ys \nhandled by x into x:n  C 1 subranges, each handled by one child of x . A search for \na key  in a B-tree  makes  an .x:n  C 1/-way  decision  based  on  comparisons  with  the  \nx:n  keys stored at node x . An internal node contains pointers to its childre n, but a \nleaf node does not. \nSection  18.1  gives  a precise  de\u00fbnition  of B-trees  and  proves  that the height of \na B-tree  grows  only  logarithmically  with  the  number  of nodes  it contains.  Sec-  \ntion  18.2  describes  how  to search  for  a key  and  insert  a key  into  a B-tree,  and  \nSection  18.3  discusses  deletion.  Before  proceeding,  howev er, we need to ask why \nwe evaluate data structures designed to work on a d isk drive differently from data \nstructures  designed  to work  in main  random-access  memory.  498 Chapter 18 B-Trees \nM \nD H Q T X \nB C F G J K L N P R S V W Y Z T: root \nFigure  18.1  A B-tree  whose  keys  are  the  consonants  of English.  An  interna l node x containing \nx:n  keys has x:n  C 1 children. All leaves are at the same depth in the t ree. The blue nodes are \nexamined in a search for the letter R. \nData  structures  on  secondary  storage  \nComputer systems take advantage of various technolo gies that provide memory \ncapacity. The main  memory  of a computer system normally consists of silicon \nmemory chips. This technology is typically more tha n an order of magnitude more \nexpensive per bit stored than magnetic storage tech nology, such as tapes or disk \ndrives. Most computer systems also have secondary  storage  based  on  solid-state  \ndrives (SSDs) or magnetic disk drives. The amount o f such secondary storage often \nexceeds the amount of primary memory by one to two orders of magnitude. SSDs \nhave faster access times than magnetic disk drives,  which are mechanical devices. \nIn recent years, SSD capacities have increased whil e their prices have decreased. \nMagnetic disk drives typically have much higher cap acities than SSDs, and they \nremain  a more  cost-effective  means  for  storing  massive  amou nts of information. \nDisk drives that store several terabytes 1 can be found for under $ 100. \nFigure  18.2  shows  a typical  disk  drive.  The  drive  consists  of one or more plat-  \nters, which rotate at a constant speed around a common spindle . A magnetizable \nmaterial covers the surface of each platter. The dr ive reads and  writes  each  plat-  \nter by a head  at the end of an arm. The arms can move their heads toward or \naway from the spindle. The surface that passes unde rneath a given head when it is \nstationary is called a track . \nAlthough disk drives are cheaper and have higher ca pacity than main memory, \nthey are much, much slower because they have moving  mechanical parts. The \nmechanical motion has two components: platter rotat ion and arm movement. As of \nthis writing, commodity disk drives rotate at speed s of 5400315,000  revolutions  per  \nminute  (RPM).  Typical  speeds  are  15,000  RPM  in server-grade  drives, 7200  RPM \n1 When specifying disk capacities, one terabyte is on e trillion bytes, rather than 2 40  bytes. Chapter 18 B-Trees 499 \nplatter track \narms read/write \nhead spindle \nFigure  18.2  A typical magnetic disk drive. It consists of one o r more platters covered with a \nmagnetizable material (two platters are shown here)  that rotate around a spindle. Each platter is read  \nand written with a head, shown in red, at the end o f an arm. Arms rotate around a common pivot \naxis. A track, drawn in blue, is the surface that p asses beneath the read/write head when the head is \nstationary. \nin drives for desktops, and 5400  RPM in drives for laptops. Although 7200  RPM \nmay seem fast, one rotation takes 8:33  milliseconds, which is over 5 orders of \nmagnitude longer than the 50  nanosecond access times (more or less) commonly \nfound for main memory. In other words, if a compute r waits a full rotation for a \nparticular item to come under the read/write head, it could access main memory \nmore  than  100,000  times  during  that  span.  The  average  wait  is only half a rotation, \nbut still, the difference in access times for main memory compared with disk drives \nis enormous. Moving the arms also takes some time. As of this writing, average \naccess times for commodity disk drives are around 4 milliseconds. \nIn order to amortize the time spent waiting for mec hanical movements, also \nknown as latency , disk drives access not just one item but several at a time. Infor-  \nmation  is divided  into  a number  of equal-sized  blocks  of bits  that  appear  consecu-  \ntively within tracks, and each disk read or write i s of one or more entire blocks. 2 \nTypical disk drives have block sizes running from 512  to 4096  bytes.  Once  the  \nread/write head is positioned correctly and the pla tter has rotated to the beginning \nof the desired block, reading or writing a magnetic  disk drive is entirely electronic \n(aside from the rotation of the platter), and the d isk drive can quickly read or write \nlarge amounts of data. \n2 SSDs also exhibit greater latency than main memory and access data in blocks. 500 Chapter 18 B-Trees \nOften,  accessing  a block  of information  and  reading  it from  a disk drive takes \nlonger than processing all the information read. Fo r this reason, in this chapter \nwe\u2019ll  look  separately  at the  two  principal  components  of the  running time: \n\ue001 the number of disk accesses, and \n\ue001 the CPU (computing) time. \nWe measure the number of disk accesses in terms of the number o f blocks  of infor-  \nmation that need to be read from or written to the disk drive. A lthough  disk-access  \ntime  is not  constant4it  depends  on  the  distance  between  the  current track and the \ndesired track and also on the initial rotational po sition of the  platters4the  number  \nof blocks  read  or written  provides  a good  \u00fbrst-order  approxi mation of the total time \nspent accessing the disk drive. \nIn a typical  B-tree  application,  the  amount  of data  handled  is so large that all \nthe  data  do  not  \u00fbt into  main  memory  at once.  The  B-tree  algorit hms copy selected \nblocks from disk into main memory as needed and wri te back onto disk the blocks \nthat  have  changed.  B-tree  algorithms  keep  only  a constant  number of blocks in \nmain memory at any time, and thus the size of main memory does not limit the size \nof B-trees  that  can  be handled.  \nB-tree  procedures  need  to be able  to read  information  from  disk  into  main  mem-  \nory and write information from main memory to disk.  Consider some object x . If x \nis currently  in the  computer\u2019s  main  memory,  then  the  code  can  refer to the attributes \nof x as usual: x: key, for example. If x resides on disk, however, then the procedure \nmust perform the operation D ISK-READ.x/  to read the block containing object x \ninto main memory before it can refer to x \u2019s attributes.  (Assume  that  if x is already \nin main memory, then D ISK-READ .x/  requires  no  disk  accesses:  it is a <no-op.=)  \nSimilarly, procedures call D ISK-WRITE .x/  to save any changes that have been \nmade to the attributes of object x by writing to disk the block containing x . Thus, \nthe typical pattern for working with an object is a s follows: \nx D a pointer to some object \nDISK-READ .x/  \noperations that access and/or modify the attributes  of x \nDISK-WRITE .x/  / / omitted if no attributes of x were changed \nother operations that access but do not modify attr ibutes of x \nThe system can keep only a limited number of blocks  in main memory at any one \ntime.  Our  B-tree  algorithms  assume  that  the  system  automatically  \u00fcushes  from  \nmain memory blocks that are no longer in use. \nSince  in most  systems  the  running  time  of a B-tree  algorithm  depends  primar-  \nily on the number of D ISK-READ and DISK-WRITE operations it performs, we 18.1  De\ufb01nition  of B-trees  501 \n1000  \n1001  1 node,  \n1000  keys  \n1001  nodes,  \n1,001,000  keys  \n1,002,001  nodes,  \n1,002,001,000  keys  1000  \n1001  1000  1000  \n1001  \u2026 \n1001  \n1000  1000  1000  \u2026 T: root \nFigure  18.3  A B-tree  of height  2 containing  over  one  billion  keys.  Shown  inside each node x \nis x:n, the number of keys in x. Each internal node and leaf contains 1000  keys.  This  B-tree  has  \n1001  nodes at depth 1 and over one million leaves at depth 2. \ntypically want each of these operations to read or write as much information as \npossible.  Thus,  a B-tree  node  is usually  as large  as a whole  disk block, and this \nsize  limits  the  number  of children  a B-tree  node  can  have.  \nLarge  B-trees  stored  on  disk  drives  often  have  branching  factors between 50  \nand 2000 , depending on the size of a key relative to the si ze of a block. A large \nbranching factor dramatically reduces both the heig ht of the tree and the number of \ndisk  accesses  required  to \u00fbnd  any  key.  Figure  18.3  shows  a B-tree with a branching \nfactor of 1001  and height 2 that can store over one billion keys. Nevertheless,  if the \nroot node is kept permanently in main memory, at mo st two disk accesses  suf\u00fbce  \nto \u00fbnd  any  key  in this  tree.  \n18.1  De\ufb01nition  of B-trees  \nTo  keep  things  simple,  let\u2019s  assume,  as we  have  for  binary  search  trees  and  red-  \nblack trees, that any satellite information associa ted with a key resides in the same \nnode as the key. In practice, you might actually st ore with each key just a pointer \nto another disk block containing the satellite info rmation for  that  key.  The  pseu-  \ndocode in this chapter implicitly assumes that the satellite information associated \nwith a key, or the pointer to such satellite inform ation, travels  with  the  key  when-  \never  the  key  is moved  from  node  to node.  A common  variant  on  a B-tree, known \nas a B C -tree , stores all the satellite information in the leave s and stores only keys \nand child pointers in the internal nodes, thus maxi mizing the branching factor of \nthe internal nodes. \nA B-tree  T is a rooted tree with root T: root having the following properties: 502 Chapter 18 B-Trees \n1. Every  node  x has the following attributes: \na. x:n, the number of keys currently stored in node x , \nb. the x:n  keys themselves, x: key  1 ;x:  key  2 ;:::;x:  key  x:n  , stored  in monotoni-  \ncally increasing order, so that x: key  1 \u0dc4 x: key  2 \u0dc4 \ue001 \ue001 \ue001 \u0dc4  x: key  x:n  , \nc. x: leaf , a boolean value that is TRUE if x is a leaf and FALSE if x is an internal \nnode. \n2. Each internal node x also contains x:n  C 1 pointers x:c  1 ;x:c  2 ;:::;x:c  x:nC1 \nto its children. Leaf nodes have no children, and s o their c i attributes  are  unde-  \n\u00fbned.  \n3. The  keys  x: key  i separate the ranges of keys stored in each subtree:  if k i is any \nkey stored in the subtree with root x:c  i , then \nk 1 \u0dc4 x: key  1 \u0dc4 k 2 \u0dc4 x: key  2 \u0dc4 \ue001 \ue001 \ue001 \u0dc4  x: key  x:n  \u0dc4 k x:nC1 : \n4. All  leaves  have  the  same  depth,  which  is the  tree\u2019s  height  h. \n5. Nodes  have  lower  and  upper  bounds  on  the  number  of keys  they  can contain, \nexpressed  in terms  of a \u00fbxed  integer  t \ue004 2 called the minimum  degree  of the \nB-tree:  \na. Every node other than the root must have at leas t t \ue003 1 keys. Every internal \nnode other than the root thus has at least t children. If the tree is nonempty, \nthe root must have at least one key. \nb. Every node may contain at most 2t \ue003 1 keys. Therefore, an internal node \nmay have at most 2t children. We say that a node is full  if it contains exactly \n2t \ue003 1 keys. 3 \nThe  simplest  B-tree  occurs  when  t D 2. Every internal node then has either 2, \n3, or 4 children, and it is a 2-3-4  tree. In practice, however, much larger values of t \nyield  B-trees  with  smaller  height.  \nThe  height  of a B-tree  \nThe number of disk accesses required for most opera tions on a B-tree  is propor-  \ntional  to the  height  of the  B-tree.  The  following  theorem  bounds  the  worst-case  \nheight  of a B-tree.  \n3 Another  common  variant  on  a B-tree,  known  as a B \ue001 -tree , requires each internal node to be at \nleast 2=3  full,  rather  than  at least  half  full,  as a B-tree  requires.  18.1  De\ufb01nition  of B-trees  503 \n1 depth number \nof nodes \n3 2t 2 1 \n2 0 1 \n2 \n2t \u2026 \u2026 t 3 1 t 3 1 \nt t \nt 3 1 t 3 1 t 3 1 t 3 1 \nt t t t \nt 3 1 t 3 1 \u2026 t 3 1 t 3 1 \u2026 t 3 1 t 3 1 \u2026 t 3 1 t 3 1 \u2026 T: root \nFigure  18.4  A B-tree  of height  3 containing a minimum possible number of keys. Shown  inside \neach node x is x:n. \nTheorem  18.1  \nIf n \ue004 1, then for any n-key  B-tree  T of height h and minimum degree t \ue004 2, \nh \u0dc4 log t n C 1 \n2 : \nProof  By  de\u00fbnition,  the  root  of a nonempty  B-tree  T contains at least one key, \nand all other nodes contain at least t \ue003 1 keys. Let h be the height of T . Then T \ncontains at least 2 nodes at depth 1, at least 2t nodes at depth 2, at least 2t 2 nodes \nat depth 3, and so on, until at depth h, it has at least 2t h\ue0021 nodes.  Figure  18.4  \nillustrates such a tree for h D 3. The number n of keys  therefore  satis\u00fbes  the  \ninequality \nn \ue004 1 C .t \ue003 1/ h X  \ni D1 2t i \ue0021 \nD 1 C 2.t  \ue003 1/ \u00cf t h \ue003 1 \nt \ue003 1 \u00d0 \n(by  equation  (A.6)  on  page  1142)  \nD 2t h \ue003 1;  \nso that t h \u0dc4 .n C 1/=2. Taking  base-t logarithms  of both  sides  proves  the  theo-  \nrem. \nYou  can  see  the  power  of B-trees  as compared  with  red-black  trees. Although \nthe height of the tree grows as O.log n/ in both cases (recall that t is a constant), \nfor  B-trees  the  base  of the  logarithm  can  be many  times  larger.  Thus,  B-trees  save  504 Chapter 18 B-Trees \na factor of about lg t over  red-black  trees  in the  number  of nodes  examined  for  \nmost tree operations. Because examining an arbitrar y node in a tree usually entails \naccessing  the  disk,  B-trees  avoid  a substantial  number  of disk accesses. \nExercises  \n18.1-1  \nWhy  isn\u2019t  a minimum  degree  of t D 1 allowed?  \n18.1-2  \nFor what values of t is the  tree  of Figure  18.1  a legal  B-tree?  \n18.1-3  \nShow  all  legal  B-trees  of minimum  degree  2 that store the keys 1;2;3;4;5 . \n18.1-4  \nAs a function of the minimum degree t , what is the maximum number of keys that \ncan  be stored  in a B-tree  of height  h? \n18.1-5  \nDescribe the data structure that results if each bl ack node in a red-black  tree  absorbs  \nits red children, incorporating their children with  its own. \n18.2  Basic  operations  on  B-trees  \nThis  section  presents  the  details  of the  operations  B-T REE-SEARCH, B-T REE- \nCREATE, and  B-T REE-I NSERT . These procedures observe two conventions: \n\ue001 The  root  of the  B-tree  is always  in main  memory,  so that  no  procedure ever \nneeds to perform a D ISK-READ on the root. If any changes to the root node \noccur, however, then D ISK-WRITE must be called on the root. \n\ue001 Any nodes that are passed as parameters must alread y have had a D ISK-READ \noperation performed on them. \nThe  procedures  are  all  <one-pass=  algorithms  that  proceed  downward from the root \nof the tree, without having to back up. \nSearching  a B-tree  \nSearching  a B-tree  is much  like  searching  a binary  search  tree, except that instead \nof making  a binary,  or <two-way,=  branching  decision  at each  node, the search 18.2  Basic  operations  on  B-trees  505 \nmakes a multiway branching decision according to th e number of the  node\u2019s  chil-  \ndren. More precisely, at each internal node x , the search makes an .x:n  C 1/-way  \nbranching decision. \nThe  procedure  B-T REE-SEARCH generalizes the T REE-SEARCH procedure  de-  \n\u00fbned  for  binary  search  trees  on  page  316.  It takes  as input  a pointer to the root \nnode x of a subtree and a key k to be searched  for  in that  subtree.  The  top-level  \ncall  is thus  of the  form  B-T REE-SEARCH .T:  root ;k/. If k is in the  B-tree,  then  \nB-T REE-SEARCH returns the ordered pair .y;i/  consisting of a node y and an \nindex i such that y: key  i D k. Otherwise,  the  procedure  returns  NIL. \nB-T REE-SEARCH .x;k/  \n1 i D 1 \n2 while  i \u0dc4 x:n  and k>x:  key  i \n3 i D i C 1 \n4 if i \u0dc4 x:n  and k = = x: key  i \n5 return  .x;i/  \n6 elseif  x: leaf \n7 return  NIL \n8 else  DISK-READ .x:c  i / \n9 return  B-T REE-SEARCH .x:c  i ;k/  \nUsing  a linear-search  procedure,  lines  133  of B-T REE-SEARCH \u00fbnd  the  smallest  \nindex i such that k \u0dc4 x: key  i , or else they set i to x:n  C 1. Lines  435  check  to \nsee whether the search has discovered the key, retu rning if it has.  Otherwise,  if x \nis a leaf,  then  line  7 terminates  the  search  unsuccessfully,  and if x is an internal \nnode,  lines  839  recurse  to search  the  appropriate  subtree  of x , after performing \nthe necessary D ISK-READ on  that  child.  Figure  18.1  illustrates  the  operation  of \nB-T REE-SEARCH . The blue nodes are those examined during a search  for the \nkey R. \nAs in the T REE-SEARCH procedure  for  binary  search  trees,  the  nodes  encoun-  \ntered during the recursion form a simple path downw ard from the root of the \ntree.  The  B-T REE-SEARCH procedure therefore accesses O.h/  D O.log t n/ disk \nblocks, where h is the  height  of the  B-tree  and  n is the  number  of keys  in the  B-tree.  \nSince x:n<2t  , the while  loop  of lines  233  takes  O.t/  time within each node, and \nthe total CPU time is O.th/  D O.t  log t n/. \nCreating  an  empty  B-tree  \nTo  build  a B-tree  T , \u00fbrst  use  the  B-T REE-CREATE procedure on the next page \nto create  an empty  root  node  and  then  call  the  B-T REE-I NSERT procedure on 506 Chapter 18 B-Trees \npage  508  to add  new  keys.  Both  of these  procedures  use  an auxil iary procedure \nALLOCATE-NODE, whose pseudocode we omit and which allocates one disk block \nto be used as a new node in O.1/  time. A node created by A LLOCATE-NODE  \nrequires no D ISK-READ, since there is as yet no useful information store d on the \ndisk  for  that  node.  B-T REE-CREATE requires O.1/  disk operations and O.1/  CPU \ntime. \nB-T REE-CREATE .T/  \n1 x D ALLOCATE-NODE  ./ \n2 x: leaf D TRUE \n3 x:n  D 0 \n4 DISK-WRITE .x/  \n5 T: root D x \nInserting  a key  into  a B-tree  \nInserting  a key  into  a B-tree  is signi\u00fbcantly  more  complicat ed than inserting a \nkey into a binary search tree. As with binary searc h trees, you search for the leaf \nposition  at which  to insert  the  new  key.  With  a B-tree,  howeve r, you cannot simply \ncreate a new leaf node and insert it, as the result ing tree would fail to be a valid \nB-tree.  Instead,  you  insert  the  new  key  into  an existing  leaf  node. Since you cannot \ninsert a key into a leaf node that is full, you nee d an operation that splits  a full \nnode y (having 2t \ue003 1 keys) around its median  key  y: key  t into two nodes having \nonly t \ue003 1 keys each. The median key moves up into y \u2019s parent  to identify  the  \ndividing point between the two new trees. But if y \u2019s parent  is also  full,  you  must  \nsplit it before you can insert the new key, and thu s you could end up splitting full \nnodes all the way up the tree. \nTo avoid having to go back up the tree, just split every full node you encounter \nas you go down the tree. In this way, whenever you need to split a full node, you \nare assured that its parent is not full. Inserting a key into a B-tree  then  requires  \nonly a single pass down the tree from the root to a  leaf. \nSplitting  a node  in a B-tree  \nThe  procedure  B-T REE-SPLIT-CHILD on the facing page takes as input a nonfull  \ninternal node x (assumed to reside in main memory) and an index i such that x:c  i \n(also assumed to reside in main memory) is a full  child of x . The procedure splits \nthis child in two and adjusts x so that it has an additional child. To split a full  root, \nyou  \u00fbrst  need  to make  the  root  a child  of a new  empty  root  node,  so that you can 18.2  Basic  operations  on  B-trees  507 \nuse  B-T REE-SPLIT-CHILD . The tree thus grows in height by 1: splitting is the \nonly means by which the tree grows taller. \nB-T REE-SPLIT-CHILD .x;i/  \n1 y D x:c  i / / full node to split \n2 \u00b4 D ALLOCATE-NODE  ./ / / \u00b4 will take half of y \n3 \u00b4: leaf D y: leaf \n4 \u00b4: n D t \ue003 1 \n5 for  j D 1 to t \ue003 1 / / \u00b4 gets y \u2019s greatest  keys  . . . \n6 \u00b4: key  j D y: key  j Ct \n7 if not y: leaf \n8 for  j D 1 to t / / . . . and its corresponding children \n9 \u00b4:c  j D y:c  j Ct \n10  y: n D t \ue003 1 / / y keeps t \ue003 1 keys \n11  for  j D x:n  C 1 downto  i C 1 / / shift x \u2019s children  to the  right  . . . \n12  x:c  j C1 D x:c  j \n13  x:c  i C1 D \u00b4 / / . . . to make room for \u00b4 as a child \n14  for  j D x:n  downto  i / / shift the corresponding keys in x \n15  x: key  j C1 D x: key  j \n16  x: key  i D y: key  t / / insert y \u2019s median  key  \n17  x:n  D x:n  C 1 / / x has gained a child \n18  DISK-WRITE .y/  \n19  DISK-WRITE .\u00b4/  \n20 DISK-WRITE .x/  \nFigure  18.5  illustrates  how  a node  splits.  B-T REE-SPLIT-CHILD splits the full \nnode y D x:c  i about its median key ( S in the  \u00fbgure),  which  moves  up  into  y \u2019s \nparent node x . Those keys in y that are greater than the median key move into a \nnew node \u00b4, which becomes a new child of x . \nB-T REE-SPLIT-CHILD works by straightforward cutting and pasting. Node x \nis the parent of the node y being split, which is x \u2019s i th child  (set  in line  1).  Node  y \noriginally has 2t children and 2t \ue003 1 keys, but splitting reduces y to t children and \nt \ue003 1 keys. The t largest children and t \ue003 1 keys of node y move over to node \u00b4, \nwhich becomes a new child of x , positioned just after y in x \u2019s table  of children.  \nThe median key of y moves up to become the key in node x that separates the \npointers to nodes y and \u00b4. \nLines 2\u20139 create node \u00b4 and give it the largest t \ue003 1 keys and, if y and \u00b4 are \ninternal nodes, the corresponding t children of y . Line  10  adjusts  the  key  count  \nfor y . Then,  lines  11317  shift  keys  and  child  pointers  in x to the right in order to \nmake room for x \u2019s new  child,  insert  \u00b4 as a new child of x , move the median key 508 Chapter 18 B-Trees \nN W \u2026 \u2026 N W S \u2026 \u2026 \nR S T Q P U V R Q P T U V x x \nT 1 T 1 T 2 T 2 T 3 T 3 T 4 T 4 T 5 T 5 T 6 T 6 T 7 T 7 T 8 T 8 y D x:c  i y D x:c  i \u00b4 D x:c  i C1 x: key i \ue0021 \nx: key i \ue0021 \nx: key i \nx: key i \nx: key i C1 \nFigure  18.5  Splitting a node with t D 4. Node y D x:c  i splits into two nodes, y and \u00b4, and the \nmedian key S of y moves up into y\u2019s parent.  \nfrom y up to x in order to separate y from \u00b4, and adjust x \u2019s key  count.  Lines  18320  \nwrite  out  all  modi\u00fbed  disk  blocks.  The  CPU  time  used  by  B-T REE-SPLIT-CHILD \nis \u201a.t/ , due to the for  loops  in lines  536  and  839.  (The  for  loops  in lines  11312  and  \n14315  also  run  for  O.t/  iterations.) The procedure performs O.1/  disk operations. \nInserting  a key  into  a B-tree  in a single  pass  down  the  tree  \nInserting a key k into  a B-tree  T of height h requires just a single pass down the \ntree and O.h/  disk accesses. The CPU time required is O.th/  D O.t  log t n/. \nThe  B-T REE-I NSERT procedure  uses  B-T REE-SPLIT-CHILD to guarantee that the \nrecursion never descends to a full node. If the roo t is full, B-TREE-I NSERT splits \nit by  calling  the  procedure  B-T REE-SPLIT-ROOT  on the facing page. \nB-T REE-I NSERT .T;k/  \n1 r D T: root \n2 if r: n = = 2t \ue003 1 \n3 s D B-T REE-SPLIT-ROOT  .T/  \n4 B-T REE-I NSERT-NONFULL  .s;k/  \n5 else  B-T REE-I NSERT-NONFULL  .r;k/  \nB-T REE-I NSERT works  as follows.  If the  root  is full,  then  line  3 calls  B-T REE- \nSPLIT-ROOT  in line  3 to split  it. A new  node  s (with two children) becomes the \nroot  and  is returned  by  B-T REE-SPLIT-ROOT. Splitting the root, illustrated in \nFigure  18.6,  is the  only  way  to increase  the  height  of a B-tree . Unlike a binary \nsearch  tree,  a B-tree  increases  in height  at the  top  instead  of at the  bottom.  Re-  \ngardless  of whether  the  root  split,  B-T REE-I NSERT \u00fbnishes  by  calling  B-T REE- \nI NSERT-NONFULL  to insert key k into the tree rooted at the nonfull root node, 18.2  Basic  operations  on  B-trees  509 \nT 8 T 7 T 6 T 5 T 4 T 3 T 2 T 1 F H L D A N P s \nH \nr \nT 8 T 7 T 6 T 5 T 4 T 3 T 2 T 1 F D A L N P r T: root T: root \nFigure  18.6  Splitting the root with t D 4. Root node r splits in two, and a new root node s is \ncreated. The new root contains the median key of r and has the two halves of r as children. The \nB-tree  grows  in height  by  one  when  the  root  is split.  A B-tree\u2019  s height increases only when the root \nsplits. \nwhich  is either  the  new  root  (the  call  in line  4) or the  origina l root (the call in \nline  5).  \nB-T REE-SPLIT-ROOT  .T/  \n1 s D ALLOCATE-NODE  ./ \n2 s: leaf D FALSE \n3 s: n D 0 \n4 s:c  1 D T: root \n5 T: root D s \n6 B-T REE-SPLIT-CHILD .s;1/  \n7 return  s \nThe  auxiliary  procedure  B-T REE-I NSERT-NONFULL  on  page  511  inserts  key  k \ninto node x , which is assumed to be nonfull when the procedure  is called. B-T REE- \nI NSERT-NONFULL  recurses as necessary down the tree, at all times g uaranteeing \nthat  the  node  to which  it recurses  is not  full  by  calling  B-T REE-SPLIT-CHILD \nas necessary.  The  operation  of B-T REE-I NSERT and the recursive operation of \nB-T REE-I NSERT-NONFULL  guarantee that this assumption is true. \nFigure  18.7  illustrates  the  various  cases  of how  B-T REE-I NSERT-NONFULL  in-  \nserts  a key  into  a B-tree.  Lines  338  handle  the  case  in which  x is a leaf node by \ninserting key k into x , shifting to the right all keys in x that are greater than k. If \nx is not a leaf node, then k should go into the appropriate leaf node in the sub tree \nrooted at internal node x . Lines  9311  determine  the  child  x:c  i to which  the  recur-  \nsion  descends.  Line  13  detects  whether  the  recursion  would  descend to a full child, \nin which  case  line  14  calls  B-T REE-SPLIT-CHILD to split  that  child  into  two  non-  510 Chapter 18 B-Trees \nP X M G (a) \nP X M G (b) \nP X M G (c) T \n(d) P \n(e) P Q inserted \nL inserted \nF inserted initial tree \nB inserted J K N O R S T D E C A U V Y Z \nJ K N O R S T D E B A U V Y Z C \nJ K N O D E B A U V Y Z C R S Q \nM G X T \nJ K N O D E B A U V Y Z C R S Q L \nM G C X T \nJ K N O D E B A U V Y Z R S Q L F \nFigure  18.7  Inserting  keys  into  a B-tree.  The  minimum  degree  t for  this  B-tree  is 3, so that a node \ncan hold at most 5 keys.  Blue  nodes  are  modi\u00fbed  by  the  insertion  process.  (a)  The initial tree for this \nexample. (b)  The result of inserting B into the initial tree. This case is a simple insert ion into a leaf \nnode. (c)  The result of inserting Q into the previous tree. The node RSTUV  splits into two nodes \ncontaining RS  and UV  , the key T moves up to the root, and Q is inserted in the leftmost of the two \nhalves (the RS  node). (d)  The result of inserting L into the previous tree. The root splits right away,  \nsince  it is full,  and  the  B-tree  grows  in height  by  one.  Then  L is inserted into the leaf containing JK. \n(e)  The result of inserting F into the previous tree. The node ABCDE  splits before F is inserted \ninto the rightmost of the two halves (the DE  node). 18.2  Basic  operations  on  B-trees  511 \nB-T REE-I NSERT-NONFULL  .x;k/  \n1 i D x:n  \n2 if x: leaf / / inserting  into  a leaf?  \n3 while  i \ue004 1 and k<x:  key  i / / shift keys in x to make room for k \n4 x: key  i C1 D x: key  i \n5 i D i \ue003 1 \n6 x: key  i C1 D k / / insert key k in x \n7 x:n  D x:n  C 1 / / now x has 1 more key \n8 DISK-WRITE .x/  \n9 else  while  i \ue004 1 and k<x:  key  i / / \u00fbnd  the  child  where  k belongs \n10  i D i \ue003 1 \n11  i D i C 1 \n12  DISK-READ .x:c  i / \n13  if x:c  i :n = = 2t \ue003 1 / / split  the  child  if it\u2019s  full  \n14  B-T REE-SPLIT-CHILD .x;i/  \n15  if k>x:  key  i / / does k go into x:c  i or x:c  i C1 ? \n16  i D i C 1 \n17  B-T REE-I NSERT-NONFULL  .x:c  i ;k/  \nfull  children,  and  lines  15316  determine  which  of the  two  children is the correct \none to descend to. (Note that D ISK-READ.x:c  i / is not  needed  after  line  16  incre-  \nments i , since the recursion descends in this case to a ch ild that was just created by \nB-T REE-SPLIT-CHILD.) The  net  effect  of lines  13316  is thus  to guarantee  that  the  \nprocedure  never  recurses  to a full  node.  Line  17  then  recurse s to insert k into the \nappropriate subtree. \nFor  a B-tree  of height  h, B-T REE-I NSERT performs O.h/  disk accesses, since \nonly O.1/  DISK-READ and DISK-WRITE operations occur at each level of the \ntree. The total CPU time used is O.t/  in each level of the tree, or O.th/  D \nO.t  log t n/ overall.  Since  B-T REE-I NSERT-NONFULL  is tail-recursive,  you  can  \ninstead implement it with a while  loop, thereby demonstrating that the number of \nblocks that need to be in main memory at any time i s O.1/ . \nExercises  \n18.2-1  \nShow the results of inserting the keys \nF;S;Q;K;C;L;H;T;V;W;M;R;N;P;A;B;X;Y;D;Z;E  512 Chapter 18 B-Trees \nin order  into  an empty  B-tree  with  minimum  degree  2. Draw  only  the  con\u00fbgura-  \ntions of the tree just before some node must split,  and also draw  the  \u00fbnal  con\u00fbgu-  \nration. \n18.2-2  \nExplain under what circumstances, if any, redundant  DISK-READ or DISK-WRITE \noperations  occur  during  the  course  of executing  a call  to B-T REE-I NSERT . (A \nredundant D ISK-READ is a DISK-READ for a block that is already in memory. \nA redundant D ISK-WRITE writes to disk a block of information that is ident ical to \nwhat is already stored there.) \n18.2-3  \nProfessor  Bunyan  asserts  that  the  B-T REE-I NSERT procedure always results in a \nB-tree  with  the  minimum  possible  height.  Show  that  the  profe ssor is mistaken by \nproving that with t D 2 and the set of keys f1;2;:::;15 g, there is no insertion \nsequence  that  results  in a B-tree  with  the  minimum  possible  height. \n? 18.2-4  \nIf you insert the keys f1;2;:::;n g into  an empty  B-tree  with  minimum  degree  2, \nhow  many  nodes  does  the  \u00fbnal  B-tree  have?  \n18.2-5  \nSince leaf nodes require no pointers to children, t hey could conceivably  use  a dif-  \nferent (larger) t value than internal nodes for the same disk block s ize. Show how \nto modify  the  procedures  for  creating  and  inserting  into  a B-tree to handle this \nvariation. \n18.2-6  \nSuppose  that  you  implement  B-T REE-SEARCH to use binary search rather than \nlinear search within each node. Show that this chan ge makes the required CPU \ntime O.lg n/, independent of how t might be chosen as a function of n. \n18.2-7  \nSuppose that disk hardware allows you to choose the  size of a disk block arbitrarily, \nbut that the time it takes to read the disk block i s a Cbt , where a and b are  speci\u00fbed  \nconstants and t is the  minimum  degree  for  a B-tree  using  blocks  of the  selecte d size. \nDescribe how to choose t so as to minimize  (approximately)  the  B-tree  search  time.  \nSuggest an optimal value of t for the case in which a D 5 milliseconds and b D 10  \nmicroseconds. 18.3  Deleting  a key  from  a B-tree  513 \n18.3  Deleting  a key  from  a B-tree  \nDeletion  from  a B-tree  is analogous  to insertion  but  a little  more  complicated,  be-  \ncause  you  can  delete  a key  from  any  node4not  just  a leaf4and  when you delete \na key  from  an internal  node,  you  must  rearrange  the  node\u2019s  children.  As  in in-  \nsertion, you must guard against deletion producing a tree whose structure violates \nthe  B-tree  properties.  Just  as a node  should  not  get  too  big  due to insertion, a node \nmust not get too small during deletion (except that  the root is allowed to have fewer \nthan the minimum number t \ue003 1 of keys). And just as a simple insertion algorithm \nmight have to back up if a node on the path to wher e the key is to be inserted is \nfull, a simple approach to deletion might have to b ack up if a node (other than the \nroot) along the path to where the key is to be dele ted has the minimum number of \nkeys. \nThe  procedure  B-T REE-DELETE deletes the key k from the subtree rooted at x . \nUnlike the procedures T REE-DELETE on  page  325  and  RB-D ELETE on  page  348,  \nwhich  are  given  the  node  to delete4presumably  as the  result  of a prior  search4  \nB-T REE-DELETE combines the search for key k with the deletion process. Why \ndo  we  combine  search  and  deletion  in B-T REE-DELETE? Just  as B-T REE-I NSERT \nprevents any node from becoming overfull (having mo re than 2t \ue003 1 keys) while \nmaking  a single  pass  down  the  tree,  B-T REE-DELETE prevents any node from \nbecoming underfull (having fewer than t \ue003 1 keys) while also making a single pass \ndown the tree, searching for and ultimately deletin g the key. \nTo  prevent  any  node  from  becoming  underfull,  the  design  of B-  TREE-DELETE \nguarantees that whenever it calls itself recursivel y on a node x , the number of keys \nin x is at least the minimum degree t at the time of the call. (Although the root \nmay have fewer than t keys and a recursive call may be made from the root, no \nrecursive call is made on the root.) This condition requires one more key tha n the \nminimum  required  by  the  usual  B-tree  conditions,  and  so a key  might have to be \nmoved from x into one of its child nodes (still leaving x with at least the minimum \nt \ue003 1 keys) before a recursive call is made on that child , thus allowing deletion to \noccur in one downward pass without having to traver se back up the tree. \nWe  describe  how  the  procedure  B-T REE-DELETE .T;k/  deletes a key k from \na B-tree  T instead of presenting detailed pseudocode. We exami ne three cases, \nillustrated  in Figure  18.8.  The  cases  are  for  when  the  search  arrives at a leaf, at an \ninternal node containing key k, and at an internal node not containing key k. As \nmentioned above, in all three cases node x has at least t keys (with the possible \nexception of when x is the  root).  Cases  2 and  34when  x is an internal  node4  \nguarantee this property as the recursion descends t hrough the B-tree.  514 Chapter 18 B-Trees \n(a) P initial tree \n(b) P F deleted:  case  1 \n(c) P M deleted: case 2a M G C X T \nJ K N O D E B A U V Y Z R S Q L F \nM G C X T \nJ K N O D E B A U V Y Z R S Q L \nG C L X T \nJ K N O D E B A U V Y Z R S Q \nFigure  18.8  Deleting  keys  from  a B-tree.  The  minimum  degree  for  this  B-tree is t D 3, so that, \nother than the root, every node must have at least 2 keys.  Blue  nodes  are  those  that  are  modi\u00fbed  by  \nthe deletion process. (a)  The  B-tree  of Figure  18.7(e).  (b)  Deletion of F , which  is case  1: simple  \ndeletion from a leaf when all nodes visited during the search (other than the root) have at least t D 3 \nkeys. (c)  Deletion of M  , which is case 2a: the predecessor L of M  moves up to take M  \u2019s position.  \nCase  1: The  search  arrives  at a leaf  node  x . If x contains key k, then delete k \nfrom x . If x does not contain key k, then k was  not  in the  B-tree  and  nothing  \nelse needs to be done. \nCase  2: The  search  arrives  at an  internal  node  x that  contains  key  k. Let k D \nx: key  i . One  of the  following  three  cases  applies,  depending  on  the  number of \nkeys in x:c  i (the child of x that precedes k) and x:c  i C1 (the child of x that \nfollows k). \nCase  2a:  x:c  i has at least t keys.  Find the predecessor k 0 of k in the subtree \nrooted at x:c  i . Recursively delete k 0 from x:c  i , and replace k by k 0 in x . (Key  k 0 \ncan be found and deleted in a single downward pass. ) \nCase  2b:  x:c  i has t \ue003 1 keys  and  x:c  i C1 has at least t keys.  This  case  is sym-  \nmetric to case 2a. Find the successor k 0 of k in the subtree rooted at x:c  i C1 . 18.3  Deleting  a key  from  a B-tree  515 \n(e) D deleted:  case  3b  \nC L P X T \nL P X T (f) B deleted:  case  3a  E (e\u02b9) tree shrinks \nin height (d) P G deleted: case 2c \nC L X T \nJ K N O D E B A U V Y Z R S Q \nC L P X T \nJ K N O E B A U V Y Z R S Q \nJ K N O E B A U V Y Z R S Q \nJ K N O A U V Y Z C R S Q \nFigure  18.8,  continued  (d)  Deletion of G, which is case 2c: push G down to make node DEGJK  \nand then delete G from  this  leaf  (case  1).  (e)  Deletion of D, which  is case  3b:  since  the  recursion  \ncannot descend to node CL  because it has only 2 keys, push P down and merge it with CL  and TX  \nto form CLPTX  . Then delete D from  a leaf  (case  1).  (e 0 ) After (e), delete the empty root. The tree \nshrinks in height by 1. (f)  Deletion of B, which  is case  3a:  C moves  to \u00fbll  B\u2019s position  and  E moves \nto \u00fbll  C \u2019s position.  \nRecursively delete k 0 from x:c  i C1 , and replace k by k 0 in x . (Again,  \u00fbnding  and  \ndeleting k 0 can be done in a single downward pass.) \nCase  2c:  Both x:c  i and x:c  i C1 have t \ue003 1 keys.  Merge k and all of x:c  i C1 \ninto x:c  i , so that x loses both k and the pointer to x:c  i C1 , and x:c  i now contains \n2t \ue003 1 keys. Then free x:c  i C1 and recursively delete k from x:c  i . \nCase  3: The  search  arrives  at an  internal  node  x that  does  not  contain  key  k. \nContinue searching down the tree while ensuring tha t each node visited has at \nleast t keys. To do so, determine the root x:c  i of the appropriate subtree that \nmust contain k, if k is in the tree at all. If x:c  i has only t \ue003 1 keys, execute 516 Chapter 18 B-Trees \ncase  3a or 3b  as necessary  to guarantee  descending  to a node  containing at least \nt keys.  Then  \u00fbnish  by  recursing  on  the  appropriate  child  of x . \nCase  3a:  x:c  i has  only  t \ue003 1 keys  but  has  an  immediate  sibling  with  at least  t \nkeys.  Give  x:c  i an extra key by moving a key from x down into x:c  i , moving \na key from x:c  i \u2019s immediate  left  or right  sibling  up  into  x , and moving the \nappropriate child pointer from the sibling into x:c  i . \nCase  3b:  x:c  i and  each  of x:c  i \u2019s immediate siblings have t \ue003 1 keys.  (It is \npossible for x:c  i to have either one or two siblings.) Merge x:c  i with one sibling, \nwhich involves moving a key from x down into the new merged node to become \nthe median key for that node. \nIn cases  2c and  3b,  if node  x is the root, it could end up having no keys. When \nthis situation occurs, then x is deleted, and x \u2019s only  child  x:c  1 becomes the new \nroot of the tree. This action decreases the height of the tree by one and preserves \nthe property that the root of the tree contains at least one key (unless the tree is \nempty). \nSince  most  of the  keys  in a B-tree  are  in the  leaves,  deletion  operations often \nend  up  deleting  keys  from  leaves.  The  B-T REE-DELETE procedure then acts in \none downward pass through the tree, without having to back up. When deleting a \nkey in an internal node x , however, the procedure might make a downward pass  \nthrough  the  tree  to \u00fbnd  the  key\u2019s  predecessor  or successor  and then return to node x \nto replace the key with its predecessor or successo r (cases 2a and 2b). Returning to \nnode x does not require a traversal through all the levels  between x and the node \ncontaining the predecessor or successor, however, s ince the procedure can just keep \na pointer to x and the key position within x and put the predecessor or successor \nkey directly there. \nAlthough this procedure seems complicated, it invol ves only O.h/  disk  oper-  \nations  for  a B-tree  of height  h, since only O.1/  calls to D ISK-READ and DISK- \nWRITE are made between recursive invocations of the proce dure. The CPU time \nrequired is O.th/  D O.t  log t n/. \nExercises  \n18.3-1  \nShow the results of deleting C , P , and V , in order,  from  the  tree  of Figure  18.8(f).  \n18.3-2  \nWrite  pseudocode  for  B-T REE-DELETE . Problems for Chapter 18 517 \nProblems  \n18-1  Stacks  on  secondary  storage  \nConsider implementing a stack in a computer that ha s a relatively small amount \nof fast primary memory and a relatively large amoun t of slower disk storage. The \noperations P USH and POP  work  on  single-word  values.  The  stack  can  grow  to be \nmuch  larger  than  can  \u00fbt in memory,  and  thus  most  of it must  be stored on disk. \nA simple,  but  inef\u00fbcient,  stack  implementation  keeps  the  entire stack on disk. \nMaintain in memory a stack pointer, which is the di sk address of the top element \non the stack. Indexing block numbers and word offse ts within blocks from 0, if the \npointer has value p, the top element is the .p  mod m/th word on block bp=mc of \nthe disk, where m is the number of words per block. \nTo implement the P USH operation,  increment  the  stack  pointer,  read  the  appro-  \npriate block into memory from disk, copy the elemen t to be pushed  to the  appropri-  \nate word on the block, and write the block back to disk. A POP  operation is similar. \nRead in the appropriate block from disk, save the t op of the stack, decrement the \nstack pointer, and return the saved value. You need  not write back the block, since \nit was  not  modi\u00fbed,  and  the  word  in the  block  that  contained  the popped value is \nignored. \nAs  in the  analyses  of B-tree  operations,  two  costs  matter:  the total number of \ndisk accesses and the total CPU time. A disk access  also incurs a cost in CPU \ntime. In particular, any disk access to a block of m words incurs charges of one \ndisk access and \u201a.m/  CPU time. \na. Asymptotically,  what  is the  worst-case  number  of disk  acces ses for n stack \noperations  using  this  simple  implementation?  What  is the  CPU time for n stack \noperations?  Express  your  answer  in terms  of m and n for this and subsequent \nparts. \nNow consider a stack implementation in which you ke ep one block of the stack in \nmemory. (You also maintain a small amount of memory  to record which block is \ncurrently in memory.) You can perform a stack opera tion only if the relevant disk \nblock resides in memory. If necessary, you can writ e the block currently in memory \nto the disk and read the new block from the disk in to memory. If the relevant disk \nblock is already in memory, then no disk accesses a re required. \nb. What  is the  worst-case  number  of disk  accesses  required  for  n PUSH opera-  \ntions?  What  is the  CPU  time?  \nc. What  is the  worst-case  number  of disk  accesses  required  for  n stack  operations?  \nWhat  is the  CPU  time?  518 Chapter 18 B-Trees \nSuppose that you now implement the stack by keeping  two blocks in memory (in \naddition to a small number of words for bookkeeping ). \nd. Describe how to manage the stack blocks so that the  amortized number of disk \naccesses for any stack operation is O.1=m/  and the amortized CPU time for \nany stack operation is O.1/ . \n18-2  Joining  and  splitting  2-3-4  trees  \nThe join  operation takes two dynamic sets S 0 and S 00 and an element x such that \nx 0 : key  < x: key  < x  00 : key  for any x 0 2 S 0 and x 00 2 S 00 . It returns a set S D \nS 0 [ fx g [  S 00 . The split  operation is like an <inverse= join: given a dynami c set S \nand an element x 2 S , it creates a set S 0 that consists of all elements in S \ue003 fx g \nwhose keys are less than x: key  and another set S 00 that consists of all elements \nin S \ue003 fx g whose keys are greater than x: key. This problem investigates how \nto implement  these  operations  on  2-3-4  trees  (B-trees  with  t D 2). Assume for \nconvenience that elements consist only of keys and that all key values are distinct. \na. Show how to maintain, for every node x of a 2-3-4  tree,  the  height  of the  subtree  \nrooted at x as an attribute x: height . Make sure that your implementation does \nnot affect the asymptotic running times of searchin g, insertion, and deletion. \nb. Show  how  to implement  the  join  operation.  Given  two  2-3-4  trees T 0 and T 00 \nand a key k, the join operation should run in O.1  C jh 0 \ue003 h 00 j/ time, where h 0 \nand h 00 are the heights of T 0 and T 00 , respectively. \nc. Consider the simple path p from  the  root  of a 2-3-4  tree  T to a given key k, \nthe set S 0 of keys in T that are less than k, and the set S 00 of keys in T that are \ngreater than k. Show that p breaks S 0 into a set of trees fT 0 \n0 ;T  0 \n1 ;:::;T  0 \nm g and a \nset of keys fk 0 \n1 ;k  0 \n2 ;:::;k  0 \nm g such that y <k  0 \ni <\u00b4  for i D 1;2;:::;m  and any \nkeys y 2 T 0 \ni \ue0021 and \u00b4 2 T 0 \ni . What is the relationship between the heights of T 0 \ni \ue0021 \nand T 0 \ni ? Describe  how  p breaks S 00 into sets of trees and keys. \nd. Show how to implement the split operation on T . Use the join operation to \nassemble the keys in S 0 into  a single  2-3-4  tree  T 0 and the keys in S 00 into a \nsingle  2-3-4  tree  T 00 . The running time of the split operation should be  O.lg n/, \nwhere n is the number of keys in T . (Hint: The  costs  for  joining  should  tele-  \nscope.) Notes for Chapter 18 519 \nChapter  notes  \nKnuth  [261],  Aho,  Hopcroft,  and  Ullman  [5],  and  Sedgewick  and  Wayne  [402]  \ngive  further  discussions  of balanced-tree  schemes  and  B-trees.  Comer  [99]  pro-  \nvides  a comprehensive  survey  of B-trees.  Guibas  and  Sedgewi ck [202] discuss the \nrelationships  among  various  kinds  of balanced-tree  schemes,  including  red-black  \ntrees  and  2-3-4  trees.  \nIn 1970,  J. E. Hopcroft  invented  2-3  trees,  a precursor  to B-trees  and  2-3-4  \ntrees, in which every internal node has either two or three children. Bayer and \nMcCreight  [39]  introduced  B-trees  in 1972  with  no  explanati on of their choice of \nname. \nBender,  Demaine,  and  Farach-Colton  [47]  studied  how  to make  B-trees  perform  \nwell  in the  presence  of memory-hierarchy  effects.  Their  cache-oblivious  algo-  \nrithms  work  ef\u00fbciently  without  explicitly  knowing  the  data  transfer sizes within \nthe memory hierarchy. 19  Data  Structures  for  Disjoint  Sets  \nSome applications involve grouping n distinct  elements  into  a collection  of dis-  \njoint  sets4sets  with  no  elements  in common.  These  applicati ons often need to \nperform  two  operations  in particular:  \u00fbnding  the  unique  set  that contains a given \nelement and uniting two sets. This chapter explores  methods for maintaining a data \nstructure that supports these operations. \nSection  19.1  describes  the  operations  supported  by  a disjoint-set  data  structure  \nand  presents  a simple  application.  Section  19.2  looks  at a simple  linked-list  imple-  \nmentation  for  disjoint  sets.  Section  19.3  presents  a more  ef\u00fbcient  representation  \nusing rooted trees. The running time using the tree  representation is theoretically \nsuperlinear, but for all practical purposes it is l inear. Section  19.4  de\u00fbnes  and  dis-  \ncusses a very quickly growing function and its very  slowly growing inverse, which \nappears  in the  running  time  of operations  on  the  tree-based  implementation, and \nthen, by a complex amortized analysis, proves an up per bound on the running time \nthat is just barely superlinear. \n19.1  Disjoint-set  operations  \nA disjoint-set  data  structure  maintains a collection S D fS 1 ;S  2 ;:::;S  k g of dis-  \njoint dynamic sets. To identify each set, choose a representative , which is some \nmember  of the  set.  In some  applications,  it doesn\u2019t  matter  which member is used \nas the representative; it matters only that if you ask for the representative  of a dy-  \nnamic set twice without modifying the set between t he requests, you get the same \nanswer  both  times.  Other  applications  may  require  a prespeci\u00fbed  rule  for  choosing  \nthe representative, such as choosing the smallest m ember in the set (for a set whose \nelements can be ordered). 19.1 Disjoint-set operations 521 \nAs  in the  other  dynamic-set  implementations  we  have  studied , each element of a \nset is represented by an object. Letting x denote  an object,  we\u2019ll  see  how  to support  \nthe following operations: \nMAKE-SET .x/, where x does not already belong to some other set, creates a new \nset whose only member (and thus representative) is x . \nUNION.x;y/  unites two disjoint, dynamic sets that contain x and y , say S x and S y , \ninto a new set that is the union of these two sets.  The represen tative  of the  result-  \ning set is any member of S x [ S y , although many implementations of U NION  \nspeci\u00fbcally  choose  the  representative  of either  S x or S y as the  new  representa-  \ntive. Since the sets in the collection must at all times be disjoint, the U NION  \noperation destroys sets S x and S y , removing them from the collection S . In \npractice, implementations often absorb the elements  of one of the sets into the \nother set. \nFIND-SET.x/  returns a pointer to the representative of the uniq ue set containing x . \nThroughout  this  chapter,  we\u2019ll  analyze  the  running  times  of disjoint-set  data  \nstructures in terms of two parameters: n, the number of M AKE-SET operations, \nand m, the total number of M AKE-SET, UNION , and F IND-SET operations.  Be-  \ncause the total number of operations m includes the n MAKE-SET operations, \nm \ue004 n. The  \u00fbrst  n operations are always M AKE-SET operations, so that after \nthe  \u00fbrst  n operations, the collection consists of n singleton sets. Since the sets are \ndisjoint at all times, each U NION  operation reduces the number of sets by 1. After \nn \ue003 1 UNION  operations, therefore, only one set remains, and so  at most n \ue003 1 \nUNION  operations can occur. \nAn  application  of disjoint-set  data  structures  \nOne  of the  many  applications  of disjoint-set  data  structures  arises  in determin-  \ning the connected components of an undirected graph  (see Section  B.4).  Fig-  \nure  19.1(a),  for  example,  shows  a graph  with  four  connected  components. \nThe procedure C ONNECTED-COMPONENTS  on the following page uses the \ndisjoint-set  operations  to compute  the  connected  components  of a graph.  Once  \nthe CONNECTED-COMPONENTS  procedure  has  preprocessed  the  graph,  the  pro-  \ncedure S AME-COMPONENT  answers queries about whether two vertices belong t o \nthe same connected component. In pseudocode, we den ote the set of vertices of a \ngraph G by G:  V and the set of edges by G:  E. \nThe procedure C ONNECTED-COMPONENTS  initially places each vertex v in its \nown set. Then, for each edge .u;v/ , it unites the sets containing u and v. By \nExercise  19.1-2,  after  all  the  edges  are  processed,  two  vertices belong to the same \nconnected component if and only if the objects corr esponding to the vertices belong 522  Chapter  19  Data  Structures  for  Disjoint  Sets  \na b \nc d f \ng e \nh i \nj Edge processed \ninitial sets \n(b, d) \n(e, f) \n(a, c) \n(h, i) \n(a, b) \n(f, g) \n(b, c) {a, b, c, d} {a, b, c, d} {a, c} {a, c} {a} {a} {a} \n{a, b, c, d} {b, d} {b, d} {b, d} {b, d} {b} \n{c} {c} {c} {d} \n{e, f, g} {e, f, g} {e, f} {e} {e} { f} \n{f} {g} \n{g} \n{h, i} {h, i} {h, i} {h, i} {h} {h} {h} {h} { i} \n{i} \n{i} \n{i} {j} \n{j} \n{j} \n{j} \n{j} \n{j} \n{j} \n{j} Collection of disjoint sets \n(a) (b) {g} \n{e, f} { g} \n{e, f} { g} \n{e, f} { g} \nFigure  19.1  (a)  A graph with four connected components: fa;b;c;d  g, fe;f;g g, fh;i  g, and fj g. \n(b)  The collection of disjoint sets after processing ea ch edge. \nCONNECTED-COMPONENTS  .G/  \n1 for  each vertex v 2 G:  V \n2 MAKE-SET .v/  \n3 for  each edge .u;v/  2 G:  E \n4 if FIND-SET.u/  \u00a4 FIND-SET.v/  \n5 UNION.u;v/  \nSAME-COMPONENT  .u;v/  \n1 if FIND-SET.u/  = = FIND-SET .v/  \n2 return  TRUE \n3 else  return  FALSE \nto the same set. Thus C ONNECTED-COMPONENTS  computes sets in such a way \nthat the procedure S AME-COMPONENT  can determine whether two vertices are \nin the  same  connected  component.  Figure  19.1(b)  illustrate s how CONNECTED- \nCOMPONENTS  computes the disjoint sets. \nIn an actual  implementation  of this  connected-components  algorithm,  the  repre-  \nsentations  of the  graph  and  the  disjoint-set  data  structure  would need to reference \neach other. That is, an object representing a verte x would contain a pointer to the \ncorresponding  disjoint-set  object,  and  vice  versa.  Since  these programming details \ndepend on the implementation language, we do not ad dress them further here. \nWhen  the  edges  of the  graph  are  static4not  changing  over  time4depth-\u00fbrst  \nsearch can compute the connected components faster (see Exercise  20.3-12  on  19.2 Linked-list representation of disjoint sets 52 3 \npage  572).  Sometimes,  however,  the  edges  are  added  dynamically,  with  the  con-  \nnected components updated as each edge is added. In  this case, the implementation \ngiven  here  can  be more  ef\u00fbcient  than  running  a new  depth-\u00fbrst  search for each new \nedge. \nExercises  \n19.1-1  \nThe CONNECTED-COMPONENTS  procedure is run on the undirected graph G D \n.V;E/ , where V D fa;b;c;d;e;f;g;h;i;j;k g , and the edges of E are  pro-  \ncessed in the order .d;i/;.f;k/;.g;i/;.b;g/;.a;h/;.i;j/;.d;k/;.b;j/;.d; f/;  \n.g;j/;.a;e/ . List the vertices in each connected component aft er each iteration of \nlines  335.  \n19.1-2  \nShow that after all edges are processed by C ONNECTED-COMPONENTS , two  ver-  \ntices belong to the same connected component if and  only if they belong to the \nsame set. \n19.1-3  \nDuring the execution of C ONNECTED-COMPONENTS  on an undirected graph G D \n.V;E/  with k connected components, how many times is F IND-SET called?  How  \nmany times is U NION  called?  Express  your  answers  in terms  of jV j, jEj, and k. \n19.2  Linked-list  representation  of disjoint  sets  \nFigure  19.2(a)  shows  a simple  way  to implement  a disjoint-se t data structure: each \nset is represented by its own linked list. The obje ct for each set has attributes head , \npointing  to the  \u00fbrst  object  in the  list,  and  tail, pointing to the last object. Each \nobject in the list contains a set member, a pointer  to the next object in the list, and \na pointer back to the set object. Within each linke d list, the objects may appear in \nany  order.  The  representative  is the  set  member  in the  \u00fbrst  object in the list. \nWith  this  linked-list  representation,  both  MAKE-SET and F IND-SET require \nonly O.1/  time. To carry out M AKE-SET .x/, create a new linked list whose only \nobject is x . For F IND-SET .x/, just follow the pointer from x back  to its  set  ob-  \nject and then return the member in the object that head points to. For example, in \nFigure  19.2(a),  the  call  FIND-SET .g/  returns f . 524  Chapter  19  Data  Structures  for  Disjoint  Sets  \nf g d c h e b (a) \n(b) \nhead \ntail S 1 c h e \nhead \ntail S 2 b f g d \nhead \ntail S 1 \nFigure  19.2  (a)  Linked-list  representations  of two  sets.  Set  S 1 contains members d , f , and g, with \nrepresentative f , and set S 2 contains members b, c, e, and h, with representative c. Each object in \nthe list contains a set member, a pointer to the ne xt object in the list, and a pointer back to the se t \nobject. Each set object has pointers head and tail to the  \u00fbrst  and  last  objects,  respectively.  (b)  The \nresult of U NION.g;e/ , which appends the linked list containing e to the linked list containing g. The \nrepresentative of the resulting set is f . The set object for e\u2019s list,  S 2 , is destroyed. \nA simple  implementation  of union  \nThe simplest implementation of the U NION  operation  using  the  linked-list  set  rep-  \nresentation  takes  signi\u00fbcantly  more  time  than  MAKE-SET or F IND-SET. As  Fig-  \nure  19.2(b)  shows,  the  operation  UNION.x;y/  appends y \u2019s list  onto  the  end  of x \u2019s \nlist. The representative of x \u2019s list  becomes  the  representative  of the  resulting  set.  \nTo  quickly  \u00fbnd  where  to append  y \u2019s list,  use  the  tail pointer for x \u2019s list.  Because  \nall members of y \u2019s list  join  x \u2019s list,  the  UNION  operation destroys the set object \nfor y \u2019s list.  The  UNION  operation is where this implementation pays the pri ce for \nFIND-SET taking constant time: U NION  must also update the pointer to the set \nobject for each object originally on y \u2019s list,  which  takes  time  linear  in the  length  of \ny \u2019s list.  In Figure  19.2,  for  example,  the  operation  UNION.g;e/  causes pointers to \nbe updated in the objects for b, c , e, and h. \nIn fact, we can construct a sequence of m operations on n objects that requires \n\u201a.n  2 / time. Starting with objects x 1 ;x  2 ;:::;x  n , execute the sequence of n MAKE- \nSET operations followed by n \ue003 1 UNION  operations  shown  in Figure  19.3,  so that  \nm D 2n  \ue0031. The n MAKE-SET operations take \u201a.n/  time. Because the i th UNION  \noperation updates i objects, the total number of objects updated by all  n \ue003 1 UNION  \noperations forms an arithmetic series: 19.2 Linked-list representation of disjoint sets 52 5 \nOperation  Number  of objects  updated  \nMAKE-SET.x 1 / 1 \nMAKE-SET.x 2 / 1 \n: : : : : : \nMAKE-SET.x n / 1 \nUNION.x 2 ;x  1 / 1 \nUNION.x 3 ;x  2 / 2 \nUNION.x 4 ;x  3 / 3 \n: : : : : : \nUNION.x n ;x  n\ue0021 / n \ue003 1 \nFigure  19.3  A sequence of 2n  \ue003 1 operations on n objects that takes \u201a.n  2 / time, or \u201a.n/  time \nper  operation  on  average,  using  the  linked-list  set  represe ntation and the simple implementation of \nUNION . \nn\ue0021 X  \ni D1 i D \u201a.n  2 /: \nThe total number of operations is 2n  \ue003 1, and so each operation on average requires \n\u201a.n/  time. That is, the amortized time of an operation i s \u201a.n/ . \nA weighted-union  heuristic  \nIn the worst case, the above implementation of U NION  requires an average of \u201a.n/  \ntime per call, because it might be appending a long er list onto a shorter list, and \nthe procedure must update the pointer to the set ob ject for each member of the \nlonger list. Suppose instead that each list also in cludes the length of the list (which \ncan be maintained straightforwardly with constant o verhead) and that the U NION  \nprocedure always appends the shorter list onto the longer, breaking ties arbitrarily. \nWith this simple weighted-union  heuristic , a single U NION  operation can still take \n\ufffd.n/  time if both sets have \ufffd.n/  members. As the following theorem shows, \nhowever, a sequence of m MAKE-SET, UNION , and F IND-SET operations, n of \nwhich are M AKE-SET operations, takes O.m  C n lg n/ time. \nTheorem  19.1  \nUsing  the  linked-list  representation  of disjoint  sets  and  the  weighted-union  heuris-  \ntic, a sequence of m MAKE-SET, UNION , and F IND-SET operations, n of which \nare MAKE-SET operations, takes O.m  C n lg n/ time. \nProof  Because each U NION  operation unites two disjoint sets, at most n \ue003 1 \nUNION  operations occur over all. We now bound the total t ime taken by these 526  Chapter  19  Data  Structures  for  Disjoint  Sets  \nUNION  operations. We start by determining, for each objec t, an upper bound on \nthe  number  of times  the  object\u2019s  pointer  back  to its  set  objec t is updated. Consider \na particular object x . Each time x \u2019s pointer  is updated,  x must have started in \nthe  smaller  set.  The  \u00fbrst  time  x \u2019s pointer  is updated,  therefore,  the  resulting  set  \nmust have at least 2 members. Similarly, the next time x \u2019s pointer  is updated,  the  \nresulting set must have had at least 4 members. Continuing on, for any k \u0dc4 n, \nafter x \u2019s pointer  has  been  updated  dlg ke times, the resulting set must have at least \nk members. Since the largest set has at most n members,  each  object\u2019s  pointer  is \nupdated at most dlg ne times over all the U NION  operations. Thus the total time \nspent updating object pointers over all U NION  operations is O.n  lg n/. We must \nalso account for updating the tail pointers and the list lengths, which take only \n\u201a.1/  time per U NION  operation. The total time spent in all U NION  operations is \nthus O.n  lg n/. \nThe time for the entire sequence of m operations follows. Each M AKE-SET and \nFIND-SET operation takes O.1/  time, and there are O.m/  of them. The total time \nfor the entire sequence is thus O.m  C n lg n/. \nExercises  \n19.2-1  \nWrite pseudocode for M AKE-SET, FIND-SET, and UNION  using  the  linked-list  \nrepresentation  and  the  weighted-union  heuristic.  Make  sure to specify the attributes \nthat you assume for set objects and list objects. \n19.2-2  \nShow the data structure that results and the answer s returned by the F IND-SET \noperations  in the  following  program.  Use  the  linked-list  representation with the \nweighted-union  heuristic.  Assume  that  if the  sets  containi ng x i and x j have the \nsame size, then the operation U NION.x i ;x  j / appends x j \u2019s list  onto  x i \u2019s list.  \n1 for  i D 1 to 16  \n2 MAKE-SET .x i / \n3 for  i D 1 to 15  by  2 \n4 UNION.x i ;x  i C1 / \n5 for  i D 1 to 13  by  4 \n6 UNION.x i ;x  i C2 / \n7 UNION.x 1 ;x  5 / \n8 UNION.x 11  ;x  13  / \n9 UNION.x 1 ;x  10  / \n10  FIND-SET.x 2 / \n11  FIND-SET.x 9 / 19.3 Disjoint-set forests 527 \n19.2-3  \nAdapt  the  aggregate  proof  of Theorem  19.1  to obtain  amortize d time bounds \nof O.1/  for MAKE-SET and F IND-SET and O.lg n/ for UNION  using  the  linked-  \nlist  representation  and  the  weighted-union  heuristic.  \n19.2-4  \nGive  a tight  asymptotic  bound  on  the  running  time  of the  seque nce of operations in \nFigure  19.3  assuming  the  linked-list  representation  and  the  weighted-union  heuris-  \ntic. \n19.2-5  \nProfessor  Gompers  suspects  that  it might  be possible  to keep  just one pointer in \neach set object, rather than two ( head and tail), while  keeping  the  number  of point-  \ners  in each  list  element  at two.  Show  that  the  professor\u2019s  suspicion is well founded \nby describing how to represent each set by a linked  list such that each operation \nhas the same running time as the operations describ ed in this section. Describe \nalso how the operations work. Your scheme should al low for the weighted-union  \nheuristic, with the same effect as described in thi s section. ( Hint: Use the tail of a \nlinked  list  as its  set\u2019s  representative.)  \n19.2-6  \nSuggest a simple change to the U NION  procedure  for  the  linked-list  representation  \nthat removes the need to keep the tail pointer  to the  last  object  in each  list.  Re-  \ngardless  of whether  the  weighted-union  heuristic  is used,  your change should not \nchange the asymptotic running time of the U NION  procedure. ( Hint: Rather than \nappending one list to another, splice them together .) \n19.3  Disjoint-set  forests  \nA faster implementation of disjoint sets represents  sets by rooted trees, with each \nnode containing one member and each tree representi ng one set. In a disjoint-set  \nforest, illustrated  in Figure  19.4(a),  each  member  points  only  to its parent. The root \nof each tree contains the representative and is its  own parent. As  we\u2019ll  see,  although  \nthe straightforward algorithms that use this repres entation are no faster than ones \nthat  use  the  linked-list  representation,  two  heuristics4< union by rank= and <path \ncompression=4yield  an asymptotically  optimal  disjoint-s et data structure. \nThe  three  disjoint-set  operations  have  simple  implementat ions. A M AKE-SET \noperation simply creates a tree with just one node.  A F IND-SET operation follows \nparent pointers until it reaches the root of the tr ee. The nodes visited  on  this  sim-  528  Chapter  19  Data  Structures  for  Disjoint  Sets  \nh e \nb d \ng \n(a) c \nh e \nb d \ng \n(b) c f f \nFigure  19.4  A disjoint-set  forest.  (a)  Trees  representing  the  two  sets  of Figure  19.2.  The  tree  on  \nthe left represents the set fb;c;e;h g, with c as the representative, and the tree on the right re presents \nthe set fd;f;g g, with f as the representative. (b)  The result of U NION.e;g/ . \nple path toward the root constitute the \u00fbnd  path. A UNION  operation, shown in \nFigure  19.4(b),  simply  causes  the  root  of one  tree  to point  to the root of the other. \nHeuristics  to improve  the  running  time  \nSo  far,  disjoint-set  forests  have  not  improved  on  the  linked-list  implementation.  A \nsequence of n \ue003 1 UNION  operations could create a tree that is just a linea r chain \nof n nodes. By using two heuristics, however, we can ach ieve a running time that \nis almost linear in the total number m of operations. \nThe  \u00fbrst  heuristic,  union  by rank, is similar  to the  weighted-union  heuristic  we  \nused  with  the  linked-list  representation.  The  common-sens e approach is to make \nthe root of the tree with fewer nodes point to the root of the tree with more nodes. \nRather than explicitly keeping track of the size of  the subtree rooted at each node, \nhowever,  we\u2019ll  adopt  an approach  that  eases  the  analysis.  For each node, maintain a \nrank , which is an upper bound on the height of the node . Union by rank makes the \nroot with smaller rank point to the root with large r rank during a U NION  operation. \nThe second heuristic, path  compression , is also  quite  simple  and  highly  effec-  \ntive.  As  shown  in Figure  19.5,  FIND-SET operations use it to make each node \non  the  \u00fbnd  path  point  directly  to the  root.  Path  compression  does not change any \nranks. \nPseudocode  for  disjoint-set  forests  \nThe  union-by-rank  heuristic  requires  its  implementation  to keep track of ranks. \nWith each node x , maintain the integer value x: rank, which is an upper bound on \nthe height of x (the  number  of edges  in the  longest  simple  path  from  a descen-  \ndant leaf to x ). When M AKE-SET creates a singleton set, the single node in the 19.3 Disjoint-set forests 529 \na b c d e \nf \na b c d e f \n(a) (b) \nFigure  19.5  Path compression during the operation F IND-SET. Arrows  and  self-loops  at roots  are  \nomitted. (a)  A tree representing a set prior to executing F IND-SET.a/. Triangles represent subtrees \nwhose roots are the nodes shown. Each node has a po inter to its parent. (b)  The same set after \nexecuting F IND-SET.a/. Each  node  on  the  \u00fbnd  path  now  points  directly  to the  root.  \ncorresponding tree has an initial rank of 0. Each F IND-SET operation leaves all \nranks unchanged. The U NION  operation has two cases, depending on whether the \nroots of the trees have equal rank. If the roots ha ve unequal ranks, make the root \nwith higher rank the parent of the root with lower rank, but don\u2019t  change  the  ranks  \nthemselves. If the roots have equal ranks, arbitrar ily choose one of the roots as the \nparent and increment its rank. \nLet\u2019s  put  this  method  into  pseudocode,  appearing  on  the  next  page. The parent \nof node x is denoted by x: p. The LINK  procedure, a subroutine called by U NION , \ntakes pointers to two roots as inputs. The F IND-SET procedure  with  path  compres-  \nsion, implemented recursively, turns out to be quit e simple. \nThe F IND-SET procedure is a two-pass  method : as it recurses, it makes one pass \nup  the  \u00fbnd  path  to \u00fbnd  the  root,  and  as the  recursion  unwinds,  it makes a second \npass  back  down  the  \u00fbnd  path  to update  each  node  to point  direct ly to the root. \nEach call of F IND-SET.x/  returns x: p in line  3. If x is the root, then F IND-SET \nskips line 2 and just returns x: p, which is x . In this case the recursion bottoms \nout.  Otherwise,  line  2 executes,  and  the  recursive  call  with  parameter x: p returns 530  Chapter  19  Data  Structures  for  Disjoint  Sets  \nMAKE-SET .x/  \n1 x: p D x \n2 x: rank D 0 \nUNION.x;y/  \n1 LINK.FIND-SET .x/;  FIND-SET.y//  \nLINK.x;y/  \n1 if x: rank >y:  rank \n2 y: p D x \n3 else  x: p D y \n4 if x: rank == y: rank \n5 y: rank D y: rank C 1 \nFIND-SET .x/  \n1 if x \u00a4 x: p / / not  the  root?  \n2 x: p D FIND-SET .x:  p/ / / the root becomes the parent \n3 return  x: p / / return the root \na pointer to the root. Line 2 updates node x to point  directly  to the  root,  and  line  3 \nreturns this pointer. \nEffect  of the  heuristics  on  the  running  time  \nSeparately, either union by rank or path compressio n improves the running time \nof the  operations  on  disjoint-set  forests,  and  combining  the two heuristics yields \nan even greater improvement. Alone, union by rank y ields a running time of \nO.m  lg n/ for a sequence of m operations, n of which are M AKE-SET (see  Ex-  \nercise  19.4-4),  and  this  bound  is tight  (see  Exercise  19.3-3).  Although  we  won\u2019t  \nprove it here, for a sequence of n MAKE-SET operations (and hence at most n \ue003 1 \nUNION  operations) and f FIND-SET operations,  the  worst-case  running  time  using  \nonly  the  path-compression  heuristic  is \u201a.n  C f \ue001 .1 C log 2Cf=n  n//. \nCombining  union  by  rank  and  path  compression  gives  a worst-c ase running time \nof O.m  \u02db.n// , where \u02db.n/  is a very  slowly  growing  function,  de\u00fbned  in Sec-  \ntion  19.4.  In any  conceivable  application  of a disjoint-set  data structure, \u02db.n/  \u0dc4 4, \nand thus, its running time is as good as linear in m for  all  practical  purposes.  Math-  \nematically  speaking,  however,  it is superlinear.  Section  19.4  proves  this  O.m\u02db.n//  \nupper bound. 19.4  Analysis  of union  by rank  with  path  compression  531 \nExercises  \n19.3-1  \nRedo  Exercise  19.2-2  using  a disjoint-set  forest  with  union  by  rank  and  path  com-  \npression. Show the resulting forest with each node including its x i and rank. \n19.3-2  \nWrite a nonrecursive version of F IND-SET with path compression. \n19.3-3  \nGive  a sequence  of m MAKE-SET, UNION , and F IND-SET operations, n of which \nare MAKE-SET operations, that takes \ufffd.m  lg n/ time when using only union by \nrank and not path compression. \n19.3-4  \nConsider the operation P RINT-SET .x/, which is given a node x and prints all the \nmembers of x \u2019s set,  in any  order.  Show  how  to add  just  a single  attribute  to each \nnode  in a disjoint-set  forest  so that  PRINT-SET .x/  takes time linear in the number \nof members of x \u2019s set  and  the  asymptotic  running  times  of the  other  operatio ns are \nunchanged. Assume that you can print each member of  the set in O.1/  time. \n? 19.3-5  \nShow that any sequence of m MAKE-SET, FIND-SET, and LINK  operations, where \nall the LINK  operations appear before any of the F IND-SET operations, takes only \nO.m/  time when using both path compression and union by rank. You may assume \nthat the arguments to L INK  are  roots  within  the  disjoint-set  forest.  What  happens  \nin the same situation when using only path compress ion and not union  by  rank?  \n? 19.4  Analysis  of union  by  rank  with  path  compression  \nAs  noted  in Section  19.3,  the  combined  union-by-rank  and  path-compression  heu-  \nristic runs in O.m\u02db.n//  time for m disjoint-set  operations  on  n elements. In this \nsection,  we\u2019ll  explore  the  function  \u02db to see  just  how  slowly  it grows.  Then  we\u2019ll  \nanalyze the running time using the potential method  of amortized analysis. \nA very  quickly  growing  function  and  its  very  slowly  growing  inverse  \nFor integers j;k  \ue004 0, we  de\u00fbne  the  function  A k .j/  as 532  Chapter  19  Data  Structures  for  Disjoint  Sets  \nA k .j/  D ( \nj C 1 if k D 0;  \nA .j C1/  \nk\ue0021 .j/  if k \ue004 1;  (19.1)  \nwhere the expression A .j C1/  \nk\ue0021 .j/  uses  the  functional-iteration  notation  de\u00fbned  in \nequation  (3.30)  on  page  68.  Speci\u00fbcally,  equation  (3.30)  gives A .0/  \nk\ue0021 .j/  D j and \nA .i/  \nk\ue0021 .j/  D A k\ue0021 .A  .i \ue0021/  \nk\ue0021 .j//  for i \ue004 1. We call the parameter k the level  of the \nfunction A. \nThe function A k .j/  strictly increases with both j and k. To see just how quickly \nthis  function  grows,  we  \u00fbrst  obtain  closed-form  expression s for A 1 .j/  and A 2 .j/. \nLemma  19.2  \nFor any integer j \ue004 1, we have A 1 .j/  D 2j C 1. \nProof  We  \u00fbrst  use  induction  on  i to show that A .i/  \n0 .j/  D j Ci . For the base case, \nA .0/  \n0 .j/  D j D j C 0. For the inductive step, assume that A .i \ue0021/  \n0 .j/  D j C .i \ue003 1/. \nThen A .i/  \n0 .j/  D A 0 .A  .i \ue0021/  \n0 .j//  D .j C .i \ue003 1//  C 1 D j C i . Finally, we note that \nA 1 .j/  D A .j C1/  \n0 .j/  D j C .j C 1/ D 2j C 1. \nLemma  19.3  \nFor any integer j \ue004 1, we have A 2 .j/  D 2 j C1 .j C 1/ \ue003 1. \nProof  We  \u00fbrst  use  induction  on  i to show that A .i/  \n1 .j/  D 2 i .j C 1/ \ue003 1. For \nthe base case, we have A .0/  \n1 .j/  D j D 2 0 .j C 1/ \ue003 1. For the inductive step, \nassume that A .i \ue0021/  \n1 .j/  D 2 i \ue0021 .j C 1/ \ue003 1. Then A .i/  \n1 .j/  D A 1 .A  .i \ue0021/  \n1 .j//  D \nA 1 .2 i \ue0021 .j C 1/ \ue003 1/ D 2\ue001 .2 i \ue0021 .j C1/ \ue0031/ C1 D 2 i .j C1/ \ue0032C1 D 2 i .j C1/ \ue0031. \nFinally, we note that A 2 .j/  D A .j C1/  \n1 .j/  D 2 j C1 .j C 1/ \ue003 1. \nNow we can see how quickly A k .j/  grows by simply examining A k .1/  for levels \nk D 0;1;2;3;4. From  the  de\u00fbnition  of A 0 .j/  and the above lemmas, we have \nA 0 .1/  D 1 C 1 D 2, A 1 .1/  D 2 \ue001 1 C 1 D 3, and A 2 .1/  D 2 1C1 \ue001 .1 C 1/ \ue003 1 D 7. \nWe also have \nA 3 .1/  D A .2/  \n2 .1/  \nD A 2 .A  2 .1//  \nD A 2 .7/  \nD 2 8 \ue001 8 \ue003 1 \nD 2 11  \ue003 1 \nD 2047  19.4  Analysis  of union  by rank  with  path  compression  533 \nand \nA 4 .1/  D A .2/  \n3 .1/  \nD A 3 .A  3 .1//  \nD A 3 .2047/  \nD A .2048/  \n2 .2047/  \n\ue007  A 2 .2047/  \nD 2 2048  \ue001 2048  \ue003 1 \nD 2 2059  \ue003 1 \n> 2  2056  \nD .2 4 / 514  \nD 16  514  \n\ue007  10  80  ; \nwhich is the estimated number of atoms in the obser vable universe. (The symbol \n<\ue007= denotes  the  <much-greater-than=  relation.)  \nWe  de\u00fbne  the  inverse  of the  function  A k .n/, for integer n \ue004 0, by \n\u02db.n/  D min fk W A k .1/  \ue004 ng : (19.2)  \nIn words, \u02db.n/  is the lowest level k for which A k .1/  is at least n. From the above \nvalues of A k .1/, we see that \n\u02db.n/  D \u02da \n0 for 0 \u0dc4 n \u0dc4 2;  \n1 for n D 3;  \n2 for 4 \u0dc4 n \u0dc4 7;  \n3 for 8 \u0dc4 n \u0dc4 2047;  \n4 for 2048  \u0dc4 n \u0dc4 A 4 .1/:  \nIt is only for values of n so large that the term <astronomical= understates t hem \n(greater than A 4 .1/, a huge number) that \u02db.n/  > 4, and so \u02db.n/  \u0dc4 4 for all \npractical purposes. \nProperties  of ranks  \nIn the remainder of this section, we prove an O.m\u02db.n//  bound on the running time \nof the  disjoint-set  operations  with  union  by  rank  and  path  compression. In order to \nprove  this  bound,  we  \u00fbrst  prove  some  simple  properties  of ranks. \nLemma  19.4  \nFor all nodes x , we have x: rank \u0dc4 x: p: rank, with strict inequality if x \u00a4 x: p (x is \nnot a root). The value of x: rank is initially 0, increases through time until x \u00a4 x: p, 534  Chapter  19  Data  Structures  for  Disjoint  Sets  \nand from then on, x: rank does not change. The value of x: p: rank monotonically \nincreases over time. \nProof  The proof is a straightforward induction on the num ber of operations,  us-  \ning the implementations of M AKE-SET, UNION , and F IND-SET that appear on \npage  530,  and  is left  as Exercise  19.4-1.  \nCorollary  19.5  \nOn  the  simple  path  from  any  node  going  up  toward  a root,  node  ranks strictly \nincrease. \nLemma  19.6  \nEvery node has rank at most n \ue003 1. \nProof  Each  node\u2019s  rank  starts  at 0, and it increases only upon L INK  operations. \nBecause there are at most n \ue003 1 UNION  operations, there are also at most n \ue003 1 \nLINK  operations. Because each L INK  operation either leaves all ranks alone or \nincreases  some  node\u2019s  rank  by  1, all ranks are at most n \ue003 1. \nLemma  19.6  provides  a weak  bound  on  ranks.  In fact,  every  node  has rank at \nmost blg nc (see  Exercise  19.4-2).  The  looser  bound  of Lemma  19.6  suf\u00fbce s for \nour purposes, however. \nProving  the  time  bound  \nIn order to prove the O.m\u02db.n//  time  bound,  we\u2019ll  use  the  potential  method  of \namortized  analysis  from  Section  16.3.  In performing  the  amortized analysis, it will \nbe convenient to assume that we invoke the L INK  operation rather than the U NION  \noperation. That is, since the parameters of the L INK  procedure are pointers to two \nroots, we act as though we perform the appropriate FIND-SET operations  sepa-  \nrately. The following lemma shows that even if we c ount the extra F IND-SET op-  \nerations induced by U NION  calls, the asymptotic running time remains unchange d. \nLemma  19.7  \nSuppose that we convert a sequence S 0 of m 0 MAKE-SET, UNION , and F IND-SET \noperations into a sequence S of m MAKE-SET, LINK, and F IND-SET operations \nby turning each U NION  into two F IND-SET operations followed by one L INK. \nThen, if sequence S runs in O.m\u02db.n//  time, sequence S 0 runs in O.m  0 \u02db.n//  time. \nProof  Since each U NION  operation in sequence S 0 is converted  into  three  oper-  \nations in S , we have m 0 \u0dc4 m \u0dc4 3m  0 , so that m D \u201a.m  0 /, Thus, an O.m\u02db.n//  19.4  Analysis  of union  by rank  with  path  compression  535 \ntime bound for the converted sequence S implies an O.m  0 \u02db.n//  time bound for \nthe original sequence S 0 . \nFrom now on, we assume that the initial sequence of  m 0 MAKE-SET, UNION , \nand F IND-SET operations has been converted to a sequence of m MAKE-SET, \nLINK, and F IND-SET operations. We now prove an O.m\u02db.n//  time bound for the \nconverted  sequence  and  appeal  to Lemma  19.7  to prove  the  O.m  0 \u02db.n//  running \ntime of the original sequence of m 0 operations. \nPotential  function  \nThe potential function we use assigns a potential \ufffd q .x/  to each node x in the \ndisjoint-set  forest  after  q operations. For the potential \u02c6 q of the entire forest after \nq operations, sum the individual node potentials: \u02c6 q D P  \nx \ufffd q .x/. Because the \nforest  is empty  before  the  \u00fbrst  operation,  the  sum  is taken  over an empty set, and \nso \u02c6 0 D 0. No potential \u02c6 q is ever negative. \nThe value of \ufffd q .x/  depends on whether x is a tree root after the qth operation. \nIf it is, or if x: rank D 0, then \ufffd q .x/  D \u02db.n/  \ue001 x: rank. \nNow suppose that after the qth operation, x is not a root and that x: rank \ue004 1. \nWe  need  to de\u00fbne  two  auxiliary  functions  on  x before  we  can  de\u00fbne  \ufffd q .x/. First \nwe  de\u00fbne  \nlevel.x/  D max fk W x: p: rank \ue004 A k .x:  rank/g : (19.3)  \nThat is, level.x/  is the greatest level k for which A k , applied to x \u2019s rank,  is no  \ngreater than x \u2019s parent\u2019s  rank.  \nWe claim that \n0 \u0dc4 level.x/<\u02db.n/;  (19.4)  \nwhich we see as follows. We have \nx: p: rank \ue004 x: rank C 1 (by  Lemma  19.4  because  x is not a root) \nD A 0 .x:  rank/ (by  the  de\u00fbnition  (19.1)  of A 0 .j/) , \nwhich implies that level .x/  \ue004 0, and \nA \u02db.n/  .x:  rank/ \ue004 A \u02db.n/  .1/  (because A k .j/  is strictly increasing) \n\ue004 n (by  the  de\u00fbnition  (19.2)  of \u02db.n/ ) \n> x: p: rank (by  Lemma  19.6)  , \nwhich implies that level .x/<\u02db.n/ . \nFor a given nonroot node x , the value of level .x/  monotonically increases over \ntime.  Why?  Because  x is not a root, its rank does not change. The rank o f x: p 536  Chapter  19  Data  Structures  for  Disjoint  Sets  \nmonotonically increases over time, since if x: p is not a root then its rank does not \nchange, and if x: p is a root then its rank can never decrease. Thus, t he difference \nbetween x: rank and x: p: rank monotonically increases over time. Therefore, the \nvalue of k needed for A k .x:  rank/ to overtake x: p: rank monotonically increases \nover time as well. \nThe second auxiliary function applies when x: rank \ue004 1: \niter.x/  D max \u02da \ni W x: p: rank \ue004 A .i/  \nlevel.x/  .x:  rank/ \ue009 \n: (19.5)  \nThat is, iter.x/  is the largest number of times we can iteratively a pply A level.x/  , \napplied initially to x \u2019s rank,  before  exceeding  x \u2019s parent\u2019s  rank.  \nWe claim that when x: rank \ue004 1, we have \n1 \u0dc4 iter.x/  \u0dc4 x: rank ; (19.6)  \nwhich we see as follows. We have \nx: p: rank \ue004 A level.x/  .x:  rank/ (by  the  de\u00fbnition  (19.3)  of level.x/) \nD A .1/  \nlevel.x/  .x:  rank/ (by  the  de\u00fbnition  (3.30)  of functional  iteration)  , \nwhich implies that iter .x/  \ue004 1. We also have \nA .x:  rankC1/  \nlevel.x/  .x:  rank/ D A level.x/C1 .x:  rank/ (by  the  de\u00fbnition  (19.1)  of A k .j/) \n>x:  p: rank (by  the  de\u00fbnition  (19.3)  of level.x/) , \nwhich implies that iter .x/  \u0dc4 x: rank. Note that because x: p: rank monotonically \nincreases over time, in order for iter .x/  to decrease, level .x/  must increase. As long \nas level.x/  remains unchanged, iter .x/  must either increase or remain unchanged. \nWith  these  auxiliary  functions  in place,  we  are  ready  to de\u00fbn e the potential of \nnode x after q operations: \n\ufffd q .x/  D \u0128 \n\u02db.n/  \ue001 x: rank if x is a root or x: rank D 0;  \n.\u02db.n/  \ue003 level.x//  \ue001 x: rank \ue003 iter.x/  \nif x is not a root and x: rank \ue004 1:  (19.7)  \nWe next investigate some useful properties of node potentials. \nLemma  19.8  \nFor every node x , and for all operation counts q, we have \n0 \u0dc4 \ufffd q .x/  \u0dc4 \u02db.n/  \ue001 x: rank : \nProof  If x is a root or x: rank D 0, then \ufffd q .x/  D \u02db.n/  \ue001 x: rank by  de\u00fbnition.  \nNow suppose that x is not a root and that x: rank \ue004 1. We can obtain a lower bound \non \ufffd q .x/  by maximizing level .x/  and iter.x/. The  bounds  (19.4)  and  (19.6)  give  \n\u02db.n/  \ue003 level.x/  \ue004 1 and iter.x/  \u0dc4 x: rank. Thus, we have 19.4  Analysis  of union  by rank  with  path  compression  537 \n\ufffd q .x/  D .\u02db.n/  \ue003 level.x//  \ue001 x: rank \ue003 iter.x/  \n\ue004 x: rank \ue003 x: rank \nD 0:  \nSimilarly, minimizing level .x/  and iter.x/  provides an upper bound on \ufffd q .x/. By \nthe  bound  (19.4),  level.x/  \ue004 0, and  by  the  bound  (19.6),  iter.x/  \ue004 1. Thus, we \nhave \n\ufffd q .x/  \u0dc4 .\u02db.n/  \ue003 0/ \ue001 x: rank \ue003 1 \nD \u02db.n/  \ue001 x: rank \ue003 1 \n< \u02db.n/  \ue001 x: rank : \nCorollary  19.9  \nIf node x is not a root and x: rank >0, then \ufffd q .x/<\u02db.n/  \ue001 x: rank. \nPotential  changes  and  amortized  costs  of operations  \nWe  are  now  ready  to examine  how  the  disjoint-set  operations  affect  node  poten-  \ntials.  Once  we  understand  how  each  operation  can  change  the  potential, we can \ndetermine the amortized costs. \nLemma  19.10  \nLet x be a node that is not a root, and suppose that the qth operation is either a \nLINK  or a F IND-SET. Then after the qth operation, \ufffd q .x/  \u0dc4 \ufffd q\ue0021 .x/. Moreover, \nif x: rank \ue004 1 and either level .x/  or iter.x/  changes due to the qth operation, then \n\ufffd q .x/  \u0dc4 \ufffd q\ue0021 .x/  \ue003 1. That is, x \u2019s potential  cannot  increase,  and  if it has  positive  \nrank and either level .x/  or iter.x/  changes, then x \u2019s potential  drops  by  at least  1. \nProof  Because x is not a root, the qth operation does not change x: rank, and \nbecause n does not change after the initial n MAKE-SET operations, \u02db.n/  remains \nunchanged as well. Hence, these components of the f ormula for x \u2019s potential  re-  \nmain the same after the qth operation. If x: rank D 0, then \ufffd q .x/  D \ufffd q\ue0021 .x/  D 0. \nNow assume that x: rank \ue004 1. Recall that level .x/  monotonically increases \nover time. If the qth operation leaves level .x/  unchanged, then iter .x/  either  in-  \ncreases or remains unchanged. If both level .x/  and iter.x/  are unchanged, then \n\ufffd q .x/  D \ufffd q\ue0021 .x/. If level.x/  is unchanged and iter .x/  increases, then it increases \nby at least 1, and so \ufffd q .x/  \u0dc4 \ufffd q\ue0021 .x/  \ue003 1. \nFinally, if the qth operation increases level .x/, it increases by at least 1, so that \nthe value of the term .\u02db.n/  \ue003 level.x//  \ue001 x: rank drops by at least x: rank. Be-  \ncause level.x/  increased, the value of iter .x/  might drop, but according to the \nbound  (19.6),  the  drop  is by  at most  x: rank \ue003 1. Thus,  the  increase  in poten-  538  Chapter  19  Data  Structures  for  Disjoint  Sets  \ntial due to the change in iter .x/  is less than the decrease in potential due to the \nchange in level .x/, yielding \ufffd q .x/  \u0dc4 \ufffd q\ue0021 .x/  \ue003 1. \nOur  \u00fbnal  three  lemmas  show  that  the  amortized  cost  of each  MAKE-SET, LINK, \nand F IND-SET operation is O.\u02db.n//. Recall  from  equation  (16.2)  on  page  456  that  \nthe amortized cost of each operation is its actual cost plus the change in potential \ndue to the operation. \nLemma  19.11  \nThe amortized cost of each M AKE-SET operation is O.1/ . \nProof  Suppose that the qth operation is M AKE-SET .x/. This operation creates \nnode x with rank 0, so that \ufffd q .x/  D 0. No other ranks or potentials change, and \nso \u02c6 q D \u02c6 q\ue0021 . Noting that the actual cost of the M AKE-SET operation is O.1/  \ncompletes the proof. \nLemma  19.12  \nThe amortized cost of each L INK  operation is O.\u02db.n// . \nProof  Suppose that the qth operation is L INK.x;y/ . The actual cost of the L INK  \noperation is O.1/ . Without loss of generality, suppose that the L INK  makes y the \nparent of x . \nTo determine the change in potential due to the L INK, note that the only nodes \nwhose potentials may change are x , y , and the children of y just  prior  to the  oper-  \nation.  We\u2019ll  show  that  the  only  node  whose  potential  can  increase due to the L INK  \nis y , and that its increase is at most \u02db.n/ : \n\ue001 By  Lemma  19.10,  any  node  that  is y \u2019s child  just  before  the  LINK  cannot have \nits potential increase due to the L INK. \n\ue001 From  the  de\u00fbnition  (19.7)  of \ufffd q .x/, note that, since x was a root just before \nthe qth operation, \ufffd q\ue0021 .x/  D \u02db.n/  \ue001 x: rank at that time. If x: rank D 0, then \n\ufffd q .x/  D \ufffd q\ue0021 .x/  D 0. Otherwise,  \n\ufffd q .x/  < \u02db.n/  \ue001 x: rank (by  Corollary  19.9)  \nD \ufffd q\ue0021 .x/;  \nand so x \u2019s potential  decreases.  \n\ue001 Because y is a root prior to the L INK, \ufffd q\ue0021 .y/  D \u02db.n/  \ue001 y: rank. After the \nLINK  operation, y remains a root, so that y \u2019s potential  still  equals  \u02db.n/  times \nits rank after the operation. The L INK  operation either leaves y \u2019s rank  alone  \nor increases y \u2019s rank  by  1. Therefore, either \ufffd q .y/  D \ufffd q\ue0021 .y/  or \ufffd q .y/  D \n\ufffd q\ue0021 .y/  C \u02db.n/ . 19.4  Analysis  of union  by rank  with  path  compression  539 \nThe increase in potential due to the L INK  operation, therefore, is at most \u02db.n/ . \nThe amortized cost of the L INK  operation is O.1/  C \u02db.n/  D O.\u02db.n// . \nLemma  19.13  \nThe amortized cost of each F IND-SET operation is O.\u02db.n// . \nProof  Suppose that the qth operation is a F IND-SET and  that  the  \u00fbnd  path  con-  \ntains s nodes. The actual cost of the F IND-SET operation is O.s/ . We will \nshow  that  no  node\u2019s  potential  increases  due  to the  FIND-SET and that at least \nmax f0;s  \ue003 .\u02db.n/  C 2/g nodes  on  the  \u00fbnd  path  have  their  potential  decrease  by  \nat least 1. \nWe  \u00fbrst  show  that  no  node\u2019s  potential  increases.  Lemma  19.10  takes care of all \nnodes other than the root. If x is the root, then its potential is \u02db.n/  \ue001 x: rank, which \ndoes not change due to the F IND-SET operation. \nNow we show that at least max f0;s  \ue003 .\u02db.n/  C 2/g nodes have their potential \ndecrease by at least 1. Let x be a node  on  the  \u00fbnd  path  such  that  x: rank > 0  \nand x is followed  somewhere  on  the  \u00fbnd  path  by  another  node  y that is not a root, \nwhere level.y/  D level.x/  just before the F IND-SET operation. (Node y need not \nimmediately  follow x on  the  \u00fbnd  path.)  All  but  at most  \u02db.n/  C 2 nodes  on  the  \u00fbnd  \npath satisfy these constraints on x . Those  that  do  not  satisfy  them  are  the  \u00fbrst  node  \non  the  \u00fbnd  path  (if  it has  rank  0), the last node on the path (i.e., the root), and the \nlast node w on the path for which level .w/  D k, for each k D 0;1;2;:::;\u02db.n/  \ue003 1. \nConsider such a node x . It has positive rank and is followed somewhere on  \nthe  \u00fbnd  path  by  nonroot  node  y such that level .y/  D level.x/  before the path \ncompression occurs. We claim that the path compress ion decreases x \u2019s potential  \nby at least 1. To prove this claim, let k D level.x/  D level.y/  and i D iter.x/  \nbefore  the  path  compression  occurs.  Just  prior  to the  path  compression caused by \nthe F IND-SET, we have \nx: p: rank \ue004 A .i/  \nk .x:  rank/ (by  the  de\u00fbnition  (19.5)  of iter.x/) , \ny: p: rank \ue004 A k .y:  rank/ (by  the  de\u00fbnition  (19.3)  of level.y/) , \ny: rank \ue004 x: p: rank (by  Corollary  19.5  and  because  \ny follows x on  the  \u00fbnd  path)  . \nPutting these inequalities together gives \ny: p: rank \ue004 A k .y:  rank/ \n\ue004 A k .x:  p: rank/ (because A k .j/  is strictly increasing) \n\ue004 A k .A  .i/  \nk .x:  rank// \nD A .i C1/  \nk .x:  rank/ (by  the  de\u00fbnition  (3.30)  of functional  iteration)  . 540  Chapter  19  Data  Structures  for  Disjoint  Sets  \nBecause path compression makes x and y have  the  same  parent,  after  path  com-  \npression we have x: p: rank D y: p: rank. The parent of y might change due to the \npath compression, but if it does, the rank of y \u2019s new  parent  compared  with  the  rank  \nof y \u2019s parent  before  path  compression  is either  the  same  or great er. Since x: rank \ndoes not change, x: p: rank D y: p: rank \ue004 A .i C1/  \nk .x:  rank/ after path compression. \nBy  the  de\u00fbnition  (19.5)  of the  iter  function,  the  value  of iter.x/  increases from i \nto at least i C 1. By  Lemma  19.10,  \ufffd q .x/  \u0dc4 \ufffd q\ue0021 .x/  \ue003 1, so that x \u2019s potential  \ndecreases by at least 1. \nThe amortized cost of the F IND-SET operation is the actual cost plus the change \nin potential. The actual cost is O.s/ , and we have shown that the total potential \ndecreases by at least max f0;s  \ue003 .\u02db.n/  C 2/g. The amortized cost, therefore, is at \nmost O.s/  \ue003 .s \ue003 .\u02db.n/  C 2//  D O.s/  \ue003 s C O.\u02db.n//  D O.\u02db.n// , since we \ncan scale up the units of potential to dominate the  constant hidden in O.s/ . (See \nExercise  19.4-6.)  \nPutting the preceding lemmas together yields the fo llowing theorem. \nTheorem  19.14  \nA sequence of m MAKE-SET, UNION , and F IND-SET operations, n of which are \nMAKE-SET operations,  can  be performed  on  a disjoint-set  forest  with  union by \nrank and path compression in O.m\u02db.n//  time. \nProof  Immediate  from  Lemmas  19.7,  19.11,  19.12,  and  19.13.  \nExercises  \n19.4-1  \nProve  Lemma  19.4.  \n19.4-2  \nProve that every node has rank at most blg nc. \n19.4-3  \nIn light  of Exercise  19.4-2,  how  many  bits  are  necessary  to store x: rank for each \nnode x ? \n19.4-4  \nUsing  Exercise  19.4-2,  give  a simple  proof  that  operations  on  a disjoint-set  forest  \nwith union by rank but without path compression run  in O.m  lg n/ time. Problems for Chapter 19 541 \n19.4-5  \nProfessor Dante reasons that because node ranks inc rease strictly along a simple \npath to the root, node levels must monotonically in crease along the path. In other \nwords, if x: rank > 0  and x: p is not a root, then level .x/  \u0dc4 level.x:  p/. Is the \nprofessor  correct?  \n19.4-6  \nThe  proof  of Lemma  19.13  ends  with  scaling  the  units  of potent ial to dominate the \nconstant hidden in the O.s/  term. To be more precise in the proof, you need to \nchange  the  de\u00fbnition  (19.7)  of the  potential  function  to multiply each of the two \ncases by a constant, say c , that dominates the constant in the O.s/  term. How must \nthe rest of the analysis change to accommodate this  updated potential  function?  \n? 19.4-7  \nConsider the function \u02db 0 .n/  D min fk W A k .1/  \ue004 lg.n C 1/g. Show that \u02db 0 .n/  \u0dc4 3 \nfor all practical values of n and,  using  Exercise  19.4-2,  show  how  to modify  the  \npotential-function  argument  to prove  that  performing  a sequence of m MAKE-SET, \nUNION , and F IND-SET operations, n of which are M AKE-SET operations, on a \ndisjoint-set  forest  with  union  by  rank  and  path  compression  takes O.m\u02db  0 .n//  time. \nProblems  \n19-1  Of\u00fcine  minimum  \nIn the of\u00fcine  minimum  problem , you maintain a dynamic set T of elements from \nthe domain f1;2;:::;n g under the operations I NSERT and E XTRACT-MIN. The \ninput is a sequence S of n I NSERT and m EXTRACT-MIN calls, where each key \nin f1;2;:::;n g is inserted exactly once. Your goal is to determine  which key \nis returned by each E XTRACT-MIN call.  Speci\u00fbcally,  you  must  \u00fbll  in an array  \nextracted  \u01521 W m\ufffd, where for i D 1;2;:::;m , extracted  \u0152i\ufffd  is the key returned by the \ni th E XTRACT-MIN call.  The  problem  is <of\u00fcine=  in the  sense  that  you  are  allowe d \nto process the entire sequence S before determining any of the returned keys. \na. Consider  the  following  instance  of the  of\u00fcine  minimum  probl em, in which each \noperation I NSERT .i/  is represented by the value of i and each E XTRACT-MIN \nis represented by the letter E: \n4;8;  E;3;  E;9;2;6;  E; E; E;1;7;  E;5:  \nFill in the correct values in the extracted  array. 542  Chapter  19  Data  Structures  for  Disjoint  Sets  \nTo develop an algorithm for this problem, break the  sequence S into homogeneous \nsubsequences. That is, represent S by \nI 1 ; E; I 2 ; E; I 3 ;:::;  I m ; E; I mC1 ; \nwhere each E represents a single E XTRACT-MIN call and each I j represents  a (pos-  \nsibly empty) sequence of I NSERT calls. For each subsequence I j , initially place the \nkeys inserted by these operations into a set K j , which is empty if I j is empty. Then \nexecute  the  OFFLINE-MINIMUM procedure. \nOFFLINE-MINIMUM.m;n/  \n1 for  i D 1 to n \n2 determine j such that i 2 K j \n3 if j \u00a4 m C 1 \n4 extracted  \u0152j \ufffd  D i \n5 let l be the smallest value greater than j for which set K l exists \n6 K l D K j [ K l , destroying K j \n7 return  extracted  \nb. Argue that the array extracted  returned  by  OFFLINE-MINIMUM is correct. \nc. Describe  how  to implement  OFFLINE-MINIMUM ef\u00fbciently  with  a disjoint-set  \ndata  structure.  Give  as tight  a bound  as you  can  on  the  worst-c ase running time \nof your implementation. \n19-2  Depth  determination  \nIn the depth-determination  problem , you maintain a forest F D fT i g of rooted \ntrees under three operations: \nMAKE-TREE .v/  creates a tree whose only node is v. \nFIND-DEPTH .v/  returns the depth of node v within its tree. \nGRAFT.r;v/  makes node r , which is assumed to be the root of a tree, become  the \nchild of node v, which is assumed to be in a different tree from r but may or \nmay not itself be a root. \na. Suppose that you use a tree representation similar to a disjoint-set  forest:  v: p \nis the parent of node v, except that v: p D v if v is a root. Suppose further \nthat  you  implement  GRAFT.r;v/  by setting r: p D v and F IND-DEPTH .v/  by \nfollowing  the  \u00fbnd  path  from  v up to the root, returning a count of all nodes \nother than v encountered.  Show  that  the  worst-case  running  time  of a sequence \nof m MAKE-TREE, FIND-DEPTH, and  GRAFT operations is \u201a.m  2 /. Problems for Chapter 19 543 \nBy  using  the  union-by-rank  and  path-compression  heuristic s, you can reduce the \nworst-case  running  time.  Use  the  disjoint-set  forest  S D fS i g, where each set S i \n(which is itself a tree) corresponds to a tree T i in the forest F . The tree structure \nwithin a set S i , however, does not necessarily correspond to that of T i . In fact, \nthe implementation of S i does  not  record  the  exact  parent-child  relationships  but  \nnevertheless  allows  you  to determine  any  node\u2019s  depth  in T i . \nThe key idea is to maintain in each node v a <pseudodistance= v: d, which is \nde\u00fbned  so that  the  sum  of the  pseudodistances  along  the  simpl e path from v to the \nroot of its set S i equals the depth of v in T i . That is, if the simple path from v to its \nroot in S i is v 0 ;v  1 ;:::;v  k , where v 0 D v and v k is S i \u2019s root,  then  the  depth  of v \nin T i is P  k \nj D0 v j : d. \nb. Give  an implementation  of MAKE-TREE. \nc. Show how to modify F IND-SET to implement F IND-DEPTH. Your  implemen-  \ntation should perform path compression, and its run ning time should be linear \nin the  length  of the  \u00fbnd  path.  Make  sure  that  your  implementat ion updates \npseudodistances correctly. \nd. Show  how  to implement  GRAFT.r;v/ , which combines the sets containing r \nand v, by modifying the U NION  and LINK  procedures. Make sure that your \nimplementation updates pseudodistances correctly. N ote that the root of a set S i \nis not necessarily the root of the corresponding tr ee T i . \ne. Give  a tight  bound  on  the  worst-case  running  time  of a sequenc e of m MAKE- \nTREE, FIND-DEPTH, and  GRAFT operations, n of which are M AKE-TREE op-  \nerations. \n19-3  Tarjan\u2019s  of\u00fcine  lowest-common-ancestors  algorithm  \nThe lowest  common  ancestor  of two nodes u and v in a rooted tree T is the node w \nthat is an ancestor of both u and v and that has the greatest depth in T . In the of\u00fcine  \nlowest-common-ancestors  problem , you are given a rooted tree T and an arbitrary \nset P D ffu;vgg of unordered pairs of nodes in T , and you wish to determine the \nlowest common ancestor of each pair in P . \nTo  solve  the  of\u00fcine  lowest-common-ancestors  problem,  the  LCA procedure on \nthe following page performs a tree walk of T with the initial call LCA .T:  root /. \nAssume that each node is colored WHITE prior to the walk. \na. Argue  that  line  10  executes  exactly  once  for  each  pair  fu;vg 2  P . \nb. Argue that at the time of the call LCA .u/, the  number  of sets  in the  disjoint-set  \ndata structure equals the depth of u in T . 544  Chapter  19  Data  Structures  for  Disjoint  Sets  \nLCA.u/  \n1 MAKE-SET .u/  \n2 FIND-SET.u/:  ancestor  D u \n3 for  each child v of u in T \n4 LCA.v/  \n5 UNION.u;v/  \n6 FIND-SET.u/:  ancestor  D u \n7 u: color  D BLACK  \n8 for  each node v such that fu;vg 2  P \n9 if v: color  = = BLACK  \n10  print <The lowest common ancestor of= \nu <and= v <is= F IND-SET .v/:  ancestor  \nc. Prove that LCA correctly prints the lowest common a ncestor of u and v for \neach pair fu;vg 2  P . \nd. Analyze the running time of LCA, assuming that you use the implementation \nof the  disjoint-set  data  structure  in Section  19.3.  \nChapter  notes  \nMany  of the  important  results  for  disjoint-set  data  structu res are due at least in part \nto R. E. Tarjan.  Using  aggregate  analysis,  Tarjan  [427,  429]  gave  the  \u00fbrst  tight  \nupper bound in terms of the very slowly growing inv erse y \u02db.m;n/  of Ackermann\u2019s  \nfunction. (The function A k .j/  given  in Section  19.4  is similar  to Ackermann\u2019s  \nfunction, and the function \u02db.n/  is similar to y \u02db.m;n/ . Both \u02db.n/  and y \u02db.m;n/  are \nat most 4 for all conceivable values of m and n.) An upper bound of O.m  lg \ue003 n/ \nwas  proven  earlier  by  Hopcroft  and  Ullman  [5,  227].  The  treatment  in Section  19.4  \nis adapted  from  a later  analysis  by  Tarjan  [431],  which  is based on an analysis by \nKozen  [270].  Harfst  and  Reingold  [209]  give  a potential-based  version  of Tarjan\u2019s  \nearlier bound. \nTarjan  and  van  Leeuwen  [432]  discuss  variants  on  the  path-compression  heuris-  \ntic,  including  <one-pass  methods,=  which  sometimes  offer  better constant factors \nin their  performance  than  do  two-pass  methods.  As  with  Tarjan\u2019s  earlier  analyses  \nof the  basic  path-compression  heuristic,  the  analyses  by  Tarjan and van Leeuwen \nare aggregate. Harfst and Reingold [209] later show ed how to make a small change \nto the  potential  function  to adapt  their  path-compression  analysis  to these  one-pass  \nvariants.  Goel  et al.  [182]  prove  that  linking  disjoint-set  trees randomly yields the Notes for Chapter 19 545 \nsame  asymptotic  running  time  as union  by  rank.  Gabow  and  Tarjan  [166]  show  \nthat  in certain  applications,  the  disjoint-set  operations  can be made to run in O.m/  \ntime. \nTarjan  [428]  showed  that  a lower  bound  of \ufffd.m  y \u02db.m;n//  time is required for \noperations  on  any  disjoint-set  data  structure  satisfying  certain technical conditions. \nThis  lower  bound  was  later  generalized  by  Fredman  and  Saks  [155],  who  showed  \nthat in the worst case, \ufffd.m  y \u02db.m;n//. lg n/-bit  words  of memory  must  be accessed.  Part  VI  Graph  Algorithms  Introduction  \nGraph  problems  pervade  computer  science,  and  algorithms  for working with them \nare  fundamental  to the  \u00fbeld.  Hundreds  of interesting  comput ational problems are \ncouched in terms of graphs. This part touches on a few of the mo re signi\u00fbcant  \nones. \nChapter 20 shows how to represent a graph in a comp uter and then discusses \nalgorithms  based  on  searching  a graph  using  either  breadth-\u00fbrst  search  or depth-  \n\u00fbrst  search.  The  chapter  gives  two  applications  of depth-\u00fbr st search: topologically \nsorting a directed acyclic graph and decomposing a directed graph into its strongly \nconnected components. \nChapter  21  describes  how  to compute  a minimum-weight  spanni ng tree of a \ngraph:  the  least-weight  way  of connecting  all  of the  vertice s together when each \nedge has an associated weight. The algorithms for c omputing minimum spanning \ntrees serve as good examples of greedy algorithms ( see Chapter 15).  \nChapters  22  and  23  consider  how  to compute  shortest  paths  between vertices \nwhen each edge has an associated length or <weight. = Chapter 22 shows how to \n\u00fbnd  shortest  paths  from  a given  source  vertex  to all  other  vertices,  and  Chapter  23  \nexamines methods to compute shortest paths between every pair of vertices. \nChapter  24  shows  how  to compute  a maximum  \u00fcow  of material  in a \u00fcow  net-  \nwork,  which  is a directed  graph  having  a speci\u00fbed  source  vertex of material, a \nspeci\u00fbed  sink  vertex,  and  speci\u00fbed  capacities  for  the  amoun t of material that can \ntraverse each directed edge. This general problem a rises in many forms, and a \ngood  algorithm  for  computing  maximum  \u00fcows  can  help  solve  a variety of related \nproblems  ef\u00fbciently.  \nFinally,  Chapter  25  explores  matchings  in bipartite  graphs : methods for pairing \nup vertices that are partitioned into two sets by s electing edges that go between \nthe  sets.  Bipartite-matching  problems  model  several  situa tions that arise in the real \nworld.  The  chapter  examines  how  to \u00fbnd  a matching  of maximum  cardinality; the 548 Part VI Graph Algorithms \n<stable-marriage  problem,=  which  has  the  highly  practical  application of matching \nmedical residents to hospitals; and assignment prob lems, which maximize the total \nweight of a bipartite matching. \nWhen we characterize the running time of a graph al gorithm on a given graph \nG D .V;E/ , we usually measure the size of the input in terms  of the number of \nvertices jV j and the number of edges jEj of the graph. That is, we denote the size \nof the input with two parameters, not just one. We adopt a common notational \nconvention for these parameters. Inside asymptotic notation (such as O-notation  \nor \u201a-notation),  and  only  inside such notation, the symbol V denotes jV j and the \nsymbol E denotes jEj. For example, we might say, <the algorithm runs in  O.VE/  \ntime,= meaning that the algorithm runs in O.jV j jEj/ time. This convention makes \nthe  running-time  formulas  easier  to read,  without  risk  of ambiguity. \nAnother convention we adopt appears in pseudocode. We denote the vertex set \nof a graph G by G:  V and its edge set by G:  E. That is, the pseudocode views vertex \nand edge sets as attributes of a graph. 20  Elementary  Graph  Algorithms  \nThis chapter presents methods for representing a gr aph and for searching a graph. \nSearching a graph means systematically following th e edges of the graph so as to \nvisit  the  vertices  of the  graph.  A graph-searching  algorith m can discover much \nabout the structure of a graph. Many algorithms beg in by searching their input \ngraph to obtain this structural information. Severa l other graph  algorithms  elabo-  \nrate on basic graph searching. Techniques for searc hing a graph lie at the heart of \nthe  \u00fbeld  of graph  algorithms.  \nSection  20.1  discusses  the  two  most  common  computational  representations of \ngraphs: as adjacency lists and as adjacency matrice s. Section  20.2  presents  a sim-  \nple  graph-searching  algorithm  called  breadth-\u00fbrst  search  and  shows  how  to cre-  \nate  a breadth-\u00fbrst  tree.  Section  20.3  presents  depth-\u00fbrst  search and proves some \nstandard  results  about  the  order  in which  depth-\u00fbrst  search  visits  vertices.  Sec-  \ntion  20.4  provides  our  \u00fbrst  real  application  of depth-\u00fbrst  search:  topologically  sort-  \ning  a directed  acyclic  graph.  A second  application  of depth-\u00fbrst  search,  \u00fbnding  the  \nstrongly connected components of a directed graph, is the topic  of Section  20.5.  \n20.1  Representations  of graphs  \nYou can choose between two standard ways to represe nt a graph G D .V;E/ : \nas a collection of adjacency lists or as an adjacen cy matrix. Either way applies \nto both directed and undirected graphs. Because the  adjacency-list  representation  \nprovides a compact way to represent sparse  graphs4those  for  which  jEj is much \nless than jV j 2 4it  is usually  the  method  of choice.  Most  of the  graph  algorit hms \npresented in this book assume that an input graph i s represented  in adjacency-list  \nform.  You  might  prefer  an adjacency-matrix  representation , however, when the \ngraph is dense4jEj is close to jV j 2 4or  when  you  need  to be able  to tell  quickly  \nwhether there is an edge connecting two given verti ces. For example, two of the 550  Chapter  20  Elementary  Graph  Algorithms  \n1 2 \n3 \n4 5 1 \n2 \n3 \n4 \n5 2 5 \n1 \n2 \n2 \n4 1 2 5 3 4 4 5 3 1 0 0 1 \n0 1 1 1 \n1 0 1 0 \n1 1 0 1 \n1 0 1 0 0 \n1 \n0 \n0 \n1 1 2 3 4 5 \n1 \n2 \n3 \n4 \n5 \n(a) (b) (c) \nFigure  20.1  Two representations of an undirected graph. (a)  An undirected graph G with  5 vertices  \nand  7 edges.  (b)  An  adjacency-list  representation  of G. (c)  The  adjacency-matrix  representation  \nof G. \n1 2 \n5 4 1 \n2 \n3 \n4 \n5 2 4 \n5 \n6 \n2 \n4 \n6 5 1 0 1 0 \n0 0 0 1 \n0 0 0 1 \n1 0 0 0 \n0 0 1 0 0 \n0 \n0 \n0 \n0 1 2 3 4 5 \n1 \n2 \n3 \n4 \n5 \n(a) (b) (c) 3 \n6 6 \n6 0 0 0 0 0 1 0 0 1 0 0 \n6 \nFigure  20.2  Two representations of a directed graph. (a)  A directed graph G with  6 vertices  and  8 \nedges. (b)  An  adjacency-list  representation  of G. (c)  The  adjacency-matrix  representation  of G. \nall-pairs  shortest-paths  algorithms  presented  in Chapter  23  assume  that  their  input  \ngraphs are represented by adjacency matrices. \nThe adjacency-list  representation  of a graph G D .V;E/  consists  of an ar-  \nray Adj of jV j lists, one for each vertex in V . For each u 2 V , the adjacency \nlist Adj\u0152u\ufffd  contains all the vertices v such that there is an edge .u;v/  2 E. That \nis, Adj\u0152u\ufffd  consists of all the vertices adjacent to u in G. (Alternatively,  it can  con-  \ntain pointers to these vertices.) Since the adjacen cy lists represent the edges of a \ngraph, our pseudocode treats the array Adj as an attribute of the graph, just like \nthe edge set E. In pseudocode, therefore, you will see notation s uch as G:  Adj\u0152u\ufffd. \nFigure  20.1(b)  is an adjacency-list  representation  of the  undirected  graph  in Fig-  \nure  20.1(a).  Similarly,  Figure  20.2(b)  is an adjacency-lis t representation of the \ndirected graph in Figure 20.2(a). \nIf G is a directed graph, the sum of the lengths of all the adjacency lists is jEj, \nsince an edge of the form .u;v/  is represented by having v appear in Adj\u0152u\ufffd. If G is 20.1 Representations of graphs 551 \nan undirected graph, the sum of the lengths of all the adjacency lists is 2 jEj, since \nif .u;v/  is an undirected edge, then u appears in v\u2019s adjacency  list  and  vice  versa.  \nFor  both  directed  and  undirected  graphs,  the  adjacency-lis t representation has the \ndesirable property that the amount of memory it req uires is \u201a.V  C E/. Finding \neach edge in the graph also takes \u201a.V  C E/  time, rather than just \u201a.E/ , since each \nof the jV j adjacency  lists  must  be examined.  Of  course,  if jEj D  \ufffd.V  /4such  as \nin a connected, undirected graph or a strongly conn ected, directed  graph4we  can  \nsay  that  \u00fbnding  each  edge  takes  \u201a.E/  time. \nAdjacency lists can also represent weighted  graphs , that is, graphs for which \neach edge has an associated weight  given by a weight  function  w W E !  R. For \nexample, let G D .V;E/  be a weighted graph with weight function w. Then you \ncan simply store the weight w.u;v/  of the edge .u;v/  2 E with vertex v in u\u2019s \nadjacency  list.  The  adjacency-list  representation  is quite robust in that you can \nmodify it to support many other graph variants. \nA potential  disadvantage  of the  adjacency-list  representa tion is that it provides \nno quicker way to determine whether a given edge .u;v/  is present in the graph \nthan to search for v in the adjacency list Adj\u0152u\ufffd. An  adjacency-matrix  representa-  \ntion of the graph remedies this disadvantage, but a t the cost of using asymptotically \nmore  memory.  (See  Exercise  20.1-8  for  suggestions  of variat ions on adjacency lists \nthat permit faster edge lookup.) \nThe adjacency-matrix  representation  of a graph G D .V;E/  assumes that the \nvertices are numbered 1;2;:::;  jV j in some  arbitrary  manner.  Then  the  adjacency-  \nmatrix representation of a graph G consists of a jV j \ue005 jV j matrix A D .a ij / such \nthat \na ij D ( \n1 if .i;j/  2 E;  \n0 otherwise : \nFigures  20.1(c)  and  20.2(c)  are  the  adjacency  matrices  of the  undirected  and  di-  \nrected  graphs  in Figures  20.1(a)  and  20.2(a),  respectively  . The adjacency matrix of \na graph requires \u201a.V  2 / memory, independent of the number of edges in the g raph. \nBecause  \u00fbnding  each  edge  in the  graph  requires  examining  the  entire adjacency \nmatrix, doing so takes \u201a.V  2 / time. \nObserve  the  symmetry  along  the  main  diagonal  of the  adjacency  matrix  in Fig-  \nure  20.1(c).  Since  in an undirected  graph,  .u;v/  and .v;u/  represent the same \nedge, the adjacency matrix A of an undirected graph is its own transpose: A D A T . \nIn some applications, it pays to store only the ent ries on and above the diagonal of \nthe adjacency matrix, thereby cutting the memory ne eded to store the graph almost \nin half. \nLike  the  adjacency-list  representation  of a graph,  an adjacency  matrix  can  rep-  \nresent a weighted graph. For example, if G D .V;E/  is a weighted graph with \nedge-weight  function  w, you can store the weight w.u;v/  of the edge .u;v/  2 E 552  Chapter  20  Elementary  Graph  Algorithms  \nas the entry in row u and column v of the adjacency matrix. If an edge does not \nexist, you can store a NIL value as its corresponding matrix entry, though for  many \nproblems it is convenient to use a value such as 0 or 1. \nAlthough  the  adjacency-list  representation  is asymptotically  at least  as space-  \nef\u00fbcient  as the  adjacency-matrix  representation,  adjacen cy matrices are simpler, \nand so you might prefer them when graphs are reason ably small. Moreover,  adja-  \ncency matrices carry a further advantage for unweig hted graphs: they require only \none bit per entry. \nRepresenting  attributes  \nMost algorithms that operate on graphs need to main tain attributes for vertices \nand/or edges. We indicate these attributes using ou r usual notation, such as v: d \nfor an attribute d of a vertex v. When we indicate edges as pairs of vertices, we \nuse the same style of notation. For example, if edg es have an attribute f , then we \ndenote this attribute for edge .u;v/  by .u;v/:  f . For the purpose of presenting and \nunderstanding  algorithms,  our  attribute  notation  suf\u00fbces . \nImplementing vertex and edge attributes in real pro grams can be another story \nentirely. There is no one best way to store and acc ess vertex and edge attributes. \nFor a given situation, your decision will likely de pend on the programming  lan-  \nguage you are using, the algorithm you are implemen ting, and how the rest of \nyour program uses the graph. If you represent a gra ph using adjacency lists, \none design choice is to represent vertex attributes  in additional arrays, such as \nan array d\u01521  W jV j\ufffd that parallels the Adj array. If the vertices adjacent to u belong \nto Adj\u0152u\ufffd, then the attribute u: d can actually be stored in the array entry d \u0152u\ufffd. Many \nother ways of implementing attributes are possible.  For example,  in an object-  \noriented programming language, vertex attributes mi ght be represented as instance \nvariables within a subclass of a Vertex  class. \nExercises  \n20.1-1  \nGiven  an adjacency-list  representation  of a directed  graph , how long does it take \nto compute  the  out-degree  of every  vertex?  How  long  does  it take to compute the \nin-degrees?  \n20.1-2  \nGive  an adjacency-list  representation  for  a complete  binar y tree on 7 vertices.  Give  \nan equivalent  adjacency-matrix  representation.  Assume  that  the  edges  are  undi-  \nrected and that the vertices are numbered from 1 to 7 as in a binary heap. 20.1 Representations of graphs 553 \n20.1-3  \nThe transpose  of a directed graph G D .V;E/  is the graph G T D .V;E  T /, where \nE T D f.v;u/  2 V \ue005 V W .u;v/  2 Eg. That is, G T is G with all its edges reversed. \nDescribe  ef\u00fbcient  algorithms  for  computing  G T from G, for  both  the  adjacency-  \nlist  and  adjacency-matrix  representations  of G. Analyze the running times of your \nalgorithms. \n20.1-4  \nGiven  an adjacency-list  representation  of a multigraph  G D .V;E/ , describe an \nO.V  C E/-time  algorithm  to compute  the  adjacency-list  representat ion of the \n<equivalent= undirected graph G 0 D .V;E  0 /, where E 0 consists of the edges in E \nwith all multiple edges between two vertices replac ed by a single edge and with all \nself-loops  removed.  \n20.1-5  \nThe square  of a directed graph G D .V;E/  is the graph G 2 D .V;E  2 / such that \n.u;v/  2 E 2 if and only if G contains a path with at most two edges between \nu and v. Describe  ef\u00fbcient  algorithms  for  computing  G 2 from G for both the \nadjacency-list  and  adjacency-matrix  representations  of G. Analyze the running \ntimes of your algorithms. \n20.1-6  \nMost  graph  algorithms  that  take  an adjacency-matrix  representation  as input  re-  \nquire \ufffd.V  2 / time, but there are some exceptions. Show how to de termine whether \na directed graph G contains a universal  sink4a  vertex  with  in-degree  jV j \ue003  1 and \nout-degree  04in  O.V/  time, given an adjacency matrix for G. \n20.1-7  \nThe incidence  matrix  of a directed graph G D .V;E/  with  no  self-loops  is a \njV j \ue005 jEj matrix B D .b ij / such that \nb ij D \u0128 \n\ue0031 if edge j leaves vertex i;  \n1 if edge j enters vertex i;  \n0 otherwise : \nDescribe what the entries of the matrix product BB  T represent, where B T is the \ntranspose of B . \n20.1-8  \nSuppose that instead of a linked list, each array e ntry Adj\u0152u\ufffd  is a hash  table  contain-  \ning the vertices v for which .u;v/  2 E, with  collisions  resolved  by  chaining.  Un-  \nder the assumption of uniform independent hashing, if all edge lookups are equally \nlikely, what is the expected time to determine whet her an edge is in the  graph?  554  Chapter  20  Elementary  Graph  Algorithms  \nWhat  disadvantages  does  this  scheme  have?  Suggest  an altern ate data structure for \neach edge list that solves these problems. Does you r alternative have disadvantages \ncompared  with  the  hash  table?  \n20.2  Breadth-\ufb01rst  search  \nBreadth-\u00fbrst  search  is one of the simplest algorithms for searching a g raph and \nthe  archetype  for  many  important  graph  algorithms.  Prim\u2019s  minimum-spanning-  \ntree  algorithm  (Section  21.2)  and  Dijkstra\u2019s  single-source  shortest-paths  algorithm  \n(Section  22.3)  use  ideas  similar  to those  in breadth-\u00fbrst  search. \nGiven  a graph  G D .V;E/  and a distinguished source  vertex s , breadth-\u00fbrst  \nsearch systematically explores the edges of G to <discover= every vertex that is \nreachable from s . It computes the distance from s to each reachable vertex, where \nthe distance to a vertex v equals the smallest number of edges needed to go fr om s \nto v. Breadth-\u00fbrst  search  also  produces  a <breadth-\u00fbrst  tree=  with root s that  con-  \ntains all reachable vertices. For any vertex v reachable from s , the simple path in \nthe  breadth-\u00fbrst  tree  from  s to v corresponds to a shortest path from s to v in G, \nthat is, a path containing the smallest number of e dges. The algorithm works on \nboth directed and undirected graphs. \nBreadth-\u00fbrst  search  is so named  because  it expands  the  frontier  between  discov-  \nered and undiscovered vertices uniformly across the  breadth of the frontier. You \ncan think of it as discovering vertices in waves em anating from the source vertex. \nThat is, starting from s , the  algorithm  \u00fbrst  discovers  all  neighbors  of s , which have \ndistance 1. Then it discovers all vertices with distance 2, then all vertices with \ndistance 3, and so on, until it has discovered every vertex r eachable from s . \nIn order  to keep  track  of the  waves  of vertices,  breadth-\u00fbrst  search  could  main-  \ntain separate arrays or lists of the vertices at ea ch distance from the source vertex. \nInstead,  it uses  a single  \u00fbrst-in,  \u00fbrst-out  queue  (see  Section  10.1.3)  containing  some  \nvertices at a distance k, possibly followed by some vertices at distance k C 1. The \nqueue, therefore, contains portions of two consecut ive waves at any time. \nTo  keep  track  of progress,  breadth-\u00fbrst  search  colors  each  vertex white, gray, \nor black. All vertices start out white, and vertice s not reachable from the source \nvertex s stay white the entire time. A vertex that is reacha ble from s is discovered  \nthe  \u00fbrst  time  it is encountered  during  the  search,  at which  time  it becomes  gray,  in-  \ndicating that is now on the frontier of the search:  the boundary between discovered \nand undiscovered vertices. The queue contains all t he gray vertices. Eventually, \nall the edges of a gray vertex will be explored, so  that all of its neighbors will be 20.2  Breadth-\ufb01rst  search  555 \ndiscovered.  Once  all  of a vertex\u2019s  edges  have  been  explored,  the vertex is behind \nthe frontier of the search, and it goes from gray t o black. 1 \nBreadth-\u00fbrst  search  constructs  a breadth-\u00fbrst  tree,  initially containing only its \nroot, which is the source vertex s . Whenever the search discovers a white vertex v \nin the course of scanning the adjacency list of a g ray vertex u, the vertex v and \nthe edge .u;v/  are added to the tree. We say that u is the predecessor  or parent  \nof v in the  breadth-\u00fbrst  tree.  Since  every  vertex  reachable  from  s is discovered \nat most once, each vertex reachable from s has exactly one parent. (There is one \nexception: because s is the  root  of the  breadth-\u00fbrst  tree,  it has  no  parent.)  Ances tor \nand  descendant  relationships  in the  breadth-\u00fbrst  tree  are  de\u00fbned  relative  to the  \nroot s as usual: if u is on the simple path in the tree from the root s to vertex v, \nthen u is an ancestor of v and v is a descendant of u. \nThe  breadth-\u00fbrst-search  procedure  BFS  on  the  following  page assumes that the \ngraph G D .V;E/  is represented using adjacency lists. It denotes th e queue by Q, \nand it attaches three additional attributes to each  vertex v in the graph: \n\ue001 v: color  is the color of v: WHITE , GRAY , or BLACK . \n\ue001 v: d holds the distance from the source vertex s to v, as computed  by  the  algo-  \nrithm. \n\ue001 v:\ufffd  is v\u2019s predecessor  in the  breadth-\u00fbrst  tree.  If v has no predecessor because \nit is the source vertex or is undiscovered, then v:\ufffd  D NIL. \nFigure  20.3  illustrates  the  progress  of BFS  on  an undirected  graph. \nThe procedure BFS works as follows. With the except ion of the source vertex s , \nlines  134  paint  every  vertex  white,  set  u: d D 1  for each vertex u, and set the \nparent of every vertex to be NIL. Because the source vertex s is always  the  \u00fbrst  \nvertex  discovered,  lines  537  paint  s gray, set s: d to 0, and set the predecessor of s \nto NIL. Lines  839  create  the  queue  Q, initially containing just the source vertex. \nThe while  loop  of lines  10318  iterates  as long  as there  remain  gray  vertices, \nwhich are on the frontier: discovered vertices that  have not yet had their adjacency \nlists fully examined. This while  loop maintains the following invariant: \nAt  the  test  in line  10,  the  queue  Q consists of the set of gray vertices. \nAlthough  we  won\u2019t  use  this  loop  invariant  to prove  correctne ss, it is easy to see \nthat  it holds  prior  to the  \u00fbrst  iteration  and  that  each  iterat ion of the loop maintains \nthe  invariant.  Prior  to the  \u00fbrst  iteration,  the  only  gray  vertex, and the only vertex \n1 We distinguish between gray and black vertices to h elp us understand  how  breadth-\u00fbrst  search  \noperates.  In fact,  as Exercise  20.2-3  shows,  we  get  the  same  result even if we do not distinguish \nbetween gray and black vertices. 556  Chapter  20  Elementary  Graph  Algorithms  \nBFS.G;s/  \n1 for  each vertex u 2 G:  V \ue003 fs g \n2 u: color  D WHITE \n3 u: d D 1  \n4 u:\ufffd  D NIL \n5 s: color  D GRAY  \n6 s: d D 0 \n7 s:\ufffd  D NIL \n8 Q D ;  \n9 ENQUEUE.Q;s/  \n10  while  Q \u00a4 ;  \n11  u D DEQUEUE.Q/  \n12  for  each vertex v in G:  Adj\u0152u\ufffd  / / search the neighbors of u \n13  if v: color  = = WHITE / / is v being  discovered  now?  \n14  v: color  D GRAY  \n15  v: d D u: d C 1 \n16  v:\ufffd  D u \n17  ENQUEUE.Q;v/  / / v is now on the frontier \n18  u: color  D BLACK  / / u is now behind the frontier \nin Q, is the source vertex s . Line  11  determines  the  gray  vertex  u at the head of \nthe queue Q and removes it from Q. The for  loop  of lines  12317  considers  each  \nvertex v in the adjacency list of u. If v is white, then it has not yet been discovered, \nand  the  procedure  discovers  it by  executing  lines  14317.  These lines paint vertex v \ngray, set v\u2019s distance  v: d to u: d C 1, record u as v\u2019s parent  v:\ufffd  , and place v at \nthe tail of the queue Q. Once  the  procedure  has  examined  all  the  vertices  on  u\u2019s \nadjacency list, it blackens u in line  18,  indicating  that  u is now behind the frontier. \nThe loop invariant is maintained because whenever a  vertex is painted gray (in \nline  14)  it is also  enqueued  (in  line  17),  and  whenever  a verte x is dequeued (in \nline  11)  it is also  painted  black  (in  line  18).  \nThe  results  of breadth-\u00fbrst  search  may  depend  upon  the  order  in which  the  neigh-  \nbors  of a given  vertex  are  visited  in line  12:  the  breadth-\u00fbrs t tree may vary, but the \ndistances d computed  by  the  algorithm  do  not.  (See  Exercise  20.2-5.)  \nA simple change allows the BFS procedure to termina te in many cases before \nthe queue Q becomes empty. Because each vertex is discovered at  most once and \nreceives  a \u00fbnite  d value only when it is discovered, the algorithm can  terminate \nonce  every  vertex  has  a \u00fbnite  d value. If BFS keeps count of how many vertices \nhave been discovered, it can terminate once either the queue Q is empty or all jV j \nvertices are discovered. 20.2  Breadth-\ufb01rst  search  557 \nr \ns \nt \nu w x \ny 0 \u221e \n\u221e \n\u221e \u221e \u221e \u221e \n\u221e \ns \n0 Q (a) z \u221e r \ns \nt \nu w x \ny 1 \n\u221e \n1 \u221e \u221e \u221e \n1 \nr \n1 Q (b) z \u221e \nu \n1 1 r \ns \nt \nu w x \ny 0 1 \n2 \n1 \u221e \u221e 2 \n1 \nQ (c) z \u221e \nu \n1 1 t \n2 w \n2 \nr \ns \nt \nu w x \ny 0 1 \n2 \n1 2 \u221e 2 \n1 \nQ (d) z \u221e \n1 t \n2 w \n2 y \n2 r \ns \nt \nu w x \ny 0 1 \n2 \n1 2 \u221e 2 \n1 \nQ (e) z \u221e \nt \n2 w \n2 y \n2 r \ns \nt u w x \ny 0 1 \n2 \n1 2 \u221e 2 \n1 \nQ (f) z \u221e \nw \n2 y \n2 \nr \ns \nt \nu w x \ny 0 1 \n2 \n1 2 3 2 \n1 \nQ (g) z 3 \ny \n2 x \n3 z \n3 r \ns \nt \nu w x \ny 0 1 \n2 \n1 2 3 2 \n1 \nQ (h) z 3 \nx \n3 z \n3 r \ns \nt \nu w x \ny 0 1 \n2 \n1 2 3 2 \n1 \nQ (i) z 3 \nz \n3 \nr \ns \nt \nu w x \ny 0 1 \n2 \n1 2 3 2 \n1 \nQ (j) z 3 0 \n; v v v v v v \nv v v v \nv v v \nFigure  20.3  The operation of BFS on an undirected graph. Each p art shows the graph and the \nqueue Q at the beginning of each iteration of the while  loop  of lines  10318.  Vertex  distances  appear  \nwithin each vertex and below vertices in the queue.  The tan region surrounds the frontier of the \nsearch, consisting of the vertices in the queue. Th e light blue region surrounds the vertices behind \nthe frontier, which have been dequeued. Each part h ighlights in orange the vertex dequeued and the \nbreadth-\u00fbrst  tree  edges  added,  if any,  in the  previous  iteration.  Blue  edges  belong  to the  breadth-\u00fbrst  \ntree constructed so far. 558  Chapter  20  Elementary  Graph  Algorithms  \nAnalysis  \nBefore  proving  the  various  properties  of breadth-\u00fbrst  search,  let\u2019s  take  on  the  easier  \njob of analyzing its running time on an input graph  G D .V;E/ . We use aggregate \nanalysis,  as we  saw  in Section  16.1.  After  initialization,  breadth-\u00fbrst  search  never  \nwhitens  a vertex,  and  thus  the  test  in line  13  ensures  that  each vertex is enqueued \nat most once, and hence dequeued at most once. The operations of enqueuing \nand dequeuing take O.1/  time, and so the total time devoted to queue operat ions \nis O.V/ . Because the procedure scans the adjacency list of  each vertex only when \nthe vertex is dequeued, it scans each adjacency lis t at most once. Since the sum \nof the lengths of all jV j adjacency lists is \u201a.E/ , the total time spent in scanning \nadjacency lists is O.V  C E/. The overhead for initialization is O.V/ , and thus the \ntotal running time of the BFS procedure is O.V  C E/. Thus,  breadth-\u00fbrst  search  \nruns  in time  linear  in the  size  of the  adjacency-list  represe ntation of G. \nShortest  paths  \nNow,  let\u2019s  see  why  breadth-\u00fbrst  search  \u00fbnds  the  shortest  distance from a given \nsource vertex s to each  vertex  in a graph.  De\u00fbne  the  shortest-path  distance  \u0131.s;v/  \nfrom s to v as the minimum number of edges in any path from ver tex s to vertex v. \nIf there is no path from s to v, then \u0131.s;v/  D 1 . We call a path of length \u0131.s;v/  \nfrom s to v a shortest  path  2 from s to v. Before  showing  that  breadth-\u00fbrst  search  \ncorrectly  computes  shortest-path  distances,  we  investiga te an important property \nof shortest-path  distances.  \nLemma  20.1  \nLet G D .V;E/  be a directed or undirected graph, and let s 2 V be an arbitrary \nvertex. Then, for any edge .u;v/  2 E, \n\u0131.s;v/  \u0dc4 \u0131.s;u/  C 1:  \nProof  If u is reachable from s , then so is v. In this case, the shortest path from s \nto v cannot be longer than the shortest path from s to u followed by the edge .u;v/ , \nand thus the inequality holds. If u is not reachable from s , then \u0131.s;u/  D 1 , and \nagain, the inequality holds. \nOur  goal  is to show  that  the  BFS  procedure  properly  computes  v: d D \u0131.s;v/  \nfor each vertex v 2 V . We  \u00fbrst  show  that  v: d bounds \u0131.s;v/  from above. \n2 Chapters  22  and  23  generalize  shortest  paths  to weighted  graphs,  in which  every  edge  has  a real-  \nvalued weight and the weight of a path is the sum o f the weights of its constituent edges. The graphs \nconsidered in the present chapter are unweighted or , equivalently, all edges have unit weight. 20.2  Breadth-\ufb01rst  search  559 \nLemma  20.2  \nLet G D .V;E/  be a directed or undirected graph, and suppose that  BFS is run \non G from a given source vertex s 2 V . Then, for each vertex v 2 V , the value v: d \ncomputed  by  BFS  satis\u00fbes  v: d \ue004 \u0131.s;v/  at all times, including at termination. \nProof  The  lemma  is true  intuitively,  because  any  \u00fbnite  value  assig ned to v: d \nequals the number of edges on some path from s to v. The formal proof is by \ninduction on the number of E NQUEUE  operations. The inductive hypothesis is that \nv: d \ue004 \u0131.s;v/  for all v 2 V . \nThe base case of the induction is the situation imm ediately after enqueuing s in \nline 9 of BFS. The inductive hypothesis holds here,  because s: d D 0 D \u0131.s;s/  \nand v: d D 1 \ue004  \u0131.s;v/  for all v 2 V \ue003 fs g. \nFor the inductive step, consider a white vertex v that is discovered during the \nsearch from a vertex u. The inductive hypothesis implies that u: d \ue004 \u0131.s;u/ . The \nassignment  performed  by  line  15  and  Lemma  20.1  give  \nv: d D u: d C 1 \n\ue004 \u0131.s;u/  C 1 \n\ue004 \u0131.s;v/:  \nVertex v is then enqueued, and it is never enqueued again be cause it is also grayed \nand  lines  14317  execute  only  for  white  vertices.  Thus,  the  value of v: d never \nchanges again, and the inductive hypothesis is main tained. \nTo prove that v: d D \u0131.s;v/, we  \u00fbrst  show  more  precisely  how  the  queue  Q \noperates during the course of BFS. The next lemma s hows that at all times, \nthe d values of vertices in the queue either are all the same or form a sequence \nhk;k;:::;k;k  C 1;k  C 1;:::;k  C 1i for some integer k \ue004 0. \nLemma  20.3  \nSuppose that during the execution of BFS on a graph  G D .V;E/ , the queue Q \ncontains the vertices hv 1 ;v  2 ;:::;v  r i, where v 1 is the head of Q and v r is the tail. \nThen, v r : d \u0dc4 v 1 : d C 1 and v i : d \u0dc4 v i C1 : d for i D 1;2;:::;r  \ue003 1. \nProof  The proof is by induction on the number of queue op erations. Initially, \nwhen the queue contains only s , the lemma trivially holds. \nFor the inductive step, we must prove that the lemm a holds after both dequeuing \nand enqueuing a vertex. First, we examine dequeuing . When the head v 1 of the \nqueue is dequeued, v 2 becomes the new head. (If the queue becomes empty, then \nthe lemma holds vacuously.) By the inductive hypoth esis, v 1 : d \u0dc4 v 2 : d. But then \nwe have v r : d \u0dc4 v 1 : d C1 \u0dc4 v 2 : d C1, and the remaining inequalities are unaffected. \nThus, the lemma follows with v 2 as the new head. 560  Chapter  20  Elementary  Graph  Algorithms  \nNow,  we  examine  enqueuing.  When  line  17  of BFS  enqueues  a vertex v onto \na queue containing vertices hv 1 ;v  2 ;:::;v  r i, the enqueued vertex becomes v r C1 . \nIf the queue was empty before v was enqueued, then after enqueuing v, we have \nr D 1 and the lemma trivially holds. Now suppose that the  queue was nonempty \nwhen v was enqueued. At that time, the procedure has most recently removed \nvertex u, whose adjacency list is currently being scanned, from the queue Q. Just  \nbefore u was removed, we had u D v 1 and the inductive hypothesis held, so that \nu: d \u0dc4 v 2 : d and v r : d \u0dc4 u: d C 1. After u is removed from the queue, the vertex \nthat had been v 2 becomes the new head v 1 of the queue, so that now u: d \u0dc4 v 1 : d. \nThus, v r C1 : d D v: d D u: d C 1 \u0dc4 v 1 : d C 1. Since v r : d \u0dc4 u: d C 1, we have \nv r : d \u0dc4 u: d C 1 D v: d D v r C1 : d, and the remaining inequalities are unaffected. \nThus, the lemma follows when v is enqueued. \nThe following corollary shows that the d values at the time that vertices are \nenqueued monotonically increase over time. \nCorollary  20.4  \nSuppose that vertices v i and v j are enqueued during the execution of BFS, and \nthat v i is enqueued before v j . Then v i : d \u0dc4 v j : d at the time that v j is enqueued. \nProof  Immediate  from  Lemma  20.3  and  the  property  that  each  vertex  receives a \n\u00fbnite  d value at most once during the course of BFS. \nWe  can  now  prove  that  breadth-\u00fbrst  search  correctly  \u00fbnds  shortest-path  dis-  \ntances. \nTheorem  20.5  (Correctness  of breadth-\u00fbrst  search)  \nLet G D .V;E/  be a directed or undirected graph, and suppose that  BFS is run \non G from a given source vertex s 2 V . Then, during its execution, BFS discovers \nevery vertex v 2 V that is reachable from the source s , and upon termination, \nv: d D \u0131.s;v/  for all v 2 V . Moreover, for any vertex v \u00a4 s that is reachable \nfrom s , one of the shortest paths from s to v is a shortest path from s to v:\ufffd  \nfollowed by the edge .v:\ufffd; v/ . \nProof  Assume for the purpose of contradiction that some v ertex receives a d \nvalue  not  equal  to its  shortest-path  distance.  Of  all  such  vertices, let v be a vertex \nthat has the minimum \u0131.s;v/ . By Lemma 20.2, we have v: d \ue004 \u0131.s;v/ , and thus \nv: d >\u0131.s;v/ . We cannot have v D s , because s: d D 0 and \u0131.s;s/  D 0. Vertex v \nmust be reachable from s , for otherwise we would have \u0131.s;v/  D 1 \ue004  v: d. Let \nu be the vertex immediately preceding v on some shortest path from s to v (since \nv \u00a4 s , vertex u must exist), so that \u0131.s;v/  D \u0131.s;u/ C1. Because \u0131.s;u/<\u0131.s;v/ , 20.2  Breadth-\ufb01rst  search  561 \nand because of how we chose v, we have u: d D \u0131.s;u/ . Putting these properties \ntogether gives \nv: d >\u0131.s;v/  D \u0131.s;u/  C 1 D u: d C 1:  (20.1)  \nNow consider the time when BFS chooses to dequeue v ertex u from Q in \nline  11.  At  this  time,  vertex  v is either white, gray, or black. We shall show \nthat each of these cases leads to a contradiction o f inequality (20.1).  If v is white, \nthen  line  15  sets  v: d D u: d C 1, contradicting  inequality  (20.1).  If v is black, \nthen it was already removed from the queue and, by Corollary 20.4,  we  have  \nv: d \u0dc4 u: d, again  contradicting  inequality  (20.1).  If v is gray, then it was painted \ngray upon dequeuing some vertex w, which was removed from Q earlier than u \nand for which v: d D w:  d C 1. By  Corollary  20.4,  however,  w:  d \u0dc4 u: d, and so \nv: d D w:  d C 1 \u0dc4 u: d C 1, once  again  contradicting  inequality  (20.1).  \nThus we conclude that v: d D \u0131.s;v/  for all v 2 V . All vertices v reachable \nfrom s must be discovered, for otherwise they would have 1 D  v: d >\u0131.s;v/ . To \nconclude  the  proof  of the  theorem,  observe  from  lines  15316  that if v:\ufffd  D u, then \nv: d D u: d C 1. Thus, to form a shortest path from s to v, take a shortest path \nfrom s to v:\ufffd  and then traverse the edge .v:\ufffd; v/ . \nBreadth-\ufb01rst  trees  \nThe  blue  edges  in Figure  20.3  show  the  breadth-\u00fbrst  tree  built  by  the  BFS  pro-  \ncedure as it searches the graph. The tree correspon ds to the \ufffd attributes. More \nformally, for a graph G D .V;E/  with source s , we  de\u00fbne  the  predecessor  sub-  \ngraph  of G as G \ue003 D .V  \ue003 ;E  \ue003 /, where \nV \ue003 D fv 2 V W v:\ufffd  \u00a4 NILg [ fs g (20.2) \nand \nE \ue003 D f.v:\ufffd; v/  W v 2 V \ue003 \ue003 fs gg : (20.3)  \nThe predecessor subgraph G \ue003 is a breadth-\u00fbrst  tree  if V \ue003 consists of the vertices \nreachable from s and, for all v 2 V \ue003 , the subgraph G \ue003 contains a unique simple \npath from s to v that is also a shortest path from s to v in G. A breadth-\u00fbrst  tree  \nis in fact a tree, since it is connected and jE \ue003 j D jV \ue003 j \ue003  1 (see Theorem B.2 on \npage  1169).  We  call  the  edges  in E \ue003 tree  edges . \nThe following lemma shows that the predecessor subg raph produced by the BFS \nprocedure  is a breadth-\u00fbrst  tree.  \nLemma  20.6  \nWhen applied to a directed or undirected graph G D .V;E/, procedure  BFS  con-  \nstructs \ufffd so that the predecessor subgraph G \ue003 D .V  \ue003 ;E  \ue003 / is a breadth-\u00fbrst  tree.  562  Chapter  20  Elementary  Graph  Algorithms  \nProof  Line  16  of BFS  sets  v:\ufffd  D u if and only if .u;v/  2 E and \u0131.s;v/<  14  \nthat is, if v is reachable from s 4and  thus  V \ue003 consists of the vertices in V reach-  \nable from s . Since the predecessor subgraph G \ue003 forms a tree, by Theorem B.2, it \ncontains a unique simple path from s to each vertex in V \ue003 . Applying  Theorem  20.5  \ninductively yields that every such path is a shorte st path in G. \nThe P RINT-PATH procedure prints out the vertices on a shortest pat h from s to v, \nassuming  that  BFS  has  already  computed  a breadth-\u00fbrst  tree.  This procedure runs \nin time linear in the number of vertices in the pat h printed, since each recursive call \nis for a path one vertex shorter. \nPRINT-PATH.G;s;v/  \n1 if v == s \n2 print s \n3 elseif  v:\ufffd  = = NIL \n4 print <no path from= s <to= v <exists= \n5 else  PRINT-PATH.G; s; v:\ufffd/  \n6 print v \nExercises  \n20.2-1  \nShow the d and \ufffd values  that  result  from  running  breadth-\u00fbrst  search  on  the  di-  \nrected graph of Figure 20.2(a), using vertex 3 as the source. \n20.2-2  \nShow the d and \ufffd values  that  result  from  running  breadth-\u00fbrst  search  on  the  undi-  \nrected  graph  of Figure  20.3,  using  vertex  u as the source. Assume that neighbors \nof a vertex are visited in alphabetical order. \n20.2-3  \nShow  that  using  a single  bit  to store  each  vertex  color  suf\u00fbce s by arguing that the \nBFS  procedure  produces  the  same  result  if line  18  is removed.  Then show how to \nobviate the need for vertex colors altogether. \n20.2-4  \nWhat is the running time of BFS if we represent its  input graph by an adjacency \nmatrix  and  modify  the  algorithm  to handle  this  form  of input?  20.3  Depth-\ufb01rst  search  563 \n20.2-5  \nArgue  that  in a breadth-\u00fbrst  search,  the  value  u: d assigned to a vertex u is inde-  \npendent of the order in which the vertices appear i n each adjacency list. Using \nFigure  20.3  as an example,  show  that  the  breadth-\u00fbrst  tree  computed by BFS can \ndepend on the ordering within adjacency lists. \n20.2-6  \nGive  an example  of a directed  graph  G D .V;E/ , a source vertex s 2 V , and a \nset of tree edges E \ue003 \u0dc2 E such that for each vertex v 2 V , the unique simple path \nin the graph .V;E  \ue003 / from s to v is a shortest path in G, yet the set of edges E \ue003 \ncannot be produced by running BFS on G, no matter how the vertices are ordered \nin each adjacency list. \n20.2-7  \nThere are two types of professional wrestlers: <fac es= (short for <babyfaces,= \ni.e., <good guys=) and <heels= (<bad guys=). Betwee n any pair of professional \nwrestlers, there may or may not be a rivalry. You a re given the names of n profes-  \nsional wrestlers and a list of r pairs  of wrestlers  for  which  there  are  rivalries.  Give  \nan O.n  C r/-time  algorithm  that  determines  whether  it is possible  to designate \nsome of the wrestlers as faces and the remainder as  heels such that each rivalry \nis between a face and a heel. If it is possible to perform such a designation, your \nalgorithm should produce it. \n? 20.2-8  \nThe diameter  of a tree T D .V;E/  is de\u00fbned  as max  f\u0131.u;v/  W u;v  2 V g, that is, \nthe  largest  of all  shortest-path  distances  in the  tree.  Give  an ef\u00fbcient  algorithm  to \ncompute the diameter of a tree, and analyze the run ning time of your algorithm. \n20.3  Depth-\ufb01rst  search  \nAs  its  name  implies,  depth-\u00fbrst  search  searches  <deeper=  in the graph whenever \npossible.  Depth-\u00fbrst  search  explores  edges  out  of the  most  recently discovered \nvertex v that  still  has  unexplored  edges  leaving  it. Once  all  of v\u2019s edges  have  been  \nexplored, the search <backtracks= to explore edges leaving the vertex from which v \nwas discovered. This process continues until all ve rtices that are reachable from the \noriginal source vertex have been discovered. If any  undiscovered vertices remain, \nthen  depth-\u00fbrst  search  selects  one  of them  as a new  source,  repeating the search 564  Chapter  20  Elementary  Graph  Algorithms  \nfrom that source. The algorithm repeats this entire  process until it has discovered \nevery vertex. 3 \nAs  in breadth-\u00fbrst  search,  whenever  depth-\u00fbrst  search  discovers a vertex v dur-  \ning a scan of the adjacency list of an already disc overed vertex u, it records this \nevent by setting v\u2019s predecessor  attribute  v:\ufffd  to u. Unlike  breadth-\u00fbrst  search,  \nwhose  predecessor  subgraph  forms  a tree,  depth-\u00fbrst  search  produces  a predeces-  \nsor subgraph that might contain several trees, beca use the search may repeat from \nmultiple  sources.  Therefore,  we  de\u00fbne  the  predecessor  subgraph  of a depth-\u00fbrst  \nsearch  slightly  differently  from  that  of a breadth-\u00fbrst  search: it always includes all \nvertices,  and  it accounts  for  multiple  sources.  Speci\u00fbcally,  for  a depth-\u00fbrst  search  \nthe predecessor subgraph is G \ue003 D .V;E  \ue003 /, where \nE \ue003 D f.v:\ufffd; v/  W v 2 V and v:\ufffd  \u00a4 NILg : \nThe  predecessor  subgraph  of a depth-\u00fbrst  search  forms  a depth-\u00fbrst  forest  com-  \nprising several depth-\u00fbrst  trees . The edges in E \ue003 are tree  edges . \nLike  breadth-\u00fbrst  search,  depth-\u00fbrst  search  colors  vertic es during the search to \nindicate their state. Each vertex is initially whit e, is grayed when it is discovered  \nin the search, and is blackened when it is \u00fbnished , that is, when its adjacency list \nhas been examined completely. This technique guaran tees that each vertex ends up \nin exactly  one  depth-\u00fbrst  tree,  so that  these  trees  are  disjo int. \nBesides  creating  a depth-\u00fbrst  forest,  depth-\u00fbrst  search  also timestamps  each  ver-  \ntex. Each vertex v has  two  timestamps:  the  \u00fbrst  timestamp  v: d records when v \nis \u00fbrst  discovered  (and  grayed),  and  the  second  timestamp  v: f records when the \nsearch  \u00fbnishes  examining  v\u2019s adjacency  list  (and  blackens  v). These timestamps \nprovide important information about the structure o f the graph and are generally \nhelpful  in reasoning  about  the  behavior  of depth-\u00fbrst  searc h. \nThe procedure DFS on the facing page records when i t discovers vertex u in \nthe attribute u: d and  when  it \u00fbnishes  vertex  u in the attribute u: f . These  time-  \nstamps are integers between 1 and 2 jV j, since there is one discovery event and one \n\u00fbnishing  event  for  each  of the  jV j vertices. For every vertex u, \nu: d <u:  f : (20.4)  \nVertex u is WHITE before time u: d, GRAY  between time u: d and time u: f , and \nBLACK  thereafter. In the DFS procedure, the input graph G may be undirected or \n3 It may  seem  arbitrary  that  breadth-\u00fbrst  search  is limited  to only  one  source  whereas  depth-\u00fbrst  \nsearch may search from multiple sources. Although c onceptually,  breadth-\u00fbrst  search  could  proceed  \nfrom  multiple  sources  and  depth-\u00fbrst  search  could  be limited  to one  source,  our  approach  re\u00fcects  how  \nthe  results  of these  searches  are  typically  used.  Breadth-\u00fbrst  search  usually  serves  to \u00fbnd  shortest-  \npath distances and the associated predecessor subgr aph from a given  source.  Depth-\u00fbrst  search  is \noften  a subroutine  in another  algorithm,  as we\u2019ll  see  later  in this chapter. 20.3  Depth-\ufb01rst  search  565 \ndirected. The variable time is a global  variable  used  for  timestamping.  Figure  20.4  \nillustrates the progress of DFS on the graph shown in Figure 20.2 (but with vertices \nlabeled by letters rather than numbers). \nDFS.G/  \n1 for  each vertex u 2 G:  V \n2 u: color  D WHITE \n3 u:\ufffd  D NIL \n4 time D 0 \n5 for  each vertex u 2 G:  V \n6 if u: color  == WHITE \n7 DFS-V ISIT .G;u/  \nDFS-V ISIT .G;u/  \n1 time D time C 1 / / white vertex u has just been discovered \n2 u: d D time \n3 u: color  D GRAY  \n4 for  each vertex v in G:  Adj\u0152u\ufffd  / / explore each edge .u;v/  \n5 if v: color  == WHITE \n6 v:\ufffd  D u \n7 DFS-V ISIT .G;v/  \n8 time D time C 1 \n9 u: f D time \n10  u: color  D BLACK  / / blacken u; it is \u00fbnished  \nThe  DFS  procedure  works  as follows.  Lines  133  paint  all  vertices white and \ninitialize their \ufffd attributes to NIL. Line  4 resets  the  global  time  counter.  Lines  537  \ncheck each vertex in V in turn and, when a white vertex is found, visit it  by calling \nDFS-V ISIT. Upon  every  call  of DFS-V ISIT .G;u/  in line  7, vertex  u becomes the \nroot  of a new  tree  in the  depth-\u00fbrst  forest.  When  DFS  returns,  every vertex u has \nbeen assigned a discovery  time  u: d and a \u00fbnish  time  u: f . \nIn each  call  DFS-V ISIT .G;u/ , vertex u is initially  white.  Lines  133  increment  \nthe global variable time, record the new value of time as the discovery time u: d, \nand paint u gray.  Lines  437  examine  each  vertex  v adjacent to u and recursively \nvisit v if it is white.  As  line  4 considers  each  vertex  v 2 Adj\u0152u\ufffd, the  depth-\u00fbrst  \nsearch explores  edge .u;v/ . Finally, after every edge leaving u has been explored, \nlines  8310  increment  time, record  the  \u00fbnish  time  in u: f , and paint u black. \nThe  results  of depth-\u00fbrst  search  may  depend  upon  the  order  in which  line  5 \nof DFS  examines  the  vertices  and  upon  the  order  in which  line  4 of DFS-V ISIT \nvisits the neighbors of a vertex. These different v isitation orders tend not to cause 566  Chapter  20  Elementary  Graph  Algorithms  \nu w \nx y z 1/ 1/ 2/ 1/ 2/ \n3/ 1/ 2/ \n3/ 4/ \n1/ 2/ \n3/ 4/ B 1/ 2/ \n3/ B \n4/5  1/ 2/ \nB \n4/5  3/6  1/ \nB \n4/5  3/6  2/7  \n1/ \nB \n4/5  3/6  2/7  \nF B \n4/5  3/6  2/7  \nF 1/8  \nB \n4/5  3/6  2/7  \nF 1/8  9/ \nB \n4/5  3/6  2/7  \nF 1/8  9/ \nC \nB \n4/5  3/6  2/7  \nF 1/8  9/ \nC B \n4/5  3/6  2/7  \nF 1/8  9/ \nC \nB B \n4/5  3/6  2/7  \nF 1/8  9/ \nC B \n4/5  3/6  2/7  \nF 1/8  \nC \nB \n10/11  9/12  u w \nx y z u w \nx y z u w \nx y z \nu w \nx y z u w \nx y z u w \nx y z u w \nx y z \nu w \nx y z u w \nx y z u w \nx y z u w \nx y z \nu w \nx y z u w \nx y z u w \nx y u w \nx y \n(m) (n) (o) (p) (i) (j) (k) (l) (e) (f) (g) (h) (a) (b) (c) (d) \n10/  10/  10/11  \nz B T T T \nT T T \nT T T \nT T T T \nT \nT T \nT T \nT \nT T \nT \nT T \nT \nT T T T \nT T T T \nT T T T \nT T T T T \nT T T T \nz v v v v v v v v v v v v v v v v \nFigure  20.4  The  progress  of the  depth-\u00fbrst-search  algorithm  DFS  on  a directed graph. Edges are \nclassi\u00fbed  as they  are  explored:  tree  edges  are  labeled  T, back edges B, forward edges F, and cross \nedges C. Timestamps within vertices indicate discov ery time/\u00fbnish  times.  Tree  edges  are  highlighted  \nin blue.  Orange  highlights  indicate  vertices  whose  discovery  or \u00fbnish  times  change  and  edges  that  \nare explored in each step. \nproblems  in practice,  because  many  applications  of depth-\u00fb rst search can use the \nresult  from  any  depth-\u00fbrst  search.  \nWhat  is the  running  time  of DFS?  The  loops  on  lines  133  and  lines  537  of DFS  \ntake \u201a.V/  time,  exclusive  of the  time  to execute  the  calls  to DFS-V ISIT. As we did \nfor  breadth-\u00fbrst  search,  we  use  aggregate  analysis.  The  procedure  DFS-V ISIT is \ncalled exactly once for each vertex v 2 V , since the vertex u on  which  DFS-V ISIT \nis invoked  must  be white  and  the  \u00fbrst  thing  DFS-V ISIT does is paint vertex u gray. \nDuring  an execution  of DFS-V ISIT .G;v/, the  loop  in lines  437  executes  jAdj\u0152v\ufffdj \ntimes. Since P  \nv2V jAdj\u0152v\ufffdj D  \u201a.E/  and  DFS-V ISIT is called once per vertex, the 20.3  Depth-\ufb01rst  search  567 \ntotal  cost  of executing  lines  437  of DFS-V ISIT is \u201a.V  C E/. The running time of \nDFS is therefore \u201a.V  C E/. \nProperties  of depth-\ufb01rst  search  \nDepth-\u00fbrst  search  yields  valuable  information  about  the  structure  of a graph.  Per-  \nhaps  the  most  basic  property  of depth-\u00fbrst  search  is that  the  predecessor  sub-  \ngraph G \ue003 does indeed form a forest of trees, since the struc ture of the depth-  \n\u00fbrst  trees  exactly  mirrors  the  structure  of recursive  calls  of DFS-V ISIT. That is, \nu D v:\ufffd  if and  only  if DFS-V ISIT .G;v/  was called during a search of u\u2019s ad-  \njacency list. Additionally, vertex v is a descendant of vertex u in the  depth-\u00fbrst  \nforest if and only if v is discovered during the time in which u is gray. \nAnother  important  property  of depth-\u00fbrst  search  is that  discovery  and  \u00fbnish  \ntimes have parenthesis  structure. If the  DFS-V ISIT procedure were to print a left \nparenthesis <.u= when it discovers vertex u and to print a right parenthesis < u/= \nwhen  it \u00fbnishes  u, then the printed expression would be well formed in the sense \nthat the parentheses are properly nested. For examp le, the depth-\u00fbrst  search  of \nFigure  20.5(a)  corresponds  to the  parenthesization  shown  in Figure  20.5(b).  The  \nfollowing theorem provides another way to character ize the parenthesis structure. \nTheorem  20.7  (Parenthesis  theorem)  \nIn any  depth-\u00fbrst  search  of a (directed  or undirected)  graph  G D .V;E/ , for any \ntwo vertices u and v, exactly one of the following three conditions hol ds: \n\ue001 the intervals \u0152u:  d;u:  f \ufffd and \u0152v:  d;v:  f \ufffd are entirely disjoint, and neither u nor v \nis a descendant  of the  other  in the  depth-\u00fbrst  forest,  \n\ue001 the interval \u0152u:  d;u:  f \ufffd is contained entirely within the interval \u0152v:  d;v:  f \ufffd, and u \nis a descendant of v in a depth-\u00fbrst  tree,  or \n\ue001 the interval \u0152v:  d;v:  f \ufffd is contained entirely within the interval \u0152u:  d;u:  f \ufffd, and v \nis a descendant of u in a depth-\u00fbrst  tree.  \nProof  We begin with the case in which u: d <v:  d. We consider two subcases, \naccording to whether v: d <u:  f . The  \u00fbrst  subcase  occurs  when  v: d <u:  f , so that \nv was discovered while u was still gray, which implies that v is a descendant of u. \nMoreover, since v was discovered after u, all of its outgoing edges are explored, \nand v is \u00fbnished,  before  the  search  returns  to and  \u00fbnishes  u. In this case, therefore, \nthe interval \u0152v:  d;v:  f \ufffd is entirely contained within the interval \u0152u:  d;u:  f \ufffd. In the \nother subcase, u: f < v: d, and  by  inequality  (20.4),  u: d < u: f < v: d < v: f , \nand thus the intervals \u0152u:  d;u:  f \ufffd and \u0152v:  d;v:  f \ufffd are disjoint. Because the intervals \nare disjoint, neither vertex was discovered while t he other was gray, and so neither \nvertex is a descendant of the other. 568  Chapter  20  Elementary  Graph  Algorithms  \n3/6  2/9  1/10  11/16  \n14/15  12/13  7/8  4/5  y z s t \nu w x B \nC F \nC C \nC B \n1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  16  \ns \nz \ny w \nx t \nu C \nF \nB \nC C B \nC (a) \n(b) \n(c) (s (z (y (x x) y) (w w ) z) s) (t ( ) ( u u) t) T T T T T \nT T T \nT T T s t \nz \ny w \nx u T v \nv v \nv v \nFigure  20.5  Properties  of depth-\u00fbrst  search.  (a)  The  result  of a depth-\u00fbrst  search  of a directed  \ngraph. Vertices are timestamped and edge types are indicated as in Figure  20.4.  (b)  Intervals for \nthe  discovery  time  and  \u00fbnish  time  of each  vertex  correspond  to the parenthesization shown. Each \nrectangle  spans  the  interval  given  by  the  discovery  and  \u00fbnish times of the corresponding vertex. \nOnly  tree  edges  are  shown.  If two  intervals  overlap,  then  one  is nested within the other, and the \nvertex corresponding to the smaller interval is a d escendant of the vertex corresponding to the larger . \n(c)  The graph of part (a) redrawn with all tree and for ward edges g oing  down  within  a depth-\u00fbrst  tree  \nand all back edges going up from a descendant to an  ancestor. \nThe case in which v: d <u:  d is similar, with the roles of u and v reversed in the \nabove argument. \nCorollary  20.8  (Nesting  of descendants\u2019  intervals)  \nVertex v is a proper descendant of vertex u in the  depth-\u00fbrst  forest  for  a (directed  \nor undirected) graph G if and only if u: d <v:  d <v:  f <u:  f . \nProof  Immediate  from  Theorem  20.7.  \nThe next theorem gives another important characteri zation of when one vertex \nis a descendant  of another  in the  depth-\u00fbrst  forest.  20.3  Depth-\ufb01rst  search  569 \nTheorem  20.9  (White-path  theorem)  \nIn a depth-\u00fbrst  forest  of a (directed  or undirected)  graph  G D .V;E/ , vertex v is \na descendant of vertex u if and only if at the time u: d that the search discovers u, \nthere is a path from u to v consisting entirely of white vertices. \nProof  ): If v D u, then the path from u to v contains just vertex u, which is \nstill white when u: d receives a value. Now, suppose that v is a proper descendant \nof u in the  depth-\u00fbrst  forest.  By  Corollary  20.8,  u: d <v:  d, and so v is white at \ntime u: d. Since v can be any descendant of u, all vertices on the unique simple \npath from u to v in the  depth-\u00fbrst  forest  are  white  at time  u: d. \n(: Suppose that there is a path of white vertices fr om u to v at time u: d, but v \ndoes not become a descendant of u in the  depth-\u00fbrst  tree.  Without  loss  of gener-  \nality, assume that every vertex other than v along the path becomes a descendant \nof u. (Otherwise,  let  v be the closest vertex to u along  the  path  that  doesn\u2019t  be-  \ncome a descendant of u.) Let w be the predecessor of v in the path, so that w is \na descendant of u (w and u may  in fact  be the  same  vertex).  By  Corollary  20.8,  \nw:  f \u0dc4 u: f . Because v must be discovered after u is discovered, but before w is \n\u00fbnished,  u: d < v: d < w:  f \u0dc4 u: f . Theorem  20.7  then  implies  that  the  interval  \n\u0152v:  d;v:  f \ufffd is contained entirely within the interval \u0152u:  d;u:  f \ufffd. By  Corollary  20.8,  v \nmust after all be a descendant of u. \nClassi\ufb01cation  of edges  \nYou can obtain important information about a graph by classifying its edges during \na depth-\u00fbrst  search.  For  example,  Section  20.4  will  show  that a directed graph is \nacyclic  if and  only  if a depth-\u00fbrst  search  yields  no  <back=  edges  (Lemma  20.11).  \nThe  depth-\u00fbrst  forest  G \ue003 produced  by  a depth-\u00fbrst  search  on  graph  G can  con-  \ntain four types of edges: \n1. Tree  edges  are  edges  in the  depth-\u00fbrst  forest  G \ue003 . Edge .u;v/  is a tree edge if v \nwas  \u00fbrst  discovered  by  exploring  edge  .u;v/ . \n2. Back  edges  are those edges .u;v/  connecting a vertex u to an ancestor v in a \ndepth-\u00fbrst  tree.  We  consider  self-loops,  which  may  occur  in directed graphs, to \nbe back edges. \n3. Forward  edges  are those nontree edges .u;v/  connecting a vertex u to a proper \ndescendant v in a depth-\u00fbrst  tree.  \n4. Cross  edges  are all other edges. They can go between vertices i n the same \ndepth-\u00fbrst  tree,  as long  as one  vertex  is not  an ancestor  of the other, or they can \ngo  between  vertices  in different  depth-\u00fbrst  trees.  570  Chapter  20  Elementary  Graph  Algorithms  \nIn Figures  20.4  and  20.5,  edge  labels  indicate  edge  types.  Figure  20.5(c)  also  shows  \nhow  to redraw  the  graph  of Figure  20.5(a)  so that  all  tree  and  forward edges head \ndownward  in a depth-\u00fbrst  tree  and  all  back  edges  go  up.  You  can  redraw any graph \nin this fashion. \nThe DFS algorithm has enough information to classif y some edges  as it encoun-  \nters them. The key idea is that when an edge .u;v/  is \u00fbrst  explored,  the  color  of \nvertex v says something about the edge: \n1. WHITE indicates a tree edge, \n2. GRAY  indicates a back edge, and \n3. BLACK  indicates a forward or cross edge. \nThe  \u00fbrst  case  is immediate  from  the  speci\u00fbcation  of the  algorithm.  For  the  sec-  \nond case, observe that the gray vertices always for m a linear chain of descendants \ncorresponding  to the  stack  of active  DFS-V ISIT invocations. The number of gray \nvertices is 1 more  than  the  depth  in the  depth-\u00fbrst  forest  of the  vertex  most recently \ndiscovered.  Depth-\u00fbrst  search  always  explores  from  the  deepest gray vertex, so \nthat an edge that reaches another gray vertex has r eached an ancestor. The third \ncase  handles  the  remaining  possibility.  Exercise  20.3-5  asks you to show that such \nan edge .u;v/  is a forward edge if u: d <v:  d and a cross edge if u: d >v:  d. \nAccording to the following theorem, forward and cro ss edges never occur in a \ndepth-\u00fbrst  search  of an undirected  graph.  \nTheorem  20.10  \nIn a depth-\u00fbrst  search  of an undirected  graph  G, every edge of G is either a tree \nedge or a back edge. \nProof  Let .u;v/  be an arbitrary edge of G, and suppose without loss of generality \nthat u: d < v: d. Then, while u is gray,  the  search  must  discover  and  \u00fbnish  v \nbefore  it \u00fbnishes  u, since v is on u\u2019s adjacency  list.  If the  \u00fbrst  time  that  the  search  \nexplores edge .u;v/ , it is in the direction from u to v, then v is undiscovered \n(white) until that time, for otherwise the search w ould have explored this edge \nalready in the direction from v to u. Thus, .u;v/  becomes a tree edge. If the \nsearch explores .u;v/  \u00fbrst  in the  direction  from  v to u, then .u;v/  is a back edge, \nsince there must be a path of tree edges from u to v. \nSince .u;v/  and .v;u/  are really the same edge in an undirected graph, th e proof \nof Theorem  20.10  says  how  to classify  the  edge.  When  searchin g from a vertex, \nwhich must be gray, if the adjacent vertex is white , then the edge is a tree edge. \nOtherwise,  the  edge  is a back  edge.  \nThe  next  two  sections  apply  the  above  theorems  about  depth-\u00fb rst search. 20.3  Depth-\ufb01rst  search  571 \nq r \ns t u \nw x y \nz v \nFigure  20.6  A directed  graph  for  use  in Exercises  20.3-2  and  20.5-2.  \nExercises  \n20.3-1  \nMake a 3-by-3 chart with row and column labels WHITE , GRAY , and BLACK . In \neach cell .i;j/, indicate  whether,  at any  point  during  a depth-\u00fbrst  search  of a di-  \nrected graph, there can be an edge from a vertex of  color i to a vertex of color j . \nFor each possible edge, indicate what edge types it  can be. Make a second such \nchart  for  depth-\u00fbrst  search  of an undirected  graph.  \n20.3-2  \nShow  how  depth-\u00fbrst  search  works  on  the  graph  of Figure  20.6.  Assume that the \nfor  loop  of lines  537  of the  DFS  procedure  considers  the  vertices  in alphabetical \norder, and assume that each adjacency list is order ed alphabetically. Show the \ndiscovery  and  \u00fbnish  times  for  each  vertex,  and  show  the  classi\u00fbcation  of each  \nedge. \n20.3-3  \nShow  the  parenthesis  structure  of the  depth-\u00fbrst  search  of Figure  20.4.  \n20.3-4  \nShow  that  using  a single  bit  to store  each  vertex  color  suf\u00fbce s by arguing that the \nDFS  procedure  produces  the  same  result  if line  10  of DFS-V ISIT is removed. \n20.3-5  \nShow that in a directed graph, edge .u;v/  is \na. a tree edge or forward edge if and only if u: d <v:  d <v:  f <u:  f , \nb. a back edge if and only if v: d \u0dc4 u: d <u:  f \u0dc4 v: f , and \nc. a cross edge if and only if v: d <v:  f <u:  d <u:  f . 572  Chapter  20  Elementary  Graph  Algorithms  \n20.3-6  \nRewrite the procedure DFS, using a stack to elimina te recursion. \n20.3-7  \nGive  a counterexample  to the  conjecture  that  if a directed  graph G contains a path \nfrom u to v, and if u: d <v:  d in a depth-\u00fbrst  search  of G, then v is a descendant \nof u in the  depth-\u00fbrst  forest  produced.  \n20.3-8  \nGive  a counterexample  to the  conjecture  that  if a directed  graph G contains a path \nfrom u to v, then  any  depth-\u00fbrst  search  must  result  in v: d \u0dc4 u: f . \n20.3-9  \nModify  the  pseudocode  for  depth-\u00fbrst  search  so that  it print s out every edge in the \ndirected graph G, together  with  its  type.  Show  what  modi\u00fbcations,  if any,  you  need \nto make if G is undirected. \n20.3-10  \nExplain how a vertex u of a directed  graph  can  end  up  in a depth-\u00fbrst  tree  contain-  \ning only u, even though u has both incoming and outgoing edges in G. \n20.3-11  \nLet G D .V;E/  be a connected,  undirected  graph.  Give  an O.V  C E/-time  algo-  \nrithm to compute a path in G that traverses each edge in E exactly once in each \ndirection.  Describe  how  you  can  \u00fbnd  your  way  out  of a maze  if you are given a \nlarge supply of pennies. \n20.3-12  \nShow  how  to use  a depth-\u00fbrst  search  of an undirected  graph  G to identify the \nconnected components of G, so that  the  depth-\u00fbrst  forest  contains  as many  trees  \nas G has connected components. More precisely, show how to modify depth-\u00fbrst  \nsearch so that it assigns to each vertex v an integer label v: cc between 1 and k, \nwhere k is the number of connected components of G, such that u: cc D v: cc if \nand only if u and v belong to the same connected component. \n? 20.3-13  \nA directed graph G D .V;E/  is singly  connected  if u \u2740  v implies that G contains \nat most one simple path from u to v for all vertices u;v  2 V . Give  an ef\u00fbcient  \nalgorithm to determine whether a directed graph is singly connected. 20.4  Topological  sort  573 \n20.4  Topological  sort  \nThis  section  shows  how  to use  depth-\u00fbrst  search  to perform  a topological sort of \na directed acyclic graph, or a <dag= as it is somet imes called. A topological  sort  \nof a dag G D .V;E/  is a linear ordering of all its vertices such that if G contains \nan edge .u;v/ , then u appears before v in the ordering. Topological sorting is \nde\u00fbned  only  on  directed  graphs  that  are  acyclic;  no  linear  ordering is possible \nwhen a directed graph contains a cycle. Think of a topological sort of a graph as \nan ordering of its vertices along a horizontal line  so that all directed edges go from \nleft to right. Topological sorting is thus differen t from the usual kind of <sorting= \nstudied in Part II. \nMany applications use directed acyclic graphs to in dicate precedences among \nevents.  Figure  20.7  gives  an example  that  arises  when  Profes sor Bumstead gets \ndressed in the morning. The professor must don cert ain garments before others \n(e.g.,  socks  before  shoes).  Other  items  may  be put  on  in any  order (e.g., socks and \npants). A directed edge .u;v/  in the  dag  of Figure  20.7(a)  indicates  that  garment  u \nmust be donned before garment v. A topological sort of this dag therefore gives a \npossible  order  for  getting  dressed.  Figure  20.7(b)  shows  the topologically sorted \ndag as an ordering of vertices along a horizontal l ine such that all directed edges \ngo from left to right. \nThe procedure T OPOLOGICAL -SORT  topologically  sorts  a dag.  Figure  20.7(b)  \nshows how the topologically sorted vertices appear in reverse order  of their  \u00fbnish  \ntimes. \nTOPOLOGICAL -SORT  .G/  \n1 call DFS.G/  to compute  \u00fbnish  times  v: f for each vertex v \n2 as each  vertex  is \u00fbnished,  insert  it onto  the  front  of a linked  list \n3 return  the linked list of vertices \nThe TOPOLOGICAL -SORT  procedure runs in \u201a.V  C E/  time,  since  depth-\u00fbrst  \nsearch takes \u201a.V  CE/  time and it takes O.1/  time to insert each of the jV j vertices \nonto the front of the linked list. \nTo  prove  the  correctness  of this  remarkably  simple  and  ef\u00fbci ent algorithm, we \nstart with the following key lemma characterizing d irected acyclic graphs. \nLemma  20.11  \nA directed graph G is acyclic  if and  only  if a depth-\u00fbrst  search  of G yields no back \nedges. 574  Chapter  20  Elementary  Graph  Algorithms  \n11/16  \n12/15  \n6/7  1/8  \n2/5  \n3/4  17/18  \n13/14  9/10  \n17/18  11/16  12/15  13/14  9/10  1/8  6/7  2/5  3/4  (a) \n(b) undershorts \npants \nbelt shirt \ntie \njacket socks \nshoes watch \nsocks undershorts pants shoes watch shirt belt tie jacket \nFigure  20.7  (a)  Professor Bumstead topologically sorts his clothing  when getting dressed. Each \ndirected edge .u;v/  means that garment u must be put on before garment v. The discovery and \n\u00fbnish  times  from  a depth-\u00fbrst  search  are  shown  next  to each  vertex. (b)  The same graph shown \ntopologically sorted, with its vertices arranged fr om left to right  in order  of decreasing  \u00fbnish  time.  \nAll directed edges go from left to right. \nProof  ): Suppose  that  a depth-\u00fbrst  search  produces  a back  edge  .u;v/ . Then \nvertex v is an ancestor of vertex u in the  depth-\u00fbrst  forest.  Thus,  G contains a path \nfrom v to u, and the back edge .u;v/  completes a cycle. \n(: Suppose that G contains a cycle c . We  show  that  a depth-\u00fbrst  search  of G \nyields a back edge. Let v be the  \u00fbrst  vertex  to be discovered  in c , and let .u;v/  be \nthe preceding edge in c . At time v: d, the vertices of c form a path of white vertices \nfrom v to u. By  the  white-path  theorem,  vertex  u becomes a descendant of v in the \ndepth-\u00fbrst  forest.  Therefore,  .u;v/  is a back edge. \nTheorem  20.12  \nTOPOLOGICAL -SORT  produces a topological sort of the directed acyclic  graph \nprovided as its input. \nProof  Suppose that DFS is run on a given dag G D .V;E/  to determine  \u00fbn-  \nish  times  for  its  vertices.  It suf\u00fbces  to show  that  for  any  pair  of distinct  ver-  \ntices u;v  2 V , if G contains an edge from u to v, then v: f < u: f . Consider \nany edge .u;v/  explored by DFS .G/. When this edge is explored, v cannot be \ngray, since then v would be an ancestor of u and .u;v/  would be a back edge, \ncontradicting  Lemma  20.11.  Therefore,  v must be either white or black. If v is 20.4  Topological  sort  575 \nz y x w u t s r q p o n m \nv \nFigure  20.8  A dag for topological sorting. \nwhite, it becomes a descendant of u, and so v: f <u:  f . If v is black, it has already \nbeen  \u00fbnished,  so that  v: f has already been set. Because the search is still e xploring \nfrom u, it has yet to assign a timestamp to u: f , so that the timestamp eventually \nassigned to u: f is greater than v: f . Thus, v: f <u:  f for any edge .u;v/  in the dag, \nproving the theorem. \nExercises  \n20.4-1  \nShow the ordering of vertices produced by T OPOLOGICAL -SORT  when it is run on \nthe  dag  of Figure  20.8.  Assume  that  the  for  loop  of lines  537  of the  DFS  procedure  \nconsiders the vertices in alphabetical order, and a ssume that each adjacency list is \nordered alphabetically. \n20.4-2  \nGive  a linear-time  algorithm  that,  given  a directed  acyclic  graph G D .V;E/  and \ntwo vertices a;b  2 V , returns the number of simple paths from a to b in G. For \nexample,  the  directed  acyclic  graph  of Figure  20.8  contains  exactly four simple \npaths from vertex p to vertex v: hp;o;v i, hp;o;r;y;v i, hp;o;s;r;y;v i, and \nhp;s;r;y;v i. Your algorithm needs only to count the simple pat hs, not list them. \n20.4-3  \nGive  an algorithm  that  determines  whether  an undirected  graph G D .V;E/  con-  \ntains a simple cycle. Your algorithm should run in O.V/  time, independent of jEj. \n20.4-4  \nProve or disprove: If a directed graph G contains cycles, then the vertex ordering \nproduced by T OPOLOGICAL -SORT  .G/  minimizes the number of <bad= edges that \nare inconsistent with the ordering produced. 576  Chapter  20  Elementary  Graph  Algorithms  \n20.4-5  \nAnother way to topologically sort a directed acycli c graph G D .V;E/  is to re-  \npeatedly  \u00fbnd  a vertex  of in-degree  0, output  it, and  remove  it and  all  of its  outgo-  \ning edges from the graph. Explain how to implement this idea so that it runs in \ntime O.V  C E/. What happens to this algorithm if G has  cycles?  \n20.5  Strongly  connected  components  \nWe  now  consider  a classic  application  of depth-\u00fbrst  search:  decomposing  a di-  \nrected graph into its strongly connected components . This section shows how to do \nso using  two  depth-\u00fbrst  searches.  Many  algorithms  that  work  with directed graphs \nbegin with such a decomposition. After decomposing the graph into  strongly  con-  \nnected components, such algorithms run separately o n each one and then combine \nthe solutions according to the structure of connect ions among components. \nRecall from Appendix B that a strongly connected co mponent of a directed \ngraph G D .V;E/  is a maximal set of vertices C \u0dc2 V such that for every pair \nof vertices u;v  2 C , both u \u2740  v and v \u2740  u, that is, vertices u and v are reachable \nfrom each other. Figure 20.9 shows an example. \nThe  algorithm  for  \u00fbnding  the  strongly  connected  components  of a directed graph \nG D .V;E/  uses the transpose of G, which  we  de\u00fbned  in Exercise  20.1-3  to be \nthe graph G T D .V;E  T /, where E T D f.u;v/  W .v;u/  2 Eg. That is, E T consists \nof the edges of G with  their  directions  reversed.  Given  an adjacency-list  repre-  \nsentation of G, the time to create G T is \u201a.V  C E/. The graphs G and G T have \nexactly the same strongly connected components: u and v are reachable from each \nother in G if and only if they are reachable from each other i n G T . Figure 20.9(b) \nshows the transpose of the graph in Figure 20.9(a),  with the strongly connected \ncomponents shaded blue in both parts. \nThe  linear-time  (i.e.,  \u201a.V  C E/-time)  procedure  STRONGLY-CONNECTED- \nCOMPONENTS  on the next page computes the strongly connected co mponents of \na directed graph G D .V;E/  using  two  depth-\u00fbrst  searches,  one  on  G and one \non G T . \nThe idea behind this algorithm comes from a key pro perty of the component  \ngraph  G SCC D .V  SCC ;E  SCC /, de\u00fbned  as follows.  Suppose  that  G has strongly \nconnected components C 1 ;C  2 ;:::;C  k . The vertex set V SCC is fv 1 ;v  2 ;:::;v  k g, \nand it contains one vertex v i for each strongly connected component C i of G. \nThere is an edge .v i ;v  j / 2 E SCC if G contains a directed edge .x;y/  for some \nx 2 C i and some y 2 C j . Looked at another way, if we contract all edges w hose \nincident vertices are within the same strongly conn ected component of G so that 20.5  Strongly  connected  components  577 \n13/14  11/16  \n12/15  3/4  2/7  5/6  a b c d \ne f g h \nabe cd  \nfg h \n(c) (b) (a) 1/10  8/9  a b c d \ne f g h \nFigure  20.9  (a)  A directed graph G. Each  region  shaded  light  blue  is a strongly  connected  com-  \nponent of G. Each  vertex  is labeled  with  its  discovery  and  \u00fbnish  times  in a depth-\u00fbrst  search,  and  \ntree edges are dark blue. (b)  The graph G T , the transpose of G, with  the  depth-\u00fbrst  forest  computed  \nin line  3 of STRONGLY-CONNECTED-COMPONENTS  shown and tree edges shaded dark blue. Each \nstrongly  connected  component  corresponds  to one  depth-\u00fbrst  tree.  Orange  vertices  b, c, g, and h are \nthe  roots  of the  depth-\u00fbrst  trees  produced  by  the  depth-\u00fbrst  search of G T . (c)  The acyclic component \ngraph G SCC obtained by contracting all edges within each stron gly connected component of G so \nthat only a single vertex remains in each component . \nSTRONGLY-CONNECTED-COMPONENTS  .G/  \n1 call DFS.G/  to compute  \u00fbnish  times  u: f for each vertex u \n2 create G T \n3 call DFS.G  T /, but in the main loop of DFS, consider the vertice s \nin order of decreasing u: f (as  computed  in line  1) \n4 output  the  vertices  of each  tree  in the  depth-\u00fbrst  forest  formed  in line  3 as a \nseparate strongly connected component \nonly a single vertex remains, the resulting graph i s G SCC . Figure 20.9(c) shows the \ncomponent graph of the graph in Figure 20.9(a). \nThe following lemma gives the key property that the  component graph is acyclic. \nWe\u2019ll  see  that  the  algorithm  uses  this  property  to visit  the  vertices of the component \ngraph in topologically sorted order, by considering  vertices in the  second  depth-  \n\u00fbrst  search  in decreasing  order  of the  \u00fbnish  times  that  were  computed  in the  \u00fbrst  \ndepth-\u00fbrst  search.  578  Chapter  20  Elementary  Graph  Algorithms  \nLemma  20.13  \nLet C and C 0 be distinct strongly connected components in direct ed graph G D \n.V;E/ , let u;v  2 C , let u 0 ;v  0 2 C 0 , and suppose that G contains a path u \u2740  u 0 . \nThen G cannot also contain a path v 0 \u2740  v. \nProof  If G contains a path v 0 \u2740  v, then it contains paths u \u2740  u 0 \u2740  v 0 and \nv 0 \u2740  v \u2740  u. Thus, u and v 0 are reachable from each other, thereby contradictin g \nthe assumption that C and C 0 are distinct strongly connected components. \nBecause the S TRONGLY-CONNECTED-COMPONENTS  procedure performs two \ndepth-\u00fbrst  searches,  there  are  two  distinct  sets  of discovery  and  \u00fbnish  times.  In this  \nsection,  discovery  and  \u00fbnish  times  always  refer  to those  computed by the \ufb01rst  call \nof DFS,  in line  1. \nThe  notation  for  discovery  and  \u00fbnish  times  extends  to sets  of vertices. For a \nsubset U of vertices, d.U/  and f.U/  are the earliest discovery time and latest \n\u00fbnish  time,  respectively,  of any  vertex  in U : d.U/  D min fu: d W u 2 U g and \nf.U/  D max fu: f W u 2 U g. \nThe following lemma and its corollary give a key pr operty relating  strongly  con-  \nnected  components  and  \u00fbnish  times  in the  \u00fbrst  depth-\u00fbrst  search. \nLemma  20.14  \nLet C and C 0 be distinct strongly connected components in direct ed graph G D \n.V;E/ . Suppose that there is an edge .u;v/  2 E, where u 2 C 0 and v 2 C . Then \nf.C  0 />f.C/ . \nProof  We consider two cases, depending on which strongly connected compo-  \nnent, C or C 0 , had  the  \u00fbrst  discovered  vertex  during  the  \u00fbrst  depth-\u00fbrst  search. \nIf d.C  0 /<d.C/ , let x be the  \u00fbrst  vertex  discovered  in C 0 . At time x: d, all  ver-  \ntices in C and C 0 are white. At that time, G contains a path from x to each vertex \nin C 0 consisting only of white vertices. Because .u;v/  2 E, for any vertex w 2 C , \nthere is also a path in G at time x: d from x to w consisting only of white vertices: \nx \u2740  u !  v \u2740  w. By  the  white-path  theorem,  all  vertices  in C and C 0 become \ndescendants of x in the  depth-\u00fbrst  tree.  By  Corollary  20.8,  x has  the  latest  \u00fbnish  \ntime of any of its descendants, and so x: f D f.C  0 />f.C/ . \nOtherwise,  d.C  0 / > d.C/ . Let y be the  \u00fbrst  vertex  discovered  in C , so that \ny: d D d.C/ . At time y: d, all vertices in C are white and G contains a path \nfrom y to each vertex in C consisting  only  of white  vertices.  By  the  white-path  \ntheorem, all vertices in C become descendants of y in the  depth-\u00fbrst  tree,  and  by  \nCorollary  20.8,  y: f D f.C/ . Because d.C  0 />d.C/  D y: d, all vertices in C 0 are \nwhite at time y: d. Since there is an edge .u;v/  from C 0 to C , Lemma  20.13  implies  \nthat there cannot be a path from C to C 0 . Hence, no vertex in C 0 is reachable 20.5  Strongly  connected  components  579 \nfrom y . At time y: f , therefore, all vertices in C 0 are still white. Thus, for any \nvertex w 2 C 0 , we have w:  f >y:  f , which implies that f.C  0 />f.C/ . \nCorollary  20.15  \nLet C and C 0 be distinct strongly connected components in direct ed graph G D \n.V;E/ , and suppose that f.C/ >f.C  0 /. Then E T contains no edge .v;u/  such \nthat u 2 C 0 and v 2 C . \nProof  The  contrapositive  of Lemma  20.14  says  that  if f.C  0 /<f.C/ , then there \nis no edge .u;v/  2 E such that u 2 C 0 and v 2 C . Because the strongly connected \ncomponents of G and G T are the same, if there is no such edge .u;v/  2 E, then \nthere is no edge .v;u/  2 E T such that u 2 C 0 and v 2 C . \nCorollary  20.15  provides  the  key  to understanding  why  the  strongly connected \ncomponents  algorithm  works.  Let9s  examine  what  happens  during the second \ndepth-\u00fbrst  search,  which  is on  G T . The search starts from the vertex x whose \n\u00fbnish  time  from  the  \u00fbrst  depth-\u00fbrst  search  is maximum.  This  vertex belongs to \nsome strongly connected component C , and since x: f is maximum, f.C/  is max-  \nimum over all strongly connected components. When t he search starts from x , it \nvisits all vertices in C . By  Corollary  20.15,  G T contains no edges from C to any \nother strongly connected component, and so the sear ch from x never visits vertices \nin any other component. Thus, the tree rooted at x contains exactly the vertices \nof C . Having completed visiting all vertices in C , the  second  depth-\u00fbrst  search  \nselects as a new root a vertex from some other stro ngly connected component C 0 \nwhose  \u00fbnish  time  f.C  0 / is maximum over all components other than C . Again, \nthe search visits all vertices in C 0 . But  by  Corollary  20.15,  if any  edges  in G T go \nfrom C 0 to any other component, they must go to C , which  the  second  depth-\u00fbrst  \nsearch  has  already  visited.  In general,  when  the  depth-\u00fbrst  search of G T in line  3 \nvisits any strongly connected component, any edges out of that component must be \nto components that the search has already visited. Each depth-\u00fbrst  tree,  therefore,  \ncorresponds to exactly one strongly connected compo nent. The following theorem \nformalizes this argument. \nTheorem  20.16  \nThe STRONGLY-CONNECTED-COMPONENTS  procedure correctly computes the \nstrongly connected components of the directed graph  G provided as its input. \nProof  We  argue  by  induction  on  the  number  of depth-\u00fbrst  trees  found  in the \ndepth-\u00fbrst  search  of G T in line  3 that  the  vertices  of each  tree  form  a strongly  \nconnected  component.  The  inductive  hypothesis  is that  the  \u00fbrst k trees produced 580  Chapter  20  Elementary  Graph  Algorithms  \nin line  3 are  strongly  connected  components.  The  basis  for  the induction, when \nk D 0, is trivial. \nIn the  inductive  step,  we  assume  that  each  of the  \u00fbrst  k depth-\u00fbrst  trees  pro-  \nduced  in line  3 is a strongly  connected  component,  and  we  consider the .k C 1/st \ntree produced. Let the root of this tree be vertex u, and let u be in strongly  con-  \nnected component C . Because  of how  the  depth-\u00fbrst  search  chooses  roots  in line  3, \nu: f D f.C/>f.C  0 / for any strongly connected component C 0 other than C that \nhas yet to be visited. By the inductive hypothesis,  at the time that  the  search  vis-  \nits u, all other vertices of C are  white.  By  the  white-path  theorem,  therefore,  all  \nother vertices of C are descendants of u in its  depth-\u00fbrst  tree.  Moreover,  by  the  \ninductive  hypothesis  and  by  Corollary  20.15,  any  edges  in G T that leave C must be \nto strongly connected components that have already been visited. Thus, no vertex \nin any strongly connected component other than C is a descendant of u during the \ndepth-\u00fbrst  search  of G T . The  vertices  of the  depth-\u00fbrst  tree  in G T that is rooted \nat u form exactly one strongly connected component, whic h completes  the  induc-  \ntive step and the proof. \nHere  is another  way  to look  at how  the  second  depth-\u00fbrst  search  operates.  Con-  \nsider the component graph .G  T / SCC of G T . If you map each strongly connected \ncomponent  visited  in the  second  depth-\u00fbrst  search  to a verte x of .G  T / SCC , the  sec-  \nond  depth-\u00fbrst  search  visits  vertices  of .G  T / SCC in the reverse of a topologically \nsorted order. If you reverse the edges of .G  T / SCC , you get the graph ..G  T / SCC / T . \nBecause ..G  T / SCC / T D G SCC (see  Exercise  20.5-4),  the  second  depth-\u00fbrst  search  \nvisits the vertices of G SCC in topologically sorted order. \nExercises  \n20.5-1  \nHow can the number of strongly connected components  of a graph change if a new \nedge  is added?  \n20.5-2  \nShow how the procedure S TRONGLY-CONNECTED-COMPONENTS  works on the \ngraph  of Figure  20.6.  Speci\u00fbcally,  show  the  \u00fbnish  times  computed  in line  1 and  \nthe  forest  produced  in line  3. Assume  that  the  loop  of lines  537  of DFS  considers  \nvertices in alphabetical order and that the adjacen cy lists are in alphabetical order. \n20.5-3  \nProfessor Bacon rewrites the algorithm for strongly  connected components to use \nthe original (instead of the transpose) graph in th e second depth-\u00fbrst  search  and  Problems for Chapter 20 581 \nscan the vertices in order of increasing  \u00fbnish  times.  Does  this  modi\u00fbed  algorithm  \nalways  produce  correct  results?  \n20.5-4  \nProve that for any directed graph G, the transpose of the component graph of G T \nis the same as the component graph of G. That is, ..G  T / SCC / T D G SCC . \n20.5-5  \nGive  an O.V  C E/-time  algorithm  to compute  the  component  graph  of a directed  \ngraph G D .V;E/ . Make sure that there is at most one edge between two vertices \nin the component graph your algorithm produces. \n20.5-6  \nGive  an O.V  C E/-time  algorithm  that,  given  a directed  graph  G D .V;E/, con-  \nstructs another graph G 0 D .V;E  0 / such that G and G 0 have the same strongly \nconnected components, G 0 has the same component graph as G, and jE 0 j is as \nsmall as possible. \n20.5-7  \nA directed graph G D .V;E/  is semiconnected  if, for all pairs of vertices u;v  2 V , \nwe have u \u2740  v or v \u2740  u. Give  an ef\u00fbcient  algorithm  to determine  whether  G is \nsemiconnected. Prove that your algorithm is correct , and analyze its running time. \n20.5-8  \nLet G D .V;E/  be a directed graph, and let l W V !  R be a function that assigns \na real-valued  label  l to each vertex. For vertices s;t  2 V , de\u00fbne  \n\ufffdl.s; t/  D ( \nl.t/  \ue003 l.s/  if there is a path from s to t in G;  \n\ue0031  otherwise : \nGive  an O.V  C E/-time  algorithm  to \u00fbnd  vertices  s and t such that \ufffdl.s; t/  is \nmaximum over all pairs of vertices. ( Hint: Use  Exercise  20.5-5.)  \nProblems  \n20-1  Classifying  edges  by breadth-\u00fbrst  search  \nA depth-\u00fbrst  forest  classi\u00fbes  the  edges  of a graph  into  tree,  back, forward, and \ncross  edges.  A breadth-\u00fbrst  tree  can  also  be used  to classify  the edges reachable \nfrom the source of the search into the same four ca tegories. 582  Chapter  20  Elementary  Graph  Algorithms  \n1 2 \n3 4 \n5 6 \nFigure  20.10  The articulation points, bridges, and biconnected c omponents  of a connected,  undi-  \nrected  graph  for  use  in Problem  20-2.  The  articulation  point s are the orange vertices, the bridges are \nthe dark blue edges, and the biconnected components  are the edges in the light blue regions, with a \nbcc  numbering shown. \na. Prove  that  in a breadth-\u00fbrst  search  of an undirected  graph,  the  following  prop-  \nerties hold: \n1. There  are  no  back  edges  and  no  forward  edges.  \n2. If .u;v/  is a tree edge, then v: d D u: d C 1. \n3. If .u;v/  is a cross edge, then v: d D u: d or v: d D u: d C 1. \nb. Prove  that  in a breadth-\u00fbrst  search  of a directed  graph,  the  following properties \nhold: \n1. There  are  no  forward  edges.  \n2. If .u;v/  is a tree edge, then v: d D u: d C 1. \n3. If .u;v/  is a cross edge, then v: d \u0dc4 u: d C 1. \n4. If .u;v/  is a back edge, then 0 \u0dc4 v: d \u0dc4 u: d. \n20-2  Articulation  points,  bridges,  and  biconnected  components  \nLet G D .V;E/  be a connected, undirected graph. An articulation  point  of G is \na vertex whose removal disconnects G. A bridge  of G is an edge whose removal \ndisconnects G. A biconnected  component  of G is a maximal set of edges such \nthat any two edges in the set lie on a common simpl e cycle. Figu re 20.10  illustrates  \nthese  de\u00fbnitions.  You  can  determine  articulation  points,  bridges, and biconnected \ncomponents  using  depth-\u00fbrst  search.  Let  G \ue003 D .V;E  \ue003 / be a depth-\u00fbrst  tree  of G. \na. Prove that the root of G \ue003 is an articulation point of G if and only if it has at \nleast two children in G \ue003 . Problems for Chapter 20 583 \nb. Let v be a nonroot vertex of G \ue003 . Prove that v is an articulation point of G if and \nonly if v has a child s such that there is no back edge from s or any descendant \nof s to a proper ancestor of v. \nc. Let \nv: low D min ( \nv: d ; \nw:  d W .u;w/  is a back edge for some descendant u of v:  \nShow how to compute v: low for all vertices v 2 V in O.E/  time. \nd. Show how to compute all articulation points in O.E/  time. \ne. Prove that an edge of G is a bridge if and only if it does not lie on any s imple \ncycle of G. \nf. Show how to compute all the bridges of G in O.E/  time. \ng. Prove that the biconnected components of G partition the nonbridge edges of G. \nh. Give  an O.E/-time  algorithm  to label  each  edge  e of G with  a positive  inte-  \nger e: bcc  such that e: bcc  D e 0 : bcc  if and only if e and e 0 belong to the same \nbiconnected component. \n20-3  Euler  tour  \nAn Euler  tour  of a strongly connected, directed graph G D .V;E/  is a cycle that \ntraverses each edge of G exactly once, although it may visit a vertex more t han \nonce. \na. Show that G has  an Euler  tour  if and  only  if in-degree.v/  D out-degree.v/  for \neach vertex v 2 V . \nb. Describe an O.E/-time  algorithm  to \u00fbnd  an Euler  tour  of G if one exists. ( Hint: \nMerge  edge-disjoint  cycles.)  \n20-4  Reachability  \nLet G D .V;E/  be a directed graph in which each vertex u 2 V is labeled with \na unique integer L.u/  from the set f1;2;:::;  jV jg. For each vertex u 2 V , let \nR.u/  D fv 2 V W u \u2740  vg be the set of vertices that are reachable from u. De\u00fbne  \nmin.u/  to be the vertex in R.u/  whose label is minimum, that is, min .u/  is the \nvertex v such that L.v/  D min fL.w/  W w 2 R.u/ g. Give  an O.V  C E/-time  \nalgorithm that computes min .u/  for all vertices u 2 V . 584  Chapter  20  Elementary  Graph  Algorithms  \n20-5  Inserting  and  querying  vertices  in planar  graphs  \nA planar  graph is an undirected graph that can be drawn in t he plane with no edges \ncrossing. Euler proved that every planar graph has jEj <3  jV j. \nConsider the following two operations on a planar g raph G: \n\ue001 I NSERT.G;v;  neighbors / inserts a new vertex v into G, where neighbors is an \narray (possibly empty) of vertices that have alread y been inserted into G and \nwill become all the neighbors of v in G when v is inserted. \n\ue001 NEWEST-NEIGHBOR  .G;v/  returns the neighbor of vertex v that  was  most  re-  \ncently inserted into G, or NIL if v has no neighbors. \nDesign a data structure that supports these two ope rations such that N EWEST- \nNEIGHBOR  takes O.1/  worst-case  time  and  I NSERT takes O.1/  amortized time. \nNote that the length of the array neighbors given to I NSERT may vary. ( Hint: Use \na potential function for the amortized analysis.) \nChapter  notes  \nEven  [137]  and  Tarjan  [429]  are  excellent  references  for  graph algorithms. \nBreadth-\u00fbrst  search  was  discovered  by  Moore  [334]  in the  context  of \u00fbnding  \npaths  through  mazes.  Lee  [280]  independently  discovered  the same algorithm in \nthe context of routing wires on circuit boards. \nHopcroft  and  Tarjan  [226]  advocated  the  use  of the  adjacency-list  representation  \nover  the  adjacency-matrix  representation  for  sparse  graphs  and  were  the  \u00fbrst  to \nrecognize  the  algorithmic  importance  of depth-\u00fbrst  search.  Depth-\u00fbrst  search  has  \nbeen  widely  used  since  the  late  1950s,  especially  in arti\u00fbci al intelligence programs. \nTarjan  [426]  gave  a linear-time  algorithm  for  \u00fbnding  strongly  connected  compo-  \nnents. The algorithm for strongly connected compone nts in Section  20.5  is adapted  \nfrom  Aho,  Hopcroft,  and  Ullman  [6],  who  credit  it to S. R. Kosaraju  (unpub-  \nlished)  and  Sharir  [408].  Dijkstra  [117,  Chapter  25]  also  developed an algorithm \nfor strongly connected components that is based on contracting  cycles.  Subse-  \nquently,  Gabow  [163]  rediscovered  this  algorithm.  Knuth  [259]  was  the  \u00fbrst  to \ngive  a linear-time  algorithm  for  topological  sorting.  21  Minimum  Spanning  Trees  \nElectronic circuit designs often need to make the p ins of several  components  elec-  \ntrically equivalent by wiring them together. To int erconnect a set of n pins, the \ndesigner can use an arrangement of n \ue003 1 wires,  each  connecting  two  pins.  Of  all  \nsuch arrangements, the one that uses the least amou nt of wire is usually the most \ndesirable. \nTo model this wiring problem, use a connected, undi rected graph G D .V;E/ , \nwhere V is the set of pins, E is the set of possible interconnections between pai rs \nof pins, and for each edge .u;v/  2 E, a weight w.u;v/  speci\u00fbes  the  cost  (amount  \nof wire needed) to connect u and v. The  goal  is to \u00fbnd  an acyclic  subset  T \u0dc2 E \nthat connects all of the vertices and whose total w eight \nw.T/  D X  \n.u;v/ 2T w.u;v/  \nis minimized. Since T is acyclic and connects all of the vertices, it mus t form a tree, \nwhich we call a spanning  tree  since it <spans= the graph G. We call the problem of \ndetermining the tree T the minimum-spanning-tree  problem . 1 Figure  21.1  shows  \nan example of a connected graph and a minimum spann ing tree. \nThis  chapter  studies  two  ways  to solve  the  minimum-spanning-tree  problem.  \nKruskal9s  algorithm  and  Prim9s  algorithm  both  run  in O.E  lg V/  time.  Prim9s  \nalgorithm achieves this bound by using a binary hea p as a priority queue. By using \nFibonacci  heaps  instead  (see  page  478),  Prim9s  algorithm  runs in O.E  C V lg V/  \ntime. This bound is better than O.E  lg V/  whenever jEj grows asymptotically \nfaster than jV j. \n1 The phrase <minimum spanning tree= is a shortened f orm of the phrase  <minimum-weight  spanning  \ntree.= There is no point in minimizing the number o f edges in T , since all spanning trees have exactly \njV j \ue003  1 edges  by  Theorem  B.2  on  page  1169.  586  Chapter  21  Minimum  Spanning  Trees  \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 2 \n7 6 \nFigure  21.1  A minimum spanning tree for a connected graph. The weights on edges are shown, \nand the blue edges form a minimum spanning tree. Th e total weight of the tree shown is 37. This \nminimum spanning tree is not unique: removing the e dge .b;c/  and replacing it with the edge .a;h/  \nyields another spanning tree with weight 37. \nThe two algorithms are greedy algorithms, as descri bed in Chapter  15.  Each  step  \nof a greedy algorithm must make one of several poss ible choices.  The  greedy  strat-  \negy advocates making the choice that is the best at  the moment. Such a strategy \ndoes  not  generally  guarantee  that  it always  \u00fbnds  globally  optimal  solutions  to prob-  \nlems.  For  the  minimum-spanning-tree  problem,  however,  we  can prove that certain \ngreedy strategies do yield a spanning tree with min imum weight. Although you can \nread  this  chapter  independently  of Chapter  15,  the  greedy  methods presented here \nare a classic application of the theoretical notion s introduced there. \nSection  21.1  introduces  a <generic=  minimum-spanning-tre e method that grows \na spanning  tree  by  adding  one  edge  at a time.  Section  21.2  gives two algorithms \nthat  implement  the  generic  method.  The  \u00fbrst  algorithm,  due  to Kruskal,  is similar  \nto the  connected-components  algorithm  from  Section  19.1.  The second, due to \nPrim,  resembles  Dijkstra9s  shortest-paths  algorithm  (Section  22.3).  \nBecause a tree is a type of graph, in order to be p recise we must de\u00fbne  a tree  \nin terms of not just its edges, but its vertices as  well. Because this chapter focuses \non  trees  in terms  of their  edges,  we9ll  implicitly  understan d that the vertices of a \ntree T are those that some edge of T is incident on. \n21.1  Growing  a minimum  spanning  tree  \nThe  input  to the  minumum-spanning-tree  problem  is a connect ed, undirected graph \nG D .V;E/  with a weight function w W E !  R. The  goal  is to \u00fbnd  a minimum  \nspanning tree for G. The two algorithms considered in this chapter use  a greedy \napproach to the problem, although they differ in ho w they apply this approach. \nThis  greedy  strategy  is captured  by  the  procedure  GENERIC-MST  on  the  facing  \npage, which grows the minimum spanning tree one edg e at a time. The generic \nmethod manages a set A of edges, maintaining the following loop invariant:  \nPrior to each iteration, A is a subset of some minimum spanning tree. 21.1  Growing  a minimum  spanning  tree  587 \nGENERIC-MST  .G;w/  \n1 A D ;  \n2 while  A does not form a spanning tree \n3 \u00fbnd  an edge  .u;v/  that is safe for A \n4 A D A [ f.u;v/ g \n5 return  A \nEach step determines an edge .u;v/  that the procedure can add to A without \nviolating this invariant, in the sense that A [ f.u;v/ g is also a subset of a minimum \nspanning tree. We call such an edge a safe  edge  for A, since it can be added safely \nto A while maintaining the invariant. \nThis generic algorithm uses the loop invariant as f ollows: \nInitialization:  After  line  1, the  set  A trivially  satis\u00fbes  the  loop  invariant.  \nMaintenance:  The  loop  in lines  234  maintains  the  invariant  by  adding  only  safe \nedges. \nTermination:  All edges added to A belong to a minimum spanning tree, and the \nloop must terminate by the time it has considered a ll edges. Therefore, the set A \nreturned  in line  5 must  be a minimum  spanning  tree.  \nThe  tricky  part  is, of course,  \u00fbnding  a safe  edge  in line  3. One  must exist, since \nwhen  line  3 is executed,  the  invariant  dictates  that  there  is a spanning tree T such \nthat A \u0dc2 T . Within the while  loop body, A must be a proper subset of T , and \ntherefore there must be an edge .u;v/  2 T such that .u;v/  \u2026 A and .u;v/  is safe \nfor A. \nThe  remainder  of this  section  provides  a rule  (Theorem  21.1)  for recognizing \nsafe edges. The next section describes two algorith ms that use this  rule  to \u00fbnd  safe  \nedges  ef\u00fbciently.  \nWe  \u00fbrst  need  some  de\u00fbnitions.  A cut  .S;V  \ue003 S/  of an undirected graph G D \n.V;E/  is a partition of V . Figure  21.2  illustrates  this  notion.  We  say  that  an \nedge .u;v/  2 E crosses  the cut .S;V  \ue003 S/  if one of its endpoints belongs to S and \nthe other belongs to V \ue003 S . A cut respects  a set A of edges if no edge in A crosses \nthe cut. An edge is a light  edge  crossing a cut if its weight is the minimum of any \nedge crossing the cut. There can be more than one l ight edge crossing a cut in the \ncase of ties. More generally, we say that an edge i s a light  edge  satisfying a given \nproperty if its weight is the minimum of any edge s atisfying the property. \nThe following theorem gives the rule for recognizin g safe edges. \nTheorem  21.1  \nLet G D .V;E/  be a connected,  undirected  graph  with  a real-valued  weight  func-  \ntion w de\u00fbned  on  E. Let A be a subset of E that is included in some minimum 588  Chapter  21  Minimum  Spanning  Trees  \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 2 \n7 6 S \nV \u2013 S S \nV \u2013 S \nFigure  21.2  A cut .S;V  \ue003 S/  of the  graph  from  Figure  21.1.  Orange  vertices  belong  to the  set S , \nand tan vertices belong to V \ue003 S . The edges crossing the cut are those connecting t an vertices with \norange vertices. The edge .d;c/  is the unique light edge crossing the cut. Blue edg es form a subset A \nof the edges. The cut .S;V  \ue003 S/  respects A, since no edge of A crosses the cut. \nspanning tree for G, let .S;V  \ue003 S/  be any cut of G that respects A, and let .u;v/  \nbe a light edge crossing .S;V  \ue003 S/. Then, edge .u;v/  is safe for A. \nProof  Let T be a minimum spanning tree that includes A, and assume that T \ndoes not contain the light edge .u;v/, since  if it does,  we  are  done.  We9ll  construct  \nanother minimum spanning tree T 0 that includes A [ f.u;v/ g by  using  a cut-and-  \npaste technique, thereby showing that .u;v/  is a safe edge for A. \nThe edge .u;v/  forms a cycle with the edges on the simple path p from u \nto v in T , as Figure  21.3  illustrates.  Since  u and v are on opposite sides of the \ncut .S;V  \ue003 S/, at least one edge in T lies on the simple path p and also crosses \nthe cut. Let .x;y/  be any such edge. The edge .x;y/  is not in A, because the cut \nrespects A. Since .x;y/  is on the unique simple path from u to v in T , remov-  \ning .x;y/  breaks T into two components. Adding .u;v/  reconnects them to form \na new spanning tree T 0 D .T  \ue003 f.x;y/ g/ [ f.u;v/ g. \nWe next show that T 0 is a minimum spanning tree. Since .u;v/  is a light edge \ncrossing .S;V  \ue003 S/  and .x;y/  also crosses this cut, w.u;v/  \u0dc4 w.x;y/ . Therefore, \nw.T  0 / D w.T/  \ue003 w.x;y/  C w.u;v/  \n\u0dc4 w.T/:  \nBut T is a minimum spanning tree, so that w.T/  \u0dc4 w.T  0 /, and thus, T 0 must be a \nminimum spanning tree as well. \nIt remains to show that .u;v/  is actually a safe edge for A. We have A \u0dc2 T 0 , \nsince A \u0dc2 T and .x;y/  \u2026 A, and thus, A [ f.u;v/ g \u0dc2  T 0 . Consequently, since T 0 \nis a minimum spanning tree, .u;v/  is safe for A. \nTheorem  21.1  provides  insight  into  how  the  GENERIC-MST  method  works  on  a \nconnected graph G D .V;E/ . As the method proceeds, the set A is always acyclic, \nsince it is a subset of a minimum spanning tree and  a tree may not contain a cycle. 21.1  Growing  a minimum  spanning  tree  589 \ny u x \np \nv \nFigure  21.3  The  proof  of Theorem  21.1.  Orange  vertices  belong  to S , and tan vertices belong \nto V \ue003 S . Only  edges  in the  minimum  spanning  tree  T are shown, along with edge .u;v/ , which \ndoes not lie in T . The edges in A are blue, and .u;v/  is a light edge crossing the cut .S;V  \ue003 S/. The \nedge .x;y/  is an edge on the unique simple path p from u to v in T . To form a minimum spanning \ntree T 0 that contains .u;v/ , remove the edge .x;y/  from T and add the edge .u;v/ . \nAt any point in the execution, the graph G A D .V;A/  is a forest, and each of the \nconnected components of G A is a tree. (Some of the trees may contain just one \nvertex, as is the case, for example, when the metho d begins: A is empty and the \nforest contains jV j trees, one for each vertex.) Moreover, any safe edg e .u;v/  for A \nconnects distinct components of G A , since A [ f.u;v/ g must be acyclic. \nThe while  loop  in lines  234  of GENERIC-MST  executes  jV j \ue003  1 times because \nit \u00fbnds  one  of the  jV j \ue003  1 edges of a minimum spanning tree in each iteration.  \nInitially, when A D ;, there are jV j trees in G A , and each iteration reduces that \nnumber by 1. When the forest contains only a single tree, the method terminates. \nThe  two  algorithms  in Section  21.2  use  the  following  corollary  to Theorem  21.1.  \nCorollary  21.2  \nLet G D .V;E/  be a connected,  undirected  graph  with  a real-valued  weight  func-  \ntion w de\u00fbned  on  E. Let A be a subset of E that is included in some minimum \nspanning tree for G, and let C D .V  C ;E  C / be a connected component (tree) in the \nforest G A D .V;A/ . If .u;v/  is a light edge connecting C to some other component \nin G A , then .u;v/  is safe for A. \nProof  The cut .V  C ;V  \ue003 V C / respects A, and .u;v/  is a light edge for this cut. \nTherefore, .u;v/  is safe for A. 590  Chapter  21  Minimum  Spanning  Trees  \nExercises  \n21.1-1  \nLet .u;v/  be a minimum-weight  edge  in a connected  graph  G. Show that .u;v/  \nbelongs to some minimum spanning tree of G. \n21.1-2  \nProfessor Sabatier conjectures the following conver se of Theorem  21.1.  Let  G D \n.V;E/  be a connected,  undirected  graph  with  a real-valued  weight  function w de-  \n\u00fbned  on  E. Let A be a subset of E that is included in some minimum spanning \ntree for G, let .S;V  \ue003 S/  be any cut of G that respects A, and let .u;v/  be a safe \nedge for A crossing .S;V  \ue003 S/. Then, .u;v/  is a light edge for the cut. Show that \nthe  professor9s  conjecture  is incorrect  by  giving  a counter example. \n21.1-3  \nShow that if an edge .u;v/  is contained in some minimum spanning tree, then it  is \na light edge crossing some cut of the graph. \n21.1-4  \nGive  a simple  example  of a connected  graph  such  that  the  set  of edges f.u;v/  W \nthere exists a cut .S;V  \ue003 S/  such that .u;v/  is a light edge crossing .S;V  \ue003 S/g \ndoes not form a minimum spanning tree. \n21.1-5  \nLet e be a maximum-weight  edge  on  some  cycle  of connected  graph  G D .V;E/ . \nProve that there is a minimum spanning tree of G 0 D .V;E  \ue003 feg/ that is also a \nminimum spanning tree of G. That is, there is a minimum spanning tree of G that \ndoes not include e. \n21.1-6  \nShow that a graph has a unique minimum spanning tre e if, for every cut of the \ngraph, there is a unique light edge crossing the cu t. Show that the converse is not \ntrue by giving a counterexample. \n21.1-7  \nArgue that if all edge weights of a graph are posit ive, then any subset of edges that \nconnects all vertices and has minimum total weight must be a tree.  Give  an example  \nto show that the same conclusion does not follow if  we allow some weights to be \nnonpositive. 21.2  The  algorithms  of Kruskal  and  Prim  591 \n21.1-8  \nLet T be a minimum spanning tree of a graph G, and let L be the sorted list of the \nedge weights of T . Show that for any other minimum spanning tree T 0 of G, the \nlist L is also the sorted list of edge weights of T 0 . \n21.1-9  \nLet T be a minimum spanning tree of a graph G D .V;E/ , and let V 0 be a subset \nof V . Let T 0 be the subgraph of T induced by V 0 , and let G 0 be the subgraph of G \ninduced by V 0 . Show that if T 0 is connected, then T 0 is a minimum spanning tree \nof G 0 . \n21.1-10  \nGiven  a graph  G and a minimum spanning tree T , suppose that the weight of one \nof the edges in T decreases. Show that T is still a minimum spanning tree for G. \nMore formally, let T be a minimum spanning tree for G with edge weights given \nby weight function w. Choose one edge .x;y/  2 T and a positive number k, and \nde\u00fbne  the  weight  function  w 0 by \nw 0 .u;v/  D ( \nw.u;v/  if .u;v/  \u00a4 .x;y/;  \nw.x;y/  \ue003 k if .u;v/  D .x;y/:  \nShow that T is a minimum spanning tree for G with edge weights given by w 0 . \n? 21.1-11  \nGiven  a graph  G and a minimum spanning tree T , suppose that the weight of one of \nthe edges not in T decreases.  Give  an algorithm  for  \u00fbnding  the  minimum  spannin g \ntree  in the  modi\u00fbed  graph.  \n21.2  The  algorithms  of Kruskal  and  Prim  \nThe  two  minimum-spanning-tree  algorithms  described  in this section elaborate on \nthe  generic  method.  They  each  use  a speci\u00fbc  rule  to determine  a safe  edge  in line  3 \nof GENERIC-MST.  In Kruskal9s  algorithm,  the  set  A is a forest whose vertices are \nall those of the given graph. The safe edge added t o A is always  a lowest-weight  \nedge in the graph that connects two distinct compon ents. In Prim9s  algorithm,  the  \nset A forms a single tree. The safe edge added to A is always  a lowest-weight  edge  \nconnecting the tree to a vertex not in the tree. Bo th algorithms assume that the \ninput graph is connected and represented by adjacen cy lists. 592  Chapter  21  Minimum  Spanning  Trees  \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 2 \n7 6 (a) (b) \n(c) (d) \n(e) \n(g) (f) \n(h) b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 \nFigure  21.4  The  execution  of Kruskal9s  algorithm  on  the  graph  from  Figure  21.1.  Blue  edges  \nbelong to the forest A being grown. The algorithm considers each edge in s orted order by weight. A \nred arrow points to the edge under consideration at  each step of the algorithm. If the edge joins two \ndistinct trees in the forest, it is added to the fo rest, thereby merging the two trees. \nKruskal\u2019s  algorithm  \nKruskal9s  algorithm  \u00fbnds  a safe  edge  to add  to the  growing  forest  by  \u00fbnding,  of all  \nthe edges that connect any two trees in the forest,  an edge .u;v/  with the lowest \nweight. Let C 1 and C 2 denote the two trees that are connected by .u;v/ . Since \n.u;v/  must be a light edge connecting C 1 to some  other  tree,  Corollary  21.2  implies  21.2  The  algorithms  of Kruskal  and  Prim  593 \n(i) (j) \n(k) (l) \n(n) (m) b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 2 \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 2 \n2 \nFigure  21.4,  continued  Further  steps  in the  execution  of Kruskal9s  algorithm.  \nthat .u;v/  is a safe edge for C 1 . Kruskal9s  algorithm  quali\u00fbes  as a greedy  algorithm  \nbecause at each step it adds to the forest an edge with the lowest possible weight. \nLike the algorithm to compute connected components from Section  19.1,  the  \nprocedure  MST-KRUSKAL  on  the  following  page  uses  a disjoint-set  data  structure  \nto maintain several disjoint sets of elements. Each  set contains the vertices in one \ntree of the current forest. The operation F IND-SET.u/  returns a representative \nelement from the set that contains u. Thus, to determine whether two vertices u \nand v belong to the same tree, just test whether F IND-SET.u/  equals F IND-SET.v/. \nTo  combine  trees,  Kruskal9s  algorithm  calls  the  UNION  procedure. \nFigure  21.4  shows  how  Kruskal9s  algorithm  works.  Lines  133  initialize the set A \nto the empty set and create jV j trees, one containing each vertex. The for  loop in \nlines  639  examines  edges  in order  of weight,  from  lowest  to highest. The loop \nchecks, for each edge .u;v/ , whether the endpoints u and v belong to the same \ntree. If they do, then the edge .u;v/  cannot be added to the forest without creating \na cycle,  and  the  edge  is ignored.  Otherwise,  the  two  vertices  belong to different 594  Chapter  21  Minimum  Spanning  Trees  \nMST-KRUSKAL.G;w/  \n1 A D ;  \n2 for  each vertex v 2 G:  V \n3 MAKE-SET .v/  \n4 create a single list of the edges in G:  E \n5 sort the list of edges into monotonically increasin g order by weight w \n6 for  each edge .u;v/  taken from the sorted list in order \n7 if FIND-SET .u/  \u00a4 FIND-SET .v/  \n8 A D A [ f.u;v/ g \n9 UNION.u;v/  \n10  return  A \ntrees.  In this  case,  line  8 adds  the  edge  .u;v/  to A, and line 9 merges the vertices \nin the two trees. \nThe  running  time  of Kruskal9s  algorithm  for  a graph  G D .V;E/  depends on the \nspeci\u00fbc  implementation  of the  disjoint-set  data  structure.  Let9s  assume  that  it uses  \nthe  disjoint-set-forest  implementation  of Section  19.3  with  the  union-by-rank  and  \npath-compression  heuristics,  since  that  is the  asymptotically  fastest  implementa-  \ntion known. Initializing the set A in line  1 takes  O.1/  time, creating a single list of \nedges  in line  4 takes  O.V  C E/  time (which is O.E/  because G is connected), and \nthe  time  to sort  the  edges  in line  5 is O.E  lg E/. (We9ll  account  for  the  cost  of the  \njV j MAKE-SET operations in the for  loop  of lines  233  in a moment.)  The  for  loop \nof lines  639  performs  O.E/  FIND-SET and UNION  operations  on  the  disjoint-set  \nforest. Along with the jV j MAKE-SET operations,  these  disjoint-set  operations  \ntake a total of O..V  C E/\u02db.V//  time, where \u02db is the  very  slowly  growing  func-  \ntion  de\u00fbned  in Section  19.4.  Because  we  assume  that  G is connected, we have \njEj \ue004 jV j \ue003  1, and  so the  disjoint-set  operations  take  O.E\u02db.V//  time. Moreover, \nsince \u02db.jV j/ D O.lg V/  D O.lg E/, the  total  running  time  of Kruskal9s  algorithm  \nis O.E  lg E/. Observing  that  jEj < jV j 2 , we have lg jEj D  O.lg V/, and so we \ncan  restate  the  running  time  of Kruskal9s  algorithm  as O.E  lg V/. \nPrim\u2019s  algorithm  \nLike  Kruskal9s  algorithm,  Prim9s  algorithm  is a special  case  of the  generic  min-  \nimum-spanning-tree  method  from  Section  21.1.  Prim9s  algor ithm operates much \nlike  Dijkstra9s  algorithm  for  \u00fbnding  shortest  paths  in a graph,  which  we9ll  see  in \nSection  22.3.  Prim9s  algorithm  has  the  property  that  the  edges in the set A always \nform  a single  tree.  As  Figure  21.5  shows,  the  tree  starts  from  an arbitrary root \nvertex r and grows until it spans all the vertices in V . Each step adds to the tree A 21.2  The  algorithms  of Kruskal  and  Prim  595 \n(a) (b) \n(c) (d) \n(e) (f) \n(g) (h) \n(i) b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 2 \n7 6 b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 2 \n7 6 \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 2 \n7 6 b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 b \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 \nb \na \nh c \ng i d \nf e 4 \n8 11  8 7 \n9 \n10  14  4 \n2 1 7 6 2 \nFigure  21.5  The  execution  of Prim9s  algorithm  on  the  graph  from  Figure  21.1.  The  root  vertex  \nis a. Blue vertices and edges belong to the tree being grown, and tan vertices have yet to be added \nto the tree. At each step of the algorithm, the ver tices in the tree determine a cut of the graph, and  a \nlight edge crossing the cut is added to the tree. T he edge and vertex added to the tree are highlighte d \nin orange. In the second step (part (c)), for examp le, the algorithm has a choice of adding either \nedge .b;c/  or edge .a;h/  to the tree since both are light edges crossing the  cut. 596  Chapter  21  Minimum  Spanning  Trees  \na light edge that connects A to an isolated  vertex4one  on  which  no  edge  of A is \nincident.  By  Corollary  21.2,  this  rule  adds  only  edges  that  are safe for A. There-  \nfore, when the algorithm terminates, the edges in A form a minimum spanning tree. \nThis  strategy  quali\u00fbes  as greedy  since  at each  step  it adds  to the tree an edge that \ncontributes  the  minimum  amount  possible  to the  tree9s  weigh t. \nIn the  procedure  MST-P RIM below, the connected graph G and the root r of the \nminimum spanning tree to be grown are inputs to the  algorithm. In order  to ef\u00fb-  \nciently select a new edge to add into tree A, the  algorithm  maintains  a min-priority  \nqueue Q of all vertices that are not in the tree, based on a key  attribute. For each \nvertex v, the attribute v: key  is the minimum weight of any edge connecting v to a \nvertex in the tree, where by convention, v: key  D 1  if there is no such edge. The \nattribute v:\ufffd  names the parent of v in the tree. The algorithm implicitly maintains \nthe set A from  GENERIC-MST  as \nA D f.v; v:\ufffd/  W v 2 V \ue003 fr g \ue003  Qg ; \nwhere we interpret the vertices in Q as forming  a set.  When  the  algorithm  termi-  \nnates,  the  min-priority  queue  Q is empty, and thus the minimum spanning tree A \nfor G is \nA D f.v; v:\ufffd/  W v 2 V \ue003 fr gg : \nMST-P RIM.G;w;r/  \n1 for  each vertex u 2 G:  V \n2 u: key  D 1  \n3 u:\ufffd  D NIL \n4 r: key  D 0 \n5 Q D ;  \n6 for  each vertex u 2 G:  V \n7 I NSERT .Q;u/  \n8 while  Q \u00a4 ;  \n9 u D EXTRACT-MIN.Q/  / / add u to the tree \n10  for  each vertex v in G:  Adj\u0152u\ufffd  / / update keys of u9s non-tree  neighbors  \n11  if v 2 Q and w.u;v/<v:  key  \n12  v:\ufffd  D u \n13  v: key  D w.u;v/  \n14  DECREASE-KEY .Q;v;w.u;v//  \nFigure  21.5  shows  how  Prim9s  algorithm  works.  Lines  137  set  the key of each \nvertex to 1  (except for the root r , whose key is set to 0 to make  it the  \u00fbrst  vertex  \nprocessed), set the parent of each vertex to NIL, and  insert  each  vertex  into  the  min-  \npriority queue Q. The  algorithm  maintains  the  following  three-part  loop  invariant: 21.2  The  algorithms  of Kruskal  and  Prim  597 \nPrior to each iteration of the while  loop  of lines  8314,  \n1. A D f.v; v:\ufffd/  W v 2 V \ue003 fr g \ue003  Qg. \n2. The vertices already placed into the minimum spa nning tree are those \nin V \ue003 Q. \n3. For  all  vertices  v 2 Q, if v:\ufffd  \u00a4 NIL, then v: key  < 1  and v: key  is \nthe weight of a light edge .v; v:\ufffd/  connecting v to some vertex already \nplaced into the minimum spanning tree. \nLine  9 identi\u00fbes  a vertex  u 2 Q incident on a light edge that crosses the cut \n.V  \ue003 Q;Q/  (with  the  exception  of the  \u00fbrst  iteration,  in which  u D r due to lines \n437).  Removing  u from the set Q adds it to the set V \ue003 Q of vertices in the \ntree, thus adding the edge .u; u:\ufffd/  to A. The for  loop  of lines  10314  updates  the  \nkey  and \ufffd attributes of every vertex v adjacent to u but not in the tree, thereby \nmaintaining the third part of the loop invariant. W henever line  13  updates  v: key, \nline  14  calls  DECREASE-KEY to inform  the  min-priority  queue  that  v9s key  has  \nchanged. \nThe  running  time  of Prim9s  algorithm  depends  on  the  speci\u00fbc  implementation \nof the  min-priority  queue  Q. You can implement Q with  a binary  min-heap  (see  \nChapter  6),  including  a way  to map  between  vertices  and  their  corresponding heap \nelements. The B UILD-MIN-HEAP procedure  can  perform  lines  537  in O.V/  time. \nIn fact, there is no need to call B UILD-MIN-HEAP. You can just put the key \nof r at the  root  of the  min-heap,  and  because  all  other  keys  are  1, they can go \nanywhere  else  in the  min-heap.  The  body  of the  while  loop executes jV j times, \nand since each E XTRACT-MIN operation takes O.lg V/  time, the total time for \nall calls to E XTRACT-MIN is O.V  lg V/. The for  loop  in lines  10314  executes  \nO.E/  times altogether, since the sum of the lengths of a ll adjacency lists is 2 jEj. \nWithin the for  loop, the test for membership in Q in line  11  can  take  constant  \ntime if you keep a bit for each vertex that indicat es whether it belongs to Q and \nupdate the bit when the vertex is removed from Q. Each call to D ECREASE- \nKEY in line  14  takes  O.lg V/  time.  Thus,  the  total  time  for  Prim9s  algorithm  is \nO.V  lg V C E lg V/  D O.E  lg V/, which is asymptotically the same as for our \nimplementation  of Kruskal9s  algorithm.  \nYou  can  further  improve  the  asymptotic  running  time  of Prim9  s algorithm by \nimplementing  the  min-priority  queue  with  a Fibonacci  heap  (see  page  478).  If a \nFibonacci heap holds jV j elements, an E XTRACT-MIN operation takes O.lg V/  \namortized time and each I NSERT and D ECREASE-KEY operation takes only O.1/  \namortized time. Therefore, by using a Fibonacci hea p to implement  the  min-  \npriority queue Q, the  running  time  of Prim9s  algorithm  improves  to O.E  CV lg V/. 598  Chapter  21  Minimum  Spanning  Trees  \nExercises  \n21.2-1  \nKruskal9s  algorithm  can  return  different  spanning  trees  for the same input graph G, \ndepending on how it breaks ties when the edges are sorted. Show that for each \nminimum spanning tree T of G, there is a way to sort the edges of G in Kruskal9s  \nalgorithm so that the algorithm returns T . \n21.2-2  \nGive  a simple  implementation  of Prim9s  algorithm  that  runs  in O.V  2 / time when \nthe graph G D .V;E/  is represented as an adjacency matrix. \n21.2-3  \nFor a sparse graph G D .V;E/ , where jEj D  \u201a.V/ , is the implementation of \nPrim9s  algorithm  with  a Fibonacci  heap  asymptotically  faster  than  the  binary-heap  \nimplementation?  What  about  for  a dense  graph,  where  jEj D  \u201a.V  2 /? How  \nmust the sizes jEj and jV j be related  for  the  Fibonacci-heap  implementation  to \nbe asymptotically  faster  than  the  binary-heap  implementation?  \n21.2-4  \nSuppose that all edge weights in a graph are intege rs in the range from 1 to jV j. \nHow  fast  can  you  make  Kruskal9s  algorithm  run?  What  if the  edge weights are \nintegers in the range from 1 to W for some constant W ? \n21.2-5  \nSuppose that all edge weights in a graph are intege rs in the range from 1 to jV j. \nHow  fast  can  you  make  Prim9s  algorithm  run?  What  if the  edge  weights are integers \nin the range from 1 to W for some constant W ? \n21.2-6  \nProfessor  Borden  proposes  a new  divide-and-conquer  algori thm for computing \nminimum  spanning  trees,  which  goes  as follows.  Given  a graph  G D .V;E/ , \npartition the set V of vertices into two sets V 1 and V 2 such that jV 1 j and jV 2 j differ \nby at most 1. Let E 1 be the set of edges that are incident only on verti ces in V 1 , and \nlet E 2 be the set of edges that are incident only on verti ces in V 2 . Recursively solve \na minimum-spanning-tree  problem  on  each  of the  two  subgraph s G 1 D .V  1 ;E  1 / \nand G 2 D .V  2 ;E  2 /. Finally,  select  the  minimum-weight  edge  in E that crosses the \ncut .V  1 ;V  2 /, and use this edge to unite the resulting two mini mum spanning trees \ninto a single spanning tree. \nEither argue that the algorithm correctly computes a minimum spanning tree \nof G, or provide an example for which the algorithm fai ls. Problems for Chapter 21 599 \n? 21.2-7  \nSuppose that the edge weights in a graph are unifor mly distributed  over  the  half-  \nopen interval \u01520;1/. Which  algorithm,  Kruskal9s  or Prim9s,  can  you  make  run  \nfaster?  \n? 21.2-8  \nSuppose that a graph G has a minimum spanning tree already computed. How \nquickly can you update the minimum spanning tree up on adding a new vertex and \nincident edges to G? \nProblems  \n21-1  Second-best  minimum  spanning  tree  \nLet G D .V;E/  be an undirected, connected graph whose weight func tion is \nw W E !  R, and suppose that jEj \ue004 jV j and all edge weights are distinct. \nWe  de\u00fbne  a second-best  minimum  spanning  tree  as follows.  Let  T be the set \nof all spanning trees of G, and let T be a minimum spanning tree of G. Then \na second-best  minimum  spanning  tree  is a spanning tree T 0 such that w.T  0 / D \nmin fw.T  00 / W T 00 2 T \ue003 fT gg. \na. Show that the minimum spanning tree is unique, but that the second-best  mini-  \nmum spanning tree need not be unique. \nb. Let T be the minimum spanning tree of G. Prove that G contains some edge \n.u;v/  2 T and some edge .x;y/  \u2026 T such that .T  \ue003 f.u;v/ g/ [ f.x;y/ g is a \nsecond-best  minimum  spanning  tree  of G. \nc. Now let T be any spanning tree of G and, for any two vertices u;v  2 V , \nlet max\u0152u; v\ufffd  denote an edge of maximum weight on the unique simp le path \nbetween u and v in T . Describe an O.V  2 /-time  algorithm  that,  given  T , com-  \nputes max\u0152u; v\ufffd  for all u;v  2 V . \nd. Give  an ef\u00fbcient  algorithm  to compute  the  second-best  minim um spanning tree \nof G. \n21-2  Minimum  spanning  tree  in sparse  graphs  \nFor a very sparse connected graph G D .V;E/ , it is possible to further improve \nupon the O.E  C V lg V/  running  time  of Prim9s  algorithm  with  a Fibonacci  heap  \nby preprocessing G to decrease  the  number  of vertices  before  running  Prim9s  al-  \ngorithm. In particular, for each vertex u, choose  the  minimum-weight  edge  .u;v/  600  Chapter  21  Minimum  Spanning  Trees  \nincident on u, and put .u;v/  into the minimum spanning tree under construction. \nThen,  contract  all  chosen  edges  (see  Section  B.4).  Rather  than contracting these \nedges  one  at a time,  \u00fbrst  identify  sets  of vertices  that  are  united into the same new \nvertex. Then create the graph that would have resul ted from contracting these edges \none at a time, but do so by <renaming= edges accord ing to the sets into which their \nendpoints were placed. Several edges from the origi nal graph might be renamed \nthe same as each other. In such a case, only one ed ge results, and its weight is the \nminimum of the weights of the corresponding origina l edges. \nInitially, set the minimum spanning tree T being constructed to be empty, and \nfor each edge .u;v/  2 E, initialize the two attributes .u;v/:  orig D .u;v/  and \n.u;v/:  c D w.u;v/ . Use the orig attribute to reference the edge from the initial \ngraph that is associated with an edge in the contra cted graph. The c attribute holds \nthe weight of an edge, and as edges are contracted,  it is updated according to the \nabove  scheme  for  choosing  edge  weights.  The  procedure  MST-R EDUCE on the \nfacing page takes inputs G and T , and it returns a contracted graph G 0 with  up-  \ndated attributes orig 0 and c 0 . The procedure also accumulates edges of G into the \nminimum spanning tree T . \na. Let T be the  set  of edges  returned  by  MST-R EDUCE , and let A be the minimum \nspanning tree of the graph G 0 formed  by  the  call  MST-P RIM.G  0 ;c 0 ;r/, where \nc 0 is the weight attribute on the edges of G 0 : E and r is any vertex in G 0 : V . \nProve that T [ f.x;y/:  orig 0 W .x;y/  2 Ag is a minimum spanning tree of G. \nb. Argue that jG 0 : V j \u0dc4 jV j =2. \nc. Show  how  to implement  MST-R EDUCE so that it runs in O.E/  time. ( Hint: \nUse simple data structures.) \nd. Suppose that you run k phases  of MST-R EDUCE , using the output G 0 produced \nby one phase as the input G to the next phase and accumulating edges in T . \nArgue that the overall running time of the k phases is O.kE/ . \ne. Suppose that after running k phases  of MST-R EDUCE , as in part (d), you run \nPrim9s  algorithm  by  calling  MST-P RIM.G  0 ;c 0 ;r/, where G 0 , with  weight  at-  \ntribute c 0 , is returned by the last phase and r is any vertex in G 0 : V . Show how \nto pick k so that the overall running time is O.E  lg lg V/. Argue that your \nchoice of k minimizes the overall asymptotic running time. \nf. For what values of jEj (in terms of jV j) does  Prim9s  algorithm  with  preprocess-  \ning  asymptotically  beat  Prim9s  algorithm  without  preprocessing?  Problems for Chapter 21 601 \nMST-R EDUCE.G;T/  \n1 for  each vertex v 2 G:  V \n2 v: mark D FALSE \n3 MAKE-SET .v/  \n4 for  each vertex u 2 G:  V \n5 if u: mark = = FALSE \n6 choose v 2 G:  Adj\u0152u\ufffd  such that .u;v/:  c is minimized \n7 UNION.u;v/  \n8 T D T [ f.u;v/:  origg \n9 u: mark D TRUE \n10  v: mark D TRUE \n11  G 0 : V D fFIND-SET.v/  W v 2 G:  V g \n12  G 0 : E D ;  \n13  for  each edge .x;y/  2 G:  E \n14  u D FIND-SET.x/  \n15  v D FIND-SET .y/  \n16  if u \u00a4 v \n17  if .u;v/  \u2026 G 0 : E \n18  G 0 : E D G 0 : E [ f.u;v/ g \n19  .u;v/:  orig 0 D .x;y/:  orig \n20 .u;v/:c  0 D .x;y/:  c \n21  elseif  .x;y/:  c <.u;v/:c  0 \n22 .u;v/:  orig 0 D .x;y/:  orig \n23  .u;v/:c  0 D .x;y/:  c \n24  construct adjacency lists G 0 : Adj for G 0 \n25  return  G 0 and T \n21-3  Alternative  minimum-spanning-tree  algorithms  \nConsider the three algorithms M AYBE-MST-A,  MAYBE-MST-B,  and  MAYBE- \nMST-C  on  the  next  page.  Each  one  takes  a connected  graph  and  a w eight function \nas input and returns a set of edges T . For each algorithm, either prove that T is \na minimum spanning tree or prove that T is not necessarily a minimum spanning \ntree.  Also  describe  the  most  ef\u00fbcient  implementation  of each algorithm, regardless \nof whether it computes a minimum spanning tree. \n21-4  Bottleneck  spanning  tree  \nA bottleneck  spanning  tree  T of an undirected graph G is a spanning tree of G \nwhose largest edge weight is minimum over all spann ing trees of G. The value of \nthe  bottleneck  spanning  tree  is the  weight  of the  maximum-we ight edge in T . 602  Chapter  21  Minimum  Spanning  Trees  \nMAYBE-MST-A  .G;w/  \n1 sort the edges into monotonically decreasing order of edge weights w \n2 T D E \n3 for  each edge e, taken in monotonically decreasing order by weight  \n4 if T \ue003 feg is a connected graph \n5 T D T \ue003 feg \n6 return  T \nMAYBE-MST-B  .G;w/  \n1 T D ;  \n2 for  each edge e, taken in arbitrary order \n3 if T [ feg has no cycles \n4 T D T [ feg \n5 return  T \nMAYBE-MST-C  .G;w/  \n1 T D ;  \n2 for  each edge e, taken in arbitrary order \n3 T D T [ feg \n4 if T has a cycle c \n5 let e 0 be a maximum-weight  edge  on  c \n6 T D T \ue003 fe 0 g \n7 return  T \na. Argue that a minimum spanning tree is a bottleneck spanning tree. \nPart  (a)  shows  that  \u00fbnding  a bottleneck  spanning  tree  is no  harder  than  \u00fbnding  \na minimum spanning tree. In the remaining parts, yo u will show how  to \u00fbnd  a \nbottleneck spanning tree in linear time. \nb. Give  a linear-time  algorithm  that,  given  a graph  G and an integer b, determines \nwhether the value of the bottleneck spanning tree i s at most b. \nc. Use  your  algorithm  for  part  (b)  as a subroutine  in a linear-ti me algorithm for the \nbottleneck-spanning-tree  problem.  (Hint: You might want to use a subroutine \nthat  contracts  sets  of edges,  as in the  MST-R EDUCE procedure described in \nProblem  21-2.)  Notes for Chapter 21 603 \nChapter  notes  \nTarjan  [429]  surveys  the  minimum-spanning-tree  problem  and provides excellent \nadvanced  material.  Graham  and  Hell  [198]  compiled  a history  of the  minimum-  \nspanning-tree  problem.  \nTarjan  attributes  the  \u00fbrst  minimum-spanning-tree  algorithm  to a 1926  paper  by  \nO.  Bor\u02da  uvka.  Bor\u02da  uvka9s  algorithm  consists  of running  O.lg V/  iterations of the \nprocedure  MST-R EDUCE described  in Problem  21-2.  Kruskal9s  algorithm  was  \nreported  by  Kruskal  [272]  in 1956.  The  algorithm  commonly  known  as Prim9s  \nalgorithm  was  indeed  invented  by  Prim  [367],  but  it was  also  invented earlier by \nV. Jarn\u00b4  \u0131k in 1930.  \nWhen jEj D  \ufffd.V  lg V/, Prim9s  algorithm,  implemented  with  a Fibonacci  heap,  \nruns in O.E/  time. For sparser graphs, using a combination of th e ideas from \nPrim9s  algorithm,  Kruskal9s  algorithm,  and  Bor\u02da  uvka9s  algorithm,  together  with  ad-  \nvanced  data  structures,  Fredman  and  Tarjan  [156]  give  an algorithm that runs in \nO.E  lg \ue003 V/  time.  Gabow,  Galil,  Spencer,  and  Tarjan  [165]  improved  this  algo-  \nrithm to run in O.E  lg lg \ue003 V/  time.  Chazelle  [83]  gives  an algorithm  that  runs  \nin O.E  y \u02db.E;V//  time, where y \u02db.E;V/  is the  functional  inverse  of Ackermann9s  \nfunction.  (See  the  chapter  notes  for  Chapter  19  for  a brief  discussion  of Acker-  \nmann9s  function  and  its  inverse.)  Unlike  previous  minimum-spanning-tree  algo-  \nrithms,  Chazelle9s  algorithm  does  not  follow  the  greedy  method.  Pettie  and  Ra-  \nmachandran  [356]  give  an algorithm  based  on  precomputed  <MS T decision trees= \nthat also runs in O.E  y \u02db.E;V//  time. \nA related problem is spanning-tree  veri\u00fbcation : given a graph G D .V;E/  and \na tree T \u0dc2 E, determine whether T is a minimum spanning tree of G. King  [254]  \ngives  a linear-time  algorithm  to verify  a spanning  tree,  building on earlier work of \nKoml\u00b4  os [269]  and  Dixon,  Rauch,  and  Tarjan  [120].  \nThe above algorithms are all deterministic and fall  into the comparison-based  \nmodel  described  in Chapter  8. Karger,  Klein,  and  Tarjan  [243 ] give a randomized \nminimum-spanning-tree  algorithm  that  runs  in O.V  C E/  expected time. This \nalgorithm  uses  recursion  in a manner  similar  to the  linear-t ime selection algorithm \nin Section  9.3:  a recursive  call  on  an auxiliary  problem  identi\u00fbes  a subset  of the  \nedges E 0 that cannot be in any minimum spanning tree. Anothe r recursive call \non E \ue003 E 0 then  \u00fbnds  the  minimum  spanning  tree.  The  algorithm  also  uses  ideas \nfrom  Bor\u02da  uvka9s  algorithm  and  King9s  algorithm  for  spanning-tree  veri\u00fbcation.  \nFredman  and  Willard  [158]  showed  how  to \u00fbnd  a minimum  spannin g tree in \nO.V  CE/  time using a deterministic algorithm that is not co mparison based. Their \nalgorithm assumes that the data are b-bit  integers  and  that  the  computer  memory  \nconsists of addressable b-bit  words.  22  Single-Source  Shortest  Paths  \nSuppose  that  you  need  to drive  from  Oceanside,  New  York,  to Oceanside,  Califor-  \nnia,  by  the  shortest  possible  route.  Your  GPS  contains  infor mation about the entire \nroad network of the United States, including the ro ad distance between each pair \nof adjacent  intersections.  How  can  your  GPS  determine  this  shortest  route?  \nOne  possible  way  is to enumerate  all  the  routes  from  Oceansid e, New York, to \nOceanside,  California,  add  up  the  distances  on  each  route,  and select the shortest. \nBut  even  disallowing  routes  that  contain  cycles,  your  GPS  would need to examine \nan enormous number of possibilities, most of which are simply not  worth  consid-  \nering. For example, a route that passes through Mia mi, Florida, is a poor choice, \nbecause Miami is several hundred miles out of the w ay. \nThis  chapter  and  Chapter  23  show  how  to solve  such  problems  ef\u00fbciently.  The  \ninput to a shortest-paths  problem  is a weighted, directed graph G D .V;E/ , \nwith a weight function w W E !  R mapping  edges  to real-valued  weights.  The  \nweight  w.p/  of path p D hv 0 ;v  1 ;:::;v  k i is the  sum  of the  weights  of its  con-  \nstituent edges: \nw.p/  D k X  \ni D1 w.v  i \ue0021 ;v  i /: \nWe  de\u00fbne  the  shortest-path  weight  \u0131.u;v/  from u to v by \n\u0131.u;v/  D ( \nminfw.p/  W u p \u2740  vg if there is a path from u to v;  \n1  otherwise : \nA shortest  path  from vertex u to vertex v is then  de\u00fbned  as any  path  p with \nweight w.p/  D \u0131.u;v/ . \nIn the  example  of going  from  Oceanside,  New  York,  to Oceansid e, California, \nyour  GPS  models  the  road  network  as a graph:  vertices  represe nt intersections, \nedges represent road segments between intersections , and edge weights represent \nroad  distances.  The  goal  is to \u00fbnd  a shortest  path  from  a given  intersection in Chapter  22  Single-Source  Shortest  Paths  605 \nOceanside,  New  York  (say,  Brower  Avenue  and  Skillman  Avenue)  to a given  inter-  \nsection  in Oceanside,  California  (say,  Topeka  Street  and  South Horne Street). \nEdge weights can represent metrics other than dista nces, such as time, cost, \npenalties, loss, or any other quantity that accumul ates linearly along a path and \nthat you want to minimize. \nThe  breadth-\u00fbrst-search  algorithm  from  Section  20.2  is a shortest-paths  algo-  \nrithm that works on unweighted graphs, that is, gra phs in which each edge has unit \nweight.  Because  many  of the  concepts  from  breadth-\u00fbrst  search arise in the study \nof shortest paths in weighted graphs, you might wan t to review Section 20.2 before \nproceeding. \nVariants  \nThis chapter focuses on the single-source  shortest-paths  problem : given a graph \nG D .V;E/, \u00fbnd  a shortest  path  from  a given  source  vertex  s 2 V to every \nvertex v 2 V . The  algorithm  for  the  single-source  problem  can  solve  many  other \nproblems, including the following variants. \nSingle-destination  shortest-paths  problem:  Find a shortest path to a given des-  \ntination  vertex  t from each vertex v. By reversing the direction of each edge in \nthe  graph,  you  can  reduce  this  problem  to a single-source  problem. \nSingle-pair  shortest-path  problem:  Find a shortest path from u to v for given \nvertices u and v. If you  solve  the  single-source  problem  with  source  vertex  u, \nyou solve this problem also. Moreover, all known al gorithms for this problem \nhave  the  same  worst-case  asymptotic  running  time  as the  best  single-source  \nalgorithms. \nAll-pairs  shortest-paths  problem:  Find a shortest path from u to v for every \npair of vertices u and v. Although you can solve this problem by running a \nsingle-source  algorithm  once  from  each  vertex,  you  often  can solve it faster. \nAdditionally, its structure is interesting in its o wn right. Chapter  23  addresses  \nthe  all-pairs  problem  in detail.  \nOptimal  substructure  of a shortest  path  \nShortest-paths  algorithms  typically  rely  on  the  property  that  a shortest  path  be-  \ntween two vertices contains other shortest paths wi thin it. (The  Edmonds-Karp  \nmaximum-\u00fcow  algorithm  in Chapter  24  also  relies  on  this  property.) Recall that \noptimal substructure is one of the key indicators t hat dynamic programming  (Chap-  \nter  14)  and  the  greedy  method  (Chapter  15)  might  apply.  Dijkstra9s  algorithm,  \nwhich  we  shall  see  in Section  22.3,  is a greedy  algorithm,  and  the  Floyd-Warshall  \nalgorithm,  which  \u00fbnds  a shortest  path  between  every  pair  of vertices  (see  Sec-  606  Chapter  22  Single-Source  Shortest  Paths  \ntion  23.2),  is a dynamic-programming  algorithm.  The  follow ing lemma states the \noptimal-substructure  property  of shortest  paths  more  precisely. \nLemma  22.1  (Subpaths  of shortest  paths  are  shortest  paths)  \nGiven  a weighted,  directed  graph  G D .V;E/  with weight function w W E !  R, \nlet p D hv 0 ;v  1 ;:::;v  k i be a shortest path from vertex v 0 to vertex v k and, for any \ni and j such that 0 \u0dc4 i \u0dc4 j \u0dc4 k, let p ij D hv i ;v  i C1 ;:::;v  j i be the subpath of p \nfrom vertex v i to vertex v j . Then, p ij is a shortest path from v i to v j . \nProof  Decompose path p into v 0 p 0i  \u2740  v i p ij  \u2740  v j p jk  \u2740  v k , so that w.p/  D w.p  0i  / C \nw.p  ij / C w.p  jk  /. Now, assume that there is a path p 0 \nij from v i to v j with weight \nw.p  0 \nij / < w.p  ij /. Then, v 0 p 0i  \u2740  v i p 0 \nij  \u2740  v j p jk  \u2740  v k is a path from v 0 to v k whose \nweight w.p  0i  / C w.p  0 \nij / C w.p  jk  / is less than w.p/, which  contradicts  the  as-  \nsumption that p is a shortest path from v 0 to v k . \nNegative-weight  edges  \nSome  instances  of the  single-source  shortest-paths  proble m may include edges \nwhose weights are negative. If the graph G D .V;E/  contains  no  negative-  \nweight cycles reachable from the source s , then for all v 2 V , the  shortest-path  \nweight \u0131.s;v/  remains  well  de\u00fbned,  even  if it has  a negative  value.  If the  graph \ncontains  a negative-weight  cycle  reachable  from  s , however,  shortest-path  weights  \nare  not  well  de\u00fbned.  No  path  from  s to a vertex  on  the  cycle  can  be a short-  \nest  path4you  can  always  \u00fbnd  a path  with  lower  weight  by  follow ing the proposed \n<shortest=  path  and  then  traversing  the  negative-weight  cycle.  If there  is a negative-  \nweight cycle on some path from s to v, we  de\u00fbne  \u0131.s;v/  D \ue0031 . \nFigure  22.1  illustrates  the  effect  of negative  weights  and  negative-weight  cy-  \ncles  on  shortest-path  weights.  Because  there  is only  one  path from s to a (the \npath hs;ai), we have \u0131.s;a/  D w.s;a/  D 3. Similarly, there is only one path \nfrom s to b, and so \u0131.s;b/  D w.s;a/  C w.a;b/  D 3 C .\ue0034/ D \ue0031. There are \nin\u00fbnitely  many  paths  from  s to c : hs;c  i, hs;c;d;c  i, hs;c;d;c;d;c  i, and so on. \nBecause the cycle hc;d;c  i has weight 6 C .\ue0033/ D 3>0 , the shortest path from s \nto c is hs;c  i, with weight \u0131.s;c/  D w.s;c/  D 5, and the shortest path from s to d \nis hs;c;d  i, with weight \u0131.s;d/  D w.s;c/  C w.c;d/  D 11. Analogously, there \nare  in\u00fbnitely  many  paths  from  s to e: hs;ei, hs;e;f;e i, hs;e;f;e;f;e i, and so \non. Because the cycle he;f;e i has weight 3 C .\ue0036/ D \ue0033 < 0 , however, there \nis no shortest path from s to e. By  traversing  the  negative-weight  cycle  he;f;e i \narbitrarily  many  times,  you  can  \u00fbnd  paths  from  s to e with arbitrarily large negative \nweights, and so \u0131.s;e/  D \ue0031 . Similarly, \u0131.s;f/  D \ue0031 . Because g is reachable \nfrom f , you  can  also  \u00fbnd  paths  with  arbitrarily  large  negative  weig hts from s to g, Chapter  22  Single-Source  Shortest  Paths  607 \n5 c d 6 \n33  \n\u2013\u221e e \n\u2013\u221e f 3 \n36  3 a \n31  b \n0 s \n\u2013\u221e g 34  \n5 3 \n2 8 4 \n7 \u221e h \n\u221e i \n2 \n\u221e \nj 38  3 11  \nFigure  22.1  Negative  edge  weights  in a directed  graph.  The  shortest-pat h weight from source s \nappears within each vertex. Because vertices e and f form  a negative-weight  cycle  reachable  from  s , \nthey  have  shortest-path  weights  of \ue0031. Because vertex g is reachable  from  a vertex  whose  shortest-  \npath weight is \ue0031, it, too,  has  a shortest-path  weight  of \ue0031. Vertices such as h, i , and j are not \nreachable from s , and  so their  shortest-path  weights  are  1, even  though  they  lie  on  a negative-weight  \ncycle. \nand so \u0131.s;g/  D \ue0031 . Vertices h, i , and j also  form  a negative-weight  cycle.  They  \nare not reachable from s , however, and so \u0131.s;h/  D \u0131.s;i/  D \u0131.s;j/  D 1 . \nSome  shortest-paths  algorithms,  such  as Dijkstra9s  algori thm, assume that all \nedge weights in the input graph are nonnegative, as  in a road network.  Others,  such  \nas the  Bellman-Ford  algorithm,  allow  negative-weight  edge s in the input graph and \nproduce  a correct  answer  as long  as no  negative-weight  cycle s are reachable from \nthe  source.  Typically,  if there  is such  a negative-weight  cycle, the algorithm can \ndetect and report its existence. \nCycles  \nCan  a shortest  path  contain  a cycle?  As  we  have  just  seen,  it cannot contain a \nnegative-weight  cycle.  Nor  can  it contain  a positive-weight  cycle,  since  remov-  \ning the cycle from the path produces a path with th e same source and destination \nvertices and a lower path weight. That is, if p D hv 0 ;v  1 ;:::;v  k i is a path and \nc D hv i ;v  i C1 ;:::;v  j i is a positive-weight  cycle  on  this  path  (so  that  v i D v j and \nw.c/  > 0), then the path p 0 D hv 0 ;v  1 ;:::;v  i ;v  j C1 ;v  j C2 ;:::;v  k i has weight \nw.p  0 / D w.p/  \ue003 w.c/<w.p/ , and so p cannot be a shortest path from v 0 to v k . \nThat leaves only 0-weight  cycles.  You  can  remove  a 0-weight  cycle  from  any  \npath to produce another path whose weight is the sa me. Thus, if there is a shortest \npath from a source vertex s to a destination vertex v that contains a 0-weight  cycle,  \nthen there is another shortest path from s to v without this cycle. As long as a \nshortest path has 0-weight  cycles,  you  can  repeatedly  remove  these  cycles  from  the \npath  until  you  have  a shortest  path  that  is cycle-free.  There fore, without loss of 608  Chapter  22  Single-Source  Shortest  Paths  \ngenerality, assume that shortest paths have no cycl es, that is, they are simple paths. \nSince any acyclic path in a graph G D .V;E/  contains at most jV j distinct vertices, \nit also contains at most jV j \ue003  1 edges. Assume, therefore, that any shortest path \ncontains at most jV j \ue003  1 edges. \nRepresenting  shortest  paths  \nIt is usually  not  enough  to compute  only  shortest-path  weigh ts. Most applications \nof shortest paths need to know the vertices on shor test paths as well. For example, if \nyour  GPS  told  you  the  distance  to your  destination  but  not  how  to get there, it would \nnot be terribly useful. We represent shortest paths  similarly to how we represented \nbreadth-\u00fbrst  trees  in Section  20.2.  Given  a graph  G D .V;E/ , maintain for each \nvertex v 2 V a predecessor  v:\ufffd  that is either another vertex or NIL. The  shortest-  \npaths algorithms in this chapter set the \ufffd attributes so that the chain of predecessors \noriginating at a vertex v runs backward along a shortest path from s to v. Thus, \ngiven a vertex v for which v:\ufffd  \u00a4 NIL, the procedure P RINT-PATH.G;s;v/  from \nSection 20.2 prints a shortest path from s to v. \nIn the  midst  of executing  a shortest-paths  algorithm,  howev er, the \ufffd values might \nnot indicate shortest paths. The predecessor  subgraph  G \ue003 D .V  \ue003 ;E  \ue003 / induced by \nthe \ufffd values  is de\u00fbned  the  same  for  single-source  shortest  paths  as for  breadth-\u00fbrst  \nsearch  in equations  (20.2)  and  (20.3)  on  page  561:  \nV \ue003 D fv 2 V W v:\ufffd  \u00a4 NILg [ fs g ; \nE \ue003 D f .v:\ufffd; v/  2 E W v 2 V \ue003 \ue003 fs gg : \nWe9ll  prove  that  the  \ufffd values produced by the algorithms in this chapter h ave \nthe property that at termination G \ue003 is a <shortest-paths  tree=4informally,  a rooted  \ntree containing a shortest path from the source s to every vertex that is reachable \nfrom s . A shortest-paths  tree  is like  the  breadth-\u00fbrst  tree  from  Section 20.2, but it \ncontains  shortest  paths  from  the  source  de\u00fbned  in terms  of edge weights instead of \nnumbers of edges. To be precise, let G D .V;E/  be a weighted, directed graph \nwith weight function w W E !  R, and assume that G contains  no  negative-weight  \ncycles reachable from the source vertex s 2 V , so that shortest paths are well \nde\u00fbned.  A shortest-paths  tree  rooted at s is a directed subgraph G 0 D .V  0 ;E  0 /, \nwhere V 0 \u0dc2 V and E 0 \u0dc2 E, such that \n1. V 0 is the set of vertices reachable from s in G, \n2. G 0 forms a rooted tree with root s , and \n3. for  all  v 2 V 0 , the unique simple path from s to v in G 0 is a shortest path from s \nto v in G. Chapter  22  Single-Source  Shortest  Paths  609 \n(a) (b) (c) 0 6 \n6 7 2 1 2 4 3 \n5 3 s t x \ny z 0 6 \n6 7 2 1 2 4 3 \n5 3 s t x \ny z 3 9 \n5 11  0 6 \n6 7 2 1 2 4 3 \n5 3 s t x \ny z 3 9 \n5 11  3 9 \n5 11  \nFigure  22.2  (a)  A weighted,  directed  graph  with  shortest-path  weights  from  source s . (b)  The blue \nedges  form  a shortest-paths  tree  rooted  at the  source  s . (c)  Another  shortest-paths  tree  with  the  same  \nroot. \nShortest paths are not necessarily unique, and neit her are shortest-paths  trees.  \nFor example, Figure 22.2 shows a weighted, directed  graph and two  shortest-paths  \ntrees with the same root. \nRelaxation  \nThe algorithms in this chapter use the technique of  relaxation . For each vertex \nv 2 V , the  single-source  shortest  paths  algorithms  maintain  an attribute v: d, which \nis an upper bound on the weight of a shortest path from source s to v. We call v: d a \nshortest-path  estimate. To  initialize  the  shortest-path  estimates  and  predecesso rs, \ncall the \u201a.V/-time  procedure  I NITIALIZE-SINGLE-SOURCE . After initialization, \nwe have v:\ufffd  D NIL for all v 2 V , s: d D 0 and v: d D 1  for v 2 V \ue003 fs g. \nI NITIALIZE-SINGLE-SOURCE  .G;s/  \n1 for  each vertex v 2 G:  V \n2 v: d D 1  \n3 v:\ufffd  D NIL \n4 s: d D 0 \nThe process of relaxing  an edge .u;v/  consists of testing whether going through \nvertex u improves the shortest path to vertex v found so far and, if so, updating \nv: d and v:\ufffd  . A relaxation  step  might  decrease  the  value  of the  shortest-path  esti-  \nmate v: d and update v9s predecessor  attribute  v:\ufffd  . The R ELAX procedure on the \nfollowing page performs a relaxation step on edge .u;v/  in O.1/  time.  Figure  22.3  \nshows two examples of relaxing an edge, one in whic h a shortest-path  estimate  \ndecreases and one in which no estimate changes. 610  Chapter  22  Single-Source  Shortest  Paths  \nu \n5 9 2 \nu \n5 7 2 \n(a) (b) u \n5 6 2 \nu \n5 6 2 v v \nv v \nRELAX.u;v;w/  RELAX.u;v;w/  \nFigure  22.3  Relaxing an edge .u;v/  with weight w.u;v/  D 2. The  shortest-path  estimate  of each  \nvertex appears within the vertex. (a)  Because v: d > u: d C w.u;v/  prior to relaxation, the value \nof v: d decreases. (b)  Since we have v: d \u0dc4 u: d C w.u;v/  before relaxing the edge, the relaxation \nstep leaves v: d unchanged. \nRELAX.u;v;w/  \n1 if v: d >u:  d C w.u;v/  \n2 v: d D u: d C w.u;v/  \n3 v:\ufffd  D u \nEach algorithm in this chapter calls I NITIALIZE-SINGLE-SOURCE  and  then  re-  \npeatedly relaxes edges. 1 Moreover,  relaxation  is the  only  means  by  which  shortest-  \npath estimates and predecessors change. The algorit hms in this chapter differ in \nhow many times they relax each edge and the order i n which they relax  edges.  Dijk-  \nstra9s  algorithm  and  the  shortest-paths  algorithm  for  directed acyclic graphs relax \neach  edge  exactly  once.  The  Bellman-Ford  algorithm  relaxes  each edge jV j \ue003  1 \ntimes. \nProperties  of shortest  paths  and  relaxation  \nTo  prove  the  algorithms  in this  chapter  correct,  we9ll  appea l to several properties \nof shortest paths and relaxation. We state these pr operties here,  and  Section  22.5  \nproves them formally. For your reference, each prop erty stated here includes the \nappropriate  lemma  or corollary  number  from  Section  22.5.  The  latter  \u00fbve  of these  \nproperties,  which  refer  to shortest-path  estimates  or the  predecessor  subgraph,  im-  \n1 It may seem strange that the term <relaxation= is u sed for an operation that tightens an upper bound. \nThe use of the term is historical. The outcome of a  relaxation step can be viewed as a relaxation of \nthe constraint v: d \u0dc4 u: d C w.u;v/, which,  by  the  triangle  inequality  (Lemma  22.10  on  page  633) , \nmust  be satis\u00fbed  if u: d D \u0131.s;u/  and v: d D \u0131.s;v/ . That is, if v: d \u0dc4 u: d C w.u;v/ , there is no \n<pressure= to satisfy this constraint, so the const raint is <relaxed.= Chapter  22  Single-Source  Shortest  Paths  611 \nplicitly assume that the graph is initialized with a call to I NITIALIZE-SINGLE- \nSOURCE.G;s/  and  that  the  only  way  that  shortest-path  estimates  and  the  prede-  \ncessor subgraph change are by some sequence of rela xation steps. \nTriangle  inequality  (Lemma  22.10)  \nFor any edge .u;v/  2 E, we have \u0131.s;v/  \u0dc4 \u0131.s;u/  C w.u;v/ . \nUpper-bound  property  (Lemma  22.11)  \nWe always have v: d \ue004 \u0131.s;v/  for all vertices v 2 V , and once v: d achieves the \nvalue \u0131.s;v/ , it never changes. \nNo-path  property  (Corollary  22.12)  \nIf there is no path from s to v, then we always have v: d D \u0131.s;v/  D 1 . \nConvergence  property  (Lemma  22.14)  \nIf s \u2740  u !  v is a shortest path in G for some u;v  2 V , and if u: d D \u0131.s;u/  at \nany time prior to relaxing edge .u;v/ , then v: d D \u0131.s;v/  at all times afterward. \nPath-relaxation  property  (Lemma  22.15)  \nIf p D hv 0 ;v  1 ;:::;v  k i is a shortest path from s D v 0 to v k , and the edges of p \nare relaxed in the order .v 0 ;v  1 /;.v  1 ;v  2 /;:::;.v  k\ue0021 ;v  k /, then v k : d D \u0131.s;v  k /. \nThis property holds regardless of any other relaxat ion steps that occur, even if \nthey are intermixed with relaxations of the edges o f p. \nPredecessor-subgraph  property  (Lemma  22.17)  \nOnce  v: d D \u0131.s;v/  for all v 2 V , the  predecessor  subgraph  is a shortest-paths  \ntree rooted at s . \nChapter  outline  \nSection  22.1  presents  the  Bellman-Ford  algorithm,  which  solves  the  single-source  \nshortest-paths  problem  in the  general  case  in which  edges  can have negative weight. \nThe  Bellman-Ford  algorithm  is remarkably  simple,  and  it has  the  further  bene\u00fbt  \nof detecting  whether  a negative-weight  cycle  is reachable  from  the  source.  Sec-  \ntion  22.2  gives  a linear-time  algorithm  for  computing  short est paths from a single \nsource  in a directed  acyclic  graph.  Section  22.3  covers  Dijkstra9s  algorithm,  which  \nhas  a lower  running  time  than  the  Bellman-Ford  algorithm  but  requires the edge \nweights  to be nonnegative.  Section  22.4  shows  how  to use  the  Bellman-Ford  algo-  \nrithm to solve a special case of linear programming . Finally , Section  22.5  proves  \nthe properties of shortest paths and relaxation sta ted above. \nThis  chapter  does  arithmetic  with  in\u00fbnities,  and  so we  need  some conventions \nfor when 1  or \ue0031  appears in an arithmetic expression. We assume that  for any \nreal number a \u00a4 \ue0031 , we have a C 1 D 1 C  a D 1 . Also, to make our \nproofs  hold  in the  presence  of negative-weight  cycles,  we  assume that for any real \nnumber a \u00a4 1 , we have a C .\ue0031/ D .\ue0031/ C a D \ue0031 . 612  Chapter  22  Single-Source  Shortest  Paths  \nAll algorithms in this chapter assume that the dire cted graph G is stored in the \nadjacency-list  representation.  Additionally,  stored  with each edge is its weight, so \nthat  as each  algorithm  traverses  an adjacency  list,  it can  \u00fbnd edge weights in O.1/  \ntime per edge. \n22.1  The  Bellman-Ford  algorithm  \nThe Bellman-Ford  algorithm  solves  the  single-source  shortest-paths  problem  in \nthe  general  case  in which  edge  weights  may  be negative.  Given  a weighted,  di-  \nrected graph G D .V;E/  with source vertex s and weight function w W E !  R, \nthe  Bellman-Ford  algorithm  returns  a boolean  value  indicat ing whether there is a \nnegative-weight  cycle  that  is reachable  from  the  source.  If there is such a cycle, the \nalgorithm indicates that no solution exists. If the re is no such cycle, the algorithm \nproduces the shortest paths and their weights. \nThe procedure B ELLMAN-FORD  relaxes  edges,  progressively  decreasing  an es-  \ntimate v: d on the weight of a shortest path from the source s to each vertex v 2 V \nuntil  it achieves  the  actual  shortest-path  weight  \u0131.s;v/ . The algorithm returns TRUE \nif and  only  if the  graph  contains  no  negative-weight  cycles  that are reachable from \nthe source. \nBELLMAN-FORD  .G;w;s/  \n1 I NITIALIZE-SINGLE-SOURCE  .G;s/  \n2 for  i D 1 to jG:  V j \ue003  1 \n3 for  each edge .u;v/  2 G:  E \n4 RELAX.u;v;w/  \n5 for  each edge .u;v/  2 G:  E \n6 if v: d >u:  d C w.u;v/  \n7 return  FALSE \n8 return  TRUE \nFigure  22.4  shows  the  execution  of the  Bellman-Ford  algorit hm on a graph \nwith 5 vertices. After initializing the d and \ufffd values  of all  vertices  in line  1, \nthe algorithm makes jV j \ue003  1 passes over the edges of the graph. Each pass is \none iteration of the for  loop  of lines  234  and  consists  of relaxing  each  edge  of the  \ngraph  once.  Figures  22.4(b)3(e)  show  the  state  of the  algori thm after each of the \nfour passes over the edges. After making jV j \ue003  1 passes,  lines  538  check  for  a \nnegative-weight  cycle  and  return  the  appropriate  boolean  value.  (We9ll  see  a little  \nlater why this check works.) 22.1 The Bellman-Ford algorithm 613 \n(a) (b) (c) \n(d) 0 5 \n9 7 8 6 \n7 \n(e) t x \ns \ny z 34  33  \u20132 2 \n7 4 \n\u20132 2 0 5 \n9 7 8 6 \n7 t x \ns \ny z 34  33  \u20132 2 \n7 4 \n2 2 0 5 \n9 7 8 6 \n7 t x \ns \ny z 34  33  \u20132 6 \n7 4 \n2 2 0 5 \n9 7 8 6 \n7 t x \ns \ny z 34  33  \u20132 6 \n7 \u221e \n\u221e 2 0 5 \n9 7 8 6 \n7 t x \ns \ny z 34  33  \u20132 \u221e \n\u221e 2 \u221e \n\u221e \nFigure  22.4  The  execution  of the  Bellman-Ford  algorithm.  The  source  is vertex s . The d \nvalues appear within the vertices, and blue edges i ndicate predecessor values: if edge .u;v/  \nis blue, then v:\ufffd  D u. In this particular example, each pass relaxes the  edges in the order \n.t;x/;.t;y/;.t;\u00b4/;.x;t/;.y;x/;.y;\u00b4/;.\u00b4;x/;.\u00b4;s/;.s; t/;.s;y/ . (a)  The situation just before the \n\u00fbrst  pass  over  the  edges.  (b)\u2013(e)  The situation after each successive pass over the e dges. Vertices \nwhose  shortest-path  estimates  and  predecessors  have  chang ed due to a pass are highlighted in orange. \nThe d and \ufffd values  in part  (e)  are  the  \u00fbnal  values.  The  Bellman-Ford  algorithm returns TRUE in this \nexample. \nThe  Bellman-Ford  algorithm  runs  in O.V  2 C VE/  time  when  the  graph  is rep-  \nresented by adjacency lists, since the initializati on in line 1 takes  \u201a.V/  time, each \nof the jV j \ue003  1 passes  over  the  edges  in lines  234  takes  \u201a.V  C E/  time  (examin-  \ning jV j adjacency  lists  to \u00fbnd  the  jEj edges), and the for  loop  of lines  537  takes  \nO.V  C E/  time. Fewer than jV j \ue003  1 passes  over  the  edges  sometimes  suf\u00fbce  (see  \nExercise  22.1-3),  which  is why  we  say  O.V  2 C VE/  time, rather than \u201a.V  2 C VE/  \ntime. In the frequent case where jEj D  \ufffd.V  /, we can express this running time \nas O.VE/. Exercise  22.1-5  asks  you  to make  the  Bellman-Ford  algorith m run in \nO.VE/  time even when jEj D  o.V/ . \nTo  prove  the  correctness  of the  Bellman-Ford  algorithm,  we  start by showing that \nif there  are  no  negative-weight  cycles,  the  algorithm  computes  correct  shortest-path  \nweights for all vertices reachable from the source.  614  Chapter  22  Single-Source  Shortest  Paths  \nLemma  22.2  \nLet G D .V;E/  be a weighted, directed graph with source vertex s and weight \nfunction w W E !  R, and assume that G contains  no  negative-weight  cycles  that  \nare reachable from s . Then, after the jV j \ue003  1 iterations of the for  loop  of lines  234  \nof B ELLMAN-FORD, v: d D \u0131.s;v/  for all vertices v that are reachable from s . \nProof  We  prove  the  lemma  by  appealing  to the  path-relaxation  property.  Con-  \nsider any vertex v that is reachable from s , and let p D hv 0 ;v  1 ;:::;v  k i, where \nv 0 D s and v k D v, be any shortest path from s to v. Because shortest paths are \nsimple, p has at most jV j \ue003  1 edges, and so k \u0dc4 jV j \ue003  1. Each of the jV j \ue003  1 itera-  \ntions of the for  loop  of lines  234  relaxes  all  jEj edges. Among the edges relaxed in \nthe i th iteration, for i D 1;2;:::;k , is .v i \ue0021 ;v  i /. By  the  path-relaxation  property,  \ntherefore, v: d D v k : d D \u0131.s;v  k / D \u0131.s;v/ . \nCorollary  22.3  \nLet G D .V;E/  be a weighted, directed graph with source vertex s and weight \nfunction w W E !  R. Then, for each vertex v 2 V , there is a path from s to v if \nand only if B ELLMAN-FORD  terminates with v: d < 1  when it is run on G. \nProof  The  proof  is left  as Exercise  22.1-2.  \nTheorem  22.4  (Correctness  of the  Bellman-Ford  algorithm)  \nLet B ELLMAN-FORD  be run on a weighted, directed graph G D .V;E/  with \nsource vertex s and weight function w W E !  R. If G contains  no  negative-weight  \ncycles that are reachable from s , then the algorithm returns TRUE , v: d D \u0131.s;v/  \nfor all vertices v 2 V , and the predecessor subgraph G \ue003 is a shortest-paths  tree  \nrooted at s . If G does  contain  a negative-weight  cycle  reachable  from  s , then the \nalgorithm returns FALSE . \nProof  Suppose that graph G contains  no  negative-weight  cycles  that  are  reach-  \nable from the source s . We  \u00fbrst  prove  the  claim  that  at termination,  v: d D \u0131.s;v/  \nfor all vertices v 2 V . If vertex v is reachable from s , then Lemma 22.2 proves this \nclaim. If v is not reachable from s , then  the  claim  follows  from  the  no-path  prop-  \nerty.  Thus,  the  claim  is proven.  The  predecessor-subgraph  property, along with the \nclaim, implies that G \ue003 is a shortest-paths  tree.  Now  we  use  the  claim  to show  that  \nBELLMAN-FORD  returns TRUE . At termination, for all edges .u;v/  2 E we have \nv: d D \u0131.s;v/  \n\u0dc4 \u0131.s;u/  C w.u;v/  (by the triangle inequality) \nD u: d C w.u;v/;  22.1 The Bellman-Ford algorithm 615 \nand  so none  of the  tests  in line  6 causes  BELLMAN-FORD  to return FALSE. There-  \nfore, it returns TRUE . \nNow, suppose that graph G contains  a negative-weight  cycle  reachable  from  the  \nsource s . Let this cycle be c D hv 0 ;v  1 ;:::;v  k i, where v 0 D v k , in which case we \nhave \nk X  \ni D1 w.v  i \ue0021 ;v  i /<0:  (22.1)  \nAssume  for  the  purpose  of contradiction  that  the  Bellman-Fo rd algorithm returns \nTRUE . Thus, v i : d \u0dc4 v i \ue0021 : d C w.v  i \ue0021 ;v  i / for i D 1;2;:::;k . Summing the \ninequalities around cycle c gives \nk X  \ni D1 v i : d \u0dc4 k X  \ni D1 .v i \ue0021 : d C w.v  i \ue0021 ;v  i // \nD k X  \ni D1 v i \ue0021 : d C k X  \ni D1 w.v  i \ue0021 ;v  i /: \nSince v 0 D v k , each vertex in c appears exactly once in each of the summations P  k \ni D1 v i : d and P  k \ni D1 v i \ue0021 : d, and so \nk X  \ni D1 v i : d D k X  \ni D1 v i \ue0021 : d : \nMoreover,  by  Corollary  22.3,  v i : d is \u00fbnite  for  i D 1;2;:::;k . Thus, \n0 \u0dc4 k X  \ni D1 w.v  i \ue0021 ;v  i /; \nwhich  contradicts  inequality  (22.1).  We  conclude  that  the  Bellman-Ford  algorithm  \nreturns TRUE if graph G contains  no  negative-weight  cycles  reachable  from  the  \nsource, and FALSE otherwise. \nExercises  \n22.1-1  \nRun  the  Bellman-Ford  algorithm  on  the  directed  graph  of Figure  22.4,  using  ver-  \ntex \u00b4 as the source. In each pass, relax edges in the sam e order as in the  \u00fbgure,  and  \nshow the d and \ufffd values after each pass. Now, change the weight of e dge .\u00b4;x/  \nto 4 and run the algorithm again, using s as the source. \n22.1-2  \nProve  Corollary  22.3.  616  Chapter  22  Single-Source  Shortest  Paths  \n22.1-3  \nGiven  a weighted,  directed  graph  G D .V;E/  with  no  negative-weight  cycles,  \nlet m be the maximum over all vertices v 2 V of the minimum number of edges \nin a shortest path from the source s to v. (Here, the shortest path is by weight, not \nthe  number  of edges.)  Suggest  a simple  change  to the  Bellman- Ford algorithm that \nallows it to terminate in m C 1 passes, even if m is not known in advance. \n22.1-4  \nModify  the  Bellman-Ford  algorithm  so that  it sets  v: d to \ue0031  for all vertices v for \nwhich  there  is a negative-weight  cycle  on  some  path  from  the  source to v. \n22.1-5  \nSuppose  that  the  graph  given  as input  to the  Bellman-Ford  algorithm is represented \nwith a list of jEj edges, where each edge indicates the vertices it le aves and enters, \nalong  with  its  weight.  Argue  that  the  Bellman-Ford  algorith m runs in O.VE/  time \nwithout the constraint that jEj D  \ufffd.V  /. Modify  the  Bellman-Ford  algorithm  so \nthat it runs in O.VE/  time in all cases when the input graph is represent ed with \nadjacency lists. \n22.1-6  \nLet G D .V;E/  be a weighted, directed graph with weight function w W E !  R. \nGive  an O.VE/-time  algorithm  to \u00fbnd,  for  all  vertices  v 2 V , the value \u0131 \ue003 .v/  D \nmin f\u0131.u;v/  W u 2 V g. \n22.1-7  \nSuppose that a weighted, directed graph G D .V;E/  contains  a negative-weight  \ncycle.  Give  an ef\u00fbcient  algorithm  to list  the  vertices  of one  such cycle. Prove that \nyour algorithm is correct. \n22.2  Single-source  shortest  paths  in directed  acyclic  graphs  \nIn this section, we introduce one further restricti on on weighted, directed graphs: \nthey are acyclic. That is, we are concerned with we ighted dags. Shortest paths \nare  always  well  de\u00fbned  in a dag,  since  even  if there  are  negative-weight  edges,  \nno  negative-weight  cycles  can  exist.  We9ll  see  that  if the  edges of a weighted \ndag G D .V;E/  are relaxed according to a topological sort of its vertices, it takes \nonly \u201a.V  C E/  time to compute shortest paths from a single source . \nThe algorithm starts by topologically sorting the d ag (see Section  20.4)  to im-  \npose a linear ordering on the vertices. If the dag contains a path from vertex u to \nvertex v, then u precedes v in the topological sort. The D AG-SHORTEST-PATHS 22.2  Single-source  shortest  paths  in directed  acyclic  grap hs 617 \nprocedure makes just one pass over the vertices in the topologically sorted order. \nAs it processes each vertex, it relaxes each edge t hat leaves the  vertex.  Figure  22.5  \nshows the execution of this algorithm. \nDAG-SHORTEST-PATHS .G;w;s/  \n1 topologically sort the vertices of G \n2 I NITIALIZE-SINGLE-SOURCE  .G;s/  \n3 for  each vertex u 2 G:  V , taken in topologically sorted order \n4 for  each vertex v in G:  Adj\u0152u\ufffd  \n5 RELAX.u;v;w/  \nLet9s  analyze  the  running  time  of this  algorithm.  As  shown  in Section  20.4,  the  \ntopological  sort  of line  1 takes  \u201a.V  C E/  time. The call of I NITIALIZE-SINGLE- \nSOURCE  in line 2 takes \u201a.V/  time. The for  loop  of lines  335  makes  one  iteration  \nper vertex. Altogether, the for  loop  of lines  435  relaxes  each  edge  exactly  once.  \n(We have used an aggregate analysis here.) Because each iteration of the inner for  \nloop takes \u201a.1/  time, the total running time is \u201a.V  C E/, which is linear in the \nsize  of an adjacency-list  representation  of the  graph.  \nThe following theorem shows that the D AG-SHORTEST-PATHS procedure  cor-  \nrectly computes the shortest paths. \nTheorem  22.5  \nIf a weighted, directed graph G D .V;E/  has source vertex s and no cycles, then \nat the termination of the D AG-SHORTEST-PATHS procedure, v: d D \u0131.s;v/  for all \nvertices v 2 V , and the predecessor subgraph G \ue003 is a shortest-paths  tree.  \nProof  We  \u00fbrst  show  that  v: d D \u0131.s;v/  for all vertices v 2 V at termination. \nIf v is not reachable from s , then v: d D \u0131.s;v/  D 1  by  the  no-path  property.  \nNow, suppose that v is reachable from s , so that there is a shortest path p D \nhv 0 ;v  1 ;:::;v  k i, where v 0 D s and v k D v. Because D AG-SHORTEST-PATHS \nprocesses the vertices in topologically sorted orde r, it relaxes the edges on p in the \norder .v 0 ;v  1 /;.v  1 ;v  2 /;:::;.v  k\ue0021 ;v  k /. The  path-relaxation  property  implies  that  \nv i : d D \u0131.s;v  i / at termination for i D 0;1;:::;k. Finally,  by  the  predecessor-  \nsubgraph property, G \ue003 is a shortest-paths  tree.  \nA useful application of this algorithm arises in de termining critical paths in \nPERT  chart  2 analysis. A job consists of several tasks. Each tas k takes a certain \n2 <PERT= is an acronym for <program evaluation and re view technique.= 618  Chapter  22  Single-Source  Shortest  Paths  \n2 \u221e \u221e 0 5 1 6 \n3 4 \u221e \u221e \u221e 7 31  32  \n2 \n(a) x t s r y z \n1 6 \n3 4 2 \n(c) x t s r y z \n1 6 \n3 4 2 \n(e) x t s r y z \n2 5 1 6 \n3 4 7 31  32  \n2 \n(g) x t s r y z 2 5 1 6 \n3 4 7 31  32  \n2 \n(b) x t s r y z \n2 5 1 6 \n3 4 7 31  32  \n2 \n(d) x t s r y z \n1 6 \n3 4 2 \n(f) x t s r y z \u221e \u221e 0 \u221e \u221e \u221e \n2 5 7 31  32  \u221e \u221e \u221e 2 6 0 \u221e 0 6 6 4 2 \n2 5 7 31  \u20132 \u221e 0 2 6 5 4 2 5 7 31  \u20132 \n\u221e 0 2 6 5 3 \n\u221e 0 2 6 5 3 \nFigure  22.5  The execution of the algorithm for shortest paths i n a directed acyclic graph. The \nvertices are topologically sorted from left to righ t. The source vertex is s . The d values appear \nwithin the vertices, and blue edges indicate the \ufffd values. (a)  The  situation  before  the  \u00fbrst  iteration  \nof the for  loop  of lines  335.  (b)\u2013(g)  The situation after each iteration of the for  loop  of lines  335.  \nBlue vertices have had their outgoing edges relaxed . The vertex highlighted in orange was used as u \nin that iteration. Each edge highlighted in orange caused a d value to change when it was relaxed in \nthat  iteration.  The  values  shown  in part  (g)  are  the  \u00fbnal  values. \namount of time, and some tasks must be completed be fore others can be started. \nFor example, if the job is to build a house, then t he foundation must be completed \nbefore starting to frame the exterior walls, which must be completed before starting \non the roof. Some tasks require more than one other  task to be completed before \nthey can be started: before the drywall can be inst alled over the wall framing, \nboth the electrical system and plumbing must be ins talled. A dag models the tasks \nand dependencies. Edges represent tasks, with the w eight of an edge indicating \nthe time required to perform the task. Vertices rep resent <milestones,= which are 22.2  Single-source  shortest  paths  in directed  acyclic  grap hs 619 \nachieved when all the tasks represented by the edge s entering the vertex have been \ncompleted. If edge .u;v/  enters vertex v and edge .v;x/  leaves v, then task .u;v/  \nmust be completed before task .v;x/  is started. A path through this dag represents \na sequence of tasks that must be performed in a par ticular order. A critical  path  is \na longest path through the dag, corresponding to the longest time to perform any \nsequence of tasks. Thus, the weight of a critical p ath provides a lower bound on the \ntotal time to perform all the tasks, even if as man y tasks as possible are performed \nsimultaneously.  You  can  \u00fbnd  a critical  path  by  either  \n\ue001 negating the edge weights and running D AG-SHORTEST-PATHS , or \n\ue001 running D AG-SHORTEST-PATHS , but replacing < 1= by < \ue0031= in line 2 of \nI NITIALIZE-SINGLE-SOURCE  and <>= by <<= in the R ELAX procedure. \nExercises  \n22.2-1  \nShow the result of running D AG-SHORTEST-PATHS on the directed acyclic graph \nof Figure  22.5,  using  vertex  r as the source. \n22.2-2  \nSuppose  that  you  change  line  3 of DAG-SHORTEST-PATHS to read \n3 for  the  \u00fbrst  jV j \ue003  1 vertices, taken in topologically sorted order \nShow that the procedure remains correct. \n22.2-3  \nAn alternative way to represent a PERT chart looks more like the dag  of Figure  20.7  \non  page  574.  Vertices  represent  tasks  and  edges  represent  sequencing constraints, \nthat is, edge .u;v/  indicates that task u must be performed before task v. Vertices, \nnot edges, have weights. Modify the D AG-SHORTEST-PATHS procedure so that \nit \u00fbnds  a longest  path  in a directed  acyclic  graph  with  weight ed vertices in linear \ntime. \n? 22.2-4  \nGive  an ef\u00fbcient  algorithm  to count  the  total  number  of paths  in a directed acyclic \ngraph. The count should include all paths between a ll pairs of vertices and all paths \nwith 0 edges. Analyze your algorithm. 620  Chapter  22  Single-Source  Shortest  Paths  \n22.3  Dijkstra\u2019s  algorithm  \nDijkstra9s  algorithm  solves  the  single-source  shortest-p aths problem on a weighted, \ndirected graph G D .V;E/ , but it requires nonnegative weights on all edges:  \nw.u;v/  \ue004 0 for each edge .u;v/  2 E. As  we  shall  see,  with  a good  implementa-  \ntion,  the  running  time  of Dijkstra9s  algorithm  is lower  than  that  of the  Bellman-Ford  \nalgorithm. \nYou  can  think  of Dijkstra9s  algorithm  as generalizing  breadth-\u00fbrst  search  to \nweighted  graphs.  A wave  emanates  from  the  source,  and  the  \u00fbrst time that a wave \narrives at a vertex, a new wave emanates from that vertex. Whe reas  breadth-\u00fbrst  \nsearch operates as if each wave takes unit time to traverse an edge, in a weighted \ngraph, the time for a wave to traverse an edge is g iven by the ed ge9s  weight.  Be-  \ncause a shortest path in a weighted graph might not  have the fewest  edges,  a sim-  \nple,  \u00fbrst-in,  \u00fbrst-out  queue  won9t  suf\u00fbce  for  choosing  the  next vertex from which \nto send out a wave. \nInstead,  Dijkstra9s  algorithm  maintains  a set  S of vertices  whose  \u00fbnal  shortest-  \npath weights from the source s have  already  been  determined.  The  algorithm  re-  \npeatedly selects the vertex u 2 V \ue003 S with  the  minimum  shortest-path  estimate,  \nadds u into S , and relaxes all edges leaving u. The procedure D IJKSTRA  replaces \nthe  \u00fbrst-in,  \u00fbrst-out  queue  of breadth-\u00fbrst  search  by  a min- priority queue Q of \nvertices, keyed by their d values. \nDIJKSTRA  .G;w;s/  \n1 I NITIALIZE-SINGLE-SOURCE  .G;s/  \n2 S D ;  \n3 Q D ;  \n4 for  each vertex u 2 G:  V \n5 I NSERT.Q;u/  \n6 while  Q \u00a4 ;  \n7 u D EXTRACT-MIN .Q/  \n8 S D S [ fug \n9 for  each vertex v in G:  Adj\u0152u\ufffd  \n10  RELAX.u;v;w/  \n11  if the call of R ELAX decreased v: d \n12  DECREASE-KEY .Q;v;v:  d/ \nDijkstra9s  algorithm  relaxes  edges  as shown  in Figure  22.6.  Line  1 initializes  the  \nd and \ufffd values in the usual way, and line 2 initializes the  set S to the empty set. \nThe algorithm maintains the invariant that Q D V \ue003 S at the start of each iteration 22.3 Dijkstra\u2019s algorithm 621 \n0 \u221e \u221e \n\u221e \u221e 0 \n2 10  \n5 \n(c) 0 \n0 0 0 6 4 3 2 9 \n7 s t x \ny z \n1 \n2 10  \n5 \n(f) 6 4 3 2 9 \n7 s t x \ny z 1 \n2 10  \n5 \n(b) 6 4 3 2 9 \n7 s t x \ny z \n1 \n2 10  \n5 \n(e) 6 4 3 2 9 \n7 s t x \ny z 1 \n2 10  \n5 \n(a) 6 4 3 2 9 \n7 s t x \ny z \n1 \n2 10  \n5 \n(d) 6 4 3 2 9 \n7 s t x \ny z \u221e 10  \n\u221e 5 1 8 14  \n5 7 \n9 8 \n5 7 8 9 \n5 7 8 13  \n5 7 \nFigure  22.6  The  execution  of Dijkstra9s  algorithm.  The  source  s is the leftmost vertex. The \nshortest-path  estimates  appear  within  the  vertices,  and  blue edges indicate predecessor values. Blue \nvertices belong to the set S , and  tan  vertices  are  in the  min-priority  queue  Q D V \ue003 S . (a)  The \nsituation  just  before  the  \u00fbrst  iteration  of the  while  loop  of lines  6312.  (b)\u2013(f)  The situation after each \nsuccessive iteration of the while  loop. In each part, the vertex highlighted in orang e was chosen as \nvertex u in line  7, and  each  edge  highlighted  in orange  caused  a d value and a predecessor to change \nwhen the edge was relaxed. The d values  and  predecessors  shown  in part  (f)  are  the  \u00fbnal  values . \nof the while  loop  of lines  6312.  Lines  335  initialize  the  min-priority  queue Q to \ncontain all the vertices in V . Since S D ;  at that time, the invariant is true upon \n\u00fbrst  reaching  line  6. Each  time  through  the  while  loop  of lines  6312,  line  7 extracts  \na vertex u from Q D V \ue003 S and  line  8 adds  it to set  S , thereby maintaining the \ninvariant.  (The  \u00fbrst  time  through  this  loop,  u D s .) Vertex u, therefore, has the \nsmallest  shortest-path  estimate  of any  vertex  in V \ue003 S . Then,  lines  9312  relax  each  \nedge .u;v/  leaving u, thus updating the estimate v: d and the predecessor v:\ufffd  if the \nshortest path to v found so far improves by going through u. Whenever a relaxation \nstep changes the d and \ufffd values, the call to D ECREASE-KEY in line  12  updates  the  \nmin-priority  queue.  The  algorithm  never  inserts  vertices  into Q after the for  loop \nof lines  435,  and  each  vertex  is extracted  from  Q and added to S exactly once, so \nthat the while  loop  of lines  6312  iterates  exactly  jV j times. \nBecause  Dijkstra9s  algorithm  always  chooses  the  <lightest = or <closest= vertex \nin V \ue003 S to add to set S , you  can  think  of it as using  a greedy  strategy.  Chap-  \nter  15  explains  greedy  strategies  in detail,  but  you  need  not  have read that chapter \nto understand  Dijkstra9s  algorithm.  Greedy  strategies  do  not always yield optimal 622  Chapter  22  Single-Source  Shortest  Paths  \nS u \ny s \nx \nFigure  22.7  The  proof  of Theorem  22.6.  Vertex  u is selected to be added into set S in line  7 of \nDIJKSTRA . Vertex y is the  \u00fbrst  vertex  on  a shortest  path  from  the  source  s to vertex u that is not in \nset S , and x 2 S is y9s predecessor  on  that  shortest  path.  The  subpath  from  y to u may or may not \nre-enter  set  S . \nresults in general, but as the following theorem an d its corollary  show,  Dijkstra9s  al-  \ngorithm does indeed compute shortest paths. The key  is to show that u: d D \u0131.s;u/  \neach time it adds a vertex u to set S . \nTheorem  22.6  (Correctness  of Dijkstra\u2019s  algorithm)  \nDijkstra9s  algorithm,  run  on  a weighted,  directed  graph  G D .V;E/  with  nonneg-  \native weight function w and source vertex s , terminates with u: d D \u0131.s;u/  for all \nvertices u 2 V . \nProof  We will show that at the start of each iteration of  the while  loop of lines \n6312,  we  have  v: d D \u0131.s;v/  for all v 2 S . The algorithm terminates when S D V , \nso that v: d D \u0131.s;v/  for all v 2 V . \nThe proof is by induction on the number of iteratio ns of the while  loop, which \nequals jS j at the start of each iteration. There are two bases : for jS j D  0, so \nthat S D ;  and the claim is trivially true, and for jS j D  1, so that S D fs g and \ns: d D \u0131.s;s/  D 0. \nFor the inductive step, the inductive hypothesis is  that v: d D \u0131.s;v/  for all \nv 2 S . The algorithm extracts vertex u from V \ue003 S . Because the algorithm adds u \ninto S , we need to show that u: d D \u0131.s;u/  at that time. If there is no path from s \nto u, then  we  are  done,  by  the  no-path  property.  If there  is a path  from s to u, then, \nas Figure  22.7  shows,  let  y be the  \u00fbrst  vertex  on  a shortest  path  from  s to u that is \nnot in S , and let x 2 S be the predecessor of y on that shortest path. (We could \nhave y D u or x D s .) Because y appears no later than u on the shortest path and \nall edge weights are nonnegative, we have \u0131.s;y/  \u0dc4 \u0131.s;u/ . Because the call of \nEXTRACT-MIN in line  7 returned  u as having the minimum d value in V \ue003 S , we \nalso have u: d \u0dc4 y: d, and  the  upper-bound  property  gives  \u0131.s;u/  \u0dc4 u: d. \nSince x 2 S , the inductive hypothesis implies that x: d D \u0131.s;x/ . During the \niteration of the while  loop that added x into S , edge .x;y/  was relaxed. By the \nconvergence property, y: d received the value of \u0131.s;y/  at that time. Thus, we have 22.3 Dijkstra\u2019s algorithm 623 \n\u0131.s;y/  \u0dc4 \u0131.s;u/  \u0dc4 u: d \u0dc4 y: d and y: d D \u0131.s;y/;  \nso that \n\u0131.s;y/  D \u0131.s;u/  D u: d D y: d : \nHence, u: d D \u0131.s;u/, and  by  the  upper-bound  property,  this  value  never  changes  \nagain. \nCorollary  22.7  \nAfter  Dijkstra9s  algorithm  is run  on  a weighted,  directed  graph G D .V;E/  with \nnonnegative weight function w and source vertex s , the predecessor subgraph G \ue003 \nis a shortest-paths  tree  rooted  at s . \nProof  Immediate  from  Theorem  22.6  and  the  predecessor-subgraph  property. \nAnalysis  \nHow  fast  is Dijkstra9s  algorithm?  It maintains  the  min-prio rity queue Q by calling \nthree  priority-queue  operations:  I NSERT (in  line  5),  EXTRACT-MIN (in  line  7),  and  \nDECREASE-KEY (in  line  12).  The  algorithm  calls  both  I NSERT and E XTRACT- \nMIN once per vertex. Because each vertex u 2 V is added to set S exactly once, \neach edge in the adjacency list Adj\u0152u\ufffd  is examined in the for  loop  of lines  9312  \nexactly once during the course of the algorithm. Si nce the total number of edges in \nall the adjacency lists is jEj, this for  loop iterates a total of jEj times, and thus the \nalgorithm calls D ECREASE-KEY at most jEj times  overall.  (Observe  once  again  \nthat we are using aggregate analysis.) \nJust  as in Prim9s  algorithm,  the  running  time  of Dijkstra9s  algorithm depends on \nthe  speci\u00fbc  implementation  of the  min-priority  queue  Q. A simple implementation \ntakes advantage of the vertices being numbered 1 to jV j: simply store v: d in the \nvth entry of an array. Each I NSERT and D ECREASE-KEY operation takes O.1/  \ntime, and each E XTRACT-MIN operation takes O.V/  time (since it has to search \nthrough the entire array), for a total time of O.V  2 C E/  D O.V  2 /. \nIf the  graph  is suf\u00fbciently  sparse4in  particular,  E D o.V  2 = lg V/4you  can  \nimprove  the  running  time  by  implementing  the  min-priority  queue with a binary \nmin-heap  that  includes  a way  to map  between  vertices  and  their corresponding \nheap elements. Each E XTRACT-MIN operation then takes O.lg V/  time.  As  be-  \nfore, there are jV j such  operations.  The  time  to build  the  binary  min-heap  is O.V/ . \n(As  noted  in Section  21.2,  you  don9t  even  need  to call  BUILD-MIN-HEAP.) Each \nDECREASE-KEY operation takes O.lg V/  time, and there are still at most jEj \nsuch operations. The total running time is therefor e O..V  C E/  lg V/, which \nis O.E  lg V/  in the typical case that jEj D  \ufffd.V  /. This running time improves \nupon the straightforward O.V  2 /-time  implementation  if E D o.V  2 = lg V/. 624  Chapter  22  Single-Source  Shortest  Paths  \nBy  implementing  the  min-priority  queue  with  a Fibonacci  heap  (see  page  478),  \nyou can improve the running time to O.V  lg V C E/. The amortized cost of each \nof the jV j EXTRACT-MIN operations is O.lg V/, and each D ECREASE-KEY call, \nof which there are at most jEj, takes only O.1/  amortized time. Historically, the \ndevelopment of Fibonacci heaps was motivated by the  observation  that  Dijkstra9s  \nalgorithm typically makes many more D ECREASE-KEY calls than E XTRACT-MIN \ncalls, so that any method of reducing the amortized  time of each D ECREASE-KEY \noperation to o.lg V/  without increasing the amortized time of E XTRACT-MIN \nwould yield an asymptotically faster implementation  than with binary heaps. \nDijkstra9s  algorithm  resembles  both  breadth-\u00fbrst  search  (see Section 20.2) and \nPrim9s  algorithm  for  computing  minimum  spanning  trees  (see  Section  21.2).  It is \nlike  breadth-\u00fbrst  search  in that  set  S corresponds to the set of black vertices in a \nbreadth-\u00fbrst  search.  Just  as vertices  in S have  their  \u00fbnal  shortest-path  weights,  so \ndo  black  vertices  in a breadth-\u00fbrst  search  have  their  correct  breadth-\u00fbrst  distances.  \nDijkstra9s  algorithm  is like  Prim9s  algorithm  in that  both  algorithms  use  a min-  \npriority  queue  to \u00fbnd  the  <lightest=  vertex  outside  a given  set (the set S in Dijkstra9s  \nalgorithm  and  the  tree  being  grown  in Prim9s  algorithm),  add  this vertex into the \nset, and adjust the weights of the remaining vertic es outside the set accordingly. \nExercises  \n22.3-1  \nRun  Dijkstra9s  algorithm  on  the  directed  graph  of Figure  22.2,  \u00fbrst  using  vertex  s \nas the source and then using vertex \u00b4 as the  source.  In the  style  of Figure  22.6,  \nshow the d and \ufffd values and the vertices in set S after each iteration of the while  \nloop. \n22.3-2  \nGive  a simple  example  of a directed  graph  with  negative-weig ht edges for which \nDijkstra9s  algorithm  produces  an incorrect  answer.  Why  doesn9t  the  proof  of The-  \norem  22.6  go  through  when  negative-weight  edges  are  allowed?  \n22.3-3  \nSuppose  that  you  change  line  6 of Dijkstra9s  algorithm  to read \n6 while  jQj >1  \nThis change causes the while  loop to execute jV j \ue003  1 times instead of jV j times. Is \nthis  proposed  algorithm  correct?  22.3 Dijkstra\u2019s algorithm 625 \n22.3-4  \nModify the D IJKSTRA  procedure so that the priority queue Q is more like the \nqueue in the BFS procedure in that it contains only  vertices that have been reached \nfrom source s so far: Q \u0dc2 V \ue003 S and v 2 Q implies v: d \u00a4 1 . \n22.3-5  \nProfessor  Gaedel  has  written  a program  that  he claims  implements  Dijkstra9s  al-  \ngorithm. The program produces v: d and v:\ufffd  for each vertex v 2 V . Give  an \nO.V  C E/-time  algorithm  to check  the  output  of the  professor9s  progr am. It should \ndetermine whether the d and \ufffd attributes  match  those  of some  shortest-paths  tree.  \nYou may assume that all edge weights are nonnegativ e. \n22.3-6  \nProfessor Newman thinks that he has worked out a si mpler proof of correctness \nfor  Dijkstra9s  algorithm.  He  claims  that  Dijkstra9s  algori thm relaxes the edges of \nevery shortest path in the graph in the order in wh ich they appear on the path, and \ntherefore  the  path-relaxation  property  applies  to every  vertex reachable from the \nsource. Show that the professor is mistaken by cons tructing a directed graph for \nwhich  Dijkstra9s  algorithm  relaxes  the  edges  of a shortest  path out of order. \n22.3-7  \nConsider a directed graph G D .V;E/  on which each edge .u;v/  2 E has an \nassociated value r.u;v/ , which is a real number in the range 0 \u0dc4 r.u;v/  \u0dc4 1 that \nrepresents the reliability of a communication chann el from vertex u to vertex v. \nInterpret r.u;v/  as the probability that the channel from u to v will not fail, and \nassume  that  these  probabilities  are  independent.  Give  an ef\u00fbcient  algorithm  to \u00fbnd  \nthe most reliable path between two given vertices. \n22.3-8  \nLet G D .V;E/  be a weighted, directed graph with positive weight function \nw W E ! f1;2;:::;W  g for some positive integer W , and  assume  that  no  two  ver-  \ntices  have  the  same  shortest-path  weights  from  source  verte x s . Now  de\u00fbne  an \nunweighted, directed graph G 0 D .V  [ V 0 ;E  0 / by replacing each edge .u;v/  2 E \nwith w.u;v/  unit-weight  edges  in series.  How  many  vertices  does  G 0 have?  Now  \nsuppose  that  you  run  a breadth-\u00fbrst  search  on  G 0 . Show that the order in which \nthe  breadth-\u00fbrst  search  of G 0 colors vertices in V black is the same as the order in \nwhich  Dijkstra9s  algorithm  extracts  the  vertices  of V from the priority queue when \nit runs on G. \n22.3-9  \nLet G D .V;E/  be a weighted, directed graph with nonnegative weig ht function \nw W E ! f0;1;:::;W  g for some nonnegative integer W . Modify  Dijkstra9s  algo-  626  Chapter  22  Single-Source  Shortest  Paths  \nrithm to compute the shortest paths from a given so urce vertex s in O.WV  C E/  \ntime. \n22.3-10  \nModify  your  algorithm  from  Exercise  22.3-9  to run  in O..V  C E/  lg W/  time. \n(Hint: How  many  distinct  shortest-path  estimates  can  V \ue003 S contain at any point \nin time?)  \n22.3-11  \nSuppose that you are given a weighted, directed gra ph G D .V;E/  in which edges \nthat leave the source vertex s may have negative weights, all other edge weights \nare  nonnegative,  and  there  are  no  negative-weight  cycles.  Argue  that  Dijkstra9s  \nalgorithm  correctly  \u00fbnds  shortest  paths  from  s in this graph. \n22.3-12  \nSuppose that you have a weighted directed graph G D .V;E/  in which all edge \nweights are positive real values in the range \u0152C; 2C \ufffd  for some positive constant C . \nModify  Dijkstra9s  algorithm  so that  it runs  in O.V  C E/  time. \n22.4  Difference  constraints  and  shortest  paths  \nChapter  29  studies  the  general  linear-programming  problem,  showing  how  to op-  \ntimize a linear function subject to a set of linear  inequalities.  This  section  in-  \nvestigates a special case of linear programming tha t reduces to \u00fbnding  shortest  \npaths  from  a single  source.  The  Bellman-Ford  algorithm  then  solves the resulting \nsingle-source  shortest-paths  problem,  thereby  also  solving  the  linear-programming  \nproblem. \nLinear  programming  \nIn the general linear-programming  problem , the input is an m \ue005 n matrix A, an \nm-vector  b, and an n-vector  c . The  goal  is to \u00fbnd  a vector  x of n elements that \nmaximizes the objective  function  P  n \ni D1 c i x i subject to the m constraints given \nby Ax  \u0dc4 b. \nThe most popular method for solving linear programs  is the simplex  algorithm , \nwhich  Section  29.1  discusses.  Although  the  simplex  algorit hm does not always run \nin time polynomial in the size of its input, there are other linear-programming  al-  \ngorithms that do run in polynomial time. We offer h ere two reasons to understand \nthe  setup  of linear-programming  problems.  First,  if you  know that you can cast a \ngiven  problem  as a polynomial-sized  linear-programming  problem,  then  you  im-  22.4  Difference  constraints  and  shortest  paths  627 \nmediately  have  a polynomial-time  algorithm  to solve  the  problem. Second, faster \nalgorithms exist for many special cases of linear p rogramming. For example, the \nsingle-pair  shortest-path  problem  (Exercise  22.4-4)  and  the  maximum-\u00fcow  prob-  \nlem  (Exercise  24.1-5)  are  special  cases  of linear  programmi ng. \nSometimes  the  objective  function  does  not  matter:  it9s  enough  just  to \u00fbnd  any  \nfeasible  solution , that is, any vector x that  satis\u00fbes  Ax  \u0dc4 b, or to determine that \nno feasible solution exists. This section focuses o n one such feasibility  problem . \nSystems  of difference  constraints  \nIn a system  of difference  constraints, each  row  of the  linear-programming  matrix  A \ncontains one 1 and one \ue0031, and all other entries of A are 0. Thus, the constraints \ngiven by Ax  \u0dc4 b are a set of m difference  constraints  involving n unknowns, in \nwhich each constraint is a simple linear inequality  of the form \nx j \ue003 x i \u0dc4 b k ; \nwhere 1 \u0dc4 i;j  \u0dc4 n, i \u00a4 j , and 1 \u0dc4 k \u0dc4 m. \nFor  example,  consider  the  problem  of \u00fbnding  a 5-vector  x D .x i / that  satis\u00fbes  \ue001 \n1 \ue0031 0 0 0  \n1 0 0 0  \ue0031 \n0 1 0 0  \ue0031 \n\ue0031 0 1 0 0  \n\ue0031 0 0 1 0  \n0 0  \ue0031 1 0  \n0 0  \ue0031 0 1  \n0 0 0  \ue0031 1  \u02d8 \n\u02c7 \nx 1 \nx 2 \nx 3 \nx 4 \nx 5 \ue002 \n\u0dc4 \ue001 \n0 \n\ue0031 \n1 \n5 \n4 \n\ue0031 \n\ue0033 \n\ue0033 \u02d8 \n: \nThis  problem  is equivalent  to \u00fbnding  values  for  the  unknowns  x 1 ;x  2 ;x  3 ;x  4 ;x  5 , \nsatisfying the following 8 difference constraints: \nx 1 \ue003 x 2 \u0dc4 0 , (22.2) \nx 1 \ue003 x 5 \u0dc4 \ue0031 , (22.3)  \nx 2 \ue003 x 5 \u0dc4 1 , (22.4)  \nx 3 \ue003 x 1 \u0dc4 5 , (22.5)  \nx 4 \ue003 x 1 \u0dc4 4 , (22.6)  \nx 4 \ue003 x 3 \u0dc4 \ue0031 , (22.7)  \nx 5 \ue003 x 3 \u0dc4 \ue0033 , (22.8)  \nx 5 \ue003 x 4 \u0dc4 \ue0033 . (22.9) \nOne  solution  to this  problem  is x D .\ue0035; \ue0033;0;  \ue0031; \ue0034/, which  you  can  verify  di-  \nrectly by checking each inequality. In fact, this p roblem has more than one solution. 628  Chapter  22  Single-Source  Shortest  Paths  \nAnother is x 0 D .0;2;5;4;1/ . These two solutions are related: each component \nof x 0 is 5 larger than the corresponding component of x . This fact is not mere \ncoincidence. \nLemma  22.8  \nLet x D .x 1 ;x  2 ;:::;x  n / be a solution to a system Ax  \u0dc4 b of difference  con-  \nstraints, and let d be any constant. Then x C d D .x 1 C d;x  2 C d;:::;x  n C d/  \nis a solution to Ax  \u0dc4 b as well. \nProof  For each x i and x j , we have .x j C d/  \ue003 .x i C d/  D x j \ue003 x i . Thus, if x \nsatis\u00fbes  Ax  \u0dc4 b, so does x C d . \nSystems of difference constraints occur in various applications. For example, the \nunknowns x i might be times at which events are to occur. Each c onstraint states \nthat at least a certain amount of time, or at most a certain amount of time, must \nelapse between two events. Perhaps the events are j obs to be performed during the \nassembly of a product. If the manufacturer applies an adhesive that takes 2 hours \nto set at time x 1 and has to wait until it sets to install a part at time x 2 , then there \nis a constraint that x 2 \ue004 x 1 C 2 or, equivalently, that x 1 \ue003 x 2 \u0dc4 \ue0032. Alternatively, \nthe manufacturer might require the part to be insta lled after the adhesive has been \napplied but no later than the time that the adhesiv e has set halfway. In this case, \nthere is a pair of constraints x 2 \ue004 x 1 and x 2 \u0dc4 x 1 C 1 or, equivalently, x 1 \ue003 x 2 \u0dc4 0 \nand x 2 \ue003 x 1 \u0dc4 1. \nIf all the constraints have nonnegative numbers on the right-hand  side4that  is, \nif b i \ue004 0 for i D 1;2;:::;m4then  \u00fbnding  a feasible  solution  is trivial:  just  set  \nall the unknowns x i equal to each other. Then all the differences are 0, and every \nconstraint  is satis\u00fbed.  The  problem  of \u00fbnding  a feasible  solution to a system of \ndifference constraints is interesting only if at le ast one constraint has b i <0. \nConstraint  graphs  \nWe can interpret systems of difference constraints from a graph-theoretic  point  \nof view. For a system Ax  \u0dc4 b of difference  constraints,  let9s  view  the  m \ue005 n \nlinear-programming  matrix  A as the  transpose  of an incidence  matrix  (see  Exer-  \ncise  20.1-7)  for  a graph  with  n vertices and m edges. Each vertex v i in the graph, \nfor i D 1;2;:::;n , corresponds to one of the n unknown variables x i . Each  di-  \nrected edge in the graph corresponds to one of the m inequalities involving two \nunknowns. \nMore formally, given a system Ax  \u0dc4 b of difference  constraints,  the  correspond-  \ning constraint  graph  is a weighted, directed graph G D .V;E/ , where 22.4  Difference  constraints  and  shortest  paths  629 \n0 \n0 \n0 0 0 0 31  \n1 \n5 \n4 \n31  33  33  0 35  \n33  \n0 31  34  v 5 \nv 0 v 1 \nv 2 \nv 3 \nv 4 \nFigure  22.8  The constraint graph corresponding to the system (2 2.2)\u2013(22.9)  of difference  con-  \nstraints. The value of \u0131.v  0 ;v  i / appears in each vertex v i . One  feasible  solution  to the  system  is \nx D .\ue0035; \ue0033;0;  \ue0031; \ue0034/. \nV D fv 0 ;v  1 ;:::;v  n g \nand \nE D f.v i ;v  j / W x j \ue003 x i \u0dc4 b k is a constraint g \n[ f.v 0 ;v  1 /;.v  0 ;v  2 /;.v  0 ;v  3 /;:::;.v  0 ;v  n /g : \nThe constraint graph includes the additional vertex  v 0 , as we shall see shortly, to \nguarantee that the graph has some vertex that can r each all other vertices. Thus, \nthe vertex set V consists of a vertex v i for each unknown x i , plus an additional \nvertex v 0 . The edge set E contains an edge for each difference constraint, pl us \nan edge .v 0 ;v  i / for each unknown x i . If x j \ue003 x i \u0dc4 b k is a difference constraint, \nthen the weight of edge .v i ;v  j / is w.v  i ;v  j / D b k . The  weight  of each  edge  leav-  \ning v 0 is 0. Figure  22.8  shows  the  constraint  graph  for  the  system  (22.2 )\u2013(22.9) of \ndifference constraints. \nThe following theorem shows how to solve a system o f difference constraints by \n\u00fbnding  shortest-path  weights  in the  corresponding  constra int graph. \nTheorem  22.9  \nGiven  a system  Ax  \u0dc4 b of difference constraints, let G D .V;E/  be the  corre-  \nsponding constraint graph. If G contains  no  negative-weight  cycles,  then  \nx D .\u0131.v  0 ;v  1 /;\u0131.v  0 ;v  2 /;\u0131.v  0 ;v  3 /;:::;\u0131.v  0 ;v  n // (22.10)  \nis a feasible solution for the system. If G contains  a negative-weight  cycle,  then  \nthere is no feasible solution for the system. 630  Chapter  22  Single-Source  Shortest  Paths  \nProof  We  \u00fbrst  show  that  if the  constraint  graph  contains  no  negative-weight  \ncycles,  then  equation  (22.10)  gives  a feasible  solution.  Consider any edge \n.v i ;v  j / 2 E. The triangle inequality implies that \u0131.v  0 ;v  j / \u0dc4 \u0131.v  0 ;v  i / C w.v  i ;v  j /, \nwhich is equivalent to \u0131.v  0 ;v  j /\ue003\u0131.v  0 ;v  i / \u0dc4 w.v  i ;v  j /. Thus, letting x i D \u0131.v  0 ;v  i / \nand x j D \u0131.v  0 ;v  j / satis\u00fbes  the  difference  constraint  x j \ue003 x i \u0dc4 w.v  i ;v  j / that  cor-  \nresponds to edge .v i ;v  j /. \nNow  we  show  that  if the  constraint  graph  contains  a negative- weight cycle, then \nthe system of difference constraints has no feasibl e solution.  Without  loss  of gen-  \nerality,  let  the  negative-weight  cycle  be c D hv 1 ;v  2 ;:::;v  k i, where v 1 D v k . \n(The vertex v 0 cannot be on cycle c , because it has no entering edges.) Cycle c \ncorresponds to the following difference constraints : \nx 2 \ue003 x 1 \u0dc4 w.v  1 ;v  2 /; \nx 3 \ue003 x 2 \u0dc4 w.v  2 ;v  3 /; \n: : : \nx k\ue0021 \ue003 x k\ue0022 \u0dc4 w.v  k\ue0022 ;v  k\ue0021 /; \nx k \ue003 x k\ue0021 \u0dc4 w.v  k\ue0021 ;v  k /: \nWe9ll  assume  that  x has a solution satisfying each of these k inequalities and then \nderive a contradiction. The solution must also sati sfy the inequality that results \nfrom summing the k inequalities  together.  In summing  the  left-hand  sides,  each \nunknown x i is added in once and subtracted out once (remember that v 1 D v k \nimplies x 1 D x k ), so that  the  left-hand  side  sums  to 0. The  right-hand  side  sums  \nto the weight w.c/  of the cycle, giving 0 \u0dc4 w.c/ . But since c is a negative-weight  \ncycle, w.c/<0 , and we obtain the contradiction that 0 \u0dc4 w.c/<0 . \nSolving  systems  of difference  constraints  \nTheorem  22.9  suggests  how  to use  the  Bellman-Ford  algorithm  to solve a system of \ndifference constraints. Because the constraint grap h contains edges from the source \nvertex v 0 to all  other  vertices,  any  negative-weight  cycle  in the  constraint graph is \nreachable from v 0 . If the  Bellman-Ford  algorithm  returns  TRUE, then  the  shortest-  \npath weights give a feasible solution to the system . In Figure 22.8,  for  example,  the  \nshortest-path  weights  provide  the  feasible  solution  x D .\ue0035; \ue0033;0;  \ue0031; \ue0034/, and \nby  Lemma  22.8,  x D .d \ue003 5;d  \ue003 3;d;d  \ue003 1;d  \ue003 4/ is also a feasible solution for \nany constant d . If the  Bellman-Ford  algorithm  returns  FALSE , there is no feasible \nsolution to the system of difference constraints. \nA system of difference constraints with m constraints on n unknowns produces \na graph with n C 1 vertices and n C m edges.  Thus,  the  Bellman-Ford  algorithm  \nprovides a way to solve the system in O..n  C 1/.n  C m//  D O.n  2 C nm/  time. 22.4  Difference  constraints  and  shortest  paths  631 \nExercise  22.4-5  asks  you  to modify  the  algorithm  to run  in O.nm/  time, even if m \nis much less than n. \nExercises  \n22.4-1  \nFind a feasible solution or determine that no feasi ble solution  exists  for  the  follow-  \ning system of difference constraints: \nx 1 \ue003 x 2 \u0dc4 1 , \nx 1 \ue003 x 4 \u0dc4 \ue0034 , \nx 2 \ue003 x 3 \u0dc4 2 , \nx 2 \ue003 x 5 \u0dc4 7 , \nx 2 \ue003 x 6 \u0dc4 5 , \nx 3 \ue003 x 6 \u0dc4 10  , \nx 4 \ue003 x 2 \u0dc4 2 , \nx 5 \ue003 x 1 \u0dc4 \ue0031 , \nx 5 \ue003 x 4 \u0dc4 3 , \nx 6 \ue003 x 3 \u0dc4 \ue0038 . \n22.4-2  \nFind a feasible solution or determine that no feasi ble solution  exists  for  the  follow-  \ning system of difference constraints: \nx 1 \ue003 x 2 \u0dc4 4 , \nx 1 \ue003 x 5 \u0dc4 5 , \nx 2 \ue003 x 4 \u0dc4 \ue0036 , \nx 3 \ue003 x 2 \u0dc4 1 , \nx 4 \ue003 x 1 \u0dc4 3 , \nx 4 \ue003 x 3 \u0dc4 5 , \nx 4 \ue003 x 5 \u0dc4 10  , \nx 5 \ue003 x 3 \u0dc4 \ue0034 , \nx 5 \ue003 x 4 \u0dc4 \ue0038 . \n22.4-3  \nCan  any  shortest-path  weight  from  the  new  vertex  v 0 in a constraint  graph  be posi-  \ntive?  Explain.  \n22.4-4  \nExpress  the  single-pair  shortest-path  problem  as a linear  program. 632  Chapter  22  Single-Source  Shortest  Paths  \n22.4-5  \nShow  how  to modify  the  Bellman-Ford  algorithm  slightly  so that when using it to \nsolve a system of difference constraints with m inequalities on n unknowns, the \nrunning time is O.nm/ . \n22.4-6  \nConsider adding equality  constraints  of the form x i D x j C b k to a system of \ndifference constraints. Show how to solve this vari ety of constraint system. \n22.4-7  \nShow how to solve a system of difference constraint s by a Bellman-Ford-like  algo-  \nrithm that runs on a constraint graph without the e xtra vertex v 0 . \n? 22.4-8  \nLet Ax  \u0dc4 b be a system of m difference constraints in n unknowns. Show that the \nBellman-Ford  algorithm,  when  run  on  the  corresponding  constraint  graph,  maxi-  \nmizes P  n \ni D1 x i subject to Ax  \u0dc4 b and x i \u0dc4 0 for all x i . \n? 22.4-9  \nShow  that  the  Bellman-Ford  algorithm,  when  run  on  the  constraint  graph  for  a sys-  \ntem Ax  \u0dc4 b of difference constraints, minimizes the quantity .max fx i g\ue003min fx i g/ \nsubject to Ax  \u0dc4 b. Explain how this fact might come in handy if the algorithm is \nused to schedule construction jobs. \n22.4-10  \nSuppose that every row in the matrix A of a linear program Ax  \u0dc4 b corresponds to \na difference  constraint,  a single-variable  constraint  of the form x i \u0dc4 b k , or a single-  \nvariable constraint of the form \ue003x i \u0dc4 b k . Show  how  to adapt  the  Bellman-Ford  \nalgorithm to solve this variety of constraint syste m. \n22.4-11  \nGive  an ef\u00fbcient  algorithm  to solve  a system  Ax  \u0dc4 b of difference constraints \nwhen all of the elements of b are  real-valued  and  all  of the  unknowns  x i must be \nintegers. \n? 22.4-12  \nGive  an ef\u00fbcient  algorithm  to solve  a system  Ax  \u0dc4 b of difference constraints \nwhen all of the elements of b are  real-valued  and  a speci\u00fbed  subset  of some,  but  \nnot necessarily all, of the unknowns x i must be integers. 22.5 Proofs of shortest-paths properties 633 \n22.5  Proofs  of shortest-paths  properties  \nThroughout this chapter, our correctness arguments have relied on the triangle \ninequality,  upper-bound  property,  no-path  property,  convergence  property,  path-  \nrelaxation  property,  and  predecessor-subgraph  property.  We stated these properties \nwithout  proof  on  page  611.  In this  section,  we  prove  them.  \nThe  triangle  inequality  \nIn studying  breadth-\u00fbrst  search  (Section  20.2),  we  proved  as Lemma  20.1  a sim-  \nple property of shortest distances in unweighted gr aphs. The triangle inequality \ngeneralizes the property to weighted graphs. \nLemma  22.10  (Triangle  inequality)  \nLet G D .V;E/  be a weighted, directed graph with weight function w W E !  R \nand source vertex s . Then, for all edges .u;v/  2 E, \n\u0131.s;v/  \u0dc4 \u0131.s;u/  C w.u;v/:  \nProof  Suppose that p is a shortest path from source s to vertex v. Then p has \nno more weight than any other path from s to v. Speci\u00fbcally,  path  p has no more \nweight than the particular path that takes a shorte st path from source s to vertex u \nand then takes edge .u;v/ . \nExercise  22.5-3  asks  you  to handle  the  case  in which  there  is no shortest path \nfrom s to v. \nEffects  of relaxation  on  shortest-path  estimates  \nThe  next  group  of lemmas  describes  how  shortest-path  estima tes are affected by \nexecuting a sequence of relaxation steps on the edg es of a weighted, directed graph \nthat has been initialized by I NITIALIZE-SINGLE-SOURCE . \nLemma  22.11  (Upper-bound  property)  \nLet G D .V;E/  be a weighted, directed graph with weight function w W E !  R. \nLet s 2 V be the source vertex, and let the graph be initiali zed by I NITIALIZE- \nSINGLE-SOURCE.G;s/ . Then, v: d \ue004 \u0131.s;v/  for all v 2 V , and this invariant is \nmaintained over any sequence of relaxation steps on  the edges of G. Moreover, \nonce v: d achieves its lower bound \u0131.s;v/ , it never changes. \nProof  We prove the invariant v: d \ue004 \u0131.s;v/  for all vertices v 2 V by induction \nover the number of relaxation steps. 634  Chapter  22  Single-Source  Shortest  Paths  \nFor the base case, v: d \ue004 \u0131.s;v/  holds after initialization, since if v: d D 1 , \nthen v: d \ue004 \u0131.s;v/  for all v 2 V \ue003 fs g, and since s: d D 0 \ue004 \u0131.s;s/ . (Note that \n\u0131.s;s/  D \ue0031  if s is on  a negative-weight  cycle  and  that  \u0131.s;s/  D 0 otherwise.) \nFor the inductive step, consider the relaxation of an edge .u;v/ . By the inductive \nhypothesis, x: d \ue004 \u0131.s;x/  for all x 2 V prior to the relaxation. The only d value \nthat may change is v: d. If it changes, we have \nv: d D u: d C w.u;v/  \n\ue004 \u0131.s;u/  C w.u;v/  (by the inductive hypothesis) \n\ue004 \u0131.s;v/  (by the triangle inequality) , \nand so the invariant is maintained. \nThe value of v: d never changes once v: d D \u0131.s;v/  because, having achieved its \nlower bound, v: d cannot decrease since we have just shown that v: d \ue004 \u0131.s;v/ , and \nit cannot increase because relaxation steps do not increase d values. \nCorollary  22.12  (No-path  property)  \nSuppose that in a weighted, directed graph G D .V;E/  with weight function \nw W E !  R, no path connects a source vertex s 2 V to a given vertex v 2 V . \nThen, after the graph is initialized by I NITIALIZE-SINGLE-SOURCE  .G;s/ , we \nhave v: d D \u0131.s;v/  D 1 , and this equation is maintained as an invariant o ver \nany sequence of relaxation steps on the edges of G. \nProof  By  the  upper-bound  property,  we  always  have  1 D  \u0131.s;v/  \u0dc4 v: d, and \nthus v: d D 1 D  \u0131.s;v/ . \nLemma  22.13  \nLet G D .V;E/  be a weighted, directed graph with weight function w W E !  R, \nand let .u;v/  2 E. Then, immediately after edge .u;v/  is relaxed by a call of \nRELAX.u;v;w/ , we have v: d \u0dc4 u: d C w.u;v/ . \nProof  If, just prior to relaxing edge .u;v/ , we have v: d > u: d C w.u;v/ , then \nv: d D u: d C w.u;v/  afterward. If, instead, v: d \u0dc4 u: d C w.u;v/  just before \nthe relaxation, then neither u: d nor v: d changes, and so v: d \u0dc4 u: d C w.u;v/  \nafterward. \nLemma  22.14  (Convergence  property)  \nLet G D .V;E/  be a weighted, directed graph with weight function w W E !  R, \nlet s 2 V be a source vertex, and let s \u2740  u !  v be a shortest path in G for \nsome vertices u;v  2 V . Suppose that G is initialized by I NITIALIZE-SINGLE- \nSOURCE.G;s/  and then a sequence of relaxation steps that includ es the call 22.5 Proofs of shortest-paths properties 635 \nRELAX.u;v;w/  is executed on the edges of G. If u: d D \u0131.s;u/  at any time \nprior to the call, then v: d D \u0131.s;v/  at all times after the call. \nProof  By  the  upper-bound  property,  if u: d D \u0131.s;u/  at some  point  prior  to relax-  \ning edge .u;v/ , then this equation holds thereafter. In particula r, after edge .u;v/  \nis relaxed, we have \nv: d \u0dc4 u: d C w.u;v/  (by  Lemma  22.13)  \nD \u0131.s;u/  C w.u;v/  \nD \u0131.s;v/  (by  Lemma  22.1  on  page  606)  . \nThe  upper-bound  property  gives  v: d \ue004 \u0131.s;v/ , from which we conclude that \nv: d D \u0131.s;v/ , and this equation is maintained thereafter. \nLemma  22.15  (Path-relaxation  property)  \nLet G D .V;E/  be a weighted, directed graph with weight function w W E !  R, \nand let s 2 V be a source vertex. Consider any shortest path p D hv 0 ;v  1 ;:::;v  k i \nfrom s D v 0 to v k . If G is initialized by I NITIALIZE-SINGLE-SOURCE  .G;s/  and \nthen a sequence of relaxation steps occurs that inc ludes, in order, relaxing the edges \n.v 0 ;v  1 /;.v  1 ;v  2 /;:::;.v  k\ue0021 ;v  k /, then v k : d D \u0131.s;v  k / after these relaxations and \nat all times afterward. This property holds no matt er what other edge relaxations \noccur, including relaxations that are intermixed wi th relaxations of the edges of p. \nProof  We show by induction that after the i th edge of path p is relaxed, we have \nv i : d D \u0131.s;v  i /. For the base case, i D 0, and before any edges of p have been \nrelaxed, we have from the initialization that v 0 : d D s: d D 0 D \u0131.s;s/ . By the \nupper-bound  property,  the  value  of s: d never changes after initialization. \nFor the inductive step, assume that v i \ue0021 : d D \u0131.s;v  i \ue0021 /. What happens when \nedge .v i \ue0021 ;v  i / is relaxed?  By  the  convergence  property,  after  this  relaxat ion, we \nhave v i : d D \u0131.s;v  i /, and this equation is maintained at all times ther eafter. \nRelaxation  and  shortest-paths  trees  \nWe now show that once a sequence of relaxations has  caused the shortest-path  es-  \ntimates  to converge  to shortest-path  weights,  the  predeces sor subgraph G \ue003 induced \nby the resulting \ufffd values  is a shortest-paths  tree  for  G. We  start  with  the  follow-  \ning lemma, which shows that the predecessor subgrap h always forms a rooted tree \nwhose root is the source. \nLemma  22.16  \nLet G D .V;E/  be a weighted, directed graph with weight function w W E !  R, \nlet s 2 V be a source vertex, and assume that G contains  no  negative-weight  636  Chapter  22  Single-Source  Shortest  Paths  \ncycles that are reachable from s . Then, after the graph is initialized by I NITIALIZE- \nSINGLE-SOURCE.G;s/ , the predecessor subgraph G \ue003 forms a rooted tree with \nroot s , and any sequence of relaxation steps on edges of G maintains this property \nas an invariant. \nProof  Initially, the only vertex in G \ue003 is the  source  vertex,  and  the  lemma  is triv-  \nially true. Consider a predecessor subgraph G \ue003 that arises after a sequence of \nrelaxation  steps.  We  \u00fbrst  prove  that  G \ue003 is acyclic.  Suppose  for  the  sake  of contra-  \ndiction that some relaxation step creates a cycle i n the graph G \ue003 . Let the cycle be \nc D hv 0 ;v  1 ;:::;v  k i, where v k D v 0 . Then, v i :\ufffd  D v i \ue0021 for i D 1;2;:::;k  and, \nwithout loss of generality, assume that relaxing ed ge .v k\ue0021 ;v  k / created the cycle \nin G \ue003 . \nWe claim that all vertices on cycle c are reachable from the source vertex s . \nWhy?  Each  vertex  on  c has  a non- NIL predecessor, and so each vertex on c was  as-  \nsigned  a \u00fbnite  shortest-path  estimate  when  it was  assigned  its  non- NIL \ufffd value. By \nthe  upper-bound  property,  each  vertex  on  cycle  c has  a \u00fbnite  shortest-path  weight,  \nwhich means that it is reachable from s . \nWe9ll  examine  the  shortest-path  estimates  on  cycle  c immediately before the call \nRELAX.v k\ue0021 ;v  k ;w/  and show that c is a negative-weight  cycle,  thereby  contra-  \ndicting the assumption that G contains  no  negative-weight  cycles  that  are  reachable  \nfrom  the  source.  Just  before  the  call,  we  have  v i :\ufffd  D v i \ue0021 for i D 1;2;:::;k  \ue003 1. \nThus, for i D 1;2;:::;k  \ue003 1, the last update to v i : d was by the assignment \nv i : d D v i \ue0021 : dCw.v  i \ue0021 ;v  i /. If v i \ue0021 : d changed since then, it decreased. Therefore, \njust before the call R ELAX.v k\ue0021 ;v  k ;w/, we have \nv i : d \ue004 v i \ue0021 : d C w.v  i \ue0021 ;v  i / for all i D 1;2;:::;k  \ue003 1:  (22.11)  \nBecause v k :\ufffd  is changed by the call R ELAX.v k\ue0021 ;v  k ;w/, immediately beforehand \nwe also have the strict inequality \nv k : d >v  k\ue0021 : d C w.v  k\ue0021 ;v  k /: \nSumming this strict inequality with the k \ue003 1 inequalities  (22.11),  we  obtain  the  \nsum  of the  shortest-path  estimates  around  cycle  c : \nk X  \ni D1 v i : d > k X  \ni D1 .v i \ue0021 : d C w.v  i \ue0021 ;v  i // \nD k X  \ni D1 v i \ue0021 : d C k X  \ni D1 w.v  i \ue0021 ;v  i /: \nBut \nk X  \ni D1 v i : d D k X  \ni D1 v i \ue0021 : d ; 22.5 Proofs of shortest-paths properties 637 \ns u x \ny z v \nFigure  22.9  Showing that a simple path in G \ue003 from source vertex s to vertex v is unique. If G \ue003 \ncontains two paths p 1 (s \u2740  u \u2740  x !  \u00b4 \u2740  v) and p 2 (s \u2740  u \u2740  y !  \u00b4 \u2740  v), where x \u00a4 y, then \n\u00b4:\ufffd  D x and \u00b4:\ufffd  D y, a contradiction. \nsince each vertex in the cycle c appears exactly once in each summation. This \nequation implies \n0>  k X  \ni D1 w.v  i \ue0021 ;v  i /: \nThus, the sum of weights around the cycle c is negative, which provides the desired \ncontradiction. \nWe have now proven that G \ue003 is a directed, acyclic graph. To show that it forms  \na rooted tree with root s , it suf\u00fbces  (see  Exercise  B.5-2  on  page  1175)  to prove  that  \nfor each vertex v 2 V \ue003 , there is a unique simple path from s to v in G \ue003 . \nThe vertices in V \ue003 are  those  with  non- NIL \ufffd values, plus s . Exercise  22.5-6  asks  \nyou to prove that a path from s exists to each vertex in V \ue003 . \nTo complete the proof of the lemma, we now show tha t for any vertex v 2 V \ue003 , the \ngraph G \ue003 contains at most one simple path from s to v. Suppose otherwise. That \nis, suppose that, as Figure 22.9 illustrates, G \ue003 contains two simple paths from s \nto some vertex v: p 1 , which we decompose into s \u2740  u \u2740  x !  \u00b4 \u2740  v, and p 2 , \nwhich we decompose into s \u2740  u \u2740  y !  \u00b4 \u2740  v, where x \u00a4 y (though u \ncould be s and \u00b4 could be v). But then, \u00b4:\ufffd  D x and \u00b4:\ufffd  D y , which implies \nthe contradiction that x D y . We conclude that G \ue003 contains a unique simple path \nfrom s to v, and thus G \ue003 forms a rooted tree with root s . \nWe can now show that if all vertices have been assi gned their true  shortest-path  \nweights after a sequence of relaxation steps, then the predecessor subgraph G \ue003 is \na shortest-paths  tree.  \nLemma  22.17  (Predecessor-subgraph  property)  \nLet G D .V;E/  be a weighted, directed graph with weight function w W E !  R, \nlet s 2 V be a source vertex, and assume that G contains  no  negative-weight  cycles  \nthat are reachable from s . Then, after a call to I NITIALIZE-S INGLE-SOURCE  .G;s/  \nfollowed by any sequence of relaxation steps on edg es of G that produces v: d D \n\u0131.s;v/  for all v 2 V , the predecessor subgraph G \ue003 is a shortest-paths  tree  rooted  \nat s . 638  Chapter  22  Single-Source  Shortest  Paths  \nProof  We  must  prove  that  the  three  properties  of shortest-paths  trees given on \npage  608  hold  for  G \ue003 . To  show  the  \u00fbrst  property,  we  must  show  that  V \ue003 is the set \nof vertices reachable from s . By  de\u00fbnition,  a shortest-path  weight  \u0131.s;v/  is \u00fbnite  \nif and only if v is reachable from s , and thus the vertices that are reachable from s \nare  exactly  those  with  \u00fbnite  d values. But a vertex v 2 V \ue003 fs g has been assigned \na \u00fbnite  value  for  v: d if and only if v:\ufffd  \u00a4 NIL, since both assignments occur in \nRELAX . Thus, the vertices in V \ue003 are exactly those reachable from s . \nThe second property, that G \ue003 forms a rooted tree with root s , follows directly \nfrom  Lemma  22.16.  \nIt remains, therefore, to prove the last property o f shortest-paths  trees:  for  each  \nvertex v 2 V \ue003 , the unique simple path s p \u2740  v in G \ue003 is a shortest path from s \nto v in G. Let p D hv 0 ;v  1 ;:::;v  k i, where v 0 D s and v k D v. Consider \nan edge .v i \ue0021 ;v  i / in path p. Because this edge belongs to G \ue003 , the  last  relax-  \nation that changed v i : d must have been of this edge. After that relaxation,  we had \nv i : d D v i \ue0021 : d C .v i \ue0021 ;v  i /. Subsequently, an edge entering v i \ue0021 could have been \nrelaxed, causing v i \ue0021 : d to decrease further, but without changing v i : d. There-  \nfore, we have v i : d \ue004 v i \ue0021 : d C w.v  i \ue0021 ;v  i /. Thus, for i D 1;2;:::;k , we have \nboth v i : d D \u0131.s;v  i / and v i : d \ue004 v i \ue0021 : d C w.v  i \ue0021 ;v  i /, which together imply \nw.v  i \ue0021 ;v  i / \u0dc4 \u0131.s;v  i / \ue003 \u0131.s;v  i \ue0021 /. Summing the weights along path p yields \nw.p/  D k X  \ni D1 w.v  i \ue0021 ;v  i / \n\u0dc4 k X  \ni D1 .\u0131.s;v  i / \ue003 \u0131.s;v  i \ue0021 // \nD \u0131.s;v  k / \ue003 \u0131.s;v  0 / (because the sum telescopes) \nD \u0131.s;v  k / (because \u0131.s;v  0 / D \u0131.s;s/  D 0) . \nThus, we have w.p/  \u0dc4 \u0131.s;v  k /. Since \u0131.s;v  k / is a lower bound on the weight of \nany path from s to v k , we conclude that w.p/  D \u0131.s;v  k /, and p is a shortest path \nfrom s to v D v k . \nExercises  \n22.5-1  \nGive  two  shortest-paths  trees  for  the  directed  graph  of Figure  22.2  on  page  609  \nother than the two shown. \n22.5-2  \nGive  an example  of a weighted,  directed  graph  G D .V;E/  with weight function \nw W E !  R and source vertex s such that G satis\u00fbes  the  following  property:  For  22.5 Proofs of shortest-paths properties 639 \nevery edge .u;v/  2 E, there  is a shortest-paths  tree  rooted  at s that contains .u;v/  \nand  another  shortest-paths  tree  rooted  at s that does not contain .u;v/ . \n22.5-3  \nModify  the  proof  of Lemma  22.10  to handle  cases  in which  shortest-path  weights  \nare 1  or \ue0031. \n22.5-4  \nLet G D .V;E/  be a weighted, directed graph with source vertex s , and let G \nbe initialized by I NITIALIZE-SINGLE-SOURCE  .G;s/ . Prove that if a sequence of \nrelaxation steps sets s:\ufffd  to a non- NIL value, then G contains  a negative-weight  \ncycle. \n22.5-5  \nLet G D .V;E/  be a weighted,  directed  graph  with  no  negative-weight  edges . Let \ns 2 V be the source vertex, and suppose that v:\ufffd  is allowed to be the predecessor \nof v on any  shortest path to v from source s if v 2 V \ue003 fs g is reachable from s , \nand NIL otherwise.  Give  an example  of such  a graph  G and an assignment of \ufffd \nvalues that produces a cycle in G \ue003 . (By  Lemma  22.16,  such  an assignment  cannot  \nbe produced by a sequence of relaxation steps.) \n22.5-6  \nLet G D .V;E/  be a weighted, directed graph with weight function w W E !  R \nand  no  negative-weight  cycles.  Let  s 2 V be the source vertex, and let G be \ninitialized by I NITIALIZE-SINGLE-SOURCE  .G;s/ . Use induction to prove that for \nevery vertex v 2 V \ue003 , there exists a path from s to v in G \ue003 and that this property is \nmaintained as an invariant over any sequence of rel axations. \n22.5-7  \nLet G D .V;E/  be a weighted,  directed  graph  that  contains  no  negative-wei ght \ncycles. Let s 2 V be the source vertex, and let G be initialized by I NITIALIZE- \nSINGLE-SOURCE.G;s/ . Prove that there exists a sequence of jV j \ue003  1 relaxation \nsteps that produces v: d D \u0131.s;v/  for all v 2 V . \n22.5-8  \nLet G be an arbitrary  weighted,  directed  graph  with  a negative-weight  cycle  reach-  \nable from the source vertex s . Show  how  to construct  an in\u00fbnite  sequence  of relax-  \nations of the edges of G such  that  every  relaxation  causes  a shortest-path  estimate  \nto change. 640  Chapter  22  Single-Source  Shortest  Paths  \nProblems  \n22-1  Yen\u2019s  improvement  to Bellman-Ford  \nThe  Bellman-Ford  algorithm  does  not  specify  the  order  in which to relax edges \nin each pass. Consider the following method for dec iding upon the order. Before \nthe  \u00fbrst  pass,  assign  an arbitrary  linear  order  v 1 ;v  2 ;:::;v  jV j to the vertices of the \ninput graph G D .V;E/ . Then partition the edge set E into E f [ E b , where \nE f D f.v i ;v  j / 2 E W i<j  g and E b D f.v i ;v  j / 2 E W i >j  g. (Assume that G \ncontains  no  self-loops,  so that  every  edge  belongs  to either  E f or E b .) De\u00fbne  \nG f D .V;E  f / and G b D .V;E  b /. \na. Prove that G f is acyclic with topological sort hv 1 ;v  2 ;:::;v  jV j i and that G b is \nacyclic with topological sort hv jV j ;v  jV j\ue0021 ;:::;v  1 i. \nSuppose  that  each  pass  of the  Bellman-Ford  algorithm  relaxes  edges  in the  fol-  \nlowing way. First, visit each vertex in the order v 1 ;v  2 ;:::;v  jV j , relaxing edges \nof E f that leave the vertex. Then visit each vertex in th e order v jV j ;v  jV j\ue0021 ;:::;v  1 , \nrelaxing edges of E b that leave the vertex. \nb. Prove that with this scheme, if G contains  no  negative-weight  cycles  that  are  \nreachable from the source vertex s , then after only djV j =2e passes over the \nedges, v: d D \u0131.s;v/  for all vertices v 2 V . \nc. Does this scheme improve the asymptotic running tim e of the Bellman-Ford  \nalgorithm?  \n22-2  Nesting  boxes  \nA d -dimensional  box  with  dimensions  .x 1 ;x  2 ;:::;x  d / nests  within another box \nwith dimensions .y 1 ;y  2 ;:::;y  d / if there exists a permutation \ufffd on f1;2;:::;d  g \nsuch that x \ue003.1/  <y  1 , x \ue003.2/  <y  2 , . . . , x \ue003.d/  <y  d . \na. Argue that the nesting relation is transitive. \nb. Describe  an ef\u00fbcient  method  to determine  whether  one  d -dimensional  box  nests  \ninside another. \nc. You are given a set of nd  -dimensional  boxes  fB 1 ;B  2 ;:::;B  n g. Give  an ef\u00fb-  \ncient  algorithm  to \u00fbnd  the  longest  sequence  hB i 1 ;B  i 2 ;:::;B  i k i of boxes such \nthat B i j nests within B i j C1 for j D 1;2;:::;k  \ue003 1. Express the running time \nof your algorithm in terms of n and d . Problems for Chapter 22 641 \n22-3  Arbitrage  \nArbitrage  is the use of discrepancies in currency exchange ra tes to transform one \nunit of a currency into more than one unit of the s ame currency. For example, \nsuppose that one U.S. dollar buys 64  Indian rupees, one Indian rupee buys 1:8  \nJapanese  yen,  and  one  Japanese  yen  buys  0:009  U.S. dollars. Then, by converting \ncurrencies, a trader can start with 1 U.S. dollar and buy 64  \ue005 1:8  \ue005 0:009  D 1:0368  \nU.S.  dollars,  thus  turning  a pro\u00fbt  of 3:68%. \nSuppose that you are given n currencies c 1 ;c 2 ;:::;c  n and an n \ue005 n table R of \nexchange rates, such that 1 unit of currency c i buys R\u0152i; j \ufffd  units of currency c j . \na. Give  an ef\u00fbcient  algorithm  to determine  whether  there  exist s a sequence of \ncurrencies hc i 1 ;c i 2 ;:::;c  i k i such that \nR\u0152i  1 ;i 2 \ufffd \ue001 R\u0152i  2 ;i 3 \ufffd \ue001 \ue001 \ue001  R\u0152i  k\ue0021 ;i k \ufffd \ue001 R\u0152i  k ;i 1 \ufffd > 1 :  \nAnalyze the running time of your algorithm. \nb. Give  an ef\u00fbcient  algorithm  to print  out  such  a sequence  if one  exists. Analyze \nthe running time of your algorithm. \n22-4  Gabow\u2019s  scaling  algorithm  for  single-source  shortest  paths  \nA scaling  algorithm solves a problem by initially considering  only the highest-  \norder bit of each relevant input value, such as an edge weight, assuming that these \nvalues  are  nonnegative  integers.  The  algorithm  then  re\u00fbnes  the initial solution by \nlooking  at the  two  highest-order  bits.  It progressively  looks at more and more \nhigh-order  bits,  re\u00fbning  the  solution  each  time,  until  it has examined all bits and \ncomputed the correct solution. \nThis problem examines an algorithm for computing th e shortest paths from a \nsingle source by scaling edge weights. The input is  a directed graph G D .V;E/  \nwith nonnegative integer edge weights w. Let W D max fw.u;v/  W .u;v/  2 Eg \nbe the maximum weight of any edge. In this problem,  you will develop  an algo-  \nrithm that runs in O.E  lg W/  time. Assume that all vertices are reachable from t he \nsource. \nThe scaling algorithm uncovers the bits in the bina ry representation of the edge \nweights  one  at a time,  from  the  most  signi\u00fbcant  bit  to the  least  signi\u00fbcant  bit.  \nSpeci\u00fbcally,  let  k D dlg.W  C 1/e be the  number  of bits  in the  binary  represen-  \ntation of W , and for i D 1;2;:::;k , let w i .u;v/  D \ue00a \nw.u;v/=2  k\ue002i \u02d8 . That is, \nw i .u;v/  is the  <scaled-down=  version  of w.u;v/  given by the i most  signi\u00fbcant  \nbits of w.u;v/ . (Thus, w k .u;v/  D w.u;v/  for all .u;v/  2 E.) For example, \nif k D 5 and w.u;v/  D 25, which has the binary representation h11001 i, then \nw 3 .u;v/  D h110i D  6. Also with k D 5, if w.u;v/  D h00100 i D  4, then \nw 4 .u;v/  D h0010i D  2. De\u00fbne  \u0131 i .u;v/  as the  shortest-path  weight  from  vertex  u 642  Chapter  22  Single-Source  Shortest  Paths  \nto vertex v using weight function w i , so that \u0131 k .u;v/  D \u0131.u;v/  for all u;v  2 V . \nFor a given source vertex s , the  scaling  algorithm  \u00fbrst  computes  the  shortest-path  \nweights \u0131 1 .s;v/  for all v 2 V , then computes \u0131 2 .s;v/  for all v 2 V , and  so on,  un-  \ntil it computes \u0131 k .s;v/  for all v 2 V . Assume throughout that jEj \ue004 jV j \ue003  1. You \nwill show how to compute \u0131 i from \u0131 i \ue0021 in O.E/  time, so that the entire algorithm \ntakes O.kE/  D O.E  lg W/  time. \na. Suppose that for all vertices v 2 V , we have \u0131.s;v/  \u0dc4 jEj. Show how to \ncompute \u0131.s;v/  for all v 2 V in O.E/  time. \nb. Show how to compute \u0131 1 .s;v/  for all v 2 V in O.E/  time. \nNow focus on computing \u0131 i from \u0131 i \ue0021 . \nc. Prove that for i D 2;3;:::;k , either w i .u;v/  D 2w  i \ue0021 .u;v/  or w i .u;v/  D \n2w  i \ue0021 .u;v/  C 1. Then prove that \n2\u0131 i \ue0021 .s;v/  \u0dc4 \u0131 i .s;v/  \u0dc4 2\u0131 i \ue0021 .s;v/  C jV j \ue003  1 \nfor all v 2 V . \nd. De\u00fbne,  for  i D 2;3;:::;k  and all .u;v/  2 E, \ny w i .u;v/  D w i .u;v/  C 2\u0131 i \ue0021 .s;u/  \ue003 2\u0131 i \ue0021 .s;v/:  \nProve that for i D 2;3;:::;k  and all u;v  2 V , the <reweighted= value y w i .u;v/  \nof edge .u;v/  is a nonnegative integer. \ne. Now  de\u00fbne  y \u0131 i .s;v/  as the  shortest-path  weight  from  s to v using the weight \nfunction y w i . Prove that for i D 2;3;:::;k  and all v 2 V , \n\u0131 i .s;v/  D y \u0131 i .s;v/  C 2\u0131 i \ue0021 .s;v/  \nand that y \u0131 i .s;v/  \u0dc4 jEj. \nf. Show how to compute \u0131 i .s;v/  from \u0131 i \ue0021 .s;v/  for all v 2 V in O.E/  time. \nConclude that you can compute \u0131.s;v/  for all v 2 V in O.E  lg W/  time. \n22-5  Karp\u2019s  minimum  mean-weight  cycle  algorithm  \nLet G D .V;E/  be a directed graph with weight function w W E !  R, and \nlet n D jV j. We  de\u00fbne  the  mean  weight  of a cycle c D he 1 ;e 2 ;:::;e  k i of edges \nin E to be Problems for Chapter 22 643 \n\ufffd.c/  D 1 \nk k X  \ni D1 w.e  i /: \nLet \ufffd \ue003 D min f\ufffd.c/  W c is a directed cycle in Gg. We call a cycle c for which \n\ufffd.c/  D \ufffd \ue003 a minimum  mean-weight  cycle. This  problem  investigates  an ef\u00fbcient  \nalgorithm for computing \ufffd \ue003 . \nAssume without loss of generality that every vertex  v 2 V is reachable from a \nsource vertex s 2 V . Let \u0131.s;v/  be the weight of a shortest path from s to v, and let \n\u0131 k .s;v/  be the weight of a shortest path from s to v consisting of exactly  k edges. \nIf there is no path from s to v with exactly k edges, then \u0131 k .s;v/  D 1 . \na. Show that if \ufffd \ue003 D 0, then G contains  no  negative-weight  cycles  and  \u0131.s;v/  D \nmin f\u0131 k .s;v/  W 0 \u0dc4 k \u0dc4 n \ue003 1g for all vertices v 2 V . \nb. Show that if \ufffd \ue003 D 0, then \nmax \u00ef \u0131 n .s;v/  \ue003 \u0131 k .s;v/  \nn \ue003 k W 0 \u0dc4 k \u0dc4 n \ue003 1 \u00f0 \n\ue004 0 \nfor all vertices v 2 V . (Hint: Use both properties from part (a).) \nc. Let c be a 0-weight  cycle,  and  let  u and v be any two vertices on c . Suppose \nthat \ufffd \ue003 D 0 and that the weight of the simple path from u to v along the cycle \nis x . Prove that \u0131.s;v/  D \u0131.s;u/  C x . (Hint: The weight of the simple path \nfrom v to u along the cycle is \ue003x .) \nd. Show that if \ufffd \ue003 D 0, then  on  each  minimum  mean-weight  cycle  there  exists  a \nvertex v such that \nmax \u00ef \u0131 n .s;v/  \ue003 \u0131 k .s;v/  \nn \ue003 k W 0 \u0dc4 k \u0dc4 n \ue003 1 \u00f0 \nD 0:  \n(Hint: Show how to extend a shortest path to any vertex on  a minimum me an-  \nweight cycle along the cycle to make a shortest pat h to the next vertex on the \ncycle.) \ne. Show that if \ufffd \ue003 D 0, then the minimum value of \nmax \u00ef \u0131 n .s;v/  \ue003 \u0131 k .s;v/  \nn \ue003 k W 0 \u0dc4 k \u0dc4 n \ue003 1 \u00f0 \n; \ntaken over all vertices v 2 V , equals 0. 644  Chapter  22  Single-Source  Shortest  Paths  \nf. Show that if you add a constant t to the weight of each edge of G, then \ufffd \ue003 \nincreases by t . Use this fact to show that \ufffd \ue003 equals the minimum value of \nmax \u00ef \u0131 n .s;v/  \ue003 \u0131 k .s;v/  \nn \ue003 k W 0 \u0dc4 k \u0dc4 n \ue003 1 \u00f0 \n; \ntaken over all vertices v 2 V . \ng. Give  an O.VE/-time  algorithm  to compute  \ufffd \ue003 . \n22-6  Bitonic  shortest  paths  \nA sequence is bitonic  if it monotonically  increases  and  then  monotonically  de-  \ncreases, or if by a circular shift it monotonically  increases and then monotonically \ndecreases. For example the sequences h1;4;6;8;3;  \ue0032i, h9;2;  \ue0034; \ue00310;  \ue0035i , and \nh1;2;3;4 i are bitonic, but h1;3;12;4;2;10 i is not  bitonic.  (See  Problem  14-3  on  \npage  407  for  the  bitonic  euclidean  traveling-salesperson  problem.) \nSuppose that you are given a directed graph G D .V;E/  with weight function \nw W E !  R, where  all  edge  weights  are  unique,  and  you  wish  to \u00fbnd  single-source  \nshortest paths from a source vertex s . You  are  given  one  additional  piece  of infor-  \nmation: for each vertex v 2 V , the weights of the edges along any shortest path \nfrom s to v form a bitonic sequence. \nGive  the  most  ef\u00fbcient  algorithm  you  can  to solve  this  proble m, and analyze its \nrunning time. \nChapter  notes  \nThe  shortest-path  problem  has  a long  history  that  is nicely  desribed in an article \nby  Schrijver  [400].  He  credits  the  general  idea  of repeatedly  executing  edge  relax-  \nations  to Ford  [148].  Dijkstra9s  algorithm  [116]  appeared  in 1959,  but  it contained  \nno  mention  of a priority  queue.  The  Bellman-Ford  algorithm  is based on separate \nalgorithms  by  Bellman  [45]  and  Ford  [149].  The  same  algorith m is also attributed \nto Moore  [334].  Bellman  describes  the  relation  of shortest  paths  to difference  con-  \nstraints.  Lawler  [276]  describes  the  linear-time  algorith m for shortest paths in a \ndag, which he considers part of the folklore. \nWhen edge weights are relatively small nonnegative integers, more  ef\u00fbcient  al-  \ngorithms  result  from  using  min-priority  queues  that  requir e integer keys and rely \non the sequence of values returned by the E XTRACT-MIN calls  in Dijkstra9s  al-  \ngorithm monotonically increasing over time. Ahuja, Mehlhorn,  Orlin,  and  Tar-  \njan  [8]  give  an algorithm  that  runs  in O.E  C V p \nlg W/  time on graphs with \nnonnegative edge weights, where W is the largest weight of any edge in the Notes for Chapter 22 645 \ngraph.  The  best  bounds  are  by  Thorup  [436],  who  gives  an algor ithm that runs \nin O.E  lg lg V/  time,  and  by  Raman  [375],  who  gives  an algorithm  that  runs  \nin O \u00e3 \nE C V min \u02da \n.lg V/  1=3C\ue001 ;.lg W/  1=4C\ue001 \ue009\u00e4 \ntime. These two algorithms use an \namount of space that depends on the word size of th e underlying machine.  Al-  \nthough the amount of space used can be unbounded in  the size of the input, it can \nbe reduced to be linear in the size of the input us ing randomized hashing. \nFor  undirected  graphs  with  integer  weights,  Thorup  [435]  gives an algorithm \nthat runs in O.V  C E/  time  for  single-source  shortest  paths.  In contrast  to the  \nalgorithms mentioned in the previous paragraph, the  sequence of values returned \nby E XTRACT-MIN calls does not monotonically increase over time, an d so this \nalgorithm  is not  an implementation  of Dijkstra9s  algorithm.  Pettie  and  Ramachan-  \ndran  [357]  remove  the  restriction  of integer  weights  on  undirected graphs. Their \nalgorithm entails a preprocessing phase, followed b y queries for  speci\u00fbc  source  \nvertices. Preprocessing takes O.MST .V;E/  C min fV lg V;V  lg lg r g/ time, where \nMST .V;E/  is the time to compute a minimum spanning tree and r is the ratio \nof the maximum edge weight to the minimum edge weig ht. After preprocessing, \neach query takes O.E  lg y \u02db.E;V//  time, where y \u02db.E;V/  is the  inverse  of Acker-  \nmann9s  function.  (See  the  chapter  notes  for  Chapter  19  for  a brief discussion of \nAckermann9s  function  and  its  inverse.)  \nFor  graphs  with  negative  edge  weights,  an algorithm  due  to Gabow  and  Tar-  \njan  [167]  runs  in O.  p \nVE  lg.VW//  time,  and  one  by  Goldberg  [186]  runs  in \nO.  p \nVE  lg W/  time, where W D max fjw.u;v/ j W .u;v/  2 Eg. There has also \nbeen some progress based on methods that use contin uous optimization  and  elec-  \ntrical  \u00fcows.  Cohen  et al.  [98]  give  such  an algorithm,  which  is randomized and \nruns in e O.E  10=7  lg W/  expected  time  (see  Problem  3-6  on  page  73  for  the  de\u00fbn-  \ntion of e O-notation).  There  is also  a pseudopolyomial-time  algorith m based on fast \nmatrix  multiplication.  Sankowski  [394]  and  Yuster  and  Zwick  [465]  designed  an \nalgorithm for shortest paths that runs in e O.WV  ! / time, where two n \ue005 n matri-  \nces can be multiplied in O.n  ! / time, giving a faster algorithm than the previously  \nmentioned algorithms for small values of W on dense graphs. \nCherkassky,  Goldberg,  and  Radzik  [89]  conducted  extensive  experiments  com-  \nparing  various  shortest-path  algorithms.  Shortest-path  algorithms are widely used \nin real-time  navigation  and  route-planning  applications.  Typically  based  on  Dijk-  \nstra9s  algorithm,  these  algorithms  use  many  clever  ideas  to be able to compute \nshortest paths on networks with many millions of ve rtices and edges in fractions of \na second.  Bast  et al.  [36]  survey  many  of these  developments.  23  All-Pairs  Shortest  Paths  \nIn this  chapter,  we  turn  to the  problem  of \u00fbnding  shortest  paths between all pairs \nof vertices in a graph. A classic application of th is problem occurs in computing a \ntable of distances between all pairs of cities for a road atlas. Classic perhaps, but \nnot  a true  application  of \u00fbnding  shortest  paths  between  all pairs of vertices. After \nall, a road map modeled as a graph has one vertex f or every  road intersection and \none edge wherever a road connects intersections. A table of intercity distances in an \natlas  might  include  distances  for  100  cities,  but  the  United  States has approximately \n300,000  signal-controlled  intersections  1 and many more uncontrolled intersections. \nA legitimate  application  of all-pairs  shortest  paths  is to determine the diameter  \nof a network: the longest of all shortest paths. If  a directed graph  models  a com-  \nmunication network, with the weight of an edge indi cating the time required for \na message to traverse a communication link, then th e diameter gives the longest \npossible transit time for a message in the network.  \nAs in Chapter 22, the input is a weighted, directed  graph G D .V;E/  with a \nweight function w W E !  R that  maps  edges  to real-valued  weights.  Now  the  goal  \nis to \u00fbnd,  for  every  pair  of vertices  u;v  2 V , a shortest  (least-weight)  path  from  u \nto v, where the weight of a path is the sum of the weig hts of its constituent edges. \nFor  the  all-pairs  problem,  the  output  typically  takes  a tabular form in which the \nentry in u9s row  and  v9s column  is the  weight  of a shortest  path  from  u to v. \nYou  can  solve  an all-pairs  shortest-paths  problem  by  running  a single-source  \nshortest-paths  algorithm  jV j times, once with each vertex as the source. If all \nedge  weights  are  nonnegative,  you  can  use  Dijkstra9s  algorithm.  If you  imple-  \nment  the  min-priority  queue  with  a linear  array,  the  running  time is O.V  3 C VE/  \nwhich is O.V  3 /. The  binary  min-heap  implementation  of the  min-priority  queue \n1 According to a report cited by U.S. Department of T ransportation Federal Highway Administration, \n<a reasonable  8rule  of thumb9  is one  signalized  intersection  per  1,000  population.=  Chapter 23 All-Pairs Shortest Paths 647 \nyields a running time of O.V.V  C E/  lg V/. If jEj D  \ufffd.V  /, the running time \nbecomes O.VE  lg V/, which is faster than O.V  3 / if the  graph  is sparse.  Alterna-  \ntively,  you  can  implement  the  min-priority  queue  with  a Fibonacci heap, yielding \na running time of O.V  2 lg V C VE/. \nIf the  graph  contains  negative-weight  edges,  Dijkstra9s  algorithm  doesn9t  work,  \nbut  you  can  run  the  slower  Bellman-Ford  algorithm  once  from  each vertex. The \nresulting running time is O.V  2 E/, which on a dense graph is O.V  4 /. This chapter \nshows how to guarantee a much better asymptotic run ning time. It also investigates \nthe  relation  of the  all-pairs  shortest-paths  problem  to matrix multiplication. \nUnlike  the  single-source  algorithms,  which  assume  an adjacency-list  representa-  \ntion of the graph, most of the algorithms in this c hapter represent the graph by \nan adjacency  matrix.  (Johnson9s  algorithm  for  sparse  graphs,  in Section  23.3,  \nuses adjacency lists.) For convenience, we assume t hat the vertices are numbered \n1;2;:::;  jV j, so that the input is an n \ue005 n matrix W D .w  ij / representing the edge \nweights of an n-vertex  directed  graph  G D .V;E/ , where \nw ij D \u0128 \n0 if i D j ;  \nthe weight of directed edge .i;j/  if i \u00a4 j and .i;j/  2 E;  \n1  if i \u00a4 j and .i;j/  \u2026 E:  (23.1)  \nThe  graph  may  contain  negative-weight  edges,  but  we  assume  for the time being \nthat  the  input  graph  contains  no  negative-weight  cycles.  \nThe  tabular  output  of each  of the  all-pairs  shortest-paths  algorithms presented \nin this chapter is an n \ue005 n matrix. The .i;j/  entry of the output matrix contains \n\u0131.i;j/, the  shortest-path  weight  from  vertex  i to vertex j , as in Chapter 22. \nA full  solution  to the  all-pairs  shortest-paths  problem  includes not only the \nshortest-path  weights  but  also  a predecessor  matrix  \u2026 D .\ufffd  ij /, where \ufffd ij is NIL \nif either i D j or there is no path from i to j , and otherwise \ufffd ij is the  predeces-  \nsor of j on some shortest path from i . Just  as the  predecessor  subgraph  G \ue003 from \nChapter  22  is a shortest-paths  tree  for  a given  source  vertex , the subgraph induced \nby the i th row of the \u2026 matrix  should  be a shortest-paths  tree  with  root  i . For each \nvertex i 2 V , the predecessor  subgraph  of G for i is G \ue003;i  D .V  \ue003;i  ;E  \ue003;i  /, where \nV \ue003;i  D fj 2 V W \ufffd ij \u00a4 NILg [ fi g ; \nE \ue003;i  D f.\ufffd  ij ;j/  W j 2 V \ue003;i  \ue003 fi gg : \nIf G \ue003;i  is a shortest-paths  tree,  then  PRINT-ALL-PAIRS-S HORTEST-PATH on the \nfollowing  page,  which  is a modi\u00fbed  version  of the  PRINT-PATH procedure from \nChapter 20, prints a shortest path from vertex i to vertex j . \nIn order  to highlight  the  essential  features  of the  all-pairs  algorithms  in this  chap-  \nter,  we  won9t  cover  how  to compute  predecessor  matrices  and  their properties as \nextensively as we dealt with predecessor subgraphs in Chapter 22. Some of the \nexercises cover the basics. 648 Chapter 23 All-Pairs Shortest Paths \nPRINT-ALL-PAIRS-S HORTEST-PATH .\u2026;i;j/  \n1 if i == j \n2 print i \n3 elseif  \ufffd ij == NIL \n4 print <no path from= i <to= j <exists= \n5 else  PRINT-ALL-PAIRS-SHORTEST-PATH .\u2026; i; \ufffd  ij / \n6 print j \nChapter  outline  \nSection  23.1  presents  a dynamic-programming  algorithm  based  on  matrix  mul-  \ntiplication  to solve  the  all-pairs  shortest-paths  problem.  The  technique  of <re-  \npeated squaring= yields a running time of \u201a.V  3 lg V/. Section  23.2  gives  another  \ndynamic-programming  algorithm,  the  Floyd-Warshall  algor ithm, which runs in \n\u201a.V  3 / time.  Section  23.2  also  covers  the  problem  of \u00fbnding  the  transitive closure \nof a directed  graph,  which  is related  to the  all-pairs  shortest-paths  problem.  Finally,  \nSection  23.3  presents  Johnson9s  algorithm,  which  solves  the  all-pairs  shortest-paths  \nproblem in O.V  2 lg V C VE/  time and is a good choice for large, sparse graphs.  \nBefore proceeding, we need to establish some conven tions for adjacency-matrix  \nrepresentations. First, we generally assume that th e input graph G D .V;E/  has n \nvertices, so that n D jV j. Second, we use the convention of denoting matrice s by \nuppercase letters, such as W , L, or D, and their individual elements by subscripted \nlowercase letters, such as w ij , l ij , or d ij . Finally, some matrices have parenthesized \nsuperscripts, as in L .r/  D \u00e3 \nl .r/  \nij \u00e4 \nor D .r/  D \u00e3 \nd .r/  \nij \u00e4 \n, to indicate iterates. \n23.1  Shortest  paths  and  matrix  multiplication  \nThis  section  presents  a dynamic-programming  algorithm  for  the  all-pairs  shortest-  \npaths problem on a directed graph G D .V;E/ . Each major loop of the dynamic \nprogram invokes an operation similar to matrix mult iplication, so that the algorithm \nlooks  like  repeated  matrix  multiplication.  We9ll  start  by  developing a \u201a.V  4 /-time  \nalgorithm  for  the  all-pairs  shortest-paths  problem,  and  then  we9ll  improve  its  run-  \nning time to \u201a.V  3 lg V/. \nBefore  proceeding,  let9s  brie\u00fcy  recap  the  steps  given  in Chapter  14  for  develop-  \ning  a dynamic-programming  algorithm:  \n1. Characterize  the  structure  of an optimal  solution.  \n2. Recursively  de\u00fbne  the  value  of an optimal  solution.  \n3. Compute  the  value  of an optimal  solution  in a bottom-up  fashion. 23.1  Shortest  paths  and  matrix  multiplication  649 \nWe  reserve  the  fourth  step4constructing  an optimal  solution  from  computed  in-  \nformation4for  the  exercises.  \nThe  structure  of a shortest  path  \nLet9s  start  by  characterizing  the  structure  of an optimal  solution.  Lemma  22.1  \ntells us that all subpaths of a shortest path are s hortest paths. Consider a shortest \npath p from vertex i to vertex j , and suppose that p contains at most r edges. \nAssuming  that  there  are  no  negative-weight  cycles,  r is \u00fbnite.  If i D j , then p has \nweight 0 and no edges. If vertices i and j are distinct, then decompose path p into \ni p 0 \n\u2740  k !  j , where path p 0 now contains at most r \ue003 1 edges.  Lemma  22.1  says  \nthat p 0 is a shortest path from i to k, and so \u0131.i;j/  D \u0131.i;k/  C w kj  . \nA recursive  solution  to the  all-pairs  shortest-paths  problem  \nNow, let l .r/  \nij be the minimum weight of any path from vertex i to vertex j that \ncontains at most r edges. When r D 0, there is a shortest path from i to j with no \nedges if and only if i D j , yielding \nl .0/  \nij D ( \n0 if i D j ;  \n1  if i \u00a4 j :  (23.2)  \nFor r \ue004 1, one  way  to achieve  a minimum-weight  path  from  i to j with at most \nr edges is by taking a path containing at most r \ue003 1 edges, so that l .r/  \nij D l .r \ue0021/  \nij . \nAnother way is by taking a path of at most r \ue003 1 edges from i to some vertex k and \nthen taking the edge .k;j/ , so that l .r/  \nij D l .r \ue0021/  \nik  C w.k;j/ . Therefore, to examine \npaths from i to j consisting of at most r edges, try all possible predecessors k of j , \ngiving  the  recursive  de\u00fbnition  \nl .r/  \nij D min n \nl .r \ue0021/  \nij ; min \u02da \nl .r \ue0021/  \nik  C w kj  W 1 \u0dc4 k \u0dc4 n \ue009 o \nD min \u02da l .r \ue0021/  \nik  C w kj  W 1 \u0dc4 k \u0dc4 n \ue009 : (23.3)  \nThe last equality follows from the observation that  w jj  D 0 for all j . \nWhat  are  the  actual  shortest-path  weights  \u0131.i;j/? If the  graph  contains  no  \nnegative-weight  cycles,  then  whenever  \u0131.i;j/<  1, there is a shortest path from \nvertex i to vertex j that is simple. (A path p from i to j that is not simple contains \na cycle.  Since  each  cycle9s  weight  is nonnegative,  removing  all cycles from the \npath leaves a simple path with weight no greater th an p9s weight.)  Because  any  \nsimple path contains at most n \ue003 1 edges, a path from vertex i to vertex j with \nmore than n \ue003 1 edges cannot have lower weight than a shortest path  from i to j . \nThe  actual  shortest-path  weights  are  therefore  given  by  650 Chapter 23 All-Pairs Shortest Paths \n\u0131.i;j/  D l .n\ue0021/  \nij D l .n/  \nij D l .nC1/  \nij D \ue001 \ue001 \ue001  : (23.4)  \nComputing  the  shortest-path  weights  bottom  up  \nTaking as input the matrix W D .w  ij /, let9s  see  how  to compute  a series  of matrices  \nL .0/  ;L  .1/  ;:::;L  .n\ue0021/  , where L .r/  D \u00e3 \nl .r/  \nij \u00e4 \nfor r D 0;1;:::;n  \ue003 1. The initial \nmatrix is L .0/  given  by  equation  (23.2).  The  \u00fbnal  matrix  L .n\ue0021/  contains the actual \nshortest-path  weights.  \nThe heart of the algorithm is the procedure E XTEND-SHORTEST-PATHS , which \nimplements  equation  (23.3)  for  all  i and j . The four inputs are the matrix L .r \ue0021/  \ncomputed  so far;  the  edge-weight  matrix  W ; the output matrix L .r/  , which will \nhold the computed result and whose elements are all  initialized to 1  before  in-  \nvoking the procedure; and the number n of vertices. The superscripts r and r \ue003 1 \nhelp to make the correspondence of the pseudocode w ith equation  (23.3)  plain,  but  \nthey play no actual role in the pseudocode. The pro cedure extends the shortest \npaths computed so far by one more edge, producing t he matrix L .r/  of shortest-  \npath weights from the matrix L .r \ue0021/  computed so far. Its running time is \u201a.n  3 / \ndue to the three nested for  loops. \nEXTEND-SHORTEST-PATHS .L  .r \ue0021/  ;W;L  .r/  ;n/  \n1 / / Assume that the elements of L .r/  are initialized to 1. \n2 for  i D 1 to n \n3 for  j D 1 to n \n4 for  k D 1 to n \n5 l .r/  \nij D min \u02da \nl .r/  \nij ;l .r \ue0021/  \nik  C w kj  \ue009 \nLet9s  now  understand  the  relation  of this  computation  to matrix multiplication. \nConsider how to compute the matrix product C D A \ue001 B of two n \ue005 n matrices \nA and B . The straightforward method used by M ATRIX-MULTIPLY on  page  81  \nuses  a triply  nested  loop  to implement  equation  (4.1),  which  we repeat here for \nconvenience: \nc ij D n X  \nkD1 a ik  \ue001 b kj  ; (23.5)  \nfor i;j  D 1;2;:::;n . Now make the substitutions 23.1  Shortest  paths  and  matrix  multiplication  651 \nl .r \ue0021/  !  a;  \nw !  b;  \nl .r/  !  c;  \nmin ! C  ; \nC ! \ue001  \nin equation  (23.3).  You  get  equation  (23.5)!  Making  these  changes to E XTEND- \nSHORTEST-PATHS , and also replacing 1  (the identity for min) by 0 (the identity \nfor C), yields the procedure M ATRIX-MULTIPLY. We  can  see  that  the  proce-  \ndure E XTEND-SHORTEST-PATHS .L  .r \ue0021/  ;W;L  .r/  ;n/  computes  the  matrix  <prod-  \nuct= L .r/  D L .r \ue0021/  \ue001 W using  this  unusual  de\u00fbnition  of matrix  multiplication.  2 \nThus,  we  can  solve  the  all-pairs  shortest-paths  problem  by  repeatedly  multi-  \nplying  matrices.  Each  step  extends  the  shortest-path  weigh ts computed so far by \none more edge using E XTEND-SHORTEST-PATHS .L  .r \ue0021/  ;W;L  .r/  ;n/  to perform \nthe matrix multiplication. Starting with the matrix  L .0/  , we produce the following \nsequence of n \ue003 1 matrices corresponding to powers of W : \nL .1/  D L .0/  \ue001 W D W 1 ; \nL .2/  D L .1/  \ue001 W D W 2 ; \nL .3/  D L .2/  \ue001 W D W 3 ; : : : \nL .n\ue0021/  D L .n\ue0022/  \ue001 W D W n\ue0021 : \nAt the end, the matrix L .n\ue0021/  D W n\ue0021 contains  the  shortest-path  weights.  \nThe procedure S LOW-APSP  on  the  next  page  computes  this  sequence  in \u201a.n  4 / \ntime. The procedure takes the n \ue005 n matrices W and L .0/  as inputs, along with n. \nFigure  23.1  illustrates  its  operation.  The  pseudocode  uses  two n \ue005 n matrices L \nand M  to store powers of W , computing M  D L \ue001 W on each iteration. Line 2 \ninitializes L D L .0/  . For each iteration r , line  4 initializes  M  D 1 , where 1  \nin this context is a matrix of scalar 1  values. The r th iteration starts with the \ninvariant L D L .r \ue0021/  D W r \ue0021 . Line  6 computes  M  D L \ue001 W D L .r \ue0021/  \ue001 W D \nW r \ue0021 \ue001 W D W r D L .r/  so that the invariant can be restored for the next iteration \nby  line  7, which  sets  L D M  . At the end, the matrix L D L .n\ue0021/  D W n\ue0021 of \nshortest-path  weights  is returned.  The  assignments  to n \ue005 n matrices  in lines  2, 4, \nand  7 implicitly  run  doubly  nested  loops  that  take  \u201a.n  2 / time for each assignment. \n2 An algebraic semiring  contains operations \u02da, which is commutative with identity I \u02da , and \u02dd, with \nidentity I \u02dd , where \u02dd distributes over \u02da on both the left and right, and where I \u02da \u02ddx D x \u02ddI \u02da D I \u02da \nfor all x. Standard matrix multiplication, as in M ATRIX-MULTIPLY , uses the semiring with C for \u02da, \n\ue001 for \u02dd, 0 for I \u02da , and 1 for I \u02dd . The procedure E XTEND-SHORTEST-PATHS uses another semiring, \nknown as the tropical  semiring , with min for \u02da, C for \u02dd, 1  for I \u02da , and 0 for I \u02dd . 652 Chapter 23 All-Pairs Shortest Paths \n2 \n1 3 \n5 4 3 4 \n8 2 \n6 7 1 34  35  L .1/  D \ue001 0 3  8 1 \ue0034 \n1  0 1  1 7 \n1  4 0 1 1  \n2 1 \ue0035 0  1  \n1 1 1  6 0 \u02d8 \nL .2/  D \ue001 0 3 8 2  \ue0034 \n3 0 \ue0034 1  7 \n1  4 0 5 11  \n2 \ue0031 \ue0035 0  \ue0032 \n8 1  1 6  0 \u02d8 \nL .3/  D \ue001 0 3 \ue0033 2  \ue0034 \n3 0 \ue0034 1  \ue0031 \n7 4 0 5 11  \n2 \ue0031 \ue0035 0  \ue0032 \n8 5 1 6  0 \u02d8 \nL .4/  D \ue001 0 1 \ue0033 2  \ue0034 \n3 0 \ue0034 1  \ue0031 \n7 4 0 5  3 \n2 \ue0031 \ue0035 0  \ue0032 \n8 5 1 6  0 \u02d8 \nFigure  23.1  A directed graph and the sequence of matrices L .r/  computed by S LOW-APSP.  You  \nmight want to verify that L .5/  , de\u00fbned  as L .4/  \ue001 W , equals L .4/  , and thus L .r/  D L .4/  for all r \ue004 4. \nThe n \ue003 1 invocations of E XTEND-SHORTEST-PATHS , each of which takes \u201a.n  3 / \ntime, dominate the computation, yielding a total ru nning time of \u201a.n  4 /. \nSLOW-APSP.W;L  .0/  ;n/  \n1 let L D .l ij / and M  D .m  ij / be new n \ue005 n matrices \n2 L D L .0/  \n3 for  r D 1 to n \ue003 1 \n4 M  D 1  / / initialize M  \n5 / / Compute the matrix <product= M  D L \ue001 W . \n6 EXTEND-SHORTEST-PATHS .L;W;M;n/  \n7 L D M  \n8 return  L \nImproving  the  running  time  \nBear in mind that the goal is not to compute all the L .r/  matrices:  only  the  ma-  \ntrix L .n\ue0021/  matters.  Recall  that  in the  absence  of negative-weight  cycles,  equa-  \ntion  (23.4)  implies  L .r/  D L .n\ue0021/  for all integers r \ue004 n \ue003 1. Just  as tradi-  \ntional matrix multiplication is associative, so is matrix multiplication  de\u00fbned  by  \nthe E XTEND-SHORTEST-PATHS procedure  (see  Exercise  23.1-4).  In fact,  we  can  \ncompute L .n\ue0021/  with only dlg.n \ue003 1/e matrix products by using the technique of \nrepeated  squaring : 23.1  Shortest  paths  and  matrix  multiplication  653 \nL .1/  D W ;  \nL .2/  D W 2 D W \ue001 W ;  \nL .4/  D W 4 D W 2 \ue001 W 2 \nL .8/  D W 8 D W 4 \ue001 W 4 ; : : : \nL .2  dlg.n\ue0031/e / D W 2 dlg.n\ue0031/e D W 2 dlg.n\ue0031/e\ue0031 \ue001 W 2 dlg.n\ue0031/e\ue0031 : \nSince 2 dlg.n\ue0021/e \ue004 n \ue003 1, the  \u00fbnal  product  is L .2  dlg.n\ue0031/e / D L .n\ue0021/  . \nThe procedure F ASTER-APSP  implements  this  idea.  It takes  just  the  n \ue005 n \nmatrix W and the size n as inputs. Each iteration of the while  loop  of lines  438  \nstarts with the invariant L D W r , which it squares using E XTEND-SHORTEST- \nPATHS to obtain the matrix M  D L 2 D .W  r / 2 D W 2r  . At the end of each \niteration, the value of r doubles, and L for the next iteration becomes M  , restoring \nthe invariant. Upon exiting the loop when r \ue004 n \ue003 1, the procedure returns L D \nW r D L .r/  D L .n\ue0021/  by  equation  (23.4).  As  in SLOW-APSP,  the  assignments  to \nn \ue005 n matrices  in lines  2, 5, and  8 implicitly  run  doubly  nested  loops, taking \u201a.n  2 / \ntime for each assignment. \nFASTER-APSP  .W;n/  \n1 let L and M  be new n \ue005 n matrices \n2 L D W \n3 r D 1 \n4 while  r<n  \ue003 1 \n5 M  D 1  / / initialize M  \n6 EXTEND-SHORTEST-PATHS .L;L;M;n/  / / compute M  D L 2 \n7 r D 2r \n8 L D M  / / ready for the next iteration \n9 return  L \nBecause each of the dlg.n \ue003 1/e matrix products takes \u201a.n  3 / time, F ASTER- \nAPSP runs in \u201a.n  3 lg n/ time. The code is tight, containing no elaborate da ta \nstructures, and the constant hidden in the \u201a-notation  is therefore  small.  \nExercises  \n23.1-1  \nRun SLOW-APSP  on  the  weighted,  directed  graph  of Figure  23.2,  showin g the \nmatrices that result for each iteration of the loop . Then do the same for F ASTER- \nAPSP. 654 Chapter 23 All-Pairs Shortest Paths \n1 2 \n3 5 31  2 1 2 \n4 5 34  38  10  7 3 \n6 \nFigure  23.2  A weighted,  directed  graph  for  use  in Exercises  23.1-1,  23.2-1,  and  23.3-1.  \n23.1-2  \nWhy is it convenient for both S LOW-APSP  and  FASTER-APSP  that  w ii D 0 for \ni D 1;2;:::;n? \n23.1-3  \nWhat does the matrix \nL .0/  D \u00e2 \n0 1  1  \ue001 \ue001 \ue001  1  \n1  0 1  \ue001 \ue001 \ue001  1  \n1 1  0 \ue001 \ue001 \ue001  1  \n: : : : : : : : : : : : : : : \n1  1  1  \ue001 \ue001 \ue001  0 \u00e3 \nused  in the  shortest-paths  algorithms  correspond  to in regular  matrix  multiplica-  \ntion?  \n23.1-4  \nShow  that  matrix  multiplication  de\u00fbned  by  EXTEND-SHORTEST-PATHS is asso-  \nciative. \n23.1-5  \nShow  how  to express  the  single-source  shortest-paths  problem  as a product  of ma-  \ntrices and a vector. Describe how evaluating this p roduct corresponds  to a Bellman-  \nFord-like  algorithm  (see  Section  22.1).  \n23.1-6  \nArgue  that  we  don9t  need  the  matrix  M  in SLOW-APSP  because  by  substituting  L \nfor M  and leaving out the initialization of M  , the code still works correctly. ( Hint: \nRelate  line  5 of EXTEND-SHORTEST-PATHS to R ELAX on  page  610.)  Do  we  need  \nthe matrix M  in F ASTER-APSP?  23.2  The  Floyd-Warshall  algorithm  655 \n23.1-7  \nSuppose that you also want to compute the vertices on shortest paths  in the  algo-  \nrithms of this section. Show how to compute the pre decessor matrix \u2026 from the \ncompleted matrix L of shortest-path  weights  in O.n  3 / time. \n23.1-8  \nYou can also compute the vertices on shortest paths  along with computing the \nshortest-path  weights.  De\u00fbne  \ufffd .r/  \nij as the predecessor of vertex j on  any  minimum-  \nweight path from vertex i to vertex j that contains at most r edges. Modify the \nEXTEND-SHORTEST-PATHS and SLOW-APSP  procedures  to compute  the  matri-  \nces \u2026 .1/  ;\u2026  .2/  ;:::;\u2026  .n\ue0021/  as they compute the matrices L .1/  ;L  .2/  ;:::;L  .n\ue0021/  . \n23.1-9  \nModify F ASTER-APSP  so that  it can  determine  whether  the  graph  contains  a \nnegative-weight  cycle.  \n23.1-10  \nGive  an ef\u00fbcient  algorithm  to \u00fbnd  the  length  (number  of edges)  of a minimum-  \nlength  negative-weight  cycle  in a graph.  \n23.2  The  Floyd-Warshall  algorithm  \nHaving  already  seen  one  dynamic-programming  solution  to the  all-pairs  shortest-  \npaths  problem,  in this  section  we9ll  see  another:  the  Floyd-Warshall  algorithm , \nwhich runs in \u201a.V  3 / time.  As  before,  negative-weight  edges  may  be present,  but  \nnot  negative-weight  cycles.  As  in Section  23.1,  we  develop  the  algorithm  by  fol-  \nlowing  the  dynamic-programming  process.  After  studying  the resulting algorithm, \nwe  present  a similar  method  for  \u00fbnding  the  transitive  closur e of a directed graph. \nThe  structure  of a shortest  path  \nIn the  Floyd-Warshall  algorithm,  we  characterize  the  struc ture of a shortest path \ndifferently  from  how  we  characterized  it in Section  23.1.  The  Floyd-Warshall  algo-  \nrithm considers the intermediate vertices of a shor test path, where an intermediate  \nvertex of a simple path p D hv 1 ;v  2 ;:::;v  l i is any vertex of p other than v 1 or v l , \nthat is, any vertex in the set fv 2 ;v  3 ;:::;v  l \ue0021 g. \nThe  Floyd-Warshall  algorithm  relies  on  the  following  obser vation. Numbering \nthe vertices of G by V D f1;2;:::;n g, take a subset f1;2;:::;k g of vertices for \nsome 1 \u0dc4 k \u0dc4 n. For any pair of vertices i;j  2 V , consider all paths from i \nto j whose intermediate vertices are all drawn from f1;2;:::;k g, and let p be a 656 Chapter 23 All-Pairs Shortest Paths \ni k \nj p 1 p 2 \np: all intermediate vertices in f1;2;:::;k g p 2 : all intermediate vertices in f1;2;:::;k  \ue003 1g p 1 : all intermediate vertices in f1;2;:::;k  \ue003 1g \nFigure  23.3  Optimal  substructure  used  by  the  Floyd-Warshall  algorithm . Path p is a shortest path \nfrom vertex i to vertex j , and k is the  highest-numbered  intermediate  vertex  of p. Path p 1 , the \nportion of path p from vertex i to vertex k, has all intermediate vertices in the set f1;2;:::;k  \ue003 1g. \nThe same holds for path p 2 from vertex k to vertex j . \nminimum-weight  path  from  among  them.  (Path  p is simple.)  The  Floyd-Warshall  \nalgorithm exploits a relationship between path p and shortest paths from i to j with \nall intermediate vertices in the set f1;2;:::;k  \ue003 1g. The details of the relationship \ndepend on whether k is an intermediate vertex of path p or not. \n\ue001 If k is not an intermediate vertex of path p, then all intermediate vertices of \npath p belong to the set f1;2;:::;k  \ue003 1g. Thus a shortest path from vertex i \nto vertex j with all intermediate vertices in the set f1;2;:::;k  \ue003 1g is also a \nshortest path from i to j with all intermediate vertices in the set f1;2;:::;k g. \n\ue001 If k is an intermediate vertex of path p, then decompose p into i p 1 \u2740  k p 2 \u2740  j , \nas Figure  23.3  illustrates.  By  Lemma  22.1,  p 1 is a shortest path from i to k \nwith all intermediate vertices in the set f1;2;:::;k g. In fact, we can make \na slightly stronger statement. Because vertex k is not an intermediate vertex \nof path p 1 , all intermediate vertices of p 1 belong to the set f1;2;:::;k  \ue003 1g. \nTherefore p 1 is a shortest path from i to k with all intermediate vertices in the \nset f1;2;:::;k  \ue003 1g. Likewise, p 2 is a shortest path from vertex k to vertex j \nwith all intermediate vertices in the set f1;2;:::;k  \ue003 1g. \nA recursive  solution  to the  all-pairs  shortest-paths  problem  \nThe above observations suggest a recursive formulat ion of shortest-path  estimates  \nthat  differs  from  the  one  in Section  23.1.  Let  d .k/  \nij be the weight of a shortest \npath from vertex i to vertex j for which all intermediate vertices belong to the s et \nf1;2;:::;k g. When k D 0, a path from vertex i to vertex j with no intermediate \nvertex numbered higher than 0 has no intermediate vertices at all. Such a path \nhas at most one edge, and hence d .0/  \nij D w ij . Following the above discussion, \nde\u00fbne  d .k/  \nij recursively by 23.2  The  Floyd-Warshall  algorithm  657 \nd .k/  \nij D ( \nw ij if k D 0;  \nmin \u02da \nd .k\ue0021/  \nij ;d  .k\ue0021/  \nik  C d .k\ue0021/  \nkj  \ue009 \nif k \ue004 1:  (23.6)  \nBecause for any path, all intermediate vertices bel ong to the set f1;2;:::;n g, the \nmatrix D .n/  D \u00e3 d .n/  \nij \u00e4 gives  the  \u00fbnal  answer:  d .n/  \nij D \u0131.i;j/  for all i;j  2 V . \nComputing  the  shortest-path  weights  bottom  up  \nBased  on  recurrence  (23.6),  the  bottom-up  procedure  FLOYD-WARSHALL com-  \nputes the values d .k/  \nij in order of increasing values of k. Its input is an n \ue005 n \nmatrix W de\u00fbned  as in equation  (23.1).  The  procedure  returns  the  matrix D .n/  \nof shortest-path  weights.  Figure  23.4  shows  the  matrices  D .k/  computed by the \nFloyd-Warshall  algorithm  for  the  graph  in Figure  23.1.  \nFLOYD-WARSHALL .W;n/  \n1 D .0/  D W \n2 for  k D 1 to n \n3 let D .k/  D \u00e3 \nd .k/  \nij \u00e4 \nbe a new n \ue005 n matrix \n4 for  i D 1 to n \n5 for  j D 1 to n \n6 d .k/  \nij D min \u02da \nd .k\ue0021/  \nij ;d  .k\ue0021/  \nik  C d .k\ue0021/  \nkj  \ue009 \n7 return  D .n/  \nThe  running  time  of the  Floyd-Warshall  algorithm  is determi ned by the triply \nnested for  loops  of lines  236.  Because  each  execution  of line  6 takes  O.1/  time, \nthe algorithm runs in \u201a.n  3 / time.  As  in the  \u00fbnal  algorithm  in Section  23.1,  the  \ncode is tight, with no elaborate data structures, a nd so the constant hidden in the \n\u201a-notation  is small.  Thus,  the  Floyd-Warshall  algorithm  is quite practical for even \nmoderate-sized  input  graphs.  \nConstructing  a shortest  path  \nThere are a variety of different methods for constr ucting shortest  paths  in the  Floyd-  \nWarshall  algorithm.  One  way  is to compute  the  matrix  D of shortest-path  weights  \nand then construct the predecessor matrix \u2026 from the D matrix.  Exercise  23.1-7  \nasks you to implement this method so that it runs i n O.n  3 / time.  Given  the  pre-  \ndecessor matrix \u2026, the P RINT-ALL-PAIRS-SHORTEST-PATH procedure prints the \nvertices on a given shortest path. \nAlternatively, the predecessor matrix \u2026 can be computed while the algorithm \ncomputes the matrices D .0/  ;D  .1/  ;:::;D  .n/  . Speci\u00fbcally,  compute  a sequence  of 658 Chapter 23 All-Pairs Shortest Paths \nD .0/  D \ue001 0 3  8 1 \ue0034 \n1  0 1  1 7 \n1  4 0 1 1  \n2 1 \ue0035 0  1  \n1 1 1  6 0 \u02d8 \n\u2026 .0/  D \ue001 \nNIL 1 1 NIL 1 \nNIL NIL NIL 2 2 \nNIL 3 NIL NIL NIL \n4 NIL 4 NIL NIL \nNIL NIL NIL 5 NIL \u02d8 \nD .1/  D \ue001 0 3  8 1 \ue0034 \n1  0 1  1 7 \n1  4 0 1 1  \n2 5  \ue0035 0  \ue0032 \n1 1 1  6 0 \u02d8 \n\u2026 .1/  D \ue001 \nNIL 1 1 NIL 1 \nNIL NIL NIL 2 2 \nNIL 3 NIL NIL NIL \n4 1 4 NIL 1 \nNIL NIL NIL 5 NIL \u02d8 \nD .2/  D \ue001 0 3  8 4  \ue0034 \n1  0 1  1 7 \n1  4 0 5 11  \n2 5  \ue0035 0  \ue0032 \n1 1 1  6 0 \u02d8 \n\u2026 .2/  D \ue001 \nNIL 1 1 2 1 \nNIL NIL NIL 2 2 \nNIL 3 NIL 2 2 \n4 1 4 NIL 1 \nNIL NIL NIL 5 NIL \u02d8 \nD .3/  D \ue001 0 3 8 4  \ue0034 \n1  0 1  1 7 \n1  4 0 5 11  \n2 \ue0031 \ue0035 0  \ue0032 \n1 1 1  6 0 \u02d8 \n\u2026 .3/  D \ue001 \nNIL 1 1 2 1 \nNIL NIL NIL 2 2 \nNIL 3 NIL 2 2 \n4 3 4 NIL 1 \nNIL NIL NIL 5 NIL \u02d8 \nD .4/  D \ue001 0 3 \ue0031 4  \ue0034 \n3 0 \ue0034 1  \ue0031 \n7 4 0 5  3 \n2 \ue0031 \ue0035 0  \ue0032 \n8 5 1 6  0 \u02d8 \n\u2026 .4/  D \ue001 \nNIL 1 4 2 1 \n4 NIL 4 2 1 \n4 3 NIL 2 1 \n4 3 4 NIL 1 \n4 3 4 5 NIL \u02d8 \nD .5/  D \ue001 0 1 \ue0033 2  \ue0034 \n3 0 \ue0034 1  \ue0031 \n7 4 0 5  3 \n2 \ue0031 \ue0035 0  \ue0032 \n8 5 1 6  0 \u02d8 \n\u2026 .5/  D \ue001 \nNIL 3 4 5 1 \n4 NIL 4 2 1 \n4 3 NIL 2 1 \n4 3 4 NIL 1 \n4 3 4 5 NIL \u02d8 \nFigure  23.4  The sequence of matrices D .k/  and \u2026 .k/  computed  by  the  Floyd-Warshall  algorithm  \nfor  the  graph  in Figure  23.1.  \nmatrices \u2026 .0/  ;\u2026  .1/  ;:::;\u2026  .n/  , where \u2026 D \u2026 .n/  and \ufffd .k/  \nij is the predecessor of \nvertex j on a shortest path from vertex i with all intermediate vertices in the set \nf1;2;:::;k g. \nHere9s  a recursive  formulation  of \ufffd .k/  \nij . When k D 0, a shortest path from i to j \nhas no intermediate vertices at all, and so 23.2  The  Floyd-Warshall  algorithm  659 \n\ufffd .0/  \nij D ( \nNIL if i D j or w ij D 1  ; \ni if i \u00a4 j and w ij < 1  : (23.7)  \nFor k \ue004 1, if the path has k as an intermediate vertex, so that it is i \u2740  k \u2740  j \nwhere k \u00a4 j , then choose as the predecessor of j on this path the same vertex \nas the predecessor of j chosen on a shortest path from k with all intermediate \nvertices in the set f1;2;:::;k  \ue003 1g. Otherwise,  when  the  path  from  i to j does not \nhave k as an intermediate vertex, choose the same predeces sor of j as on a shortest \npath from i with all intermediate vertices in the set f1;2;:::;k  \ue003 1g. Formally, for \nk \ue004 1, \n\ufffd .k/  \nij D ( \n\ufffd .k\ue0021/  \nkj  if d .k\ue0021/  \nij >d  .k\ue0021/  \nik  C d .k\ue0021/  \nkj  (k is an intermediate vertex) ; \n\ufffd .k\ue0021/  \nij if d .k\ue0021/  \nij \u0dc4 d .k\ue0021/  \nik  C d .k\ue0021/  \nkj  (k is not an intermediate vertex) : \n(23.8)  \nExercise  23.2-3  asks  you  to show  how  to incorporate  the  \u2026 .k/  matrix  compu-  \ntations into the F LOYD-WARSHALL procedure.  Figure  23.4  shows  the  sequence  \nof \u2026 .k/  matrices that the resulting algorithm computes for the graph of Figure  23.1.  \nThe  exercise  also  asks  for  the  more  dif\u00fbcult  task  of proving  that the predecessor \nsubgraph G \ue003;i  is a shortest-paths  tree  with  root  i . Exercise  23.2-7  asks  for  yet  \nanother way to reconstruct shortest paths. \nTransitive  closure  of a directed  graph  \nGiven  a directed  graph  G D .V;E/  with vertex set V D f1;2;:::;n g, you might \nwish to determine simply whether G contains a path from i to j for all vertex \npairs i;j  2 V , without  regard  to edge  weights.  We  de\u00fbne  the  transitive  closure  \nof G as the graph G \ue003 D .V;E  \ue003 /, where \nE \ue003 D f.i;j/  W there is a path from vertex i to vertex j in Gg : \nOne  way  to compute  the  transitive  closure  of a graph  in \u201a.n  3 / time is to assign \na weight of 1 to each edge of E and  run  the  Floyd-Warshall  algorithm.  If there  is a \npath from vertex i to vertex j , you get d ij <n. Otherwise,  you  get  d ij D 1 . \nThere is another, similar way to compute the transi tive closure of G in \u201a.n  3 / \ntime, which can save time and space in practice. Th is method substitutes  the  log-  \nical operations _ (logical  OR)  and  ^ (logical AND) for the arithmetic operations \nmin and C in the  Floyd-Warshall  algorithm.  For  i;j;k  D 1;2;:::;n, de\u00fbne  t .k/  \nij \nto be 1 if there exists a path in graph G from vertex i to vertex j with  all  interme-  \ndiate vertices in the set f1;2;:::;k g, and 0 otherwise. To construct the transitive \nclosure G \ue003 D .V;E  \ue003 /, put edge .i;j/  into E \ue003 if and only if t .n/  \nij D 1. A recursive \nde\u00fbnition  of t .k/  \nij , analogous  to recurrence  (23.6),  is 660 Chapter 23 All-Pairs Shortest Paths \n1 2 \n4 3 T .0/  D \u00e3 1 0 0 0  \n0 1 1 1  \n0 1 1 0  \n1 0 1 1  \u00e4 \nT .1/  D \u00e3 1 0 0 0  \n0 1 1 1  \n0 1 1 0  \n1 0 1 1  \u00e4 \nT .2/  D \u00e3 1 0 0 0  \n0 1 1 1  \n0 1 1 1  \n1 0 1 1  \u00e4 \nT .3/  D \u00e3 1 0 0 0  \n0 1 1 1  \n0 1 1 1  \n1 1 1 1  \u00e4 \nT .4/  D \u00e3 1 0 0 0  \n1 1 1 1  \n1 1 1 1  \n1 1 1 1  \u00e4 \nFigure  23.5  A directed graph and the matrices T .k/  computed  by  the  transitive-closure  algorithm.  \nt .0/  \nij D ( \n0 if i \u00a4 j and .i;j/  \u2026 E;  \n1 if i D j or .i;j/  2 E;  \nand for k \ue004 1, \nt .k/  \nij D t .k\ue0021/  \nij _ \u00e3 t .k\ue0021/  \nik  ^ t .k\ue0021/  \nkj  \u00e4 : (23.9)  \nAs  in the  Floyd-Warshall  algorithm,  the  TRANSITIVE-CLOSURE  procedure  com-  \nputes the matrices T .k/  D \u00e3 \nt .k/  \nij \u00e4 \nin order of increasing k. \nTRANSITIVE-CLOSURE  .G;n/  \n1 let T .0/  D \u00e3 \nt .0/  \nij \u00e4 \nbe a new n \ue005 n matrix \n2 for  i D 1 to n \n3 for  j D 1 to n \n4 if i == j or .i;j/  2 G:  E \n5 t .0/  \nij D 1 \n6 else  t .0/  \nij D 0 \n7 for  k D 1 to n \n8 let T .k/  D \u00e3 \nt .k/  \nij \u00e4 \nbe a new n \ue005 n matrix \n9 for  i D 1 to n \n10  for  j D 1 to n \n11  t .k/  \nij D t .k\ue0021/  \nij _ \u00e3 \nt .k\ue0021/  \nik  ^ t .k\ue0021/  \nkj  \u00e4 \n12  return  T .n/  \nFigure  23.5  shows  the  matrices  T .k/  computed by the T RANSITIVE-CLOSURE  \nprocedure on a sample graph. The T RANSITIVE-CLOSURE  procedure, like the \nFloyd-Warshall  algorithm,  runs  in \u201a.n  3 / time.  On  some  computers,  though,  log-  \nical  operations  on  single-bit  values  execute  faster  than  arithmetic operations on \ninteger words of data. Moreover, because the direct  transitive-closure  algorithm  23.2  The  Floyd-Warshall  algorithm  661 \nuses only boolean values rather than integer values , its space requirement is less \nthan  the  Floyd-Warshall  algorithm9s  by  a factor  correspond ing to the size of a word \nof computer storage. \nExercises  \n23.2-1  \nRun  the  Floyd-Warshall  algorithm  on  the  weighted,  directed  graph  of Figure  23.2.  \nShow the matrix D .k/  that results for each iteration of the outer loop. \n23.2-2  \nShow how to compute the transitive closure using th e technique of Section  23.1.  \n23.2-3  \nModify the F LOYD-WARSHALL procedure to compute the \u2026 .k/  matrices according \nto equations  (23.7)  and  (23.8).  Prove  rigorously  that  for  all i 2 V , the predecessor \nsubgraph G \ue003;i  is a shortest-paths  tree  with  root  i . (Hint: To show that G \ue003;i  is \nacyclic,  \u00fbrst  show  that  \ufffd .k/  \nij D l implies d .k/  \nij \ue004 d .k/  \nil C w lj , according to the \nde\u00fbnition  of \ufffd .k/  \nij . Then  adapt  the  proof  of Lemma  22.16.)  \n23.2-4  \nAs  it appears  on  page  657,  the  Floyd-Warshall  algorithm  requires \u201a.n  3 / space, \nsince it creates d .k/  \nij for i;j;k  D 1;2;:::;n . Show that the procedure F LOYD- \nWARSHALL 0 , which simply drops all the superscripts, is corre ct, and thus only \n\u201a.n  2 / space is required. \nFLOYD-WARSHALL 0 .W;n/  \n1 D D W \n2 for  k D 1 to n \n3 for  i D 1 to n \n4 for  j D 1 to n \n5 d ij D min fd ij ;d  ik  C d kj  g \n6 return  D \n23.2-5  \nConsider  the  following  change  to how  equation  (23.8)  handle s equality: \n\ufffd .k/  \nij D ( \n\ufffd .k\ue0021/  \nkj  if d .k\ue0021/  \nij \ue004 d .k\ue0021/  \nik  C d .k\ue0021/  \nkj  (k is an intermediate vertex) ; \n\ufffd .k\ue0021/  \nij if d .k\ue0021/  \nij <d  .k\ue0021/  \nik  C d .k\ue0021/  \nkj  (k is not an intermediate vertex) : \nIs this  alternative  de\u00fbnition  of the  predecessor  matrix  \u2026 correct?  662 Chapter 23 All-Pairs Shortest Paths \n23.2-6  \nShow  how  to use  the  output  of the  Floyd-Warshall  algorithm  to detect the presence \nof a negative-weight  cycle.  \n23.2-7  \nAnother  way  to reconstruct  shortest  paths  in the  Floyd-Wars hall algorithm uses \nvalues \ufffd .k/  \nij for i;j;k  D 1;2;:::;n , where \ufffd .k/  \nij is the  highest-numbered  interme-  \ndiate vertex of a shortest path from i to j in which all intermediate vertices lie in \nthe set f1;2;:::;k g. Give  a recursive  formulation  for  \ufffd .k/  \nij , modify the F LOYD- \nWARSHALL procedure to compute the \ufffd .k/  \nij values, and rewrite the P RINT-ALL- \nPAIRS-SHORTEST-PATH procedure to take the matrix \u02c6 D \u00e3 \n\ufffd .n/  \nij \u00e4 \nas an input. \nHow is the matrix \u02c6 like the s table  in the  matrix-chain  multiplication  problem  of \nSection  14.2?  \n23.2-8  \nGive  an O.VE/-time  algorithm  for  computing  the  transitive  closure  of a directed \ngraph G D .V;E/ . Assume that jV j D  O.E/  and that the graph is represented \nwith adjacency lists. \n23.2-9  \nSuppose that it takes f.jV j ; jEj/ time  to compute  the  transitive  closure  of a di-  \nrected acyclic graph, where f is a monotonically increasing function of both jV j \nand jEj. Show that the time to compute the transitive clos ure G \ue003 D .V;E  \ue003 / of a \ngeneral directed graph G D .V;E/  is then f.jV j ; jEj/ C O.V  C E \ue003 /. \n23.3  Johnson\u2019s  algorithm  for  sparse  graphs  \nJohnson9s  algorithm  \u00fbnds  shortest  paths  between  all  pairs  in O.V  2 lg V C VE/  \ntime. For sparse graphs, it is asymptotically faste r than either repeated squaring of \nmatrices  or the  Floyd-Warshall  algorithm.  The  algorithm  either returns a matrix of \nshortest-path  weights  for  all  pairs  of vertices  or reports  that the input graph contains \na negative-weight  cycle.  Johnson9s  algorithm  uses  as subroutines  both  Dijkstra9s  \nalgorithm  and  the  Bellman-Ford  algorithm,  which  Chapter  22  describes. \nJohnson9s  algorithm  uses  the  technique  of reweighting , which works as follows. \nIf all edge weights w in a graph G D .V;E/  are  nonnegative,  Dijkstra9s  algo-  \nrithm  can  \u00fbnd  shortest  paths  between  all  pairs  of vertices  by  running it once from \neach  vertex.  With  the  Fibonacci-heap  min-priority  queue,  the running time of this \nall-pairs  algorithm  is O.V  2 lg V C VE/. If G has  negative-weight  edges  but  no  \nnegative-weight  cycles,  \u00fbrst  compute  a new  set  of nonnegati ve edge weights so 23.3 Johnson\u2019s algorithm for sparse graphs 663 \nthat  Dijkstra9s  algorithm  applies.  The  new  set  of edge  weigh ts y w must satisfy two \nimportant properties: \n1. For  all  pairs  of vertices  u;v  2 V , a path p is a shortest path from u to v using \nweight function w if and only if p is also a shortest path from u to v using \nweight function y w. \n2. For all edges .u;v/ , the new weight y w.u;v/  is nonnegative. \nAs  we9ll  see  in a moment,  preprocessing  G to determine the new weight function y w \ntakes O.VE/  time. \nPreserving  shortest  paths  by  reweighting  \nThe following lemma shows how to reweight the edges  to satisfy the  \u00fbrst  property  \nabove. We use \u0131 to denote  shortest-path  weights  derived  from  weight  functi on w \nand y \u0131 to denote  shortest-path  weights  derived  from  weight  functi on y w. \nLemma  23.1  (Reweighting  does  not  change  shortest  paths)  \nGiven  a weighted,  directed  graph  G D .V;E/  with weight function w W E !  R, \nlet h W V !  R be any function mapping vertices to real numbers. F or each \nedge .u;v/  2 E, de\u00fbne  \ny w.u;v/  D w.u;v/  C h.u/  \ue003 h.v/:  (23.10)  \nLet p D hv 0 ;v  1 ;:::;v  k i be any path from vertex v 0 to vertex v k . Then p is a \nshortest path from v 0 to v k with weight function w if and only if it is a shortest path \nwith weight function y w. That is, w.p/  D \u0131.v  0 ;v  k / if and only if y w.p/  D y \u0131.v  0 ;v  k /. \nFurthermore, G has  a negative-weight  cycle  using  weight  function  w if and only \nif G has  a negative-weight  cycle  using  weight  function  y w. \nProof  We start by showing that \ny w.p/  D w.p/  C h.v  0 / \ue003 h.v  k /: (23.11)  \nWe have \ny w.p/  D k X  \ni D1 y w.v  i \ue0021 ;v  i / \nD k X  \ni D1 .w.v  i \ue0021 ;v  i / C h.v  i \ue0021 / \ue003 h.v  i // \nD k X  \ni D1 w.v  i \ue0021 ;v  i / C h.v  0 / \ue003 h.v  k / (because the sum telescopes) \nD w.p/  C h.v  0 / \ue003 h.v  k /: 664 Chapter 23 All-Pairs Shortest Paths \nTherefore, any path p from v 0 to v k has y w.p/  D w.p/  C h.v  0 / \ue003 h.v  k /. Be-  \ncause h.v  0 / and h.v  k / do not depend on the path, if one path from v 0 to v k is \nshorter than another using weight function w, then it is also shorter using y w. Thus, \nw.p/  D \u0131.v  0 ;v  k / if and only if y w.p/  D y \u0131.v  0 ;v  k /. \nFinally, we show that G has  a negative-weight  cycle  using  weight  function  w if \nand only if G has  a negative-weight  cycle  using  weight  function  y w. Consider any \ncycle c D hv 0 ;v  1 ;:::;v  k i, where v 0 D v k . By  equation  (23.11),  \ny w.c/  D w.c/  C h.v  0 / \ue003 h.v  k / \nD w.c/;  \nand thus c has negative weight using w if and  only  if it has  negative  weight  us-  \ning y w. \nProducing  nonnegative  weights  by  reweighting  \nOur  next  goal  is to ensure  that  the  second  property  holds:  y w.u;v/  must  be nonneg-  \native for all edges .u;v/  2 E. Given  a weighted,  directed  graph  G D .V;E/  with \nweight function w W E !  R, we9ll  see  how  to make  a new  graph  G 0 D .V  0 ;E  0 /, \nwhere V 0 D V [ fs g for some new vertex s \u2026 V and E 0 D E [ f.s;v/  W v 2 V g. \nTo incorporate the new vertex s , extend the weight function w so that w.s;v/  D 0 \nfor all v 2 V . Since no edges enter s , no shortest paths in G 0 , other than those with \nsource s , contain s . Moreover, G 0 has  no  negative-weight  cycles  if and  only  if G \nhas  no  negative-weight  cycles.  Figure  23.6(a)  shows  the  graph G 0 corresponding \nto the graph G of Figure  23.1.  \nNow suppose that G and G 0 have  no  negative-weight  cycles.  De\u00fbne  the  func-  \ntion h.v/  D \u0131.s;v/  for all v 2 V 0 . By  the  triangle  inequality  (Lemma  22.10  on  \npage  633),  we  have  h.v/  \u0dc4 h.u/  C w.u;v/  for all edges .u;v/  2 E 0 . Thus, \nby  de\u00fbning  reweighted  edge  weights  y w according  to equation  (23.10),  we  have  \ny w.u;v/  D w.u;v/  C h.u/  \ue003 h.v/  \ue004 0, thereby satisfying the second property. \nFigure  23.6(b)  shows  the  graph  G 0 from  Figure  23.6(a)  with  reweighted  edges.  \nComputing  all-pairs  shortest  paths  \nJohnson9s  algorithm  to compute  all-pairs  shortest  paths  uses  the  Bellman-Ford  al-  \ngorithm  (Section  22.1)  and  Dijkstra9s  algorithm  (Section  22.3)  as subroutines.  The  \npseudocode  appears  in the  procedure  J OHNSON  on  page  666.  It assumes  implic-  \nitly that the edges are stored in adjacency lists. The algorithm returns the usual \njV j \ue005 jV j matrix D D .d ij /, where d ij D \u0131.i;j/ , or it reports that the input \ngraph  contains  a negative-weight  cycle.  As  is typical  for  an all-pairs  shortest-paths  \nalgorithm, it assumes that the vertices are numbere d from 1 to jV j. 23.3 Johnson\u2019s algorithm for sparse graphs 665 \n2 \n1 \n5 4 3 4 \n8 2 \n6 7 1 0 \n0 \n0 \n0 \n0 0 \n0 \n2/1  \n2/33  \n2/2 0/34  2/3  0/34  \n0/1  2/31  2/7  0/4  \n0/5  2/3  \n2/2 0/31  \n0/35  \n2/\u20132 4/8  2/5  \n2/1  \n2/6  (a) \n(c) (b) 34  \n34  31  \n35  \n35  3 2 \n1 \n5 4 4 0 \n13  2 \n2 10  0 5 \n1 \n0 \n4 \n0 0 \n0 0 \n34  31  \n35  \n0 3 \n2 \n1 \n5 4 4 0 \n13  2 \n2 10  0 0 0 3 \n(d) 2 \n1 \n5 4 4 0 \n13  2 \n2 10  0 0 0 3 \n(e) 2 \n1 \n5 4 4 0 \n13  2 \n2 10  0 0 0 3 \n(f) 2 \n1 \n5 4 4 0 \n13  2 \n2 10  0 0 0 3 \n(g) 2 \n1 \n5 4 4 0 \n13  2 \n2 10  0 0 0 3 \n0/0 0/0 0/0 0/0 \n0/0 0 0 \nFigure  23.6  Johnson9s  all-pairs  shortest-paths  algorithm  run  on  the  graph  of Figure  23.1.  Ver-  \ntex numbers appear outside the vertices. (a)  The graph G 0 with the original weight function w. \nThe new vertex s is blue. Within each vertex v is h.v/  D \u0131.s;v/ . (b)  After reweighting each \nedge .u;v/  with weight function y w.u;v/  D w.u;v/  C h.u/  \ue003 h.v/. (c)\u2013(g)  The result of running \nDijkstra9s  algorithm  on  each  vertex  of G using weight function y w. In each part, the source vertex u \nis blue,  and  blue  edges  belong  to the  shortest-paths  tree  computed by the algorithm. Within each \nvertex v are the values y \u0131.u;v/  and \u0131.u;v/ , separated by a slash. The value d uv  D \u0131.u;v/  is equal to \ny \u0131.u;v/  C h.v/  \ue003 h.u/ . 666 Chapter 23 All-Pairs Shortest Paths \nJ OHNSON.G;w/  \n1 compute G 0 , where G 0 : V D G:  V [ fs g, \nG 0 : E D G:  E [ f.s;v/  W v 2 G:  V g, and \nw.s;v/  D 0 for all v 2 G:  V \n2 if BELLMAN-FORD  .G  0 ;w;s/  == FALSE \n3 print  <the  input  graph  contains  a negative-weight  cycle=  \n4 else  for  each vertex v 2 G 0 : V \n5 set h.v/  to the value of \u0131.s;v/  \ncomputed  by  the  Bellman-Ford  algorithm  \n6 for  each edge .u;v/  2 G 0 : E \n7 y w.u;v/  D w.u;v/  C h.u/  \ue003 h.v/  \n8 let D D .d uv  / be a new n \ue005 n matrix \n9 for  each vertex u 2 G:  V \n10  run DIJKSTRA.G;  y w;u/  to compute y \u0131.u;v/  for all v 2 G:  V \n11  for  each vertex v 2 G:  V \n12  d uv  D y \u0131.u;v/  C h.v/  \ue003 h.u/  \n13  return  D \nThe  J OHNSON  procedure  simply  performs  the  actions  speci\u00fbed  earlier.  Line  1 \nproduces G 0 . Line  2 runs  the  Bellman-Ford  algorithm  on  G 0 with  weight  func-  \ntion w and source vertex s . If G 0 , and hence G, contains  a negative-weight  cycle,  \nline  3 reports  the  problem.  Lines  4312  assume  that  G 0 contains  no  negative-weight  \ncycles.  Lines  435  set  h.v/  to the  shortest-path  weight  \u0131.s;v/  computed by the \nBellman-Ford  algorithm  for  all  v 2 V 0 . Lines  637  compute  the  new  weights  y w. For \neach pair of vertices u;v  2 V , the for  loop  of lines  9312  computes  the  shortest-path  \nweight y \u0131.u;v/  by  calling  Dijkstra9s  algorithm  once  from  each  vertex  in V . Line  12  \nstores in matrix entry d uv  the  correct  shortest-path  weight  \u0131.u;v/ , calculated using \nequation  (23.11).  Finally,  line  13  returns  the  completed  D matrix.  Figure  23.6  \ndepicts  the  execution  of Johnson9s  algorithm.  \nIf the  min-priority  queue  in Dijkstra9s  algorithm  is implem ented by a Fibonacci \nheap,  Johnson9s  algorithm  runs  in O.V  2 lg V CVE/  time.  The  simpler  binary  min-  \nheap implementation yields a running time of O.VE  lg V/, which  is still  asymp-  \ntotically  faster  than  the  Floyd-Warshall  algorithm  if the  graph is sparse. \nExercises  \n23.3-1  \nUse  Johnson9s  algorithm  to \u00fbnd  the  shortest  paths  between  all pairs of vertices in \nthe  graph  of Figure  23.2.  Show  the  values  of h and y w computed by the algorithm. Problems for Chapter 23 667 \n23.3-2  \nWhat is the purpose of adding the new vertex s to V , yielding V 0 ? \n23.3-3  \nSuppose that w.u;v/  \ue004 0 for all edges .u;v/  2 E. What is the relationship \nbetween the weight functions w and y w? \n23.3-4  \nProfessor  Greenstreet  claims  that  there  is a simpler  way  to reweight edges than the \nmethod  used  in Johnson9s  algorithm.  Letting  w \ue003 D min fw.u;v/  W .u;v/  2 Eg, \njust  de\u00fbne  y w.u;v/  D w.u;v/  \ue003 w \ue003 for all edges .u;v/  2 E. What is wrong with \nthe  professor9s  method  of reweighting?  \n23.3-5  \nShow that if G contains a 0-weight  cycle  c , then y w.u;v/  D 0 for every edge .u;v/  \nin c . \n23.3-6  \nProfessor Michener claims that there is no need to create a new source vertex in \nline  1 of J OHNSON . He suggests using G 0 D G instead and letting s be any  ver-  \ntex.  Give  an example  of a weighted,  directed  graph  G for which incorporating \nthe  professor9s  idea  into  J OHNSON  causes incorrect answers. Assume that 1 \ue003 1  \nis unde\u00fbned,  and  in particular,  it is not  0. Then show that if G is strongly  con-  \nnected (every vertex is reachable from every other vertex), the results returned by \nJ OHNSON  with  the  professor9s  modi\u00fbcation  are  correct.  \nProblems  \n23-1  Transitive  closure  of a dynamic  graph  \nYou wish to maintain the transitive closure of a di rected graph G D .V;E/  as \nyou insert edges into E. That is, after inserting an edge, you update the transitive \nclosure of the edges inserted so far. Start with G having no edges initially, and \nrepresent the transitive closure by a boolean matri x. \na. Show how to update the transitive closure G \ue003 D .V;E  \ue003 / of a graph G D .V;E/  \nin O.V  2 / time when a new edge is added to G. \nb. Give  an example  of a graph  G and an edge e such that \ufffd.V  2 / time is required to \nupdate the transitive closure after inserting e into G, no matter what algorithm \nis used. 668 Chapter 23 All-Pairs Shortest Paths \nc. Give  an algorithm  for  updating  the  transitive  closure  as edges are inserted into \nthe graph. For any sequence of r insertions, your algorithm should run in time P  r \ni D1 t i D O.V  3 /, where t i is the time to update the transitive closure upon \ninserting the i th edge. Prove that your algorithm attains this tim e bound. \n23-2  Shortest  paths  in \ue002-dense  graphs  \nA graph G D .V;E/  is \ue002-dense  if jEj D  \u201a.V  1C\ue001 / for some constant \ufffd in the \nrange 0<\ufffd  \u0dc4 1. d -ary  min-heaps  (see  Problem  6-2  on  page  179)  provide  a way  \nto match  the  running  times  of Fibonacci-heap-based  shortest-path  algorithms  on  \n\ufffd -dense  graphs  without  using  as complicated  a data  structure . \na. What are the asymptotic running times for the opera tions I NSERT , EXTRACT- \nMIN, and D ECREASE-KEY, as a function of d and the number n of elements \nin a d -ary  min-heap?  What  are  these  running  times  if you  choose  d D \u201a.n  \u02db / \nfor some constant 0<\u02db  \u0dc4 1? Compare  these  running  times  to the  amortized  \ncosts of these operations for a Fibonacci heap. \nb. Show how to compute shortest paths from a single so urce on an \ufffd -dense  directed  \ngraph G D .V;E/  with  no  negative-weight  edges  in O.E/  time. ( Hint: Pick d \nas a function of \ufffd .) \nc. Show  how  to solve  the  all-pairs  shortest-paths  problem  on  an \ufffd -dense  directed  \ngraph G D .V;E/  with  no  negative-weight  edges  in O.VE/  time. \nd. Show  how  to solve  the  all-pairs  shortest-paths  problem  in O.VE/  time on an \n\ufffd -dense  directed  graph  G D .V;E/  that  may  have  negative-weight  edges  but  \nhas  no  negative-weight  cycles.  \nChapter  notes  \nLawler  [276]  has  a good  discussion  of the  all-pairs  shortest-paths  problem.  He  \nattributes  the  matrix-multiplication  algorithm  to the  folklore.  The  Floyd-Warshall  \nalgorithm  is due  to Floyd  [144],  who  based  it on  a theorem  of Warshall  [450]  that  \ndescribes how to compute the transitive closure of boolean matrices.  Johnson9s  \nalgorithm  is taken  from  [238].  \nSeveral researchers have given improved algorithms for computing shortest \npaths  via  matrix  multiplication.  Fredman  [153]  shows  how  to solve  the  all-  \npairs shortest paths problem using O.V  5=2  / comparisons between sums of edge \nweights and obtains an algorithm that runs in O.V  3 .lg lg V=  lg V/  1=3  / time, which \nis slightly  better  than  the  running  time  of the  Floyd-Warsha ll algorithm. This bound Notes for Chapter 23 669 \nhas been improved several times, and the fastest al gorithm is now by Williams \n[457],  with  a running  time  of O.V  3 =2  \ue004.lg 1=2  V /  /. \nAnother line of research demonstrates how to apply algorithms for fast matrix \nmultiplication  (see  the  chapter  notes  for  Chapter  4) to the  all-pairs  shortest  paths  \nproblem. Let O.n  ! / be the running time of the fastest algorithm for mu ltiplying \ntwo n \ue005 n matrices.  Galil  and  Margalit  [170,  171]  and  Seidel  [403]  designed  al-  \ngorithms  that  solve  the  all-pairs  shortest  paths  problem  in undirected, unweighted \ngraphs in .V  ! p.V//  time, where p.n/  denotes  a particular  function  that  is poly-  \nlogarithmically bounded in n. In dense graphs, these algorithms are faster than  \nthe O.VE/  time needed to perform jV j breadth-\u00fbrst  searches.  Several  researchers  \nhave extended these results to give algorithms for solving the all-pairs  shortest  \npaths problem in undirected graphs in which the edg e weights are integers in the \nrange f1;2;:::;W  g. The asymptotically fastest such algorithm, by Sho shan and \nZwick  [410],  runs  in O.WV  ! p.VW//  time. In directed graphs, the best algorithm \nto date  is due  to Zwick  [467]  and  runs  in e O.W  1=.4\ue002!/  V 2C1=.4\ue002!/  / time. \nKarger,  Koller,  and  Phillips  [244]  and  independently  McGeoch  [320]  have  given  \na time bound that depends on E \ue003 , the set of edges in E that participate in some \nshortest  path.  Given  a graph  with  nonnegative  edge  weights,  their algorithms run in \nO.VE  \ue003 C V 2 lg V/  time  and  improve  upon  running  Dijkstra9s  algorithm  jV j times \nwhen jE \ue003 j D  o.E/. Pettie  [355]  uses  an approach  based  on  component  hierarchi es \nto achieve a running time of O.VE  C V 2 lg lg V/, and the same running time is \nalso  achieved  by  Hagerup  [205].  \nBaswana,  Hariharan,  and  Sen  [37]  examined  decremental  algorithms,  which  al-  \nlow a sequence of intermixed edge deletions and que ries, for maintaining  all-pairs  \nshortest  paths  and  transitive-closure  information.  When  a path  exists,  their  ran-  \ndomized  transitive-closure  algorithm  can  fail  to report  it with probability 1=n  c \nfor an arbitrary c > 0 . The query times are O.1/  with high probability. For \ntransitive closure, the amortized time for each upd ate is O.V  4=3  lg 1=3  V/. By \ncomparison,  Problem  23-1,  in which  edges  are  inserted,  asks  for an incremental \nalgorithm.  For  all-pairs  shortest  paths,  the  update  times  depend on the queries. \nFor  queries  just  giving  the  shortest-path  weights,  the  amor tized time per update \nis O.V  3 =E  lg 2 V/. To report the actual shortest path, the amortized  update time \nis min \u02da \nO.V  3=2  p \nlg V/;O.V  3 =E  lg 2 V/  \ue009 \n. Demetrescu  and  Italiano  [111]  showed  \nhow to handle update and query operations when edge s are both inserted and \ndeleted, as long as the range of edge weights is bo unded. \nAho,  Hopcroft,  and  Ullman  [5]  de\u00fbned  an algebraic  structure  known as a <closed \nsemiring,= which serves as a general framework for solving path  problems  in di-  \nrected  graphs.  Both  the  Floyd-Warshall  algorithm  and  the  transitive-closure  algo-  \nrithm  from  Section  23.2  are  instantiations  of an all-pairs  algorithm based on closed \nsemirings.  Maggs  and  Plotkin  [309]  showed  how  to \u00fbnd  minimum  spanning trees \nusing a closed semiring. 24  Maximum  Flow  \nJust  as you  can  model  a road  map  as a directed  graph  in order  to \u00fbnd the shortest \npath from one point to another, you can also interp ret a directed  graph  as a <\u00fcow  \nnetwork=  and  use  it to answer  questions  about  material  \u00fcows.  Imagine  a mate-  \nrial coursing through a system from a source, where  the material is produced, to \na sink, where it is consumed. The source produces t he material at some steady \nrate, and the sink consumes the material at the sam e rate. The <\u00fcow=  of the  mate-  \nrial at any point in the system is intuitively the rate at which the material moves. \nFlow  networks  can  model  many  problems,  including  liquids  \u00fcowing through pipes, \nparts through assembly lines, current through elect rical networks, and information \nthrough communication networks. \nYou  can  think  of each  directed  edge  in a \u00fcow  network  as a conduit  for  the  mate-  \nrial. Each conduit has a stated capacity, given as a maximum r ate  at which  the  ma-  \nterial  can  \u00fcow  through  the  conduit,  such  as 200  gallons of liquid per hour through \na pipe or 20  amperes of electrical current through a wire. Verti ces are conduit \njunctions,  and  other  than  the  source  and  sink,  material  \u00fcows  through the vertices \nwithout collecting in them. In other words, the rat e at which material  enters  a ver-  \ntex must equal the rate at which it leaves the vert ex. We call t his  property  <\u00fcow  \nconservation,=  and  it is equivalent  to Kirchhoff9s  current  law when the material is \nelectrical current. \nThe  goal  of the  maximum-\u00fcow  problem  is to compute  the  greatest  rate  for  ship-  \nping material from the source to the sink without v iolating any capacity constraints. \nIt is one  of the  simplest  problems  concerning  \u00fcow  networks  and, as we shall see \nin this  chapter,  this  problem  can  be solved  by  ef\u00fbcient  algor ithms. Moreover, \nother  network-\u00fcow  problems  are  solvable  by  adapting  the  basic techniques used \nin maximum-\u00fcow  algorithms.  \nThis chapter presents two general methods for solvi ng the maximum-\u00fcow  prob-  \nlem.  Section  24.1  formalizes  the  notions  of \u00fcow  networks  and  \u00fcows,  formally  \nde\u00fbning  the  maximum-\u00fcow  problem.  Section  24.2  describes  the classical method 24.1 Flow networks 671 \nof Ford  and  Fulkerson  for  \u00fbnding  maximum  \u00fcows.  We  \u00fbnish  up  with a simple \napplication  of this  method,  \u00fbnding  a maximum  matching  in an undirected bipartite \ngraph,  in Section  24.3.  (Section  25.1  will  give  a more  ef\u00fbcie nt algorithm that is \nspeci\u00fbcally  designed  to \u00fbnd  a maximum  matching  in a bipartit e graph.) \n24.1  Flow  networks  \nThis  section  gives  a graph-theoretic  de\u00fbnition  of \u00fcow  netwo rks, discusses their \nproperties,  and  de\u00fbnes  the  maximum-\u00fcow  problem  precisely.  It also introduces \nsome helpful notation. \nFlow  networks  and  \ufb02ows  \nA \u00fcow  network  G D .V;E/  is a directed graph in which each edge .u;v/  2 E \nhas a nonnegative capacity  c.u;v/  \ue004 0. We further require that if E contains \nan edge .u;v/ , then there is no edge .v;u/  in the  reverse  direction.  (We9ll  see  \nshortly how to work around this restriction.) If .u;v/  \u2026 E, then for convenience \nwe  de\u00fbne  c.u;v/  D 0, and  we  disallow  self-loops.  Each  \u00fcow  network  contains  \ntwo distinguished vertices: a source  s and a sink  t . For convenience, we assume \nthat each vertex lies on some path from the source to the sink. That is, for each \nvertex v 2 V , the  \u00fcow  network  contains  a path  s \u2740  v \u2740  t . Because each vertex \nother than s has at least one entering edge, we have jEj \ue004 jV j \ue003  1. Figure  24.1  \nshows  an example  of a \u00fcow  network.  \ns t 16 12  \n20 7 \n9 4 \n13 \n14  4 Edmonton \nCalgary Saskatoon \nRegina Vancouver Winnipeg \ns t 11/16 12/12  \n15/20\n 7/7  \n4/9 1/4  \n8/13\n \n11/14  4/4 \n(a) (b) v 1 v 1 \nv 2 v 2 v 3 v 3 \nv 4 v 4 \nFigure  24.1  (a)  A \u00fcow  network  G D .V;E/  for  the  Lucky  Puck  Company9s  trucking  problem.  \nThe Vancouver factory is the source s , and the Winnipeg warehouse is the sink t . The company ships \npucks through intermediate cities, but only c.u;v/  crates per day can go from city u to city v. Each \nedge is labeled with its capacity. (b)  A \u00fcow  f in G with value jf j D  19. Each edge .u;v/  is labeled \nby f.u;v/=c.u;v/ . The  slash  notation  merely  separates  the  \u00fcow  and  capacity  and does not indicate \ndivision. 672  Chapter  24  Maximum  Flow  \nWe  are  now  ready  to de\u00fbne  \u00fcows  more  formally.  Let  G D .V;E/  be a \u00fcow  \nnetwork with a capacity function c . Let s be the source of the network, and let t be \nthe sink. A \u00fcow  in G is a real-valued  function  f W V \ue005 V !  R that  satis\u00fbes  the  \nfollowing two properties: \nCapacity  constraint:  For all u;v  2 V , we require \n0 \u0dc4 f.u;v/  \u0dc4 c.u;v/:  \nThe  \u00fcow  from  one  vertex  to another  must  be nonnegative  and  must not exceed \nthe given capacity. \nFlow  conservation:  For all u 2 V \ue003 fs;t  g, we require \nX  \nv2V f.v;u/  D X  \nv2V f.u;v/:  \nThe  total  \u00fcow  into  a vertex  other  than  the  source  or sink  must  equal the total \n\u00fcow  out  of that  vertex4informally,  <\u00fcow  in equals  \u00fcow  out.=  \nWhen .u;v/  \u2026 E, there  can  be no  \u00fcow  from  u to v, and f.u;v/  D 0. \nWe call the nonnegative quantity f.u;v/  the  \u00fcow  from  vertex  u to vertex v. The \nvalue  jf j of a \u00fcow  f is de\u00fbned  as \njf j D  X  \nv2V f.s;v/  \ue003 X  \nv2V f.v;s/;  (24.1)  \nthat  is, the  total  \u00fcow  out  of the  source  minus  the  \u00fcow  into  the  source. (Here, the j\ue001j \nnotation  denotes  \u00fcow  value,  not  absolute  value  or cardinality.)  Typically,  a \u00fcow  \nnetwork  does  not  have  any  edges  into  the  source,  and  the  \u00fcow  into the source, \ngiven by the summation P  \nv2V f.v;s/ , is 0. We include it, however, because when \nwe  introduce  residual  networks  later  in this  chapter,  the  \u00fcow into the source can \nbe positive. In the maximum-\u00fcow  problem, the  input  is a \u00fcow  network  G with \nsource s and sink t , and  the  goal  is to \u00fbnd  a \u00fcow  of maximum  value.  \nAn  example  of \ufb02ow  \nA \u00fcow  network  can  model  the  trucking  problem  shown  in Figure  24.1(a).  The  \nLucky Puck Company has a factory (source s ) in Vancouver that manufactures \nhockey pucks, and it has a warehouse (sink t ) in Winnipeg that stocks them. Lucky \nPuck  leases  space  on  trucks  from  another  \u00fbrm  to ship  the  pucks  from the factory \nto the  warehouse.  Because  the  trucks  travel  over  speci\u00fbed  routes (edges) between \ncities (vertices) and have a limited capacity, Luck y Puck can ship at most c.u;v/  \ncrates per day between each pair of cities u and v in Figure  24.1(a).  Lucky  Puck  24.1 Flow networks 673 \ns t 16 12  \n20 7 \n9 4 \n13 \n14  4 \n(a) (b) 10  s t 16 12  \n20 7 \n9 4 \n13 \n14  4 10  \n10  v 1 v 1 \nv 2 v 2 v 3 v 3 \nv 4 v 4 v 0 \nFigure  24.2  Converting a network with antiparallel edges to an equivalent one with no antiparallel \nedges. (a)  A \u00fcow  network  containing  both  the  edges  .v 1 ;v  2 / and .v 2 ;v  1 /. (b)  An equivalent network \nwith no antiparallel edges. A new vertex v 0 was added, and edge .v 1 ;v  2 / was replaced by the pair \nof edges .v 1 ;v  0 / and .v 0 ;v  2 /, both with the same capacity as .v 1 ;v  2 /. \nhas no control over these routes and capacities, an d so the company cannot alter \nthe  \u00fcow  network  shown  in Figure  24.1(a).  They  need  to determi ne the largest \nnumber p of crates per day that they can ship and then to pr oduce this amount, since \nthere is no point in producing more pucks than they  can ship to their warehouse. \nLucky Puck is not concerned with how long it takes for a given puck to get from \nthe factory to the warehouse. They care only that p crates per day leave the factory \nand p crates per day arrive at the warehouse. \nA \u00fcow  in this  network  models  the  <\u00fcow=  of shipments  because  the number of \ncrates shipped per day from one city to another is subject to a capacity constraint. \nAdditionally,  the  model  must  obey  \u00fcow  conservation,  for  in a steady state, the rate \nat which pucks enter an intermediate city must equa l the rate at which they leave. \nOtherwise,  crates  would  accumulate  at intermediate  cities . \nModeling  problems  with  antiparallel  edges  \nSuppose  that  the  trucking  \u00fbrm  offers  Lucky  Puck  the  opportun ity to lease space \nfor  10  crates  in trucks  going  from  Edmonton  to Calgary.  It might seem natural to \nadd this opportunity to our example and form the ne twork shown in Figure  24.2(a).  \nThis network suffers from one problem, however: it violates the  original  assump-  \ntion that if edge .v 1 ;v  2 / 2 E, then .v 2 ;v  1 / \u2026 E. We call the two edges .v 1 ;v  2 / \nand .v 2 ;v  1 / antiparallel. Thus,  to model  a \u00fcow  problem  with  antiparallel  edges,  \nthe network must be transformed into an equivalent one containing  no  antiparal-  \nlel  edges.  Figure  24.2(b)  displays  this  equivalent  network.  To  transform  the  net-  \nwork, choose one of the two antiparallel edges, in this case .v 1 ;v  2 /, and split it by \nadding a new vertex v 0 and replacing edge .v 1 ;v  2 / with the pair of edges .v 1 ;v  0 / \nand .v 0 ;v  2 /. Also set the capacity of both new edges to the ca pacity of the orig-  \ninal  edge.  The  resulting  network  satis\u00fbes  the  property  that  if an edge belongs to 674  Chapter  24  Maximum  Flow  \n\u221e \n(a) \u221e \u221e \n(b) s t 3 \n15 \n6 \n20 s 1 \ns 2 \ns 3 t 1 \nt 2 10  \n12 \n5 \n8 \n14  3 \n15 \n6 \n20 s 1 \ns 2 \ns 3 t 1 \nt 2 10  \n12 \n5 \n8 \n14  \u221e \u221e \nFigure  24.3  Converting  a multiple-source,  multiple-sink  maximum-\u00fcow  problem into a problem \nwith a single source and a single sink. (a)  A \u00fcow  network  with  three  sources  S D fs 1 ; s 2 ; s 3 g and two \nsinks T D ft 1 ; t 2 g. (b)  An  equivalent  single-source,  single-sink  \u00fcow  network.  Add  a supersource s \nand  an  edge  with  in\u00fbnite  capacity  from  s to each of the multiple sources. Also add a supersi nk t and \nan  edge  with  in\u00fbnite  capacity  from  each  of the  multiple  sinks  to t . \nthe  network,  the  reverse  edge  does  not.  As  Exercise  24.1-1  asks you to prove, the \nresulting network is equivalent to the original one . \nNetworks  with  multiple  sources  and  sinks  \nA maximum-\u00fcow  problem  may  have  several  sources  and  sinks,  rather than just \none of each. The Lucky Puck Company, for example, m ight actually have a set \nof m factories fs 1 ; s 2 ; : : : ; s  m g and a set of n warehouses ft 1 ; t 2 ; : : : ; t  n g, as shown \nin Figure  24.3(a).  Fortunately,  this  problem  is no  harder  than ordinary maximum \n\u00fcow.  \nThe  problem  of determining  a maximum  \u00fcow  in a network  with  multiple sources \nand  multiple  sinks  reduces  to an ordinary  maximum-\u00fcow  problem.  Figure  24.3(b)  \nshows  how  to convert  the  network  from  (a)  to an ordinary  \u00fcow  network with only a \nsingle source and a single sink. Add a supersource  s and add a directed edge .s; s  i / \nwith capacity c.s; s  i / D 1  for each i D 1; 2; : : : ; m . Similarly, create a new \nsupersink  t and add a directed edge .t i ; t/  with capacity c.t  i ; t/  D 1  for each \ni D 1; 2; : : : ; n. Intuitively,  any  \u00fcow  in the  network  in (a)  corresponds  to a \u00fcow in \nthe network in (b), and vice versa. The single supe rsource s provides  as much  \u00fcow  \nas desired for the multiple sources s i , and the single supersink t likewise consumes \nas much  \u00fcow  as desired  for  the  multiple  sinks  t i . Exercise  24.1-2  asks  you  to prove  \nformally that the two problems are equivalent. 24.1 Flow networks 675 \nExercises  \n24.1-1  \nShow  that  splitting  an edge  in a \u00fcow  network  yields  an equival ent network. More \nformally,  suppose  that  \u00fcow  network  G contains edge .u; v/, and  de\u00fbne  a new  \u00fcow  \nnetwork G 0 by creating a new vertex x and replacing .u; v/  by new edges .u; x/  \nand .x; v/  with c.u; x/  D c.x; v/  D c.u; v/. Show  that  a maximum  \u00fcow  in G 0 has \nthe  same  value  as a maximum  \u00fcow  in G. \n24.1-2  \nExtend  the  \u00fcow  properties  and  de\u00fbnitions  to the  multiple-source,  multiple-sink  \nproblem.  Show  that  any  \u00fcow  in a multiple-source,  multiple-sink  \u00fcow  network  \ncorresponds  to a \u00fcow  of identical  value  in the  single-source,  single-sink  network  \nobtained by adding a supersource and a supersink, a nd vice versa. \n24.1-3  \nSuppose  that  a \u00fcow  network  G D .V; E/  violates the assumption that the network \ncontains a path s \u2740  v \u2740  t for all vertices v 2 V . Let u be a vertex for which there \nis no path s \u2740  u \u2740  t . Show  that  there  must  exist  a maximum  \u00fcow  f in G such \nthat f .u; v/  D f .v; u/  D 0 for all vertices v 2 V . \n24.1-4  \nLet f be a \u00fcow  in a network,  and  let  \u02db be a real number. The scalar  \u00fcow  product , \ndenoted \u02dbf  , is a function from V \ue005 V to R de\u00fbned  by  \n.\u02dbf /.u; v/  D \u02db \ue001 f .u; v/ :  \nProve  that  the  \u00fcows  in a network  form  a convex  set. That is, show that if f 1 and f 2 \nare  \u00fcows,  then  so is \u02dbf  1 C .1 \ue003 \u02db/f  2 for all \u02db in the range 0 \u0dc4 \u02db \u0dc4 1. \n24.1-5  \nState  the  maximum-\u00fcow  problem  as a linear-programming  problem. \n24.1-6  \nProfessor Adam has two children who, unfortunately,  dislike each  other.  The  prob-  \nlem is so severe that not only do they refuse to wa lk to school together, but in fact \neach one refuses to walk on any block that the othe r child has stepped on that day. \nThe children have no problem with their paths cross ing at a corner. Fortunately \nboth  the  professor9s  house  and  the  school  are  on  corners,  but  beyond that he is not \nsure if it is going to be possible to send both of his children to the same school. \nThe professor has a map of his town. Show how to fo rmulate the p roblem  of de-  \ntermining whether both his children can go to the s ame school as a maximum-\u00fcow  \nproblem. 676  Chapter  24  Maximum  Flow  \n24.1-7  \nSuppose  that,  in addition  to edge  capacities,  a \u00fcow  network  has vertex  capacities . \nThat is each vertex v has a limit l.v/  on  how  much  \u00fcow  can  pass  through  v. Show \nhow  to transform  a \u00fcow  network  G D .V; E/  with  vertex  capacities  into  an equiv-  \nalent  \u00fcow  network  G 0 D .V  0 ; E  0 / without vertex capacities, such that a maximum \n\u00fcow  in G 0 has  the  same  value  as a maximum  \u00fcow  in G. How many vertices and \nedges does G 0 have?  \n24.2  The  Ford-Fulkerson  method  \nThis  section  presents  the  Ford-Fulkerson  method  for  solving  the  maximum-\u00fcow  \nproblem. We call it a <method= rather than an <algo rithm= because it encompasses \nseveral implementations with differing running time s. The Ford-Fulkerson  method  \ndepends on three important ideas that transcend the  method and are relevant to \nmany  \u00fcow  algorithms  and  problems:  residual  networks,  augme nting paths, and \ncuts.  These  ideas  are  essential  to the  important  max-\u00fcow  min-cut  theorem  (The-  \norem  24.6),  which  characterizes  the  value  of a maximum  \u00fcow  in terms of cuts of \nthe  \u00fcow  network.  We  end  this  section  by  presenting  one  speci\u00fb c implementation \nof the  Ford-Fulkerson  method  and  analyzing  its  running  time. \nThe  Ford-Fulkerson  method  iteratively  increases  the  value  of the  \u00fcow.  It starts  \nwith f .u; v/  D 0 for all u; v  2 V , giving  an initial  \u00fcow  of value  0. Each iteration \nincreases  the  \u00fcow  value  in G by  \u00fbnding  an <augmenting  path=  in an associated  \n<residual network= G f . The edges of the augmenting path in G f indicate on which \nedges in G to update  the  \u00fcow  in order  to increase  the  \u00fcow  value.  Although  each \niteration  of the  Ford-Fulkerson  method  increases  the  value  of the  \u00fcow,  we9ll  see  \nthat  the  \u00fcow  on  any  particular  edge  of G may increase or decrease. Although it \nmight  seem  counterintuitive  to decrease  the  \u00fcow  on  an edge,  doing so may enable \n\u00fcow  to increase  on  other  edges,  allowing  more  \u00fcow  to travel  from the source to \nthe  sink.  The  Ford-Fulkerson  method,  given  in the  procedure  FORD-FULKERSON- \nMETHOD, repeatedly  augments  the  \u00fcow  until  the  residual  network  has  no more \naugmenting  paths.  The  max-\u00fcow  min-cut  theorem  shows  that  upon termination, \nthis  process  yields  a maximum  \u00fcow.  \nFORD-FULKERSON-METHOD  .G; s; t/  \n1 initialize  \u00fcow  f to 0 \n2 while  there exists an augmenting path p in the residual network G f \n3 augment  \u00fcow  f along p \n4 return  f 24.2  The  Ford-Fulkerson  method  677 \nIn order  to implement  and  analyze  the  Ford-Fulkerson  method,  we  need  to in-  \ntroduce several additional concepts. \nResidual  networks  \nIntuitively,  given  a \u00fcow  network  G and  a \u00fcow  f , the residual network G f consists \nof edges  whose  capacities  represent  how  the  \u00fcow  can  change  on  edges of G. An \nedge  of the  \u00fcow  network  can  admit  an amount  of additional  \u00fcow  equal to the \nedge9s  capacity  minus  the  \u00fcow  on  that  edge.  If that  value  is positive, that edge \ngoes into G f with a <residual capacity= of c f .u; v/  D c.u; v/  \ue003 f .u; v/ . The \nonly edges of G that belong to G f are  those  that  can  admit  more  \u00fcow.  Those  \nedges .u; v/  whose  \u00fcow  equals  their  capacity  have  c f .u; v/  D 0, and they do not \nbelong to G f . \nYou might be surprised that the residual network G f can also contain edges that \nare not in G. As  an algorithm  manipulates  the  \u00fcow,  with  the  goal  of increa sing \nthe  total  \u00fcow,  it might  need  to decrease  the  \u00fcow  on  a particula r edge in order to \nincrease  the  \u00fcow  elsewhere.  In order  to represent  a possible  decrease in the positive \n\u00fcow  f .u; v/  on an edge in G, the residual network G f contains an edge .v; u/  with \nresidual capacity c f .v; u/  D f .u; v/4that  is, an edge  that  can  admit  \u00fcow  in the  \nopposite direction to .u; v/, at most  canceling  out  the  \u00fcow  on  .u; v/ . These reverse \nedges in the residual network allow an algorithm to  send back \u00fcow  it has  already  \nsent  along  an edge.  Sending  \u00fcow  back  along  an edge  is equivale nt to decreasing  \nthe  \u00fcow  on  the  edge,  which  is a necessary  operation  in many  algorithms. \nMore  formally,  for  a \u00fcow  network  G D .V; E/  with source s , sink t , and a \n\u00fcow  f , consider a pair of vertices u; v  2 V . We  de\u00fbne  the  residual  capac-  \nity  c f .u; v/  by \nc f .u; v/  D \u0128 \nc.u; v/  \ue003 f .u; v/  if .u; v/  2 E ;  \nf .v; u/  if .v; u/  2 E ;  \n0 otherwise : (24.2)  \nIn a \u00fcow  network,  .u; v/  2 E implies .v; u/  \u2026 E, and so exactly one case in \nequation  (24.2)  applies  to each  ordered  pair  of vertices.  \nAs  an example  of equation  (24.2),  if c.u; v/  D 16  and f .u; v/  D 11, then \nf .u; v/  can increase by up to c f .u; v/  D 5 units before exceeding the capacity \nconstraint on edge .u; v/ . Alternatively, up to 11  units  of \u00fcow  can  return  from  v \nto u, so that c f .v; u/  D 11. \nGiven  a \u00fcow  network  G D .V; E/  and  a \u00fcow  f , the residual  network  of G \ninduced by f is G f D .V; E  f /, where \nE f D f.u; v/  2 V \ue005 V W c f .u; v/ > 0 g : (24.3)  678  Chapter  24  Maximum  Flow  \n9 15 s t 5 12  \n5 7 \n5 3 1 \n8 \n11  4 \ns t 11/16 12/12  \n19/20\n 7/7  \n9 1/4  \n12/13\n \n11/14  4/4 (b) \n(c) 11 \n5 \n3 4 \ns t 11/16 12/12  \n15/20\n 7/7  \n4/9 1/4  \n8/13\n \n11/14  4/4 \n(d) 19 s t 5 12  \n1 7 3 1 \n12 \n11  4 11 \n1 \n3 (a) \nv 1 v 1 v 1 v 1 \nv 2 v 2 v 2 v 2 \nv 3 v 3 v 3 v 3 \nv 4 v 4 v 4 v 4 \nFigure  24.4  (a)  The  \u00fcow  network  G and  \u00fcow  f of Figure  24.1(b).  (b)  The residual network G f \nwith augmenting path p, having residual capacity c f .p/  D c f .v 2 ; v  3 / D 4, in blue. Edges with \nresidual capacity equal to 0, such as .v 1 ; v  3 /, are not shown, a convention we follow in the rema inder \nof this section. (c)  The  \u00fcow  in G that results from augmenting along path p by its residual capacity 4. \nEdges  carrying  no  \u00fcow,  such  as .v 3 ; v  2 /, are labeled only by their capacity, another conve ntion we \nfollow throughout. (d)  The  residual  network  induced  by  the  \u00fcow  in (c).  \nThat is, as promised above, each edge of the residu al network, or residual  edge , \ncan  admit  a \u00fcow  that  is greater  than  0. Figure  24.4(a)  repeats  the  \u00fcow  network  G \nand  \u00fcow  f of Figure  24.1(b),  and  Figure  24.4(b)  shows  the  correspondi ng residual \nnetwork G f . The edges in E f are either edges in E or their reversals, and thus \njE f j \u0dc4  2 jEj : \nObserve  that  the  residual  network  G f is similar  to a \u00fcow  network  with  capac-  \nities given by c f . It does  not  satisfy  the  de\u00fbnition  of a \u00fcow  network,  however,  \nbecause  it could  contain  antiparallel  edges.  Other  than  this difference, a residual \nnetwork  has  the  same  properties  as a \u00fcow  network,  and  we  can  de\u00fbne  a \u00fcow  in the  \nresidual  network  as one  that  satis\u00fbes  the  de\u00fbnition  of a \u00fcow,  but with respect to \ncapacities c f in the residual network G f . \nA \u00fcow  in a residual  network  provides  a roadmap  for  adding  \u00fcow  to the original \n\u00fcow  network.  If f is a \u00fcow  in G and f 0 is a \u00fcow  in the  corresponding  residual  \nnetwork G f , we  de\u00fbne  f \" f 0 , the augmentation  of \u00fcow  f by f 0 , to be a function \nfrom V \ue005 V to R, de\u00fbned  by  24.2  The  Ford-Fulkerson  method  679 \n.f \" f 0 /.u;v/  D ( \nf.u;v/  C f 0 .u;v/  \ue003 f 0 .v;u/  if .u;v/  2 E;  \n0 otherwise : (24.4)  \nThe  intuition  behind  this  de\u00fbnition  follows  the  de\u00fbnition  of the residual network. \nThe  \u00fcow  on  .u;v/  increases by f 0 .u;v/ , but decreases by f 0 .v;u/  because  push-  \ning  \u00fcow  on  the  reverse  edge  in the  residual  network  signi\u00fbes  decreasing  the  \u00fcow  \nin the  original  network.  Pushing  \u00fcow  on  the  reverse  edge  in the residual network is \nalso known as cancellation . For example, suppose that 5 crates of hockey pucks go \nfrom u to v and 2 crates go from v to u. That is equivalent (from the perspective of \nthe  \u00fbnal  result)  to sending  3 crates from u to v and none from v to u. Cancellation \nof this  type  is crucial  for  any  maximum-\u00fcow  algorithm.  \nThe  following  lemma  shows  that  augmenting  a \u00fcow  in G by  a \u00fcow  in G f yields \na new  \u00fcow  in G with  a greater  \u00fcow  value.  \nLemma  24.1  \nLet G D .V;E/  be a \u00fcow  network  with  source  s and sink t , and let f be a \u00fcow  \nin G. Let G f be the residual network of G induced by f , and let f 0 be a \u00fcow  \nin G f . Then the function f \" f 0 de\u00fbned  in equation  (24.4)  is a \u00fcow  in G with \nvalue jf \" f 0 j D jf j C jf 0 j. \nProof  We  \u00fbrst  verify  that  f \" f 0 obeys the capacity constraint for each edge in E \nand  \u00fcow  conservation  at each  vertex  in V \ue003 fs;t  g. \nFor  the  capacity  constraint,  \u00fbrst  observe  that  if .u;v/  2 E, then c f .v;u/  D \nf.u;v/ . Because f 0 is a \u00fcow  in G f , we have f 0 .v;u/  \u0dc4 c f .v;u/ , which gives \nf 0 .v;u/  \u0dc4 f.u;v/ . Therefore, \n.f \" f 0 /.u;v/  D f.u;v/  C f 0 .u;v/  \ue003 f 0 .v;u/  (by  equation  (24.4))  \n\ue004 f.u;v/  C f 0 .u;v/  \ue003 f.u;v/  (because f 0 .v;u/  \u0dc4 f.u;v/ ) \nD f 0 .u;v/  \n\ue004 0:  \nIn addition, \n.f \" f 0 /.u;v/  \nD f.u;v/  C f 0 .u;v/  \ue003 f 0 .v;u/  (by  equation  (24.4))  \n\u0dc4 f.u;v/  C f 0 .u;v/  (because  \u00fcows  are  nonnegative)  \n\u0dc4 f.u;v/  C c f .u;v/  (capacity constraint) \nD f.u;v/  C c.u;v/  \ue003 f.u;v/  (de\u00fbnition  of c f ) \nD c.u;v/:  \nTo  show  that  \u00fcow  conservation  holds  and  that  jf \" f 0 j D jf j C jf 0 j, we  \u00fbrst  \nprove the claim that for all u 2 V , we have 680  Chapter  24  Maximum  Flow  \nX  \nv2V .f \" f 0 /.u;v/  \ue003 X  \nv2V .f \" f 0 /.v;u/  \nD X  \nv2V f.u;v/  \ue003 X  \nv2V f.v;u/  C X  \nv2V f 0 .u;v/  \ue003 X  \nv2V f 0 .v;u/:  (24.5)  \nBecause we disallow antiparallel edges in G (but not in G f ), we know that for \neach vertex u, there can be an edge .u;v/  or .v;u/  in G, but never both. For a \n\u00fbxed  vertex  u, de\u00fbne  V l .u/  D fv W .u;v/  2 Eg to be the set of vertices with edges \nin G leaving u, and  de\u00fbne  V e .u/  D fv W .v;u/  2 Eg to be the set of vertices with \nedges in G entering u. We have V l .u/  [ V e .u/  \u0dc2 V and, because G contains no \nantiparallel edges, V l .u/  \\ V e .u/  D ;. By  the  de\u00fbnition  of \u00fcow  augmentation  in \nequation  (24.4),  only  vertices  v in V l .u/  can have positive .f \" f 0 /.u;v/ , and only \nvertices v in V e .u/  can have positive .f \" f 0 /.v;u/. Starting  from  the  left-hand  \nside  of equation  (24.5),  we  use  this  fact  and  then  reorder  and  group terms, giving \nX  \nv2V .f \" f 0 /.u;v/  \ue003 X  \nv2V .f \" f 0 /.v;u/  \nD X  \nv2V l .u/  .f \" f 0 /.u;v/  \ue003 X  \nv2V e .u/  .f \" f 0 /.v;u/  \nD X  \nv2V l .u/  .f.u;v/  C f 0 .u;v/  \ue003 f 0 .v;u//  \ue003 X  \nv2V e .u/  .f.v;u/  C f 0 .v;u/  \ue003 f 0 .u;v//  \nD X  \nv2V l .u/  f.u;v/  C X  \nv2V l .u/  f 0 .u;v/  \ue003 X  \nv2V l .u/  f 0 .v;u/  \n\ue003 X  \nv2V e .u/  f.v;u/  \ue003 X  \nv2V e .u/  f 0 .v;u/  C X  \nv2V e .u/  f 0 .u;v/  \nD X  \nv2V l .u/  f.u;v/  \ue003 X  \nv2V e .u/  f.v;u/  \nC X  \nv2V l .u/  f 0 .u;v/  C X  \nv2V e .u/  f 0 .u;v/  \ue003 X  \nv2V l .u/  f 0 .v;u/  \ue003 X  \nv2V e .u/  f 0 .v;u/  \nD X  \nv2V l .u/  f.u;v/  \ue003 X  \nv2V e .u/  f.v;u/  C X  \nv2V l .u/[V e .u/  f 0 .u;v/  \ue003 X  \nv2V l .u/[V e .u/  f 0 .v;u/:  (24.6)  \nIn equation  (24.6),  all  four  summations  can  extend  to sum  over V , since each \nadditional term has value 0. (Exercise  24.2-1  asks  you  to prove  this  formally.)  \nTaking all four summations over V , instead of just subsets of V , proves the claim \nin equation  (24.5).  \nNow  we  are  ready  to prove  \u00fcow  conservation  for  f \" f 0 and that jf \" f 0 j D  \njf j C jf 0 j. For the latter property, let u D s in equation  (24.5).  Then,  we  have  24.2  The  Ford-Fulkerson  method  681 \njf \" f 0 j D  X  \nv2V .f \" f 0 /.s;v/  \ue003 X  \nv2V .f \" f 0 /.v;s/  \nD X  \nv2V f.s;v/  \ue003 X  \nv2V f.v;s/  C X  \nv2V f 0 .s;v/  \ue003 X  \nv2V f 0 .v;s/  \nD jf j C jf 0 j : \nFor  \u00fcow  conservation,  observe  that  for  any  vertex  u that is neither s nor t , \u00fcow  \nconservation for f and f 0 means  that  the  right-hand  side  of equation  (24.5)  is 0, \nand thus P  \nv2V .f \" f 0 /.u;v/  D P  \nv2V .f \" f 0 /.v;u/ . \nAugmenting  paths  \nGiven  a \u00fcow  network  G D .V;E/  and  a \u00fcow  f , an augmenting  path  p is a \nsimple path from s to t in the residual network G f . By  the  de\u00fbnition  of the  resid-  \nual  network,  the  \u00fcow  on  an edge  .u;v/  of an augmenting path may increase by \nup to c f .u;v/  without violating the capacity constraint on whiche ver of .u;v/  \nand .v;u/  belongs  to the  original  \u00fcow  network  G. \nThe  blue  path  in Figure  24.4(b)  is an augmenting  path.  Treati ng the residual \nnetwork G f in the  \u00fbgure  as a \u00fcow  network,  the  \u00fcow  through  each  edge  of this  \npath can increase by up to 4 units without violating a capacity constraint, sinc e the \nsmallest residual capacity on this path is c f .v 2 ;v  3 / D 4. We call the maximum \namount  by  which  we  can  increase  the  \u00fcow  on  each  edge  in an augme nting path p \nthe residual  capacity  of p, given by \nc f .p/  D min fc f .u;v/  W .u;v/  is in pg : \nThe  following  lemma,  which  Exercise  24.2-7  asks  you  to prove , makes the above \nargument more precise. \nLemma  24.2  \nLet G D .V;E/  be a \u00fcow  network,  let  f be a \u00fcow  in G, and let p be an augmenting \npath in G f . De\u00fbne  a function  f p W V \ue005 V !  R by \nf p .u;v/  D ( \nc f .p/  if .u;v/  is on p;  \n0 otherwise : (24.7)  \nThen, f p is a \u00fcow  in G f with value jf p j D  c f .p/>0 . \nThe following corollary shows that augmenting f by f p produces  another  \u00fcow  \nin G whose  value  is closer  to the  maximum.  Figure  24.4(c)  shows  the result of \naugmenting  the  \u00fcow  f from  Figure  24.4(a)  by  the  \u00fcow  f p in Figure  24.4(b),  and  \nFigure  24.4(d)  shows  the  ensuing  residual  network.  682  Chapter  24  Maximum  Flow  \nCorollary  24.3  \nLet G D .V;E/  be a \u00fcow  network,  let  f be a \u00fcow  in G, and let p be an aug-  \nmenting path in G f . Let f p be de\u00fbned  as in equation  (24.7),  and  suppose  that  \nf is augmented by f p . Then the function f \" f p is a \u00fcow  in G with value \njf \" f p j D jf j C jf p j > jf j. \nProof  Immediate  from  Lemmas  24.1  and  24.2.  \nCuts  of \ufb02ow  networks  \nThe  Ford-Fulkerson  method  repeatedly  augments  the  \u00fcow  along augmenting paths \nuntil  it has  found  a maximum  \u00fcow.  How  do  we  know  that  when  the  algorithm \nterminates,  it has  actually  found  a maximum  \u00fcow?  The  max-\u00fcow  min-cut  theorem,  \nwhich  we  will  prove  shortly,  tells  us that  a \u00fcow  is maximum  if and only if its \nresidual network contains no augmenting path. To pr ove this theorem, though, we \nmust  \u00fbrst  explore  the  notion  of a cut  of a \u00fcow  network.  \nA cut  .S;T/  of \u00fcow  network  G D .V;E/  is a partition of V into S and \nT D V \ue003 S such that s 2 S and t 2 T . (This  de\u00fbnition  is similar  to the  def-  \ninition of <cut= that we used for minimum spanning trees in Chapter  21,  except  \nthat here we are cutting a directed graph rather th an an undirected graph, and we \ninsist that s 2 S and t 2 T .) If f is a \u00fcow,  then  the  net  \u00fcow  f.S;T/  across the \ncut .S;T/  is de\u00fbned  to be \nf.S;T/  D X  \nu2S X  \nv2T f.u;v/  \ue003 X  \nu2S X  \nv2T f.v;u/:  (24.8)  \nThe capacity  of the cut .S;T/  is \nc.S;T/  D X  \nu2S X  \nv2T c.u;v/:  (24.9)  \nA minimum  cut  of a network is a cut whose capacity is minimum ove r all cuts of \nthe network. \nYou  probably  noticed  that  the  de\u00fbnitions  of \u00fcow  across  a cut  and capacity of \na cut  differ  in that  \u00fcow  counts  edges  going  in both  directions  across the cut, but \ncapacity counts only edges going from the source si de of the cut toward the sink \nside. This asymmetry is intentional and important. The reason for this difference \nwill become apparent later in this section. \nFigure  24.5  shows  the  cut  .fs;v  1 ;v  2 g ; fv 3 ;v  4 ;t g/ in the  \u00fcow  network  of Fig-  \nure  24.1(b).  The  net  \u00fcow  across  this  cut  is \nf.v  1 ;v  3 / C f.v  2 ;v  4 / \ue003 f.v  3 ;v  2 / D 12  C 11  \ue003 4 \nD 19;  \nand the capacity of this cut is 24.2  The  Ford-Fulkerson  method  683 \ns t 11/16 12/12  \n15/20\n 7/7  \n4/9 1/4  \n8/13\n \n11/14  4/4 \nS T v 1 \nv 2 v 3 \nv 4 \nFigure  24.5  A cut .S;T/  in the  \u00fcow  network  of Figure  24.1(b),  where  S D fs;v  1 ;v  2 g and \nT D fv 3 ;v  4 ;t g. The vertices in S are orange, and the vertices in T are  tan.  The  net  \u00fcow  \nacross .S;T/  is f.S;T/  D 19, and the capacity is c.S;T/  D 26. \nc.v  1 ;v  3 / C c.v  2 ;v  4 / D 12  C 14  \nD 26:  \nThe  following  lemma  shows  that,  for  a given  \u00fcow  f , the  net  \u00fcow  across  any  cut  \nis the same, and it equals jf j, the  value  of the  \u00fcow.  \nLemma  24.4  \nLet f be a \u00fcow  in a \u00fcow  network  G with source s and sink t , and let .S;T/  be any \ncut of G. Then  the  net  \u00fcow  across  .S;T/  is f.S;T/  D jf j. \nProof  For any vertex u 2 V \ue003 fs;t  g, rewrite  the  \u00fcow-conservation  condition  as \nX  \nv2V f.u;v/  \ue003 X  \nv2V f.v;u/  D 0:  (24.10)  \nTaking  the  de\u00fbnition  of jf j from  equation  (24.1)  and  adding  the  left-hand  side  of \nequation  (24.10),  which  equals  0, summed over all vertices in S \ue003 fs g, gives \njf j D  X  \nv2V f.s;v/  \ue003 X  \nv2V f.v;s/  C X  \nu2S\ue002fsg \ue001 X  \nv2V f.u;v/  \ue003 X  \nv2V f.v;u/  ! \n: \nExpanding  the  right-hand  summation  and  regrouping  terms  yields \njf j D  X  \nv2V f.s;v/  \ue003 X  \nv2V f.v;s/  C X  \nu2S\ue002fsg X  \nv2V f.u;v/  \ue003 X  \nu2S\ue002fsg X  \nv2V f.v;u/  \nD X  \nv2V \ue001 \nf.s;v/  C X  \nu2S\ue002fsg f.u;v/  ! \n\ue003 X  \nv2V \ue001 \nf.v;s/  C X  \nu2S\ue002fsg f.v;u/  ! \nD X  \nv2V X  \nu2S f.u;v/  \ue003 X  \nv2V X  \nu2S f.v;u/:  684  Chapter  24  Maximum  Flow  \nBecause V D S [ T and S \\ T D ; , splitting each summation over V into \nsummations over S and T gives \njf j D  X  \nv2S X  \nu2S f.u;v/  C X  \nv2T X  \nu2S f.u;v/  \ue003 X  \nv2S X  \nu2S f.v;u/  \ue003 X  \nv2T X  \nu2S f.v;u/  \nD X  \nv2T X  \nu2S f.u;v/  \ue003 X  \nv2T X  \nu2S f.v;u/  \nC \ue001 X  \nv2S X  \nu2S f.u;v/  \ue003 X  \nv2S X  \nu2S f.v;u/  ! \n: \nThe two summations within the parentheses are actua lly the same, since for all \nvertices x;y  2 S , the term f.x;y/  appears once in each summation. Hence, these \nsummations cancel, yielding \njf j D  X  \nu2S X  \nv2T f.u;v/  \ue003 X  \nu2S X  \nv2T f.v;u/  \nD f.S;T/:  \nA corollary  to Lemma  24.4  shows  how  cut  capacities  bound  the  value  of a \u00fcow.  \nCorollary  24.5  \nThe  value  of any  \u00fcow  f in a \u00fcow  network  G is bounded from above by the capacity \nof any cut of G. \nProof  Let .S;T/  be any cut of G and let f be any  \u00fcow.  By  Lemma  24.4  and  the  \ncapacity constraint, \njf j D  f.S;T/  \nD X  \nu2S X  \nv2T f.u;v/  \ue003 X  \nu2S X  \nv2T f.v;u/  \n\u0dc4 X  \nu2S X  \nv2T f.u;v/  \n\u0dc4 X  \nu2S X  \nv2T c.u;v/  \nD c.S;T/:  \nCorollary  24.5  yields  the  immediate  consequence  that  the  value of a maximum \n\u00fcow  in a network  is bounded  from  above  by  the  capacity  of a mini mum cut of \nthe  network.  The  important  max-\u00fcow  min-cut  theorem,  which  we now state and \nprove,  says  that  the  value  of a maximum  \u00fcow  is in fact  equal  to the capacity of a \nminimum cut. 24.2  The  Ford-Fulkerson  method  685 \nTheorem  24.6  (Max-\u00fcow  min-cut  theorem)  \nIf f is a \u00fcow  in a \u00fcow  network  G D .V;E/  with source s and sink t , then the \nfollowing conditions are equivalent: \n1. f is a maximum  \u00fcow  in G. \n2. The residual network G f contains no augmenting paths. \n3. jf j D  c.S;T/  for some cut .S;T/  of G. \nProof  .1/  )  .2/: Suppose for the sake of contradiction that f is a maximum \n\u00fcow  in G but that G f has an augmenting path p. Then,  by  Corollary  24.3,  the  \n\u00fcow  found  by  augmenting  f by f p , where f p is given  by  equation  (24.7),  is a \u00fcow  \nin G with value strictly greater than jf j, contradicting the assumption that f is a \nmaximum  \u00fcow.  \n.2/  )  .3/: Suppose that G f has no augmenting path, that is, that G f contains \nno path from s to t . De\u00fbne  \nS D fv 2 V W there exists a path from s to v in G f g \nand T D V \ue003 S . The partition .S;T/  is a cut: we have s 2 S trivially and \nt \u2026 S because there is no path from s to t in G f . Now  consider  a pair  of ver-  \ntices u 2 S and v 2 T . If .u;v/  2 E, we must have f.u;v/  D c.u;v/ , since \notherwise .u;v/  2 E f , which would place v in set S . If .v;u/  2 E, we must \nhave f.v;u/  D 0, because otherwise c f .u;v/  D f.v;u/  would be positive and \nwe would have .u;v/  2 E f , which again would place v in S . Of  course,  if neither  \n.u;v/  nor .v;u/  belongs to E, then f.u;v/  D f.v;u/  D 0. We thus have \nf.S;T/  D X  \nu2S X  \nv2T f.u;v/  \ue003 X  \nv2T X  \nu2S f.v;u/  \nD X  \nu2S X  \nv2T c.u;v/  \ue003 X  \nv2T X  \nu2S 0 \nD c.S;T/:  \nBy  Lemma  24.4,  therefore,  jf j D  f.S;T/  D c.S;T/ . \n.3/  )  .1/: By  Corollary  24.5,  jf j \u0dc4  c.S;T/  for all cuts .S;T/ . The condition \njf j D  c.S;T/  thus implies that f is a maximum  \u00fcow.  \nThe  basic  Ford-Fulkerson  algorithm  \nEach  iteration  of the  Ford-Fulkerson  method  \u00fbnds  some augmenting path p and \nuses p to modify  the  \u00fcow  f . As  Lemma  24.2  and  Corollary  24.3  suggest,  replac-  \ning f by f \" f p produces  a new  \u00fcow  whose  value  is jf j C jf p j. The procedure \nFORD-FULKERSON  on  the  next  page  implements  the  method  by  updating  the  \u00fcow  686  Chapter  24  Maximum  Flow  \nattribute .u;v/:  f for each edge .u;v/  2 E. 1 It assumes implicitly that .u;v/:  f D 0 \nif .u;v/  \u2026 E. The procedure also assumes that the capacities c.u;v/  come with \nthe  \u00fcow  network,  and  that  c.u;v/  D 0 if .u;v/  \u2026 E. The procedure computes \nthe residual capacity c f .u;v/  in accordance  with  the  formula  (24.2).  The  expres-  \nsion c f .p/  in the code is just a temporary variable that store s the residual capacity \nof the path p. \nFORD-FULKERSON  .G;s;t/  \n1 for  each edge .u;v/  2 G:  E \n2 .u;v/:  f D 0 \n3 while  there exists a path p from s to t in the residual network G f \n4 c f .p/  D min fc f .u;v/  W .u;v/  is in pg \n5 for  each edge .u;v/  in p \n6 if .u;v/  2 G:  E \n7 .u;v/:  f D .u;v/:  f C c f .p/  \n8 else  .v;u/:  f D .v;u/:  f \ue003 c f .p/  \n9 return  f \nThe FORD-FULKERSON  procedure simply expands on the F ORD-FULKERSON- \nMETHOD  pseudocode  given  earlier.  Figure  24.6  shows  the  result  of each iteration \nin a sample  run.  Lines  132  initialize  the  \u00fcow  f to 0. The while  loop  of lines  338  \nrepeatedly  \u00fbnds  an augmenting  path  p in G f and  augments  \u00fcow  f along p by \nthe residual capacity c f .p/. Each residual edge in path p is either an edge in the \noriginal network or the reversal of an edge in the original network.  Lines  638  \nupdate  the  \u00fcow  in each  case  appropriately,  adding  \u00fcow  when  the residual edge is \nan original edge and subtracting it otherwise. When  no augmenting paths exist, the \n\u00fcow  f is a maximum  \u00fcow.  \nAnalysis  of Ford-Fulkerson  \nThe running time of F ORD-FULKERSON  depends on the augmenting path p and \nhow  it\u2019s  found  in line  3. If the  edge  capacities  are  irrational  numbers,  it\u2019s  possible  \nto choose the augmenting path so that the algorithm  never terminates: the value \nof the  \u00fcow  increases  with  successive  augmentations,  but  never converges to the \nmaximum  \u00fcow  value.  The  good  news  is that  if the  algorithm  \u00fbnds  the augmenting \npath  by  using  a breadth-\u00fbrst  search  (which  we  saw  in Section  20.2), it runs in \n1 Recall  from  Section  20.1  that  we  represent  an  attribute  f for edge .u;v/  with the same style of \nnotation4.u;v/:  f 4that  we  use  for  an  attribute  of any  other  object.  24.2  The  Ford-Fulkerson  method  687 \n12 \n4 \n4 4/4  4 \n4 16 4 s t 16 12  \n20 7 \n9 4 \n13 \n14  4 s t 4/16 4/12  \n20 7 \n4/9 \n13 \n4/14  4/4 \ns t \n7 \n5 4 \n4 8 \n4 \n13 20 \ns t 4/16 8/12  \n4/20\n 7 \n4/9 \n4/13\n \n4/14  4/4 \n4 10  s t \n7 \n5 8 \n4 4 \n9 s t 8/16 8/12  \n8/20\n 7 \n9 \n4/13\n \n4/14  4/4 (b) (a) \n(c) 12 \n4 4 4 4 \n4 10  \n4 \n12 \n2 \n11 2 \n11 8 \n8 9 \n4 \n4 9 8 4 4 \n9 8 s t 12 7 \n4 4 s t 8/16 8/12  15/20\n 7/7  \n9 \n11/13\n \n11/14  4/4 10  \n19 s t 12  \n1 7 \n11  4 (d) \n(f) \n4 \n9 8 4 4 15 s t 5 7 \n11  4 s t 12/16 12/12  19/20\n 7/7  \n9 \n11/13\n \n11/14  4/4 (e) \n4 8 \n8 \n3 \n3 v 1 v 1 v 1 v 1 v 1 v 1 v 1 v 1 v 1 v 1 v 1 \nv 2 v 2 v 2 v 2 v 2 v 2 v 2 v 2 v 2 v 2 v 2 \nv 3 v 3 v 3 v 3 v 3 v 3 v 3 v 3 v 3 v 3 v 3 \nv 4 v 4 v 4 v 4 v 4 v 4 v 4 v 4 v 4 v 4 v 4 \nFigure  24.6  The  execution  of the  basic  Ford-Fulkerson  algorithm.  (a)\u2013(e)  Successive iterations of \nthe while  loop. The left side of each part shows the residual  network G f from  line  3 with  a blue  \naugmenting path p. The  right  side  of each  part  shows  the  new  \u00fcow  f that results from augmenting f \nby f p . The  residual  network  in (a)  is the  input  \u00fcow  network  G. (f)  The residual network at the last \nwhile  loop  test.  It has  no  augmenting  paths,  and  the  \u00fcow  f shown in (e) is therefore a maximum \n\u00fcow.  The  value  of the  maximum  \u00fcow  found  is 23. 688  Chapter  24  Maximum  Flow  \n1 999,999 \n999,999 \n1 s t 1,000,000 1,000,000\n 1 \n1,000,000\n 1,000,000 999,999 \n1 1 999,999 u \ns t 1,000,000\n 1 \n1,000,000\n u \n999,999 \n1 999,999 \n1 \ns t \n1 u \n(a) (b) (c) v v v \nFigure  24.7  (a)  A \u00fcow  network  for  which  FORD-FULKERSON  can take \u201a.E  jf \ue003 j/ time, where \nf \ue003 is a maximum  \u00fcow,  shown  here  with  jf \ue003 j D  2,000,000. The blue path is an augmenting path \nwith residual capacity 1. (b)  The resulting residual network, with another augmen ting path whose \nresidual capacity is 1. (c)  The resulting residual network. \npolynomial time. Before proving this result, we obt ain a simple bound for the case \nin which  all  capacities  are  integers  and  the  algorithm  \u00fbnds  any augmenting path. \nIn practice,  the  maximum-\u00fcow  problem  often  arises  with  integer capacities. If \nthe capacities are rational numbers, an appropriate  scaling transformation can make \nthem all integers. If f \ue003 denotes  a maximum  \u00fcow  in the  transformed  network,  then  \na straightforward implementation of F ORD-FULKERSON  executes the while  loop \nof lines  338  at most  jf \ue003 j times,  since  the  \u00fcow  value  increases  by  at least  1 unit in \neach iteration. \nA good implementation should perform the work done within the while  loop \nef\u00fbciently.  It should  represent  the  \u00fcow  network  G D .V;E/  with the right data \nstructure  and  \u00fbnd  an augmenting  path  by  a linear-time  algorithm.  Let\u2019s  assume  \nthat the implementation keeps a data structure corr esponding to a directed graph \nG 0 D .V;E  0 /, where E 0 D f.u;v/  W .u;v/  2 E or .v;u/  2 Eg. Edges  in the  net-  \nwork G are also edges in G 0 , making it straightforward to maintain capacities and \n\u00fcows  in this  data  structure.  Given  a \u00fcow  f on G, the  edges  in the  residual  net-  \nwork G f consist of all edges .u;v/  of G 0 such that c f .u;v/ > 0 , where c f con-  \nforms  to equation  (24.2).  The  time  to \u00fbnd  a path  in a residual  network  is there-  \nfore O.V  C E 0 / D O.E/  using  either  depth-\u00fbrst  search  or breadth-\u00fbrst  search.  \nEach iteration of the while  loop thus takes O.E/  time, as does the initialization \nin lines  132,  making  the  total  running  time  of the  FORD-FULKERSON  algorithm \nO.E  jf \ue003 j/. \nWhen  the  capacities  are  integers  and  the  optimal  \u00fcow  value  jf \ue003 j is small, the \nrunning  time  of the  Ford-Fulkerson  algorithm  is good.  Figure  24.7(a)  shows  an ex-  \nample  of what  can  happen  on  a simple  \u00fcow  network  for  which  jf \ue003 j is large.  A max-  \nimum  \u00fcow  in this  network  has  value  2,000,000:  1,000,000  units  of \u00fcow  traverse  \nthe path s !  u !  t , and  another  1,000,000  units  traverse  the  path  s !  v !  t . If \nthe  \u00fbrst  augmenting  path  found  by  FORD-FULKERSON  is s !  u !  v !  t , shown 24.2  The  Ford-Fulkerson  method  689 \nin Figure  24.7(a),  the  \u00fcow  has  value  1 after  the  \u00fbrst  iteration.  The  resulting  resid-  \nual  network  appears  in Figure  24.7(b).  If the  second  iteration  \u00fbnds  the  augment-  \ning path s !  v !  u !  t , as shown  in Figure  24.7(b),  the  \u00fcow  then  has  value  2. \nFigure  24.7(c)  shows  the  resulting  residual  network.  If the  algorithm  continues  al-  \nternately choosing the augmenting paths s !  u !  v !  t and s !  v !  u !  t , it \nperforms a total of 2,000,000 augmentations, increa sing the \u00fcow  value  by  only  1 \nunit in each. \nThe  Edmonds-Karp  algorithm  \nIn the  example  of Figure  24.7,  the  algorithm  never  chooses  the augmenting path \nwith  the  fewest  edges.  It should  have.  By  using  breadth-\u00fbrst  search  to \u00fbnd  an \naugmenting path in the residual network, the algori thm runs in polynomial time, \nindependent  of the  maximum  \u00fcow  value.  We  call  the  Ford-Fulke rson method so \nimplemented the Edmonds-Karp  algorithm . \nLet\u2019s  now  prove  that  the  Edmonds-Karp  algorithm  runs  in O.VE  2 / time. The \nanalysis depends on the distances to vertices in th e residual network G f . The \nnotation \u0131 f .u;v/  denotes  the  shortest-path  distance  from  u to v in G f , where each \nedge has unit distance. \nLemma  24.7  \nIf the  Edmonds-Karp  algorithm  is run  on  a \u00fcow  network  G D .V;E/  with source s \nand sink t , then for all vertices v 2 V \ue003 fs;t  g, the  shortest-path  distance  \u0131 f .s;v/  \nin the residual network G f increases  monotonically  with  each  \u00fcow  augmentation.  \nProof  We\u2019ll  suppose  that  a \u00fcow  augmentation  occurs  that  causes  the  shortest-  \npath distance from s to some vertex v 2 V \ue003 fs;t  g to decrease and then derive a \ncontradiction. Let f be the  \u00fcow  just  before  an augmentation  that  decreases  some  \nshortest-path  distance,  and  let  f 0 be the  \u00fcow  just  afterward.  Let  v be a vertex with \nthe minimum \u0131 f 0 .s;v/  whose distance was decreased by the augmentation, s o that \n\u0131 f 0 .s;v/<\u0131  f .s;v/ . Let p D s \u2740  u !  v be a shortest path from s to v in G f 0 , so \nthat .u;v/  2 E f 0 and \n\u0131 f 0 .s;u/  D \u0131 f 0 .s;v/  \ue003 1:  (24.11)  \nBecause of how we chose v, we know that the distance of vertex u from the source s \ndid not decrease, that is, \n\u0131 f 0 .s;u/  \ue004 \u0131 f .s;u/:  (24.12)  \nWe claim that .u;v/  62 E f . Why?  If we  have  .u;v/  2 E f , then we also have 690  Chapter  24  Maximum  Flow  \n\u0131 f .s;v/  \u0dc4 \u0131 f .s;u/  C 1 (by  Lemma  22.10,  the  triangle  inequality)  \n\u0dc4 \u0131 f 0 .s;u/  C 1 (by  inequality  (24.12))  \nD \u0131 f 0 .s;v/  (by  equation  (24.11))  , \nwhich contradicts our assumption that \u0131 f 0 .s;v/<\u0131  f .s;v/ . \nHow can we have .u;v/  \u2026 E f and .u;v/  2 E f 0 ? The  augmentation  must  have  \nincreased  the  \u00fcow  from  v to u, so that edge .v;u/  was in the augmenting path. The \naugmenting path was a shortest path from s to t in G f , and since any subpath of a \nshortest path is itself a shortest path, this augme nting path includes a shortest path \nfrom s to u in G f that has .v;u/  as its last edge. Therefore, \n\u0131 f .s;v/  D \u0131 f .s;u/  \ue003 1 \n\u0dc4 \u0131 f 0 .s;u/  \ue003 1 (by  inequality  (24.12))  \nD \u0131 f 0 .s;v/  \ue003 2 (by  equation  (24.11))  , \nso that \u0131 f 0 .s;v/>\u0131  f .s;v/ , contradicting our assumption that \u0131 f 0 .s;v/<\u0131  f .s;v/ . \nWe conclude that our assumption that such a vertex v exists is incorrect. \nThe next theorem bounds the number of iterations of  the Edmonds-Karp  algo-  \nrithm. \nTheorem  24.8  \nIf the  Edmonds-Karp  algorithm  is run  on  a \u00fcow  network  G D .V;E/  with source s \nand sink t , then  the  total  number  of \u00fcow  augmentations  performed  by  the  algorithm \nis O.VE/ . \nProof  We say that an edge .u;v/  in a residual network G f is critical  on  an aug-  \nmenting path p if the residual capacity of p is the residual capacity of .u;v/ , that \nis, if c f .p/  D c f .u;v/. After  \u00fcow  is augmented  along  an augmenting  path,  any  \ncritical edge on the path disappears from the resid ual network. Moreover, at least \none  edge  on  any  augmenting  path  must  be critical.  We\u2019ll  show  that each of the jEj \nedges can become critical at most jV j =2  times. \nLet u and v be vertices in V that are connected by an edge in E. Since  augment-  \ning paths are shortest paths, when .u;v/  is critical  for  the  \u00fbrst  time,  we  have  \n\u0131 f .s;v/  D \u0131 f .s;u/  C 1:  \nOnce  the  \u00fcow  is augmented,  the  edge  .u;v/  disappears from the residual network. \nIt cannot reappear later on another augmenting path  until after  the  \u00fcow  from  u to v \nis decreased, which occurs only if .v;u/  appears on an augmenting path. If f 0 is \nthe  \u00fcow  in G when this event occurs, then we have \n\u0131 f 0 .s;u/  D \u0131 f 0 .s;v/  C 1:  24.2  The  Ford-Fulkerson  method  691 \nSince \u0131 f .s;v/  \u0dc4 \u0131 f 0 .s;v/  by  Lemma  24.7,  we  have  \n\u0131 f 0 .s;u/  D \u0131 f 0 .s;v/  C 1 \n\ue004 \u0131 f .s;v/  C 1 \nD \u0131 f .s;u/  C 2:  \nConsequently, from the time .u;v/  becomes critical to the time when it next \nbecomes critical, the distance of u from the source increases by at least 2. The \ndistance of u from the source is initially at least 0. Because edge .u;v/  is on an \naugmenting path, and augmenting paths end at t , we know that u cannot be t , so \nthat in any residual network that has a path from s to u, the shortest such path has \nat most jV j \ue003  2 edges.  Thus,  after  the  \u00fbrst  time  that  .u;v/  becomes critical, it can \nbecome critical at most .jV j \ue003  2/=2  D jV j =2  \ue003 1 times more, for a total of at \nmost jV j =2  times. Since there are O.E/  pairs of vertices that can have an edge \nbetween them in a residual network, the total numbe r of critical edges during the \nentire  execution  of the  Edmonds-Karp  algorithm  is O.VE/ . Each augmenting path \nhas at least one critical edge, and hence the theor em follows. \nBecause each iteration of F ORD-FULKERSON  takes O.E/  time when it uses \nbreadth-\u00fbrst  search  to \u00fbnd  the  augmenting  path,  the  total  running time of the \nEdmonds-Karp  algorithm  is O.VE  2 /. \nExercises  \n24.2-1  \nProve  that  the  summations  in equation  (24.6)  equal  the  summations  on  the  right-  \nhand  side  of equation  (24.5).  \n24.2-2  \nIn Figure  24.1(b),  what  is the  net  \u00fcow  across  the  cut  .fs;v  2 ;v  4 g ; fv 1 ;v  3 ;t g/? What  \nis the  capacity  of this  cut?  \n24.2-3  \nShow  the  execution  of the  Edmonds-Karp  algorithm  on  the  \u00fcow  network  of Fig-  \nure  24.1(a).  \n24.2-4  \nIn the  example  of Figure  24.6,  what  is the  minimum  cut  corresponding  to the  max-  \nimum  \u00fcow  shown?  Of  the  augmenting  paths  appearing  in the  exam ple, which one \ncancels  \u00fcow?  692  Chapter  24  Maximum  Flow  \n24.2-5  \nThe  construction  in Section  24.1  to convert  a \u00fcow  network  with multiple sources \nand  sinks  into  a single-source,  single-sink  network  adds  edges  with  in\u00fbnite  capac-  \nity.  Prove  that  any  \u00fcow  in the  resulting  network  has  a \u00fbnite  value if the edges of \nthe  original  network  with  multiple  sources  and  sinks  have  \u00fbnite capacity. \n24.2-6  \nSuppose that each source s i in a \u00fcow  network  with  multiple  sources  and  sinks  \nproduces exactly p i units  of \u00fcow,  so that  P  \nv2V f.s  i ;v/  D p i . Suppose also \nthat each sink t j consumes exactly q j units, so that P  \nv2V f.v;t  j / D q j , where P  \ni p i D P  \nj q j . Show  how  to convert  the  problem  of \u00fbnding  a \u00fcow  f that obeys \nthese  additional  constraints  into  the  problem  of \u00fbnding  a maximum  \u00fcow  in a single-  \nsource,  single-sink  \u00fcow  network.  \n24.2-7  \nProve  Lemma  24.2.  \n24.2-8  \nSuppose  that  we  rede\u00fbne  the  residual  network  to disallow  edges into s . Argue that \nthe procedure F ORD-FULKERSON  still  correctly  computes  a maximum  \u00fcow.  \n24.2-9  \nSuppose that both f and f 0 are  \u00fcows  in a \u00fcow  network.  Does  the  augmented  \n\u00fcow  f \" f 0 satisfy  the  \u00fcow  conservation  property?  Does  it satisfy  the  capacity \nconstraint?  \n24.2-10  \nShow  how  to \u00fbnd  a maximum  \u00fcow  in a \u00fcow  network  G D .V;E/  by a sequence \nof at most jEj augmenting paths. ( Hint: Determine the paths after \u00fbnding  the  \nmaximum  \u00fcow.)  \n24.2-11  \nThe edge  connectivity  of an undirected graph is the minimum number k of edges \nthat must be removed to disconnect the graph. For e xample, the edge connectivity \nof a tree is 1, and the edge connectivity of a cyclic chain of ve rtices is 2. Show how \nto determine the edge connectivity of an undirected  graph G D .V;E/  by running \na maximum-\u00fcow  algorithm  on  at most  jV j \u00fcow  networks,  each  having  O.V  C E/  \nvertices and O.E/  edges. \n24.2-12  \nYou  are  given  a \u00fcow  network  G, where G contains edges entering the source s . \nLet f be a \u00fcow  in G with jf j \ue004  0 in which one of the edges .v;s/  entering 24.3  Maximum  bipartite  matching  693 \nthe source has f.v;s/  D 1. Prove  that  there  must  exist  another  \u00fcow  f 0 with \nf 0 .v;s/  D 0 such that jf j D jf 0 j. Give  an O.E/-time  algorithm  to compute  f 0 , \ngiven f and assuming that all edge capacities are integers.  \n24.2-13  \nSuppose  that  you  wish  to \u00fbnd,  among  all  minimum  cuts  in a \u00fcow  network G with \ninteger capacities, one that contains the smallest number of edges. Show how to \nmodify the capacities of G to create  a new  \u00fcow  network  G 0 in which any minimum \ncut in G 0 is a minimum cut with the smallest number of edges in G. \n24.3  Maximum  bipartite  matching  \nSome  combinatorial  problems  can  be cast  as maximum-\u00fcow  prob lems, such as the \nmultiple-source,  multiple-sink  maximum-\u00fcow  problem  from  Section  24.1.  Other  \ncombinatorial problems seem on the surface to have little to do  with  \u00fcow  networks,  \nbut  they  can  in fact  be reduced  to maximum-\u00fcow  problems.  This  section presents \none  such  problem:  \u00fbnding  a maximum  matching  in a bipartite  graph. In order to \nsolve  this  problem,  we\u2019ll  take  advantage  of an integrality  property provided by the \nFord-Fulkerson  method.  We\u2019ll  also  see  how  to use  the  Ford-Fu lkerson method to \nsolve  the  maximum-bipartite-matching  problem  on  a graph  G D .V;E/  in O.VE/  \ntime.  Section  25.1  will  present  an algorithm  speci\u00fbcally  designed to solve this \nproblem. \nThe  maximum-bipartite-matching  problem  \nGiven  an undirected  graph  G D .V;E/ , a matching  is a subset of edges M  \u0dc2 E \nsuch that for all vertices v 2 V , at most one edge of M  is incident on v. We say \nthat a vertex v 2 V is matched  by the matching M  if some edge in M  is incident \non v, and otherwise, v is unmatched . A maximum  matching  is a matching of \nmaximum cardinality, that is, a matching M  such that for any matching M  0 , we \nhave jM  j \ue004 jM  0 j. In this  section,  we  restrict  our  attention  to \u00fbnding  maximu m \nmatchings in bipartite graphs: graphs in which the vertex set can be partitioned \ninto V D L [ R, where L and R are disjoint and all edges in E go between L \nand R. We further assume that every vertex in V has at least one incident edge. \nFigure  24.8  illustrates  the  notion  of a matching  in a biparti te graph. \nThe  problem  of \u00fbnding  a maximum  matching  in a bipartite  graph  has many \npractical applications. As an example, consider mat ching a set L of machines with \na set R of tasks to be performed simultaneously. An edge .u;v/  in E signi\u00fbes  that  694  Chapter  24  Maximum  Flow  \nL R L R s t \n(a) (c) L R \n(b) \nFigure  24.8  A bipartite graph G D .V;E/  with vertex partition V D L [ R. (a)  A matching \nwith cardinality 2, indicated by blue edges. (b)  A maximum matching with cardinality 3. (c)  The \ncorresponding  \u00fcow  network  G 0 with  a maximum  \u00fcow  shown.  Each  edge  has  unit  capacity.  Blue  \nedges  have  a \u00fcow  of 1, and  all  other  edges  carry  no  \u00fcow.  The  blue  edges  from  L to R correspond to \nthose in the maximum matching from (b). \na particular machine u 2 L is capable of performing a particular task v 2 R. A \nmaximum matching provides work for as many machines  as possible. \nFinding  a maximum  bipartite  matching  \nThe  Ford-Fulkerson  method  provides  a basis  for  \u00fbnding  a maxi mum matching in \nan undirected bipartite graph G D .V;E/  in time polynomial in jV j and jEj. \nThe  trick  is to construct  a \u00fcow  network  in which  \u00fcows  correspo nd to matchings, as \nshown  in Figure  24.8(c).  We  de\u00fbne  the  corresponding  \u00fcow  network  G 0 D .V  0 ;E  0 / \nfor the bipartite graph G as follows. Let the source s and sink t be new vertices \nnot in V , and let V 0 D V [ fs;t  g. If the vertex partition of G is V D L [ R, the \ndirected edges of G 0 are the edges of E, directed from L to R, along with jV j new \ndirected edges: \nE 0 D f.s;u/  W u 2 Lg \n[ f.u;v/  W u 2 L;v  2 R;  and .u;v/  2 Eg \n[ f.v;t/  W v 2 Rg : \nTo complete the construction, assign unit capacity to each edge in E 0 . Since each \nvertex in V has at least one incident edge, jEj \ue004 jV j =2. Thus, jEj \u0dc4 jE 0 j D  \njEj C jV j \u0dc4  3 jEj, and so jE 0 j D  \u201a.E/ . 24.3  Maximum  bipartite  matching  695 \nThe following lemma shows that a matching in G corresponds  directly  to a \u00fcow  \nin G\u2019s corresponding  \u00fcow  network  G 0 . We  say  that  a \u00fcow  f on  a \u00fcow  network  \nG D .V;E/  is integer-valued  if f.u;v/  is an integer for all .u;v/  2 V \ue005 V . \nLemma  24.9  \nLet G D .V;E/  be a bipartite graph with vertex partition V D L [ R, and let \nG 0 D .V  0 ;E  0 / be its  corresponding  \u00fcow  network.  If M  is a matching in G, then \nthere  is an integer-valued  \u00fcow  f in G 0 with value jf j D jM  j. Conversely, if f \nis an integer-valued  \u00fcow  in G 0 , then there is a matching M  in G with cardinality \njM  j D jf j consisting of edges .u;v/  2 E such that f.u;v/>0 . \nProof  We  \u00fbrst  show  that  a matching  M  in G corresponds  to an integer-valued  \n\u00fcow  f in G 0 . De\u00fbne  f as follows. If .u;v/  2 M  , then f.s;u/  D f.u;v/  D \nf.v;t/  D 1. For all other edges .u;v/  2 E 0 , de\u00fbne  f.u;v/  D 0. It is simple to \nverify that f satis\u00fbes  the  capacity  constraint  and  \u00fcow  conservation.  \nIntuitively, each edge .u;v/  2 M  corresponds to 1 unit  of \u00fcow  in G 0 that  tra-  \nverses the path s !  u !  v !  t . Moreover, the paths induced by edges in M  are \nvertex-disjoint,  except  for  s and t . The  net  \u00fcow  across  cut  .L  [ fs g ;R  [ ft g/ is \nequal to jM  j, and  thus,  by  Lemma  24.4,  the  value  of the  \u00fcow  is jf j D jM  j. \nTo prove the converse, let f be an integer-valued  \u00fcow  in G 0 and,  as in the  state-  \nment of the lemma, let \nM  D f.u;v/  W u 2 L;v  2 R;  and f.u;v/>0 g : \nEach vertex u 2 L has only one entering edge, namely .s;u/ , and its capacity \nis 1. Thus, each u 2 L has at most 1 unit  of \u00fcow  entering  it, and  if 1 unit  of \u00fcow  \ndoes  enter,  by  \u00fcow  conservation,  1 unit  of \u00fcow  must  leave.  Furthermore,  since  the  \n\u00fcow  f is integer-valued,  for  each  u 2 L, the 1 unit  of \u00fcow  can  enter  on  at most  \none edge and can leave on at most one edge. Thus, 1 unit  of \u00fcow  enters  u if and \nonly if there is exactly one vertex v 2 R such that f.u;v/  D 1, and at most one \nedge leaving each u 2 L carries  positive  \u00fcow.  A symmetric  argument  applies  to \neach v 2 R. The set M  is therefore a matching. \nTo see that jM  j D jf j, observe that of the edges .u;v/  2 E 0 such that u 2 L \nand v 2 R, \nf.u;v/  D ( \n1 if .u;v/  2 M ;  \n0 if .u;v/  \u2026 M :  \nConsequently, f.L  [ fs g ;R  [ ft g/, the  net  \u00fcow  across  cut  .L  [ fs g ;R  [ ft g/, is \nequal to jM  j. Lemma  24.4  gives  that  jf j D  f.L  [ fs g ;R  [ ft g/ D jM  j. \nBased  on  Lemma  24.9,  we  would  like  to conclude  that  a maximum  matching \nin a bipartite graph G corresponds  to a maximum  \u00fcow  in its  corresponding  \u00fcow  696  Chapter  24  Maximum  Flow  \nnetwork G 0 , and  therefore  running  a maximum-\u00fcow  algorithm  on  G 0 provides a \nmaximum matching in G. The  only  hitch  in this  reasoning  is that  the  maximum-  \n\u00fcow  algorithm  might  return  a \u00fcow  in G 0 for which some f.u;v/  is not an integer, \neven  though  the  \u00fcow  value  jf j must be an integer. The following theorem shows \nthat  the  Ford-Fulkerson  method  cannot  produce  a solution  with this problem. \nTheorem  24.10  (Integrality  theorem)  \nIf the capacity function c takes  on  only  integer  values,  then  the  maximum  \u00fcow  f \nproduced  by  the  Ford-Fulkerson  method  has  the  property  that  jf j is an integer. \nMoreover, for all vertices u and v, the value of f.u;v/  is an integer. \nProof  Exercise  24.3-2  asks  you  to provide  the  proof  by  induction  on  the number \nof iterations. \nWe  can  now  prove  the  following  corollary  to Lemma  24.9.  \nCorollary  24.11  \nThe cardinality of a maximum matching M  in a bipartite graph G equals the value \nof a maximum  \u00fcow  f in its  corresponding  \u00fcow  network  G 0 . \nProof  We  use  the  nomenclature  from  Lemma  24.9.  Suppose  that  M  is a max-  \nimum matching in G and  that  the  corresponding  \u00fcow  f in G 0 is not maximum. \nThen  there  is a maximum  \u00fcow  f 0 in G 0 such that jf 0 j > jf j. Since  the  ca-  \npacities in G 0 are  integer-valued,  by  Theorem  24.10,  we  can  assume  that  f 0 is \ninteger-valued.  Thus,  f 0 corresponds to a matching M  0 in G with cardinality \njM  0 j D jf 0 j > jf j D jM  j, contradicting our assumption that M  is a maximum \nmatching. In a similar manner, we can show that if f is a maximum  \u00fcow  in G 0 , its \ncorresponding matching is a maximum matching on G. \nThus,  to \u00fbnd  a maximum  matching  in a bipartite  undirected  graph G, create the \n\u00fcow  network  G 0 , run  the  Ford-Fulkerson  method  on  G 0 , and  convert  the  integer-  \nvalued  maximum  \u00fcow  found  into  a maximum  matching  for  G. Since any matching \nin a bipartite graph has cardinality at most min fjLj ; jRjg D  O.V/ , the value of \nthe  maximum  \u00fcow  in G 0 is O.V/. Therefore,  \u00fbnding  a maximum  matching  in a \nbipartite graph takes O.VE  0 / D O.VE/  time, since jE 0 j D  \u201a.E/ . \nExercises  \n24.3-1  \nRun  the  Ford-Fulkerson  algorithm  on  the  \u00fcow  network  in Figure  24.8(c)  and  show  \nthe  residual  network  after  each  \u00fcow  augmentation.  Number  the vertices in L top Problems for Chapter 24 697 \nto bottom from 1 to 5 and in R top to bottom from 6 to 9. For each iteration, pick \nthe augmenting path that is lexicographically small est. \n24.3-2  \nProve  Theorem  24.10.  Use  induction  on  the  number  of iterations  of the  Ford-  \nFulkerson method. \n24.3-3  \nLet G D .V;E/  be a bipartite graph with vertex partition V D L [ R, and let G 0 \nbe its  corresponding  \u00fcow  network.  Give  a good  upper  bound  on  the length of any \naugmenting path found in G 0 during the execution of F ORD-FULKERSON . \nProblems  \n24-1  Escape  problem  \nAn n\ue005n grid  is an undirected graph consisting of n rows and n columns of vertices, \nas shown  in Figure  24.9.  We  denote  the  vertex  in the  i th row and the j th column \nby .i;j/ . All vertices in a grid have exactly four neighbor s, except for the boundary \nvertices, which are the points .i;j/  for which i D 1, i D n, j D 1, or j D n. \nGiven  m \u0dc4 n 2 starting points .x 1 ;y  1 /;.x  2 ;y  2 /;:::;.x  m ;y  m / in the grid, the \nescape  problem  is to determine whether there are m vertex-disjoint  paths  from  the  \nstarting points to any m different points on the boundary. For example, the grid in \nFigure  24.9(a)  has  an escape,  but  the  grid  in Figure  24.9(b)  does not. \n(a) (b) \nFigure  24.9  Grids  for  the  escape  problem.  Starting  points  are  blue,  and  other grid vertices are tan. \n(a)  A grid with an escape, shown by blue paths. (b)  A grid with no escape. 698  Chapter  24  Maximum  Flow  \na. Consider  a \u00fcow  network  in which  vertices,  as well  as edges,  have capacities. \nThat  is, the  total  positive  \u00fcow  entering  any  given  vertex  is subject to a capacity \nconstraint. Show how to reduce the problem of deter mining the maximum  \u00fcow  \nin a network with edge and vertex capacities to an ordinary ma ximum-\u00fcow  \nproblem  on  a \u00fcow  network  of comparable  size.  \nb. Describe  an ef\u00fbcient  algorithm  to solve  the  escape  problem,  and analyze its \nrunning time. \n24-2  Minimum  path  cover  \nA path  cover  of a directed graph G D .V;E/  is a set P of vertex-disjoint  paths  \nsuch that every vertex in V is included in exactly one path in P . Paths may start \nand end anywhere, and they may be of any length, in cluding 0. A minimum  path  \ncover  of G is a path cover containing the fewest possible path s. \na. Give  an ef\u00fbcient  algorithm  to \u00fbnd  a minimum  path  cover  of a directed acyclic \ngraph G D .V;E/ . (Hint: Assuming that V D f1;2;:::;n g, construct  a \u00fcow  \nnetwork based on the graph G 0 D .V  0 ;E  0 /, where \nV 0 D fx 0 ;x  1 ;:::;x  n g [ fy 0 ;y  1 ;:::;y  n g ; \nE 0 D f.x 0 ;x  i / W i 2 V g [ f.y i ;y  0 / W i 2 V g [ f.x i ;y  j / W .i;j/  2 Eg ; \nand  run  a maximum-\u00fcow  algorithm.)  \nb. Does your algorithm work for directed graphs that c ontain cycles?  Explain.  \n24-3  Hiring  consulting  experts  \nProfessor Fieri wants to open a consulting company for the food industry. He \nhas  identi\u00fbed  n important food categories, which he represents by t he set C D \nfC 1 ;C  2 ;:::;C  n g. In each category C k , he can hire an expert in that category for \ne k >0  dollars. The consulting company has lined up a set J D fJ 1 ;J  2 ;:::;J  m g \nof potential jobs. In order to perform job J i , the company needs to have hired \nexperts in a subset R i \u0dc2 C of categories. Each expert can work on multiple job s \nsimultaneously. If the company chooses to accept jo b J i , it must have hired experts \nin all categories in R i , and it takes in revenue of p i >0  dollars. \nProfessor  Fieri\u2019s  job  is to determine  which  categories  to hire experts in and \nwhich jobs to accept in order to maximize the net r evenue, which is the total income \nfrom jobs accepted minus the total cost of employin g the experts. \nConsider  the  following  \u00fcow  network  G. It contains a source vertex s , vertices \nC 1 ;C  2 ;:::;C  n , vertices J 1 ;J  2 ;:::;J  m , and a sink vertex t . For k D 1;2:::;n , \nthe  \u00fcow  network  contains  an edge  .s;C  k / with capacity c.s;C  k / D e k , and \nfor i D 1;2;:::;m, the  \u00fcow  network  contains  an edge  .J i ;t/  with capacity Problems for Chapter 24 699 \nc.J  i ;t/  D p i . For k D 1;2;:::;n  and i D 1;2;:::;m , if C k 2 R i , then G \ncontains an edge .C  k ;J  i / with capacity c.C  k ;J  i / D 1 . \na. Show that if J i 2 T for  a \u00fbnite-capacity  cut  .S;T/  of G, then C k 2 T for \neach C k 2 R i . \nb. Show how to determine the maximum net revenue from the capacity of a mini-  \nmum cut of G and the given p i values. \nc. Give  an ef\u00fbcient  algorithm  to determine  which  jobs  to accept  and which experts \nto hire. Analyze the running time of your algorithm  in terms of m, n, and \nr D P  m \ni D1 jR i j. \n24-4  Updating  maximum  \u00fcow  \nLet G D .V;E/  be a \u00fcow  network  with  source  s , sink t , and integer capacities. \nSuppose  that  you  are  given  a maximum  \u00fcow  in G. \na. Suppose that the capacity of a single edge .u;v/  2 E increases by 1. Give  an \nO.V  C E/-time  algorithm  to update  the  maximum  \u00fcow.  \nb. Suppose that the capacity of a single edge .u;v/  2 E decreases by 1. Give  an \nO.V  C E/-time  algorithm  to update  the  maximum  \u00fcow.  \n24-5  Maximum  \u00fcow  by scaling  \nLet G D .V;E/  be a \u00fcow  network  with  source  s , sink t , and  an integer  capac-  \nity c.u;v/  on each edge .u;v/  2 E. Let C D max fc.u;v/  W .u;v/  2 Eg. \na. Argue that a minimum cut of G has capacity at most C jEj. \nb. For a given number K, show  how  to \u00fbnd  an augmenting  path  of capacity  at \nleast K in O.E/  time, if such a path exists. \nThe procedure M AX-FLOW-BY-SCALING  appearing  on  the  following  page  mod-  \ni\u00fbes  the  basic  FORD-FULKERSON-METHOD  procedure to compute a maximum \n\u00fcow  in G. \nc. Argue that M AX-FLOW-BY-SCALING  returns  a maximum  \u00fcow.  \nd. Show that the capacity of a minimum cut of the resi dual network G f is less \nthan 2K  jEj each  time  line  4 executes.  \ne. Argue that the inner while  loop  of lines  536  executes  O.E/  times for each value \nof K. 700  Chapter  24  Maximum  Flow  \nMAX-FLOW-BY-SCALING  .G;s;t/  \n1 C D max fc.u;v/  W .u;v/  2 Eg \n2 initialize  \u00fcow  f to 0 \n3 K D 2 blg C c \n4 while  K \ue004 1 \n5 while  there exists an augmenting path p of capacity at least K \n6 augment  \u00fcow  f along p \n7 K D K=2  \n8 return  f \nf. Conclude that M AX-FLOW-BY-SCALING  can be implemented so that it runs \nin O.E  2 lg C/  time. \n24-6  Widest  augmenting  path  \nThe  Edmonds-Karp  algorithm  implements  the  Ford-Fulkerson  algorithm by always \nchoosing a shortest augmenting path in the residual  network. Suppose instead that \nthe  Ford-Fulkerson  algorithm  chooses  a widest  augmenting  path: an augmenting \npath with the greatest residual capacity. Assume th at G D .V;E/  is a \u00fcow  network  \nwith source s and sink t , that all capacities are integer, and that the lar gest capacity \nis C . In this problem, you will show that choosing a wi dest augmenting path results \nin at most jEj ln jf \ue003 j augmentations  to \u00fbnd  a maximum  \u00fcow  f \ue003 . \na. Show  how  to adjust  Dijkstra\u2019s  algorithm  to \u00fbnd  the  widest  augmenting path in \nthe residual network. \nb. Show  that  a maximum  \u00fcow  in G can  be formed  by  successive  \u00fcow  augmenta-  \ntions along at most jEj paths from s to t . \nc. Given  a \u00fcow  f , argue that the residual network G f has an augmenting path p \nwith residual capacity c f .p/  \ue004 .jf \ue003 j \ue003 jf j/= jEj. \nd. Assuming that each augmenting path is a widest augm enting path, let f i be \nthe  \u00fcow  after  augmenting  the  \u00fcow  by  the  i th augmenting path, where f 0 has \nf.u;v/  D 0 for all edges .u;v/ . Show that jf \ue003 j \ue003 jf i j \u0dc4 jf \ue003 j .1 \ue003 1=  jEj/ i . \ne. Show that jf \ue003 j \ue003 jf i j < jf \ue003 j e \ue002i=jEj . \nf. Conclude  that  after  the  \u00fcow  is augmented  at most  jEj ln jf \ue003 j times,  the  \u00fcow  is \na maximum  \u00fcow.  Problems for Chapter 24 701 \n24-7  Global  minimum  cut  \nA global  cut  in an undirected graph G D .V;E/  is a partition  (see  page  1156)  of V \ninto two nonempty sets V 1 and V 2 . This  de\u00fbnition  is like  the  de\u00fbnition  of cut  that  \nwe have used in this chapter, except that we no lon ger have distinguished vertices \ns and t . Any edge .u;v/  with u 2 V 1 and v 2 V 2 is said to cross  the cut. \nWe  can  extend  this  de\u00fbnition  of a cut  to a multigraph  G D .V;E/  (see \npage  1167),  and  we  denote  by  c.u;v/  the number of edges in the multigraph with \nendpoints u and v. A global cut in a multigraph is still a partition  of the vertices, \nand the value of a global cut .V  1 ;V  2 / is c.V  1 ;V  2 / D P  \nu2V 1 ;v2V 2 c.u;v/. A so-  \nlution to the global-minimum-cut  problem  is a cut .V  1 ;V  2 / such that c.V  1 ;V  2 / \nis minimum. Let \ufffd.G/  denote the value of a global minimum cut in a graph  or \nmultigraph G. \na. Show  how  to \u00fbnd  a global  minimum  cut  of a graph  G D .V;E/  by solving \u00e3 jV j \n2 \u00e4 \nmaximum-\u00fcow  problems,  each  with  a different  pair  of vertice s as the \nsource and sink, and taking the mininum value of th e cuts found. \nb. Give  an algorithm  to \u00fbnd  a global  minimum  cut  by  solving  only  \u201a.V/  \nmaximum-\u00fcow  problems.  What  is the  running  time  of your  algorithm?  \nThe remainder of this problem develops an algorithm  for the global-minimum-  \ncut  problem  that  does  not  use  any  maximum-\u00fcow  computations.  It uses the notion \nof an edge  contraction,  de\u00fbned  on  page  1168,  with  one  crucial  difference. The \nalgorithm maintains a multigraph, so that upon cont racting an edge .u;v/ , it creates \na new vertex x , and for any other vertex y 2 V , the number of edges between x \nand y is c.u;y/  C c.v;y/. The  algorithm  does  not  maintain  self-loops,  and  so it \nsets c.x;x/  to 0. Denote by G=.u;v/  the multigraph that results from contracting \nedge .u;v/  in multigraph G. \nConsider what can happen to the minimum cut when an  edge is contracted.  As-  \nsume that, at all points, the minimum cut in a mult igraph G is unique.  We\u2019ll  remove  \nthis assumption later. \nc. Show that for any edge .u;v/ , we have \ufffd.G=.u;  v//  \u0dc4 \ufffd.G/ . Under what \nconditions is \ufffd.G=.u;  v//  < \ufffd.G/? \nNext, you will show that if you pick an edge unifor mly at random, the probability \nthat it belongs to the minimum cut is small. \nd. Show that for any multigraph G D .V;E/ , the value of the global minimum \ncut is at most the average degree of a vertex: that  \ufffd.G/  \u0dc4 2 jEj = jV j, where \njEj denotes the total number of edges in the multigraph . 702  Chapter  24  Maximum  Flow  \ne. Using the results from parts (c) and (d), show that , if we pick an edge .u;v/  \nuniformly at random, then the probability that .u;v/  belongs to the minimum \ncut is at most 2=V  . \nConsider the algorithm that repeatedly chooses an e dge at random and contracts \nit until the multigraph has exactly two vertices, s ay u and v. At that point, the \nmultigraph corresponds to a cut in the original gra ph, with vertex u representing \nall the nodes in one side of the original graph, an d v representing all the vertices \non the other side. The number of edges given by c.u;v/  corresponds exactly to the \nnumber of edges crossing the corresponding cut in t he original graph. We call this \nalgorithm the contraction  algorithm . \nf. Suppose that the contraction algorithm terminates w ith a multigraph whose \nonly vertices are u and v. Show that Pr fc.u;v/  D \ufffd.G/ g D  \ufffd \ue002 \n1=  \u00e3 jV j \n2 \u00e4 \u0dc1 \n. \ng. Prove that if the contraction algorithm repeats \u00e3 jV j \n2 \u00e4 ln jV j times,  then  the  prob-  \nability that at least one of the runs returns the m inimum cut is at least 1 \ue003 1=  jV j. \nh. Give  a detailed  implementation  of the  contraction  algorith m that runs in O.V  2 / \ntime. \ni. Combine the previous parts and remove the assumptio n that the minimum cut \nmust be unique, to conclude that running the contra ction algorithm \u00e3 jV j \n2 \u00e4 \nln jV j \ntimes yields an algorithm that runs in O.V  4 lg V/  time and returns a minimum \ncut with probability at least 1 \ue003 1=V  . \nChapter  notes  \nAhuja,  Magnanti,  and  Orlin  [7],  Even  [137],  Lawler  [276],  Papadimitriou  and  Stei-  \nglitz  [353],  Tarjan  [429],  and  Williamson  [458]  are  good  references for network \n\u00fcows  and  related  algorithms.  Schrijver  [399]  has  written  an interesting review of \nhistorical  developments  in the  \u00fbeld  of network  \u00fcows.  \nThe  Ford-Fulkerson  method  is due  to Ford  and  Fulkerson  [149] , who originated \nthe formal study of many of the problems in the are a of network \u00fcow,  including  \nthe  maximum-\u00fcow  and  bipartite-matching  problems.  Many  early implementations \nof the  Ford-Fulkerson  method  found  augmenting  paths  using  breadth-\u00fbrst  search.  \nEdmonds  and  Karp  [132],  and  independently  Dinic  [119],  proved that this strategy \nyields  a polynomial-time  algorithm.  A related  idea,  that  of using  <blocking  \u00fcows,=  \nwas  also  \u00fbrst  developed  by  Dinic  [119].  \nA class of algorithms known as push-relabel  algorithms, due  to Goldberg  [185]  \nand  Goldberg  and  Tarjan  [188],  takes  a different  approach  from  the  Ford-Fulkerson  Notes for Chapter 24 703 \nmethod.  Push-relabel  algorithms  allow  \u00fcow  conservation  to be violated at vertices \nother  than  the  source  and  sink  as they  execute.  Using  an idea  \u00fbrst developed by \nKarzonov  [251],  they  allow  a pre\u00fcow  in which  the  \u00fcow  into  a vertex  may  exceed  \nthe  \u00fcow  out  of the  vertex.  Such  a vertex  is said  to be over\u00fcowing . Initially, every \nedge  leaving  the  source  is \u00fblled  to capacity,  so that  all  neighbors of the source \nare  over\u00fcowing.  In a push-relabel  algorithm,  each  vertex  is assigned an integer \nheight.  An  over\u00fcowing  vertex  may  push  \u00fcow  to a neighboring  vertex to which it \nhas a residual edge provided that it is higher than  the neighbor. If all residual edges \nfrom  an over\u00fcowing  vertex  go  to neighbors  with  equal  or great er heights, then the \nvertex  may  increase  its  height.  Once  all  vertices  other  than  the sink are no longer \nover\u00fcowing,  the  pre\u00fcow  is not  only  a legal  \u00fcow,  but  also  a maximum  \u00fcow.  \nGoldberg  and  Tarjan  [188]  gave  an O.V  3 /-time  algorithm  that  uses  a queue  to \nmaintain  the  set  of over\u00fcowing  vertices,  as well  as an algori thm that uses dynamic \ntrees to achieve a running time of O.VE  lg.V  2 =E  C 2//. Several other researchers \ndeveloped  improved  variants  and  implementations  [9,  10,  15,  86,  87,  255,  358],  \nthe  fastest  of which,  by  King,  Rao,  and  Tarjan  [255],  runs  in O.VE  log E=.V  lg V /  V/  \ntime. \nAnother  ef\u00fbcient  algorithm  for  maximum  \u00fcow,  by  Goldberg  and  Rao  [187],  runs  \nin O \u00e3 \nmin \u02da \nV 2=3  ;E  1=2  \ue009 \nE lg.V  2 =E  C 2/ lg C \u00e4 \ntime, where C is the  maximum  ca-  \npacity  of any  edge.  Orlin  [350]  gave  an algorithm  in the  same  spirit  as this  algo-  \nrithm that runs in O.VE  C E 31=16  lg 2 V/  time. Combining it with the algorithm of \nKing,  Rao,  and  Tarjan  results  in an O.VE/-time  algorithm.  \nA different  approach  to maximum  \u00fcows  and  related  problems  is to use  tech-  \nniques from continuous optimization including elect rical \u00fcows  and  interior-point  \nmethods.  The  \u00fbrst  breakthrough  in this  line  of work  is due  to Madry  [308],  who  \ngave an e O.E  10=7  /-time  algorithm  for  unit-capacity  maximum  \u00fcow  and  bipartit e \nmaximum  matching.  (See  Problem  3-6  on  page  73  for  a de\u00fbnition  of e O .) There has \nbeen  a series  of papers  in this  area  for  matchings,  maximum  \u00fcows,  and  minimum-  \ncost  \u00fcows.  The  fastest  algorithm  to date  in this  line  of work  for  maximum  \u00fcow  is \ndue  to Lee  and  Sidford  [285],  taking  e O.  p \nVE  lg O.1/  C/  time. If the capacities are \nnot too large, this algorithm is faster than the O.VE/-time  algorithm  mentioned  \nabove.  Another  algorithm,  due  to Liu  and  Sidford  [303]  runs  in e O.E  11=8  C 1=4  / \ntime, where C is the maximum capacity of any edge. This algorithm  does not run \nin polynomial time, but for small enough capacities , it is faster than the previous \nones. \nIn practice,  push-relabel  algorithms  currently  dominate  algorithms  based  on  aug-  \nmenting  paths,  continuous-optimization,  and  linear  programming  for  the  maxi-  \nmum-\u00fcow  problem  [88]  . 25  Matchings  in Bipartite  Graphs  \nMany  real-world  problems  can  be modeled  as \u00fbnding  matchings  in an undirected \ngraph. For an undirected graph G D .V;E/ , a matching  is a subset of edges \nM  \u0dc2 E such that every vertex in V has at most one incident edge in M  . \nFor example, consider the following scenario. You h ave one or more positions \nto \u00fbll  and  several  candidates  to interview.  According  to your schedule, you are \nable to interview candidates at certain time slots.  You ask the candidates  to indi-  \ncate the subsets of time slots at which they are av ailable. How can you schedule \nthe interviews so that each time slot has at most o ne candidate scheduled, while \nmaximizing  the  number  of candidates  that  you  can  interview?  You can model this \nscenario as a matching problem on a bipartite graph  in which each  vertex  repre-  \nsents either a candidate or a time slot, with an ed ge between a candidate and a time \nslot if the candidate is available then. If an edge  is included in the matching, that \nmeans you are scheduling a particular candidate for  a particular time slot. Your \ngoal  is to \u00fbnd  a maximum  matching: a matching  of maximum  cardinality.  One  of \nthe authors of this book was faced with exactly thi s situation when hiring teaching \nassistants  for  a large  class.  He  used  the  Hopcroft-Karp  algorithm  in Section  25.1  \nto schedule the interviews. \nAnother application of matching is the U.S. Nationa l Resident Matching  Pro-  \ngram, in which medical students are matched to hosp itals where they  will  be sta-  \ntioned as medical residents. Each student ranks the  hospitals by preference, and \neach hospital ranks the students. The goal is to as sign students to hospitals so that \nthere is never a student and a hospital that both h ave regrets because the student was \nnot assigned to the hospital, yet each ranked the o ther higher than who or where \nthey  were  assigned.  This  scenario  is perhaps  the  best-known  real-world  example  \nof the  <stable-marriage  problem,=  which  Section  25.2  exami nes. \nYet another instance where matching comes into play  occurs when workers must \nbe assigned to tasks in order to maximize the overa ll effectiveness  of the  assign-  \nment. For each worker and each task, the worker has  some quanti\u00fbed  effectiveness  25.1  Maximum  bipartite  matching  (revisited)  705 \nfor that task. Assuming that there are equal number s of workers and tasks, the goal \nis to \u00fbnd  a matching  with  the  maximum  total  effectiveness.  Such a situation is an \nexample  of an assignment  problem,  which  Section  25.3  shows  how to solve. \nThe  algorithms  in this  chapter  \u00fbnd  matchings  in bipartite  graphs.  As  in Sec-  \ntion  24.3,  the  input  is an undirected  graph  G D .V;E/ , where V D L [ R, the \nvertex sets L and R are disjoint, and every edge in E is incident on one vertex in L \nand one vertex in R. A matching, therefore, matches vertices in L with vertices \nin R. In some applications, the sets L and R have equal cardinality, and in other \napplications they need not be the same size. \nAn undirected graph need not be bipartite for the c oncept of m atching  to ap-  \nply. Matching in general undirected graphs has appl ications in areas such as \nscheduling and computational chemistry. It models p roblems in which you want \nto pair up entities, represented by vertices. Two v ertices are adjacent  if they  rep-  \nresent  compatible  entities,  and  you  need  to \u00fbnd  a large  set  of compatible pairs. \nMaximum-matching  and  maximum-weight  matching  problems  on  general graphs \ncan  be solved  by  polynomial-time  algorithms  whose  running  times are similar to \nthose  for  bipartite  matching,  but  the  algorithms  are  signi\u00fbcantly  more  compli-  \ncated.  Exercise  25.2-5  discusses  the  general  version  of the  stable-marriage  prob-  \nlem,  known  as the  <stable-roommates  problem.=  Although  matching applies to \ngeneral undirected graphs, this chapter deals only with bipartite graphs. \n25.1  Maximum  bipartite  matching  (revisited)  \nSection  24.3  demonstrated  one  way  to \u00fbnd  a maximum  matching  in a bipartite \ngraph,  by  \u00fbnding  a maximum  \u00fcow.  This  section  provides  a more  ef\u00fbcient  method,  \nthe  Hopcroft-Karp  algorithm,  which  runs  in O.  p \nVE/  time.  Figure  25.1(a)  shows  \na matching in an undirected bipartite graph. A vert ex that has an incident edge in \nmatching M  is matched  under M  , and otherwise, it is unmatched . A maximal  \nmatching  is a matching M  to which no other edges can be added, that is, for every \nedge e 2 E \ue003 M  , the edge set M  [ feg fails to be a matching. A maximum \nmatching is always maximal, but the reverse does no t always hold. \nMany  algorithms  to \u00fbnd  maximum  matchings,  the  Hopcroft-Karp  algorithm  in-  \ncluded, work by incrementally increasing the size o f a matching.  Given  a match-  \ning M  in an undirected graph G D .V;E/ , an M  -alternating  path  is a simple path \nwhose edges alternate between being in M  and being in E \ue003 M  . Figure  25.1(b)  de-  \npicts an M  -augmenting  path  (sometimes called an augmenting path with respect \nto M  ): an M  -alternating  path  whose  \u00fbrst  and  last  edges  belong  to E \ue003 M  . Since an \nM  -augmenting  path  contains  one  more  edge  in E \ue003 M  than in M  , it must consist \nof an odd number of edges. 706  Chapter  25  Matchings  in Bipartite  Graphs  \nl 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 \nR L r 1 \nr 2 \nr 3 \nr 4 \nr 5 \nr 6 \nr 7 \nr 8 \n(b) l 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 \nR L r 1 \nr 2 \nr 3 \nr 4 \nr 5 \nr 6 \nr 7 \nr 8 \n(a) l 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 \nR L r 1 \nr 2 \nr 3 \nr 4 \nr 5 \nr 6 \nr 7 \nr 8 \n(c) \nFigure  25.1  A bipartite graph, where V D L [ R, L D fl 1 ;l 2 ;:::;l  7 g, and R D fr 1 ;r 2 ;:::;r  8 g. \n(a)  A matching M  with cardinality 4, highlighted in blue. Matched vertices are blue, a nd unmatched \nvertices are tan. (b)  The  \u00fbve  edges  highlighted  in orange  form  an  M  -augmenting  path  P going \nbetween vertices l 6 and r 8 . (c)  The set of edges M  0 D M  \u02da P highlighted in blue is a matching \ncontaining one more edge than M  and adding l 6 and r 8 to the matched vertices. This matching is \nnot  a maximum  matching  (see  Exercise  25.1-1).  \nFigure  25.1(c)  demonstrates  the  following  lemma,  which  shows  that  by  remov-  \ning from matching M  the edges in an M  -augmenting  path  that  belong  to M  and \nadding to M  the edges in the M  -augmenting  path  that  are  not  in M  , the result \nis a new matching with one more edge than M  . Since a matching is a set of \nedges, the lemma relies on the notion of the symmetric  difference  of two sets: \nX \u02da Y D .X  \ue003 Y/  [ .Y  \ue003 X/, that is, the elements that belong to X or Y , but not \nboth. Alternatively, you can think of X \u02daY as .X  [Y/\ue003.X  \\Y/. The operator \u02da is \ncommutative and associative. Furthermore, X \u02da X D ;  and X \u02da ; D ; \u02da  X D X \nfor any set X , so that the empty set is the identity for \u02da. \nLemma  25.1  \nLet M  be a matching in any undirected graph G D .V;E/ , and let P be an \nM  -augmenting  path.  Then  the  set  of edges  M  0 D M  \u02da P is also a matching \nin G with jM  0 j D jM  j C  1. 25.1  Maximum  bipartite  matching  (revisited)  707 \nProof  Let P contain q edges, so that dq=2e edges belong to E \ue003 M  and bq=2c \nedges belong to M  , and let these q edges be .v 1 ;v  2 /;.v  2 ;v  3 /;:::;.v  q ;v  qC1 /. Be-  \ncause P is an M  -augmenting  path,  vertices  v 1 and v qC1 are unmatched under M  \nand all other vertices in P are matched. Edges .v 1 ;v  2 /;.v  3 ;v  4 /;:::;.v  q ;v  qC1 / \nbelong to E \ue003 M  , and edges .v 2 ;v  3 /;.v  4 ;v  5 /;:::;.v  q\ue0021 ;v  q / belong to M  . \nThe symmetric difference M  0 D M  \u02da P reverses these roles, so that edges \n.v 1 ;v  2 /;.v  3 ;v  4 /;:::;.v  q ;v  qC1 / belong to M  0 and .v 2 ;v  3 /;.v  4 ;v  5 /;:::;.v  q\ue0021 ;v  q / \nbelong to E \ue003 M  0 . Each vertex v 1 ;v  2 ;:::;v  q ;v  qC1 is matched under M  0 , which \ngains one additional edge relative to M  , and no other vertices or edges in G \nare affected by the change from M  to M  0 . Hence, M  0 is a matching in G, and \njM  0 j D jM  j C  1. \nSince taking the symmetric difference of a matching  M  with an M  -augmenting  \npath increases the size of the matching by 1, the following corollary shows that \ntaking the symmetric difference of M  with k vertex-disjoint  M  -augmenting  paths  \nincreases the size of the matching by k. \nCorollary  25.2  \nLet M  be a matching in any undirected graph G D .V;E/  and P 1 ;P  2 ;:::;P  k be \nvertex-disjoint  M  -augmenting  paths.  Then  the  set  of edges  M  0 D M  \u02da .P  1 [ P 2 [ \n\ue001 \ue001 \ue001 [  P k / is a matching in G with jM  0 j D jM  j C  k. \nProof  Since the M  -augmenting  paths  P 1 ;P  2 ;:::;P  k are  vertex-disjoint,  we  have  \nthat P 1 [P 2 [\ue001 \ue001 \ue001[P k D P 1 \u02daP 2 \u02da\ue001 \ue001 \ue001\u02daP k . Because the operator \u02da is associative, \nwe have \nM  \u02da .P  1 [ P 2 [ \ue001 \ue001 \ue001 [  P k / D M  \u02da .P  1 \u02da P 2 \u02da \ue001 \ue001 \ue001 \u02da  P k / \nD .\ue001 \ue001 \ue001  ..M  \u02da P 1 / \u02da P 2 / \u02da \ue001 \ue001 \ue001 \u02da  P k\ue0021 / \u02da P k : \nA simple induction on i using  Lemma  25.1  shows  that  M  \u02da .P  1 [ P 2 [ \ue001 \ue001 \ue001 [  P i \ue0021 / \nis a matching in G containing jM  j C  i \ue003 1 edges and that path P i is an augmenting \npath with respect to M  \u02da .P  1 [ P 2 [ \ue001 \ue001 \ue001 [  P i \ue0021 /. Each of these augmenting paths \nincreases the size of the matching by 1, and so jM  0 j D jM  j C  k. \nAs  the  Hopcroft-Karp  algorithm  goes  from  matching  to matchi ng, it will be \nuseful to consider the symmetric difference between  two matchings. \nLemma  25.3  \nLet M  and M  \ue003 be matchings in graph G D .V;E/ , and consider the graph G 0 D \n.V;E  0 /, where E 0 D M  \u02da M  \ue003 . Then, G 0 is a disjoint union of simple paths, simple \ncycles, and/or isolated vertices. The edges in each  such simple path or simple cycle 708  Chapter  25  Matchings  in Bipartite  Graphs  \nalternate between M  and M  \ue003 . If jM  \ue003 j > jM  j, then G 0 contains at least jM  \ue003 j\ue003jM  j \nvertex-disjoint  M  -augmenting  paths.  \nProof  Each vertex in G 0 has degree 0, 1, or 2, since at most two edges of E 0 can \nbe incident on a vertex: at most one edge from M  and at most one edge from M  \ue003 . \nTherefore, each connected component of G 0 is either  a singleton  vertex,  an even-  \nlength simple cycle with edges alternately in M  and M  \ue003 , or a simple path with \nedges alternately in M  and M  \ue003 . Since \nE 0 D M  \u02da M  \ue003 \nD .M  [ M  \ue003 / \ue003 .M  \\ M  \ue003 / \nand jM  \ue003 j > jM  j, the edge set E 0 must contain jM  \ue003 j \ue003 jM  j more edges from M  \ue003 \nthan from M  . Because each cycle in G 0 has  an even  number  of edges  drawn  al-  \nternately from M  and M  \ue003 , each cycle has an equal number of edges from M  \nand M  \ue003 . Therefore, the simple paths in G 0 account for there being jM  \ue003 j \ue003 jM  j \nmore edges from M  \ue003 than M  . Each path containing a different number of edges \nfrom M  and M  \ue003 either starts and ends with edges from M  , containing one more \nedge from M  than from M  \ue003 , or starts and ends with edges from M  \ue003 , containing \none more edge from M  \ue003 than from M  . Because E 0 contains jM  \ue003 j \ue003 jM  j more \nedges from M  \ue003 than from M  , there are at least jM  \ue003 j \ue003 jM  j paths of the latter \ntype, and each one is an M  -augmenting  path.  Because  each  vertex  has  at most  two  \nincident edges from E 0 , these  paths  must  be vertex-disjoint.  \nIf an algorithm  \u00fbnds  a maximum  matching  by  incrementally  increasing the size \nof the  matching,  how  does  it determine  when  to stop?  The  following corollary \ngives the answer: when there are no augmenting path s. \nCorollary  25.4  \nMatching M  in graph G D .V;E/  is a maximum matching if and only if G con-  \ntains no M  -augmenting  path.  \nProof  We prove the contrapositive of both directions of t he lemma statement. \nThe contrapositive of the forward direction is stra ightforward. If there is an \nM  -augmenting  path  P in G, then  by  Lemma  25.1,  the  matching  M  \u02da P contains \none more edge than M  , meaning that M  could not be a maximum matching. \nTo  show  the  contrapositive  of the  backward  direction4if  M  is not a maximum \nmatching, then G contains an M  -augmenting  path4let  M  \ue003 be a maximum  match-  \ning  in Lemma  25.3,  so that  jM  \ue003 j > jM  j. Then G contains at least jM  \ue003 j\ue003jM  j >0  \nvertex-disjoint  M  -augmenting  paths.  25.1  Maximum  bipartite  matching  (revisited)  709 \nWe  already  have  learned  enough  to create  a maximum-matching  algorithm that \nruns in O.VE/  time. Start with the matching M  empty. Then repeatedly run \na variant  of either  breadth-\u00fbrst  search  or depth-\u00fbrst  searc h from an unmatched \nvertex  that  takes  alternating  paths  until  you  \u00fbnd  another  unmatched vertex. Use \nthe resulting M  -augmenting  path  to increase  the  size  of M  by 1. \nThe  Hopcroft-Karp  algorithm  \nThe  Hopcroft-Karp  algorithm  improves  the  running  time  to O.  p \nVE/. The  proce-  \ndure HOPCROFT-KARP is given  an undirected  bipartite  graph,  and  it uses  Corol-  \nlary  25.2  to repeatedly  increase  the  size  of the  matching  M  it \u00fbnds.  Corol-  \nlary  25.4  proves  that  the  algorithm  is correct,  since  it terminates once there are no \nM  -augmenting  paths.  It remains  to show  that  the  algorithm  does run in O.  p \nVE/  \ntime.  We\u2019ll  see  that  the  repeat  loop  of lines  235  iterates  O.  p \nV/  times and how to \nimplement  line  3 so that  it runs  in O.E/  time in each iteration. \nHOPCROFT-KARP .G/  \n1 M  D ;  \n2 repeat  \n3 let P D fP 1 ;P  2 ;:::;P  k g be a maximal  set  of vertex-disjoint  \nshortest M  -augmenting  paths  \n4 M  D M  \u02da .P  1 [ P 2 [ \ue001 \ue001 \ue001 [  P k / \n5 until  P == ; \n6 return  M  \nLet\u2019s  \u00fbrst  see  how  to \u00fbnd  a maximal  set  of vertex-disjoint  shortest M  - \naugmenting paths in O.E/  time.  There  are  three  phases.  The  \u00fbrst  phase  forms  \na directed version G M  of the undirected bipartite graph G. The  second  phase  cre-  \nates a directed acyclic graph H from G M  via  a variant  of breadth-\u00fbrst  search.  The  \nthird  phase  \u00fbnds  a maximal  set  of vertex-disjoint  shortest  M  -augmenting  paths  \nby  running  a variant  of depth-\u00fbrst  search  on  the  transpose  H T of H . (Recall that \nthe transpose of a directed graph reverses the dire ction of each edge. Since H is \nacyclic, so is H T .) \nGiven  a matching  M  , you can think of an M  -augmenting  path  P as starting \nat an unmatched vertex in L, traversing an odd number of edges, and ending at \nan unmatched vertex in R. The edges in P traversed from L to R must belong \nto E \ue003 M  , and the edges in P traversed from R to L must belong to M  . The  \u00fbrst  \nphase, therefore, creates the directed graph G M  by directing the edges accordingly: \nG M  D .V;E  M  /, where 710  Chapter  25  Matchings  in Bipartite  Graphs  \nl 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 \nR L r 1 \nr 2 \nr 3 \nr 4 \nr 5 \nr 6 \nr 7 \nr 8 \n(a) 0 \n1 1 1 \n2 \n2 \n2 3 \n3 \n3 \n3 \n4 \n5 l 1 r 2 \nr 3 \nr 7 l 4 0 \nl 6 0 l 2 \nl 3 \nl 5 r 1 \nr 4 \nr 5 \nr 6 \n(b) layer  0 layer  1 layer  2 layer  3 3 \n3 \n3 \n3 2 \n2 \n2 1 0 1 0 1 0 \nFigure  25.2  (a)  The directed graph G M  created  in the  \u00fbrst  phase  for  the  undirected  bipartite  \ngraph G and matching M  in Figure  25.1(a).  Breadth-\u00fbrst  distances  from  any  unmatch ed vertex \nin L appear next to each vertex. (b)  The dag H created from G M  in the second phase. Because the \nsmallest distance to an unmatched vertex in R is 3, vertices l 7 and r 8 , with distances greater than 3, \nare not in H . \nE M  D f.l;r/  W l 2 L;r  2 R;  and .l;r/  2 E \ue003 M  g (edges from L to R) \n[ f.r;l/  W r 2 R;l  2 L;  and .l;r/  2 M  g (edges from R to L) . \nFigure  25.2(a)  shows  the  graph  G M  for the graph G and matching M  in Fig-  \nure  25.1(a).  \nThe dag H D .V  H  ;E  H  / created  by  the  second  phase  has  layers  of vertices.  Fig-  \nure  25.2(b)  shows  the  dag  H corresponding to the directed graph G M  in part (a) of \nthe  \u00fbgure.  Each  layer  contains  only  vertices  from  L or only vertices from R, alter-  \nnating from layer to layer. The layer that a vertex  resides in is given  by  that  vertex\u2019s  \nminimum  breadth-\u00fbrst  distance  in G M  from any unmatched vertex in L. Vertices \nin L appear  in even-numbered  layers,  and  vertices  in R appear  in odd-numbered  \nlayers. Let q denote the smallest distance in G M  of any unmatched vertex in R. \nThen, the last layer in H contains the vertices in R with distance q. Vertices whose \ndistance exceeds q do not appear in V H  . (The graph H in Figure  25.2(b)  omits  ver-  \ntices l 7 and r 8 because their distances from any unmatched vertex i n L exceed \nq D 3.) The edges in E H  form a subset of E M  : 25.1  Maximum  bipartite  matching  (revisited)  711 \nE H  D f.l;r/  2 E M  W r: d \u0dc4 q and r: d D l: d C 1g [ f.r;l/  2 E M  W l: d \u0dc4 qg ; \nwhere the attribute d of a vertex  gives  the  vertex\u2019s  breadth-\u00fbrst  distance  in G M  \nfrom any unmatched vertex in L. Edges that do not go between two consecutive \nlayers are omitted from E H  . \nTo  determine  the  breadth-\u00fbrst  distances  of vertices,  run  breadth-\u00fbrst  search  on  \nthe graph G M  , but starting from all the unmatched vertices in L. (In the BFS \nprocedure  on  page  556,  replace  the  root  vertex  s by the set of unmatched vertices \nin L.) The predecessor attributes \ufffd computed by the BFS procedure are not needed \nhere, since H is a dag and not necessarily a tree. \nEvery path in H from a vertex in layer 0 to an unmatched vertex in layer q \ncorresponds to a shortest M  -augmenting  path  in the  original  bipartite  graph  G. Just  \nuse the undirected versions of the directed edges i n H . Moreover, every shortest \nM  -augmenting  path  in G is present in H . \nThe  third  phase  identi\u00fbes  a maximal  set  of vertex-disjoint  shortest M  -augment-  \ning  paths.  As  Figure  25.3  shows,  it starts  by  creating  the  transpose H T of H . Then, \nfor each unmatched vertex r in layer q, it performs  a depth-\u00fbrst  search  starting  \nfrom r until it either reaches a vertex in layer 0 or has exhausted all possible paths \nwithout reaching a vertex in layer 0. Instead  of maintaining  discovery  and  \u00fbnish  \ntimes,  the  depth-\u00fbrst  search  just  needs  to keep  track  of the  predecessor attributes \ufffd \nin the  depth-\u00fbrst  tree  of each  search.  Upon  reaching  a vertex  in layer 0, tracing back \nalong  the  predecessors  identi\u00fbes  an M  -augmenting  path.  Each  vertex  is searched  \nfrom  only  when  it is \u00fbrst  discovered  in any  search.  If the  search from a vertex r \nin layer q cannot  \u00fbnd  a path  of undiscovered  vertices  to an undiscovere d vertex in \nlayer 0, then no M  -augmenting  path  including  r goes into the maximal set. \nFigure  25.3  shows  the  result  of the  third  phase.  The  \u00fbrst  depth-\u00fbrst  search  starts  \nfrom vertex r 1 . It identi\u00fbes  the  M  -augmenting  path  h.r 1 ;l 3 /;.l  3 ;r  3 /;.r  3 ;l 1 /i, \nwhich is highlighted in orange, and discovers verti ces r 1 , l 3 , r 3 , and l 1 . The next \ndepth-\u00fbrst  search  starts  from  vertex  r 4 . This  search  \u00fbrst  examines  the  edge  .r 4 ;l 3 /, \nbut because l 3 was already discovered, it backtracks and examines edge .r 4 ;l 5 /. \nFrom  there,  it continues  and  identi\u00fbes  the  M  -augmenting  path  h.r 4 ;l 5 /;.l  5 ;r  7 /; \n.r 7 ;l 6 /i, which is highlighted in yellow, and discovers ver tices r 4 , l 5 , r 7 , and l 6 . \nThe  depth-\u00fbrst  search  from  vertex  r 6 gets stuck at vertices l 3 and l 5 , which have \nalready  been  discovered,  and  so this  search  fails  to \u00fbnd  a path of undiscovered \nvertices to a vertex in layer 0. There  is no  depth-\u00fbrst  search  from  vertex  r 5 because \nit is matched,  and  depth-\u00fbrst  searches  start  from  unmatched  vertices. Therefore, the \nmaximal  set  of vertex-disjoint  shortest  M  -augmenting  paths  found  contains  just  the  \ntwo M  -augmenting  paths  .hr 1 ;l 3 /;.l  3 ;r 3 /;.r  3 ;l 1 /i and h.r 4 ;l 5 /;.l  5 ;r 7 /;.r  7 ;l 6 /i. \nYou might have noticed that in this example, this m aximal set of two  vertex-  \ndisjoint shortest M  -augmenting  paths  is not  a maximum  set.  The  graph  con-  \ntains  three  vertex-disjoint  shortest  M  -augmenting  paths:  h.r 1 ;l 2 /;.l  2 ;r 2 /;.r  2 ;l 1 /i, \nh.r 4 ;l 3 /;.l  3 ;r 3 /;.r  3 ;l 4 /i, and h.r 6 ;l 5 /;.l  5 ;r 7 /;.r  7 ;l 6 /i. No matter: the algorithm 712  Chapter  25  Matchings  in Bipartite  Graphs  \nlayer  0 layer  1 layer  2 layer  3 l 4 \nl 6 l 1 r 2 \nr 3 \nr 7 l 2 \nl 3 \nl 5 r 1 \nr 4 \nr 5 \nr 6 \nFigure  25.3  The transpose H T of the dag H created  in the  third  phase.  The  \u00fbrst  depth-\u00fbrst  search,  \nstarting from vertex r 1 , identi\u00fbes  the  M  -augmenting  path  h.r 1 ;l 3 /;.l  3 ;r 3 /;.r  3 ;l 1 /i highlighted in \norange, and it discovers vertices r 1 ;l 3 ;r 3 ;l 1 . The  second  depth-\u00fbrst  search,  starting  from  vertex  r 4 , \nidenti\u00fbes  the  M  -augmenting  path  h.r 4 ;l 5 /; .l 5 ;r  7 /; .r 7 ;l 6 /i highlighted in yellow, discovering \nvertices r 4 ;l 5 ;r 7 ;l 6 . \nrequires  the  set  of vertex-disjoint  shortest  M  -augmenting  paths  found  in line  3 of \nHOPCROFT-KARP to be only maximal, not necessarily maximum. \nIt remains  to show  that  all  three  phases  of line  3 take  O.E/  time. We assume that \nin the original bipartite graph G, each vertex has at least one incident edge so tha t \njV j D  O.E/ , which in turn implies that jV jCjEj D  O.E/. The  \u00fbrst  phase  creates  \nthe directed graph G M  by simply directing each edge of G, so that jV M  j D jV j and \njE M  j D jEj. The  second  phase  performs  a breadth-\u00fbrst  search  on  G M  , taking \nO.V  M  C E M  / D O.E  M  / D O.E/  time.  In fact,  it can  stop  once  the  \u00fbrst  distance  \nin the  queue  within  the  breadth-\u00fbrst  search  exceeds  the  shortest distance q to an \nunmatched vertex in R. The dag H has jV H  j \u0dc4 jV M  j and jE H  j \u0dc4 jE M  j, so \nthat it takes O.V  H  C E H  / D O.E/  time to construct. Finally, the third phase \nperforms  depth-\u00fbrst  searches  from  the  unmatched  vertices  in layer q. Once  a vertex  \nis discovered, it is not searched from again, and s o the analysis  of depth-\u00fbrst  search  \nfrom  Section  20.3  applies  here:  O.V  H  C E H  / D O.E/ . Hence, all three phases \ntake just O.E/  time. \nOnce  the  maximal  set  of vertex-disjoint  shortest  M  -augmenting  paths  have  been  \nfound  in line  3, updating  the  matching  in line  4 takes  O.E/  time, as it is just a \nmatter of going through the edges of the M  -augmenting  paths  and  adding  edges  to \nand removing edges from the matching M  . Thus, each iteration of the repeat  loop \nof lines  235  can  run  in O.E/  time. 25.1  Maximum  bipartite  matching  (revisited)  713 \nIt remains to show that the repeat  loop iterates O.  p \nV/  times. We start with \nthe following lemma, which shows that after each it eration of the repeat  loop, the \nlength of an augmenting path increases. \nLemma  25.5  \nLet G D .V;E/  be an undirected bipartite graph with matching M  , and let q \nbe the length of a shortest M  -augmenting  path.  Let  P D fP 1 ;P  2 ;:::;P  k g be \na maximal  set  of vertex-disjoint  M  -augmenting  paths  of length  q. Let M  0 D \nM  \u02da .P  1 [ P 2 [ \ue001 \ue001 \ue001 [  P k /, and suppose that P is a shortest M  0 -augmenting  path.  \nThen P has more than q edges. \nProof  We consider separately the cases in which P is vertex-disjoint  from  the  \naugmenting paths in P and  in which  it is not  vertex-disjoint.  \nFirst, assume that P is vertex-disjoint  from  the  augmenting  paths  in P . Then, \nP contains edges that are in M  but are not in any of P 1 ;P  2 ;:::;P  k , so that P is \nalso an M  -augmenting  path.  Since  P is disjoint from P 1 ;P  2 ;:::;P  k but is also \nan M  -augmenting  path,  and  since  P is a maximal set of shortest M  -augmenting  \npaths, P must be longer than any of the augmenting paths in P , each of which has \nlength q. Therefore, P has more than q edges. \nNow, assume that P visits at least one vertex from the M  -augmenting  paths  \nin P . By  Corollary  25.2,  M  0 is a matching in G with jM  0 j D jM  j C  k. Since P is \nan M  0 -augmenting  path,  by  Lemma  25.1,  M  0 \u02da P is a matching with jM  0 \u02da P j D  \njM  0 j C  1 D jM  j C  k C 1. Now let A D M  \u02da M  0 \u02da P . We claim that A D \n.P  1 [ P 2 [ \ue001 \ue001 \ue001 [  P k / \u02da P : \nA D M  \u02da M  0 \u02da P \nD M  \u02da .M  \u02da .P  1 [ P 2 [ \ue001 \ue001 \ue001 [  P k // \u02da P \nD .M  \u02da M/  \u02da .P  1 [ P 2 [ \ue001 \ue001 \ue001 [  P k / \u02da P (associativity of \u02da) \nD ; \u02da  .P  1 [ P 2 [ \ue001 \ue001 \ue001 [  P k / \u02da P (X \u02da X D ;  for all X ) \nD .P  1 [ P 2 [ \ue001 \ue001 \ue001 [  P k / \u02da P (; \u02da  X D X for all X ) . \nLemma  25.3  with  M  \ue003 D M  0 \u02da P gives that A contains at least jM  0 \u02da P j\ue003jM  j D  \nk C 1 vertex-disjoint  M  -augmenting  paths.  Since  each  such  M  -augmenting  path  \nhas at least q edges, we have jAj \ue004  .k C 1/q  D kq  C q. \nNow we claim that P shares at least one edge with some M  -augmenting  path  \nin P . Under the matching M  0 , every vertex in each M  -augmenting  path  in P \nis matched.  (Only  the  \u00fbrst  and  last  vertex  in each  M  -augmenting  path  P i is un-  \nmatched under M  , and under M  \u02da P i , all vertices in P i are matched. Because \nthe M  -augmenting  paths  in P are  vertex-disjoint,  no  other  path  in P can affect \nwhether the vertices in P i are matched. That is, the vertices in P i are matched \nunder .M  \u02da P i / \u02da P j if and only if they are matched under M  \u02da P i , for any other 714  Chapter  25  Matchings  in Bipartite  Graphs  \npath P j 2 P .) Suppose that P shares a vertex v with some path P i 2 P . Vertex v \ncannot be an endpoint of P , because the endpoints of P are unmatched under M  0 . \nTherefore, v has an incident edge in P that belongs to M  0 . Since any vertex has \nat most one incident edge in a matching, this edge must also belong to P i , thus \nproving the claim. \nBecause A D .P  1 [ P 2 [ \ue001 \ue001 \ue001 [  P k / \u02da P and P shares at least one edge with \nsome P i 2 P , we have that jAj < jP 1 [ P 2 [ \ue001 \ue001 \ue001 [  P k j C jP j. Thus, we have \nkq  C q \u0dc4 jAj \n< jP 1 [ P 2 [ \ue001 \ue001 \ue001 [  P k j C jP j \nD kq  C jP j ; \nso that q<  jP j. We conclude that P contains more than q edges. \nThe next lemma bounds the size of a maximum matchin g, based on the length \nof a shortest augmenting path. \nLemma  25.6  \nLet M  be a matching in graph G D .V;E/ , and let a shortest M  -augmenting  \npath in G contain q edges. Then the size of a maximum matching in G is at most \njM  j C jV j =.q  C 1/. \nProof  Let M  \ue003 be a maximum matching in G. By  Lemma  25.3,  G contains at \nleast jM  \ue003 j\ue003jM  j vertex-disjoint  M  -augmenting  paths.  Each  of these  paths  contains  \nat least q edges, and hence at least q C 1 vertices.  Because  these  paths  are  vertex-  \ndisjoint, we have .jM  \ue003 j\ue003jM  j/.q  C1/ \u0dc4 jV j, so that jM  \ue003 j \u0dc4 jM  jCjV j =.q  C1/. \nThe  \u00fbnal  lemma  bounds  the  number  of iterations  of the  repeat  loop  of lines  235.  \nLemma  25.7  \nWhen the H OPCROFT-KARP procedure runs on an undirected bipartite graph G D \n.V;E/ , the repeat  loop  of lines  235  iterates  O.  p \nV/  times. \nProof  By  Lemma  25.5,  the  length  q of the shortest M  -augmenting  paths  found  in \nline  3 increases  from  iteration  to iteration.  After  \u02d9p  \njV j \ue00c \niterations, therefore, we \nmust have q \ue004 \u02d9p  \njV j \ue00c \n. Consider  the  situation  after  the  \u00fbrst  time  line  4 executes  \nwith M  -augmenting  paths  whose  length  is at least  \u02d9p  \njV j \ue00c \n. Since the size of a \nmatching increases by at least one edge per iterati on, Lemma 25.6  implies  that  the  \nnumber of additional iterations before achieving a maximum matching is at most \njV j \u02d9p  \njV j \ue00c \nC 1 < jV j p \njV j D p \njV j : 25.1  Maximum  bipartite  matching  (revisited)  715 \nHence, the total number of loop iterations is less than 2 p \njV j. \nThus, we have the following bound on the running ti me of the H OPCROFT-KARP \nprocedure. \nTheorem  25.8  \nThe procedure H OPCROFT-KARP runs in O.  p \nVE/  time on an undirected bipartite \ngraph G D .V;E/ . \nProof  By  Lemma  25.7  the  repeat  loop iterates O.  p \nV/  times, and we have seen \nhow to implement each iteration in O.E/  time. \nExercises  \n25.1-1  \nUse  the  Hopcroft-Karp  algorithm  to \u00fbnd  a maximum  matching  for the graph in \nFigure  25.1.  \n25.1-2  \nHow are M  -augmenting  paths  and  augmenting  paths  in \u00fcow  networks  similar?  \nHow  do  they  differ?  \n25.1-3  \nWhat is the advantage of searching in the transpose  H T from unmatched vertices \nin layer q (the  \u00fbrst  layer  that  contains  an unmatched  vertex  in R) to layer 0 versus \nsearching in the dag H from layer 0 to layer q? \n25.1-4  \nShow how to bound the number of iterations of the t he repeat  loop  of lines  235  of \nHOPCROFT-KARP by \u02d9 \n3 p \njV j=2  \ue00c \n. \n? 25.1-5  \nA perfect  matching  is a matching under which every vertex is matched. Let G D \n.V;E/  be an undirected bipartite graph with vertex partit ion V D L [ R, where \njLj D jRj. For any X \u0dc2 V , de\u00fbne  the  neighborhood  of X as \nN.X/  D fy 2 V W .x;y/  2 E for some x 2 X g ; \nthat is, the set of vertices adjacent to some membe r of X . Prove Hall\u2019s  theorem : \nthere exists a perfect matching in G if and only if jAj \u0dc4 jN.A/ j for every subset \nA \u0dc2 L. 716  Chapter  25  Matchings  in Bipartite  Graphs  \n25.1-6  \nIn a d -regular  graph, every vertex has degree d . If G D .V;E/  is bipartite with \nvertex partition V D L [ R and also d -regular,  then  jLj D jRj. Use  Hall\u2019s  \ntheorem  (see  Exercise  25.1-5)  to prove  that  every  d -regular  bipartite  graph  contains  \na perfect matching. Then use that result to prove t hat every d -regular  bipartite  \ngraph contains d disjoint perfect matchings. \n25.2  The  stable-marriage  problem  \nIn Section  25.1,  the  goal  was  to \u00fbnd  a maximum  matching  in an undirected bipartite \ngraph. If you know that the graph G D .V;E/  with vertex partition V D L [ R is \na complete  bipartite  graph  1 4containing  an edge  from  every  vertex  in L to every \nvertex in R4then  you  can  \u00fbnd  a maximum  matching  by  a simple  greedy  algori thm. \nWhen a graph can have several matchings, you might want to decide which \nmatchings  are  most  desirable.  In Section  25.3,  we\u2019ll  add  weights to the edges and \n\u00fbnd  a matching  of maximum  weight.  In this  section,  we  will  instead add some \ninformation to each vertex in a complete bipartite graph: a ranking of the vertices \nin the other side. That is, each vertex in L has an ordered list of all the vertices in R, \nand  vice-versa.  To  keep  things  simple,  let\u2019s  assume  that  L and R each contain n \nvertices. The goal here is to match each vertex in L with a vertex in R in a <stable= \nway. \nThis problem derives its name, the stable-marriage  problem , from the notion of \nheterosexual marriage, viewing L as a set of women and R as a set of men. 2 Each \nwoman ranks all the men in terms of desirability, a nd each man does the same with \nall the women. The goal is to pair up women and men  (a matching) so that if a \nwoman and a man are not matched to each other, then  at least one of them prefers \ntheir assigned partner. \nIf a woman and a man are not matched to each other but each prefers the other \nover their assigned partner, they form a blocking  pair. A blocking  pair  has  incen-  \ntive to opt out of the assigned pairing and get tog ether on their own. If that were \nto occur, then this pair would block the matching f rom being <stable.= A stable  \n1 The  de\u00fbnition  of a complete  bipartite  graph  differs  from  the  de\u00fbnition  of complete  graph  given  \non  page  1167  because  in a bipartite  graph,  there  are  no  edges  between vertices in L and no edges \nbetween vertices in R. \n2 Although  marriage  norms  are  changing,  it\u2019s  traditional  to view  the  stable-marriage  problem  through  \nthe lens of heterosexual marriage. 25.2 The stable-marriage problem 717 \nmatching , therefore, is a matching that has no blocking pai r. If there is a blocking \npair, then the matching is unstable . \nLet\u2019s  look  at an example  with  four  women4Wanda,  Emma,  Lacey,  and  Karen4  \nand  four  men4Oscar,  Davis,  Brent,  and  Hank4having  the  follo wing preferences: \nWanda:  Brent,  Hank,  Oscar,  Davis  \nEmma:  Davis,  Hank,  Oscar,  Brent  \nLacey:  Brent,  Davis,  Hank,  Oscar  \nKaren:  Brent,  Hank,  Davis,  Oscar  \nOscar:  Wanda,  Karen,  Lacey,  Emma  \nDavis:  Wanda,  Lacey,  Karen,  Emma  \nBrent:  Lacey,  Karen,  Wanda,  Emma  \nHank:  Lacey,  Wanda,  Emma,  Karen  \nA stable matching comprises the following pairs: \nLacey and Brent \nWanda and Hank \nKaren  and  Davis  \nEmma  and  Oscar  \nYou can verify that this matching has no blocking p air. For example, even though \nKaren  prefers  Brent  and  Hank  to her  partner  Davis,  Brent  prefers his partner Lacey \nto Karen,  and  Hank  prefers  his  partner  Wanda  to Karen,  so that  neither  Karen  and  \nBrent  nor  Karen  and  Hank  form  a blocking  pair.  In fact,  this  stable matching is \nunique. Suppose instead that the last two pairs wer e \nEmma and Davis \nKaren  and  Oscar  \nThen  Karen  and  Davis  would  be a blocking  pair,  because  they  were  not  paired  to-  \ngether,  Karen  prefers  Davis  to Oscar,  and  Davis  prefers  Kare n to Emma. Therefore, \nthis matching is not stable. \nStable matchings need not be unique. For example, s uppose that there are three \nwomen4Monica,  Phoebe,  and  Rachel4and  three  men4Chandler,  Joey,  and  Ross  \n4with  these  preferences:  \nMonica:  Chandler,  Joey,  Ross  \nPhoebe:  Joey,  Ross,  Chandler  \nRachel:  Ross,  Chandler,  Joey  \nChandler: Phoebe, Rachel, Monica \nJoey:  Rachel,  Monica,  Phoebe  \nRoss: Monica, Phoebe, Rachel 718  Chapter  25  Matchings  in Bipartite  Graphs  \nIn this case, there are three stable matchings: \nMatching  1 \nMonica and Chandler \nPhoebe  and  Joey  \nRachel and Ross Matching 2 \nPhoebe and Chandler \nRachel  and  Joey  \nMonica and Ross Matching  3 \nRachel and Chandler \nMonica  and  Joey  \nPhoebe and Ross \nIn matching  1, all  women  get  their  \u00fbrst  choice  and  all  men  get  their last choice. \nMatching  2 is the  opposite,  with  all  men  getting  their  \u00fbrst  choice and all women \ngetting their last choice. When all the women or al l the men ge t their  \u00fbrst  choice,  \nthere  plainly  cannot  be a blocking  pair.  In matching  3, every one gets their second \nchoice. You can verify that there are no blocking p airs. \nYou might wonder whether it is always possible to c ome up with a stable  match-  \ning no matter what rankings each participant provid es. The answer  is yes.  (Ex-  \nercise  25.2-3  asks  you  to show  that  even  in the  scenario  of the  National Resident \nMatching Program, where each hospital takes on mult iple students, it is always \npossible to devise a stable assignment.) A simple a lgorithm known  as the  Gale-  \nShapley  algorithm  always  \u00fbnds  a stable  matching.  The  algori thm has two variants, \nwhich  mirror  each  other:  <woman-oriented=  and  <man-oriented.=  Let\u2019s  examine  \nthe  woman-oriented  version.  Each  participant  is either  <free=  or <engaged.=  Ev-  \neryone starts out free. Engagements occur when a fr ee woman proposes to a man. \nWhen  a man  is \u00fbrst  proposed  to,  he goes  from  free  to engaged,  and he always stays \nengaged, though not necessarily to the same woman. If an engaged man receives \na proposal  from  a woman  whom  he prefers  to the  woman  he\u2019s  curre ntly engaged \nto, that engagement is broken, the woman to whom he  had been engaged becomes \nfree, and the man and the woman whom he prefers bec ome engaged. Each woman \nproposes to the men in her preference list, in orde r, until the last time she becomes \nengaged. When a woman is engaged, she temporarily s tops proposing, but if she \nbecomes  free  again,  she  continues  down  her  list.  Once  everyo ne is engaged, the \nalgorithm  terminates.  The  procedure  GALE-SHAPLEY on the next page makes this \nprocess more concrete. The procedure allows for som e choice: any free woman \nmay  be selected  in line  2. We\u2019ll  see  that  the  procedure  produc es a stable matching \nregardless of the order in which line 2 chooses fre e women. Fo r the  man-oriented  \nversion, just reverse the roles of men and women in  the procedure. \nLet\u2019s  see  how  the  GALE-SHAPLEY procedure executes on the example with \nWanda,  Emma,  Lacey,  Karen,  Oscar,  Davis,  Brent,  and  Hank.  After everyone is \ninitialized to free, here is one possible version o f what can occur in successive \niterations of the while  loop of lines 2\u20139: \n1. Wanda  proposes  to Brent.  Brent  is free,  so that  Wanda  and  Brent become \nengaged and no longer free. 25.2 The stable-marriage problem 719 \nGALE-SHAPLEY .men; women; rankings/ \n1 assign each woman and man as free \n2 while  some woman w is free \n3 let m be the  \u00fbrst  man  on  w\u2019s ranked  list  to whom  she  has  not  proposed  \n4 if m is free \n5 w and m become engaged to each other (and not free) \n6 elseif  m ranks w higher than the woman w 0 he is currently engaged to \n7 m breaks the engagement to w 0 , who becomes free \n8 w and m become engaged to each other (and not free) \n9 else  m rejects w, with w remaining free \n10  return  the stable matching consisting of the engaged pairs  \n2. Emma proposes to Davis. Davis is free, so that E mma and Davis become \nengaged and no longer free. \n3. Lacey  proposes  to Brent.  Brent  is engaged  to Wanda,  but  he prefers Lacey. \nBrent breaks the engagement to Wanda, who becomes f ree. Lacey and Brent \nbecome engaged, with Lacey no longer free. \n4. Karen  proposes  to Brent.  Brent  is engaged  to Lacey,  whom  he prefers  to Karen.  \nBrent  rejects  Karen,  who  remains  free.  \n5. Karen  proposes  to Hank.  Hank  is free,  so that  Karen  and  Hank  become engaged \nand no longer free. \n6. Wanda  proposes  to Hank.  Hank  is engaged  to Karen,  but  he prefers Wanda. \nHank  breaks  the  engagement  with  Karen,  who  becomes  free.  Wanda and Hank \nbecome engaged, with Wanda no longer free. \n7. Karen  proposes  to Davis.  Davis  is engaged  to Emma,  but  he prefers  Karen.  \nDavis  breaks  the  engagement  to Emma,  who  becomes  free.  Karen  and Davis \nbecome  engaged,  with  Karen  no  longer  free.  \n8. Emma  proposes  to Hank.  Hank  is engaged  to Wanda,  whom  he prefers to \nEmma. Hank rejects Emma, who remains free. \n9. Emma  proposes  to Oscar.  Oscar  is free,  so that  Emma  and  Oscar  become  en-  \ngaged and no longer free. \nAt this point, everyone is engaged and nobody is fr ee, so the while  loop terminates. \nThe procedure returns the stable matching we saw ea rlier. \nThe  following  theorem  shows  that  not  only  does  GALE-SHAPLEY terminate, \nbut that it always returns a stable matching, there by proving that a stable matching \nalways exists. 720  Chapter  25  Matchings  in Bipartite  Graphs  \nTheorem  25.9  \nThe  procedure  GALE-SHAPLEY always terminates and returns a stable matching. \nProof  Let\u2019s  \u00fbrst  show  that  the  while  loop of lines 2\u20139 always terminates, so \nthat the procedure terminates. The proof is by cont radiction. If the loop fails to \nterminate, it is because some woman remains free. I n order for a woman to remain \nfree, she must have proposed to all the men and bee n rejected by each one. In \norder for a man to reject a woman, he must be alrea dy engaged. Therefore, all \nthe  men  are  engaged.  Once  engaged,  a man  stays  engaged  (thoug h not necessarily \nto the same woman). There are an equal number n of women and men, however, \nwhich means that every woman is engaged, leading to  the contradiction that no \nwomen are free. We must also show that the while  loop makes a bounded number \nof iterations. Since each of the n women goes through her ranking of the n men in \norder, possibly not reaching the end of her list, t he total number of iterations is at \nmost n 2 . Therefore, the while  loop always terminates, and the procedure returns a  \nmatching. \nWe  need  to show  that  there  are  no  blocking  pairs.  We  \u00fbrst  obser ve that once a \nman m is engaged to a woman w, all subsequent actions for m occur  in lines  638.  \nTherefore, once a man is engaged, he stays engaged,  and any time he breaks an \nengagement to a woman w, it\u2019s  for  a woman  whom  he prefers  to w. Suppose that \na woman w is matched with a man m, but she prefers man m 0 . We\u2019ll  show  that  w \nand m 0 is not a blocking pair, because m 0 does not prefer w to his partner. Because \nw ranks m 0 higher than m, she must have proposed to m 0 before proposing to m, \nand m 0 either rejected her proposal or accepted it and lat er broke the engagement. \nIf m 0 rejected the proposal from w, it is because he was already engaged to some \nwoman he prefers to w. If m 0 accepted and later broke the engagement, he was at \nsome point engaged to w but later accepted a proposal from a woman he prefe rs \nto w. In either case, he ultimately ends up with a part ner whom he prefers to w. \nWe conclude that even though w might prefer m 0 to her partner m, it is not also the \ncase that m 0 prefers w to his partner. Therefore, the procedure returns a matching \ncontaining no blocking pairs. \nExercise  25.2-1  asks  you  to provide  the  proof  of the  followin g corollary. \nCorollary  25.10  \nGiven  preference  rankings  for  n women and n men,  the  Gale-Shapley  algorithm  \ncan be implemented to run in O.n  2 / time. \nBecause line 2 can choose any free woman, you might  wonder whether different \nchoices can produce different stable matchings. The  answer is no: as the following 25.2 The stable-marriage problem 721 \ntheorem  shows,  every  execution  of the  GALE-SHAPLEY produces exactly the same \nresult. Moreover, the stable matching returned is o ptimal for the women. \nTheorem  25.11  \nRegardless  of how  women  are  chosen  in line  2 of GALE-SHAPLEY , the procedure \nalways returns the same stable matching, and in thi s stable matching, each woman \nhas the best partner possible in any stable matchin g. \nProof  The proof that each woman has the best partner poss ible in any stable \nmatching  is by  contradiction.  Suppose  that  the  GALE-SHAPLEY procedure returns \na stable matching M  , but that there is a different stable matching M  0 in which some \nwoman w prefers her partner m 0 to the partner m she has in M  . Because w ranks \nm 0 higher than m, she must have proposed to m 0 before proposing to m. Then there \nis a woman w 0 whom m 0 prefers to w, and m 0 was already engaged to w 0 when w \nproposed or m 0 accepted the proposal from w and later broke the engagement in \nfavor of w 0 . Either way, there is a moment when m 0 decided against w in favor \nof w 0 . Now suppose, without loss of generality, that thi s moment was the  \u00fbrst  time  \nthat any man rejected a partner who belongs to some  stable matching. \nWe claim that w 0 cannot have a partner m 00 in a stable matching whom she prefers \nto m 0 . If there were such a man m 00 , then in order for w 0 to propose to m 0 , she would \nhave proposed to m 00 and been rejected at some point before proposing to  m 0 . If m 0 \naccepted the proposal from w and later broke it to accept w 0 , then since this was \nthe  \u00fbrst  rejection  in a stable  matching,  we  get  the  contradic tion that m 00 could not \nhave rejected w 0 beforehand. If m 0 was already engaged to w 0 when w proposed, \nthen again, m 00 could not have rejected w 0 beforehand, thus proving the claim. \nSince w 0 does not prefer anyone to m 0 in a stable matching and w 0 is not matched \nwith m 0 in M  0 (because m 0 is matched with w in M  0 ), w 0 prefers m 0 to her partner \nin M  0 . Since w 0 prefers m 0 over her partner in M  0 and m 0 prefers w 0 over his \npartner w in M  0 , the pair w 0 and m 0 is a blocking pair in M  0 . Because M  0 has a \nblocking pair, it cannot be a stable matching, ther eby contradicting the assumption \nthat there exists some stable matching in which eac h woman has the best partner \npossible other than the matching M  returned  by  GALE-SHAPLEY . \nWe put no condition on the execution of the procedu re, which means that all \npossible orders in which line 2 selects women resul t in the same stable matching \nbeing returned. \nCorollary  25.12  \nThere  can  be stable  matchings  that  the  GALE-SHAPLEY procedure does not return. \nProof  Theorem  25.11  says  that  for  a given  set  of rankings,  GALE-SHAPLEY re-  \nturns just one matching, no matter how it chooses w omen in line 2. The  earlier  ex-  722  Chapter  25  Matchings  in Bipartite  Graphs  \nample of three women and three men with three diffe rent stable matchings shows \nthat there can be multiple stable matchings for a g iven set of rankings. A call of \nGALE-SHAPLEY is capable of returning only one of these stable ma tchings. \nAlthough  the  GALE-SHAPLEY procedure gives the best possible outcome for \nthe women, the following corollary shows that it al so produces the worst possible \noutcome for the men. \nCorollary  25.13  \nIn the  stable  matching  returned  by  the  procedure  GALE-SHAPLEY , each man has \nthe worst partner possible in any stable matching. \nProof  Let M  be the  matching  returned  by  a call  to GALE-SHAPLEY . Suppose \nthat there is another stable matching M  0 and a man m who prefers his partner w \nin M  to his partner w 0 in M  0 . Let the partner of w in M  0 be m 0 . By  Theorem  25.11,  \nm is the best partner that w can have in any stable matching, which means that w \nprefers m to m 0 . Since m prefers w to w 0 , the pair w and m is a blocking pair in M  0 , \ncontradicting the assumption that M  0 is a stable matching. \nExercises  \n25.2-1  \nDescribe  how  to implement  the  Gale-Shapley  algorithm  so that it runs in O.n  2 / \ntime. \n25.2-2  \nIs it possible to have an unstable matching with ju st two wome n and  two  men?  If \nso, provide and justify an example. If not, argue w hy not. \n25.2-3  \nThe National Resident Matching Program differs from  the scenario  for  the  stable-  \nmarriage problem set out in this section in two way s. First, a hospital may be \nmatched with more than one student, so that hospita l h takes r h \ue004 1 students. \nSecond, the number of students might not equal the number of hospitals. Describe \nhow  to modify  the  Gale-Shapley  algorithm  to \u00fbt the  requireme nts of the National \nResident Matching Program. \n25.2-4  \nProve the following property, which is known as weak  Pareto  optimality : \nLet M  be the  stable  matching  produced  by  the  GALE-SHAPLEY procedure, \nwith women proposing to men. Then, for a given inst ance of the stable-  \nmarriage  problem  there  is no  matching4stable  or unstable4s uch that every 25.3  The  Hungarian  algorithm  for  the  assignment  problem  723  \nwoman has a partner whom she prefers to her partner  in the stable match-  \ning M  . \n25.2-5  \nThe stable-roommates  problem  is similar  to the  stable-marriage  problem,  except  \nthat the graph is a complete graph, not bipartite, with an even number  of ver-  \ntices. Each vertex represents a person, and each pe rson ranks all  the  other  peo-  \nple.  The  de\u00fbnitions  of blocking  pairs  and  stable  matching  extend in the natural \nway: a blocking pair comprises two people who both prefer each other to their \ncurrent partner, and a matching is stable if there are no blocking  pairs.  For  exam-  \nple,  consider  four  people4Wendy,  Xenia,  Yolanda,  and  Zelda4with  the  following  \npreference lists: \nWendy: Xenia, Yolanda, Zelda \nXenia: Wendy, Zelda, Yolanda \nYolanda: Wendy, Zelda, Xenia \nZelda: Xenia, Yolanda, Wendy \nYou can verify that the following matching is stabl e: \nWendy and Xenia \nYolanda and Zelda \nUnlike  the  stable-marriage  problem,  the  stable-roommates  problem can have inputs \nfor which no stable matching exists. Find such an i nput and explain why no stable \nmatching exists. \n25.3  The  Hungarian  algorithm  for  the  assignment  problem  \nLet us once again add some information to a complet e bipartite graph G D .V;E/ , \nwhere V D L [ R. This time, instead of having the vertices of each  side rank the \nvertices on the other side, we assign a weight to e ach edge. Ag ain,  let\u2019s  assume  \nthat the vertex sets L and R each contain n vertices, so that the graph contains n 2 \nedges. For l 2 L and r 2 R, denote the weight of edge .l;r/  by w.l;r/ , which \nrepresents the utility gained by matching vertex l with vertex r . \nThe  goal  is to \u00fbnd  a perfect  matching  M  \ue003 (see  Exercises  25.1-5  and  25.1-6)  \nwhose edges have the maximum total weight over all perfect matchings. That is, \nletting w.M/  D P  \n.l;r/2M  w.l;r/  denote  the  total  weight  of the  edges  in match-  \ning M  , we  want  to \u00fbnd  a perfect  matching  M  \ue003 such that \nw.M  \ue003 / D max fw.M/  W M  is a perfect matching g : 724  Chapter  25  Matchings  in Bipartite  Graphs  \nWe  call  \u00fbnding  such  a maximum-weight  perfect  matching  the  assignment  prob-  \nlem. A solution to the assignment problem is a perfect  matching that maximizes \nthe  total  utility.  Like  the  stable-marriage  problem,  the  assignment  problem  \u00fbnds  a \nmatching  that  is <good,=  but  with  a different  de\u00fbnition  of good: maximizing total \nvalue rather than achieving stability. \nAlthough you could enumerate all n\u0160 perfect matchings to solve the assignment \nproblem, an algorithm known as the Hungarian  algorithm  solves it much faster. \nThis section will prove an O.n  4 / time  bound,  and  Problem  25-2  asks  you  to re\u00fbne  \nthe algorithm to reduce the running time to O.n  3 /. Instead of working with the \ncomplete bipartite graph G, the Hungarian algorithm works with a subgraph of G \ncalled the <equality subgraph.= The equality subgra ph, which is de\u00fbned  below,  \nchanges  over  time  and  has  the  bene\u00fbcial  property  that  any  perfect matching in the \nequality subgraph is also an optimal solution to th e assignment problem. \nThe equality subgraph depends on assigning an attri bute h to each vertex. We \ncall h the label  of a vertex, and we say that h is a feasible  vertex  labeling  of G if \nl: h C r: h \ue004 w.l;r/  for all l 2 L and r 2 R:  \nA feasible vertex labeling always exists, such as t he default  vertex  labeling  given \nby \nl: h D max fw.l;r/  W r 2 Rg for all l 2 L , (25.1)  \nr: h D 0 for all r 2 R . (25.2)  \nGiven  a feasible  vertex  labeling  h, the equality  subgraph  G h D .V;E  h / of G \nconsists of the same vertices as G and the subset of edges \nE h D f.l;r/  2 E W l: h C r: h D w.l;r/ g : \nThe following theorem ties together a perfect match ing in an equality subgraph \nand an optimal solution to the assignment problem. \nTheorem  25.14  \nLet G D .V;E/ , where V D L [ R, be a complete bipartite graph where each \nedge .l;r/  2 E has weight w.l;r/ . Let h be a feasible vertex labeling of G and \nG h be the equality subgraph of G. If G h contains a perfect matching M  \ue003 , then M  \ue003 \nis an optimal solution to the assignment problem on  G. \nProof  If G h contains a perfect matching M  \ue003 , then because G h and G have the \nsame sets of vertices, M  \ue003 is also a perfect matching in G. Because each edge \nof M  \ue003 belongs to G h and each vertex has exactly one incident edge from any \nperfect matching, we have 25.3  The  Hungarian  algorithm  for  the  assignment  problem  725  \nw.M  \ue003 / D X  \n.l;r/2M  \ue002 w.l;r/  \nD X  \n.l;r/2M  \ue002 .l:  h C r: h/ (because all edges in M  \ue003 belong to G h ) \nD X  \nl 2L l: h C X  \nr 2R r: h (because M  \ue003 is a perfect matching) . \nLetting M  be any perfect matching in G, we have \nw.M/  D X  \n.l;r/2M  w.l;r/  \n\u0dc4 X  \n.l;r/2M  .l:  h C r: h/ (because h is a feasible vertex labeling) \nD X  \nl 2L l: h C X  \nr 2R r: h (because M  is a perfect matching) . \nThus, we have \nw.M/  \u0dc4 X  \nl 2L l: h C X  \nr 2R r: h D w.M  \ue003 /; (25.3)  \nso that M  \ue003 is a maximum-weight  perfect  matching  in G. \nThe  goal  now  becomes  \u00fbnding  a perfect  matching  in an equality  subgraph. \nWhich  equality  subgraph?  It does  not  matter!  We  have  free  rein to not only choose \nan equality subgraph, but to change which equality subgraph we choose as we go \nalong.  We  just  need  to \u00fbnd  some perfect matching in some equality subgraph. \nTo understand the equality subgraph better, conside r again the  proof  of Theo-  \nrem  25.14  and,  in the  second  half,  let  M  be any matching. The proof is still valid, \nin particular,  inequality  (25.3):  the  weight  of any  matchin g is always at most the \nsum of the vertex labels. If we choose any set of v ertex labels that  de\u00fbne  an equality  \nsubgraph,  then  a maximum-cardinality  matching  in this  equa lity subgraph has total \nvalue at most the sum of the vertex labels. If the set of vertex labels is the <right= \none, then it will have total value equal to w.M  \ue003 /, and  a maximum-cardinality  \nmatching  in the  equality  subgraph  is also  a maximum-weight  perfect matching. \nThe  Hungarian  algorithm  repeatedly  modi\u00fbes  the  matching  and the vertex labels \nin order to achieve this goal. \nThe Hungarian algorithm starts with any feasible ve rtex labeling h and any \nmatching M  in the equality subgraph G h . It repeatedly  \u00fbnds  an M  -augmenting  \npath P in G h and,  using  Lemma  25.1,  updates  the  matching  to be M  \u02da P , thereby \nincrementing the size of the matching. As long as t here is some equality subgraph \nthat contains an M  -augmenting  path,  the  size  of the  matching  can  increase,  until a \nperfect matching is achieved. 726  Chapter  25  Matchings  in Bipartite  Graphs  \nFour questions arise: \n1. What  initial  feasible  vertex  labeling  should  the  algorithm  start  with?  Answer:  \nthe  default  vertex  labeling  given  by  equations  (25.1)  and  (25.2).  \n2. What initial matching in G h should  the  algorithm  start  with?  Short  answer:  \nany matching, even an empty matching, but a greedy maximal matching works \nwell. \n3. If an M  -augmenting  path  exists  in G h , how  to \u00fbnd  it?  Short  answer:  use  a \nvariant  of breadth-\u00fbrst  search  similar  to the  second  phase  of the procedure used \nin the  Hopcroft-Karp  algorithm  to \u00fbnd  a maximal  set  of shorte st M  -augmenting  \npaths. \n4. What  if the  search  for  an M  -augmenting  path  fails?  Short  answer:  update  the  \nfeasible vertex labeling to bring in at least one n ew edge. \nWe\u2019ll  elaborate  on  the  short  answers  using  the  example  that  starts  in Figure  25.4.  \nHere, L D fl 1 ;l 2 ;:::;l  7 g and R D fr 1 ;r 2 ;:::;r  7 g. The edge weights appear in the \nmatrix shown in part (a), where the weight w.l  i ;r j / appears in row i and column j . \nThe feasible vertex labels, given by the default ve rtex labeling, appear to the left \nof and above the matrix. Matrix entries in red indi cate edges .l i ;r j / for which \nl i : h C r j : h D w.l  i ;r j /, that is, edges in the equality subgraph G h appearing in \npart  (b)  of the  \u00fbgure.  \nGreedy  maximal  bipartite  matching  \nThere  are  several  ways  to implement  a greedy  method  to \u00fbnd  a maximal bipartite \nmatching.  The  procedure  GREEDY-BIPARTITE-MATCHING  shows one. Edges \nin Figure  25.4(b)  highlighted  in blue  indicate  the  initial  greedy maximal matching \nin G h . Exercise  25.3-2  asks  you  to show  that  the  GREEDY-BIPARTITE-MATCHING  \nprocedure returns a matching that is at least half the size of a maximum matching. \nGREEDY-BIPARTITE-MATCHING  .G/  \n1 M  D ;  \n2 for  each vertex l 2 L \n3 if l has an unmatched neighbor in R \n4 choose any such unmatched neighbor r 2 R \n5 M  D M  [ f.l;r/ g \n6 return  M  25.3  The  Hungarian  algorithm  for  the  assignment  problem  727  \n(a) 4 10  10  10  2 9 3 r 1 r 2 r 3 r 4 r 5 r 6 r 7 \n6 8 5 12  9 7 2 \n11  9 6 7 9 5 15  \n3 9 6 7 5 6 3 \n2 6 5 3 2 4 2 \n10  8 11  4 11  2 11  \n3 4 5 4 3 6 8 0 0 0 0 0 0 0 \n10  \n12  \n15  \n9 \n6 \n11  \n8 h \nl 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 \nR L l 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 r 1 \nr 2 \nr 3 \nr 4 \nr 5 \nr 6 \nr 7 G h \n(b) R L l 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 r 1 \nr 2 \nr 3 \nr 4 \nr 5 \nr 6 \nr 7 G M,h \n(c) \nFigure  25.4  The start of the Hungarian algorithm. (a)  The matrix of edge weights for a bipartite \ngraph with L D fl 1 ;l 2 ;:::;l  7 g and R D fr 1 ;r 2 ;:::;r  7 g. The value in row i and column j indi-  \ncates w.l  i ;r j /. Feasible vertex labels appear above and next to t he matrix. Red entries correspond to \nedges in the equality subgraph. (b)  The equality subgraph G h . Edges highlighted in blue belong to \nthe initial greedy maximal matching M  . Blue vertices are matched, and tan vertices are u nmatched. \n(c)  The directed equality subgraph G M;h  created from G h by directing edges in M  from R to L and \nall other edges from L to R. \nFinding  an  M  -augmenting  path  in G h \nTo  \u00fbnd  an M  -augmenting  path  in the  equality  subgraph  G h with a matching M  , the \nHungarian  algorithm  \u00fbrst  creates  the  directed  equality  subgraph  G M;h  from G h , \njust  as the  Hopcroft-Karp  algorithm  creates  G M  from G. As  in the  Hopcroft-Karp  \nalgorithm, you can think of an M  -augmenting  path  as starting  from  an unmatched  \nvertex in L, ending at an unmatched vertex in R, taking unmatched edges from L \nto R, and taking matched edges from R to L. Thus, G M;h  D .V;E  M;h  /, where \nE M;h  D f.l;r/  W l 2 L;r  2 R;  and .l;r/  2 E h \ue003 M  g (edges from L to R) \n[ f.r;l/  W r 2 R;l  2 L;  and .l;r/  2 M  g (edges from R to L) . \nBecause an M  -augmenting  path  in the  directed  equality  subgraph  G M:h  is also an \nM  -augmenting  path  in the  equality  subgraph  G h , it suf\u00fbces  to \u00fbnd  M  -augmenting  \npaths in G M:h  . Figure  25.4(c)  shows  the  directed  equality  subgraph  G M;h  corre-  \nsponding to the equality subgraph G h and matching M  from  part  (b)  of the  \u00fbgure.  728  Chapter  25  Matchings  in Bipartite  Graphs  \nWith the directed equality subgraph G M;h  in hand, the Hungarian algorithm \nsearches for an M  -augmenting  path  from  any  unmatched  vertex  in L to any  un-  \nmatched vertex in R. Any  exhaustive  graph-search  method  suf\u00fbces.  Here,  we\u2019ll  \nuse  breadth-\u00fbrst  search,  starting  from  all  the  unmatched  vertices in L (just as the \nHopcroft-Karp  algorithm  does  when  creating  the  dag  H ), but  stopping  upon  \u00fbrst  \ndiscovering some unmatched vertex in R. Figure  25.5  shows  the  idea.  To  start  \nfrom all the unmatched vertices in L, initialize  the  \u00fbrst-in,  \u00fbrst-out  queue  with  all  \nthe unmatched vertices in L, rather than just one source vertex. Unlike the da g H \nin the  Hopcroft-Karp  algorithm,  here  each  vertex  needs  just  one predecessor, so \nthat  the  breadth-\u00fbrst  search  creates  a breadth-\u00fbrst  forest  F D .V  F ;E  F /. Each \nunmatched vertex in L is a root in F . \nIn Figure  25.5(g),  the  breadth-\u00fbrst  search  has  found  the  M  -augmenting  path  \nh.l 4 ;r 2 /;.r  2 ;l 1 /;.l  1 ;r 3 /;.r  3 ;l 6 /;.l  6 ;r 5 /i. Figure  25.6(a)  shows  the  new  matching  \ncreated by taking the symmetric difference of the m atching M  in Figure  25.5(a)  \nwith this M  -augmenting  path.  \nWhen  the  search  for  an  M  -augmenting  path  fails  \nHaving updated the matching M  from an M  -augmenting  path,  the  Hungarian  algo-  \nrithm updates the directed equality subgraph G M;h  according to the new matching \nand  then  starts  a new  breadth-\u00fbrst  search  from  all  the  unmatc hed vertices in L. \nFigure  25.6  shows  the  start  of this  process,  picking  up  from  Figure  25.5.  \nIn Figure  25.6(d),  the  queue  contains  vertices  l 4 and l 3 . Neither of these vertices \nhas an edge that leaves it, however, so that once t hese vertices are removed from \nthe queue, the queue becomes empty. The search term inates at this point, before \ndiscovering an unmatched vertex in R to yield an M  -augmenting  path.  When-  \never this situation occurs, the most recently disco vered vertices must belong to L. \nWhy?  Whenever  an unmatched  vertex  in R is discovered, the search has found \nan M  -augmenting  path,  and  when  a matched  vertex  in R is discovered, it has an \nunvisited neighbor in L, which the search can then discover. \nRecall that we have the freedom to work with any eq uality subgraph. We can \nchange  the  directed  equality  subgraph  <on  the  \u00fcy,=  as long  we  do not counteract the \nwork already done. The Hungarian algorithm updates the feasible vertex labeling h \nto ful\u00fbll  the  following  criteria:  \n1. No  edge  in the  breadth-\u00fbrst  forest  F leaves the directed equality subgraph. \n2. No edge in the matching M  leaves the directed equality subgraph. \n3. At  least  one  edge  .l;r/ , where l 2 L \\ V F and r 2 R \ue003 V F goes into E h , and \nhence into E M;h  . Therefore, at least one vertex in R will be newly discovered. \nThus, at least one new edge enters the directed equ ality subgraph, and any edge \nthat leaves the directed equality subgraph belongs to neither the matching M  nor 25.3  The  Hungarian  algorithm  for  the  assignment  problem  729  \nl 4 l 5 l 7 \nr 7 \nl 3 r 2 \nl 1 \nr 3 r 4 \nl 6 \nr 5 l 2 \n(g) l 4 l 5 l 7 \n(b) l 4 l 5 l 7 \nr 7 r 2 \n(c) \nl 4 l 5 l 7 \nr 7 \nl 3 r 2 \nl 1 \n(d) l 4 l 5 l 7 \nr 7 \nl 3 r 2 \nl 1 \nr 3 r 4 \n(e) \nl 4 l 5 l 7 \nr 7 \nl 3 r 2 \nl 1 \nr 3 r 4 \nl 6 l 2 \n(f) R L l 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 r 1 \nr 2 \nr 3 \nr 4 \nr 5 \nr 6 \nr 7 G M,h \n(a) \nFigure  25.5  Finding an M  -augmenting  path  in G M;h  by  breadth-\u00fbrst  search.  (a)  The directed \nequality subgraph G M;h  from  Figure  25.4(c).  (b)\u2013(g)  Successive  versions  of the  breadth-\u00fbrst  for-  \nest F , shown  as the  vertices  at each  distance  from  the  roots4the  unmatched vertices in L4are  dis-  \ncovered. In parts (b)\u2013(f), the layer of vertices cl osest to the bottom  of the  \u00fbgure  are  those  in the  \u00fbrst-  \nin,  \u00fbrst-out  queue.  For  example,  in part  (b),  the  queue  conta ins the roots hl 4 ;l 5 ;l 7 i, and in part (e), \nthe queue contains hr 3 ;r 4 i, at distance 3 from the roots. In part (g), the unmatched vertex r 5 is dis-  \ncovered,  so the  breadth-\u00fbrst  search  terminates.  The  path  h.l 4 ;r 2 /;.r  2 ;l 1 /;.l  1 ;r 3 /;.r  3 ;l 6 /;.l  6 ;r 5 /i, \nhighlighted in orange in parts (a) and (g), is an M  -augmenting  path.  Taking  its  symmetric  difference  \nwith the matching M  yields a new matching with one more edge than M  . 730  Chapter  25  Matchings  in Bipartite  Graphs  \nR L l 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 r 1 \nr 2 \nr 3 \nr 4 \nr 5 \nr 6 \nr 7 G M,h \n(a) l 5 l 7 \n(b) l 5 l 7 \n(c) r 2 r 7 \nl 5 l 7 \n(d) r 2 r 7 \nl 4 l 3 \nFigure  25.6  (a)  The new matching M  and the new directed equality subgraph G M:h  after updating \nthe  matching  in Figure  25.5(a)  with  the  M  -augmenting  path  in Figure  25.5(g).  (b)\u2013(d)  Successive \nversions  of the  breadth-\u00fbrst  forest  F in a new  breadth-\u00fbrst  search  with  roots  l 5 and l 7 . After the \nvertices l 4 and l 3 in part (d) have been removed from the queue, the q ueue becomes empty before \nthe search can discover an unmatched vertex in R. \nthe  breadth-\u00fbrst  forest  F . Newly discovered vertices in R are enqueued, but their \ndistances are not necessarily 1 greater  than  the  distances  of the  most  recently  dis-  \ncovered vertices in L. \nTo update the feasible vertex labeling, the Hungari an algorithm  \u00fbrst  computes  \nthe value \n\u0131 D min fl: h C r: h \ue003 w.l;r/  W l 2 F L and r 2 R \ue003 F R g ; (25.4)  \nwhere F L D L \\ V F and F R D R \\ V F denote  the  vertices  in the  breadth-\u00fbrst  \nforest F that belong to L and R, respectively. That is, \u0131 is the smallest difference \nby which an edge incident on a vertex in F L missed being in the current equality \nsubgraph G h . The Hungarian algorithm then creates a new feasib le vertex labeling, \nsay h 0 , by subtracting \u0131 from l: h for all vertices l 2 F L and adding \u0131 to r: h for all \nvertices r 2 F R : \nv: h 0 D \u0128 \nv: h \ue003 \u0131 if v 2 F L ; \nv: h C \u0131 if v 2 F R ; \nv: h otherwise (v 2 V \ue003 V F ) : (25.5)  25.3  The  Hungarian  algorithm  for  the  assignment  problem  731  \nThe following lemma shows that these changes achiev e the three criteria above. \nLemma  25.15  \nLet h be a feasible vertex labeling for the complete bipa rtite graph G with equality \nsubgraph G h , and let M  be a matching for G h and F be a breadth-\u00fbrst  forest  \nbeing constructed for the directed equality subgrap h G M;h  . Then, the labeling h 0 in \nequation  (25.5)  is a feasible  vertex  labeling  for  G with the following properties: \n1. If .u;v/  is an edge  in the  breadth-\u00fbrst  forest  F for G M;h  , then .u;v/  2 E M;h  0 . \n2. If .l;r/  belongs to the matching M  for G h , then .r;l/  2 E M;h  0 . \n3. There  exist  vertices  l 2 F L and r 2 R \ue003 F R such that .l;r/  \u2026 E M;h  but \n.l;r/  2 E M;h  0 . \nProof  We  \u00fbrst  show  that  h 0 is a feasible vertex labeling for G. Because h is a \nfeasible vertex labeling, we have l: h C r: h \ue004 w.l;r/  for all l 2 L and r 2 R. \nIn order for h 0 to not be a feasible vertex labeling, we would need  l: h 0 C r: h 0 < \nl: h C r: h for some l 2 L and r 2 R. The only way this could occur would be \nfor some l 2 F L and r 2 R \ue003 F R . In this instance, the amount of the decrease \nequals \u0131 , so that l: h 0 C r: h 0 D l: h \ue003 \u0131 C r: h. By  equation  (25.4),  we  have  that  \nl: h \ue003\u0131 Cr: h \ue004 w.l;r/  for any l 2 F L and r 2 R \ue003F R , so that l: h 0 Cr: h 0 \ue004 w.l;r/ . \nFor all other edges, we have l: h 0 C r: h 0 \ue004 l: h C r: h \ue004 w.l;r/ . Thus, h 0 is a feasible \nvertex labeling. \nNow we show that each of the three desired properti es holds: \n1. If l 2 F L and r 2 F R , then we have l: h 0 Cr: h 0 D l: h Cr: h because \u0131 is added to \nthe label of l and subtracted from the label of r . Therefore, if an edge belongs \nto F for the directed graph G M;h  , it also belongs to G M;h  0 . \n2. We claim that at the time the Hungarian algorith m computes the new feasible \nvertex labeling h 0 , for every edge .l;r/  2 M  , we have l 2 F L if and only if \nr 2 F R . To see why, consider a matched vertex r and let .l;r/  2 M  . First \nsuppose that r 2 F R , so that the search discovered r and enqueued it. When r \nwas removed from the queue, l was discovered, so l 2 F L . Now suppose that \nr \u2026 F R , so r is undiscovered. We will show that l \u2026 F L . The only edge in G M;h  \nthat enters l is .r;l/ , and since r is undiscovered, the search has not taken this \nedge; if l 2 F L , it is not because of the edge .r;l/ . The only other way that \na vertex in L can be in F L is if it is a root of the search, but only unmatche d \nvertices in L are roots and l is matched. Thus, l \u2026 F L , and the claim is proved. \nWe already saw that l 2 F L and r 2 F R implies l: h 0 C r: h 0 D l: h C r: h. For \nthe opposite case, when l 2 L \ue003 F L and R 2 R \ue003 F R , we have that l: h 0 D l: h \nand r: h 0 D r: h, so that again l: h 0 C r: h 0 D l: h C r: h. Thus, if edge .l;r/  is in \nthe matching M  for the equality graph G h , then .r;l/  2 E M;h  0 . 732  Chapter  25  Matchings  in Bipartite  Graphs  \n3. Let  .l;r/  be an edge not in E h such that l 2 F L , r 2 R \ue003 F R , and \u0131 D \nl: h C r: h \ue003 w.l;r/. By  the  de\u00fbnition  of \u0131 , there is at least one such edge. Then, \nwe have \nl: h 0 C r: h 0 D l: h \ue003 \u0131 C r: h \nD l: h \ue003 .l:  h C r: h \ue003 w.l;r//  C r: h \nD w.l;r/;  \nand thus .l;r/  2 E h 0 . Since .l;r/  is not in E h , it is not in the matching M  , so \nthat in E M;h  0 it must be directed from L to R. Thus, .l;r/  2 E M;h  0 . \nIt is possible for an edge to belong to E M;h  but not to E M;h  0 . By  Lemma  25.15,  \nany such edge belongs neither to the matching M  nor  to the  breadth-\u00fbrst  forest  F at \nthe time that the new feasible vertex labeling h 0 is computed.  (See  Exercise  25.3-3.)  \nGoing  back  to Figure  25.6(d),  the  queue  became  empty  before  an M  -augmenting  \npath  was  found.  Figure  25.7  shows  the  next  steps  taken  by  the  algorithm. The \nvalue of \u0131 D 1 is achieved by the edge .l 5 ;r 3 / because  in Figure  25.4(a),  l 5 : h C \nr 3 : h \ue003 w.l  5 ;r 3 / D 6 C 0 \ue003 5 D 1. In Figure  25.7(a),  the  values  of l 3 : h, l 4 : h, \nl 5 : h, and l 7 : h have decreased by 1 and the values of r 2 : h and r 7 : h have increased \nby 1 because these vertices are in F . As a result, the edges .l 1 ;r 2 / and .l 6 ;r 7 / \nleave G M;h  and the edge .l 5 ;r 3 / enters.  Figure  25.7(b)  shows  the  new  directed  \nequality subgraph G M;h  . With edge .l 5 ;r 3 / now in G M;h  , Figure  25.7(c)  shows  \nthat  this  edge  is added  to the  breadth-\u00fbrst  forest  F , and r 3 is added to the queue. \nParts  (c)3(f)  show  the  breadth-\u00fbrst  forest  continuing  to be built until in part (f), the \nqueue once again becomes empty after vertex l 2 , which has no edges leaving, is \nremoved. Again, the algorithm must update the feasi ble vertex labeling and the \ndirected equality subgraph. Now the value of \u0131 D 1 is achieved by three edges: \n.l 1 ;r 6 /, .l 5 ;r 6 /, and .l 7 ;r 6 /. \nAs  Figure  25.8  shows  in parts  (a)  and  (b),  these  edges  enter  G M;h  , and \nedge .l 6 ;r 3 / leaves. Part (c) shows that edge .l 1 ;r 6 / is added  to the  breadth-  \n\u00fbrst  forest.  (Either  of edges  .l 5 ;r 6 / or .l 7 ;r 6 / could  have  been  added  in-  \nstead.) Because r 6 is unmatched, the search has found the M  -augmenting  path  \nh.l 5 ;r 3 /;.r  3 ;l 1 /;.l  1 ;r 6 /i, highlighted in orange. \nFigure  25.9(a)  shows  G M;h  after the matching M  has  been  updated  by  tak-  \ning its symmetric difference with the M  -augmenting  path.  The  Hungarian  al-  \ngorithm  starts  its  last  breadth-\u00fbrst  search,  with  vertex  l 7 as the only root. The \nsearch  proceeds  as shown  in parts  (b)3(h)  of the  \u00fbgure,  until  the queue becomes \nempty after removing l 4 . This  time,  we  \u00fbnd  that  \u0131 D 2, achieved  by  the  \u00fbve  \nedges .l 2 ;r 5 /, .l 3 ;r 1 /, .l 4 ;r 5 /, .l 5 ;r 1 /, and .l 5 ;r 5 /, each of which enters G M;h  . \nFigure  25.10(a)  shows  the  results  of decreasing  the  feasibl e vertex label of each \nvertex in F L by 2 and increasing the feasible vertex label of each ve rtex in F R 25.3  The  Hungarian  algorithm  for  the  assignment  problem  733  \nr 4 l 1 \n(a) 4 10  10  10  2 9 3 r 1 r 2 r 3 r 4 r 5 r 6 r 7 \n6 8 5 12  9 7 2 \n11  9 6 7 9 5 15  \n3 9 6 7 5 6 3 \n2 6 5 3 2 4 2 \n10  8 11  4 11  2 11  \n3 4 5 4 3 6 8 0 1 0 0 0 0 1 \n10  \n12  \n14  \n8 \n5 \n11  \n7 h \nl 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 \nR L l 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 r 1 \nr 2 \nr 3 \nr 4 \nr 5 \nr 6 \nr 7 G M,h \n(b) l 5 l 7 \n(c) r 2 r 7 \nl 4 l 3 r 3 \nl 2 l 5 l 7 \n(d) r 2 r 7 \nl 4 l 3 r 3 \nl 1 l 5 l 7 \n(e) r 2 r 7 \nl 4 l 3 r 3 \nr 4 l 1 l 5 l 7 \n(f) r 2 r 7 \nl 4 l 3 r 3 \nFigure  25.7  Updating the feasible vertex labeling and the direc ted equality subgraph G M;h  when \nthe  queue  becomes  empty  before  \u00fbnding  an  M  -augmenting  path.  (a)  With \u0131 D 1, the values of l 3 : h, \nl 4 : h, l 5 : h, and l 7 : h decreased by 1 and r 2 : h and r 7 : h increased by 1. Edges .l 1 ;r 2 / and .l 6 ;r 7 / \nleave G M;h  , and edge .l 5 ;r 3 / enters. These changes are highlighted in yellow. (b)  The resulting \ndirected equality subgraph G M;h  . (c)\u2013(f)  With edge .l 5 ;r 3 / added  to the  breadth-\u00fbrst  forest  and  r 3 \nadded  to the  queue,  the  breadth-\u00fbrst  search  continues  until  the queue once again becomes empty in \npart (f). \nby 2, and  Figure  25.10(b)  shows  the  resulting  directed  equality  subgraph G M;h  . \nPart (c) shows that edge .l 3 ;r 1 / is added  to the  breadth-\u00fbrst  forest.  Since  r 1 is \nan unmatched vertex, the search terminates, having found the M  -augmenting  path  \nh.l 7 ;r 7 /;.r  7 ;l 3 /;.l  3 ;r 1 /i, highlighted in orange. If r 1 had been matched, vertex r 5 \nwould  also  have  been  added  to the  breadth-\u00fbrst  forest,  with  any of l 2 , l 4 , or l 5 as \nits parent. \nAfter updating the matching M  , the algorithm arrives at the perfect matching \nshown for the equality subgraph G h in Figure  25.11.  By  Theorem  25.14,  the  edges  \nin M  form an optimal solution to the original assignment  problem given in the \nmatrix. Here, the weights of edges .l 1 ;r 6 /, .l 2 ;r 4 /, .l 3 ;r 1 /, .l 4 ;r 2 /, .l 5 ;r 3 /, .l 6 ;r 5 /, \nand .l 7 ;r 7 / sum to 65, which is the maximum weight of any matching. \nThe  weight  of the  maximum-weight  matching  equals  the  sum  of all the feasible \nvertex  labels.  These  problems4maximizing  the  weight  of a matching  and  mini-  734  Chapter  25  Matchings  in Bipartite  Graphs  \n(a) 4 10  10  10  2 9 3 r 1 r 2 r 3 r 4 r 5 r 6 r 7 \n6 8 5 12  9 7 2 \n11  9 6 7 9 5 15  \n3 9 6 7 5 6 3 \n2 6 5 3 2 4 2 \n10  8 11  4 11  2 11  \n3 4 5 4 3 6 8 0 2 1 1 0 0 2 \n9 \n11  \n13  \n7 \n4 \n11  \n6 h \nl 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 \nR L r 1 \nr 2 \nr 3 \nr 4 \nr 5 \nr 6 \nr 7 G M,h \n(b) l 2 r 4 l 1 l 5 l 7 \n(c) r 2 r 7 \nl 4 l 3 r 3 l 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 r 6 \nFigure  25.8  Another update to the feasible vertex labeling and directed equality subgraph G M;h  \nbecause  the  queue  became  empty  before  \u00fbnding  an  M  -augmenting  path.  (a)  With \u0131 D 1, the values \nof l 1 : h, l 2 : h, l 3 : h, l 4 : h, l 5 : h, and l 7 : h decrease by 1, and r 2 : h, r 3 : h, r 4 : h, and r 7 : h increase by 1. \nEdge .l 6 ;r 3 / leaves G M;h  , and edges .l 1 ;r 6 /, .l 5 ;r 6 / and .l 7 ;r 6 / enter. (b)  The resulting directed \nequality subgraph G M;h  . (c)  With edge .l 1 ;r 6 / added  to the  breadth-\u00fbrst  forest  and  r 6 unmatched, \nthe search terminates, having found the M  -augmenting  path  h.l 5 ;r 3 /;.r  3 ;l 1 /;.l  1 ;r 6 /i, highlighted \nin orange in parts (b) and (c). \nmizing  the  sum  of the  feasible  vertex  labels4are  <duals=  of each other, in a similar \nvein  to how  the  value  of a maximum  \u00fcow  equals  the  capacity  of a minimum cut. \nSection  29.3  explores  duality  in more  depth.  \nThe  Hungarian  algorithm  \nThe procedure H UNGARIAN  on  page  737  and  its  subroutine  FIND-AUGMENTING - \nPATH on  page  738  follow  the  steps  we  have  just  seen.  The  third  prope rty in \nLemma  25.15  ensures  that  in line  23  of FIND-AUGMENTING -PATH the queue Q \nis nonempty. The pseudocode uses the attribute \ufffd to indicate  predecessor  ver-  \ntices  in the  breadth-\u00fbrst  forest.  Instead  of coloring  vertices,  as in the  BFS  proce-  \ndure  on  page  556,  the  search  puts  the  discovered  vertices  into the sets F L and F R . \nBecause  the  Hungarian  algorithm  does  not  need  breadth-\u00fbrst  distances,  the  pseu-  \ndocode omits the d attribute computed by the BFS procedure. 25.3  The  Hungarian  algorithm  for  the  assignment  problem  735  \nR L r 1 \nr 2 \nr 4 \nr 5 \nr 7 G M,h \n(a) l 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 r 3 \nr 6 l 1 \nl 2 l 5 r 3 l 3 l 7 \n(h) r 6 \nl 1 r 7 \nr 4 \nl 4 r 2 l 7 \n(b) l 7 \nr 6 r 7 \n(c) \nl 3 l 7 \nr 6 \nl 1 r 7 \n(d) \nr 3 l 3 l 7 \nr 6 \nl 1 r 7 \nr 4 \n(e) \nl 2 l 5 r 3 l 3 l 7 \nr 6 \nl 1 r 7 \nr 4 \n(f) l 2 l 5 r 3 l 3 l 7 \nr 6 \nl 1 r 7 \nr 4 \nr 2 \n(g) \nFigure  25.9  (a)  The new matching M  and the new directed equality subgraph G M;h  after  up-  \ndating  the  matching  in Figure  25.8  with  the  M  -augmenting  path  in Figure  25.8  parts  (b)  and  (c).  \n(b)\u2013(h)  Successive  versions  of the  breadth-\u00fbrst  forest  F in a new  breadth-\u00fbrst  search  with  root  l 7 . \nAfter the vertex l 4 in part (h) has been removed from the queue, the qu eue becomes empty before \nthe search discovers an unmatched vertex in R. \nNow,  let\u2019s  see  why  the  Hungarian  algorithm  runs  in O.n  4 / time, where jV j D  \nn=2  and jEj D  n 2 in the original graph G. (Below we outline how to reduce the \nrunning time to O.n  3 /.) You can go through the pseudocode of H UNGARIAN  to \nverify  that  lines  136  and  11  take  O.n  2 / time. The while  loop  of lines  7310  iterates  \nat most n times, since each iteration increases the size of t he matching M  by 1. \nEach  test  in line  7 can  take  constant  time  by  just  checking  whether jM  j <n, each \nupdate of M  in line 9 takes O.n/  time,  and  the  updates  in line  10  take  O.n  2 / time. \nTo achieve the O.n  4 / time bound, it remains to show that each call of F IND- \nAUGMENTING -PATH runs in O.n  3 / time.  Let\u2019s  call  each  execution  of lines  10322  736  Chapter  25  Matchings  in Bipartite  Graphs  \nR L r 1 \nr 2 \nr 4 \nr 5 \nr 7 G M,h \n(b) l 2 \nl 6 \nl 7 r 3 \nr 6 l 1 \nl 2 l 5 r 3 l 3 l 7 \n(c) r 6 \nl 1 r 7 \nr 4 \nl 4 r 2 (a) 4 10  10  10  2 9 3 r 1 r 2 r 3 r 4 r 5 r 6 r 7 \n6 8 5 12  9 7 2 \n11  9 6 7 9 5 15  \n3 9 6 7 5 6 3 \n2 6 5 3 2 4 2 \n10  8 11  4 11  2 11  \n3 4 5 4 3 6 8 0 4 3 3 0 2 4 \n7 \n9 \n11  \n5 \n2 \n11  \n4 h \nl 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 \nl 5 l 3 \nr 1 l 4 \nFigure  25.10  Updating the feasible vertex labeling and directed equality subgraph G M;h  . (a)  Here, \n\u0131 D 2, so the values of l 1 : h, l 2 : h, l 3 : h, l 4 : h, l 5 : h, and l 7 : h decreased by 2, and the values of r 2 : h, \nr 3 : h, r 4 : h, r 6 : h, and r 7 : h increased by 2. Edges .l 2 ;r 5 /, .l 3 ;r 1 /, .l 4 ;r 5 /, .l 5 ;r 1 /, and .l 5 ;r 5 / \nenter G M;h  . (b)  The resulting directed graph G M;h  . (c)  With edge .l 3 ;r 1 / added  to the  breadth-  \n\u00fbrst  forest  and  r 1 unmatched, the search terminates, having found the M  -augmenting  path  h.l 7 ;r 7 /; \n.r 7 ;l 3 /;.l  3 ;r 1 /i, highlighted in orange in parts (b) and (c). \na growth  step. Ignoring the growth steps, you can verify that F IND-AUGMENTING - \nPATH is a breadth-\u00fbrst  search.  With  the  sets  F L and F R represented appropriately, \nthe  breadth-\u00fbrst  search  takes  O.V  C E/  D O.n  2 / time. Within a call of F IND- \nAUGMENTING -PATH, at most n growth steps can occur, since each growth step is \nguaranteed to discover at least one vertex in R. Since there are at most n 2 edges \nin G M;h  , the for  loop  of lines  16322  iterates  at most  n 2 times per call of F IND- \nAUGMENTING -PATH. The  bottleneck  is lines  10  and  15,  which  take  O.n  2 / time, \nso that F IND-AUGMENTING -PATH takes O.n  3 / time. \nExercise  25.3-5  asks  you  to show  that  reconstructing  the  directed  equality  sub-  \ngraph G M;h  in line  15  is actually  unnecessary,  so that  its  cost  can  be eliminated.  Re-  \nducing the cost of computing \u0131 in line  10  to O.n/  takes a little more effort and is the \nsubject  of Problem  25-2.  With  these  changes,  each  call  of FIND-AUGMENTING - \nPATH takes O.n  2 / time, so that the Hungarian algorithm runs in O.n  3 / time. 25.3  The  Hungarian  algorithm  for  the  assignment  problem  737  \nR L G h \n(b) (a) 4 10  10  10  2 9 3 r 1 r 2 r 3 r 4 r 5 r 6 r 7 \n6 8 5 12  9 7 2 \n11  9 6 7 9 5 15  \n3 9 6 7 5 6 3 \n2 6 5 3 2 4 2 \n10  8 11  4 11  2 11  \n3 4 5 4 3 6 8 0 4 3 3 0 2 4 \n7 \n9 \n11  \n5 \n2 \n11  \n4 h \nl 1 \nl 2 \nl 3 \nl 4 \nl 5 \nl 6 \nl 7 r 2 \nr 4 \nr 5 \nr 7 l 2 \nl 6 \nl 7 r 3 \nr 6 l 1 \nl 5 l 3 r 1 \nl 4 \nFigure  25.11  The  \u00fbnal  matching,  shown  for  the  equality  subgraph  G h with blue edges and blue \nentries in the matrix. The weights of the edges in the matching sum to 65, which is the maximum for \nany matching in the original complete bipartite gra ph G, as well  as the  sum  of all  the  \u00fbnal  feasible  \nvertex labels. \nHUNGARIAN.G/  \n1 for  each vertex l 2 L \n2 l: h D max fw.l;r/  W r 2 Rg / / from  equation  (25.1)  \n3 for  each vertex r 2 R \n4 r: h D 0 / / from  equation  (25.2)  \n5 let M  be any matching in G h (such as the matching returned by \nGREEDY-BIPARTITE-MATCHING ) \n6 from G, M  , and h, form the equality subgraph G h \nand the directed equality subgraph G M;h  \n7 while  M  is not a perfect matching in G h \n8 P D FIND-AUGMENTING -PATH .G  M;h  / \n9 M  D M  \u02da P \n10  update the equality subgraph G h \nand the directed equality subgraph G M;h  \n11  return  M  738  Chapter  25  Matchings  in Bipartite  Graphs  \nFIND-AUGMENTING -PATH .G  M;h  / \n1 Q D ;  \n2 F L D ;  \n3 F R D ;  \n4 for  each unmatched vertex l 2 L \n5 l:\ufffd  D NIL \n6 ENQUEUE.Q;l/  \n7 F L D F L [ fl g / / forest F starts with unmatched vertices in L \n8 repeat  \n9 if Q is empty / / ran  out  of vertices  to search  from?  \n10  \u0131 D min fl: h C r: h \ue003 w.l;r/  W l 2 F L and r 2 R \ue003 F R g \n11  for  each vertex l 2 F L \n12  l: h D l: h \ue003 \u0131 / / relabel  according  to equation  (25.5)  \n13  for  each vertex r 2 F R \n14  r: h D r: h C \u0131 / / relabel  according  to equation  (25.5)  \n15  from G, M  , and h, form a new directed equality graph G M;h  \n16  for  each new edge .l;r/  in G M;h  / / continue search with new edges \n17  if r \u2026 F R \n18  r:\ufffd  D l / / discover r , add it to F \n19  if r is unmatched \n20 an M  -augmenting  path  has  been  found  \n(exit the repeat  loop) \n21  else  ENQUEUE.Q;r/  / / can search from r later \n22 F R D F R [ fr g \n23  u D DEQUEUE.Q/  / / search from u \n24  for  each neighbor v of u in G M;h  \n25  if v 2 L \n26  v:\ufffd  D u \n27  F L D F L [ fvg / / discover v, add it to F \n28  ENQUEUE.Q;v/  / / can search from v later \n29 elseif  v \u2026 F R / / v 2 R, do  same  as lines  18322  \n30  v:\ufffd  D u \n31  if v is unmatched \n32  an M  -augmenting  path  has  been  found  \n(exit the repeat  loop) \n33  else  ENQUEUE.Q;v/  \n34  F R D F R [ fvg \n35  until  an M  -augmenting  path  has  been  found  \n36  using the predecessor attributes \ufffd , construct an M  -augmenting  path  P \nby tracing back from the unmatched vertex in R \n37  return  P 25.3  The  Hungarian  algorithm  for  the  assignment  problem  739  \nExercises  \n25.3-1  \nThe F IND-AUGMENTING -PATH procedure  checks  in two  places  (lines  19  and  31)  \nwhether a vertex it discovers in R is unmatched.  Show  how  to rewrite  the  pseu-  \ndocode so that it checks for an unmatched vertex in  R in only one place. What is \nthe  downside  of doing  so?  \n25.3-2  \nShow  that  for  any  bipartite  graph,  the  GREEDY-BIPARTITE-MATCHING  procedure \non  page  726  returns  a matching  at least  half  the  size  of a maxim um matching. \n25.3-3  \nShow that if an edge .l;r/  belongs to the directed equality subgraph G M;h  but is \nnot a member of G M;h  0 , where h 0 is given  by  equation  (25.5),  then  l 2 L \ue003 F L and \nr 2 F R at the time that h 0 is computed. \n25.3-4  \nAt line 29 in the F IND-AUGMENTING -PATH procedure,  it has  already  been  es-  \ntablished that v 2 R. This line checks to see whether v is already discovered by \ntesting whether v 2 F R . Why  doesn\u2019t  the  procedure  need  to check  whether  v is \nalready discovered for the case when v 2 L, in lines  26328?  \n25.3-5  \nProfessor Hrabosky asserts that the directed equali ty subgraph G M;h  must  be con-  \nstructed and maintained by the Hungarian algorithm,  so that line  6 of HUNGARIAN  \nand  line  15  of FIND-AUGMENTING -PATH are required. Argue that the professor is \nincorrect by showing how to determine whether an ed ge belongs to E M;h  without \nexplicitly constructing G M;h  . \n25.3-6  \nHow  can  you  modify  the  Hungarian  algorithm  to \u00fbnd  a matching  of vertices in L \nto vertices in R that minimizes, rather than maximizes, the sum of t he edge weights \nin the  matching?  \n25.3-7  \nHow can an assignment problem with jLj \u00a4 jRj be modi\u00fbed  so that  the  Hungarian  \nalgorithm  solves  it?  740  Chapter  25  Matchings  in Bipartite  Graphs  \nProblems  \n25-1  Perfect  matchings  in a regular  bipartite  graph  \na. Problem  20-3  asked  about  Euler  tours  in directed  graphs.  Prove  that  a con-  \nnected, undirected  graph G D .V;E/  has  an Euler  tour4a  cycle  traversing  \neach edge exactly once, though it may visit a verte x multiple times4if  and  \nonly if the degree of every vertex in V is even. \nb. Assuming that G is connected, undirected, and every vertex in V has even \ndegree, give an O.E/-time  algorithm  to \u00fbnd  an Euler  tour  of G, as in Prob-  \nlem  20-3(b).  \nc. Exercise  25.1-6  states  that  if G D .V;E/  is a d -regular  bipartite  graph,  then  it \ncontains d disjoint perfect matchings. Suppose that d is an exact power of 2. \nGive  an algorithm  to \u00fbnd  all  d disjoint perfect matchings in a d -regular  bipartite  \ngraph in \u201a.E  lg d/  time. \n25-2  Reducing  the  running  time  of the  Hungarian  algorithm  to O.n  3 / \nIn this problem, you will show how to reduce the ru nning time of the Hungarian \nalgorithm from O.n  4 / to O.n  3 / by showing how to reduce the running time of \nthe F IND-AUGMENTING -PATH procedure from O.n  3 / to O.n  2 /. Exercise  25.3-5  \ndemonstrates  that  line  6 of HUNGARIAN  and  line  15  of FIND-AUGMENTING - \nPATH are unnecessary. Now you will show how to reduce th e running time of \neach  execution  of line  10  in FIND-AUGMENTING -PATH to O.n/ . \nFor each vertex r 2 R \ue003 F R , de\u00fbne  a new  attribute  r:\ufffd  , where \nr:\ufffd  D min fl: h C r: h \ue003 w.l;r/  W l 2 F L g : \nThat is, r:\ufffd  indicates how close r is to being adjacent to some vertex l 2 F L in the \ndirected equality subgraph G m;h  . Initially, before placing any vertices into F L , set \nr:\ufffd  to 1  for all r 2 R. \na. Show how to compute \u0131 in line  10  in O.n/  time, based on the \ufffd attribute. \nb. Show how to update all the \ufffd attributes in O.n/  time after \u0131 has been computed. \nc. Show that updating all the \ufffd attributes when F L changes takes O.n  2 / time per \ncall of F IND-AUGMENTING -PATH. \nd. Conclude that the H UNGARIAN  procedure can be implemented to run in O.n  3 / \ntime. Problems for Chapter 25 741 \n25-3  Other  matching  problems  \nThe  Hungarian  algorithm  \u00fbnds  a maximum-weight  perfect  matc hing in a complete \nbipartite graph. It is possible to use the Hungaria n algorithm to solve problems in \nother graphs by modifying the input graph, running the Hungarian algorithm, and \nthen possibly modifying the output. Show how to sol ve the following matching \nproblems in this manner. \na. Give  an algorithm  to \u00fbnd  a maximum-weight  matching  in a weigh ted bipartite \ngraph that is not necessarily complete and with all  edge weights positive. \nb. Redo part (a), but with edge weights allowed to als o be 0 or negative. \nc. A cycle  cover  in a directed graph, not necessarily bipartite, is a set of edge-  \ndisjoint directed cycles such that each vertex lies  on at most one  cycle.  Given  \nnonnegative edge weights w.u;v/ , let C be the set of edges in a cycle cover, \nand  de\u00fbne  w.C/  D P  \n.u;v/ 2C w.u;v/  to be the  weight  of the  cycle  cover.  Give  \nan algorithm  to \u00fbnd  a maximum-weight  cycle  cover.  \n25-4  Fractional  matchings  \nIt is possible  to de\u00fbne  a fractional  matching. Given  a graph  G D .V;E/, we  de\u00fbne  \na fractional matching x as a function x W E !  \u01520; 1\ufffd  (real numbers between 0 and 1, \ninclusive) such that for every vertex u 2 V , we have P  \n.u;v/ 2E x.u;v/  \u0dc4 1. The \nvalue of a fractional matching is P  \n.u;v/ 2E x.u;v/. The  de\u00fbnition  of a fractional  \nmatching is identical to that of a matching, except  that a matching has the additional \nconstraint that x.u;v/  2 f0;1g for all edges .u;v/  2 E. Given  a graph,  we  let  M  \ue003 \ndenote a maximum matching and x \ue003 denote a fractional matching with maximum \nvalue. \na. Argue that, for any bipartite graph, we must have P  \n.u;v/ 2E x \ue003 .u;v/  \ue004 jM  \ue003 j. \nb. Prove that, for any bipartite graph, we must have P  \n.u;v/ 2E x \ue003 .e/  \u0dc4 jM  \ue003 j. \n(Hint: Give  an algorithm  that  converts  a fractional  matching  with  an integer \nvalue to a matching.) Conclude that the maximum val ue of a fractional  match-  \ning in a bipartite graph is the same as the size of  the maximum cardinality \nmatching. \nc. We  can  de\u00fbne  a fractional  matching  in a weighted  graph  in the  same manner: \nthe value of the matching is now P  \n.u;v/ 2E w.u;v/x.u;v/ . Extend the results \nof the previous parts to show that in a weighted bi partite graph, the maximum \nvalue of a weighted fractional matching is equal to  the value of a maximum \nweighted matching. 742  Chapter  25  Matchings  in Bipartite  Graphs  \nd. In a general graph, the analogous results do not ne cessarily hold.  Give  an ex-  \nample of a small graph that is not bipartite for wh ich the fractional matching \nwith maximum value is not a maximum matching. \n25-5  Computing  vertex  labels  \nYou are given a complete bipartite graph G D .V;E/  with edge weights w.l;r/  \nfor all .l;r/  2 E. You  are  also  given  a maximum-weight  perfect  matching  M  \ue003 \nfor G. You wish to compute a feasible vertex labeling h such that M  \ue003 is a perfect \nmatching in the equality subgraph G h . That is, you want to compute a labeling h \nof vertices such that \nl: h C r: h \ue004 w.l;r/  for all l 2 L and r 2 R , (25.6)  \nl: h C r: h D w.l;r/  for all .l;r/  2 M  \ue003 . (25.7)  \n(Requirement  (25.6)  holds  for  all  edges,  and  the  stronger  requirement  (25.7)  holds  \nfor all edges in M  \ue003 .) Give  an algorithm  to compute  the  feasible  vertex  label-  \ning h, and prove that it is correct. ( Hint: Use the similarity between conditions \n(25.6)  and  (25.7)  and  some  of the  properties  of shortest  paths proved in Chapter 22, \nin particular  the  triangle  inequality  (Lemma  22.10)  and  the  convergence property \n(Lemma  22.14.))  \nChapter  notes  \nMatching algorithms have a long history and have be en central to many  break-  \nthroughs in algorithm design and analysis. The book  by Lov\u00b4 asz and Plummer \n[306]  is an excellent  reference  on  matching  problems,  and  the chapter on matching \nin the  book  by  Ahuja,  Magnanti  and  Orlin  [10]  also  has  extensi ve references. \nThe  Hopcroft-Karp  algorithm  is by  Hopcroft  and  Karp  [224].  Madry  [308]  gave  \nan e O.E  10=7  /-time  algorithm,  which  is asymptotically  faster  than  Hopcroft-Karp  \nfor sparse graphs. \nCorollary  25.4  is due  to Berge  [53],  and  it also  holds  in graphs  that  are  not  bi-  \npartite. Matching in general graphs requires more c omplicated algorithms. The \n\u00fbrst  polynomial-time  algorithm,  running  in O.V  4 / time,  is due  to Edmonds  [130]  \n(in  a paper  that  also  introduced  the  notion  of a polynomial-t ime algorithm). Like \nthe bipartite case, this algorithm also uses augmen ting paths,  although  the  algo-  \nrithm  for  \u00fbnding  augmenting  paths  in general  graphs  is more  involved than the one \nfor bipartite graphs. Subsequently, several O.  p \nVE/-time  algorithms  appeared,  \nincluding  ones  by  Gabow  and  Tarjan  [168]  as part  of an algorit hm for weighted \nmatching  and  a simpler  one  by  Gabow  [164].  Notes for Chapter 25 743 \nThe Hungarian algorithm is described in the book by  Bondy and Murty  [67]  \nand  is based  on  work  by  Kuhn  [273]  and  Munkres  [337].  Kuhn  adop ted the name \n<Hungarian algorithm= because the algorithm derived  from work by the Hungarian \nmathematicians  D.  K\u02dd  onig  and  J. Egerv\u00b4  ery.  The  algorithm  is an early example of \na primal-dual  algorithm.  A faster  algorithm  that  runs  in O.  p \nVE  log.VW//  time, \nwhere the edge weights are integers from 0 to W , was  given  by  Gabow  and  Tarjan  \n[167],  and  an algorithm  with  the  same  time  bound  for  maximum- weight matching \nin general  graphs  was  given  by  Duan,  Pettie,  and  Su  [127].  \nThe  stable-marriage  problem  was  \u00fbrst  de\u00fbned  and  analyzed  by  Gale  and  Shapley  \n[169].  The  stable-marriage  problem  has  numerous  variants.  The  books  by  Gus\u00fbeld  \nand  Irving  [203],  Knuth  [266],  and  Manlove  [313]  serve  as excellent sources for \ncataloging and solving them. Part  VII  Selected  Topics  Introduction  \nThis part contains a selection of algorithmic topic s that extend and complement \nearlier material in this book. Some chapters introd uce new models of computation \nsuch  as circuits  or parallel  computers.  Others  cover  specia lized domains such as \nmatrices or number theory. The last two chapters di scuss some of the  known  lim-  \nitations  to the  design  of ef\u00fbcient  algorithms  and  introduce  techniques for coping \nwith those limitations. \nChapter  26  presents  an algorithmic  model  for  parallel  computing  based  on  task-  \nparallel  computing,  and  more  speci\u00fbcally,  fork-join  parallelism.  The  chapter  in-  \ntroduces the basics of the model, showing how to qu antify parallelism in terms of \nthe measures of work and span. It then investigates  several interesting  fork-join  \nalgorithms, including algorithms for matrix multipl ication and merge sorting. \nAn algorithm that receives its input over time, rat her than having the entire input \navailable at the start, is called an <online= algor ithm. Chapter  27  examines  tech-  \nniques used in online algorithms, starting with the  <toy= problem of how long to \nwait for an elevator before taking the stairs. It t hen studies the  <move-to-front=  \nheuristic  for  maintaining  a linked  list  and  \u00fbnishes  with  the  online version of the \ncaching  problem  we  saw  back  in Section  15.4.  The  analyses  of these  online  al-  \ngorithms are remarkable in that they prove that the se algorithms, which do not \nknow their future inputs, perform within a constant  factor of optimal algorithms \nthat know the future inputs. \nChapter  28  studies  ef\u00fbcient  algorithms  for  operating  on  matrices. It presents \ntwo  general  methods4LU  decomposition  and  LUP  decomposition4for  solving  \nlinear  equations  by  Gaussian  elimination  in O.n  3 / time. It also shows that matrix \ninversion and matrix multiplication can be performe d equally fast. The chapter \nconcludes  by  showing  how  to compute  a least-squares  approxi mate solution when \na set of linear equations has no exact solution. 746  Part  VII  Selected  Topics  \nChapter 29 studies how to model problems as linear programs, where the goal \nis to maximize or minimize an objective, given limi ted resources and competing \nconstraints. Linear programming arises in a variety  of practical application areas. \nThe chapter also addresses the concept of <duality=  which, by establishing that a \nmaximization problem and minimization problem have the same objective value, \nhelps to show that solutions to each are optimal. \nChapter  30  studies  operations  on  polynomials  and  shows  how  to use  a well-  \nknown  signal-processing  technique4the  fast  Fourier  transform  (FFT)4to  multi-  \nply  two  degree-n polynomials in O.n  lg n/ time. It also derives a parallel circuit to \ncompute the FFT. \nChapter  31  presents  number-theoretic  algorithms.  After  reviewing elementary \nnumber  theory,  it presents  Euclid\u2019s  algorithm  for  computing  greatest  common  di-  \nvisors. Next, it studies algorithms for solving mod ular linear equations and for \nraising one number to a power modulo another number . Then, it explores  an impor-  \ntant  application  of number-theoretic  algorithms:  the  RSA  public-key  cryptosystem.  \nThis cryptosystem can be used not only to encrypt m essages so that an adversary \ncannot read them, but also to provide digital signa tures. The chapter  \u00fbnishes  with  \nthe  Miller-Rabin  randomized  primality  test,  which  enables  \u00fbnding  large  primes  \nef\u00fbciently4an  essential  requirement  for  the  RSA  system.  \nChapter  32  studies  the  problem  of \u00fbnding  all  occurrences  of a given pattern \nstring in a given text string, a problem that arise s frequently in text-editing  pro-  \ngrams. After examining the naive approach, the chap ter presents  an elegant  ap-  \nproach  due  to Rabin  and  Karp.  Then,  after  showing  an ef\u00fbcient  solution based \non  \u00fbnite  automata,  the  chapter  presents  the  Knuth-Morris-P ratt algorithm, which \nmodi\u00fbes  the  automaton-based  algorithm  to save  space  by  cleverly preprocessing \nthe  pattern.  The  chapter  \u00fbnishes  by  studying  suf\u00fbx  arrays,  which  can  not  only  \u00fbnd  \na pattern  in a text  string,  but  can  do  quite  a bit  more,  such  as \u00fbnding the longest \nrepeated  substring  in a text  and  \u00fbnding  the  longest  common  substring appearing in \ntwo texts. \nChapter  33  examines  three  algorithms  within  the  expansive  \u00fbeld of machine \nlearning.  Machine-learning  algorithms  are  designed  to take in vast amounts of \ndata, devise hypotheses about patterns in the data,  and test these hypotheses. The \nchapter starts with k-means  clustering,  which  groups  data  elements  into  k classes \nbased on how similar they are to each other. It the n shows how to use the technique \nof multiplicative weights to make predictions accur ately based on a set of <experts= \nof varying quality. Perhaps surprisingly, even with out knowing which experts are \nreliable and which are not, you can predict almost as accurately as the most reliable \nexpert.  The  chapter  \u00fbnishes  with  gradient  descent,  an optim ization technique that \n\u00fbnds  a local  minimum  value  for  a function.  Gradient  descent  has  many  applica-  \ntions,  including  \u00fbnding  parameter  settings  for  many  machine-learning  models.  Part  VII  Selected  Topics  747 \nChapter  34  concerns  NP-complete  problems.  Many  interestin g computational \nproblems  are  NP-complete,  but  no  polynomial-time  algorithm  is known  for  solv-  \ning any of them. This chapter presents techniques f or determining when a problem \nis NP-complete,  using  them  to prove  several  classic  problems  NP-complete:  de-  \ntermining whether a graph has a hamiltonian cycle ( a cycle that includes every \nvertex),  determining  whether  a boolean  formula  is satis\u00fbab le (whether there exists \nan assignment of boolean values to its variables th at causes the  formula  to eval-  \nuate to TRUE ), and determining whether a given set of numbers h as a subset that \nadds up to a given target value. The chapter also p roves that the famous  traveling-  \nsalesperson  problem  (\u00fbnd  a shortest  route  that  starts  and  ends at the same location \nand  visits  each  of a set  of locations  once)  is NP-complete.  \nChapter  35  shows  how  to \u00fbnd  approximate  solutions  to NP-comp lete problems \nef\u00fbciently  by  using  approximation  algorithms.  For  some  NP-complete problems, \napproximate solutions that are near optimal are qui te easy to produce,  but  for  oth-  \ners even the best approximation algorithms known wo rk progressively more poorly \nas the problem size increases. Then, there are some  problems for which investing \nincreasing amounts of computation time yields incre asingly better  approximate  so-  \nlutions. This chapter illustrates these possibiliti es with the  vertex-cover  problem  \n(unweighted and weighted versions), an optimization  version  of 3-CNF  satis\u00fbabil-  \nity,  the  traveling-salesperson  problem,  the  set-covering  problem,  and  the  subset-  \nsum problem. 26  Parallel  Algorithms  \nThe vast majority of algorithms in this book are serial  algorithms  suitable  for  run-  \nning on a uniprocessor computer that executes only one instruction at a time. This \nchapter extends our algorithmic model to encompass parallel  algorithms , where \nmultiple  instructions  can  execute  simultaneously.  Speci\u00fbcally,  we\u2019ll  explore  the  \nelegant  model  of task-parallel  algorithms,  which  are  amenable  to algorithmic  de-  \nsign  and  analysis.  Our  study  focuses  on  fork-join  parallel  algorithms, the most \nbasic  and  best  understood  kind  of task-parallel  algorithm.  Fork-join  parallel  al-  \ngorithms can be expressed cleanly using simple ling uistic extensions to ordinary \nserial  code.  Moreover,  they  can  be implemented  ef\u00fbciently  in practice. \nParallel  computers4computers  with  multiple  processing  units4are  ubiquitous.  \nHandheld, laptop, desktop, and cloud machines are a ll multicore  computers , or \nsimply, multicores , containing multiple processing <cores.= Each proc essing core \nis a full-\u00fcedged  processor  that  can  directly  access  any  location in a common shared  \nmemory . Multicores can be aggregated into larger systems,  such as clusters, by \nusing a network to interconnect them. These multico re clusters usually have a dis-  \ntributed  memory, where  one  multicore\u2019s  memory  cannot  be accessed  directly  by a \nprocessor in another multicore. Instead, the proces sor must explicitly  send  a mes-  \nsage over the cluster network to a processor in the  remote multicore to request any \ndata it requires. The most powerful clusters are su percomputers, comprising many \nthousands  of multicores.  But  since  shared-memory  programming  tends  to be con-  \nceptually  easier  than  distributed-memory  programming,  and multicore machines \nare widely available, this chapter focuses on paral lel algorithms for multicores. \nOne  approach  to programming  multicores  is thread  parallelism. This  processor-  \ncentric  parallel-programming  model  employs  a software  abstraction of <virtual \nprocessors,= or threads  that share a common memory. Each thread maintains i ts \nown program counter and can execute code independen tly of the other threads. The \noperating system loads a thread onto a processing c ore for execution and switches \nit out when another thread needs to run. Chapter 26 Parallel Algorithms 749 \nUnfortunately,  programming  a shared-memory  parallel  comp uter using threads \ntends  to be dif\u00fbcult  and  error-prone.  One  reason  is that  it can be complicated \nto dynamically partition the work among the threads  so that each thread receives \napproximately the same load. For any but the simple st of applications,  the  pro-  \ngrammer must use complex communication protocols to  implement a scheduler \nthat  load-balances  the  work.  \nTask-parallel  programming  \nThe  dif\u00fbculty  of thread  programming  has  led  to the  creation  of task-parallel  plat-  \nforms , which provide a layer of software on top of threa ds to coordinate, schedule, \nand  manage  the  processors  of a multicore.  Some  task-paralle l platforms are built as \nruntime  libraries,  but  others  provide  full-\u00fcedged  paralle l languages with compiler \nand runtime support. \nTask-parallel  programming  allows  parallelism  to be speci\u00fbed  in a <processor-  \noblivious=  fashion,  where  the  programmer  identi\u00fbes  what  computational tasks may \nrun in parallel but does not indicate which thread or processor performs the task. \nThus, the programmer is freed from worrying about c ommunication protocols, load \nbalancing, and other vagaries of thread programming . The task-parallel  platform  \ncontains  a scheduler,  which  automatically  load-balances  the  tasks  across  the  pro-  \ncessors,  thereby  greatly  simplifying  the  programmer\u2019s  chore. Task-parallel  algo-  \nrithms  provide a natural extension to ordinary serial algo rithms, allowing  perfor-  \nmance to be reasoned about mathematically using <wo rk/span analysis.= \nFork-join  parallelism  \nAlthough  the  functionality  of task-parallel  environments  is still  evolving  and  in-  \ncreasing, almost all support fork-join  parallelism , which is typically embodied \nin two linguistic features: spawning  and parallel  loops. Spawning  allows  a sub-  \nroutine to be <forked=: executed like a subroutine call, except that the caller can \ncontinue to execute while the spawned subroutine co mputes its result. A parallel \nloop is like an ordinary for  loop, except that multiple iterations of the loop c an \nexecute at the same time. \nFork-join  parallel algorithms employ spawning and parallel lo ops to describe \nparallelism. A key aspect of this parallel model, i nherited from  the  task-parallel  \nmodel but different from the thread model, is that the programmer does not specify \nwhich tasks in a computation must  run in parallel, only which tasks may  run in \nparallel. The underlying runtime system uses thread s to load-balance  the  tasks  \nacross the processors. This chapter investigates pa rallel algorithms described in \nthe  fork-join  model,  as well  as how  the  underlying  runtime  system can schedule \ntask-parallel  computations  (which  include  fork-join  computations)  ef\u00fbciently.  750 Chapter 26 Parallel Algorithms \nFork-join  parallelism  offers  several  important  advantage s: \n\ue001 The  fork-join  programming  model  is a simple  extension  of the  familiar serial \nprogramming model used in most of this book. To des cribe a fork-join  par-  \nallel algorithm, the pseudocode in this book needs just three added keywords: \nparallel , spawn , and sync . Deleting these parallel keywords from the paralle l \npseudocode results in ordinary serial pseudocode fo r the same problem, which \nwe call the <serial projection= of the parallel alg orithm. \n\ue001 The  underlying  task-parallel  model  provides  a theoretically  clean  way  to quan-  \ntify parallelism based on the notions of <work= and  <span.= \n\ue001 Spawning  allows  many  divide-and-conquer  algorithms  to be parallelized  natu-  \nrally.  Moreover,  just  as serial  divide-and-conquer  algori thms lend themselves \nto analysis using recurrences, so do parallel algor ithms in the  fork-join  model.  \n\ue001 The  fork-join  programming  model  is faithful  to how  multicor e programming \nhas been evolving in practice. A growing number of multicore environments \nsupport  one  variant  or another  of fork-join  parallel  progra mming, including \nCilk  [290,  291,  383,  396],  Habanero-Java  [466],  the  Java  Fork-Join  Framework  \n[279],  OpenMP  [81],  Task  Parallel  Library  [289],  Threading  Building Blocks \n[376],  and  X10  [82].  \nSection  26.1  introduces  parallel  pseudocode,  shows  how  the  execution  of a task-  \nparallel computation can be modeled as a directed a cyclic graph, and presents the \nmetrics of work, span, and parallelism, which you c an use to analyze  parallel  al-  \ngorithms.  Section  26.2  investigates  how  to multiply  matrices  in parallel,  and  Sec-  \ntion  26.3  tackles  the  tougher  problem  of designing  an ef\u00fbcie nt parallel merge sort. \n26.1  The  basics  of fork-join  parallelism  \nOur  exploration  of parallel  programming  begins  with  the  problem of computing \nFibonacci  numbers  recursively  in parallel.  We\u2019ll  look  at a straightforward serial \nFibonacci  calculation,  which,  although  inef\u00fbcient,  serve s as a good illustration of \nhow to express parallelism in pseudocode. \nRecall  that  the  Fibonacci  numbers  are  de\u00fbned  by  equation  (3.31)  on  page  69:  \nF i D \u0128 \n0 if i D 0;  \n1 if i D 1;  \nF i \ue0021 C F i \ue0022 if i \ue004 2:  \nTo calculate the nth Fibonacci number recursively, you could use the ordinary serial \nalgorithm in the procedure F IB on the facing page. You would not really want to 26.1  The  basics  of fork-join  parallelism  751 \ncompute large Fibonacci numbers this way, because t his computation does needless \nrepeated work, but parallelizing it can be instruct ive. \nFIB.n/  \n1 if n \u0dc4 1 \n2 return  n \n3 else  x D FIB.n \ue003 1/ \n4 y D FIB.n \ue003 2/ \n5 return  x C y \nTo analyze this algorithm, let T.n/  denote the running time of F IB.n/. Since \nFIB.n/  contains two recursive calls plus a constant amount  of extra work, we obtain \nthe recurrence \nT.n/  D T.n  \ue003 1/ C T.n  \ue003 2/ C \u201a.1/:  \nThis recurrence has solution T.n/  D \u201a.F  n /, which we can establish by using the \nsubstitution  method  (see  Section  4.3).  To  show  that  T.n/  D O.F  n /, we\u2019ll  adopt  the  \ninductive hypothesis that T.n/  \u0dc4 aF  n \ue003 b, where a>1  and b>0  are constants. \nSubstituting, we obtain \nT.n/  \u0dc4 .aF  n\ue0021 \ue003 b/ C .aF  n\ue0022 \ue003 b/ C \u201a.1/  \nD a.F  n\ue0021 C F n\ue0022 / \ue003 2b  C \u201a.1/  \n\u0dc4 aF  n \ue003 b;  \nif we choose b large  enough  to dominate  the  upper-bound  constant  in the  \u201a.1/  \nterm. We can then choose a large  enough  to upper-bound  the  \u201a.1/  base case \nfor small n. To show that T.n/  D \ufffd.F  n /, we use the inductive hypothesis \nT.n/  \ue004 aF  n \ue003 b. Substituting and following reasoning similar to t he asymptotic \nupper-bound  argument,  we  establish  this  hypothesis  by  choo sing b smaller than \nthe  lower-bound  constant  in the  \u201a.1/  term and a small  enough  to lower-bound  \nthe \u201a.1/  base case for small n. Theorem  3.1  on  page  56  then  establishes  that  \nT.n/  D \u201a.F  n /, as desired. Since F n D \u201a.\ufffd  n /, where \ufffd D .1 C p \n5/=2  is the \ngolden  ratio,  by  equation  (3.34)  on  page  69,  it follows  that  \nT.n/  D \u201a.\ufffd  n /: (26.1)  \nThus this procedure is a particularly slow way to c ompute Fibonacci numbers, \nsince  it runs  in exponential  time.  (See  Problem  31-3  on  page  954  for  faster  ways.)  \nLet\u2019s  see  why  the  algorithm  is inef\u00fbcient.  Figure  26.1  shows  the tree of recursive \nprocedure instances created when computing F 6 with the F IB procedure. The call \nto F IB.6/  recursively calls F IB.5/  and then F IB.4/. But, the call to F IB.5/  also 752 Chapter 26 Parallel Algorithms \nFIB.0/  \nFIB.0/  FIB.0/  FIB.0/  \nFIB.0/  FIB.1/  FIB.1/  \nFIB.1/  FIB.1/  \nFIB.1/  FIB.1/  FIB.1/  \nFIB.1/  FIB.2/  \nFIB.2/  FIB.2/  FIB.2/  \nFIB.2/  FIB.3/  FIB.3/  \nFIB.3/  FIB.4/  \nFIB.4/  FIB.5/  FIB.6/  \nFigure  26.1  The invocation tree for F IB.6/. Each node in the tree represents a procedure inst ance \nwhose children are the procedure instances it calls  during its execution. Since each instance of F IB \nwith the same argument does the same work to produc e the same r esult,  the  inef\u00fbciency  of this  \nalgorithm for computing the Fibonacci numbers can b e seen by the vast number of repeated calls \nto compute the same thing. The portion of the tree shaded blue appears  in task-parallel  form  in \nFigure  26.2.  \nresults in a call to F IB.4/. Both instances of F IB.4/  return the same result ( F 4 D 3). \nSince the F IB procedure  does  not  memoize  (recall  the  de\u00fbnition  of <memoiz e= \nfrom  page  368),  the  second  call  to FIB.4/  replicates  the  work  that  the  \u00fbrst  call  \nperforms, which is wasteful. \nAlthough the F IB procedure is a poor way to compute Fibonacci number s, it \ncan help us warm up to parallelism concepts. Perhap s the most basic concept is \nto understand is that if two parallel tasks operate  on entirely different  data,  then4  \nabsent  other  interference4they  each  produce  the  same  outco mes when executed \nat the same time as when they run serially one afte r the other. Within F IB.n/, for \nexample,  the  two  recursive  calls  in line  3 to FIB.n \ue003 1/ and  in line  4 to FIB.n \ue003 2/ \ncan safely execute in parallel because the computat ion performed by one in no way \naffects the other. \nParallel  keywords  \nThe  P-F IB procedure on the next page computes Fibonacci numbe rs, but using the \nparallel  keywords  spawn  and sync  to indicate parallelism in the pseudocode. \nIf the keywords spawn  and sync  are  deleted  from  P-F IB, the  resulting  pseu-  \ndocode text is identical to F IB (other than renaming the procedure in the header 26.1  The  basics  of fork-join  parallelism  753 \nP-F IB.n/  \n1 if n \u0dc4 1 \n2 return  n \n3 else  x D spawn  P-F IB.n \ue003 1/ / / don\u2019t  wait  for  subroutine  to return  \n4 y D P-F IB.n \ue003 2/ / / in parallel with spawned subroutine \n5 sync  / / wait  for  spawned  subroutine  to \u00fbnish  \n6 return  x C y \nand  in the  two  recursive  calls).  We  de\u00fbne  the  serial  projection  1 of a parallel  al-  \ngorithm to be the serial algorithm that results fro m ignoring the parallel directives, \nwhich in this case can be done by omitting the keyw ords spawn  and sync . For \nparallel  for  loops,  which  we\u2019ll  see  later  on,  we  omit  the  keyword  parallel . Indeed, \nour parallel pseudocode possesses the elegant prope rty that its serial projection is \nalways ordinary serial pseudocode to solve the same  problem. \nSemantics  of parallel  keywords  \nSpawning  occurs when the keyword spawn  precedes  a procedure  call,  as in line  3 \nof P-F IB. The semantics of a spawn differs from an ordinary  procedure call in \nthat  the  procedure  instance  that  executes  the  spawn4the  parent4may  continue  \nto execute  in parallel  with  the  spawned  subroutine4its  child4instead  of waiting  \nfor  the  child  to \u00fbnish,  as would  happen  in a serial  execution.  In this case, while \nthe  spawned  child  is computing  P-F IB.n \ue003 1/, the parent may go on to compute \nP-F IB.n\ue0032/ in line  4 in parallel  with  the  spawned  child.  Since  the  P-F IB procedure \nis recursive, these two subroutine calls themselves  create nested parallelism, as \ndo their children, thereby creating a potentially v ast tree of subcomputations, all \nexecuting in parallel. \nThe keyword spawn  does not say, however, that a procedure must  execute in \nparallel with its spawned children, only that it may. The parallel keywords express \nthe logical  parallelism  of the  computation,  indicating  which  parts  of the  compu-  \ntation may proceed in parallel. At runtime, it is u p to a scheduler  to determine \nwhich subcomputations actually run in parallel by a ssigning them  to available  pro-  \n1 In mathematics, a projection is an idempotent funct ion, that is, a function f such that f \u0131 f D f . \nIn this case, the function f maps the set P of fork-join  programs  to the  set  P S \ue00a P of serial \nprograms,  which  are  themselves  fork-join  programs  with  no  parallelism.  For  a fork-join  program  \nx 2 P , since we have f.f.x//  D f.x/, the  serial  projection,  as we  have  de\u00fbned  it, is indeed  a \nmathematical projection. 754 Chapter 26 Parallel Algorithms \ncessors  as the  computation  unfolds.  We\u2019ll  discuss  the  theory  behind  task-parallel  \nschedulers  shortly  (on  page  759).  \nA procedure cannot safely use the values returned b y its spawned  children  un-  \ntil after it executes a sync  statement,  as in line  5. The  keyword  sync  indicates \nthat the procedure must wait as necessary for all i ts spawned children  to \u00fbnish  be-  \nfore proceeding to the statement after the sync4the  <join=  of a fork-join  parallel  \ncomputation.  The  P-F IB procedure requires a sync  before the return  statement \nin line  6 to avoid  the  anomaly  that  would  occur  if x and y were summed before \nP-F IB.n \ue003 1/ had  \u00fbnished  and  its  return  value  had  been  assigned  to x . In addition \nto explicit join synchronization provided by the sync  statement, it is convenient \nto assume that every procedure executes a sync  implicitly before it returns, thus \nensuring  that  all  children  \u00fbnish  before  their  parent  \u00fbnishe s. \nA graph  model  for  parallel  execution  \nIt helps  to view  the  execution  of a parallel  computation4the  dynamic stream of \nruntime instructions executed by processors under t he direction  of a parallel  pro-  \ngram4as  a directed  acyclic  graph  G D .V;E/ , called a (parallel)  trace . 2 Con-  \nceptually, the vertices in V are executed instructions, and the edges in E represent \ndependencies between instructions, where .u;v/  2 E means  that  the  parallel  pro-  \ngram required instruction u to execute before instruction v. \nIt\u2019s  sometimes  inconvenient,  especially  if we  want  to focus  on  the  parallel  struc-  \nture of a computation, for a vertex of a trace to r epresent only one  executed  instruc-  \ntion. Consequently, if a chain of instructions cont ains no parallel or procedural \ncontrol (no spawn , sync , procedure call, or return4via  either  an explicit  return  \nstatement or the return that happens implicitly upo n reaching  the  end  of a proce-  \ndure), we group the entire chain into a single strand. As  an example,  Figure  26.2  \nshows  the  trace  that  results  from  computing  P-F IB.4/  in the  portion  of Figure  26.1  \nshaded blue. Strands do not include instructions th at involve parallel or procedural \ncontrol. These control dependencies must be represe nted as edges in the trace. \nWhen a parent procedure calls a child, the trace co ntains an edge .u;v/  from \nthe strand u in the  parent  that  executes  the  call  to the  \u00fbrst  strand  v of the spawned \nchild,  as illustrated  in Figure  26.2  by  the  edge  from  the  orange  strand  in P-F IB.4/  \nto the  blue  strand  in P-F IB.2/. When the last strand v 0 in the child returns, the trace \ncontains an edge .v 0 ;u  0 / to the strand u 0 , where u 0 is the successor strand of u in \nthe  parent,  as with  the  edge  from  the  white  strand  in P-F IB.2/  to the white strand \nin P-F IB.4/. \n2 Also called a computation  dag  in the literature. 26.1  The  basics  of fork-join  parallelism  755 \nP-FIB(1)  P-FIB(0) P-FIB(3)  P-FIB(4)  \nP-FIB(1)  P-FIB(1)  \nP-FIB(0) P-FIB(2) \nP-FIB(2) \nFigure  26.2  The  trace  of P-F IB.4/  corresponding  to the  shaded  portion  of Figure  26.1.  Each  \ncircle represents one strand, with blue circles rep resenting any instructions executed in the part of \nthe  procedure  (instance)  up  to the  spawn  of P-F IB.n \ue003 1/ in line  3; orange  circles  representing  the  \ninstructions executed in the part of the procedure that calls P-F IB.n \ue003 2/ in line  4 up  to the  sync  in \nline  5, where  it suspends  until  the  spawn  of P-F IB.n \ue003 1/ returns; and white circles representing the \ninstructions executed in the part of the procedure after the sync , where it sums x and y, up to the \npoint where it returns the result. Strands belongin g to the same procedure are grouped into a rounded \nrectangle, blue for spawned procedures and tan for called procedures. Assuming that each strand \ntakes unit time, the work is 17  time units, since there are 17  strands, and the span is 8 time units, \nsince  the  critical  path4shown  with  blue  edges4contains  8 strands. \nWhen the parent spawns a child, however, the trace is a little different. The \nedge .u;v/  goes from parent to child as with a call, such as t he edge from the blue \nstrand  in P-F IB.4/  to the  blue  strand  in P-F IB.3/, but the trace contains another \nedge .u;u  0 / as well, indicating that u\u2019s successor  strand  u 0 can continue to execute \nwhile v is executing.  The  edge  from  the  blue  strand  in P-F IB.4/  to the orange \nstrand  in P-F IB.4/  illustrates one such edge. As with a call, there is  an edge from \nthe last strand v 0 in the child, but with a spawn, it no longer goes t o u\u2019s successor.  \nInstead, the edge is .v 0 ;x/, where x is the strand immediately following the sync  in \nthe  parent  that  ensures  that  the  child  has  \u00fbnished,  as with  the edge from the white \nstrand  in P-F IB.3/  to the  white  strand  in P-F IB.4/. \nYou  can  \u00fbgure  out  what  parallel  control  created  a particular  trace. If a strand \nhas two successors, one of them must have been spaw ned, and if a strand has \nmultiple predecessors, the predecessors joined beca use of a sync  statement. Thus, \nin the general case, the set V forms the set of strands, and the set E of directed \nedges represents dependencies between strands induc ed by parallel and procedural 756 Chapter 26 Parallel Algorithms \ncontrol. If G contains a directed path from strand u to strand v, we say that the \ntwo strands are (logically)  in series . If there is no path in G either from u to v or \nfrom v to u, the strands are (logically)  in parallel . \nA fork-join  parallel  trace  can  be pictured  as a dag  of strands  embedded in an \ninvocation  tree  of procedure  instances.  For  example,  Figure  26.1  shows  the  invo-  \ncation tree for F IB.6/, which  also  serves  as the  invocation  tree  for  P-F IB.6/, the \nedges between procedure instances now representing either calls  or spawns.  Fig-  \nure  26.2  zooms  in on  the  subtree  that  is shaded  blue,  showing  the  strands  that  con-  \nstitute  each  procedure  instance  in P-F IB.4/. All directed edges connecting strands \nrun either within a procedure or along undirected e dges of the invocation tree in \nFigure  26.1.  (More  general  task-parallel  traces  that  are  not  fork-join  traces  may  \ncontain some directed edges that do not run along t he undirected tree edges.) \nOur  analyses  generally  assume  that  parallel  algorithms  execute on an ideal  par-  \nallel  computer , which consists of a set of processors and a sequentially  consistent  \nshared  memory.  To  understand  sequential  consistency,  you  \u00fbrst need to know that \nmemory is accessed by load  instructions , which copy data from a location in the \nmemory to a register within a processor, and by store  instructions , which copy data \nfrom a processor register to a location in the memo ry. A single line of pseudocode \ncan entail several such instructions. For example, the line x D y C \u00b4 could result \nin load instructions to fetch each of y and \u00b4 from  memory  into  a processor,  an in-  \nstruction to add them together inside the processor , and a store instruction to place \nthe result x back into memory. In a parallel computer, several p rocessors might \nneed to load or store at the same time. Sequential consistency means that even if \nmultiple processors attempt to access the memory si multaneously,  the  shared  mem-  \nory behaves as if exactly one instruction from one of the processors is executed at \na time, even though the actual transfer of data may  happen at the same time. It is \nas if the instructions were executed one at a time sequentially according to some \nglobal linear order among all the processors that p reserves the individual orders in \nwhich each processor executes its own instructions.  \nFor  task-parallel  computations,  which  are  scheduled  onto  processors  automati-  \ncally by a runtime system, the sequentially consist ent shared memory behaves as \nif a parallel  computation\u2019s  executed  instructions  were  executed one by one in the \norder  of a topological  sort  (see  Section  20.4)  of its  trace.  That is, you can reason \nabout the execution by imagining that the individua l instructions (not generally the \nstrands, which may aggregate many instructions) are  interleaved in some linear \norder that preserves the partial order of the trace . Depending on scheduling, the \nlinear order could vary from one run of the program  to the next, but the behavior \nof any execution is always as if the instructions e xecuted serially in a linear order \nconsistent with the dependencies within the trace. \nIn addition to making assumptions about semantics, the ideal parallel-computer  \nmodel  makes  some  performance  assumptions.  Speci\u00fbcally,  it assumes that each 26.1  The  basics  of fork-join  parallelism  757 \nprocessor in the machine has equal computing power,  and it ignores the cost of \nscheduling. Although this last assumption may sound  optimistic, it turns out that \nfor  algorithms  with  suf\u00fbcient  <parallelism=  (a term  we\u2019ll  de\u00fbne  precisely  a little  \nlater), the overhead of scheduling is generally min imal in practice. \nPerformance  measures  \nWe  can  gauge  the  theoretical  ef\u00fbciency  of a task-parallel  algorithm using work/  \nspan  analysis , which is based on two metrics: <work= and <span.=  The work  of \na task-parallel  computation  is the  total  time  to execute  the  entire computation on \none processor. In other words, the work is the sum of the times taken by each of \nthe strands. If each strand takes unit time, the wo rk is just the number of vertices \nin the trace. The span  is the fastest possible time to execute the computa tion on an \nunlimited number of processors, which corresponds t o the sum of the times taken \nby the strands along a longest path in the trace, w here <longest= means that each \nstrand is weighted by its execution time. Such a lo ngest path is called the critical  \npath  of the trace, and thus the span is the weight of th e longest (weighted) path \nin the  trace.  (Section  22.2,  pages  6173619  shows  how  to \u00fbnd  a critical path in a \ndag G D .V;E/  in \u201a.V  C E/  time.) For a trace in which each strand takes unit \ntime, the span equals the number of strands on the critical path. For example, the \ntrace  of Figure  26.2  has  17  vertices in all and 8 vertices on its critical path, so that \nif each strand takes unit time, its work is 17  time units and its span is 8 time units. \nThe  actual  running  time  of a task-parallel  computation  depe nds not only on its \nwork and its span, but also on how many processors are available and how the \nscheduler allocates strands to processors. To denot e the running  time  of a task-  \nparallel computation on P processors, we subscript by P . For example, we might \ndenote the running time of an algorithm on P processors by T P . The work is \nthe running time on a single processor, or T 1 . The span is the running time if we \ncould  run  each  strand  on  its  own  processor4in  other  words,  if we had an unlimited \nnumber  of processors4and  so we  denote  the  span  by  T 1  . \nThe work and span provide lower bounds on the runni ng time T P of a task-  \nparallel computation on P processors: \n\ue001 In one step, an ideal parallel computer with P processors can do at most P \nunits of work, and thus in T P time, it can perform at most PT  P work. Since the \ntotal work to do is T 1 , we have PT  P \ue004 T 1 . Dividing by P yields the work  law: \nT P \ue004 T 1 =P  : (26.2)  \n\ue001 A P -processor  ideal  parallel  computer  cannot  run  any  faster  than a machine \nwith an unlimited number of processors. Looked at a nother way, a machine 758 Chapter 26 Parallel Algorithms \nwith an unlimited number of processors can emulate a P -processor  machine  by  \nusing just P of its processors. Thus, the span  law  follows: \nT P \ue004 T 1  : (26.3)  \nWe  de\u00fbne  the  speedup  of a computation on P processors by the ratio T 1 =T  P , \nwhich says how many times faster the computation ru ns on P processors than \non one processor. By the work law, we have T P \ue004 T 1 =P  , which implies that \nT 1 =T  P \u0dc4 P . Thus, the speedup on a P -processor  ideal  parallel  computer  can  be \nat most P . When the speedup is linear in the number of proce ssors, that is, when \nT 1 =T  P D \u201a.P/ , the computation exhibits linear  speedup . Perfect  linear  speedup  \noccurs when T 1 =T  P D P . \nThe ratio T 1 =T  1  of the work to the span gives the parallelism  of the parallel \ncomputation. We can view the parallelism from three  perspectives. As a ratio, the \nparallelism denotes the average amount of work that  can be performed in parallel \nfor each step along the critical path. As an upper bound, the parallelism gives the \nmaximum possible speedup that can be achieved on an y number of processors.  Per-  \nhaps most important, the parallelism provides a lim it on the possibility of attaining \nperfect  linear  speedup.  Speci\u00fbcally,  once  the  number  of processors exceeds the \nparallelism, the computation cannot possibly achiev e perfect linear speedup. To \nsee this last point, suppose that P >T  1 =T  1  , in which case the span law implies \nthat  the  speedup  satis\u00fbes  T 1 =T  P \u0dc4 T 1 =T  1  < P  . Moreover, if the number P of \nprocessors in the ideal parallel computer greatly e xceeds the parallelism4that  is, \nif P \ue007  T 1 =T  1  4then  T 1 =T  P \ue008  P , so that the speedup is much less than the \nnumber of processors. In other words, if the number  of processors exceeds the \nparallelism, adding even more processors makes the speedup less perfect. \nAs  an example,  consider  the  computation  P-F IB.4/  in Figure  26.2,  and  assume  \nthat each strand takes unit time. Since the work is  T 1 D 17  and the span is T 1  D 8, \nthe parallelism is T 1 =T  1  D 17=8  D 2:125 . Consequently, achieving much more \nthan double the performance is impossible, no matte r how many processors execute \nthe  computation.  For  larger  input  sizes,  however,  we\u2019ll  see  that  P-F IB.n/  exhibits \nsubstantial parallelism. \nWe  de\u00fbne  the  (parallel)  slackness  of a task-parallel  computation  executed  on  \nan ideal parallel computer with P processors to be the ratio .T  1 =T  1  /=P  D \nT 1 =.PT  1  /, which is the factor by which the parallelism of t he computat ion  ex-  \nceeds the number of processors in the machine. Rest ating the bounds on speedup, \nif the slackness is less than 1, perfect linear speedup is impossible, because \nT 1 =.PT  1  / < 1  and the span law imply that T 1 =T  P \u0dc4 T 1 =T  1  < P  . Indeed, \nas the slackness decreases from 1 and approaches 0, the  speedup  of the  computa-  \ntion diverges further and further from perfect line ar speedup. If the slackness is \nless than 1, additional parallelism in an algorithm can have a  great impact on its 26.1  The  basics  of fork-join  parallelism  759 \nexecution  ef\u00fbciency.  If the  slackness  is greater  than  1, however,  the  work  per  pro-  \ncessor  is the  limiting  constraint.  We\u2019ll  see  that  as the  slackness increases from 1, a \ngood scheduler can achieve closer and closer to per fect linear speedup. But once \nthe slackness is much greater than 1, the advantage of additional parallelism shows \ndiminishing returns. \nScheduling  \nGood  performance  depends  on  more  than  just  minimizing  the  work and span. The \nstrands  must  also  be scheduled  ef\u00fbciently  onto  the  processors  of the  parallel  ma-  \nchine.  Our  fork-join  parallel-programming  model  provides  no  way  for  a program-  \nmer to specify which strands to execute on which pr ocessors. Instead, we rely on \nthe  runtime  system\u2019s  scheduler  to map  the  dynamically  unfol ding computation to \nindividual processors. In practice, the scheduler m aps the strands to static threads, \nand the operating system schedules the threads on t he processors themselves. But \nthis extra level of indirection is unnecessary for our understanding of scheduling. \nWe can just imagine that the scheduler maps strands  to processors directly. \nA task-parallel  scheduler  must  schedule  the  computation  without  knowing  in ad-  \nvance  when  procedures  will  be spawned  or when  they  will  \u00fbnish4that  is, it must  \noperate online . Moreover, a good scheduler operates in a distribu ted fashion, where \nthe  threads  implementing  the  scheduler  cooperate  to load-b alance the computation. \nProvably good online, distributed schedulers exist,  but analyzing  them  is compli-  \ncated.  Instead,  to keep  our  analysis  simple,  we\u2019ll  consider  an online centralized  \nscheduler that knows the global state of the comput ation at any moment. \nIn particular,  we\u2019ll  analyze  greedy  schedulers , which assign as many strands to \nprocessors as possible in each time step, never lea ving a processor idle if there is \nwork  that  can  be done.  We\u2019ll  classify  each  step  of a greedy  scheduler as follows: \n\ue001 Complete  step: At least P strands are ready  to execute, meaning that all strands \non  which  they  depend  have  \u00fbnished  execution.  A greedy  schedu ler assigns \nany P of the ready strands to the processors, completely utilizing all  the  pro-  \ncessor resources. \n\ue001 Incomplete  step: Fewer than P strands  are  ready  to execute.  A greedy  sched-  \nuler assigns each ready strand to its own processor , leaving some processors \nidle for the step, but executing all the ready stra nds. \nThe work law tells us that the fastest running time  T P that we can hope for \non P processors must be at least T 1 =P  . The span law tells us that the fastest \npossible running time must be at least T 1  . The following theorem shows that \ngreedy scheduling is provably good in that it achie ves the sum of these two lower \nbounds as an upper bound. 760 Chapter 26 Parallel Algorithms \nTheorem  26.1  \nOn  an ideal  parallel  computer  with  P processors, a greedy scheduler executes a \ntask-parallel  computation  with  work  T 1 and span T 1  in time \nT P \u0dc4 T 1 =P  C T 1  : (26.4)  \nProof  Without loss of generality, assume that each strand  takes unit time.  (If  nec-  \nessary,  replace  each  longer  strand  by  a chain  of unit-time  strands.)  We\u2019ll  consider  \ncomplete and incomplete steps separately. \nIn each complete step, the P processors together perform a total of P work. \nThus, if the number of complete steps is k, the total work executing all the complete \nsteps is kP  . Since  the  greedy  scheduler  doesn\u2019t  execute  any  strand  more  than once \nand only T 1 work needs to be performed, it follows that kP  \u0dc4 T 1 , from which we \ncan conclude that the number k of complete steps is at most T 1 =P  . \nNow,  let\u2019s  consider  an incomplete  step.  Let  G be the  trace  for  the  entire  com-  \nputation, let G 0 be the subtrace of G that has yet to be executed at the start of the \nincomplete step, and let G 00 be the  subtrace  remaining  to be executed  after  the  in-  \ncomplete step. Consider the set R of strands that are ready at the beginning of the \nincomplete step, where jRj <P  . By  de\u00fbnition,  if a strand  is ready,  all  its  predeces-  \nsors in trace G have executed. Thus the predecessors of strands in R do not belong \nto G 0 . A longest path in G 0 must necessarily start at a strand in R, since every other \nstrand in G 0 has a predecessor and thus could not start a longes t path. Because the \ngreedy scheduler executes all ready strands during the incomplete step, the strands \nof G 00 are exactly those in G 0 minus the strands in R. Consequently, the length \nof a longest path in G 00 must be 1 less than the length of a longest path in G 0 . In \nother words, every incomplete step decreases the sp an of the trace remaining to be \nexecuted by 1. Hence, the number of incomplete steps can be at m ost T 1  . \nSince each step is either complete or incomplete, t he theorem follows. \nThe following corollary shows that a greedy schedul er always performs well. \nCorollary  26.2  \nThe running time T P of any  task-parallel  computation  scheduled  by  a greedy  sched-  \nuler on a P -processor  ideal  parallel  computer  is within  a factor  of 2 of optimal. \nProof  Let T \ue003 \nP be the running time produced by an optimal schedule r on a machine \nwith P processors, and let T 1 and T 1  be the work and span of the computation, \nrespectively.  Since  the  work  and  span  laws4inequalities  (26.2)  and  (26.3)4give  \nT \ue003 \nP \ue004 max fT 1 =P;T  1  g, Theorem  26.1  implies  that  \nT P \u0dc4 T 1 =P  C T 1  \n\u0dc4 2 \ue001 max fT 1 =P;T  1  g \n\u0dc4 2T  \ue003 \nP : 26.1  The  basics  of fork-join  parallelism  761 \nThe next corollary shows that, in fact, a greedy sc heduler achieves  near-perfect  \nlinear  speedup  on  any  task-parallel  computation  as the  slackness grows. \nCorollary  26.3  \nLet T P be the  running  time  of a task-parallel  computation  produced  by a greedy \nscheduler on an ideal parallel computer with P processors, and let T 1 and T 1  be \nthe work and span of the computation, respectively.  Then, if P \ue008  T 1 =T  1  , or \nequivalently, the parallel slackness is much greate r than 1, we have T P \ue002 T 1 =P  , a \nspeedup of approximately P . \nProof  If we suppose that P \ue008  T 1 =T  1  , then it follows that T 1  \ue008  T 1 =P  , and \nhence  Theorem  26.1  gives  T P \u0dc4 T 1 =P  C T 1  \ue002 T 1 =P  . Since  the  work  law  (26.2)  \ndictates that T P \ue004 T 1 =P  , we conclude that T P \ue002 T 1 =P  , which is a speedup of \nT 1 =T  P \ue002 P . \nThe \ue008  symbol  denotes  <much  less,=  but  how  much  is <much  less=?  As  a rule \nof thumb, a slackness of at least 104that  is, 10  times  more  parallelism  than  pro-  \ncessors4generally  suf\u00fbces  to achieve  good  speedup.  Then,  the span term in the \ngreedy  bound,  inequality  (26.4),  is less  than  10% of the  work-per-processor  term,  \nwhich is good enough for most engineering situation s. For example,  if a computa-  \ntion  runs  on  only  10  or 100  processors,  it doesn\u2019t  make  sense  to value parallelism \nof,  say  1,000,000,  over  parallelism  of 10,000,  even  with  the  factor  of 100  differ-  \nence.  As  Problem  26-2  shows,  sometimes  reducing  extreme  parallelism yields \nalgorithms that are better with respect to other co ncerns and which still scale up \nwell on reasonable numbers of processors. \nAnalyzing  parallel  algorithms  \nWe now have all the tools we need to analyze parall el algorithms using work/span \nanalysis,  allowing  us to bound  an algorithm\u2019s  running  time  on  any  number  of pro-  \ncessors. Analyzing the work is relatively straightf orward, since  it amounts  to noth-  \ning more than analyzing the running time of an ordi nary serial algorithm, namely, \nthe serial projection of the parallel algorithm. Yo u should already be familiar with \nanalyzing work, since that is what most of this tex tbook is about! Analyzing the \nspan  is the  new  thing  that  parallelism  engenders,  but  it\u2019s  generally no harder once \nyou  get  the  hang  of it. Let\u2019s  investigate  the  basic  ideas  using  the  P-F IB program. \nAnalyzing the work T 1 .n/  of P-F IB.n/  poses  no  hurdles,  because  we\u2019ve  already  \ndone  it. The  serial  projection  of P-F IB is effectively the original F IB procedure, \nand hence, we have T 1 .n/  D T.n/  D \u201a.\ufffd  n / from  equation  (26.1).  \nFigure  26.3  illustrates  how  to analyze  the  span.  If two  trace s are joined in series, \ntheir spans add to form the span of their compositi on, whereas if they are joined 762 Chapter 26 Parallel Algorithms \nA \n(a) (b) B A \nB \nWork: T 1 .A  [ B/  D T 1 .A/  C T 1 .B/  \nSpan: T 1  .A  [ B/  D T 1  .A/  C T 1  .B/  Work: T 1 .A  [ B/  D T 1 .A/  C T 1 .B/  \nSpan: T 1  .A  [ B/  D max.T  1  .A/;T  1  .B/) \nFigure  26.3  Series-parallel  composition  of parallel  traces.  (a)  When two traces are joined in series, \nthe work of the composition is the sum of their wor k, and the span of the composition is the sum of \ntheir spans. (b)  When two traces are joined in parallel, the work of  the composition remains the sum \nof their work, but the span of the composition is o nly the maximum of their spans. \nin parallel, the span of their composition is the m aximum of the spans of the two \ntraces.  As  it turns  out,  the  trace  of any  fork-join  parallel  computation can be built \nup  from  single  strands  by  series-parallel  composition.  \nArmed  with  an understanding  of series-parallel  compositio n, we can analyze the \nspan  of P-F IB.n/. The  spawned  call  to P-F IB.n \ue003 1/ in line  3 runs  in parallel  with  \nthe  call  to P-F IB.n \ue003 2/ in line  4. Hence,  we  can  express  the  span  of P-F IB.n/  as \nthe recurrence \nT 1  .n/  D max fT 1  .n \ue003 1/;T  1  .n \ue003 2/g C  \u201a.1/  \nD T 1  .n \ue003 1/ C \u201a.1/;  \nwhich has solution T 1  .n/  D \u201a.n/ . (The second equality above follows from the \n\u00fbrst  because  P-F IB.n \ue003 1/ uses  P-F IB.n \ue003 2/ in its computation, so that the span \nof P-F IB.n \ue003 1/ must  be at least  as large  as the  span  of P-F IB.n \ue003 2/.) \nThe  parallelism  of P-F IB.n/  is T 1 .n/=T  1  .n/  D \u201a.\ufffd  n =n/, which  grows  dramat-  \nically as n gets  large.  Thus,  Corollary  26.3  tells  us that  on  even  the  lar  gest parallel \ncomputers, a modest value for n suf\u00fbces  to achieve  near  perfect  linear  speedup  for  \nP-F IB.n/, because this procedure exhibits considerable para llel slackness. \nParallel  loops  \nMany algorithms contain loops for which all the ite rations can operate in parallel. \nAlthough the spawn  and sync  keywords can be used to parallelize such loops, \nit is more convenient to specify directly that the iterations of such loops can run \nin parallel.  Our  pseudocode  provides  this  functionality  via the parallel  keyword, \nwhich precedes the for  keyword in a for  loop statement. 26.1  The  basics  of fork-join  parallelism  763 \nAs an example, consider the problem of multiplying a square n \ue005 n matrix \nA D .a ij / by an n-vector  x D .x j /. The resulting n-vector  y D .y i / is given \nby the equation \ny i D n X  \nj D1 a ij x j ; \nfor i D 1;2;:::;n. The  P-M AT-VEC procedure  performs  matrix-vector  multipli-  \ncation (actually, y D y C Ax  ) by computing all the entries of y in parallel. The \nparallel  for  keywords  in line  1 of P-M AT-VEC indicate that the n iterations of the \nloop body, which includes a serial for  loop,  may  be run  in parallel.  The  initializa-  \ntion y D 0, if desired, should be performed before calling th e procedure (and can \nbe done with a parallel  for  loop). \nP-M AT-VEC.A;x;y;n/  \n1 parallel  for  i D 1 to n / / parallel loop \n2 for  j D 1 to n / / serial loop \n3 y i D y i C a ij x j \nCompilers  for  fork-join  parallel  programs  can  implement  parallel  for  loops in \nterms of spawn  and sync  by using recursive spawning. For example, for the \nparallel  for  loop  in lines  133,  a compiler  can  generate  the  auxiliary  subroutine \nP-M AT-VEC-RECURSIVE and  call  P-M AT-VEC-RECURSIVE .A;x;y;n;1;n/  in \nthe place where the loop would be in the compiled c ode. As Figu re 26.4  illus-  \ntrates,  this  procedure  recursively  spawns  the  \u00fbrst  half  of the iterations of the loop \nto execute  in parallel  (line  5) with  the  second  half  of the  iterations  (line  6) and  then  \nexecutes a sync  (line  7),  thereby  creating  a binary  tree  of parallel  executi on. Each \nleaf represents a base case, which is the serial for  loop  of lines  233.  \nP-M AT-VEC-RECURSIVE .A;x;y;n;i;i  0 / \n1 if i = = i 0 / / just  one  iteration  to do?  \n2 for  j D 1 to n / / mimic  P-M AT-VEC serial loop \n3 y i D y i C a ij x j \n4 else  mid D b.i C i 0 /=2c / / parallel  divide-and-conquer  \n5 spawn  P-M AT-VEC-RECURSIVE .A;x;y;n;i;  mid/ \n6 P-M AT-VEC-RECURSIVE .A;x;y;n;  mid C 1;i  0 / \n7 sync  \nTo calculate the work T 1 .n/  of P-M AT-VEC on an n \ue005 n matrix, simply compute \nthe running time of its serial projection, which co mes from replacing the parallel  764 Chapter 26 Parallel Algorithms \n1:1  2:2  3:3  4:4  5:5  6:6  7:7  8:8  1:2  3:4  5:6  7:8  1:4  5:8  1:8  \nFigure  26.4  A trace  for  the  computation  of P-M AT-VEC-RECURSIVE.A;x;y;8;1;8/ . The two \nnumbers within each rounded rectangle give the valu es of the last two parameters ( i and i 0 in \nthe procedure header) in the invocation (spawn, in blue, or call, in tan) of the procedure. The \nblue circles represent strands corresponding to the  part of the procedure up to the spawn of \nP-M AT-VEC-RECURSIVE in line  5. The  orange  circles  represent  strands  correspondi ng to the part of \nthe  procedure  that  calls  P-M AT-VEC-RECURSIVE in line  6 up  to the  sync  in line  7, where  it suspends  \nuntil  the  spawned  subroutine  in line  5 returns.  The  white  circles represent strands corresponding to \nthe (negligible) part of the procedure after the sync  up to the point where it returns. \nfor  loop  in line  1 with  an ordinary  for  loop. The running time of the resulting serial \npseudocode is \u201a.n  2 /, which means that T 1 .n/  D \u201a.n  2 /. This analysis seems to \nignore the overhead for recursive spawning in imple menting the parallel loops, \nhowever. Indeed, the overhead of recursive spawning  does increase the work of \na parallel loop compared with that of its serial pr ojection, but not asymptotically. \nTo see why, observe that since the tree of recursiv e procedure instances is a full \nbinary tree, the number of internal nodes is one le ss than the number of leaves \n(see  Exercise  B.5-3  on  page  1175).  Each  internal  node  perfor ms constant work to \ndivide the iteration range, and each leaf correspon ds to a base case, which takes \nat least constant time ( \u201a.n/  time in this case). Thus, by amortizing the overhea d \nof recursive spawning over the work of the iteratio ns in the leaves, we see that the \noverall work increases by at most a constant factor . \nTo  reduce  the  overhead  of recursive  spawning,  task-paralle l platforms sometimes \ncoarsen  the leaves of the recursion by executing several it erations in a single leaf, \neither automatically or under programmer control. T his optimization comes at \nthe expense of reducing the parallelism. If the com putation has  suf\u00fbcient  parallel  \nslackness,  however,  near-perfect  linear  speedup  won\u2019t  be sacri\u00fbced.  26.1  The  basics  of fork-join  parallelism  765 \nAlthough  recursive  spawning  doesn\u2019t  affect  the  work  of a parallel  loop  asymp-  \ntotically, we must take it into account when analyz ing the span. Consider a parallel \nloop with n iterations in which the i th iteration has span iter 1  .i/. Since the depth \nof recursion is logarithmic in the number of iterat ions, the parallel  loop\u2019s  span  is \nT 1  .n/  D \u201a.lg n/ C max fiter 1  .i/  W 1 \u0dc4 i \u0dc4 ng : \nFor  example,  let\u2019s  compute  the  span  of the  doubly  nested  loops  in lines  133  of \nP-M AT-VEC. The span for the parallel  for  loop control is \u201a.lg n/. For  each  it- \neration of the outer parallel loop, the inner seria l for  loop contains n iterations of \nline  3. Since  each  iteration  takes  constant  time,  the  total  span for the inner serial for  \nloop is \u201a.n/ , no matter which iteration of the outer parallel  for  loop  it\u2019s  in.  Thus,  \ntaking the maximum over all iterations of the outer  loop and adding in the \u201a.lg n/ \nfor loop control yields an overall span of T 1  n D \u201a.n/  C \u201a.lg n/ D \u201a.n/  for the \nprocedure. Since the work is \u201a.n  2 /, the parallelism is \u201a.n  2 /=\u201a.n/  D \u201a.n/. (Ex-  \nercise  26.1-7  asks  you  to provide  an implementation  with  even more parallelism.) \nRace  conditions  \nA parallel algorithm is deterministic  if it always does the same thing on the same \ninput, no matter how the instructions are scheduled  on the multicore computer. It \nis nondeterministic  if its behavior might vary from run to run when the  input is the \nsame. A parallel algorithm that is intended to be d eterministic may nevertheless \nact  nondeterministically,  however,  if it contains  a dif\u00fbcult-to-diagnose  bug  called  a \n<determinacy race.= \nFamous  race  bugs  include  the  Therac-25  radiation  therapy  machine, which killed \nthree people and injured several others, and the No rtheast Blackout  of 2003,  which  \nleft  over  50  million  people  in the  United  States  without  powe r. These pernicious \nbugs  are  notoriously  hard  to \u00fbnd.  You  can  run  tests  in the  lab  for days without a \nfailure, only to discover that your software sporad ically crashes  in the  \u00fbeld,  some-  \ntimes with dire consequences. \nA determinacy  race  occurs when two logically parallel instructions acc ess the \nsame memory location and at least one of the instru ctions modi\u00fbes  the  value  stored  \nin the location. The toy procedure R ACE-EXAMPLE on  the  following  page  illus-  \ntrates a determinacy race. After initializing x to 0 in line  1, RACE-EXAMPLE \ncreates two parallel strands, each of which increme nts x in line  3. Although  it \nmight seem that a call of R ACE-EXAMPLE should always print the value 2 (its  se-  \nrial projection certainly does), it could instead p rint the value 1. Let\u2019s  see  how  this  \nanomaly might occur. \nWhen a processor increments x , the operation is not indivisible, but is composed  \nof a sequence of instructions: 766 Chapter 26 Parallel Algorithms \nincr r 1 3 r 1 = x 2 \nx = r 1 7 incr r 2 5 r 2 = x 4 \nx = r 2 6 x = 0 1 \nprint x 8 \n(a) step x r 1 r 2 \n1 \n2 \n3 \n4 \n5 \n6 \n7 0 \n0 \n0 \n0 \n0 \n1 \n1 \u2013 \n0 \n1 \n1 \n1 \n1 \n1 \u2013 \n\u2013 \n\u2013 \n0 \n1 \n1 \n1 \n(b) \nFigure  26.5  Illustration of the determinacy race in R ACE-EXAMPLE . (a)  A trace showing the \ndependencies among individual instructions. The pro cessor registers are r 1 and r 2 . Instructions \nunrelated to the race, such as the implementation o f loop control, are omitted. (b)  An execution \nsequence that elicits the bug, showing the values o f x in memory and registers r 1 and r 2 for each \nstep in the execution sequence. \nRACE-EXAMPLE ./  \n1 x D 0 \n2 parallel  for  i D 1 to 2 \n3 x D x C 1 / / determinacy race \n4 print x \n\ue001 Load x from  memory  into  one  of the  processor\u2019s  registers.  \n\ue001 Increment the value in the register. \n\ue001 Store the value in the register back into x in memory. \nFigure  26.5(a)  illustrates  a trace  representing  the  execut ion of R ACE-EXAMPLE , \nwith the strands broken down to individual instruct ions. Recall that since an ideal \nparallel computer supports sequential consistency, you can view  the  parallel  ex-  \necution of a parallel algorithm as an interleaving of instructions that respects the \ndependencies  in the  trace.  Part  (b)  of the  \u00fbgure  shows  the  values in an execution \nof the computation that elicits the anomaly. The va lue x is kept in memory, and \nr 1 and r 2 are  processor  registers.  In step  1, one  of the  processors  sets x to 0. In \nsteps  2 and  3, processor  1 loads  x from memory into its register r 1 and increments \nit, producing the value 1 in r 1 . At that point, processor 2 comes into the picture , \nexecuting  instructions  436.  Processor  2 loads  x from memory into register r 2 ; in-  \ncrements it, producing the value 1 in r 2 ; and then stores this value into x , setting x \nto 1. Now,  processor  1 resumes  with  step  7, storing  the  value  1 in r 1 into x , which 26.1  The  basics  of fork-join  parallelism  767 \nleaves the value of x unchanged.  Therefore,  step  8 prints  the  value  1, rather than \nthe value 2 that the serial projection would print. \nLet\u2019s  recap  what  happened.  By  sequential  consistency,  the  effect of the parallel \nexecution is as if the executed instructions of the  two processors are interleaved. \nIf processor  1 executes  all  its  instructions  before  process or 2, a trivial interleaving, \nthe value 2 is printed. Conversely, if processor 2 executes all  its instructions before \nprocessor  1, the  value  2 is still printed. When the instructions of the two processors \ninterleave nontrivially, however, it is possible, a s in this example execution, that \none of the updates to x is lost, resulting in the value 1 being printed. \nOf  course,  many  executions  do  not  elicit  the  bug.  That\u2019s  the  problem  with  deter-  \nminacy  races.  Generally,  most  instruction  orderings  produ ce correct results, such \nas any where the instructions on the left branch ex ecute before the instructions \non the right branch, or vice versa. But some orderi ngs generate improper results \nwhen the instructions interleave. Consequently, rac es can be extremely hard to test \nfor. Your program may fail, but you may be unable t o reliably reproduce  the  fail-  \nure in subsequent tests, confounding your attempts to locate the bug in your code \nand  \u00fbx  it. Task-parallel  programming  environments  often  provide  race-detection  \nproductivity tools to help you isolate race bugs. \nMany parallel programs in the real world are intent ionally nondeterministic. \nThey contain determinacy races, but they mitigate t he dangers of nondeterminism \nthrough  the  use  of mutual-exclusion  locks  and  other  methods  of synchronization. \nFor  our  purposes,  however,  we\u2019ll  insist  on  an absence  of determinacy races in the \nalgorithms we develop. Nondeterministic programs ar e indeed interesting,  but  non-  \ndeterministic programming is a more advanced topic and unnecessary for a wide \nswath of interesting parallel algorithms. \nTo ensure that algorithms are deterministic, any tw o strands that  operate  in par-  \nallel should be mutually  noninterfering : they only read, and do not modify, any \nmemory locations accessed by both of them. Conseque ntly, in a parallel  for  con-  \nstruct,  such  as the  outer  loop  of P-M AT-VEC, we want all the iterations of the \nbody, including any code an iteration executes in s ubroutines,  to be mutually  non-  \ninterfering. And between a spawn  and its corresponding sync , we want the code \nexecuted by the spawned child and the code executed  by the parent to be mutually \nnoninterfering, once again including invoked subrou tines. \nAs an example of how easy it is to write code with unintentional races, the \nP-M AT-VEC-WRONG  procedure  on  the  next  page  is a faulty  parallel  implementa-  \ntion  of matrix-vector  multiplication  that  achieves  a span  of \u201a.lg n/ by parallelizing \nthe inner for  loop. This procedure is incorrect, unfortunately, d ue to determinacy \nraces when updating y i in line  3, which  executes  in parallel  for  all  n values of j . \nIndex variables of parallel  for  loops, such as i in line  1 and  j in line 2, do \nnot cause races between iterations. Conceptually, e ach iteration of the loop creates \nan independent variable to hold the index of that i teration during  that  iteration\u2019s  768 Chapter 26 Parallel Algorithms \nP-M AT-VEC-WRONG  .A;x;y;n/  \n1 parallel  for  i D 1 to n \n2 parallel  for  j D 1 to n \n3 y i D y i C a ij x j / / determinacy race \nexecution of the loop body. Even if two parallel it erations both  access  the  same  in-  \ndex variable, they really are accessing different v ariable instances4hence  different  \nmemory  locations4and  no  race  occurs.  \nA parallel algorithm with races can sometimes be de terministic.  As  an exam-  \nple, two parallel threads might store the same valu e into a shared variable, and it \nwouldn\u2019t  matter  which  stored  the  value  \u00fbrst.  For  simplicity  , however, we generally \nprefer code without determinacy races, even if the races are benign. And good \nparallel programmers frown on code with determinacy  races that  cause  nondeter-  \nministic behavior, if deterministic code that perfo rms comparably is an option. \nBut nondeterministic code does have its place. For example, you  can\u2019t  im-  \nplement a parallel hash table, a highly practical d ata structure, without writing \ncode containing determinacy races. Much research ha s centered  around  how  to ex-  \ntend  the  fork-join  model  to incorporate  limited  <structure d= nondeterminism while \navoiding the full measure of complications that ari se when nondeterminism  is com-  \npletely unrestricted. \nA chess  lesson  \nTo illustrate the power of work/span analysis, this  section closes with a true story \nthat  occurred  during  the  development  of one  of the  \u00fbrst  world-class  parallel  chess-  \nplaying  programs  [106]  many  years  ago.  The  timings  below  have  been  simpli\u00fbed  \nfor exposition. \nThe chess program was developed and tested on a 32-processor  computer,  but  it \nwas designed to run on a supercomputer with 512  processors.  Since  the  supercom-  \nputer availability was limited and expensive, the d evelopers ran benchmarks on the \nsmall computer and extrapolated performance to the large computer. \nAt one point, the developers incorporated an optimi zation into the program that \nreduced its running time on an important benchmark on the small machine from \nT 32  D 65  seconds to T 0 \n32  D 40  seconds. Yet, the developers used the work and span  \nperformance measures to conclude that the optimized  version, which was faster \non 32  processors, would actually be slower than the origi nal version on the 512  \nprocessors of the large machine. As a result, they abandoned the <optimization.= \nHere is their work/span analysis. The original vers ion of the program had work \nT 1 D 2048  seconds and span T 1  D 1 second.  Let\u2019s  treat  inequality  (26.4)  on  26.1  The  basics  of fork-join  parallelism  769 \npage  760  as the  equation  T P D T 1 =P  C T 1  , which we can use as an approximation \nto the running time on P processors. Then indeed we have T 32  D 2048=32  C 1 D \n65. With the optimization, the work becomes T 0 \n1 D 1024  seconds, and the span \nbecomes T 0 \n1  D 8 seconds.  Our  approximation  gives  T 0 \n32  D 1024=32  C 8 D 40. \nThe relative speeds of the two versions switch when  we estimate their running \ntimes on 512  processors,  however.  The  \u00fbrst  version  has  a running  time  of T 512  D \n2048=512 C1 D 5 seconds, and the second version runs in T 0 \n512  D 1024=512 C8 D \n10  seconds. The optimization that speeds up the progra m on 32  processors makes \nthe program run for twice as long on 512  processors!  The  optimized  version\u2019s  \nspan of 8, which is not the dominant term in the running tim e on 32  processors, \nbecomes the dominant term on 512  processors, nullifying the advantage from using \nmore processors. The optimization does not scale up . \nThe moral of the story is that work/span analysis, and measurements of work \nand span, can be superior to measured running times  alone in extrapolating an \nalgorithm\u2019s  scalability.  \nExercises  \n26.1-1  \nWhat does a trace for the execution of a serial alg orithm look like?  \n26.1-2  \nSuppose  that  line  4 of P-F IB spawns  P-F IB.n \ue003 2/, rather than calling it as is done \nin the  pseudocode.  How  would  the  trace  of P-F IB(4)  in Figure  26.2  change?  What  \nis the  impact  on  the  asymptotic  work,  span,  and  parallelism?  \n26.1-3  \nDraw  the  trace  that  results  from  executing  P-F IB.5/. Assuming that each strand \nin the computation takes unit time, what are the wo rk, span, and parallelism of \nthe  computation?  Show  how  to schedule  the  trace  on  3 processors using greedy \nscheduling by labeling each strand with the time st ep in which it is executed. \n26.1-4  \nProve that a greedy scheduler achieves the followin g time bound, which is slightly \nstronger  than  the  bound  proved  in Theorem  26.1:  \nT P \u0dc4 T 1 \ue003 T 1  \nP C T 1  : (26.5)  \n26.1-5  \nConstruct a trace for which one execution by a gree dy scheduler can take nearly \ntwice the time of another execution by a greedy sch eduler on the same number of \nprocessors. Describe how the two executions would p roceed. 770 Chapter 26 Parallel Algorithms \n26.1-6  \nProfessor  Karan  measures  her  deterministic  task-parallel  algorithm on 4, 10, and 64  \nprocessors of an ideal parallel computer using a gr eedy scheduler. She claims \nthat the three runs yielded T 4 D 80  seconds, T 10  D 42  seconds, and T 64  D 10  \nseconds. Argue that the professor is either lying o r incompetent. ( Hint: Use the \nwork  law  (26.2),  the  span  law  (26.3),  and  inequality  (26.5)  from  Exercise  26.1-4.)  \n26.1-7  \nGive  a parallel  algorithm  to multiply  an n \ue005 n matrix by an n-vector  that  achieves  \n\u201a.n  2 = lg n/ parallelism while maintaining \u201a.n  2 / work. \n26.1-8  \nAnalyze  the  work,  span,  and  parallelism  of the  procedure  P-TRANSPOSE , which \ntransposes an n \ue005 n matrix A in place. \nP-TRANSPOSE  .A;n/  \n1 parallel  for  j D 2 to n \n2 parallel  for  i D 1 to j \ue003 1 \n3 exchange a ij with a ji  \n26.1-9  \nSuppose that instead of a parallel  for  loop  in line  2, the  P-TRANSPOSE  proce-  \ndure  in Exercise  26.1-8  had  an ordinary  for  loop. Analyze the work, span, and \nparallelism of the resulting algorithm. \n26.1-10  \nFor what number of processors do the two versions o f the chess program run \nequally fast, assuming that T P D T 1 =P  C T 1  ? \n26.2  Parallel  matrix  multiplication  \nIn this  section,  we\u2019ll  explore  how  to parallelize  the  three  matrix-multiplication  al-  \ngorithms  from  Sections  4.1  and  4.2.  We\u2019ll  see  that  each  algorithm  can  be paral-  \nlelized in a straightforward fashion using either p arallel loops  or recursive  spawn-  \ning.  We\u2019ll  analyze  them  using  work/span  analysis,  and  we\u2019ll  see that each parallel \nalgorithm attains the same performance on one proce ssor as its corresponding  se-  \nrial algorithm, while scaling up to large numbers o f processors. 26.2  Parallel  matrix  multiplication  771 \nA parallel  algorithm  for  matrix  multiplication  using  parallel  loops  \nThe  \u00fbrst  algorithm  we\u2019ll  study  is P-M ATRIX-MULTIPLY, which  simply  paral-  \nlelizes the two outer loops in the procedure M ATRIX-MULTIPLY on  page  81.  \nP-M ATRIX-MULTIPLY .A;B;C;n/  \n1 parallel  for  i D 1 to n / / compute entries in each of n rows \n2 parallel  for  j D 1 to n / / compute n entries in row i \n3 for  k D 1 to n \n4 c ij D c ij C a ik  \ue001 b kj  / / add  in another  term  of equation  (4.1)  \nLet\u2019s  analyze  P-M ATRIX-MULTIPLY. Since  the  serial  projection  of the  algo-  \nrithm is just M ATRIX-MULTIPLY , the work is the same as the running time of \nMATRIX-MULTIPLY : T 1 .n/  D \u201a.n  3 /. The span is T 1  .n/  D \u201a.n/, because  it fol-  \nlows a path down the tree of recursion for the parallel  for  loop  starting  in line  1, \nthen down the tree of recursion for the parallel  for  loop starting in line 2, and \nthen executes all n iterations of the ordinary for  loop  starting  in line  3, resulting  \nin a total span of \u201a.lg n/ C \u201a.lg n/ C \u201a.n/  D \u201a.n/ . Thus the parallelism is \n\u201a.n  3 /=\u201a.n/  D \u201a.n  2 /. (Exercise  26.2-3  asks  you  to parallelize  the  inner  loop  to \nobtain a parallelism of \u201a.n  3 = lg n/, which you cannot do straightforwardly using \nparallel  for, because you would create races.) \nA parallel  divide-and-conquer  algorithm  for  matrix  multiplication  \nSection  4.1  shows  how  to multiply  n \ue005 n matrices serially in \u201a.n  3 / time using \na divide-and-conquer  strategy.  Let\u2019s  see  how  to paralleliz e that algorithm using \nrecursive spawning instead of calls. \nThe serial M ATRIX-MULTIPLY-RECURSIVE procedure  on  page  83  takes  as \ninput three n \ue005 n matrices A, B , and C and performs the matrix calculation \nC D C C A \ue001 B by recursively performing eight multiplications of n=2  \ue005 n=2  \nsubmatrices of A and B . The  P-M ATRIX-MULTIPLY-RECURSIVE procedure on \nthe  following  page  implements  the  same  divide-and-conquer  strategy, but it uses \nspawning to perform the eight multiplications in pa rallel. To avoid determinacy \nraces in updating the elements of C , it creates a temporary matrix D to store four \nof the submatrix products. At the end, it adds C and D together to produce the \n\u00fbnal  result.  (Problem  26-2  asks  you  to eliminate  the  tempora ry matrix D at the \nexpense of some parallelism.) \nLines  233  of P-M ATRIX-MULTIPLY-RECURSIVE handle  the  base  case  of mul-  \ntiplying 1 \ue005 1 matrices. The remainder of the procedure deals with  the recursive \ncase.  Line  4 allocates  a temporary  matrix  D, and  lines  537  zero  it. Line  8 parti-  \ntions each of the four matrices A, B , C , and D into n=2  \ue005 n=2  submatrices. (As 772 Chapter 26 Parallel Algorithms \nP-M ATRIX-MULTIPLY-RECURSIVE .A;B;C;n/  \n1 if n = = 1 / / just  one  element  in each  matrix?  \n2 c 11  D c 11  C a 11  \ue001 b 11  \n3 return  \n4 let D be a new n \ue005 n matrix / / temporary matrix \n5 parallel  for  i D 1 to n / / set D D 0 \n6 parallel  for  j D 1 to n \n7 d ij D 0 \n8 partition A, B , C , and D into n=2  \ue005 n=2  submatrices \nA 11  ;A  12  ;A  21  ;A  22  ; B 11  ;B  12  ;B  21  ;B  22  ; C 11  ;C  12  ;C  21  ;C  22  ; \nand D 11  ;D  12  ;D  21  ;D  22  ; respectively \n9 spawn  P-M ATRIX-MULTIPLY-RECURSIVE .A  11  ;B  11  ;C  11  ;n=2/  \n10  spawn  P-M ATRIX-MULTIPLY-RECURSIVE .A  11  ;B  12  ;C  12  ;n=2/  \n11  spawn  P-M ATRIX-MULTIPLY-RECURSIVE .A  21  ;B  11  ;C  21  ;n=2/  \n12  spawn  P-M ATRIX-MULTIPLY-RECURSIVE .A  21  ;B  12  ;C  22  ;n=2/  \n13  spawn  P-M ATRIX-MULTIPLY-RECURSIVE .A  12  ;B  21  ;D  11  ;n=2/  \n14  spawn  P-M ATRIX-MULTIPLY-RECURSIVE .A  12  ;B  22  ;D  12  ;n=2/  \n15  spawn  P-M ATRIX-MULTIPLY-RECURSIVE .A  22  ;B  21  ;D  21  ;n=2/  \n16  spawn  P-M ATRIX-MULTIPLY-RECURSIVE .A  22  ;B  22  ;D  22  ;n=2/  \n17  sync  / / wait for spawned submatrix products \n18  parallel  for  i D 1 to n / / update C D C C D \n19  parallel  for  j D 1 to n \n20 c ij D c ij C d ij \nwith M ATRIX-MULTIPLY-RECURSIVE on  page  83,  we\u2019re  glossing  over  the  subtle  \nissue of how to use index calculations to represent  submatrix sections of a matrix.) \nThe spawned recursive call in line 9 sets C 11  D C 11  C A 11  \ue001 B 11  , so that C 11  ac-  \ncumulates  the  \u00fbrst  of the  two  terms  in equation  (4.5)  on  page  82. Similarly, lines \n10312  cause  each  of C 12  , C 21  , and C 22  in parallel  to accumulate  the  \u00fbrst  of the  \ntwo  terms  in equations  (4.6)3(4.8),  respectively.  Line  13  sets the submatrix D 11  to \nthe submatrix product A 12  \ue001 B 21  , so that D 11  equals the second of the two terms \nin equation  (4.5).  Lines  14316  set  each  of D 12  , D 21  , and D 22  in parallel to the \nsecond  of the  two  terms  in equations  (4.6)3(4.8),  respectiv ely. The sync  statement \nin line  17  ensures  that  all  the  spawned  submatrix  products  in lines  9316  have  been  \ncomputed, after which the doubly nested parallel  for  loops  in lines  18320  add  the  \nelements of D to the corresponding elements of C . \nLet\u2019s  analyze  the  P-M ATRIX-MULTIPLY-RECURSIVE procedure. We start by \nanalyzing the work M  1 .n/, echoing  the  serial  running-time  analysis  of its  progen-  \nitor M ATRIX-MULTIPLY-RECURSIVE . The recursive case allocates and zeros the 26.2  Parallel  matrix  multiplication  773 \ntemporary matrix D in \u201a.n  2 / time, partitions in \u201a.1/  time,  performs  eight  recur-  \nsive multiplications of n=2  \ue005 n=2  matrices,  and  \u00fbnishes  up  with  the  \u201a.n  2 / work \nfrom adding two n \ue005 n matrices. Thus the work outside the spawned recursi ve calls \nis \u201a.n  2 /, and the recurrence for the work M  1 .n/  becomes \nM  1 .n/  D 8M  1 .n=2/  C \u201a.n  2 / \nD \u201a.n  3 / \nby  case  1 of the  master  theorem  (Theorem  4.1).  Not  surprising ly, the work of this \nparallel algorithm is asymptotically the same as th e running time of the procedure \nMATRIX-MULTIPLY on  page  81,  with  its  triply  nested  loops.  \nLet\u2019s  determine  the  span  M  1  .n/  of P-M ATRIX-MULTIPLY-RECURSIVE. Be-  \ncause the eight parallel recursive spawns all execu te on matrices of the same size, \nthe maximum span for any recursive spawn is just th e span of a single one of \nthem, or M  1  .n=2/ . The span for the doubly nested parallel  for  loops  in lines  537  \nis \u201a.lg n/ because each loop control adds \u201a.lg n/ to the  constant  span  of line  7. \nSimilarly, the doubly nested parallel  for  loops  in lines  18320  add  another  \u201a.lg n/. \nMatrix partitioning by index calculation has \u201a.1/  span, which is dominated by the \n\u201a.lg n/ span of the nested loops. We obtain the recurrence \nM  1  .n/  D M  1  .n=2/  C \u201a.lg n/:  (26.6)  \nSince this recurrence falls under case 2 of the mas ter theorem with k D 1, the \nsolution is M  1  .n/  D \u201a.lg 2 n/. \nThe  parallelism  of P-M ATRIX-MULTIPLY-RECURSIVE is M  1 .n/=M  1  .n/  D \n\u201a.n  3 = lg 2 n/, which  is huge.  (Problem  26-2  asks  you  to simplify  this  parallel  al-  \ngorithm at the expense of just a little less parall elism.) \nParallelizing  Strassen\u2019s  method  \nTo  parallelize  Strassen\u2019s  algorithm,  we  can  follow  the  same  general outline as on \npages  86387,  but  use  spawning.  You  may  \u00fbnd  it helpful  to compa re each step \nbelow  with  the  corresponding  step  there.  We\u2019ll  analyze  costs as we go along to \ndevelop recurrences T 1 .n/  and T 1  .n/  for the overall work and span, respectively. \n1. If n D 1, the matrices each contain a single element. Perfo rm a single scalar \nmultiplication  and  a single  scalar  addition,  and  return.  Otherwise, partition the \ninput matrices A and B and output matrix C into n=2  \ue005 n=2  submatrices, as in \nequation  (4.2)  on  page  82.  This  step  takes  \u201a.1/  work and \u201a.1/  span by index \ncalculation. \n2. Create n=2  \ue005 n=2  matrices S 1 ;S  2 ;:::;S  10  , each  of which  is the  sum  or dif-  \nference  of two  submatrices  from  step  1. Create  and  zero  the  entries of seven \nn=2\ue005n=2  matrices P 1 ;P  2 ;:::;P  7 to hold seven n=2\ue005n=2  matrix products. All 774 Chapter 26 Parallel Algorithms \n17  matrices can be created, and the P i initialized, with doubly nested parallel  \nfor  loops using \u201a.n  2 / work and \u201a.lg n/ span. \n3. Using  the  submatrices  from  step  1 and  the  matrices  S 1 ;S  2 ;:::;S  10  created in \nstep 2, recursively spawn computations of each of t he seven n=2  \ue005 n=2  matrix \nproducts P 1 ;P  2 ;:::;P  7 , taking 7T  1 .n=2/  work and T 1  .n=2/  span. \n4. Update  the  four  submatrices  C 11  ;C  12  ;C  21  ;C  22  of the result matrix C by adding \nor subtracting various P i matrices. Using doubly nested parallel  for  loops, \ncomputing all four submatrices takes \u201a.n  2 / work and \u201a.lg n/ span. \nLet\u2019s  analyze  this  algorithm.  Since  the  serial  projection  is the  same  as the  orig-  \ninal serial algorithm, the work is just the running  time of the serial projection, \nnamely, \u201a.n  lg 7 /. As  we  did  with  P-M ATRIX-MULTIPLY-RECURSIVE , we can \ndevise a recurrence for the span. In this case, sev en recursive calls execute in \nparallel, but since they all operate on matrices of  the same size, we obtain the \nsame  recurrence  (26.6)  as we  did  for  P-M ATRIX-MULTIPLY-RECURSIVE , with \nsolution \u201a.lg 2 n/. Thus  the  parallel  version  of Strassen\u2019s  method  has  paralle lism \n\u201a.n  lg 7 = lg 2 n/, which is large. Although the parallelism is sligh tly less than that of \nP-M ATRIX-MULTIPLY-RECURSIVE, that\u2019s  just  because  the  work  is also  less.  \nExercises  \n26.2-1  \nDraw  the  trace  for  computing  P-M ATRIX-MULTIPLY on 2 \ue005 2 matrices, labeling \nhow the vertices in your diagram correspond to stra nds in the execution of the \nalgorithm. Assuming that each strand executes in un it time, analyze the work, \nspan, and parallelism of this computation. \n26.2-2  \nRepeat  Exercise  26.2-1  for  P-M ATRIX-MULTIPLY-RECURSIVE . \n26.2-3  \nGive  pseudocode  for  a parallel  algorithm  that  multiplies  two n \ue005 n matrices with \nwork \u201a.n  3 / but span only \u201a.lg n/. Analyze your algorithm. \n26.2-4  \nGive  pseudocode  for  an ef\u00fbcient  parallel  algorithm  that  multiplies a p \ue005 q matrix \nby a q \ue005 r matrix. Your algorithm should be highly parallel ev en if any of p, q, \nand r equal 1. Analyze your algorithm. 26.3 Parallel merge sort 775 \n26.2-5  \nGive  pseudocode  for  an ef\u00fbcient  parallel  version  of the  Floyd-Warshall  algorithm  \n(see  Section  23.2),  which  computes  shortest  paths  between  all pairs of vertices in \nan edge-weighted  graph.  Analyze  your  algorithm.  \n26.3  Parallel  merge  sort  \nWe  \u00fbrst  saw  serial  merge  sort  in Section  2.3.1,  and  in Section  2.3.2  we  analyzed  \nits running time and showed it to be \u201a.n  lg n/. Because merge sort already uses \nthe  divide-and-conquer  method,  it seems  like  a terri\u00fbc  cand idate for implementing \nusing  fork-join  parallelism.  \nThe  procedure  P-MERGE-SORT  modi\u00fbes  merge  sort  to spawn  the  \u00fbrst  recursive  \ncall. Like its serial counterpart M ERGE-SORT  on  page  39,  the  P-MERGE-SORT  \nprocedure sorts the subarray A\u0152p  W r\ufffd. After the sync  statement  in line  8 ensures  \nthat  the  two  recursive  spawns  in lines  5 and  7 have  \u00fbnished,  P-  MERGE-SORT  calls \nthe  P-MERGE  procedure,  a parallel  merging  algorithm,  which  is on  page  779, but \nyou  don\u2019t  need  to bother  looking  at it right  now.  \nP-MERGE-SORT  .A;p;r/  \n1 if p \ue004 r / / zero  or one  element?  \n2 return  \n3 q D b.p  C r/=2c / / midpoint of A\u0152p  W r\ufffd \n4 / / Recursively sort A\u0152p  W q\ufffd in parallel. \n5 spawn  P-MERGE-SORT  .A;p;q/  \n6 / / Recursively sort A\u0152q  C 1 W r\ufffd in parallel. \n7 spawn  P-MERGE-SORT  .A;q  C 1;r/  \n8 sync  / / wait for spawns \n9 / / Merge A\u0152p  W q\ufffd and A\u0152q  C 1 W r\ufffd into A\u0152p  W r\ufffd. \n10  P-MERGE.A;p;q;r/  \nFirst,  let\u2019s  use  work/span  analysis  to get  some  intuition  for  why  we  need  a par-  \nallel merge procedure. After all, it may seem as th ough there should be plenty \nof parallelism just by parallelizing M ERGE-SORT  without  worrying  about  paral-  \nlelizing  the  merge.  But  what  would  happen  if the  call  to P-MERGE  in line  10  \nof P-MERGE-SORT  were replaced by a call to the serial M ERGE  procedure on \npage  36?  Let\u2019s  call  the  pseudocode  so modi\u00fbed  P-N AIVE-MERGE-SORT. \nLet T 1 .n/  be the  (worst-case)  work  of P-N AIVE-MERGE-SORT  on an n-element  \nsubarray, where n D r \ue003 p C 1 is the number of elements in A\u0152p  W r\ufffd, and let T 1  .n/  776 Chapter 26 Parallel Algorithms \nbe the span. Because M ERGE  is serial with running time \u201a.n/ , both its work and \nspan are \u201a.n/. Since  the  serial  projection  of P-N AIVE-MERGE-SORT  is exactly \nMERGE-SORT, its work is T 1 .n/  D \u201a.n  lg n/. The  two  recursive  calls  in lines  5 \nand  7 run  in parallel,  and  so its  span  is given  by  the  recurrenc e \nT 1  .n/  D T 1  .n=2/  C \u201a.n/  \nD \u201a.n/;  \nby  case  1 of the  master  theorem.  Thus  the  parallelism  of P-N AIVE-MERGE-SORT  \nis T 1 .n/=T  1  .n/  D \u201a.lg n/, which is an unimpressive amount of parallelism. T o \nsort a million elements, for example, since lg 10  6 \ue002 20, it might achieve linear \nspeedup on a few processors, but it would not scale  up to dozens of processors. \nThe  parallelism  bottleneck  in P-N AIVE-MERGE-SORT  is plainly the M ERGE  \nprocedure. If we asymptotically reduce the span of merging, the master theorem \ndictates that the span of parallel merge sort will also get smaller. When you look at \nthe pseudocode for M ERGE, it may  seem  that  merging  is inherently  serial,  but  it\u2019s  \nnot. We can fashion a parallel merging algorithm. T he goal is to reduce the span of \nparallel  merging  asymptotically,  but  if we  want  an ef\u00fbcient  parallel algorithm, we \nmust ensure that the \u201a.n/  bound  on  work  doesn\u2019t  increase.  \nFigure  26.6  depicts  the  divide-and-conquer  strategy  that  we\u2019ll  use  in P-MERGE . \nThe heart of the algorithm is a recursive auxiliary  procedure P-MERGE-AUX that \nmerges two sorted subarrays of an array A into a subarray of another array B \nin parallel.  Speci\u00fbcally,  P-MERGE-AUX merges A\u0152p  1 W r 1 \ufffd and A\u0152p  2 W r 2 \ufffd into \nsubarray B\u0152p  3 W r 3 \ufffd, where r 3 D p 3 C .r 1 \ue003 p 1 C 1/ C .r 2 \ue003 p 2 C 1/ \ue003 1 D \np 3 C .r 1 \ue003 p 1 / C .r 2 \ue003 p 2 / C 1. \nThe  key  idea  of the  recursive  merging  algorithm  in P-MERGE-AUX is to split \neach of the two sorted subarrays of A around a pivot x , such that all the elements \nin the lower part of each subarray are at most x and all the elements in the upper \npart of each subarray are at least x . The procedure can then recurse in parallel on \ntwo subtasks: merging the two lower parts, and merg ing the two upper parts. The \ntrick  is to \u00fbnd  a pivot  x so that  the  recursion  is not  too  lopsided.  We  don\u2019t  want  a \nsituation  such  as that  in QUICKSORT  on  page  183,  where  bad  partitioning  elements  \nlead  to a dramatic  loss  of asymptotic  ef\u00fbciency.  We  could  opt  to partition around \na random element, as R ANDOMIZED -QUICKSORT  on  page  192  does,  but  because  \nthe  input  subarrays  are  sorted,  P-MERGE-AUX can quickly determine a pivot that \nalways works well. \nSpeci\u00fbcally,  the  recursive  merging  algorithm  picks  the  pivot x as the middle \nelement of the larger of the two input subarrays, w hich we can assume without \nloss of generality is A\u0152p  1 W r 1 \ufffd, since otherwise, the two subarrays can just switc h \nroles. That is, x D A\u0152q  1 \ufffd, where q 1 D b.p  1 C r 1 /=2c. Because A\u0152p  1 W r 1 \ufffd is \nsorted, x is a median of the subarray elements: every element  in A\u0152p  1 W q 1 \ue003 1\ufffd is \nno more than x , and every element in A\u0152q  1 C 1 W r 1 \ufffd is no less than x . Then the 26.3 Parallel merge sort 777 \n\u2026 \n\u2026 \u2026 merge merge copy \u2026 \u2026 \u2026 binary search \np 1 q 1 r 1 p 2 q 2 r 2 \np 3 q 3 r 3 B A \nx x \n\u0dc4 x \u0dc4 x \u0dc4 x \n\ue004 x \ue004 x \ue004 x \nFigure  26.6  The  idea  behind  P-MERGE-AUX, which merges two sorted subarrays A\u0152p  1 W r 1 \ufffd and \nA\u0152p  2 W r 2 \ufffd into the subarray B\u0152p  3 W r 3 \ufffd in parallel. Letting x D A\u0152q  1 \ufffd (shown in yellow) be a median \nof A\u0152p  1 W r 1 \ufffd and q 2 be a place in A\u0152p  2 W r 2 \ufffd such that x would fall between A\u0152q  2 \ue003 1\ufffd and A\u0152q  2 \ufffd, \nevery element in the subarrays A\u0152p  1 W q 1 \ue003 1\ufffd and A\u0152p  2 W q 2 \ue003 1\ufffd (shown in orange) is at most x, \nand every element in the subarrays A\u0152q  1 C 1 W r 1 \ufffd and A\u0152q  2 C 1 W r 2 \ufffd (shown in blue) is at least x. To \nmerge, compute the index q 3 where x belongs in B\u0152p  3 W r 3 \ufffd, copy x into B\u0152q  3 \ufffd, and then recursively \nmerge A\u0152p  1 W q 1 \ue003 1\ufffd with A\u0152p  2 W q 2 \ue003 1\ufffd into B\u0152p  3 W q 3 \ue003 1\ufffd and A\u0152q  1 C 1 W r 1 \ufffd with A\u0152q  2 W r 2 \ufffd \ninto B\u0152q  3 C 1 W r 3 \ufffd. \nalgorithm  \u00fbnds  the  <split  point=  q 2 in the smaller subarray A\u0152p  2 W r 2 \ufffd such that all \nthe elements in A\u0152p  2 W q 2 \ue003 1\ufffd (if any) are at most x and all the elements in A\u0152q  2 W r 2 \ufffd \n(if any) are at least x . Intuitively, the subarray A\u0152p  2 W r 2 \ufffd would still be sorted if x \nwere inserted between A\u0152q  2 \ue0031\ufffd and A\u0152q  2 \ufffd (although  the  algorithm  doesn\u2019t  do  that).  \nSince A\u0152p  2 W r 2 \ufffd is sorted,  a minor  variant  of binary  search  (see  Exercise  2.3-6)  with  \nx as the  search  key  can  \u00fbnd  the  split  point  q 2 in \u201a.lg n/ time in the worst case. As \nwe\u2019ll  see  when  we  get  to the  analysis,  even  if x splits A\u0152p  2 W r 2 \ufffd badly4x is either \nsmaller  than  all  the  subarray  elements  or larger4we\u2019ll  still have at least 1=4  of \nthe elements in each of the two recursive merges. T hus the larger of the recursive \nmerges operates on at most 3=4  elements, and the recursion is guaranteed to bottom  \nout after \u201a.lg n/ recursive calls. \nNow  let\u2019s  put  these  ideas  into  pseudocode.  We  start  with  the  serial procedure \nFIND-SPLIT-POINT  .A;p;r;x/  on the next page, which takes as input a sorted \nsubarray A\u0152p  W r\ufffd and a key x . The procedure returns a split point of A\u0152p  W r\ufffd: an \nindex q in the range p \u0dc4 q \u0dc4 r C 1 such that all the elements in A\u0152p  W q \ue003 1\ufffd (if \nany) are at most x and all the elements in A\u0152q  W r\ufffd (if any) are at least x . \nThe F IND-SPLIT-POINT  procedure  uses  binary  search  to \u00fbnd  the  split  point.  \nLines  1 and  2 establish  the  range  of indices  for  the  search.  Each time through the \nwhile  loop,  line  5 compares  the  middle  element  of the  range  with  the  search key x , \nand  lines  6 and  7 narrow  the  search  range  to either  the  lower  half or the upper half \nof the subarray, depending on the result of the tes t. In the end, after the range has \nbeen  narrowed  to a single  index,  line  8 returns  that  index  as the split point. 778 Chapter 26 Parallel Algorithms \nFIND-SPLIT-POINT  .A;p;r;x/  \n1 low D p / / low end of search range \n2 high D r C 1 / / high end of search range \n3 while  low < high / / more  than  one  element?  \n4 mid D b.low C high/=2c / / midpoint of range \n5 if x \u0dc4 A\u0152mid\ufffd / / is answer q \u0dc4 mid? \n6 high D mid / / narrow search to A\u0152low W mid\ufffd \n7 else  low D mid C 1 / / narrow search to A\u0152mid C 1 W high \ufffd \n8 return  low \nBecause F IND-SPLIT-POINT  contains no parallelism, its span is just its seria l \nrunning  time,  which  is also  its  work.  On  a subarray  A\u0152p  W r\ufffd of size n D r \ue003 p C 1, \neach iteration of the while  loop halves the search range, which means that the loop \nterminates after \u201a.lg n/ iterations. Since each iteration takes constant tim e, the \nalgorithm runs in \u201a.lg n/ (worst-case)  time.  Thus  the  procedure  has  work  and  \nspan \u201a.lg n/. \nLet\u2019s  now  look  at the  pseudocode  for  the  parallel  merging  procedure  P-MERGE  \non the next page. Most of the pseudocode is devoted  to the recursive procedure \nP-MERGE-AUX. The  procedure  P-MERGE  itself is just a <wrapper= that sets \nup  for  P-MERGE-AUX. It allocates a new array B\u0152p  W r\ufffd to hold the output of \nP-MERGE-AUX in line  1. It then  calls  P-MERGE-AUX in line  2, passing  the  in-  \ndices of the two subarrays to be merged and providi ng B as the output destination \nof the merged result, starting at index p. After  P-MERGE-AUX returns,  lines  334  \nperform a parallel copy of the output B\u0152p  W r\ufffd into the subarray A\u0152p  W r\ufffd, which is \nwhere  P-MERGE-SORT  expects it. \nThe  P-MERGE-AUX procedure  is the  interesting  part  of the  algorithm.  Let\u2019s  \nstart by understanding the parameters of this recur sive parallel procedure. The \ninput array A and the four indices p 1 ;r 1 ;p  2 ;r 2 specify the subarrays A\u0152p  1 W r 1 \ufffd and \nA\u0152p  2 W r 2 \ufffd to be merged. The array B and the index p 3 indicate that the merged \nresult should be stored into B\u0152p  3 W r 3 \ufffd, where r 3 D p 3 C .r 1 \ue003 p 1 / C .r 2 \ue003 p 2 / C 1, \nas we saw earlier. The end index r 3 of the output subarray is not needed by the \npseudocode, but it helps conceptually to name the e nd index, as in the comment in \nline  13.  \nThe procedure begins by checking the base case of t he recursion and doing some \nbookkeeping  to simplify  the  rest  of the  pseudocode.  Lines  1 and 2 test whether the \ntwo subarrays are both empty, in which case the pro cedure returns.  Line  3 checks  \nwhether  the  \u00fbrst  subarray  contains  fewer  elements  than  the  second subarray. Since \nthe  number  of elements  in the  \u00fbrst  subarray  is r 1 \ue003 p 1 C 1 and the number in the \nsecond subarray is r 2 \ue003 p 2 C 1, the test omits the two < C1\u2019s.=  If the  \u00fbrst  subarray  26.3 Parallel merge sort 779 \nP-MERGE.A;p;q;r/  \n1 let B\u0152p  W r\ufffd be a new array / / allocate scratch array \n2 P-MERGE-AUX .A;p;q;q  C 1;r;B;p/  / / merge from A into B \n3 parallel  for  i D p to r / / copy B back to A in parallel \n4 A\u0152i\ufffd  D B\u0152i\ufffd  \nP-MERGE-AUX.A;p  1 ;r 1 ;p  2 ;r 2 ;B;p  3 / \n1 if p 1 >r  1 and p 2 >r  2 / / are  both  subarrays  empty?  \n2 return  \n3 if r 1 \ue003 p 1 <r  2 \ue003 p 2 / / second  subarray  bigger?  \n4 exchange p 1 with p 2 / / swap subarray roles \n5 exchange r 1 with r 2 \n6 q 1 D b.p  1 C r 1 /=2c / / midpoint of A\u0152p  1 W r 1 \ufffd \n7 x D A\u0152q  1 \ufffd / / median of A\u0152p  1 W r 1 \ufffd is pivot x \n8 q 2 D FIND-SPLIT-POINT  .A;p  2 ;r 2 ;x/  / / split A\u0152p  2 W r 2 \ufffd around x \n9 q 3 D p 3 C .q 1 \ue003 p 1 / C .q 2 \ue003 p 2 / / / where x belongs in B:::  \n10  B\u0152q  3 \ufffd D x / / :::  put it there \n11  / / Recursively merge A\u0152p  1 W q 1 \ue003 1\ufffd and A\u0152p  2 W q 2 \ue003 1\ufffd into B\u0152p  3 W q 3 \ue003 1\ufffd. \n12  spawn  P-MERGE-AUX.A;p  1 ;q  1 \ue003 1;p  2 ;q  2 \ue003 1;B;p  3 / \n13  / / Recursively merge A\u0152q  1 C 1 W r 1 \ufffd and A\u0152q  2 W r 2 \ufffd into B\u0152q  3 C 1 W r 3 \ufffd. \n14  spawn  P-MERGE-AUX.A;q  1 C 1;r  1 ;q  2 ;r 2 ;B;q  3 C 1/ \n15  sync  / / wait for spawns \nis the  smaller  of the  two,  lines  4 and  5 switch  the  roles  of the  subarrays so that \nA\u0152p  1 ;r 1 \ufffd refers to the larger subarray for the balance of th e procedure. \nWe\u2019re  now  at the  crux  of P-MERGE-AUX: implementing  the  parallel  divide-and-  \nconquer strategy. As we continue our pseudocode wal k, you may \u00fbnd  it helpful  to \nrefer  again  to Figure  26.6.  \nFirst  the  divide  step.  Line  6 computes  the  midpoint  q 1 of A\u0152p  1 W r 1 \ufffd, which  in-  \ndexes a median x D A\u0152q  1 \ufffd of this  subarray  to be used  as the  pivot,  and  line  7 \ndetermines x itself.  Next,  line  8 uses  the  FIND-SPLIT-POINT  procedure  to \u00fbnd  the  \nindex q 2 in A\u0152p  2 W r 2 \ufffd such that all elements in A\u0152p  2 W q 2 \ue003 1\ufffd are at most x and all \nthe elements in A\u0152q  2 W r 2 \ufffd are at least x . Line 9 computes the index q 3 of the element \nthat divides the output subarray B\u0152p  3 W r 3 \ufffd into B\u0152p  3 W q 3 \ue003 1\ufffd and B\u0152q  3 C 1 W r 3 \ufffd, \nand  then  line  10  puts  x directly into B\u0152q  3 \ufffd, which is where it belongs in the output. \nNext is the conquer step, which is where the parall el recursion  occurs.  Lines  12  \nand  14  each  spawn  P-MERGE-AUX to recursively merge from A into B , the  \u00fbrst  \nto merge the smaller elements and the second to mer ge the larger elements. The 780 Chapter 26 Parallel Algorithms \nsync  statement  in line  15  ensures  that  the  subproblems  \u00fbnish  before the procedure \nreturns. \nThere is no combine step, as B\u0152p  W r\ufffd already contains the correct sorted output. \nWork/span  analysis  of parallel  merging  \nLet\u2019s  \u00fbrst  analyze  the  worst-case  span  T 1  .n/  of P-MERGE-AUX on  input  subar-  \nrays that together contain a total of n elements. The call to F IND-SPLIT-POINT  in \nline  8 contributes  \u201a.lg n/ to the span in the worst case, and the procedure pe rforms \nat most a constant amount of additional serial work  outside of the two recursive \nspawns  in lines  12  and  14.  \nBecause the two recursive spawns operate logically in parallel, only one of them \ncontributes  to the  overall  worst-case  span.  We  claimed  earlier  that  neither  recur-  \nsive invocation ever operates on more than 3n=4  elements.  Let\u2019s  see  why.  Let  \nn 1 D r 1 \ue003 p 1 C 1 and n 2 D r 2 \ue003 p 2 C 1, where n D n 1 C n 2 , be the sizes of the \ntwo  subarrays  when  line  6 starts  executing,  that  is, after  we  have established that \nn 2 \u0dc4 n 1 by swapping the roles of the two subarrays, if nece ssary. Since the pivot x \nis a median of of A\u0152p  1 W r 1 \ufffd, in the worst case, a recursive merge involves at most \nn 1 =2  elements of A\u0152p  1 W r 1 \ufffd, but it might involve all n 2 of the elements of A\u0152p  2 W r 2 \ufffd. \nThus we can bound the number of elements involved i n a recursive invocation of \nP-MERGE-AUX by \nn 1 =2  C n 2 D .2n  1 C 4n  2 /=4  \n\u0dc4 .3n  1 C 3n  2 /=4  (since n 2 \u0dc4 n 1 ) \nD 3n=4;  \nproving the claim. \nThe  worst-case  span  of P-MERGE-AUX can  therefore  be described  by  the  fol-  \nlowing recurrence: \nT 1  .n/  D T 1  .3n=4/  C \u201a.lg n/:  (26.7)  \nBecause this recurrence falls under case 2 of the m aster theorem with k D 1, its \nsolution is T 1  .n/  D \u201a.lg 2 n/. \nNow  let\u2019s  verify  that  the  work  T 1 .n/  of P-MERGE-AUX on n elements is linear. \nA lower bound of \ufffd.n/  is straightforward, since each of the n elements is copied \nfrom array A to array B . We\u2019ll  show  that  T 1 .n/  D O.n/  by deriving a recurrence \nfor  the  worst-case  work.  The  binary  search  in line  8 costs  \u201a.lg n/ in the worst case, \nwhich dominates the other work outside of the recur sive spawns. For the recursive \nspawns,  observe  that  although  lines  12  and  14  might  merge  different numbers of \nelements, the two recursive spawns together merge a t most n \ue003 1 elements (since \nx D A\u0152q\ufffd  is not merged). Moreover, as we saw when analyzing the span, a recur-  \nsive spawn operates on at most 3n=4  elements. We therefore obtain the recurrence 26.3 Parallel merge sort 781 \nT 1 .n/  D T 1 .\u02dbn/  C T 1 ..1  \ue003 \u02db/n/  C \u201a.lg n/;  (26.8)  \nwhere \u02db lies in the range 1=4  \u0dc4 \u02db \u0dc4 3=4. The value of \u02db can vary from one \nrecursive invocation to another. \nWe\u2019ll  use  the  substitution  method  (see  Section  4.3)  to prove  that  the  above  re-  \ncurrence  (26.8)  has  solution  T 1 .n/  D O.n/. (You  could  also  use  the  Akra-Bazzi  \nmethod  from  Section  4.7.)  Assume  that  T 1 .n/  \u0dc4 c 1 n \ue003 c 2 lg n for  some  posi-  \ntive constants c 1 and c 2 . Using  the  properties  of logarithms  on  pages  663674in  \nparticular, to deduce that lg \u02db C lg.1 \ue003 \u02db/  D \ue003\u201a.1/4substitution  yields  \nT 1 .n/  \u0dc4 .c 1 \u02dbn  \ue003 c 2 lg.\u02dbn//  C .c 1 .1 \ue003 \u02db/n  \ue003 c 2 lg..1  \ue003 \u02db/n//  C \u201a.lg n/ \nD c 1 .\u02db  C .1 \ue003 \u02db//n  \ue003 c 2 .lg.\u02dbn/  C lg..1  \ue003 \u02db/n//  C \u201a.lg n/ \nD c 1 n \ue003 c 2 .lg \u02db C lg n C lg.1 \ue003 \u02db/  C lg n/ C \u201a.lg n/ \nD c 1 n \ue003 c 2 lg n \ue003 c 2 .lg n C lg \u02db C lg.1 \ue003 \u02db//  C \u201a.lg n/ \nD c 1 n \ue003 c 2 lg n \ue003 c 2 .lg n \ue003 \u201a.1//  C \u201a.lg n/ \n\u0dc4 c 1 n \ue003 c 2 lg n;  \nif we choose c 2 large enough that the c 2 .lg n \ue003 \u201a.1//  term dominates the \u201a.lg n/ \nterm  for  suf\u00fbciently  large  n. Furthermore, we can choose c 1 large enough to satisfy \nthe implied \u201a.1/  base cases of the recurrence, completing the induct ion. The lower \nand upper bounds of \ufffd.n/  and O.n/  give T 1 .n/  D \u201a.n/ , asymptotically the same \nwork as for serial merging. \nThe  execution  of the  pseudocode  in the  P-MERGE  procedure itself does not add \nasymptotically  to the  work  and  span  of P-MERGE-AUX. The parallel  for  loop \nin lines  334  has  \u201a.lg n/ span due to the loop control, and each iteration ru ns in \nconstant time. Thus the \u201a.lg 2 n/ span  of P-MERGE-AUX dominates, yielding \n\u201a.lg 2 n/ span  overall  for  P-MERGE . The parallel  for  loop contains \u201a.n/  work, \nmatching  the  asymptotic  work  of P-MERGE-AUX and yielding \u201a.n/  work overall \nfor  P-MERGE . \nAnalysis  of parallel  merge  sort  \nThe <heavy lifting= is done. Now that we have deter mined the work and span of \nP-MERGE, we  can  analyze  P-MERGE-SORT. Let T 1 .n/  and T 1  .n/  be the work \nand  span,  respectively,  of P-MERGE-SORT  on an array of n elements. The call to \nP-MERGE  in line  10  of P-MERGE-SORT  dominates  the  costs  of lines  133,  for  both  \nwork and span. Thus we obtain the recurrence \nT 1 .n/  D 2T  1 .n=2/  C \u201a.n/  \nfor  the  work  of P-MERGE-SORT, and we obtain the recurrence \nT 1  .n/  D T 1  .n=2/  C \u201a.lg 2 n/ 782 Chapter 26 Parallel Algorithms \nfor its span. The work recurrence has solution T 1 .n/  D \u201a.n  lg n/ by case 2 of the \nmaster theorem with k D 0. The span recurrence has solution T 1  .n/  D \u201a.lg 3 n/, \nalso by case 2 of the master theorem, but with k D 2. \nParallel  merging  gives  P-MERGE-SORT  a parallelism  advantage  over  P-N AIVE- \nMERGE-SORT. The  parallelism  of P-N AIVE-MERGE-SORT, which calls the serial \nMERGE  procedure, is only \u201a.lg n/. For  P-MERGE-SORT, the parallelism is \nT 1 .n/=T  1  .n/  D \u201a.n  lg n/=\u201a. lg 3 n/ \nD \u201a.n=  lg 2 n/;  \nwhich is much better, both in theory and in practic e. A good implementation in \npractice  would  sacri\u00fbce  some  parallelism  by  coarsening  the  base case in order to \nreduce the constants hidden by the asymptotic notat ion. For example, you could \nswitch  to an ef\u00fbcient  serial  sort,  perhaps  quicksort,  when  the number of elements \nto be sorted  is suf\u00fbciently  small.  \nExercises  \n26.3-1  \nExplain  how  to coarsen  the  base  case  of P-MERGE . \n26.3-2  \nInstead  of \u00fbnding  a median  element  in the  larger  subarray,  as P-MERGE  does,  sup-  \npose  that  the  merge  procedure  \u00fbnds  a median  of all  the  element s in the two sorted \nsubarrays  using  the  result  of Exercise  9.3-10.  Give  pseudocode  for  an ef\u00fbcient  \nparallel  merging  procedure  that  uses  this  median-\u00fbnding  procedure. Analyze your \nalgorithm. \n26.3-3  \nGive  an ef\u00fbcient  parallel  algorithm  for  partitioning  an array around a pivot, as is \ndone by the P ARTITION  procedure  on  page  184.  You  need  not  partition  the  array  \nin place. Make your algorithm as parallel as possib le. Analyze your algorithm. \n(Hint: You might need an auxiliary array and might need to  make more than one \npass over the input elements.) \n26.3-4  \nGive  a parallel  version  of FFT  on  page  890.  Make  your  implemen tation as parallel \nas possible. Analyze your algorithm. \n? 26.3-5  \nShow how to parallelize S ELECT from  Section  9.3.  Make  your  implementation  as \nparallel as possible. Analyze your algorithm. Problems for Chapter 26 783 \nProblems  \n26-1  Implementing  parallel  loops  using  recursive  spawning  \nConsider the parallel procedure S UM-ARRAYS for performing pairwise addition \non n-element  arrays  A\u01521  W n\ufffd and B\u01521  W n\ufffd, storing the sums in C\u01521  W n\ufffd. \nSUM-ARRAYS.A;B;C;n/  \n1 parallel  for  i D 1 to n \n2 C \u0152i\ufffd  D A\u0152i\ufffd  C B\u0152i\ufffd  \na. Rewrite the parallel loop in S UM-ARRAYS using recursive spawning in the \nmanner  of P-M AT-VEC-RECURSIVE . Analyze the parallelism. \nConsider another implementation of the parallel loo p in S UM-ARRAYS given by \nthe procedure S UM-ARRAYS 0 , where the value grain-size  must  be speci\u00fbed.  \nSUM-ARRAYS 0 .A;B;C;n/  \n1 grain-size  D \u2039 / / to be determined \n2 r D dn=grain-sizee \n3 for  k D 0 to r \ue003 1 \n4 spawn  ADD-SUBARRAY.A;B;C;k  \ue001 grain-size  C 1; \nmin f.k C 1/ \ue001 grain-size;ng/ \n5 sync  \nADD-SUBARRAY.A;B;C;i;j/  \n1 for  k D i to j \n2 C \u0152k\ufffd  D A\u0152k\ufffd  C B\u0152k\ufffd  \nb. Suppose that you set grain-size  D 1. What  is the  resulting  parallelism?  \nc. Give  a formula  for  the  span  of SUM-ARRAYS 0 in terms of n and grain-size. \nDerive the best value for grain-size  to maximize parallelism. \n26-2  Avoiding  a temporary  matrix  in recursive  matrix  multiplication  \nThe  P-M ATRIX-MULTIPLY-RECURSIVE procedure  on  page  772  must  allocate  a \ntemporary matrix D of size n \ue005 n, which can adversely affect the constants hidden \nby the \u201a-notation.  The  procedure  has  high  parallelism,  however:  \u201a.n  3 = log 2 n/. 784 Chapter 26 Parallel Algorithms \nFor example, ignoring the constants in the \u201a-notation,  the  parallelism  for  mul-  \ntiplying 1000  \ue005 1000  matrices comes to approximately 1000  3 =10  2 D 10  7 , since \nlg 1000  \ue002 10. Most parallel computers have far fewer than 10  million processors. \na. Parallelize M ATRIX-MULTIPLY-RECURSIVE without  using  temporary  matri-  \nces so that it retains its \u201a.n  3 / work. ( Hint: Spawn the recursive calls, but insert \na sync  in a judicious location to avoid races.) \nb. Give  and  solve  recurrences  for  the  work  and  span  of your  imple mentation. \nc. Analyze the parallelism of your implementation. Ign oring the constants in the \n\u201a-notation,  estimate  the  parallelism  on  1000  \ue005 1000  matrices. Compare with \nthe  parallelism  of P-M ATRIX-MULTIPLY-RECURSIVE , and discuss whether \nthe  trade-off  would  be worthwhile.  \n26-3  Parallel  matrix  algorithms  \nBefore attempting this problem, it may be helpful t o read Chapter  28.  \na. Parallelize  the  LU-DECOMPOSITION  procedure  on  page  827  by  giving  pseu-  \ndocode for a parallel version of this algorithm. Ma ke your implementation as \nparallel as possible, and analyze its work, span, a nd parallelism. \nb. Do  the  same  for  LUP-DECOMPOSITION  on  page  830.  \nc. Do  the  same  for  LUP-SOLVE  on  page  824.  \nd. Using  equation  (28.14)  on  page  835,  write  pseudocode  for  a parallel algorithm \nto invert  a symmetric  positive-de\u00fbnite  matrix.  Make  your  implementation as \nparallel as possible, and analyze its work, span, a nd parallelism. \n26-4  Parallel  reductions  and  scan  (pre\u00fbx)  computations  \nA \u02dd-reduction  of an array x\u01521  W n\ufffd, where \u02dd is an associative operator, is the value \ny D x\u01521\ufffd  \u02dd x\u01522\ufffd  \u02dd \ue001 \ue001 \ue001 \u02dd  x\u0152n\ufffd. The R EDUCE procedure computes the \u02dd-reduction  \nof a subarray x\u0152i  W j \ufffd serially. \nREDUCE.x;i;j/  \n1 y D x\u0152i\ufffd  \n2 for  k D i C 1 to j \n3 y D y \u02dd x\u0152k\ufffd  \n4 return  y Problems for Chapter 26 785 \na. Design  and  analyze  a parallel  algorithm  P-R EDUCE that  uses  recursive  spawn-  \ning to perform the same function with \u201a.n/  work and \u201a.lg n/ span. \nA related problem is that of computing a \u02dd-scan , sometimes called a \u02dd-pre\u00fbx  \ncomputation , on an array x\u01521  W n\ufffd, where \u02dd is once  again  an associative  opera-  \ntor. The \u02dd-scan,  implemented  by  the  serial  procedure  SCAN, produces  the  ar-  \nray y\u01521  W n\ufffd given by \ny\u01521\ufffd  D x\u01521\ufffd ;  \ny\u01522\ufffd  D x\u01521\ufffd  \u02dd x\u01522\ufffd ;  \ny\u01523\ufffd  D x\u01521\ufffd  \u02dd x\u01522\ufffd  \u02dd x\u01523\ufffd ;  \n: : : \ny\u0152n\ufffd  D x\u01521\ufffd  \u02dd x\u01522\ufffd  \u02dd x\u01523\ufffd  \u02dd \ue001 \ue001 \ue001 \u02dd  x\u0152n\ufffd ;  \nthat  is, all  pre\u00fbxes  of the  array  x <summed= using the \u02dd operator. \nSCAN.x;n/  \n1 let y\u01521  W n\ufffd be a new array \n2 y\u01521\ufffd  D x\u01521\ufffd  \n3 for  i D 2 to n \n4 y\u0152i\ufffd  D y\u0152i  \ue003 1\ufffd \u02dd x\u0152i\ufffd  \n5 return  y \nParallelizing S CAN is not straightforward. For example, simply changin g the for  \nloop to a parallel  for  loop would create races, since each iteration of th e loop body \ndepends  on  the  previous  iteration.  The  procedures  P-S CAN-1 and  P-S CAN-1-A UX \nperform the \u02dd-scan  in parallel,  albeit  inef\u00fbciently.  \nP-S CAN-1.x;n/  \n1 let y\u01521  W n\ufffd be a new array \n2 P-S CAN-1-A UX.x;y;1;n/  \n3 return  y \nP-S CAN-1-A UX.x;y;i;j/  \n1 parallel  for  l D i to j \n2 y\u0152l\ufffd  D P-R EDUCE.x;1;l/  \nb. Analyze  the  work,  span,  and  parallelism  of P-S CAN-1.  786 Chapter 26 Parallel Algorithms \nThe  procedures  P-S CAN-2 and  P-S CAN-2-A UX use  recursive  spawning  to per-  \nform  a more  ef\u00fbcient  \u02dd-scan.  \nP-S CAN-2 .x;n/  \n1 let y\u01521  W n\ufffd be a new array \n2 P-S CAN-2-A UX .x;y;1;n/  \n3 return  y \nP-S CAN-2-A UX .x;y;i;j/  \n1 if i == j \n2 y\u0152i\ufffd  D x\u0152i\ufffd  \n3 else  k D b.i C j/=2c \n4 spawn  P-S CAN-2-A UX.x;y;i;k/  \n5 P-S CAN-2-A UX.x;y;k  C 1;j/  \n6 sync  \n7 parallel  for  l D k C 1 to j \n8 y\u0152l\ufffd  D y\u0152k\ufffd  \u02dd y\u0152l\ufffd  \nc. Argue  that  P-S CAN-2 is correct,  and  analyze  its  work,  span,  and  parallelism.  \nTo  improve  on  both  P-S CAN-1 and  P-S CAN-2,  perform  the  \u02dd-scan  in two  dis-  \ntinct  passes  over  the  data.  The  \u00fbrst  pass  gathers  the  terms  for  various  contigu-  \nous subarrays of x into a temporary array t , and the second pass uses the terms \nin t to compute  the  \u00fbnal  result  y . The  pseudocode  in the  procedures  P-S CAN-3,  \nP-S CAN-UP, and  P-S CAN-DOWN  on the facing page implements this strategy, but \ncertain expressions have been omitted. \nd. Fill  in the  three  missing  expressions  in line  8 of P-S CAN-UP and  lines  5 and  6 of \nP-S CAN-DOWN. Argue  that  with  the  expressions  you  supplied,  P-S CAN-3 is \ncorrect. ( Hint: Prove that the value v passed  to P-S CAN-DOWN.v;x;t;y;i;j/  \nsatis\u00fbes  v D x\u01521\ufffd  \u02dd x\u01522\ufffd  \u02dd \ue001 \ue001 \ue001 \u02dd  x\u0152i  \ue003 1\ufffd.) \ne. Analyze  the  work,  span,  and  parallelism  of P-S CAN-3.  \nf. Describe  how  to rewrite  P-S CAN-3 so that  it doesn\u2019t  require  the  use  of the  \ntemporary array t . \n? g. Give  an algorithm  P-S CAN-4 .x;n/  for a scan that operates in place. It should \nplace its output in x and require only constant auxiliary storage. \nh. Describe  an ef\u00fbcient  parallel  algorithm  that  uses  a C-scan  to determine  whether  \na string of parentheses is well formed. For example , the string ( ( )( ) )( )  Problems for Chapter 26 787 \nis well formed, but the string ( ( ) ) )( ( )  is not. ( Hint: Interpret ( as a 1 \nand ) as a \ue0031, and then perform a C-scan.)  \nP-S CAN-3.x;n/  \n1 let y\u01521  W n\ufffd and t\u01521  W n\ufffd be new arrays \n2 y\u01521\ufffd  D x\u01521\ufffd  \n3 if n>1  \n4 P-S CAN-UP.x;t;2;n/  \n5 P-S CAN-DOWN .x\u01521\ufffd; x; t; y; 2; n/  \n6 return  y \nP-S CAN-UP.x;t;i;j/  \n1 if i = = j \n2 return  x\u0152i\ufffd  \n3 else  \n4 k D b.i C j/=2c \n5 t\u0152k\ufffd  D spawn  P-S CAN-UP.x;t;i;k/  \n6 right D P-S CAN-UP.x;t;k  C 1;j/  \n7 sync  \n8 return  / / \u00fbll  in the  blank  \nP-S CAN-DOWN.v;x;t;y;i;j/  \n1 if i = = j \n2 y\u0152i\ufffd  D v \u02dd x\u0152i\ufffd  \n3 else  \n4 k D b.i C j/=2c \n5 spawn  P-S CAN-DOWN. ;x;t;y;i;k/  / / \u00fbll  in the  blank  \n6 P-S CAN-DOWN. ;x;t;y;k  C 1;j/  / / \u00fbll  in the  blank  \n7 sync  \n26-5  Parallelizing  a simple  stencil  calculation  \nComputational science is replete with algorithms th at require the entries of an array \nto be \u00fblled  in with  values  that  depend  on  the  values  of certain  already computed \nneighboring entries, along with other information t hat does not change over the \ncourse of the computation. The pattern of neighbori ng entries does not change \nduring the computation and is called a stencil. For  example,  Section  14.4  presents  \na stencil algorithm to compute a longest common sub sequence, where the value in \nentry c\u0152i; j \ufffd  depends only on the values in c\u0152i  \ue003 1; j \ufffd, c\u0152i;j  \ue003 1\ufffd, and c\u0152i  \ue003 1;j  \ue003 1\ufffd, 788 Chapter 26 Parallel Algorithms \nas well as the elements x i and y j within the two sequences given as inputs. The \ninput  sequences  are  \u00fbxed,  but  the  algorithm  \u00fblls  in the  two-d imensional array c so \nthat it computes entry c\u0152i; j \ufffd  after computing all three entries c\u0152i  \ue003 1; j \ufffd, c\u0152i;j  \ue003 1\ufffd, \nand c\u0152i  \ue003 1;j  \ue003 1\ufffd. \nThis problem examines how to use recursive spawning  to parallelize a simple \nstencil calculation on an n \ue005 n array A in which the value placed into entry A\u0152i; j \ufffd  \ndepends only on values in A\u0152i  0 ;j 0 \ufffd, where i 0 \u0dc4 i and j 0 \u0dc4 j (and of course, i 0 \u00a4 i \nor j 0 \u00a4 j ). In other words, the value in an entry depends on ly on values in entries \nthat are above it and/or to its left, along with st atic information outside of the array. \nFurthermore, we assume throughout this problem that  once the entries upon which \nA\u0152i; j \ufffd  depends  have  been  \u00fblled  in,  the  entry  A\u0152i; j \ufffd  can be computed in \u201a.1/  time \n(as  in the  LCS-LENGTH  procedure  of Section  14.4).  \nPartition the n \ue005 n array A into four n=2  \ue005 n=2  subarrays as follows: \nA D \u00cf A 11  A 12  \nA 21  A 22  \u00d0 \n: (26.9)  \nYou  can  immediately  \u00fbll  in subarray  A 11  recursively, since it does not depend on \nthe  entries  in the  other  three  subarrays.  Once  the  computati on of A 11  \u00fbnishes,  you  \ncan  \u00fbll  in A 12  and A 21  recursively in parallel, because although they both  depend \non A 11  , they  do  not  depend  on  each  other.  Finally,  you  can  \u00fbll  in A 22  recursively. \na. Give  parallel  pseudocode  that  performs  this  simple  stencil  calculation using \na divide-and-conquer  algorithm  SIMPLE-STENCIL based  on  the  decomposi-  \ntion  (26.9)  and  the  discussion  above.  (Don\u2019t  worry  about  the  details of the \nbase  case,  which  depends  on  the  speci\u00fbc  stencil.)  Give  and  solve recurrences \nfor the work and span of this algorithm in terms of  n. What  is the  parallelism?  \nb. Modify your solution to part (a) to divide an n \ue005 n array into nine n=3  \ue005 n=3  \nsubarrays, again recursing with as much parallelism  as possible. Analyze this \nalgorithm. How much more or less parallelism does t his algorithm  have  com-  \npared  with  the  algorithm  from  part  (a)?  \nc. Generalize  your  solutions  to parts  (a)  and  (b)  as follows.  Choose an integer \nb \ue004 2. Divide an n \ue005 n array into b 2 subarrays, each of size n=b  \ue005 n=b, \nrecursing with as much parallelism as possible. In terms of n and b, what \nare  the  work,  span,  and  parallelism  of your  algorithm?  Argue  that, using this \napproach, the parallelism must be o.n/  for any choice of b \ue004 2. (Hint: For this \nargument, show that the exponent of n in the parallelism is strictly less than 1 \nfor any choice of b \ue004 2.) \nd. Give  pseudocode  for  a parallel  algorithm  for  this  simple  stencil calculation that \nachieves \u201a.n=  lg n/ parallelism. Argue using notions of work and span t hat Notes for Chapter 26 789 \nthe problem has \u201a.n/  inherent  parallelism.  Unfortunately,  simple  fork-join  \nparallelism does not let you achieve this maximal p arallelism. \n26-6  Randomized  parallel  algorithms  \nLike serial algorithms, parallel algorithms can emp loy random-number  generators.  \nThis problem explores how to adapt the measures of work, span, and parallelism to \nhandle  the  expected  behavior  of randomized  task-parallel  algorithms. It also asks \nyou to design and analyze a parallel algorithm for randomized quicksort. \na. Explain  how  to modify  the  work  law  (26.2),  span  law  (26.3),  and  greedy  sched-  \nuler  bound  (26.4)  to work  with  expectations  when  T P , T 1 , and T 1  are  all  ran-  \ndom variables. \nb. Consider a randomized parallel algorithm for which 1% of the time, T 1 D 10  4 \nand T 10;000  D 1, but for the remaining 99% of the time, T 1 D T 10;000  D 10  9 . \nArgue that the speedup  of a randomized  parallel  algorithm  should  be de\u00fbned  as \nE \u0152T 1 \ufffd =E \u0152T P \ufffd, rather than E \u0152T 1 =T  P \ufffd. \nc. Argue that the parallelism  of a randomized  task-parallel  algorithm  should  be \nde\u00fbned  as the  ratio  E \u0152T 1 \ufffd =E \u0152T 1  \ufffd. \nd. Parallelize the R ANDOMIZED -QUICKSORT  algorithm  on  page  192  by  using  \nrecursive  spawning  to produce  P-RANDOMIZED -QUICKSORT. (Do  not  paral-  \nlelize RANDOMIZED -PARTITION .) \ne. Analyze your parallel algorithm for randomized quic ksort. ( Hint: Review the \nanalysis of R ANDOMIZED -SELECT on  page  230.)  \nf. Parallelize R ANDOMIZED -SELECT on  page  230.  Make  your  implementation  \nas parallel as possible. Analyze your algorithm. ( Hint: Use the partitioning \nalgorithm  from  Exercise  26.3-3.)  \nChapter  notes  \nParallel computers and algorithmic models for paral lel programming have been \naround in various forms for years. Prior editions o f this book included material on \nsorting  networks  and  the  PRAM  (Parallel  Random-Access  Mach ine) model. The \ndata-parallel  model  [58,  217]  is another  popular  algorithm ic programming model, \nwhich features operations on vectors and matrices a s primitives. The notion of \nsequential  consistency  is due  to Lamport  [275].  \nGraham  [197]  and  Brent  [71]  showed  that  there  exist  schedule rs achieving \nthe  bound  of Theorem  26.1.  Eager,  Zahorjan,  and  Lazowska  [129] showed that 790 Chapter 26 Parallel Algorithms \nany greedy scheduler achieves this bound and propos ed the methodology  of us-  \ning work and span (although not by those names) to analyze parallel algorithms. \nBlelloch  [57]  developed  an algorithmic  programming  model  based on work and \nspan  (which  he called  <depth=)  for  data-parallel  programmi ng. Blumofe and \nLeiserson  [63]  gave  a distributed  scheduling  algorithm  for  task-parallel  computa-  \ntions  based  on  randomized  <work-stealing=  and  showed  that  it achieves the bound \nE \u0152T P \ufffd \u0dc4 T 1 =P  C O.T  1  /. Arora,  Blumofe,  and  Plaxton  [20]  and  Blelloch,  Gib-  \nbons,  and  Matias  [61]  also  provided  provably  good  algorithms  for  scheduling  task-  \nparallel computations. The recent literature contai ns many algorithms  and  strate-  \ngies for scheduling parallel programs. \nThe  parallel  pseudocode  and  programming  model  were  in\u00fcuenc ed by Cilk [290, \n291,  383,  396].  The  open-source  project  OpenCilk  (www.open cilk.org) provides \nCilk programming as an extension to the C and C++ p rogramming languages. All \nof the parallel algorithms in this chapter can be c oded straightforwardly in Cilk. \nConcerns about nondeterministic parallel programs w ere expressed  by  Lee  [281]  \nand  Bocchino,  Adve,  Adve,  and  Snir  [64].  The  algorithms  literature contains many \nalgorithmic  strategies  (see,  for  example,  [60,  85,  118,  140,  160,  282,  283,  412,  \n461])  for  detecting  races  and  extending  the  fork-join  model  to avoid  or safely  em-  \nbrace various kinds of nondeterminism. Blelloch, Fi neman, Gibbons,  and  Shun  \n[59]  showed  that  deterministic  parallel  algorithms  can  often be as fast as, or even \nfaster than, their nondeterministic counterparts. \nSeveral of the parallel algorithms in this chapter appeared in unpublished lecture \nnotes by C. E. Leiserson and H. Prokop and were ori ginally implemented in Cilk. \nThe  parallel  merge-sorting  algorithm  was  inspired  by  an algorithm  due  to Akl  [12].  27  Online  Algorithms  \nMost problems described in this book have assumed t hat the entire  input  was  avail-  \nable before the algorithm executes. In many situati ons, however, the input becomes \navailable not in advance, but only as the algorithm  executes. This idea was implicit \nin much of the discussion of data structures in Par t III. The reason that you want \nto design, for example, a data structure that can h andle n I NSERT , DELETE , and \nSEARCH operations in O.lg n/ time per operation is most likely because you are \ngoing to receive n such operation requests without knowing in advance what oper- \nations will be coming. This idea was also implicit in amortized analysis  in Chap-  \nter  16,  where  we  saw  how  to maintain  a table  that  can  grow  or shrink in response \nto a sequence of insertion and deletion operations,  yet with a constant amortized \ncost per operation. \nAn online  algorithm  receives its input progressively over time, rather than hav- \ning the entire input available at the start, as in an of\u00fcine  algorithm. Online  algo-  \nrithms pertain to many situations in which informat ion arrives gradually. A stock \ntrader must make decisions today, without knowing w hat the prices  will  be tomor-  \nrow, yet wants to achieve good returns. A computer system must schedule arriving \njobs without knowing what work will need to be done  in the future. A store must \ndecide when to order more inventory without knowing  what the future demand will \nbe.  A driver  for  a ride-hailing  service  must  decide  whether  to pick up a fare without \nknowing who will request rides in the future. In ea ch of these situations, and many \nmore, algorithmic decisions must be made without kn owledge of the future. \nThere are several approaches for dealing with unkno wn future inputs.  One  ap-  \nproach is to form a probabilistic model of future i nputs and design an algorithm \nthat assumes future inputs conform to the model. Th is technique is common, for \nexample,  in the  \u00fbeld  of queuing  theory,  and  it is also  related  to machine learning. \nOf  course,  you  might  not  be able  to develop  a workable  probabi listic model, or \neven if you can, some inputs might not conform to i t. This chapter  takes  a differ-  792 Chapter 27 Online Algorithms \nent approach. Instead of assuming anything about th e future input, we employ a \nconservative strategy of limiting how poor a soluti on any input can entail. \nThis  chapter,  therefore,  adopts  a worst-case  approach,  designing  online  algo-  \nrithms that guarantee the quality of the solution f or all possible  future  inputs.  We\u2019ll  \nanalyze online algorithms by comparing the solution  produced by  the  online  algo-  \nrithm with a solution produced by an optimal algori thm that knows  the  future  in-  \nputs,  and  taking  a worst-case  ratio  over  all  possible  instances.  We  call  this  method-  \nology competitive  analysis. We\u2019ll  use  a similar  approach  when  we  study  approx-  \nimation  algorithms  in Chapter  35,  where  we\u2019ll  compare  the  solution returned by \nan algorithm that might be suboptimal with the valu e of the optimal solution, and \ndetermine  a worst-case  ratio  over  all  possible  instances.  \nWe start with a <toy= problem: deciding between whe ther to take the elevator \nor the stairs. This problem will introduce the basi c methodology of thinking about \nonline algorithms and how to analyze them via compe titive analysis. We will then \nlook  at two  problems  that  use  competitive  analysis.  The  \u00fbrst  is how to maintain a \nsearch list so that the access time is not too larg e, and the second is about strategies \nfor deciding which cache blocks to evict from a cac he or other kind of fast computer \nmemory. \n27.1  Waiting  for  an  elevator  \nOur  \u00fbrst  example  of an online  algorithm  models  a problem  that  you likely have \nencountered yourself: whether you should wait for a n elevator to arrive or just take \nthe stairs. Suppose that you enter a building and w ish to visit an of\u00fbce  that  is k \n\u00fcoors  up.  You  have  two  choices:  walk  up  the  stairs  or take  the  elevator.  Let\u2019s  \nassume, for convenience, that you can climb the sta irs at the rate  of one  \u00fcoor  per  \nminute. The elevator travels much faster than you c an climb the stairs: it can ascend \nall k \u00fcoors  in just  one  minute.  Your  dilemma  is that  you  do  not  know  how long it \nwill  take  for  the  elevator  to arrive  at the  ground  \u00fcoor  and  pick you up. Should you \ntake  the  elevator  or the  stairs?  How  do  you  decide?  \nLet\u2019s  analyze  the  problem.  Taking  the  stairs  takes  k minutes, no matter what. \nSuppose you know that the elevator takes at most B \ue003 1 minutes to arrive for some \nvalue of B that is considerably higher than k. (The elevator could be going up \nwhen  you  call  for  it and  then  stop  at several  \u00fcoors  on  its  way  down.) To keep \nthings  simple,  let\u2019s  also  assume  that  the  number  of minutes  for the elevator to \narrive is an integer. Therefore, waiting for the el evator and taking it k \u00fcoors  up  \ntakes anywhere from one minute (if the elevator is already at the  ground  \u00fcoor)  to \n.B  \ue003 1/ C 1 D B minutes (the worst case). Although you know B and k, you  don\u2019t  \nknow how long the elevator will take to arrive this  time. You can use competitive 27.1 Waiting for an elevator 793 \nanalysis to inform your decision regarding whether to take the stairs or elevator. \nIn the spirit of competitive analysis, you want to be sure that, no matter what the \nfuture brings (i.e., how long the elevator takes to  arrive), you will not wait much \nlonger than a seer who knows when the elevator will  arrive. \nLet  us \u00fbrst  consider  what  the  seer  would  do.  If the  seer  knows  that the elevator \nis going to arrive in at most k \ue003 1 minutes, the seer waits for the elevator, and \notherwise, the seer takes the stairs. Letting m denote the number of minutes it \ntakes  for  the  elevator  to arrive  at the  ground  \u00fcoor,  we  can  express the time that the \nseer spends as the function \nt.m/  D ( \nm C 1 if m \u0dc4 k \ue003 1;  \nk if m \ue004 k:  (27.1)  \nWe typically evaluate online algorithms by their competitive  ratio . Let U denote \nthe set (universe) of all possible inputs, and cons ider some input I 2 U. For \na minimization  problem,  such  as the  stairs-versus-elevato r problem, if an online \nalgorithm A produces a solution with value A.I/  on input I and the solution from \nan algorithm F that knows the future has value F.I/  on the same input, then the \ncompetitive ratio of algorithm A is \nmax fA.I/=F.I/  W I 2 Ug : \nIf an online algorithm has a competitive ratio of c , we say that it is c -competitive . \nThe competitive ratio is always at least 1, so that we want an online algorithm with \na competitive ratio as close to 1 as possible. \nIn the  stairs-versus-elevator  problem,  the  only  input  is the  time  for  the  eleva-  \ntor to arrive. Algorithm F knows this information, but an online algorithm has  \nto make a decision without knowing when the elevato r will arrive. Consider the \nalgorithm <always take the stairs,= which always ta kes exactly k minutes. Using \nequation  (27.1),  the  competitive  ratio  is \nmax fk=t.m/  W 0 \u0dc4 m \u0dc4 B \ue003 1g : (27.2)  \nEnumerating  the  terms  in equation  (27.2)  gives  the  competit ive ratio as \nmax \u00ef k \n1 ; k \n2 ; k \n3 ;:::;  k \n.k \ue003 1/ ; k \nk ; k \nk ;:::;  k \nk \u00f0 \nD k;  \nso that the competitive ratio is k. The maximum is achieved when the elevator \narrives immediately. In this case, taking the stair s requires k minutes, but the \noptimal solution takes just 1 minute. \nNow  let\u2019s  consider  the  opposite  approach:  <always  take  the  elevator.= If it takes \nm minutes  for  the  elevator  to arrive  at the  ground  \u00fcoor,  then  this algorithm will \nalways take m C 1 minutes. Thus the competitive ratio becomes \nmax f.m  C 1/=t.m/  W 0 \u0dc4 m \u0dc4 B \ue003 1g ; 794 Chapter 27 Online Algorithms \nwhich we can again enumerate as \nmax \u00ef 1 \n1 ; 2 \n2 ;:::;  k \nk ; k C 1 \nk ; k C 2 \nk ;:::;  B \nk \u00f0 \nD B \nk : \nNow the maximum is achieved when the elevator takes  B \ue003 1 minutes to arrive, \ncompared with the optimal approach of taking the st airs, which requires k minutes. \nHence, the algorithm <always take the stairs= has c ompetitive ratio k, and the \nalgorithm <always take the elevator= has competitiv e ratio B=k . Because we prefer \nthe algorithm with smaller competitive ratio, if k D 10  and B D 300, we prefer \n<always take the stairs,= with competitive ratio 10, over <always take the elevator,= \nwith competitive ratio 30. Taking the stairs is not always better, or necess arily \nmore  often  better.  It\u2019s  just  that  taking  the  stairs  guards  better  against  the  worst-case  \nfuture. \nThese two approaches of always taking the stairs an d always taking the elevator \nare extreme solutions, however. Instead, you can <h edge your bets= and guard even \nbetter  against  a worst-case  future.  In particular,  you  can  wait for the elevator for a \nwhile,  and  then  if it doesn\u2019t  arrive,  take  the  stairs.  How  long  is <a while=?  Let\u2019s  say  \nthat <a while= is k minutes. Then the time h.m/  required by this hedging strategy, \nas a function of the number m of minutes before the elevator arrives, is \nh.m/  D ( \nm C 1 if m \u0dc4 k;  \n2k  if m>k:  \nIn the second case, h.m/  D 2k  because you wait for k minutes and then climb the \nstairs for k minutes. The competitive ratio is now \nmax fh.m/=t.m/  W 0 \u0dc4 m \u0dc4 B \ue003 1g : \nEnumerating this ratio yields \nmax \u00ef 1 \n1 ; 2 \n2 ;:::;  k \nk ; k C 1 \nk ; 2k  \nk ; 2k  \nk ; 2k  \nk ;:::;  2k  \nk \u00f0 \nD 2:  \nThe competitive ratio is now independent of k and B . \nThis example illustrates a common philosophy in onl ine algorithms: we want \nan algorithm that guards against any possible worst  case. Initially, waiting for the \nelevator guards against the case when the elevator arrives quickly, but eventually \nswitching to the stairs guards against the case whe n the elevator takes a long time \nto arrive. 27.2  Maintaining  a search  list  795 \nExercises  \n27.1-1  \nSuppose that when hedging your bets, you wait for p minutes, instead of for k \nminutes, before taking the stairs. What is the comp etitive ratio as a function of p \nand k? How  should  you  choose  p to minimize  the  competitive  ratio?  \n27.1-2  \nImagine that you decide to take up downhill skiing.  Suppose that a pair of skis \ncosts r dollars to rent for a day and b dollars to buy, where b>r  . If you knew in \nadvance how many days you would ever ski, your deci sion whether to rent or buy \nwould  be easy.  If you\u2019ll  ski  for  at least  db=r  e days, then you should buy skis, and \notherwise you should rent. This strategy minimizes the total that you ever spend. \nIn reality,  you  don\u2019t  know  in advance  how  many  days  you\u2019ll  eventually ski. Even \nafter  you  have  skied  several  times,  you  still  don\u2019t  know  how  many more times \nyou\u2019ll  ever  ski.  Yet  you  don\u2019t  want  to waste  your  money.  Give  and analyze an \nalgorithm that has a competitive ratio of 2, that is, an algorithm guaranteeing that, \nno matter how many times you ski, you never spend m ore than twice what you \nwould have spent if you knew from the outset how ma ny times you \u2019ll ski.  \n27.1-3  \nIn <concentration solitaire,= a game for one person , you have n pairs of matching \ncards. The backs of the cards are all the same, but  the fronts contain pictures of \nanimals.  One  pair  has  pictures  of aardvarks,  one  pair  has  pictures of bears, one pair \nhas pictures of camels, and so on. At the start of the game, the cards are all placed \nface down. In each round, you can turn two cards fa ce up to reveal their pictures. If \nthe pictures match, then you remove that pair from the game. If they  don\u2019t  match,  \nthen you turn both of them over, hiding their pictu res once again. The game ends \nwhen you have removed all n pairs, and your score is how many rounds you needed  \nto do so. Suppose that you can remember the picture  on every card that you have \nseen.  Give  an algorithm  to play  concentration  solitaire  that has a competitive ratio \nof 2. \n27.2  Maintaining  a search  list  \nThe next example of an online algorithm pertains to  maintaining  the  order  of ele-  \nments  in a linked  list,  as in Section  10.2.  This  problem  often  arises in practice for \nhash tables when collisions are resolved by chainin g (see Section  11.2),  since  each  \nslot contains a linked list. Reordering the linked list of elements in each slot of the \nhash table can boost the performance of searches me asurably. 796 Chapter 27 Online Algorithms \nThe  list-maintenance  problem  can  be set  up  as follows.  You  are given a list L of \nn elements fx 1 ;x  2 ;:::;x  n g. We\u2019ll  assume  that  the  list  is doubly  linked,  although  \nthe algorithms and analysis work just as well for s ingly linked lists. Denote the \nposition of element x i in the list L by r L .x i /, where 1 \u0dc4 r L .x i / \u0dc4 n. Calling \nLIST-SEARCH .L;x  i / on  page  260  thus  takes  \u201a.r  L .x i // time. \nIf you know in advance something about the distribu tion of search requests, then \nit makes sense to arrange the list ahead of time to  put the more frequently searched \nelements closer to the front, which minimizes the t otal cost (see  Exercise  27.2-1).  \nIf instead  you  don\u2019t  know  anything  about  the  search  sequence , then no matter how \nyou arrange the list, it is possible that every sea rch is for whatever element appears \nat the tail of the list. The total searching time w ould then be \u201a.nm/ , where m is \nthe number of searches. \nIf you notice patterns in the access sequence or yo u observe differences in the \nfrequencies in which elements are accessed, then yo u might want to rearrange the \nlist as you perform searches. For example, if you d iscover that every search is for a \nparticular element, you could move that element to the front of the list. In general, \nyou could rearrange the list after each call to L IST-SEARCH . But how would you \ndo  so without  knowing  the  future?  After  all,  no  matter  how  you  move elements \naround, every search could be for the last element.  \nBut it turns out that some search sequences are <ea sier= than others. Rather than \njust  evaluate  performance  on  the  worst-case  sequence,  let\u2019s  compare  a reorganiza-  \ntion  scheme  with  whatever  an optimal  of\u00fcine  algorithm  would  do if it knew the \nsearch sequence in advance. That way, if the sequen ce is fundamentally hard, the \noptimal  of\u00fcine  algorithm  will  also  \u00fbnd  it hard,  but  if the  sequence is easy, we can \nhope to do reasonably well. \nTo  ease  analysis,  we\u2019ll  drop  the  asymptotic  notation  and  say  that the cost is \njust i to search for the i th element  in the  list.  Let\u2019s  also  assume  that  the  only  way  \nto reorder the elements in the list is by swapping two adjacent elements in the list. \nBecause the list is doubly linked, each swap incurs  a cost of 1. Thus, for example, \na search for the sixth element followed by moving i t forward two places (entailing \ntwo swaps) incurs a total cost 8. The goal is to minimize the total cost of calls t o \nLIST-SEARCH plus the total number of swaps performed. \nThe  online  algorithm  that  we\u2019ll  explore  is MOVE-TO-FRONT  .L;x/. This  proce-  \ndure  \u00fbrst  searches  for  x in the doubly linked list L, and then it moves x to the front \nof the list. 1 If x is located at position r D r L .x/  before the call, M OVE-TO-FRONT  \nswaps x with the element in position r \ue003 1, then with the element in position r \ue003 2, \n1 The  path-compression  heuristic  in Section  19.3  resembles  MOVE-TO-FRONT , although it would \nbe more  accurately  expressed  as <move-to-next-to-front.=  Unlike M OVE-TO-FRONT  in a doubly \nlinked list, path compression can relocate multiple  elements to become  <next-to-front.=  27.2  Maintaining  a search  list  797 \nFORESEE  MOVE-TO-FRONT  \nsearch + search + \nelement search swap swap cumulative search swap swap cumulative \nsearched L cost cost cost cost L cost cost cost cost \n5 h1;2;3;4;5 i 5 0 5 5 h1;2;3;4;5 i 5 4 9 9 \n3 h1;2;3;4;5 i 3 3 6 11  h5;1;2;3;4 i 4 3 7 16  \n4 h4;1;2;3;5 i 1 0 1 12  h3;5;1;2;4 i 5 4 9 25  \n4 h4;1;2;3;5 i 1 0 1 13  h4;3;5;1;2 i 1 0 1 26  \nFigure  27.1  The costs incurred by the procedures F ORESEE  and MOVE-TO-FRONT  when  search-  \ning for the elements 5, 3, 4, and 4, starting with the list L D h1;2;3;4;5 i. If FORESEE  instead \nmoved 3 to the front after the search for 5, the cumulative cost would not change, nor would t he \ncumulative cost change if 4 moved to the second position after the search for 5. \nand  so on,  until  it \u00fbnally  swaps  x with the element in position 1. Thus if the call \nMOVE-TO-FRONT  .L;8/  executes on the list L D h5;3;12;4;8;9;22 i, the list \nbecomes h8;5;3;12;4;9;22 i. The call M OVE-TO-FRONT  .L;k/  costs 2r L .k/  \ue003 1: \nit costs r L .k/  to search for k, and it costs 1 for each of the r L .k/  \ue003 1 swaps that \nmove k to the front of the list. \nWe\u2019ll  see  that  MOVE-TO-FRONT  has a competitive ratio of 4. Let\u2019s  think  about  \nwhat this means. M OVE-TO-FRONT  performs a series of operations on a doubly \nlinked list, accumulating cost. For comparison, sup pose that there is an algorithm \nFORESEE  that knows the future. Like M OVE-TO-FRONT , it also searches the list \nand moves elements around, but after each call it o ptimally rearranges the list for \nthe future. (There may be more than one optimal ord er.) Thus F ORESEE  and \nMOVE-TO-FRONT  maintain different lists of the same elements. \nConsider  the  example  shown  in Figure  27.1.  Starting  with  the  list h1;2;3;4;5 i , \nfour searches occur, for the elements 5, 3, 4, and 4. The hypothetical procedure \nFORESEE , after searching for 3, moves 4 to the front of the list, knowing that a \nsearch for 4 is imminent. It thus incurs a swap cost of 3 upon its second call, after \nwhich no further swap costs accrue. M OVE-TO-FRONT  incurs swap costs in each \nstep, moving the found element to the front. In thi s example, M OVE-TO-FRONT  \nhas a higher cost in each step, but that is not nec essarily always the case. \nThe key to proving the competitive bound is to show  that at any point, the total \ncost of MOVE-TO-FRONT  is not much higher than that of F ORESEE . Surprisingly, \nwe can determine a bound on the costs incurred by M OVE-TO-FRONT  relative to \nFORESEE  even though M OVE-TO-FRONT  cannot see the future. \nIf we compare any particular step, M OVE-TO-FRONT  and FORESEE  may  be op-  \nerating on very different lists and do very differe nt things. If we focus on the search \nfor 4 above, we observe that F ORESEE  actually moves it to the front of the list early, \npaying to move the element to the front before it i s accessed. To  capture  this  con-  798 Chapter 27 Online Algorithms \ncept, we use the idea of an inversion : a pair of elements, say a and b, in which a \nappears before b in one list, but b appears before a in another list. For two lists L \nand L 0 , let I.L;L  0 /, called the inversion  count , denote the number of inversions \nbetween the two lists, that is, the number of pairs  of elements whose order differs in \nthe two lists. For example, with lists L D h5;3;1;4;2 i and L 0 D h3;1;2;4;5 i, then \nout of the \u00e3 5 \n2 \u00e4 \nD 10  pairs,  exactly  \u00fbve  of them4.1;5/;.2;4/;.2;5/;.3;5/;.4;5/  \n4are  inversions,  since  these  pairs,  and  only  these  pairs,  appear in different orders \nin the two lists. Thus the inversion count is I.L;L  0 / D 5. \nIn order  to analyze  the  algorithm,  we  de\u00fbne  the  following  notation. Let L M  \ni be \nthe list maintained by M OVE-TO-FRONT  immediately after the i th search, and \nsimilarly, let L F \ni be FORESEE\u2019s list  immediately  after  the  i th search. Let c M  \ni \nand c F \ni be the costs incurred by M OVE-TO-FRONT  and FORESEE  on their i th \ncalls,  respectively.  We  don\u2019t  know  how  many  swaps  FORESEE  performs in its i th \ncall,  but  we\u2019ll  denote  that  number  by  t i . Therefore, if the i th operation is a search \nfor element x , then \nc M  \ni D 2r L M  \ni \ue0031 .x/  \ue003 1;  (27.3)  \nc F \ni D r L F \ni \ue0031 .x/  C t i : (27.4)  \nIn order  to compare  these  costs  more  carefully,  let\u2019s  break  down the elements \ninto subsets, depending on their positions in the t wo lists before the i th search, \nrelative to the element x being searched for in the i th search.  We  de\u00fbne  three  sets:  \nBB D felements before x in both L M  \ni \ue0021 and L F \ni \ue0021 g ; \nBA D felements before x in L M  \ni \ue0021 but after x in L F \ni \ue0021 g ; \nAB D felements after x in L M  \ni \ue0021 but before x in L F \ni \ue0021 g : \nWe can now relate the position of element x in L F \ni \ue0021 and L M  \ni \ue0021 to the sizes of these \nsets: \nr L M  \ni \ue0031 .x/  D jBBj C jBAj C  1;  (27.5)  \nr L F \ni \ue0031 .x/  D jBBj C jABj C  1:  (27.6)  \nWhen a swap occurs in one of the lists, it changes the relative positions of the \ntwo elements involved, which in turn changes the in version count. Suppose that \nelements x and y are swapped in some list. Then the only possible di fference in \nthe inversion count between this list and any  other list depends on whether .x;y/  \nis an inversion. In fact, the inversion count of .x;y/  with respect to any other list \nmust  change. If .x;y/  is an inversion before the swap, it no longer is af terward, \nand vice versa. Therefore, if two consecutive eleme nts x and y swap positions in \na list L, then for any other list L 0 , the value of the inversion count I.L;L  0 / either \nincreases by 1 or decreases by 1. 27.2  Maintaining  a search  list  799 \nAs we compare M OVE-TO-FRONT  and FORESEE  searching and modifying their \nlists,  we\u2019ll  think  about  MOVE-TO-FRONT  executing on its list for the i th time \nand then F ORESEE  executing on its list for the i th time. After M OVE-TO-FRONT  \nhas executed for the i th time and before F ORESEE  has executed for the i th time, \nwe\u2019ll  compare  I.L  M  \ni \ue0021 ;L  F \ni \ue0021 / (the inversion count immediately before the i th call \nof MOVE-TO-FRONT ) with I.L  M  \ni ;L  F \ni \ue0021 / (the inversion count after the i th call of \nMOVE-TO-FRONT  but before the i th call of F ORESEE). We\u2019ll  concern  ourselves  \nlater with what F ORESEE  does. \nLet us analyze what happens to the inversion count after executing the i th call \nof MOVE-TO-FRONT , and suppose that it searches for element x . More precisely, \nwe\u2019ll  compute  I.L  M  \ni ;L  F \ni \ue0021 / \ue003 I.L  M  \ni \ue0021 ;L  F \ni \ue0021 /, the change in the inversion count, \nwhich gives a rough idea of how much M OVE-TO-FRONT\u2019s list  becomes  more  or \nless like F ORESEE\u2019s list.  After  searching,  MOVE-TO-FRONT  performs a series of \nswaps with each of the elements on the list L M  \ni \ue0021 that precedes x . Using the notation \nabove, the number of such swaps is jBBj C jBAj. Bearing in mind that the list L F \ni \ue0021 \nhas yet to be changed by the i th call of F ORESEE, let\u2019s  see  how  the  inversion  count  \nchanges. \nConsider a swap with an element y 2 BB. Before the swap, y precedes x \nin both L M  \ni \ue0021 and L F \ni \ue0021 . After the swap, x precedes y in L M  \ni , and L F \ni \ue0021 does not \nchange. Therefore, the inversion count increases by  1 for each element in BB. Now \nconsider a swap with an element \u00b4 2 BA. Before the swap, \u00b4 precedes x in L M  \ni \ue0021 \nbut x precedes \u00b4 in L F \ni \ue0021 . After the swap, x precedes \u00b4 in both lists. Therefore, \nthe inversion count decreases by 1 for each element in BA. Thus altogether, the \ninversion count increases by \nI.L  M  \ni ;L  F \ni \ue0021 / \ue003 I.L  M  \ni \ue0021 ;L  F \ni \ue0021 / D jBBj \ue003 jBAj : (27.7)  \nWe have laid the groundwork needed to analyze M OVE-TO-FRONT . \nTheorem  27.1  \nAlgorithm M OVE-TO-FRONT  has a competitive ratio of 4. \nProof  The proof uses a potential function, as described i n Chapter 16  on  amor-  \ntized analysis. The value \u02c6 i of the potential function after the i th calls of M OVE- \nTO-FRONT  and FORESEE  depends on the inversion count: \n\u02c6 i D 2I.L  M  \ni ;L  F \ni /: \n(Intuitively, the factor of 2 embodies the notion that each inversion represents a \ncost of 2 for MOVE-TO-FRONT  relative to F ORESEE : 1 for searching and 1 for \nswapping.)  By  equation  (27.7),  after  the  i th call of M OVE-TO-FRONT , but before \nthe i th call of F ORESEE , the potential increases by 2.jBBj \ue003 j BAj/. Since the \ninversion count of the two lists is nonnegative, we  have \u02c6 i \ue004 0 for all i \ue004 0. 800 Chapter 27 Online Algorithms \nAssuming that M OVE-TO-FRONT  and FORESEE  start with the same list, the initial \npotential \u02c6 0 is 0, so that \u02c6 i \ue004 \u02c6 0 for all i . \nDrawing  from  equation  (16.2)  on  page  456,  the  amortized  cost  y c M  \ni of the i th \nMOVE-TO-FRONT  operation is \ny c M  \ni D c M  \ni C \u02c6 i \ue003 \u02c6 i \ue0021 ; \nwhere c M  \ni , the actual cost of the i th MOVE-TO-FRONT  operation, is given by \nequation  (27.3):  \nc M  \ni D 2r L M  \ni \ue0031 .x/  \ue003 1:  \nNow,  let\u2019s  consider  the  potential  change  \u02c6 i \ue003 \u02c6 i \ue0021 . Since both L M  and L F \nchange,  let\u2019s  consider  the  changes  to one  list  at a time.  Reca ll that when M OVE- \nTO-FRONT  moves element x to the front, it increases the potential by exactly  \n2.jBBj \ue003 jBAj/. We now consider how the optimal algorithm F ORESEE  changes its \nlist L F : it performs t i swaps. Each swap performed by F ORESEE  either increases \nor decreases the potential by 2, and thus the increase in potential by F ORESEE  in \nthe i th call can be at most 2t i . We therefore have \ny c M  \ni D c M  \ni C \u02c6 i \ue003 \u02c6 i \ue0021 \n\u0dc4 2r L M  \ni \ue0031 .x/  \ue003 1 C 2.jBBj \ue003 jBAj C  t i / \nD 2r L M  \ni \ue0031 .x/  \ue003 1 C 2.jBBj \ue003  .r L M  \ni \ue0031 .x/  \ue003 1 \ue003 jBBj/ C t i / \n(by  equation  (27.5))  \nD 4 jBBj C  1 C 2t i \n\u0dc4 4 jBBj C  4 jABj C  4 C 4t i (increasing some terms) \nD 4.jBBj C jABj C  1 C t i / \nD 4.r  L F \ni \ue0031 .x/  C t i / (by  equation  (27.6))  \nD 4c  F \ni (by  equation  (27.4))  . (27.8)  \nWe  now  \u00fbnish  the  proof  as in Chapter  16  by  showing  that  the  total amortized \ncost provides an upper bound on the total actual co st, because the initial potential \nfunction is 0 and the potential function is always nonnegative. B y equation  (16.3)  \non  page  456,  for  any  sequence  of m MOVE-TO-FRONT  operations, we have \nm X  \ni D1 y c M  \ni D m X  \ni D1 c M  \ni C \u02c6 m \ue003 \u02c6 0 \n\ue004 m X  \ni D1 c M  \ni (because \u02c6 m \ue004 \u02c6 0 ). (27.9)  27.2  Maintaining  a search  list  801 \nTherefore, we have \nm X  \ni D1 c M  \ni \u0dc4 m X  \ni D1 y c M  \ni (by  equation  (27.9))  \n\u0dc4 m X  \ni D1 4c  F \ni (by  equation  (27.8))  \nD 4 m X  \ni D1 c F \ni : \nThus the total cost of the m MOVE-TO-FRONT  operations is at most 4 times the \ntotal cost of the m FORESEE  operations, so M OVE-TO-FRONT  is 4-competitive.  \nIsn\u2019t  it amazing  that  we  can  compare  MOVE-TO-FRONT  with  the  optimal  algo-  \nrithm FORESEE  when we have no idea of the swaps that F ORESEE  makes?  We  \nwere able to relate the performance of M OVE-TO-FRONT  to the optimal algorithm \nby capturing how particular properties (swaps in th is case) must evolve relative to \nthe optimal algorithm, without actually knowing the  optimal algorithm. \nThe online algorithm M OVE-TO-FRONT  has a competitive ratio of 4: on any \ninput sequence, it incurs a cost at most 4 times  that  of any  other  algorithm.  On  a \nparticular input sequence, it could cost much less than 4 times  the  optimal  algo-  \nrithm, perhaps even matching the optimal algorithm.  \nExercises  \n27.2-1  \nYou are given a set S D fx 1 ;x  2 ;:::;x  n g of n elements, and you wish to make a \nstatic list L (no rearranging once the list is created) containin g the elements of S \nthat is good for searching. Suppose that you have a  probability distribution, where \np.x  i / is the probability that a given search searches for  element x i . Argue that the \nexpected cost for m searches is \nm n X  \ni D1 p.x  i / \ue001 r L .x i /: \nProve that this sum is minimized when the elements of L are sorted in decreasing \norder with respect to p.x  i /. \n27.2-2  \nProfessor Carnac claims that since F ORESEE  is an optimal algorithm that knows \nthe future, then at each step it must incur no more  cost than M OVE-TO-FRONT . \nEither prove that Professor Carnac is correct or pr ovide a counterexample. 802 Chapter 27 Online Algorithms \n27.2-3  \nAnother  way  to maintain  a linked  list  for  ef\u00fbcient  searching  is for each element \nto maintain a frequency  count : the number of times that the element has been \nsearched for. The idea is to rearrange list element s after searches so that the list is \nalways sorted by decreasing frequency count, from l argest to smallest. Either show \nthat this algorithm is O.1/-competitive,  or prove  that  it is not.  \n27.2-4  \nThe model in this section charged a cost of 1 for each swap. We can consider \nan alternative cost model in which, after accessing  x , you can move x anywhere \nearlier in the list, and there is no cost for doing  so. The only cost is the cost of the \nactual accesses. Show that M OVE-TO-FRONT  is 2-competitive  in this  cost  model,  \nassuming  that  the  number  requests  is suf\u00fbciently  large.  (Hint: Use the potential \nfunction \u02c6 i D I.L  M  \ni ;L  F \ni /.) \n27.3  Online  caching  \nIn Section  15.4,  we  studied  the  caching  problem,  in which  blocks  of data from the \nmain memory of a computer are stored in the cache : a small but faster memory. In \nthat  section,  we  studied  the  of\u00fcine  version  of the  problem,  in which we assumed \nthat we knew the sequence of memory requests in adv ance, and we designed an \nalgorithm to minimize the number of cache misses. I n almost all computer  sys-  \ntems, caching is, in fact, an online problem. We do  not generally know the series \nof cache requests in advance; they are presented to  the algorithm  only  as the  re-  \nquests for blocks are actually made. To gain a bett er understanding of this more \nrealistic scenario, we analyze online algorithms fo r caching.  We  will  \u00fbrst  see  that  \nall deterministic online algorithms for caching hav e a lower bound of \ufffd.k/  for \nthe competitive ratio, where k is the size of the cache. We will then present an \nalgorithm with a competitive ratio of \u201a.n/ , where the input size is n, and one \nwith a competitive ratio of O.k/ , which matches the lower bound. We will end \nby showing how to use randomization to design an al gorithm with a much better \ncompetitive ratio of \u201a.lg k/. We will also discuss the assumptions that underli e \nrandomized online algorithms, via the notion of an adversary, such as we saw in \nChapter  11  and  will  see  in Chapter  31.  \nYou  can  \u00fbnd  the  terminology  used  to describe  the  caching  problem  in Sec-  \ntion  15.4,  which  you  might  wish  to review  before  proceeding.  27.3  Online  caching  803 \n27.3.1  Deterministic  caching  algorithms  \nIn the caching problem, the input comprises a seque nce of n memory requests, for \ndata in blocks b 1 ;b  2 ;:::;b  n , in that order. The blocks requested are not neces sarily \ndistinct: each block may appear multiple times with in the request sequence. After \nblock b i is requested, it resides in a cache that can hold u p to k blocks, where k is \na \u00fbxed  cache  size.  We  assume  that  n>k , since otherwise we are assured that the \ncache can hold all the requested blocks at once. Wh en a block b i is requested, if it \nis already in the cache, then a cache  hit  occurs and the cache remains unchanged. \nIf b i is not in the cache, then a cache  miss  occurs. If the cache contains fewer \nthan k blocks upon a cache miss, block b i is placed into the cache, which now \ncontains one block more than before. If a cache mis s occurs with an already full \ncache, however, some block must be evicted from the  cache before b i can enter. \nThus, a caching algorithm must decide which block t o evict from the cache upon \na cache miss when the cache is full. The goal is to  minimize the number of cache \nmisses over the entire request sequence. The cachin g algorithms considered in this \nchapter differ only in which block they decide to e vict upon a cache miss. We \ndo not consider abilities such as prefetching, in w hich a block is brought into the \ncache before an upcoming request in order to avert a future cache miss. \nThere are many online caching policies to determine  which block  to evict,  in-  \ncluding the following: \n\ue001 First-in,  \u00fbrst-out  (FIFO):  evict  the  block  that  has  been  in the cache the longest \ntime. \n\ue001 Last-in,  \u00fbrst-out  (LIFO):  evict  the  block  that  has  been  in the cache the shortest \ntime. \n\ue001 Least Recently Used (LRU): evict the block whose la st use is furthest in the \npast. \n\ue001 Least Frequently Used (LFU): evict the block that h as been accessed the fewest \ntimes, breaking ties by choosing the block that has  been in the cache the longest. \nTo analyze these algorithms, we assume that the cac he starts out empty, so that \nno  evictions  occur  during  the  \u00fbrst  k requests.  We  wish  to compare  the  perfor-  \nmance  of an online  algorithm  to an optimal  of\u00fcine  algorithm  that knows the future \nrequests. As we will soon see, all these determinis tic online algorithms have a \nlower bound of \ufffd.k/  for their competitive ratio. Some deterministic alg orithms \nalso have a competitive ratio with an O.k/  upper  bound,  but  some  other  determin-  \nistic algorithms are considerably worse, having a c ompetitive ratio of \u201a.n=k/ . \nWe  now  proceed  to analyze  the  LIFO  and  LRU  policies.  In additi on to assuming \nthat n>k , we will assume that at least k distinct  blocks  are  requested.  Otherwise,  \nthe  cache  never  \u00fblls  up  and  no  blocks  are  evicted,  so that  all  algorithms exhibit the \nsame  behavior.  We  begin  by  showing  that  LIFO  has  a large  compe titive ratio. 804 Chapter 27 Online Algorithms \nTheorem  27.2  \nLIFO  has  a competitive  ratio  of \u201a.n=k/  for the online caching problem with n \nrequests and a cache of size k. \nProof  We  \u00fbrst  show  a lower  bound  of \ufffd.n=k/ . Suppose that the input consists \nof k C 1 blocks, numbered 1;2;:::;k  C 1, and the request sequence is \n1; 2; 3; 4; :::; k; k  C 1; k; k C 1; k; k C 1; ::: ;  \nwhere after the initial 1;2;:::;k;k  C 1, the remainder of the sequence alternates \nbetween k and k C 1, with a total of n requests. The sequence ends on block k \nif n and k are either both even or both odd, and otherwise, th e sequence ends on \nblock kC1. That is, b i D i for i D 1;2;:::k \ue0031, b i D kC1 for i D kC1;kC3;:::  \nand b i D k for i D k;k  C 2;:::. How  many  blocks  does  LIFO  evict?  After  the  \n\u00fbrst  k requests (which are considered to be cache misses),  the cache is \u00fblled  with  \nblocks 1;2;:::;k . The .k C 1/st request, which is for block k C 1, causes block k \nto be evicted. The .k C 2/nd request, which is for block k, forces block k C 1 to be \nevicted, since that block was just placed into the cache. This behavior continues, \nalternately evicting blocks k and k C 1 for  the  remaining  requests.  LIFO,  therefore,  \nsuffers a cache miss on every one of the n requests. \nThe  optimal  of\u00fcine  algorithm  knows  the  entire  sequence  of requests in advance. \nUpon  the  \u00fbrst  request  of block  k C 1, it just evicts any block except block k, and \nthen  it never  evicts  another  block.  Thus,  the  optimal  of\u00fcine  algorithm evicts only \nonce.  Since  the  \u00fbrst  k requests are considered cache misses, the total num ber of \ncache misses is k C 1. The competitive ratio, therefore, is n=.k  C 1/, or \ufffd.n=k/ . \nFor the upper bound, observe that on any input of s ize n, any caching algorithm \nincurs at most n cache misses. Because the input contains at least k distinct blocks, \nany  caching  algorithm,  including  the  optimal  of\u00fcine  algori thm, must incur at least \nk cache  misses.  Therefore,  LIFO  has  a competitive  ratio  of O.n=k/ . \nWe call such a competitive ratio unbounded , because it grows with the input \nsize.  Exercise  27.3-2  asks  you  to show  that  LFU  also  has  an unbounded competitive \nratio. \nFIFO  and  LRU  have  a much  better  competitive  ratio  of \u201a.k/ . There is a big \ndifference between competitive ratios of \u201a.n=k/  and \u201a.k/ . The cache size k is \nindependent of the input sequence and does not grow  as more requests arrive over \ntime. A competitive ratio that depends on n, on the other hand, does grow with \nthe size of the input sequence and thus can get qui te large. It is preferable to use \nan algorithm with a competitive ratio that does not  grow with the  input  sequence\u2019s  \nsize, when possible. \nWe now show that LRU has a competitive ratio of \u201a.k/, \u00fbrst  showing  the  upper  \nbound. 27.3  Online  caching  805 \nTheorem  27.3  \nLRU has a competitive ratio of O.k/  for the online caching problem with n requests \nand a cache of size k. \nProof  To analyze LRU, we will divide the sequence of requ ests into epochs . \nEpoch 1 begins  with  the  \u00fbrst  request.  Epoch  i , for i > 1, begins  upon  encoun-  \ntering the .k C 1/st distinct request since the beginning of epoch i \ue003 1. Consider \nthe following example of requests with k D 3: \n1; 2; 1; 5; 4; 4; 1; 2; 4; 2; 3; 4; 5; 2; 2; 1; 2; 2:  (27.10)  \nThe  \u00fbrst  k D 3 distinct requests are for blocks 1, 2 and 5, so epoch 2 begins with \nthe  \u00fbrst  request  for  block  4. In epoch 2, the  \u00fbrst  3 distinct requests are for blocks \n4, 1, and 2. Requests for these blocks recur until the request  for block 3, and with \nthis request epoch 3 begins. Thus, this example has four epochs: \n1; 2; 1; 5 4; 4; 1; 2; 4; 2  3; 4; 5 2; 2; 1; 2; 2:  (27.11)  \nNow  we  consider  the  behavior  of LRU.  In each  epoch,  the  \u00fbrst  time  a re-  \nquest for a particular block appears, it may cause a cache miss, but subsequent \nrequests for that block within the epoch cannot cau se a cache miss, since the block \nis now one of the k most recently used. For example, in epoch 2, the  \u00fbrst  request  \nfor block 4 causes a cache miss, but the subsequent requests fo r block 4 do not. \n(Exercise  27.3-1  asks  you  to show  the  contents  of the  cache  after each request.) In \nepoch 3, requests for blocks 3 and 5 cause cache misses, but the request for block 4 \ndoes not, because it was recently accessed in epoch  2. Since  only  the  \u00fbrst  request  \nfor a block within an epoch can cause a cache miss and the cache holds k blocks, \neach epoch incurs at most k cache misses. \nNow  consider  the  behavior  of the  optimal  algorithm.  The  \u00fbrst  request in each \nepoch must cause a cache miss, even for an optimal algorithm. The  miss  occurs  be-  \ncause,  by  the  de\u00fbnition  of an epoch,  there  must  have been k other blocks accessed \nsince the last access to this block. \nSince, for each epoch, the optimal algorithm incurs  at least one miss and LRU \nincurs at most k, the competitive ratio is at most k=1  D O.k/ . \nExercise  27.3-3  asks  you  to show  that  FIFO  also  has  a competit ive ratio of O.k/ . \nWe could show lower bounds of \ufffd.k/  on  LRU  and  FIFO,  but  in fact,  we  can  \nmake a much stronger statement: any  deterministic online caching algorithm must \nhave a competitive ratio of \ufffd.k/ . The proof relies on an adversary who knows the \nonline algorithm being used and can tailor the futu re requests to cause the online \nalgorithm  to incur  more  cache  misses  than  the  optimal  of\u00fcine  algorithm. \nConsider a scenario in which the cache has size k and the set of possible blocks \nto request is f1;2;:::;k  C 1g. The  \u00fbrst  k requests are for blocks 1;2;:::;k , so 806 Chapter 27 Online Algorithms \nthat both the adversary and the deterministic onlin e algorithm place these blocks \ninto the cache. The next request is for block k C 1. In order to make room in \nthe cache for block k C 1, the online algorithm evicts some block b 1 from the \ncache. The adversary, knowing that the online algor ithm has just evicted block b 1 , \nmakes the next request be for b 1 , so that the online algorithm must evict some \nother block b 2 to clear room in the cache for b 1 . As you might have guessed, the \nadversary makes the next request be for block b 2 , so that the online algorithm evicts \nsome other block b 3 to make room for b 2 . The online algorithm and the adversary \ncontinue in this manner. The online algorithm incur s a cache miss on every request \nand therefore incurs n cache misses over the n requests. \nNow  let\u2019s  consider  an optimal  of\u00fcine  algorithm,  which  knows  the  future.  As  dis-  \ncussed  in Section  15.4,  this  algorithm  is known  as furthest-in-future,  and  it always  \nevicts the block whose next request is furthest in the future. Since there are only \nk C 1 unique  blocks,  when  furthest-in-future  evicts  a block,  we  know that it will \nnot be accessed during at least the next k requests.  Thus,  after  the  \u00fbrst  k cache \nmisses, the optimal algorithm incurs a cache miss a t most once every k requests. \nTherefore, the number of cache misses over n requests is at most k C n=k. \nSince the deterministic online algorithm incurs n cache misses and the optimal \nof\u00fcine  algorithm  incurs  at most  k C n=k  cache misses, the competitive ratio is at \nleast \nn \nk C n=k  D nk  \nn C k 2 : \nFor n \ue004 k 2 , the above expression is at least \nnk  \nn C k 2 \ue004 nk  \n2n  D k \n2 : \nThus,  for  suf\u00fbciently  long  request  sequences,  we  have  shown  the following: \nTheorem  27.4  \nAny deterministic online algorithm for caching with  a cache size of k has  compet-  \nitive ratio \ufffd.k/ . \nAlthough we can analyze the common caching strategi es from the point of view \nof competitive analysis, the results are somewhat u nsatisfying.  Yes,  we  can  dis-  \ntinguish between algorithms with a competitive rati o of \u201a.k/  and  those  with  un-  \nbounded competitive ratios. In the end, however, al l of these competitive ratios are \nrather high. The online algorithms we have seen so far are deterministic, and it is \nthis property that the adversary is able to exploit . 27.3  Online  caching  807 \n27.3.2  Randomized  caching  algorithms  \nIf we  don\u2019t  limit  ourselves  to deterministic  online  algorithms,  we  can  use  random-  \nization  to develop  an online  caching  algorithm  with  a signi\u00fbcantly  smaller  compet-  \nitive  ratio.  Before  describing  the  algorithm,  let\u2019s  discus s randomization in online \nalgorithms in general. Recall that we analyze onlin e algorithms with respect to \nan adversary who knows the online algorithm and can  design requests knowing the \ndecisions made by the online algorithm. With random ization, we must ask whether \nthe adversary also knows the random choices made by  the online algorithm.  An  ad-  \nversary who does not know the random choices is oblivious , and an adversary who \nknows the random choices is nonoblivious . Ideally, we prefer to design algorithms \nagainst a nonoblivious adversary, as this adversary  is stronger than an oblivious \none. Unfortunately, a nonoblivious adversary mitiga tes much of the  power  of ran-  \ndomness, as an adversary who knows the outcome of r andom choices typically can \nact as if the online algorithm is deterministic. Th e oblivious adversary, on the other \nhand, does not know the random choices of the onlin e algorithm, and that is the \nadversary we typically use. \nAs a simple illustration of the difference between an oblivious and nonoblivious \nadversary,  imagine  that  you  are  \u00fcipping  a fair  coin  n times, and the adversary wants \nto know  how  many  heads  you  \u00fcipped.  A nonoblivious  adversary  knows, after each \n\u00fcip,  whether  the  coin  came  up  heads  or tails,  and  hence  knows  how many heads \nyou  \u00fcipped.  An  oblivious  adversary,  on  the  other  hand,  knows  only that you are \n\u00fcipping  a fair  coin  n times. The oblivious adversary, therefore, can reas on that \nthe number of heads follows a binomial distribution , so that the expected number \nof heads is n=2  (by  equation  (C.41)  on  page  1199)  and  the  variance  is n=4  (by \nequation  (C.44)  on  page  1200).  But  the  oblivious  adversary  has no way of knowing \nexactly  how  many  heads  you  actually  \u00fcipped.  \nLet\u2019s  return  to caching.  We\u2019ll  start  with  a deterministic  algorithm  and  then  ran-  \ndomize  it. The  algorithm  we\u2019ll  use  is an approximation  of LRU  called MARKING . \nRather than <least recently used,= think of M ARKING  as simply <recently used.= \nMARKING  maintains a 1-bit  attribute  mark for each block in the cache. Initially, \nall blocks in the cache are unmarked. When a block is requested, if it is already \nin the cache, it is marked. If the request is a cac he miss, M ARKING  checks to \nsee whether there are any unmarked blocks in the ca che. If all blocks are marked, \nthen they are all changed to unmarked. Now, regardl ess of whether all blocks in \nthe cache were marked when the request occurred, th ere is at least one unmarked \nblock in the cache, and so an arbitrary unmarked bl ock is evicted, and the requested \nblock is placed into the cache and marked. \nHow should the block to evict from among the unmark ed blocks in the cache \nbe chosen?  The  procedure  RANDOMIZED -MARKING  on the next page shows the 808 Chapter 27 Online Algorithms \nprocess when the block is chosen randomly. The proc edure takes as input a block b \nbeing requested. \nRANDOMIZED -MARKING  .b/  \n1 if block b resides in the cache, \n2 b: mark D 1 \n3 else  \n4 if all blocks b 0 in the cache have b 0 : mark D 1 \n5 unmark all blocks b 0 in the cache, setting b 0 : mark D 0 \n6 select an unmarked block u with u: mark D 0 uniformly at random \n7 evict block u \n8 place block b into the cache \n9 b: mark D 1 \nFor the purpose of analysis, we say that a new epoc h begins immediately after \neach  time  line  5 executes.  An  epoch  starts  with  no  marked  blocks in the cache. \nThe  \u00fbrst  time  a block  is requested  during  an epoch,  the  number  of marked blocks \nincreases by 1, and any subsequent requests to that block do not change the n um-  \nber of marked blocks. Therefore, the number of mark ed blocks monotonically \nincreases within an epoch. Under this view, epochs are the same as in the proof of \nTheorem  27.3:  with  a cache  that  holds  k blocks, an epoch comprises requests for k \ndistinct  blocks  (possibly  fewer  for  the  \u00fbnal  epoch),  and  the  next epoch begins upon \na request for a block not in those k. \nBecause we are going to analyze a randomized algori thm, we will compute the \nexpected competitive ratio. Recall that for an inpu t I , we denote the solution value \nof an online algorithm A by A.I/  and the solution value of an optimal algorithm F \nby F.I/. Online  algorithm  A has an expected  competitive  ratio  c if for all inputs I , \nwe have \nE \u0152A.I /\ufffd  \u0dc4 cF.I/;  (27.12)  \nwhere the expectation is taken over the random choi ces made by A. \nAlthough the deterministic M ARKING  algorithm has a competitive ratio of \u201a.k/  \n(Theorem  27.4  provides  the  lower  bound  and  see  Exercise  27.3-4  for  the  upper  \nbound), R ANDOMIZED -MARKING  has a much smaller expected competitive ratio, \nnamely O.lg k/. The key to the improved competitive ratio is that  the adversary \ncannot always make a request for a block that is no t in the cache, since an oblivious \nadversary does not know which blocks are in the cac he. 27.3  Online  caching  809 \nTheorem  27.5  \nRANDOMIZED -MARKING  has an expected competitive ratio of O.lg k/  for the \nonline caching problem with n requests and a cache of size k, against an oblivious \nadversary. \nBefore  proving  Theorem  27.5,  we  prove  a basic  probabilistic  fact. \nLemma  27.6  \nSuppose that a bag contains x C y balls: x \ue003 1 blue balls, y white balls, and 1 red \nball. You repeatedly choose a ball at random and re move it from the bag until you \nhave chosen a total of m balls that are either blue or red, where m \u0dc4 x . You set \naside each white ball you choose. Then, one of the balls chosen is the red ball with \nprobability m=x  . \nProof  Choosing a white ball does not affect how many blue  or red balls are  cho-  \nsen in any way. Therefore, we can continue the anal ysis as if there were no white \nballs and the bag contains just x \ue003 1 blue balls and 1 red ball. \nLet A be the event that the red ball is not chosen, and l et A i be the event that the \ni th draw does not choose the red ball. By equation ( C.22) on pag e 1190,  we  have  \nPr fAg D  Pr fA 1 \\ A 2 \\ \ue001 \ue001 \ue001 \\  A m g \nD Pr fA 1 g \ue001 Pr fA 2 j A 1 g \ue001 Pr fA 3 j A 1 \\ A 2 g \ue001 \ue001 \ue001  \nPr fA m j A 1 \\ A 2 \\ \ue001 \ue001 \ue001 \\  A m\ue0021 g : (27.13)  \nThe probability Pr fA 1 g that  the  \u00fbrst  ball  is blue  equals  .x \ue003 1/=x  , since initially \nthere are x \ue003 1 blue balls and 1 red ball. More generally, we have \nPr fA i j A 1 \\ \ue001 \ue001 \ue001 \\  A i \ue0021 g D  x \ue003 i \nx \ue003 i C 1 ; (27.14)  \nsince the i th draw is from x \ue003 i blue balls and 1 red  ball.  Equations  (27.13)  \nand  (27.14)  give  \nPr fAg D  \u00cf x \ue003 1 \nx \u00d0\u00cf  x \ue003 2 \nx \ue003 1 \u00d0\u00cf  x \ue003 3 \nx \ue003 2 \u00d0 \n\ue001 \ue001 \ue001  \u00cf x \ue003 m C 1 \nx \ue003 m C 2 \u00d0\u00cf  x \ue003 m \nx \ue003 m C 1 \u00d0 \n: (27.15)  \nThe  right-hand  side  of equation  (27.15)  is a telescoping  product, similar to the \ntelescoping  series  in equation  (A.12)  on  page  1143.  The  nume rator of one term \nequals the denominator of the next, so that everyth ing except the  \u00fbrst  denominator  \nand last numerator cancel, and we obtain Pr fAg D  .x \ue003 m/=x  . Since we actually \nwant to compute Pr \u02da N A \ue009 D 1 \ue003 Pr fAg, that is, the probability that the red ball is \nchosen, we get Pr \u02da N A \ue009 \nD 1 \ue003 .x \ue003 m/=x  D m=x  . \nNow  we  can  prove  Theorem  27.5.  810 Chapter 27 Online Algorithms \nProof  We\u2019ll  analyze  RANDOMIZED -MARKING  one epoch at a time. Within \nepoch i , any request for a block b that  is not  the  \u00fbrst  request  for  block  b in epoch i \nmust  result  in a cache  hit,  since  after  the  \u00fbrst  request  in epoch i , block b resides in \nthe cache and is marked, so that it cannot be evict ed during the epoch. Therefore, \nsince  we  are  counting  cache  misses,  we\u2019ll  consider  only  the  \u00fbrst request for each \nblock within each epoch, disregarding all other req uests. \nWe can classify the requests in an epoch as either old or new. If block b resides \nin the cache at the start of epoch i , each request for block b during epoch i is an \nold  request. Old  requests  in epoch  i are for blocks requested in epoch i \ue003 1. If a \nrequest in epoch i is not old, it is a new  request , and it is for a block not requested \nin epoch i \ue003 1. All requests in epoch 1 are  new.  For  example,  let\u2019s  look  again  at \nthe  request  sequence  in example  (27.11):  \n1; 2; 1; 5 4; 4; 1; 2; 4; 2  3; 4; 5 2; 2; 1; 2; 2:  \nSince we can disregard all requests for a block wit hin an epoch other  than  the  \u00fbrst  \nrequest, to analyze the cache behavior, we can view  this request sequence as just \n1; 2; 5 4; 1; 2 3; 4; 5 2; 1:  \nAll three requests in epoch 1 are new. In epoch 2, the requests for blocks 1 and 2 \nare old, but the request for block 4 is new. In epoch 3, the request for block 4 is \nold, and the requests for blocks 3 and 5 are new. Both requests in epoch 4 are new. \nWithin an epoch, each new request must cause a cach e miss since, by  de\u00fbnition,  \nthe block is not already in the cache. An old reque st, on the other hand, may or \nmay not cause a cache miss. The old block is in the  cache at the beginning of the \nepoch, but other requests might cause it to be evic ted. Returning to our example, \nin epoch 2, the request for block 4 must cause a cache miss, as this request is \nnew. The request for block 1, which is old, may or may not cause a cache miss. \nIf block 1 was evicted when block 4 was requested, then a cache miss occurs and \nblock 1 must be brought back into the cache. If instead blo ck 1 was not evicted \nwhen block 4 was requested, then the request for block 1 results in a cache hit. The \nrequest for block 2 could  incur  a cache  miss  under  two  scenarios.  One  is if block  2 \nwas evicted when block 4 was requested. The other is if block 1 was evicted when \nblock 4 was requested, and then block 2 was evicted when block 1 was requested. \nWe see that, within an epoch, each ensuing old requ est has an increasing chance of \ncausing a cache miss. \nBecause  we  consider  only  the  \u00fbrst  request  for  each  block  within an epoch, we \nassume that each epoch contains exactly k requests, and each request within an \nepoch is for a unique block. (The last epoch might contain fewer than k requests. \nIf it does,  just  add  dummy  requests  to \u00fbll  it out  to k requests.) In epoch i , denote \nthe number of new requests by r i \ue004 1 (an epoch must contain at least one new 27.3  Online  caching  811 \nrequest), so that the number of old requests is k \ue003 r i . As mentioned above, a new \nrequest always incurs a cache miss. \nLet us now focus on an arbitrary epoch i to obtain a bound on the expected \nnumber of cache misses within that epoch. In partic ular, let\u2019s think  about  the  j th \nold request within the epoch, where 1 \u0dc4 j <k . Denote by b ij the block requested \nin the j th old request of epoch i , and denote by n ij and o ij the number of new \nand old requests, respectively, that occur within e poch i but before the j th old \nrequest. Because j \ue003 1 old requests occur before the j th old request, we have \no ij D j \ue003 1. We will show that the probability of a cache miss  upon the j th old \nrequest is n ij =.k  \ue003 o ij /, or n ij =.k  \ue003 j C 1/. \nStart  by  considering  the  \u00fbrst  old  request,  for  block  b i;1  . What is the probability \nthat  this  request  causes  a cache  miss?  It causes  a cache  miss  precisely when one \nof the n i;1  previous requests resulted in b i;1  being evicted. We can determine the \nprobability that b i;1  was  chosen  for  eviction  by  using  Lemma  27.6:  consider  the  k \nblocks in the cache to be k balls, with block b i;1  as the red ball, the other k \ue003 1 \nblocks as the k \ue003 1 blue balls, and no white balls. Each of the n i;1  requests chooses \na block to evict with equal probability, correspond ing to drawing balls n i;1  times. \nThus,  we  can  apply  Lemma  27.6  with  x D k, y D 0, and m D n i;1  , deriving \nthe  probability  of a cache  miss  upon  the  \u00fbrst  old  request  as n i;1  =k, which equals \nn ij =.k  \ue003 j C 1/ since j D 1. \nIn order to determine the probability of a cache mi ss for subsequent old requests, \nwe\u2019ll  need  an additional  observation.  Let\u2019s  consider  the  second old request, which \nis for block b i;2  . This request causes a cache miss precisely when o ne of the pre- \nvious requests evicts b i;2  . Let\u2019s  consider  two  cases,  based  on  the  request  for  b i;1  . \nIn the  \u00fbrst  case,  suppose  that  the  request  for  b i;1  did not cause an eviction, because \nb i;1  was already in the cache. Then, the only way that b i;2  could have been evicted \nis by one of the n i;2  new requests that precedes it. What is the probabil ity that \nthis  eviction  happens?  There  are  n i;2  chances for b i;2  to be evicted, but we also \nknow that there is one block in the cache, namely b i;1  , that is not evicted. Thus, \nwe  can  again  apply  Lemma  27.6,  but  with  b i;1  as the white ball, b i;2  as the red \nball, the remaining blocks as the blue balls, and d rawing balls n i;2  times. Applying \nLemma  27.6,  with  x D k \ue003 1, y D 1, and m D n i;2  , we  \u00fbnd  that  the  probability  of \na cache miss is n i;2  =.k  \ue003 1/. In the second case, the request for b i;1  does cause an \neviction, which can happen only if one of the new r equests preceding the request \nfor b i;1  evicts b i;1  . Then, the request for b i;1  brings b i;1  back into the cache and \nevicts some other block. In this case, we know that  of the new requests, one of \nthem did not result in b i;2  being evicted, since b i;1  was evicted. Therefore, n i;2  \ue003 1 \nnew requests could evict b i;2  , as could the request for b i;1  , so that the number of \nrequests that could evict b i;2  is n i;2  . Each such request evicts a block chosen from \namong k \ue003 1 blocks, since the request that resulted in evicting  b i;1  did not also \ncause b i;2  to be evicted.  Therefore,  we  can  apply  Lemma  27.6,  with  x D k \ue003 1, 812 Chapter 27 Online Algorithms \ny D 1, and m D n i;2  , and get that the probability of a miss is n i;2  =.k  \ue003 1/. In both \ncases the probability is the same, and it equals n ij =.k  \ue003 j C 1/ since j D 2. \nMore generally, o ij old requests occur before the j th old request. Each of these \nprior old requests either caused an eviction or did  not. For those that caused an \neviction, it is because they were evicted by a prev ious request, and for those that did \nnot cause an eviction, it is because they were not evicted by any previous request. \nIn either case, we can decrease the number of block s that the random process is \nchoosing from by 1 for each old request, and thus o ij requests cannot cause b ij to \nbe evicted.  Therefore,  we  can  use  Lemma  27.6  to determine  the  probability that \nb ij was evicted by a previous request, with x D k \ue003 o ij , y D o ij and m D n ij . \nThus, we have proven our claim that the probability  of a cache miss on the j th \nrequest for an old block is n ij =.k  \ue003 o ij /, or n ij =.k  \ue003 j C 1/. Since n ij \u0dc4 r i (recall \nthat r i is the number of new requests during epoch i ), we have an upper bound of \nr i =.k  \ue003 j C 1/ on the probability that the j th old request incurs a cache miss. \nWe can now compute the expected number of misses du ring epoch i using  indi-  \ncator  random  variables,  as introduced  in Section  5.2.  We  de\u00fbne indicator random \nvariables \nY ij D I fthe j th old request in epoch i incurs a cache miss g ; \nZ ij D I fthe j th new request in epoch i incurs a cache miss g : \nWe have Z ij D 1 for j D 1;2;:::;r  i , since every new request results in a cache \nmiss. Let X i be the random variable denoting the number of cache  misses during \nepoch i , so that \nX i D k\ue002r i X  \nj D1 Y ij C r i X  \nj D1 Z ij ; \nand so \nE \u0152X  i \ufffd D E \" k\ue002r i X  \nj D1 Y ij C r i X  \nj D1 Z ij # \nD k\ue002r i X  \nj D1 E \u0152Y ij \ufffd C r i X  \nj D1 E \u0152Z  ij \ufffd (by linearity of expectation) \n\u0dc4 k\ue002r i X  \nj D1 r i \nk \ue003 j C 1 C r i X  \nj D1 1 (by  Lemma  5.1  on  page  130)  \nD r i \ue001 k\ue002r i X  \nj D1 1 \nk \ue003 j C 1 C 1 ! 27.3  Online  caching  813 \n\u0dc4 r i \ue001 k\ue0021 X  \nj D1 1 \nk \ue003 j C 1 C 1 ! \nD r i H k (by  equation  (A.8)  on  page  1142)  , (27.16)  \nwhere H k is the kth harmonic number. \nTo compute the expected total number of cache misse s, we sum over all epochs. \nLet p denote the number of epochs and X be the random variable denoting the \nnumber of cache misses. Then, we have X D P  p \ni D1 X i , so that \nE \u0152X\ufffd  D E \" p X  \ni D1 X i # \nD p X  \ni D1 E \u0152X  i \ufffd (by linearity of expectation) \n\u0dc4 p X  \ni D1 r i H k (by  inequality  (27.16))  \nD H k p X  \ni D1 r i : (27.17)  \nTo complete the analysis, we need to understand the  behavior of the  optimal  of-  \n\u00fcine  algorithm.  It could  make  a completely  different  set  of decisions from those \nmade by R ANDOMIZED -MARKING , and at any point its cache may look nothing \nlike the cache of the randomized algorithm. Yet, we  want to relate the number of \ncache  misses  of the  optimal  of\u00fcine  algorithm  to the  value  in inequality  (27.17),  in \norder to have a competitive ratio that does not dep end on P  p \ni D1 r i . Focusing on \nindividual  epochs  won\u2019t  suf\u00fbce.  At  the  beginning  of any  epoch,  the  of\u00fcine  algo-  \nrithm might have loaded the cache with exactly the blocks that will be requested in \nthat epoch. Therefore, we cannot take any one epoch  in isolation and claim that an \nof\u00fcine  algorithm  must  suffer  any  cache  misses  during  that  epoch. \nIf we consider two consecutive epochs, however, we can better analyze  the  opti-  \nmal  of\u00fcine  algorithm.  Consider  two  consecutive  epochs,  i \ue003 1 and i . Each contains \nk requests for k different blocks. (Recall our assumption that all r equests are  \u00fbrst  \nrequests in an epoch.) Epoch i contains r i requests for new blocks, that is, blocks \nthat were not requested during epoch i \ue003 1. Therefore,  the  number  of distinct  re-  \nquests during epochs i \ue0031 and i is exactly k Cr i . No matter what the cache contents \nwere at the beginning of epoch i \ue003 1, after k C r i distinct requests, there must be at \nleast r i cache misses. There could be more, but there is no way to have f ewer.  Let-  \nting m i denote  the  number  of cache  misses  of the  of\u00fcine  algorithm  during epoch i , \nwe have just argued that \nm i \ue0021 C m i \ue004 r i : (27.18)  814 Chapter 27 Online Algorithms \nThe  total  number  of cache  misses  of the  of\u00fcine  algorithm  is \np X  \ni D1 m i D 1 \n2 p X  \ni D1 2m  i \nD 1 \n2 \ue001 \nm 1 C p X  \ni D2 .m  i \ue0021 C m i / C m p ! \n\ue004 1 \n2 \ue001 \nm 1 C p X  \ni D2 .m  i \ue0021 C m i / ! \n\ue004 1 \n2 \ue001 \nm 1 C p X  \ni D2 r i ! \n(by  inequality  (27.18))  \nD 1 \n2 p X  \ni D1 r i (because m 1 D r 1 ) . \nThe  justi\u00fbcation  m 1 D r 1 for the last equality follows because, by our assum ptions, \nthe cache starts out empty and every request incurs  a cache miss in the  \u00fbrst  epoch,  \neven  for  the  optimal  of\u00fcine  adversary.  \nTo conclude the analysis, because we have an upper bound of H k P  p \ni D1 r i on the \nexpected number of cache misses for R ANDOMIZED -MARKING  and a lower bound \nof 1 \n2 P  p \ni D1 r i on  the  number  of cache  misses  for  the  optimal  of\u00fcine  algorith m, the \nexpected competitive ratio is at most \nH k P  p \ni D1 r i \n1 \n2 P  p \ni D1 r i D 2H  k \nD 2 ln k C O.1/  (by  equation  (A.9)  on  page  1142)  \nD O.lg k/:  \nExercises  \n27.3-1  \nFor  the  cache  sequence  (27.10),  show  the  contents  of the  cache after each request \nand count the number of cache misses. How many miss es does each epoch  incur?  \n27.3-2  \nShow that LFU has a competitive ratio of \u201a.n=k/  for the online caching problem \nwith n requests and a cache of size k. \n27.3-3  \nShow  that  FIFO  has  a competitive  ratio  of O.k/  for the online caching problem \nwith n requests and a cache of size k. Problems for Chapter 27 815 \n27.3-4  \nShow that the deterministic M ARKING  algorithm has a competitive ratio of O.k/  \nfor the online caching problem with n requests and a cache of size k. \n27.3-5  \nTheorem  27.4  shows  that  any  deterministic  online  algorithm  for  caching  has  a com-  \npetitive ratio of \ufffd.k/ , where k is the  cache  size.  One  way  in which  an algorithm  \nmight be able to perform better is to have some abi lity to know what the next few \nrequests will be. We say that an algorithm is l -lookahead  if it has the ability to look \nahead at the next l requests. Prove that for every constant l \ue004 0 and every cache \nsize k \ue0041, every  deterministic  l -lookahead  algorithm  has  competitive  ratio  \ufffd.k/ . \nProblems  \n27-1  Cow-path  problem  \nThe Appalachian Trail (AT) is a marked hiking trail  in the eastern United States \nextending  between  Springer  Mountain  in Georgia  and  Mount  Katahdin in Maine. \nThe  trail  is about  2,190  miles  long.  You  decide  that  you  are  going to hike the AT \nfrom  Georgia  to Maine  and  back.  You  plan  to learn  more  about  algorithms while \non the trail, and so you bring along your copy of Introduction  to Algorithms  in \nyour backpack. 2 You have already read through this chapter before s tarting out. \nBecause the beauty of the trail distracts you, you forget about reading this book \nuntil  you  have  reached  Maine  and  hiked  halfway  back  to Georgi a. At that point, \nyou decide that you have already seen the trail and  want to continue reading the \nrest  of the  book,  starting  with  Chapter  28.  Unfortunately,  you  \u00fbnd  that  the  book  is \nno longer in your pack. You must have left it somew here along the trail, but you \ndon\u2019t  know  where.  It could  be anywhere  between  Georgia  and  Maine. You want to \n\u00fbnd  the  book,  but  now  that  you  have  learned  something  about  online algorithms, \nyou  want  your  algorithm  for  \u00fbnding  it to have  a good  competiti ve ratio. That is, no \nmatter where the book is, if its distance from you is x miles away, you would like \nto be sure that you do not walk more than cx  miles  to \u00fbnd  it, for  some  constant  c . \nYou do not know x , though you may assume that x \ue004 1. 3 \n2 This book is heavy. We do not recommend that you ca rry it on a long hike. \n3 In case  you\u2019re  wondering  what  this  problem  has  to do  with  cows , some papers about it frame the \nproblem  as a cow  looking  for  a \u00fbeld  in which  to graze.  816 Chapter 27 Online Algorithms \nWhat algorithm should you use, and what constant c can you prove bounds the \ntotal distance cx  that  you  would  have  to walk?  Your  algorithm  should  work  for  a \ntrail  of any  length,  not  just  the  2,190-mile-long  AT.  \n27-2  Online  scheduling  to minimize  average  completion  time  \nProblem  15-2  discusses  scheduling  to minimize  average  comp letion time on one \nmachine, without release times and preemption and w ith release  times  and  preemp-  \ntion. Now you will develop an online algorithm for nonpreemptively scheduling a \nset of tasks with release times. Suppose you are gi ven a set S D fa 1 ;a  2 ;:::;a  n g of \ntasks, where task a i has release  time  r i , before which it cannot start, and requires \np i units of processing time to complete once it has st arted. You have one computer \non which to run the tasks. Tasks cannot be preempted , which is to say that once \nstarted, a task must run to completion without inte rruption. (See  Problem  15-2  on  \npage  446  for  a more  detailed  description  of this  problem.)  Given a schedule, let \nC i be the completion  time  of task a i , that is, the time at which task a i completes \nprocessing.  Your  goal  is to \u00fbnd  a schedule  that  minimizes  the  average completion \ntime, that is, to minimize .1=n/  P  n \ni D1 C i : \nIn the online version of this problem, you learn ab out task i only when it arrives \nat its release time r i , and at that point, you know its processing time p i . The \nof\u00fcine  version  of this  problem  is NP-hard  (see  Chapter  34),  but you will develop a \n2-competitive  online  algorithm.  \na. Show that, if there are release times, scheduling b y shortest processing time \n(when the machine becomes idle, start the already r eleased task  with  the  small-  \nest processing time that has not yet run) is not d -competitive  for  any  constant  d . \nIn order to develop an online algorithm, consider t he preemptive version of this \nproblem,  which  is discussed  in Problem  15-2(b).  One  way  to schedule is to run the \ntasks according to the shortest remaining processin g time (SRPT) order. That is, \nat any point, the machine is running the available task with the smallest amount of \nremaining processing time. \nb. Explain how to run SRPT as an online algorithm. \nc. Suppose that you run SRPT and obtain completion tim es C P \n1 ;:::;C  P \nn . Show \nthat \nn X  \ni D1 C P \ni \u0dc4 n X  \ni D1 C \ue003 \ni ; \nwhere the C \ue003 \ni are the completion times in an optimal nonpreemptiv e schedule. Notes for Chapter 27 817 \nConsider  the  (of\u00fcine)  algorithm  COMPLETION -TIME-SCHEDULE . \nCOMPLETION -TIME-SCHEDULE.S/  \n1 compute an optimal schedule for the preemptive vers ion of the problem \n2 renumber the tasks so that the completion times in the optimal \npreemptive schedule are ordered by their completion  times \nC P \n1 <C  P \n2 < \ue001 \ue001 \ue001  <C  P \nn in SRPT order \n3 greedily schedule the tasks nonpreemptively in the renumbered \norder a 1 ;:::;a  n \n4 let C 1 ;:::;C  n be the completion times of renumbered tasks a 1 ;:::;a  n \nin this nonpreemptive schedule \n5 return  C 1 ;:::;C  n \nd. Prove that C P \ni \ue004 max \u02daP  i \nj D1 p j ; max fr j W j \u0dc4 i g \ue009 \nfor i D 1;:::;n . \ne. Prove that C i \u0dc4 max fr j W j \u0dc4 i g C  P  i \nj D1 p j for i D 1;:::;n . \nf. Algorithm C OMPLETION -TIME-SCHEDULE is an of\u00fcine  algorithm.  Explain  \nhow to modify it to produce an online algorithm. \ng. Combine parts (c)\u2013(f) to show that the online versi on of COMPLETION -TIME- \nSCHEDULE is 2-competitive.  \nChapter  notes  \nOnline  algorithms  are  widely  used  in many  domains.  Some  good  overviews include \nthe  textbook  by  Borodin  and  El-Yaniv  [68],  the  collection  of surveys edited by Fiat \nand  Woeginger  [142],  and  the  survey  by  Albers  [14].  \nThe  move-to-front  heuristic  from  Section  27.2  was  analyzed  by  Sleator  and  Tar-  \njan  [416,  417]  as part  of their  early  work  on  amortized  analys is. This rule works \nquite well in practice. \nCompetitive analysis of online caching also origina ted with Sleator and Tarjan \n[417].  The  randomized  marking  algorithm  was  proposed  and  analyzed by Fiat et al. \n[141].  Young  [464]  surveys  online  caching  and  paging  algori thms, and Buchbinder \nand  Naor  [76]  survey  primal-dual  online  algorithms.  \nSpeci\u00fbc  types  of online  algorithms  are  described  using  other names. Dynamic  \ngraph  algorithms  are online algorithms on graphs, where at each step  a vertex \nor edge  undergoes  modi\u00fbcation.  Typically  a vertex  or edge  is either inserted or 818 Chapter 27 Online Algorithms \ndeleted, or some associated property, such as edge weight, changes. Some graph \nproblems need to be solved again after each change to the graph, and  a good  dy-  \nnamic graph algorithm will not need to solve from s cratch. For example, edges are \ninserted and deleted, and after each change to the graph, the minimum spanning \ntree  is recomputed.  Exercise  21.2-8  asks  such  a question.  Similar questions can be \nasked for other graph algorithms, such as shortest paths, connectivity, or matching. \nThe  \u00fbrst  paper  in this  \u00fbeld  is credited  to Even  and  Shiloach  [138],  who  study  how  \nto maintain  a shortest-path  tree  as edges  are  being  deleted  from a graph. Since \nthen hundreds of papers have been published. Demetr escu et al. [110]  survey  early  \ndevelopments in dynamic graph algorithms. \nFor massive data sets, the input data might be too large to store. Streaming  al-  \ngorithms  model this situation by requiring the memory used b y an algorithm to be \nsigni\u00fbcantly  smaller  than  the  input  size.  For  example,  you  may have a graph with n \nvertices and m edges with m \ue007  n, but the memory allowed may be only O.n/. Or  \nyou may have n numbers, but the memory allowed may only be O.lg n/ or O.  p n/. \nA streaming algorithm is measured by the number of passes made over the data in \naddition  to the  running  time  of the  algorithm.  McGregor  [322] surveys streaming \nalgorithms  for  graphs  and  Muthukrishnan  [341]  surveys  general  streaming  algo-  \nrithms. 28  Matrix  Operations  \nBecause  operations  on  matrices  lie  at the  heart  of scienti\u00fbc  computing,  ef\u00fbcient  al-  \ngorithms for working with matrices have many practi cal applications. This chapter \nfocuses on how to multiply matrices and solve sets of simultaneous  linear  equa-  \ntions. Appendix D reviews the basics of matrices. \nSection  28.1  shows  how  to solve  a set  of linear  equations  using  LUP  decom-  \npositions.  Then,  Section  28.2  explores  the  close  relations hip between multiplying \nand  inverting  matrices.  Finally,  Section  28.3  discusses  the  important  class  of sym-  \nmetric  positive-de\u00fbnite  matrices  and  shows  how  to use  them  to \u00fbnd  a least-squares  \nsolution to an overdetermined set of linear equatio ns. \nOne  important  issue  that  arises  in practice  is numerical  stability . Because actual \ncomputers  have  limits  to how  precisely  they  can  represent  \u00fcoating-point  numbers,  \nround-off  errors  in numerical  computations  may  become  ampli\u00fbed  over  the  course  \nof a computation, leading to incorrect results. Suc h computations are called nu-  \nmerically  unstable. Although  we\u2019ll  brie\u00fcy  consider  numerical  stability  on  occa-  \nsion,  we  won\u2019t  focus  on  it in this  chapter.  We  refer  you  to the  excellent book by \nHigham  [216]  for  a thorough  discussion  of stability  issues.  \n28.1  Solving  systems  of linear  equations  \nNumerous applications need to solve sets of simulta neous linear  equations.  A lin-  \near system can be cast as a matrix equation in whic h each matrix or vector element \nbelongs  to a \u00fbeld,  typically  the  real  numbers  R. This section discusses how to \nsolve a system of linear equations using a method c alled LUP decomposition. \nThe process starts with a set of linear equations i n n unknowns x 1 ;x  2 ;:::;x  n : 820 Chapter 28 Matrix Operations \na 11  x 1 C a 12  x 2 C \ue001 \ue001 \ue001 C  a 1n  x n D b 1 ; \na 21  x 1 C a 22  x 2 C \ue001 \ue001 \ue001 C  a 2n  x n D b 2 ; \n: : : \na n1  x 1 C a n2  x 2 C \ue001 \ue001 \ue001 C  a nn  x n D b n : (28.1)  \nA solution  to the  equations  (28.1)  is a set  of values  for  x 1 ;x  2 ;:::;x  n that satisfy \nall of the equations simultaneously. In this sectio n, we treat only the case in which \nthere are exactly n equations in n unknowns. \nNext,  rewrite  equations  (28.1)  as the  matrix-vector  equati on \u00db \na 11  a 12  \ue001 \ue001 \ue001  a 1n  \na 21  a 22  \ue001 \ue001 \ue001  a 2n  \n: : : : : : : : : : : : \na n1  a n2  \ue001 \ue001 \ue001  a nn  \ue005\u00db \nx 1 \nx 2 \n: : : \nx n \ue005 \nD \u00db \nb 1 \nb 2 \n: : : \nb n \ue005 \nor, equivalently, letting A D .a ij /, x D .x i /, and b D .b i /, as \nAx  D b:  (28.2)  \nIf A is nonsingular, it possesses an inverse A \ue0021 , and \nx D A \ue0021 b (28.3)  \nis the solution vector. We can prove that x is the  unique  solution  to equation  (28.2)  \nas follows. If there are two solutions, x and x 0 , then Ax  D Ax  0 D b and, letting I \ndenote an identity matrix, \nx D Ix  \nD .A  \ue0021 A/x  \nD A \ue0021 .Ax/  \nD A \ue0021 .Ax  0 / \nD .A  \ue0021 A/x  0 \nD Ix  0 \nD x 0 : \nThis section focuses on the case in which A is nonsingular or, equivalently (by \nTheorem  D.1  on  page  1220),  the  rank  of A equals the number n of unknowns. \nThere are other possibilities, however, which merit  a brief discussion.  If the  num-  \nber of equations is less than the number n of unknowns4or,  more  generally,  if \nthe rank of A is less than n4then  the  system  is underdetermined . An  underde-  \ntermined  system  typically  has  in\u00fbnitely  many  solutions,  although it may have no 28.1  Solving  systems  of linear  equations  821 \nsolutions at all if the equations are inconsistent.  If the number  of equations  ex-  \nceeds the number n of unknowns, the system is overdetermined , and there may not \nexist  any  solutions.  Section  28.3  addresses  the  important  problem  of \u00fbnding  good  \napproximate solutions to overdetermined systems of linear equations. \nLet\u2019s  return  to the  problem  of solving  the  system  Ax  D b of n equations in n un-  \nknowns.  One  option  is to compute  A \ue0021 and  then,  using  equation  (28.3),  multiply  b \nby A \ue0021 , yielding x D A \ue0021 b. This approach suffers in practice from numerical \ninstability.  Fortunately,  another  approach4LUP  decomposition4is  numerically  \nstable and has the further advantage of being faste r in practice. \nOverview  of LUP  decomposition  \nThe  idea  behind  LUP  decomposition  is to \u00fbnd  three  n \ue005 n matrices L, U , and P \nsuch that \nPA  D LU  ; (28.4)  \nwhere \n\ue001 L is a unit  lower-triangular  matrix,  \n\ue001 U is an upper-triangular  matrix,  and  \n\ue001 P is a permutation matrix. \nWe call matrices L, U , and P satisfying  equation  (28.4)  an LUP  decomposition  \nof the matrix A. We\u2019ll  show  that  every  nonsingular  matrix  A possesses such a \ndecomposition. \nComputing an LUP decomposition for the matrix A has the advantage that linear \nsystems  can  be ef\u00fbciently  solved  when  they  are  triangular,  as is the case for both \nmatrices L and U . If you have an LUP decomposition for A, you  can  solve  equa-  \ntion  (28.2),  Ax  D b, by solving only triangular linear systems, as fol lows. Multiply \nboth sides of Ax  D b by P , yielding the equivalent equation PAx  D Pb. By  Exer-  \ncise  D.1-4  on  page  1219,  multiplying  both  sides  by  a permutat ion matrix amounts \nto permuting  the  equations  (28.1).  By  the  decomposition  (28.4),  substituting  LU  \nfor PA  gives \nLUx  D Pb:  \nYou can now solve this equation by solving two tria ngular linear  systems.  De\u00fbne  \ny D Ux  , where x is the  desired  solution  vector.  First,  solve  the  lower-tria ngular \nsystem \nLy  D Pb  (28.5)  \nfor the unknown vector y by a method called <forward substitution.= Having s olved \nfor y , solve  the  upper-triangular  system  822 Chapter 28 Matrix Operations \nUx  D y (28.6)  \nfor the unknown x by  a method  called  <back  substitution.=  Why  does  this  pro-  \ncess solve Ax  D b? Because  the  permutation  matrix  P is invertible  (see  Exer-  \ncise  D.2-3  on  page  1223),  multiplying  both  sides  of equation  (28.4)  by  P \ue0021 gives \nP \ue0021 PA  D P \ue0021 LU  , so that \nA D P \ue0021 LU  : (28.7)  \nHence, the vector x that  satis\u00fbes  Ux  D y is the solution to Ax  D b: \nAx  D P \ue0021 LUx  (by  equation  (28.7))  \nD P \ue0021 Ly  (by  equation  (28.6))  \nD P \ue0021 Pb  (by  equation  (28.5))  \nD b:  \nThe next step is to show how forward and back subst itution work and then attack \nthe problem of computing the LUP decomposition itse lf. \nForward  and  back  substitution  \nForward  substitution  can  solve  the  lower-triangular  system  (28.5)  in \u201a.n  2 / time, \ngiven L, P , and b. An array \ufffd\u01521  W n\ufffd provides a more compact format to represent \nthe permutation P than an n \ue005 n matrix that is mostly 0s. For i D 1;2;:::;n , the \nentry \ufffd\u0152i  \ufffd indicates that P i;\ue003\u0152i\u0141  D 1 and P ij D 0 for j \u00a4 \ufffd\u0152i  \ufffd. Thus, PA  has \na \ue003\u0152i\u0141;j  in row i and column j , and Pb  has b \ue003\u0152i\u0141  as its i th element. Since L is unit \nlower-triangular,  the  matrix  equation  Ly  D Pb  is equivalent to the n equations \ny 1 D b \ue003\u01521\u0141  ; \nl 21  y 1 C y 2 D b \ue003\u01522\u0141  ; \nl 31  y 1 C l 32  y 2 C y 3 D b \ue003\u01523\u0141  ; \n: : : \nl n1  y 1 C l n2  y 2 C l n3  y 3 C \ue001 \ue001 \ue001 C  y n D b \ue003\u0152n\u0141  : \nThe  \u00fbrst  equation  gives  y 1 D b \ue003\u01521\u0141  directly.  Knowing  the  value  of y 1 , you can \nsubstitute it into the second equation, yielding \ny 2 D b \ue003\u01522\u0141  \ue003 l 21  y 1 : \nNext, you can substitute both y 1 and y 2 into the third equation, obtaining \ny 3 D b \ue003\u01523\u0141  \ue003 .l 31  y 1 C l 32  y 2 /: \nIn general, you substitute y 1 ;y  2 ;:::;y  i \ue0021 <forward= into the i th equation to solve \nfor y i : 28.1  Solving  systems  of linear  equations  823 \ny i D b \ue003\u0152i\u0141  \ue003 i \ue0021 X  \nj D1 l ij y j : \nOnce  you\u2019ve  solved  for  y , you can solve for x in equation  (28.6)  using  back  \nsubstitution , which is similar to forward substitution. This ti me, you solve the nth \nequation  \u00fbrst  and  work  backward  to the  \u00fbrst  equation.  Like  forward substitution, \nthis process runs in \u201a.n  2 / time. Since U is upper-triangular,  the  matrix  equation  \nUx  D y is equivalent to the n equations \nu 11  x 1 C u 12  x 2 C \ue001 \ue001 \ue001 C  u 1;n\ue0022 x n\ue0022 C u 1;n\ue0021 x n\ue0021 C u 1n  x n D y 1 ; \nu 22  x 2 C \ue001 \ue001 \ue001 C  u 2;n\ue0022 x n\ue0022 C u 2;n\ue0021 x n\ue0021 C u 2n  x n D y 2 ; \n: : : \nu n\ue0022;n\ue0022 x n\ue0022 C u n\ue0022;n\ue0021 x n\ue0021 C u n\ue0022;n  x n D y n\ue0022 ; \nu n\ue0021;n\ue0021 x n\ue0021 C u n\ue0021;n  x n D y n\ue0021 ; \nu n;n  x n D y n : \nThus, you can solve for x n ;x  n\ue0021 ;:::;x  1 successively as follows: \nx n D y n =u  n;n  ; \nx n\ue0021 D .y n\ue0021 \ue003 u n\ue0021;n  x n /=u  n\ue0021;n\ue0021 ; \nx n\ue0022 D .y n\ue0022 \ue003 .u  n\ue0022;n\ue0021 x n\ue0021 C u n\ue0022;n  x n //=u  n\ue0022;n\ue0022 ; \n: : : \nor, in general, \nx i D \ue001 \ny i \ue003 n X  \nj Di C1 u ij x j ! \n=u  ii : \nGiven  P , L, U , and b, the  procedure  LUP-SOLVE  on the next page solves for x \nby combining forward and back substitution. The per mutation matrix P is repre-  \nsented by the array \ufffd . The  procedure  \u00fbrst  solves  for  y using forward substitution in \nlines  233,  and  then  it solves  for  x using  backward  substitution  in lines  435.  Since  \nthe summation within each of the for  loops includes an implicit loop, the running \ntime is \u201a.n  2 /. \nAs an example of these methods, consider the system  of linear equations  de\u00fbned  \nby Ax  D b, where \nA D \u00e3 \n1 2 0  \n3 4 4  \n5 6 3  \u00e4 \nand b D \u00e3 \n3 \n7 \n8 \u00e4 \n; 824 Chapter 28 Matrix Operations \nLUP-SOLVE .L; U; \ufffd; b; n/  \n1 let x and y be new vectors of length n \n2 for  i D 1 to n \n3 y i D b \ue003\u0152i\u0141  \ue003 P  i \ue0021 \nj D1 l ij y j \n4 for  i D n downto  1 \n5 x i D \u00e3 \ny i \ue003 P  n \nj Di C1 u ij x j \u00e4 \n=u  ii \n6 return  x \nand we want to solve for the unknown x . The LUP decomposition is \nL D \u00e3 \n1 0 0  \n0:2  1 0 \n0:6  0:5  1 \u00e4 \n; U  D \u00e3 \n5 6  3 \n0 0:8  \ue0030:6  \n0 0 2:5  \u00e4 \n; and P D \u00e3 \n0 0 1  \n1 0 0  \n0 1 0  \u00e4 \n: \n(You might want to verify that PA  D LU  .) Using forward substitution, solve \nLy  D Pb  for y : \u00e3 \n1 0 0  \n0:2  1 0 \n0:6  0:5  1 \u00e4\u00e3 \ny 1 \ny 2 \ny 3 \u00e4 \nD \u00e3 \n8 \n3 \n7 \u00e4 \n; \nobtaining \ny D \u00e3 \n8 \n1:4  \n1:5  \u00e4 \nby  computing  \u00fbrst  y 1 , then y 2 , and  \u00fbnally  y 3 . Then, using back substitution, solve \nUx  D y for x : \u00e3 \n5 6  3 \n0 0:8  \ue0030:6  \n0 0 2:5  \u00e4\u00e3 \nx 1 \nx 2 \nx 3 \u00e4 \nD \u00e3 \n8 \n1:4  \n1:5  \u00e4 \n; \nthereby obtaining the desired answer \nx D \u00e3 \n\ue0031:4  \n2:2  \n0:6  \u00e4 \nby  computing  \u00fbrst  x 3 , then x 2 , and  \u00fbnally  x 1 . \nComputing  an  LU  decomposition  \nGiven  an LUP  decomposition  for  a nonsingular  matrix  A, you can use forward and \nback substitution to solve the system Ax  D b of linear  equations.  Now  let\u2019s  see  28.1  Solving  systems  of linear  equations  825 \nhow  to ef\u00fbciently  compute  an LUP  decomposition  for  A. We start with the simpler \ncase in which A is an n \ue005 n nonsingular matrix and P is absent (or, equivalently, \nP D I n , the n \ue005 n identity matrix), so that A D LU  . We call the two matrices L \nand U an LU  decomposition  of A. \nTo  create  an LU  decomposition,  we\u2019ll  use  a process  known  as Gaussian  elimi-  \nnation. Start  by  subtracting  multiples  of the  \u00fbrst  equation  from  the other equations \nin order  to remove  the  \u00fbrst  variable  from  those  equations.  Then subtract multiples \nof the second equation from the third and subsequen t equations so that  now  the  \u00fbrst  \nand second variables are removed from them. Continu e this process  until  the  sys-  \ntem  that  remains  has  an upper-triangular  form4this  is the  matrix U . The matrix L \ncomprises the row multipliers that cause variables to be eliminated. \nTo  implement  this  strategy,  let\u2019s  start  with  a recursive  formulation. The input \nis an n \ue005 n nonsingular matrix A. If n D 1, then nothing needs to be done: just \nchoose L D I 1 and U D A. For n>1 , break A into four parts: \nA D \u00db \na 11  a 12  \ue001 \ue001 \ue001  a 1n  \na 21  a 22  \ue001 \ue001 \ue001  a 2n  \n: : : : : : : : : : : : \na n1  a n2  \ue001 \ue001 \ue001  a nn  \ue005 \nD \u00cf a 11  w T \nv A  0 \u00d0 \n; (28.8)  \nwhere v D .a 21  ;a  31  ;:::;a  n1  / is a column .n\ue0031/-vector,  w T D .a 12  ;a  13  ;:::;a  1n  / T \nis a row .n \ue003 1/-vector,  and  A 0 is an .n \ue003 1/ \ue005 .n \ue003 1/ matrix. Then, using matrix \nalgebra (verify the equations by simply multiplying  through), factor A as \nA D \u00cf a 11  w T \nv A  0 \u00d0 \nD \u00cf 1 0 \nv=a  11  I n\ue0021 \u00d0\u00cf  a 11  w T \n0 A  0 \ue003 vw  T =a  11  \u00d0 \n: (28.9)  \nThe 0s in the  \u00fbrst  and  second  matrices  of equation  (28.9)  are  row  and column \n.n \ue003 1/-vectors,  respectively.  The  term  vw  T =a  11  is an .n \ue003 1/ \ue005 .n \ue003 1/ matrix \nformed by taking the outer product of v and w and dividing each element of the \nresult by a 11  . Thus it conforms in size to the matrix A 0 from which it is subtracted. \nThe resulting .n \ue003 1/ \ue005 .n \ue003 1/ matrix \nA 0 \ue003 vw  T =a  11  (28.10)  \nis called the Schur  complement  of A with respect to a 11  . \nWe claim that if A is nonsingular, then the Schur complement is nonsin gular, \ntoo.  Why?  Suppose  that  the  Schur  complement,  which  is .n \ue003 1/ \ue005 .n \ue003 1/, is \nsingular.  Then  by  Theorem  D.1,  it has  row  rank  strictly  less  than n \ue003 1. Because \nthe bottom n \ue003 1 entries  in the  \u00fbrst  column  of the  matrix  826 Chapter 28 Matrix Operations \n\u00cf a 11  w T \n0 A  0 \ue003 vw  T =a  11  \u00d0 \nare all 0, the bottom n \ue003 1 rows of this matrix must have row rank strictly les s \nthan n \ue003 1. The row rank of the entire matrix, therefore, is strictly less than n. \nApplying  Exercise  D.2-8  on  page  1223  to equation  (28.9),  A has rank strictly less \nthan n, and  from  Theorem  D.1,  we  derive  the  contradiction  that  A is singular. \nBecause the Schur complement is nonsingular, it, to o, has an LU decomposition, \nwhich  we  can  \u00fbnd  recursively.  Let\u2019s  say  that  \nA 0 \ue003 vw  T =a  11  D L 0 U 0 ; \nwhere L 0 is unit  lower-triangular  and  U 0 is upper-triangular.  The  LU  decomposi-  \ntion of A is then A D LU  , with \nL D \u00cf 1 0 \nv=a  11  L 0 \u00d0 \nand U D \u00cf a 11  w T \n0 U  0 \u00d0 \n; \nas shown by \nA D \u00cf 1 0 \nv=a  11  I n\ue0021 \u00d0\u00cf  a 11  w T \n0 A  0 \ue003 vw  T =a  11  \u00d0 \n(by  equation  (28.9))  \nD \u00cf 1 0 \nv=a  11  I n\ue0021 \u00d0\u00cf  a 11  w T \n0 L  0 U 0 \u00d0 \nD \u00cf a 11  w T \nv vw  T =a  11  C L 0 U 0 \u00d0 \nD \u00cf 1 0 \nv=a  11  L 0 \u00d0\u00cf  a 11  w T \n0 U  0 \u00d0 \nD LU  : \nBecause L 0 is unit  lower-triangular,  so is L, and because U 0 is upper-triangular,  so \nis U . \nOf  course,  if a 11  D 0, this  method  doesn\u2019t  work,  because  it divides  by  0. It also \ndoesn\u2019t  work  if the  upper  leftmost  entry  of the  Schur  complem ent A 0 \ue003 vw  T =a  11  \nis 0, since the next step of the recursion will divide by it. The denominators in each \nstep of LU decomposition are called pivots , and they occupy the diagonal elements \nof the matrix U . The permutation matrix P included  in LUP  decomposition  pro-  \nvides a way to avoid dividing by 0, as we\u2019ll  see  below.  Using  permutations  to avoid  \ndivision by 0 (or by small numbers, which can contribute to numer ical instability), \nis called pivoting . \nAn important class of matrices for which LU decompo sition always  works  cor-  \nrectly  is the  class  of symmetric  positive-de\u00fbnite  matrices . Such matrices require \nno pivoting to avoid dividing by 0 in the recursive strategy outlined above. We will \nprove  this  result,  as well  as several  others,  in Section  28.3. 28.1  Solving  systems  of linear  equations  827 \nThe  pseudocode  in the  procedure  LU-DECOMPOSITION  follows the recursive \nstrategy, except that an iteration loop replaces th e recursion. (This transformation is \na standard  optimization  for  a <tail-recursive=  procedure4 one whose last operation \nis a recursive  call  to itself.  See  Problem  7-5  on  page  202.)  The procedure initializes \nthe matrix U with 0s below the diagonal and matrix L with 1s on its diagonal \nand 0s above the diagonal. Each iteration works on a squ are submatrix, using its \nupper leftmost element as the pivot to compute the v and w vectors and the Schur \ncomplement, which becomes the square submatrix work ed on by the next iteration. \nLU-DECOMPOSITION  .A;n/  \n1 let L and U be new n \ue005 n matrices \n2 initialize U with 0s below the diagonal \n3 initialize L with 1s on the diagonal and 0s above the diagonal \n4 for  k D 1 to n \n5 u kk  D a kk  \n6 for  i D k C 1 to n \n7 l ik  D a ik  =a  kk  / / a ik  holds v i \n8 u ki  D a ki  / / a ki  holds w i \n9 for  i D k C 1 to n / / compute the Schur complement . . . \n10  for  j D k C 1 to n \n11  a ij D a ij \ue003 l ik  u kj  / / . . . and store it back into A \n12  return  L and U \nEach recursive step in the description above takes place in one iteration of the \nouter for  loop  of lines  4311.  Within  this  loop,  line  5 determines  the  pivot to \nbe u kk  D a kk  . The for  loop  in lines  638  (which  does  not  execute  when  k D n) \nuses the v and w vectors to update L and U . Line  7 determines  the  below-diagonal  \nelements of L, storing v i =a  kk  in l ik  , and  line  8 computes  the  above-diagonal  el-  \nements of U , storing w i in u ki  . Finally,  lines  9311  compute  the  elements  of the  \nSchur complement and store them back into the matri x A. (There is no need to \ndivide by a kk  in line  11  because  that  already  happened  when  line  7 computed  l ik  .) \nBecause  line  11  is triply  nested,  LU-DECOMPOSITION  runs in \u201a.n  3 / time. \nFigure  28.1  illustrates  the  operation  of LU-DECOMPOSITION . It shows  a stan-  \ndard  optimization  of the  procedure  that  stores  the  signi\u00fbca nt elements of L and U \nin place in the matrix A. Each element a ij corresponds to either l ij (if i > j  ) \nor u ij (if i \u0dc4 j ), so that the matrix A holds both L and U when the procedure \nterminates. To obtain the pseudocode for this optim ization from the pseudocode \nfor  the  LU-DECOMPOSITION  procedure, just replace each reference to l or u by a. \nYou can verify that this transformation preserves c orrectness. 828 Chapter 28 Matrix Operations \n2 \n4 \n1 2 3 1 5 \n6 13  5 19  \n2 19  10  23  \n4 10  11  31  \n(a) 3 1 5 \n3 4 2 4 \n1 16  9 18  \n2 4 9 21  \n(b) 2 3 1 5 \n3 2 4 \n1 4 1 2 \n2 1 7 17  \n(c) 2 3 1 5 \n3 4 2 4 \n1 4 2 \n2 1 7 3 \n(d) \n(e) \ue001 \n2 3 1 5  \n6 13  5 19  \n2 19  10  23  \n4 10  11  31  \u00da \nD \ue001 \n1 0 0 0  \n3 1 0 0  \n1 4 1 0  \n2 1 7 1  \u00da \ue001  \n2 3 1 5  \n0 4 2 4  \n0 0 1 2  \n0 0 0 3  \u00da \nA L U \nFigure  28.1  The  operation  of LU-DECOMPOSITION . (a)  The matrix A. (b)  The  result  of the  \u00fbrst  \niteration of the outer for  loop  of lines  4311.  The  element  a 11  D 2 highlighted in blue is the pivot, \nthe tan column is v=a  11  , and the tan row is w T . The elements of U computed thus far are above \nthe horizontal line, and the elements of L are to the left of the vertical line. The Schur com plement \nmatrix A 0 \ue003 vw  T =a  11  occupies the lower right. (c)  The result of the next iteration of the outer for  \nloop, on the Schur complement matrix from part (b).  The element a 22  D 4 highlighted in blue is the \npivot, and the tan column and row are v=a  22  and w T (in the partitioning of the Schur complement), \nrespectively. Lines divide the matrix into the elem ents of U computed so far (above), the elements \nof L computed so far (left), and the new Schur complemen t (lower right). (d)  After the next iteration, \nthe matrix A is factored. The element 3 in the new Schur complement becomes part of U when the \nrecursion terminates.) (e)  The factorization A D LU  . \nComputing  an  LUP  decomposition  \nIf the  diagonal  of the  matrix  given  to LU-DECOMPOSITION  contains any 0s, then \nthe procedure will attempt to divide by 0, which would cause disaster. Even if \nthe diagonal contains no 0s, but does have numbers with small absolute values , \ndividing by such numbers can cause numerical instab ilities. Therefore,  LUP  de-  \ncomposition pivots on entries with the largest abso lute values  that  it can  \u00fbnd.  \nIn LUP decomposition, the input is an n \ue005 n nonsingular matrix A, with a goal \nof \u00fbnding  a permutation  matrix  P , a unit  lower-triangular  matrix  L, and  an upper-  \ntriangular matrix U such that PA  D LU  . Before partitioning the matrix A, as LU \ndecomposition does, LUP decomposition moves a nonze ro element, say a k1  , from \nsomewhere  in the  \u00fbrst  column  to the  .1;1/  position of the matrix. For the greatest \nnumerical stability, LUP decomposition chooses the element in the  \u00fbrst  column  \nwith the greatest absolute value as a k1  . (The  \u00fbrst  column  cannot  contain  only  0s, \nfor then A would be singular, because its determinant would be  0, by Theorems \nD.4  and  D.5  on  page  1221.)  In order  to preserve  the  set  of equations,  LUP  decom-  \nposition exchanges row 1 with row k, which is equivalent to multiplying A by a 28.1  Solving  systems  of linear  equations  829 \npermutation matrix Q on  the  left  (Exercise  D.1-4  on  page  1219).  Thus,  the  analog  \nto equation  (28.8)  expresses  QA  as \nQA  D \u00cf a k1  w T \nv A  0 \u00d0 \n; \nwhere v D .a 21  ;a  31  ;:::;a  n1  /, except that a 11  replaces a k1  ; w T D .a k2  ;a  k3  ; \n:::;a  kn  / T ; and A 0 is an .n \ue003 1/ \ue005 .n \ue003 1/ matrix. Since a k1  \u00a4 0, the analog \nto equation  (28.9)  guarantees  no  division  by  0: \nQA  D \u00cf a k1  w T \nv A  0 \u00d0 \nD \u00cf 1 0 \nv=a  k1  I n\ue0021 \u00d0\u00cf  a k1  w T \n0 A  0 \ue003 vw  T =a  k1  \u00d0 \n: \nJust  as in LU  decomposition,  if A is nonsingular, then the Schur complement \nA 0 \ue003 vw  T =a  k1  is nonsingular,  too.  Therefore,  you  can  recursively  \u00fbnd  an LUP \ndecomposition  for  it, with  unit  lower-triangular  matrix  L 0 , upper-triangular  ma-  \ntrix U 0 , and permutation matrix P 0 , such that \nP 0 .A  0 \ue003 vw  T =a  k1  / D L 0 U 0 : \nDe\u00fbne  \nP D \u00cf 1 0  \n0 P  0 \u00d0 \nQ;  \nwhich is a permutation matrix, since it is the prod uct of two permutation matrices \n(Exercise  D.1-4  on  page  1219).  This  de\u00fbnition  of P gives \nPA  D \u00cf 1 0  \n0 P  0 \u00d0 \nQA  \nD \u00cf 1 0  \n0 P  0 \u00d0\u00cf  1 0 \nv=a  k1  I n\ue0021 \u00d0\u00cf  a k1  w T \n0 A  0 \ue003 vw  T =a  k1  \u00d0 \nD \u00cf 1 0 \nP 0 v=a  k1  P 0 \u00d0\u00cf  a k1  w T \n0 A  0 \ue003 vw  T =a  k1  \u00d0 \nD \u00cf 1 0 \nP 0 v=a  k1  I n\ue0021 \u00d0\u00cf  a k1  w T \n0 P  0 .A  0 \ue003 vw  T =a  k1  / \u00d0 \nD \u00cf 1 0 \nP 0 v=a  k1  I n\ue0021 \u00d0\u00cf  a k1  w T \n0 L  0 U 0 \u00d0 \nD \u00cf 1 0 \nP 0 v=a  k1  L 0 \u00d0\u00cf  a k1  w T \n0 U  0 \u00d0 \nD LU  ; 830 Chapter 28 Matrix Operations \nwhich yields the LUP decomposition. Because L 0 is unit  lower-triangular,  so is L, \nand because U 0 is upper-triangular,  so is U . \nNotice that in this derivation, unlike the one for LU decomposition, both the \ncolumn vector v=a  k1  and the Schur complement A 0 \ue003 vw  T =a  k1  are multiplied by \nthe permutation matrix P 0 . The  procedure  LUP-  DECOMPOSITION  gives  the  pseu-  \ndocode for LUP decomposition. \nLUP-DECOMPOSITION  .A;n/  \n1 let \ufffd\u01521  W n\ufffd be a new array \n2 for  i D 1 to n \n3 \ufffd\u0152i  \ufffd D i / / initialize \ufffd to the identity permutation \n4 for  k D 1 to n \n5 p D 0 \n6 for  i D k to n / / \u00fbnd  largest  absolute  value  in column  k \n7 if ja ik  j >p  \n8 p D ja ik  j \n9 k 0 D i / / row number of the largest found so far \n10  if p = = 0 \n11  error  <singular matrix= \n12  exchange \ufffd\u0152k\ufffd with \ufffd\u0152k  0 \ufffd \n13  for  i D 1 to n \n14  exchange a ki  with a k 0 i / / exchange rows k and k 0 \n15  for  i D k C 1 to n \n16  a ik  D a ik  =a  kk  \n17  for  j D k C 1 to n \n18  a ij D a ij \ue003 a ik  a kj  / / compute L and U in place in A \nLike  LU-DECOMPOSITION , the  LUP-DECOMPOSITION  procedure replaces the \nrecursion with an iteration loop. As an improvement  over a direct implementation \nof the recursion, the procedure dynamically maintai ns the permutation matrix P \nas an array \ufffd , where \ufffd\u0152i  \ufffd D j means that the i th row of P contains a 1 in col-  \numn j . The  LUP-DECOMPOSITION  procedure also implements the improvement \nmentioned earlier, computing L and U in place in the matrix A. Thus, when the \nprocedure terminates, \na ij D ( \nl ij if i >j ;  \nu ij if i \u0dc4 j :  \nFigure  28.2  illustrates  how  LUP-DECOMPOSITION  factors a matrix. Lines \n233  initialize  the  array  \ufffd to represent the identity permutation. The outer for  \nloop  of lines  4318  implements  the  recursion,  \u00fbnding  an LUP  decomposition of 28.1  Solving  systems  of linear  equations  831 \n2 0 2 0.6  \n3 3 4 32  \n5 5 4 2 \n31  32  3.4  31  \n(a) 1 \n2 \n3 \n4 2 0 2 0.6  3 3 4 32  5 5 4 2 \n31  32  3.4  31  \n(b) 3 \n2 \n1 \n4 0.4  32  0.4  3.2  0.6  0 1.6  33.2  5 5 4 2 \n30.2  31  4.2  30.6  \n(c) 3 \n2 \n1 \n4 \n0.4  32  0.4  30.2  0.6  0 1.6  33.2  5 5 4 2 \n30.2  31  4.2  30.6  \n(d) 3 \n2 \n1 \n4 0.4  32  0.4  30.2  \n0.6  0 1.6  33.2  5 5 4 2 \n30.2  31  4.2  30.6  \n(e) 3 \n2 1 \n4 0.4  32  0.4  30.2  \n0.6  0 1.6  33.2  5 5 4 2 \n30.2  0.5  4 30.5  \n(f) 3 \n2 1 \n4 \n0.4  32  0.4  30.2  \n0.6  0 1.6  33.2  5 5 4 2 \n30.2  0.5  4 30.5  \n(g) 3 \n2 1 \n4 0.4  32  0.4  30.2  \n0.6  0 1.6  33.2  5 5 4 2 \n30.2  0.5  4 30.5  \n(h) 3 \n2 1 \n4 0.4  32  0.4  30.2  \n0.6  0 0.4  33  5 5 4 2 \n30.2  0.5  4 30.5  \n(i) 3 \n2 1 \n4 \n(j) \ue001 \n0 0 1 0  \n1 0 0 0  \n0 0 0 1  \n0 1 0 0  \u00da \ue001  \n2 0 2 0:6  \n3 3 4  \ue0032 \n5 5 4 2  \n\ue0031 \ue0032 3:4  \ue0031 \u00da \nD \ue001 \n1 0 0 0  \n0:4  1 0 0 \n\ue0030:2  0:5  1 0 \n0:6  0 0:4  1 \u00da \ue001  \n5 5 4  2 \n0 \ue0032 0:4  \ue0030:2  \n0 0 4  \ue0030:5  \n0 0 0  \ue0033 \u00da \nP A L U \nFigure  28.2  The  operation  of LUP-DECOMPOSITION . (a)  The input matrix A with the identity \npermutation  of the  rows  in yellow  on  the  left.  The  \u00fbrst  step  of the algorithm determines that the \nelement 5 highlighted  in blue  in the  third  row  is the  pivot  for  the  \u00fbrst  column. (b)  Rows 1 and 3 \nare swapped and the permutation is updated. The tan  column and row represent v and w T . (c)  The \nvector v is replaced by v=5, and the lower right of the matrix is updated with  the Schur complement. \nLines divide the matrix into three regions: element s of U (above), elements of L (left), and elements \nof the Schur complement (lower right). (d)\u2013(f)  The second step. (g)\u2013(i)  The third step. No further \nchanges  occur  on  the  fourth  (\u00fbnal)  step.  (j)  The LUP decomposition PA  D LU  . 832 Chapter 28 Matrix Operations \nthe .n \ue003 k C 1/ \ue005 .n \ue003 k C 1/ submatrix whose upper left is in row k and  col-  \numn k. Each  time  through  the  outer  loop,  lines  539  determine  the  element a k 0 k \nwith  the  largest  absolute  value  of those  in the  current  \u00fbrst  column (column k) of \nthe .n \ue003 k C 1/ \ue005 .n \ue003 k C 1/ submatrix that the procedure is currently working \non.  If all  elements  in the  current  \u00fbrst  column  are  0, lines  10311  report  that  the  \nmatrix  is singular.  To  pivot,  line  12  exchanges  \ufffd\u0152k  0 \ufffd with \ufffd\u0152k \ufffd, and  lines  13314  \nexchange the kth and k 0 th rows of A, thereby making the pivot element a kk  . (The \nentire rows are swapped because in the derivation o f the method above, not only is \nA 0 \ue003 vw  T =a  k1  multiplied by P 0 , but so is v=a  k1  .) Finally, the Schur complement is \ncomputed  by  lines  15318  in much  the  same  way  as it is computed  by  lines  6311  of \nLU-DECOMPOSITION , except that here the operation is written to work  in place. \nBecause  of its  triply  nested  loop  structure,  LUP-DECOMPOSITION  has  a run-  \nning time of \u201a.n  3 /, which  is the  same  as that  of LU-DECOMPOSITION . Thus, \npivoting costs at most a constant factor in time. \nExercises  \n28.1-1  \nSolve the equation \u00e3 \n1 0 0  \n4 1 0  \n\ue0036 5 1  \u00e4\u00e3 \nx 1 \nx 2 \nx 3 \u00e4 \nD \u00e3 \n3 \n14  \n\ue0037 \u00e4 \nby using forward substitution. \n28.1-2  \nFind an LU decomposition of the matrix \u00e3 \n4 \ue0035 6  \n8 \ue0036 7  \n12  \ue0037 12  \u00e4 \n: \n28.1-3  \nSolve the equation \u00e3 \n1 5 4  \n2 0 3  \n5 8 2  \u00e4\u00e3 \nx 1 \nx 2 \nx 3 \u00e4 \nD \u00e3 \n12  \n9 \n5 \u00e4 \nby using an LUP decomposition. \n28.1-4  \nDescribe the LUP decomposition of a diagonal matrix . 28.2  Inverting  matrices  833 \n28.1-5  \nDescribe the LUP decomposition of a permutation mat rix, and prove that it is \nunique. \n28.1-6  \nShow that for all n \ue004 1, there exists a singular n \ue005 n matrix  that  has  an LU  decom-  \nposition. \n28.1-7  \nIn LU-DECOMPOSITION , is it necessary to perform the outermost for  loop  itera-  \ntion when k D n? How  about  in LUP-DECOMPOSITION ? \n28.2  Inverting  matrices  \nAlthough  you  can  use  equation  (28.3)  to solve  a system  of linear  equations  by  com-  \nputing a matrix inverse, in practice you are better  off using more numerically stable \ntechniques, such as LUP decomposition. Sometimes, h owever, you really do need \nto compute a matrix inverse. This section shows how  to use LUP decomposition to \ncompute a matrix inverse. It also proves that matri x multiplication and computing \nthe inverse of a matrix are equivalently hard probl ems, in that (subject  to techni-  \ncal conditions) an algorithm for one can solve the other in the same asymptotic \nrunning  time.  Thus,  you  can  use  Strassen\u2019s  algorithm  (see  Section  4.2)  for  matrix  \nmultiplication  to invert  a matrix.  Indeed,  Strassen\u2019s  original paper was motivated \nby the idea that a set of a linear equations could be solved more quickly than by \nthe usual method. \nComputing  a matrix  inverse  from  an  LUP  decomposition  \nSuppose that you have an LUP decomposition of a mat rix A in the form of three \nmatrices L, U , and P such that PA  D LU  . Using  LUP-SOLVE , you can solve \nan equation of the form Ax  D b in \u201a.n  2 / time.  Since  the  LUP  decomposition  de-  \npends on A but not b, you  can  run  LUP-SOLVE  on a second set of equations of the \nform Ax  D b 0 in \u201a.n  2 / additional  time.  In general,  once  you  have  the  LUP  decom-  \nposition of A, you can solve, in \u201a.kn  2 / time, k versions of the equation Ax  D b \nthat differ only in the vector b. \nLet\u2019s  think  of the  equation  \nAX  D I n ; (28.11)  \nwhich  de\u00fbnes  the  matrix  X , the inverse of A, as a set of n distinct equations of the \nform Ax  D b. To be precise, let X i denote the i th column of X , and recall that the 834 Chapter 28 Matrix Operations \nunit vector e i is the i th column of I n . You  can  then  solve  equation  (28.11)  for  X \nby using the LUP decomposition for A to solve each equation \nAX  i D e i \nseparately for X i . Once  you  have  the  LUP  decomposition,  you  can  compute  each  \nof the n columns X i in \u201a.n  2 / time, and so you can compute X from the LUP \ndecomposition of A in \u201a.n  3 / time.  Since  you  \u00fbnd  the  LUP  decomposition  of A in \n\u201a.n  3 / time, you can compute the inverse A \ue0021 of a matrix A in \u201a.n  3 / time. \nMatrix  multiplication  and  matrix  inversion  \nNow  let\u2019s  see  how  the  theoretical  speedups  obtained  for  matrix  multiplication  trans-  \nlate  to speedups  for  matrix  inversion.  In fact,  we\u2019ll  prove  something  stronger:  ma-  \ntrix inversion is equivalent to matrix multiplicati on, in the following sense. If M.n/  \ndenotes the time to multiply two n \ue005 n matrices, then a nonsingular n \ue005 n matrix \ncan be inverted in O.M.n//  time. Moreover, if I.n/  denotes the time to invert a \nnonsingular n \ue005 n matrix, then two n \ue005 n matrices can be multiplied in O.I.n//  \ntime. We prove these results as two separate theore ms. \nTheorem  28.1  (Multiplication  is no  harder  than  inversion)  \nIf an n \ue005 n matrix can be inverted in I.n/  time, where I.n/  D \ufffd.n  2 / and I.n/  \nsatis\u00fbes  the  regularity  condition  I.3n/  D O.I.n// , then two n \ue005 n matrices can be \nmultiplied in O.I.n//  time. \nProof  Let A and B be n \ue005 n matrices. To compute their product C D AB  , de\u00fbne  \nthe 3n  \ue005 3n  matrix D by \nD D \u00e3 \nI n A 0  \n0 I  n B \n0 0 I  n \u00e4 \n: \nThe inverse of D is \nD \ue0021 D \u00e3 \nI n \ue003A AB  \n0 I  n \ue003B \n0 0 I  n \u00e4 \n; \nand thus to compute the product AB  , just take the upper right n \ue005 n submatrix \nof D \ue0021 . \nConstructing matrix D takes \u201a.n  2 / time, which is O.I.n//  from the assumption \nthat I.n/  D \ufffd.n  2 /, and inverting D takes O.I.3n//  D O.I.n//  time, by the \nregularity condition on I.n/. We thus have M.n/  D O.I.n// . \nNote that I.n/  satis\u00fbes  the  regularity  condition  whenever  I.n/  D \u201a.n  c lg d n/ \nfor any constants c>0  and d \ue004 0. 28.2  Inverting  matrices  835 \nThe proof that matrix inversion is no harder than m atrix multiplication relies on \nsome  properties  of symmetric  positive-de\u00fbnite  matrices  proved  in Section  28.3.  \nTheorem  28.2  (Inversion  is no  harder  than  multiplication)  \nSuppose that two n \ue005 n real matrices can be multiplied in M.n/  time, where \nM.n/  D \ufffd.n  2 / and M.n/  satis\u00fbes  the  following  two  regularity  conditions:  \n1. M.n  C k/  D O.M.n//  for any k in the range 0 \u0dc4 k<n , and \n2. M.n=2/  \u0dc4 cM.n/  for some constant c<1=2 . \nThen the inverse of any real nonsingular n \ue005 n matrix can be computed in O.M.n//  \ntime. \nProof  Let A be an n \ue005 n matrix  with  real-valued  entries  that  is nonsingular.  As-  \nsume that n is an exact power of 2 (i.e., n D 2 l for some integer l ); we\u2019ll  see  at the  \nend of the proof what to do if n is not an exact power of 2. \nFor the moment, assume that the n \ue005 n matrix A is symmetric  and  positive-  \nde\u00fbnite.  Partition  each  of A and its inverse A \ue0021 into four n=2  \ue005 n=2  submatrices: \nA D \u00cf B C  T \nC D  \u00d0 \nand A \ue0021 D \u00cf R T  \nU V  \u00d0 \n: (28.12)  \nThen, if we let \nS D D \ue003 CB  \ue0021 C T (28.13)  \nbe the Schur complement of A with respect to B (we\u2019ll  see  more  about  this  form  \nof Schur  complement  in Section  28.3),  we  have  \nA \ue0021 D \u00cf R T  \nU V  \u00d0 \nD \u00cf B \ue0021 C B \ue0021 C T S \ue0021 CB  \ue0021 \ue003B \ue0021 C T S \ue0021 \n\ue003S \ue0021 CB  \ue0021 S \ue0021 \u00d0 \n; (28.14)  \nsince AA  \ue0021 D I n , as you can verify by performing the matrix multip lication. Be-  \ncause A is symmetric  and  positive-de\u00fbnite,  Lemmas  28.4  and  28.5  in Section  28.3  \nimply that B and S are  both  symmetric  and  positive-de\u00fbnite.  By  Lemma  28.3  in \nSection  28.3,  therefore,  the  inverses  B \ue0021 and S \ue0021 exist,  and  by  Exercise  D.2-6  on  \npage  1223,  B \ue0021 and S \ue0021 are symmetric, so that .B  \ue0021 / T D B \ue0021 and .S  \ue0021 / T D S \ue0021 . \nTherefore, to compute the submatrices \nR D B \ue0021 C B \ue0021 C T S \ue0021 CB  \ue0021 ; \nT D \ue003B \ue0021 C T S \ue0021 ; \nU D \ue003S \ue0021 CB  \ue0021 ; and \nV D S \ue0021 \nof A \ue0021 , do the following, where all matrices mentioned ar e n=2  \ue005 n=2: 836 Chapter 28 Matrix Operations \n1. Form  the  submatrices  B , C , C T , and D of A. \n2. Recursively compute the inverse B \ue0021 of B . \n3. Compute  the  matrix  product  W D CB  \ue0021 , and then compute its transpose W T , \nwhich equals B \ue0021 C T (by  Exercise  D.1-2  on  page  1219  and  .B  \ue0021 / T D B \ue0021 ). \n4. Compute  the  matrix  product  X D WC  T , which equals CB  \ue0021 C T , and then \ncompute the matrix S D D \ue003 X D D \ue003 CB  \ue0021 C T . \n5. Recursively  compute  the  inverse  S \ue0021 of S . \n6. Compute  the  matrix  product  Y D S \ue0021 W , which equals S \ue0021 CB  \ue0021 , and \nthen compute its transpose Y T , which equals B \ue0021 C T S \ue0021 (by  Exercise  D.1-2,  \n.B  \ue0021 / T D B \ue0021 , and .S  \ue0021 / T D S \ue0021 ). \n7. Compute  the  matrix  product  Z D W T Y , which equals B \ue0021 C T S \ue0021 CB  \ue0021 . \n8. Set  R D B \ue0021 C Z. \n9. Set T D \ue003Y T . \n10.  Set  U D \ue003Y . \n11.  Set  V D S \ue0021 . \nThus, to invert an n \ue005 n symmetric  positive-de\u00fbnite  matrix,  invert  two  n=2  \ue005 n=2  \nmatrices  in steps  2 and  5; perform  four  multiplications  of n=2  \ue005 n=2  matrices in \nsteps  3, 4, 6, and  7; plus  incur  an additional  cost  of O.n  2 / for  extracting  submatri-  \nces from A, inserting submatrices into A \ue0021 , and performing a constant number of \nadditions, subtractions, and transposes on n=2  \ue005 n=2  matrices. The running time \nis given by the recurrence \nI.n/  \u0dc4 2I.n=2/  C 4M.n=2/  C O.n  2 / \nD 2I.n=2/  C \u201a.M.n//  (28.15)  \nD O.M.n//:  \nThe second line follows from the assumption that M.n/  D \ufffd.n  2 / and from the \nsecond regularity condition in the statement of the  theorem, which implies that \n4M.n=2/  < 2M.n/ . Because M.n/  D \ufffd.n  2 /, case  3 of the  master  theorem  \n(Theorem  4.1)  applies  to the  recurrence  (28.15),  giving  the  O.M.n//  result. \nIt remains to prove how to obtain the same asymptot ic running time  for  ma-  \ntrix multiplication as for matrix inversion when A is invertible but not symmetric \nand  positive-de\u00fbnite.  The  basic  idea  is that  for  any  nonsing ular matrix A, the  ma-  \ntrix A T A is symmetric  (by  Exercise  D.1-2)  and  positive-de\u00fbnite  (by  Theorem  D.6  \non  page  1222).  The  trick,  then,  is to reduce  the  problem  of inverting A to the \nproblem of inverting A T A. \nThe reduction is based on the observation that when  A is an n \ue005 n nonsingular \nmatrix, we have 28.2  Inverting  matrices  837 \nA \ue0021 D .A  T A/  \ue0021 A T ; \nsince ..A  T A/  \ue0021 A T /A  D .A  T A/  \ue0021 .A  T A/  D I n and a matrix inverse is unique. \nTherefore, to compute A \ue0021 , \u00fbrst  multiply  A T by A to obtain A T A, then invert the \nsymmetric  positive-de\u00fbnite  matrix  A T A using  the  above  divide-and-conquer  al-  \ngorithm,  and  \u00fbnally  multiply  the  result  by  A T . Each of these three steps takes \nO.M.n//  time, and thus any nonsingular matrix with real ent ries can be inverted \nin O.M.n//  time. \nThe above proof assumed that A is an n \ue005 n matrix, where n is an exact power \nof 2. If n is not an exact power of 2, then let k<n  be such that n C k is an exact \npower of 2, and  de\u00fbne  the  .n C k/  \ue005 .n C k/  matrix A 0 as \nA 0 D \u00cf A 0  \n0 I  k \u00d0 \n: \nThen the inverse of A 0 is \n\u00cf A 0  \n0 I  k \u00d0 \ue0021 \nD \u00cf A \ue0021 0 \n0 I  k \u00d0 \n; \nApply the method of the proof to A 0 to compute the inverse of A 0 , and  take  the  \u00fbrst  \nn rows and n columns of the result as the desired answer A \ue0021 . The  \u00fbrst  regular-  \nity condition on M.n/  ensures that enlarging the matrix in this way incre ases the \nrunning time by at most a constant factor. \nThe  proof  of Theorem  28.2  suggests  how  to solve  the  equation  Ax  D b by using \nLU decomposition without pivoting, so long as A is nonsingular. Let y D A T b. \nMultiply both sides of the equation Ax  D b by A T , yielding .A  T A/x  D A T b D y . \nThis  transformation  doesn\u2019t  affect  the  solution  x , since A T is invertible. Because \nA T A is symmetric  positive-de\u00fbnite,  it can  be factored  by  computing  an LU  de-  \ncomposition. Then, use forward and back substitutio n to solve for x in the  equa-  \ntion .A  T A/x  D y . Although this method is theoretically correct, in  practice the \nprocedure  LUP-DECOMPOSITION  works  much  better.  LUP  decomposition  re-  \nquires fewer arithmetic operations by a constant fa ctor, and it has somewhat better \nnumerical properties. \nExercises  \n28.2-1  \nLet M.n/  be the time to multiply two n \ue005 n matrices, and let S.n/  denote the time \nrequired to square an n \ue005 n matrix.  Show  that  multiplying  and  squaring  matri-  \nces  have  essentially  the  same  dif\u00fbculty:  an M.n/-time  matrix-multiplication  al-  \ngorithm implies an O.M.n//-time  squaring  algorithm,  and  an S.n/-time  squaring  \nalgorithm implies an O.S.n//-time  matrix-multiplication  algorithm.  838 Chapter 28 Matrix Operations \n28.2-2  \nLet M.n/  be the time to multiply two n \ue005 n matrices. Show that an M.n/-time  \nmatrix-multiplication  algorithm  implies  an O.M.n//-time  LUP-decomposition  al-  \ngorithm. (The LUP decomposition your method produce s need not be the same as \nthe  result  produced  by  the  LUP-DECOMPOSITION  procedure.) \n28.2-3  \nLet M.n/  be the time to multiply two n \ue005 n boolean matrices, and let T.n/  be the \ntime  to \u00fbnd  the  transitive  closure  of an n \ue005 n boolean  matrix.  (See  Section  23.2.)  \nShow that an M.n/-time  boolean  matrix-multiplication  algorithm  implies  an \nO.M.n/  lg n/-time  transitive-closure  algorithm,  and  a T.n/-time  transitive-closure  \nalgorithm implies an O.T.n//-time  boolean  matrix-multiplication  algorithm.  \n28.2-4  \nDoes  the  matrix-inversion  algorithm  based  on  Theorem  28.2  work when matrix \nelements  are  drawn  from  the  \u00fbeld  of integers  modulo  2? Explain.  \n? 28.2-5  \nGeneralize  the  matrix-inversion  algorithm  of Theorem  28.2  to handle matrices of \ncomplex numbers, and prove that your generalization  works correctly. ( Hint: In-  \nstead of the transpose of A, use the conjugate  transpose  A \ue003 , which you obtain \nfrom the transpose of A by  replacing  every  entry  with  its  complex  conjugate.  In-  \nstead of symmetric matrices, consider Hermitian  matrices, which are matrices A \nsuch that A D A \ue003 .) \n28.3  Symmetric  positive-de\u00fbnite  matrices  and  least-squar es approximation  \nSymmetric  positive-de\u00fbnite  matrices  have  many  interesting  and  desirable  proper-  \nties. An n \ue005 n matrix A is symmetric  positive-de\u00fbnite  if A D A T (A is symmetric) \nand x T Ax>0  for all n-vectors  x \u00a4 0 (A is positive-de\u00fbnite).  Symmetric  positive-  \nde\u00fbnite  matrices  are  nonsingular,  and  an LU  decomposition  on them will not divide \nby 0. This section proves these and several other impor tant properties of symmetric \npositive-de\u00fbnite  matrices.  We\u2019ll  also  see  an interesting  application  to curve  \u00fbtting  \nby  a least-squares  approximation.  \nThe  \u00fbrst  property  we  prove  is perhaps  the  most  basic.  \nLemma  28.3  \nAny  positive-de\u00fbnite  matrix  is nonsingular.  28.3  Symmetric  positive-de\ufb01nite  matrices  and  least-squar es approximation 839 \nProof  Suppose that a matrix A is singular.  Then  by  Corollary  D.3  on  page  1221,  \nthere exists a nonzero vector x such that Ax  D 0. Hence, x T Ax  D 0, and A cannot \nbe positive-de\u00fbnite.  \nThe  proof  that  an LU  decomposition  on  a symmetric  positive-de\u00fbnite  matrix  A \nwon\u2019t  divide  by  0 is more involved. We begin by proving properties ab out certain \nsubmatrices of A. De\u00fbne  the  kth leading  submatrix  of A to be the matrix A k \nconsisting  of the  intersection  of the  \u00fbrst  k rows  and  \u00fbrst  k columns of A. \nLemma  28.4  \nIf A is a symmetric  positive-de\u00fbnite  matrix,  then  every  leading  submatrix of A is \nsymmetric  and  positive-de\u00fbnite.  \nProof  Since A is symmetric, each leading submatrix A k is also  symmetric.  We\u2019ll  \nprove that A k is positive-de\u00fbnite  by  contradiction.  If A k is not  positive-de\u00fbnite,  \nthen there exists a k-vector  x k \u00a4 0 such that x T \nk A k x k \u0dc4 0. Let A be n \ue005 n, and \nA D \u00cf A k B T \nB C  \u00d0 \n(28.16)  \nfor submatrices B (which is .n \ue003 k/  \ue005 k) and C (which is .n \ue003 k/  \ue005 .n \ue003 k/). De\u00fbne  \nthe n-vector  x D .x  T \nk 0/  T , where n \ue003 k0s follow x k . Then we have \nx T Ax  D .x  T \nk 0/  \u00cf A k B T \nB C  \u00d0\u00cf  x k \n0 \u00d0 \nD .x  T \nk 0/  \u00cf A k x k \nBx  k \u00d0 \nD x T \nk A k x k \n\u0dc4 0;  \nwhich contradicts A being  positive-de\u00fbnite.  \nWe now turn to some essential properties of the Sch ur complement. Let A be a \nsymmetric  positive-de\u00fbnite  matrix,  and  let  A k be a leading k \ue005 k submatrix of A. \nPartition A once  again  according  to equation  (28.16).  Equation  (28.10)  generalizes \nto de\u00fbne  the  Schur  complement  S of A with respect to A k as \nS D C \ue003 BA  \ue0021 \nk B T : (28.17)  \n(By  Lemma  28.4,  A k is symmetric  and  positive-de\u00fbnite,  and  therefore,  A \ue0021 \nk exists \nby  Lemma  28.3,  and  S is well  de\u00fbned.)  The  earlier  de\u00fbnition  (28.10)  of the  Schur  \ncomplement  is consistent  with  equation  (28.17)  by  letting  k D 1. \nThe  next  lemma  shows  that  the  Schur-complement  matrices  of symmetric  posi-  \ntive-de\u00fbnite  matrices  are  themselves  symmetric  and  positive-de\u00fbnite.  We  used  this  840 Chapter 28 Matrix Operations \nresult  in Theorem  28.2,  and  its  corollary  will  help  prove  that LU decomposition \nworks  for  symmetric  positive-de\u00fbnite  matrices.  \nLemma  28.5  (Schur  complement  lemma)  \nIf A is a symmetric  positive-de\u00fbnite  matrix  and  A k is a leading k \ue005 k submatrix \nof A, then the Schur complement S of A with respect to A k is symmetric and \npositive-de\u00fbnite.  \nProof  Because A is symmetric, so is the submatrix C . By  Exercise  D.2-6  on  \npage  1223,  the  product  BA  \ue0021 \nk B T is symmetric. Since C and BA  \ue0021 \nk B T are  symmet-  \nric,  then  by  Exercise  D.1-1  on  page  1219,  so is S . \nIt remains to show that S is positive-de\u00fbnite.  Consider  the  partition  of A given in \nequation  (28.16).  For  any  nonzero  vector  x , we have x T Ax>0  by the assumption \nthat A is positive-de\u00fbnite.  Let  the  subvectors  y and \u00b4 consist  of the  \u00fbrst  k and last \nn \ue003 k elements in x , respectively, and thus they are compatible with A k and C , \nrespectively. Because A \ue0021 \nk exists, we have \nx T Ax  D .y  T \u00b4 T / \u00cf A k B T \nB C  \u00d0\u00cf  y \n\u00b4 \u00d0 \nD .y  T \u00b4 T / \u00cf A k y C B T \u00b4 \nBy  C C\u00b4  \u00d0 \nD y T A k y C y T B T \u00b4 C \u00b4 T By  C \u00b4 T C\u00b4  \nD .y C A \ue0021 \nk B T \u00b4/ T A k .y C A \ue0021 \nk B T \u00b4/ C \u00b4 T .C  \ue003 BA  \ue0021 \nk B T /\u00b4;  (28.18)  \nThis last equation, which you can verify by multipl ying through,  amounts  to <com-  \npleting  the  square=  of the  quadratic  form.  (See  Exercise  28.3-2.)  \nSince x T Ax >0  holds for any nonzero x , pick any nonzero \u00b4 and then choose \ny D \ue003A \ue0021 \nk B T \u00b4, which  causes  the  \u00fbrst  term  in equation  (28.18)  to vanish,  leaving \n\u00b4 T .C  \ue003 BA  \ue0021 \nk B T /\u00b4 D \u00b4 T S\u00b4  \nas the value of the expression. For any \u00b4 \u00a4 0, we therefore have \u00b4 T S\u00b4  D \nx T Ax>0 , and thus S is positive-de\u00fbnite.  \nCorollary  28.6  \nLU  decomposition  of a symmetric  positive-de\u00fbnite  matrix  never causes a division \nby 0. \nProof  Let A be an n \ue005 n symmetric  positive-de\u00fbnite  matrix.  In fact,  we\u2019ll  prove  \na stronger result than the statement of the corolla ry: every pivot is strictly positive. \nThe  \u00fbrst  pivot  is a 11  . Let e 1 be the  length-n unit vector .1  0 0 \ue001 \ue001 \ue001  0/  T , \nso that a 11  D e T \n1 Ae  1 , which is positive because e 1 is nonzero and A is positive 28.3  Symmetric  positive-de\ufb01nite  matrices  and  least-squar es approximation 841 \nde\u00fbnite.  Since  the  \u00fbrst  step  of LU  decomposition  produces  the Schur complement \nof A with respect to A 1 D .a 11  /, Lemma  28.5  implies  by  induction  that  all  pivots  \nare positive. \nLeast-squares  approximation  \nOne  important  application  of symmetric  positive-de\u00fbnite  matrices  arises  in \u00fbtting  \ncurves to given sets of data points. You are given a set of m data points \n.x 1 ;y  1 /;.x  2 ;y  2 /;:::;.x  m ;y  m /; \nwhere you know that the y i are  subject  to measurement  errors.  You  wish  to deter-  \nmine a function F.x/  such that the approximation errors \n\u0dc1 i D F.x  i / \ue003 y i (28.19)  \nare small for i D 1;2;:::;m . The form of the function F depends on the problem \nat hand.  Let\u2019s  assume  that  it has  the  form  of a linearly  weight ed sum \nF.x/  D n X  \nj D1 c j f j .x/;  \nwhere the number n of summands  and  the  speci\u00fbc  basis  functions  f j are chosen \nbased on knowledge of the problem at hand. A common  choice is f j .x/  D x j \ue0021 , \nwhich means that \nF.x/  D c 1 C c 2 x C c 3 x 2 C \ue001 \ue001 \ue001 C  c n x n\ue0021 \nis a polynomial of degree n \ue003 1 in x . Thus, if you are given m data points \n.x 1 ;y  1 /;.x  2 ;y  2 /;:::;.x  m ;y  m /, you need to calculate n coef\u00fbcients  c 1 ;c 2 ;:::;c  n \nthat minimize the approximation errors \u0dc1 1 ; \u0dc1  2 ; : : : ; \u0dc1  m . \nBy choosing n D m, you can calculate each y i exactly  in equation  (28.19).  \nSuch  a high-degree  polynomial  F <\u00fbts  the  noise=  as well  as the  data,  however,  and  \ngenerally gives poor results when used to predict y for previously unseen values \nof x . It is usually better to choose n signi\u00fbcantly  smaller  than  m and hope that \nby  choosing  the  coef\u00fbcients  c j well, you can obtain a function F that  \u00fbnds  the  \nsigni\u00fbcant  patterns  in the  data  points  without  paying  undue  attention to the noise. \nSome theoretical principles exist for choosing n, but they are beyond the scope of \nthis text. In any case, once you choose a value of n that is less than m, you end up \nwith an overdetermined set of equations whose solut ion you wish to approximate. \nLet\u2019s  see  how  to do  so.  842 Chapter 28 Matrix Operations \nLet \nA D \u00db \nf 1 .x 1 / f  2 .x 1 / :::  f n .x 1 / \nf 1 .x 2 / f  2 .x 2 / :::  f n .x 2 / \n: : : : : : : : : : : : \nf 1 .x m / f  2 .x m / :::  f n .x m / \ue005 \ndenote the matrix of values of the basis functions at the given points, that is, \na ij D f j .x i /. Let c D .c k / denote the desired n-vector  of coef\u00fbcients.  Then,  \nAc  D \u00db \nf 1 .x 1 / f  2 .x 1 / :::  f n .x 1 / \nf 1 .x 2 / f  2 .x 2 / :::  f n .x 2 / \n: : : : : : : : : : : : \nf 1 .x m / f  2 .x m / :::  f n .x m / \ue005\u00db \nc 1 \nc 2 \n: : : \nc n \ue005 \nD \u00db \nF.x  1 / \nF.x  2 / \n: : : \nF.x  m / \ue005 \nis the m-vector  of <predicted  values=  for  y . Thus, \n\u0dc1 D Ac  \ue003 y \nis the m-vector  of approximation  errors . \nTo  minimize  approximation  errors,  let\u2019s  minimize  the  norm  of the error vector \u0dc1, \nwhich gives a least-squares  solution , since \nk\u0dc1k D  \ue001 m X  \ni D1 \u0dc1 2 \ni ! 1=2  \n: \nBecause \nk\u0dc1k 2 D kAc  \ue003 y k 2 D m X  \ni D1 \ue001 n X  \nj D1 a ij c j \ue003 y i ! 2 \n; \nto minimize k\u0dc1k, differentiate k\u0dc1k 2 with respect to each c k and then set the result \nto 0: \nd k\u0dc1k 2 \ndc  k D m X  \ni D1 2 \ue001 n X  \nj D1 a ij c j \ue003 y i ! \na ik  D 0:  (28.20)  \nThe n equations  (28.20)  for  k D 1;2;:::;n  are equivalent to the single matrix \nequation 28.3  Symmetric  positive-de\ufb01nite  matrices  and  least-squar es approximation 843 \n.Ac  \ue003 y/  T A D 0 \nor,  equivalently  (using  Exercise  D.1-2  on  page  1219),  to \nA T .Ac  \ue003 y/  D 0;  \nwhich implies \nA T Ac  D A T y:  (28.21)  \nIn statistics,  equation  (28.21)  is called  the  normal  equation . The matrix A T A is \nsymmetric  by  Exercise  D.1-2,  and  if A has  full  column  rank,  then  by  Theorem  D.6  \non  page  1222,  A T A is positive-de\u00fbnite  as well.  Hence,  .A  T A/  \ue0021 exists, and the \nsolution  to equation  (28.21)  is \nc D \u00e3 \n.A  T A/  \ue0021 A T \u00e4 \ny \nD A C y;  (28.22)  \nwhere the matrix A C D ..A  T A/  \ue0021 A T / is the pseudoinverse  of the matrix A. The \npseudoinverse naturally generalizes the notion of a  matrix inverse to the case in \nwhich A is not  square.  (Compare  equation  (28.22)  as the  approximate  solution \nto Ac  D y with the solution A \ue0021 b as the exact solution to Ax  D b.) \nAs  an example  of producing  a least-squares  \u00fbt,  suppose  that  you  have  \u00fbve  data  \npoints \n.x 1 ;y  1 / D .\ue0031;2/;  \n.x 2 ;y  2 / D .1;1/;  \n.x 3 ;y  3 / D .2;1/;  \n.x 4 ;y  4 / D .3;0/;  \n.x 5 ;y  5 / D .5;3/;  \nshown  as orange  dots  in Figure  28.3,  and  you  want  to \u00fbt these  points  with  a qua-  \ndratic polynomial \nF.x/  D c 1 C c 2 x C c 3 x 2 : \nStart  with  the  matrix  of basis-function  values  \nA D \u00e2 \n1 x  1 x 2 \n1 \n1 x  2 x 2 \n2 \n1 x  3 x 2 \n3 \n1 x  4 x 2 \n4 \n1 x  5 x 2 \n5 \u00e3 \nD \u00e2 \n1 \ue0031 1  \n1 1 1  \n1 2 4  \n1 3 9  \n1 5 25  \u00e3 \n; \nwhose pseudoinverse is 844 Chapter 28 Matrix Operations \n0.5  1.0  1.5  2.0 2.5  3.0  \n0.0 \n1 2 3 4 5 0 31  \u20132 x y \nF(x) = 1.2  3 0.757 x + 0.214 x 2 \nFigure  28.3  The  least-squares  \u00fbt of a quadratic  polynomial  to the  set  of \u00fbve data points \nf.\ue0031;2/;.1;1/;.2;1/;.3;0/;.5;3/ g. The orange dots are the data points, and the blue  dots are their \nestimated values predicted by the polynomial F.x/  D 1:2  \ue003 0:757x  C 0:214x  2 , the  quadratic  poly-  \nnomial that minimizes the sum of the squared errors , plotted in blue. Each orange line shows the \nerror for one data point. \nA C D \u00e3 \n0:500  0:300  0:200  0:100  \ue0030:100  \n\ue0030:388  0:093  0:190  0:193  \ue0030:088  \n0:060  \ue0030:036  \ue0030:048  \ue0030:036  0:060  \u00e4 \n: \nMultiplying y by A C gives  the  coef\u00fbcient  vector  \nc D \u00e3 \n1:200  \n\ue0030:757  \n0:214  \u00e4 \n; \nwhich corresponds to the quadratic polynomial \nF.x/  D 1:200  \ue003 0:757x  C 0:214x  2 \nas the  closest-\u00fbtting  quadratic  to the  given  data,  in a least-squares  sense.  \nAs a practical matter, you would typically solve th e normal equation  (28.21)  by  \nmultiplying y by A T and  then  \u00fbnding  an LU  decomposition  of A T A. If A has full \nrank, the matrix A T A is guaranteed to be nonsingular, because it is symm etric and \npositive-de\u00fbnite.  (See  Exercise  D.1-2  and  Theorem  D.6.)  28.3  Symmetric  positive-de\ufb01nite  matrices  and  least-squar es approximation 845 \nFigure  28.4  A least-squares  \u00fbt of a curve  of the  form  \nc 1 C c 2 x C c 3 x 2 C c 4 sin.2\ufffdx/  C c 5 cos.2\ufffdx/  \nfor  the  carbon-dioxide  concentrations  measured  in Mauna  Loa,  Hawaii  from  1990  1 to 2019,  where  \nx is the  number  of years  elapsed  since  1990.  This  curve  is the  famous  <Keeling  curve,=  illustrating  \ncurve-\u00fbtting  to nonpolynomial  formulas.  The  sine  and  cosin e terms allow modeling of seasonal \nvariations  in CO  2 concentrations.  The  red  curve  shows  the  measured  CO  2 concentrations. The best \n\u00fbt,  shown  in black,  has  the  form  \n352:83  C 1:39x  C 0:02x  2 C 2:83  sin.2\ufffdx/  \ue003 0:94  cos.2\ufffdx/ :  \nWe  close  this  section  with  an example  in Figure  28.4,  illustr ating that a curve \ncan  also  \u00fbt a nonpolynomial  function.  The  curve  con\u00fbrms  one  aspect of climate \nchange:  that  carbon  dioxide  (CO  2 ) concentrations have steadily increased over a \nperiod of 29  years. Linear and quadratic terms model the annual increase, and sine \nand cosine terms model seasonal variations. \n1 The year in which Introduction  to Algorithms  was  \u00fbrst  published.  846 Chapter 28 Matrix Operations \nExercises  \n28.3-1  \nProve  that  every  diagonal  element  of a symmetric  positive-de\u00fbnite  matrix  is posi-  \ntive. \n28.3-2  \nLet A D \u00cf a b  \nb c  \u00d0 \nbe a 2 \ue005 2 symmetric  positive-de\u00fbnite  matrix.  Prove  that  its  \ndeterminant ac  \ue003 b 2 is positive by <completing the square= in a manner similar to \nthat  used  in the  proof  of Lemma  28.5.  \n28.3-3  \nProve  that  the  maximum  element  in a symmetric  positive-de\u00fbn ite matrix lies on \nthe diagonal. \n28.3-4  \nProve that the determinant of each leading submatri x of a symmetric  positive-  \nde\u00fbnite  matrix  is positive.  \n28.3-5  \nLet A k denote the kth leading  submatrix  of a symmetric  positive-de\u00fbnite  matri x A. \nProve that det .A  k /= det.A  k\ue0021 / is the kth pivot during LU decomposition, where, \nby convention, det .A  0 / D 1. \n28.3-6  \nFind the function of the form \nF.x/  D c 1 C c 2 x lg x C c 3 e x \nthat  is the  best  least-squares  \u00fbt to the  data  points  \n.1;1/;.2;1/;.3;3/;.4;8/:  \n28.3-7  \nShow that the pseudoinverse A C satis\u00fbes  the  following  four  equations:  \nAA  C A D A;  \nA C AA  C D A C ; \n.AA  C / T D AA  C ; \n.A  C A/  T D A C A:  Problems for Chapter 28 847 \nProblems  \n28-1  Tridiagonal  systems  of linear  equations  \nConsider the tridiagonal matrix \nA D \u02c7 \n1 \ue0031 0 0 0  \n\ue0031 2  \ue0031 0 0  \n0 \ue0031 2  \ue0031 0  \n0 0  \ue0031 2  \ue0031 \n0 0 0  \ue0031 2  \ue002 \n: \na. Find an LU decomposition of A. \nb. Solve the equation Ax  D .1  1 1 1 1/  T by  using  forward  and  back  sub-  \nstitution. \nc. Find the inverse of A. \nd. Show how to solve the equation Ax  D b for any n \ue005 n symmetric  positive-  \nde\u00fbnite,  tridiagonal  matrix  A and any n-vector  b in O.n/  time by performing \nan LU decomposition. Argue that any method based on  forming A \ue0021 is asymp-  \ntotically more expensive in the worst case. \ne. Show how to solve the equation Ax  D b for any n \ue005 n nonsingular, tridiagonal \nmatrix A and any n-vector  b in O.n/  time  by  performing  an LUP  decomposi-  \ntion. \n28-2  Splines  \nA practical method for interpolating a set of point s with a curve is to use cu-  \nbic  splines . You are given a set f.x i ;y  i / W i D 0;1;:::;n g of n C 1 point-value  \npairs, where x 0 < x  1 < \ue001 \ue001 \ue001  < x  n . Your  goal  is to \u00fbt a piecewise-cubic  curve  \n(spline) f.x/  to the points. That is, the curve f.x/  is made up of n cubic  polyno-  \nmials f i .x/  D a i C b i x C c i x 2 C d i x 3 for i D 0;1;:::;n  \ue003 1, where if x falls in the \nrange x i \u0dc4 x \u0dc4 x i C1 , then the value of the curve is given by f.x/  D f i .x \ue003 x i /. \nThe points x i at which the cubic polynomials are <pasted= togethe r are called knots . \nFor simplicity, assume that x i D i for i D 0;1;:::;n . \nTo ensure continuity of f.x/ , require that \nf.x  i / D f i .0/  D y i ; \nf.x  i C1 / D f i .1/  D y i C1 \nfor i D 0;1;:::;n  \ue003 1. To ensure that f.x/  is suf\u00fbciently  smooth,  also  require  the  \n\u00fbrst  derivative  to be continuous  at each  knot:  848 Chapter 28 Matrix Operations \nf 0 .x i C1 / D f 0 \ni .1/  D f 0 \ni C1 .0/  \nfor i D 0;1;:::;n  \ue003 2. \na. Suppose that for i D 0;1;:::;n, in addition  to the  point-value  pairs  f.x i ;y  i /g, \nyou  are  also  given  the  \u00fbrst  derivative  D i D f 0 .x i / at each knot. Express each \ncoef\u00fbcient  a i , b i , c i , and d i in terms of the values y i , y i C1 , D i , and D i C1 . \n(Remember that x i D i .) How quickly can you compute the 4n  coef\u00fbcients  \nfrom  the  point-value  pairs  and  \u00fbrst  derivatives?  \nThe  question  remains  of how  to choose  the  \u00fbrst  derivatives  of f.x/  at the knots. \nOne  method  is to require  the  second  derivatives  to be continu ous at the knots: \nf 00 .x i C1 / D f 00 \ni .1/  D f 00 \ni C1 .0/  \nfor i D 0;1;:::;n \ue0032. At  the  \u00fbrst  and  last  knots,  assume  that  f 00 .x 0 / D f 00 \n0 .0/  D 0 \nand f 00 .x n / D f 00 \nn\ue0021 .1/  D 0. These assumptions make f.x/  a natural  cubic spline. \nb. Use the continuity constraints on the second deriva tive to show that for i D \n1;2;:::;n  \ue003 1, \nD i \ue0021 C 4D  i C D i C1 D 3.y  i C1 \ue003 y i \ue0021 /: (28.23)  \nc. Show that \n2D  0 C D 1 D 3.y  1 \ue003 y 0 /; (28.24)  \nD n\ue0021 C 2D  n D 3.y  n \ue003 y n\ue0021 /: (28.25)  \nd. Rewrite  equations  (28.23)3(28.25)  as a matrix  equation  involving the vector \nD D .D  0 D 1 D 2 \ue001 \ue001 \ue001  D n / T of unknowns.  What  attributes  does  the  ma-  \ntrix  in your  equation  have?  \ne. Argue that a natural cubic spline can interpolate a  set of n C 1 point-value  pairs  \nin O.n/  time  (see  Problem  28-1).  \nf. Show how to determine a natural cubic spline that i nterpolates a set of n C 1 \npoints .x i ;y  i / satisfying x 0 <x  1 < \ue001 \ue001 \ue001  <x  n , even when x i is not necessarily \nequal to i . What matrix equation must your method solve, and how quickly \ndoes  your  algorithm  run?  \nChapter  notes  \nMany  excellent  texts  describe  numerical  and  scienti\u00fbc  comp utation in much greater \ndetail than we have room for here. The following ar e especially readable:  George  Notes for Chapter 28 849 \nand  Liu  [180],  Golub  and  VanLoan  [192],  Press,  Teukolsky,  Vetterling,  and  Flan-  \nnery  [365,  366],  and  Strang  [422,  423].  \nGolub  and  Van  Loan  [192]  discuss  numerical  stability.  They  show why det.A/  \nis not necessarily a good indicator of the stabilit y of a matrix A, proposing instead \nto use kAk 1  kA \ue0021 k 1  , where kAk 1  D max \u02daP  n \nj D1 ja ij j W 1 \u0dc4 i \u0dc4 n \ue009 \n. They also \naddress the question of how to compute this value w ithout actually computing A \ue0021 . \nGaussian  elimination,  upon  which  the  LU  and  LUP  decompositi ons are based, \nwas  the  \u00fbrst  systematic  method  for  solving  linear  systems  of equations. It was also \none of the earliest numerical algorithms. Although it was known  earlier,  its  dis-  \ncovery  is commonly  attributed  to C. F. Gauss  (177731855).  In his famous paper \n[424],  Strassen  showed  that  an n \ue005 n matrix can be inverted in O.n  lg 7 / time.  Wino-  \ngrad  [460]  originally  proved  that  matrix  multiplication  is no harder than matrix \ninversion, and the converse is due to Aho, Hopcroft , and Ullman [5].  \nAnother important matrix decomposition is the singular  value  decomposition , \nor SVD . The SVD factors an m \ue005 n matrix A into A D Q 1 \u2020Q  T \n2 , where \u2020 is an \nm \ue005 n matrix with nonzero values only on the diagonal, Q 1 is m \ue005 m with mutually \northonormal columns, and Q 2 is n \ue005 n, also with mutually orthonormal columns. \nTwo vectors are orthonormal  if their inner product is 0 and each vector has a norm \nof 1. The  books  by  Strang  [422,  423]  and  Golub  and  Van  Loan  [192]  contain good \ntreatments of the SVD. \nStrang  [423]  has  an excellent  presentation  of symmetric  positive-de\u00fbnite  matri-  \nces and of linear algebra in general. 29  Linear  Programming  \nMany problems take the form of maximizing or minimi zing an objective, given \nlimited resources and competing constraints. If you  can specify the objective as \na linear function of certain variables, and if you can specify the constraints on \nresources as equalities or inequalities on those va riables, then you have a linear-  \nprogramming  problem. Linear  programs  arise  in a variety  of practical  applica-  \ntions. We begin by studying an application in elect oral politics. \nA political  problem  \nSuppose that you are a politician trying to win an election. Your district has three \ndifferent  types  of areas4urban,  suburban,  and  rural.  These  areas  have,  respec-  \ntively,  100,000,  200,000,  and  50,000  registered  voters.  Although  not  all  the  reg-  \nistered voters actually go to the polls, you decide  that to govern effectively, you \nwould like at least half the registered voters in e ach of the three regions to vote \nfor you. You are honorable and would never consider  supporting policies you \ndon\u2019t  believe  in.  You  realize,  however,  that  certain  issues  may be more effective \nin winning votes in certain places. Your primary is sues are preparing for a zombie \napocalypse, equipping sharks with lasers, building highways for  \u00fcying  cars,  and  \nallowing dolphins to vote. \nAccording  to your  campaign  staff\u2019s  research,  you  can  estima te how many votes \nyou  win  or lose  from  each  population  segment  by  spending  $1,000 on advertising \non each issue. This information appears in the tabl e of Figure 29.1.  In this  table,  \neach entry indicates the number of thousands of eit her urban, suburban, or rural \nvoters  who  would  be won  over  by  spending  $1,000  on  advertisin g in support of a \nparticular issue. Negative entries denote votes tha t would be lost. Your task is to \n\u00fbgure  out  the  minimum  amount  of money  that  you  need  to spend  in order to win \n50,000  urban  votes,  100,000  suburban  votes,  and  25,000  rural votes. \nYou could, by trial and error, devise a strategy th at wins the required number \nof votes, but the strategy you come up with might n ot be the least expensive one. \nFor example, you could devote $20,000 of advertisin g to preparing for a zombie Chapter 29 Linear Programming 851 \npolicy urban suburban rural \nzombie apocalypse \ue0032 5 3 \nsharks with lasers 8 2 \ue0035 \nhighways  for  \u00fcying  cars  0 0 10  \ndolphins voting 10  0 \ue0032 \nFigure  29.1  The effects of policies on voters. Each entry descr ibes the number of thousands of \nurban, suburban, or rural voters who could be won o ver by spending  $1,000  on  advertising  support  \nof a policy on a particular issue. Negative entries  denote votes that would be lost. \napocalypse,  $0  to equipping  sharks  with  lasers,  $4,000  to building highways for \n\u00fcying  cars,  and  $9,000  to allowing  dolphins  to vote.  In this  case, you would win \n.20  \ue001 \ue0032/ C .0 \ue001 8/ C .4 \ue001 0/ C .9 \ue001 10/  D 50  thousand urban votes, .20  \ue001 5/ C \n.0 \ue001 2/ C .4 \ue001 0/ C .9 \ue001 0/ D 100  thousand suburban votes, and .20  \ue001 3/ C .0 \ue001 \ue0035/ C \n.4 \ue001 10/  C .9 \ue001 \ue0032/ D 82  thousand rural votes. You would win the exact numbe r \nof votes desired in the urban and suburban areas an d more than enough votes in the \nrural area. (In fact, according to your model, in t he rural area you would receive \nmore votes than there are voters.) In order to garn er these votes, you would have \npaid for 20  C 0 C 4 C 9 D 33  thousand dollars of advertising. \nIt\u2019s  natural  to wonder  whether  this  strategy  is the  best  possible. That is, can you \nachieve  your  goals  while  spending  less  on  advertising?  Addi tional trial and error \nmight help you to answer this question, but a bette r approach is to formulate (or \nmodel ) this question mathematically. \nThe  \u00fbrst  step  is to decide  what  decisions  you  have  to make  and  to introduce \nvariables that capture these decisions. Since you h ave four decisions, you introduce \nfour decision  variables : \n\ue001 x 1 is the number of thousands of dollars spent on adve rtising on preparing for \na zombie apocalypse, \n\ue001 x 2 is the number of thousands of dollars spent on adve rtising on equipping \nsharks with lasers, \n\ue001 x 3 is the number of thousands of dollars spent on adve rtising on building  high-  \nways  for  \u00fcying  cars,  and  \n\ue001 x 4 is the number of thousands of dollars spent on adve rtising on allowing  dol-  \nphins to vote. \nYou then think about constraints , which are limits, or restrictions, on the values \nthat the decision variables can take. You can write  the requirement that you win at \nleast  50,000  urban  votes  as \n\ue0032x  1 C 8x  2 C 0x  3 C 10x  4 \ue004 50:  (29.1)  852 Chapter 29 Linear Programming \nSimilarly, you can write the requirements that you win at least 100,000  suburban  \nvotes  and  25,000  rural  votes  as \n5x  1 C 2x  2 C 0x  3 C 0x  4 \ue004 100  (29.2) \nand \n3x  1 \ue003 5x  2 C 10x  3 \ue003 2x  4 \ue004 25:  (29.3)  \nAny setting of the variables x 1 ;x  2 ;x  3 ;x  4 that  satis\u00fbes  inequalities  (29.1)3(29.3)  \nyields  a strategy  that  wins  a suf\u00fbcient  number  of each  type  of vote. \nFinally, you think about your objective , which is the quantity that you wish to \neither minimize or maximize. In order to keep costs  as small as possible, you would \nlike to minimize the amount spent on advertising. T hat is, you want to minimize \nthe expression \nx 1 C x 2 C x 3 C x 4 : (29.4)  \nAlthough negative advertising often occurs in polit ical campaigns, there is no such \nthing  as negative-cost  advertising.  Consequently,  you  require that \nx 1 \ue004 0; x 2 \ue004 0; x 3 \ue004 0; and x 4 \ue004 0:  (29.5)  \nCombining  inequalities  (29.1)3(29.3)  and  (29.5)  with  the  objective  of minimiz-  \ning  (29.4)  produces  what  is known  as a <linear  program.=  We  can format this \nproblem tabularly as \nminimize x 1 C x 2 C x 3 C x 4 (29.6)  \nsubject to \n\ue0032x  1 C 8x  2 C 0x  3 C 10x  4 \ue004 50  (29.7)  \n5x  1 C 2x  2 C 0x  3 C 0x  4 \ue004 100  (29.8)  \n3x  1 \ue003 5x  2 C 10x  3 \ue003 2x  4 \ue004 25  (29.9) \nx 1 ;x  2 ;x  3 ;x  4 \ue004 0 :  (29.10)  \nThe solution to this linear program yields your opt imal strategy. \nThe remainder of this chapter covers how to formula te linear programs and is \nan introduction to modeling in general. Modeling re fers to the general process of \nconverting a problem into a mathematical form amena ble to solution  by  an algo-  \nrithm.  Section  29.1  discusses  brie\u00fcy  the  algorithmic  aspects  of linear  program-  \nming,  although  it does  not  include  the  details  of a linear-pr ogramming algorithm. \nThroughout this book, we have seen ways to model pr oblems, such as by shortest \npaths and connectivity in a graph. When modeling a problem as a linear program, \nyou  go  through  the  steps  used  in this  political  example4iden tifying the decision \nvariables, specifying the constraints, and formulat ing the objective  function.  In or-  \nder to model a problem as a linear program, the con straints and objectives must be 29.1  Linear  programming  formulations  and  algorithms  853  \nlinear. In Section 29.2, we will see several other examples of modeling via linear \nprograms.  Section  29.3  discusses  duality,  an important  concept  in linear  program-  \nming and other optimization algorithms. \n29.1  Linear  programming  formulations  and  algorithms  \nLinear programs take a particular form, which we wi ll examine in this section. \nMultiple algorithms have been developed to solve li near programs. Some run in \npolynomial time, some do not, but they are all too complicated to show  here.  In-  \nstead, we will give an example that demonstrates so me ideas behind the simplex \nalgorithm, which is currently the most commonly dep loyed solution method. \nGeneral  linear  programs  \nIn the  general  linear-programming  problem,  we  wish  to optim ize a linear function \nsubject  to a set  of linear  inequalities.  Given  a set  of real  numbers a 1 ;a  2 ;:::;a  n and \na set of variables x 1 ;x  2 ;:::;x  n , we  de\u00fbne  a linear  function  f on those variables \nby \nf.x  1 ;x  2 ;:::;x  n / D a 1 x 1 C a 2 x 2 C \ue001 \ue001 \ue001 C  a n x n D n X  \nj D1 a j x j : \nIf b is a real number and f is a linear function, then the equation \nf.x  1 ;x  2 ;:::;x  n / D b \nis a linear  equality  and the inequalities \nf.x  1 ;x  2 ;:::;x  n / \u0dc4 b and f.x  1 ;x  2 ;:::;x  n / \ue004 b \nare linear  inequalities . We use the general term linear  constraints  to denote either \nlinear equalities or linear inequalities. Linear pr ogramming does not allow strict \ninequalities. Formally, a linear-programming  problem  is the problem of either \nminimizing  or maximizing  a linear  function  subject  to a \u00fbnite  set  of linear  con-  \nstraints. If minimizing, we call the linear program  a minimization  linear  program , \nand if maximizing, we call the linear program a maximization  linear  program . \nIn order  to discuss  linear-programming  algorithms  and  properties, it will be \nhelpful to use a standard notation for the input. B y convention,  a maximiza-  \ntion linear program takes as input n real numbers c 1 ;c 2 ;:::;c  n ; m real numbers \nb 1 ;b  2 ;:::;b  m ; and mn  real numbers a ij for i D 1;2;:::;m  and j D 1;2;:::;n . 854 Chapter 29 Linear Programming \nThe  goal  is to \u00fbnd  n real numbers x 1 ;x  2 ;:::;x  n that \nmaximize n X  \nj D1 c j x j (29.11)  \nsubject to \nn X  \nj D1 a ij x j \u0dc4 b i for i D 1;2;:::;m  (29.12)  \nx j \ue004 0 for j D 1;2;:::;n :  (29.13)  \nWe  call  expression  (29.11)  the  objective  function  and the n C m inequalities in \nlines  (29.12)  and  (29.13)  the  constraints . The n constraints  in line  (29.13)  are  \nthe nonnegativity  constraints . It can sometimes be more convenient to express a \nlinear program in a more compact form. If we create  an m \ue005 n matrix A D .a ij /, \nan m-vector  b D .b i /, an n-vector  c D .c j /, and an n-vector  x D .x j /, then we \ncan  rewrite  the  linear  program  de\u00fbned  in (29.11)3(29.13)  as \nmaximize c T x (29.14)  \nsubject to \nAx  \u0dc4 b (29.15)  \nx \ue004 0 :  (29.16)  \nIn line  (29.14),  c T x is the inner product of two n-vectors.  In inequality  (29.15),  Ax  \nis the m-vector  that  is the  product  of an m \ue005 n matrix and an n-vector,  and  in in-  \nequality  (29.16),  x \ue004 0 means that each entry of the vector x must be nonnegative. \nWe call this representation the standard  form  for a linear program, and we adopt \nthe convention that A, b, and c always have the dimensions given above. \nThe standard form above may not naturally correspon d to real-life  situations  you  \nare trying to model. For example, you might have eq uality constraints or variables \nthat  can  take  on  negative  values.  Exercises  29.1-6  and  29.1-7  ask  you  to show  how  \nto convert any linear program into this standard fo rm. \nWe now introduce terminology to describe solutions to linear programs. We \ndenote a particular setting of the values in a vari able, say x , by putting a bar over \nthe variable name: N x. If N x satis\u00fbes  all  the  constraints,  then  it is a feasible  solution , \nbut if it fails to satisfy at least one constraint,  then it is an infeasible  solution . We \nsay that a solution N x has objective  value  c T N x. A feasible solution N x whose objective \nvalue is maximum over all feasible solutions is an optimal  solution , and we call \nits objective value c T N x the optimal  objective  value . If a linear program has no \nfeasible solutions, we say that the linear program is infeasible , and otherwise, it \nis feasible . The set of points that satisfy all the constraint s is the feasible  region . \nIf a linear program has some feasible solutions but  does not have  a \u00fbnite  optimal  \nobjective value, then the feasible region is unbounded  and so is the linear program. \nExercise  29.1-5  asks  you  to show  that  a linear  program  can  have  a \u00fbnite  optimal  \nobjective value even if the feasible region is unbo unded. 29.1  Linear  programming  formulations  and  algorithms  855  \nOne  of the  reasons  for  the  power  and  popularity  of linear  programming is that \nlinear  programs  can,  in general,  be solved  ef\u00fbciently.  Ther e are two classes of \nalgorithms,  known  as ellipsoid  algorithms  and  interior-po int algorithms, that solve \nlinear programs in polynomial time. In addition, th e simplex algorithm is widely \nused. Although it does not run in polynomial time i n the worst case, it tends to \nperform well in practice. \nWe will not give a detailed algorithm for linear pr ogramming, but will discuss a \nfew important ideas. First, we will give an example  of using a geometric procedure \nto solve  a two-variable  linear  program.  Although  this  example  does  not  immedi-  \nately  generalize  to an ef\u00fbcient  algorithm  for  larger  proble ms, it introduces some \nimportant concepts for linear programming and for o ptimization in general. \nA two-variable  linear  program  \nLet  us \u00fbrst  consider  the  following  linear  program  with  two  variables: \nmaximize x 1 C x 2 (29.17)  \nsubject to \n4x  1 \ue003 x 2 \u0dc4 8 (29.18)  \n2x  1 C x 2 \u0dc4 10  (29.19)  \n5x  1 \ue003 2x  2 \ue004 \ue0032 (29.20) \nx 1 ;x  2 \ue004 0 :  (29.21)  \nFigure 29.2(a) graphs the constraints in the .x 1 ;x  2 /-Cartesian  coordinate  system.  \nThe  feasible  region  in the  two-dimensional  space  (highlighted  in blue  in the  \u00fbg-  \nure) is convex. 1 Conceptually, you could evaluate the objective func tion x 1 C x 2 at \neach point in the feasible region, and then identif y a point that has the maximum \nobjective value as an optimal solution. For this ex ample (and for  most  linear  pro-  \ngrams),  however,  the  feasible  region  contains  an in\u00fbnite  number of points, and so \nto solve  this  linear  program,  you  need  an ef\u00fbcient  way  to \u00fbnd  a point that achieves \nthe maximum objective value without explicitly eval uating the objective function \nat every point in the feasible region. \nIn two dimensions, you can optimize via a graphical  procedure. The set of points \nfor which x 1 C x 2 D \u00b4, for any \u00b4, is a line with a slope of \ue0031. Plotting x 1 C x 2 D 0 \nproduces the line with slope \ue0031 through the origin, as in Figure 29.2(b). The \nintersection of this line and the feasible region i s the set of feasible solutions that \nhave an objective value of 0. In this case, that intersection of the line with the \nfeasible region is the single point .0;0/ . More generally, for any value \u00b4, the \n1 An  intuitive  de\u00fbnition  of a convex  region  is that  it ful\u00fblls  the requirement that for any two points \nin the region, all points on a line segment between  them are also in the region. 856 Chapter 29 Linear Programming \nx 1 + x 2 = 0 4x 1 \u2013 x 2 f 8 \n2x 1 + x 2 f 10\n x 2 \nx 1 x 2 g 0 x 1 g 0 5x 1 \u2013 2x 2 g \u20132 \n(a) x 2 \nx 1 \n(b) x 1 + x 2 = 4 x 1 + x 2 = 8 \nFigure  29.2  (a)  The  linear  program  given  in (29.18)3(29.21).  Each  constrai nt is represented by a \nline and a direction. The intersection of the const raints, which is the feasible region, is highlighte d \nin blue. (b)  The red lines show, respectively, the points for wh ich the objective value is 0, 4, and 8. \nThe optimal solution to the linear program is x 1 D 2 and x 2 D 6 with objective value 8. \nintersection of the line x 1 C x 2 D \u00b4 and the feasible region is the set of feasible \nsolutions that have objective value \u00b4. Figure 29.2(b) shows the lines x 1 C x 2 D 0, \nx 1 C x 2 D 4, and x 1 C x 2 D 8. Because the feasible region in Figure 29.2 is \nbounded, there must be some maximum value \u00b4 for which the intersection of the \nline x 1 C x 2 D \u00b4 and the feasible region is nonempty. Any point in t he feasible \nregion that maximizes x 1 C x 2 is an optimal solution to the linear program, which  \nin this case is the vertex of the feasible region a t x 1 D 2 and x 2 D 6, with objective \nvalue 8. \nIt is no accident that an optimal solution to the l inear program occurs at a vertex \nof the feasible region. The maximum value of \u00b4 for which the line x 1 C x 2 D \u00b4 \nintersects the feasible region must be on the bound ary of the feasible region, and \nthus the intersection of this line with the boundar y of the feasible region is either a \nsingle vertex or a line segment. If the intersectio n is a single vertex, then there is \njust one optimal solution, and it is that vertex. I f the intersection is a line segment, \nevery point on that line segment must have the same  objective value. In particular, \nboth endpoints of the line segment are optimal solu tions. Since each endpoint of a \nline segment is a vertex, there is an optimal solut ion at a vertex in this case as well. \nAlthough you cannot easily graph linear programs wi th more than two variables, \nthe same intuition holds. If you have three variabl es, then each  constraint  corre-  \nsponds  to a half-space  in three-dimensional  space.  The  intersection  of these  half-  29.1  Linear  programming  formulations  and  algorithms  857  \nspaces forms the feasible region. The set of points  for which the objective function \nobtains a given value \u00b4 is now a plane (assuming no degenerate conditions).  If all \ncoef\u00fbcients  of the  objective  function  are  nonnegative,  and  if the origin is a feasible \nsolution to the linear program, then as you move th is plane away from the origin, in \na direction  normal  to the  objective  function,  you  \u00fbnd  points  of increasing objective \nvalue.  (If  the  origin  is not  feasible  or if some  coef\u00fbcients  in the objective function \nare negative, the intuitive picture becomes slightl y more complicated.) As in two \ndimensions, because the feasible region is convex, the set of points that achieve \nthe optimal objective value must include a vertex o f the feasible  region.  Simi-  \nlarly, if you have n variables,  each  constraint  de\u00fbnes  a half-space  in n-dimensional  \nspace. We call the feasible region formed by the in tersection of these  half-spaces  \na simplex . The objective function is now a hyperplane and, b ecause of convexity, \nan optimal solution still occurs at a vertex of the  simplex. Any algorithm for linear \nprogramming must also identify linear programs that  have no solutions, as well as \nlinear  programs  that  have  no  \u00fbnite  optimal  solution.  \nThe simplex  algorithm  takes as input a linear program and returns an opti mal \nsolution. It starts at some vertex of the simplex a nd performs a sequence  of itera-  \ntions. In each iteration, it moves along an edge of  the simplex from a current vertex \nto a neighboring vertex whose objective value is no  smaller than that of the current \nvertex (and usually is larger.) The simplex algorit hm terminates when it reaches \na local maximum, which is a vertex from which all n eighboring vertices have a \nsmaller objective value. Because the feasible regio n is convex and the objective \nfunction is linear, this local optimum is actually a global optimum.  In Section  29.3,  \nwe\u2019ll  see  an important  concept  called  <duality,=  which  we\u2019ll use to prove that the \nsolution returned by the simplex algorithm is indee d optimal. \nThe simplex algorithm, when implemented carefully, often solves  general  lin-  \near programs quickly in practice. With some careful ly contrived inputs, however, \nthe  simplex  algorithm  can  require  exponential  time.  The  \u00fbrst  polynomial-time  al-  \ngorithm for linear programming was the ellipsoid  algorithm , which runs slowly \nin practice.  A second  class  of polynomial-time  algorithms  are known as interior-  \npoint  methods . In contrast to the simplex algorithm, which moves  along the exte-  \nrior of the feasible region and maintains a feasibl e solution that is a vertex of the \nsimplex at each iteration, these algorithms move th rough the interior of the feasible \nregion. The intermediate solutions, while feasible,  are not necessarily vertices of \nthe  simplex,  but  the  \u00fbnal  solution  is a vertex.  For  large  inputs,  interior-point  algo-  \nrithms can run as fast as, and sometimes faster tha n, the simplex algorithm. The \nchapter notes point you to more information about t hese algorithms. \nIf you add to a linear program the additional requi rement that all variables \ntake on integer values, you have an integer  linear  program. Exercise  34.5-3  on  \npage  1098  asks  you  to show  that  just  \u00fbnding  a feasible  solutio n to this problem is \nNP-hard.  Since  no  polynomial-time  algorithms  are  known  for  any  NP-hard  prob-  858 Chapter 29 Linear Programming \nlems,  there  is no  known  polynomial-time  algorithm  for  integ er linear programming. \nIn contrast,  a general  linear-programming  problem  can  be solved in polynomial \ntime. \nExercises  \n29.1-1  \nConsider the linear program \nminimize \ue0032x  1 C 3x  2 \nsubject to \nx 1 C x 2 D 7 \nx 1 \ue003 2x  2 \u0dc4 4 \nx 1 \ue004 0 :  \nGive  three  feasible  solutions  to this  linear  program.  What  is the objective value of \neach  one?  \n29.1-2  \nConsider the following linear program, which has a nonpositivity constraint: \nminimize 2x  1 C 7x  2 C x 3 \nsubject to \nx 1 \ue003 x 3 D 7 \n3x  1 C x 2 \ue004 24  \nx 2 \ue004 0 \nx 3 \u0dc4 0 :  \nGive  three  feasible  solutions  to this  linear  program.  What  is the objective value of \neach  one?  \n29.1-3  \nShow that the following linear program is infeasibl e: \nmaximize 3x  1 \ue003 2x  2 \nsubject to \nx 1 C x 2 \u0dc4 2 \n\ue0032x  1 \ue003 2x  2 \u0dc4 \ue00310  \nx 1 ;x  2 \ue004 0 :  29.1  Linear  programming  formulations  and  algorithms  859  \n29.1-4  \nShow that the following linear program is unbounded : \nmaximize x 1 \ue003 x 2 \nsubject to \n\ue0032x  1 C x 2 \u0dc4 \ue0031 \n\ue003x 1 \ue003 2x  2 \u0dc4 \ue0032 \nx 1 ;x  2 \ue004 0 :  \n29.1-5  \nGive  an example  of a linear  program  for  which  the  feasible  region is not bounded, \nbut  the  optimal  objective  value  is \u00fbnite.  \n29.1-6  \nSometimes, in a linear program, you need to convert  constraints from one form to \nanother. \na. Show how to convert an equality constraint into an equivalent set of inequalities. \nThat is, given a constraint P  n \nj D1 a ij x j D b i , give a set of inequalities that will \nbe satis\u00fbed  if and  only  if P  n \nj D1 a ij x j D b i , \nb. Show how to convert an inequality constraint P  n \nj D1 a ij x j \u0dc4 b i into  an equal-  \nity constraint and a nonnegativity constraint. You will need to introduce an \nadditional variable s , and use the constraint that s \ue004 0. \n29.1-7  \nExplain how to convert a minimization linear progra m to an equivalent  maximiza-  \ntion linear program, and argue that your new linear  program is equivalent to the \noriginal one. \n29.1-8  \nIn the political problem at the beginning of this c hapter, there are feasible solutions \nthat correspond to winning more voters than there a ctually are in the district. For \nexample, you can set x 2 to 200, x 3 to 200, and x 1 D x 4 D 0. That solution \nis feasible,  yet  it seems  to say  that  you  will  win  400,000  subu rban voters, even \nthough there are only 200,000 actual suburban voter s. What constraints can you \nadd to the linear program to ensure that you never seem to win more voters than \nthere  actually  are?  Even  if you  don\u2019t  add  these  constraints,  argue that the optimal \nsolution to this linear program can never win more voters than there actually are in \nthe district. 860 Chapter 29 Linear Programming \n29.2  Formulating  problems  as linear  programs  \nLinear programming has many applications. Any textb ook on operations research \nis \u00fblled  with  examples  of linear  programming,  and  linear  programming has become \na standard tool taught to students in most business  schools. The election scenario \nis one typical example. Here are two more examples:  \n\ue001 An  airline  wishes  to schedule  its  \u00fcight  crews.  The  Federal  Aviation  Adminis-  \ntration imposes several constraints, such as limiti ng the number of consecutive \nhours that each crew member can work and insisting that a particular crew work \nonly on one model of aircraft during each month. Th e airline wants to schedule \ncrews  on  all  of its  \u00fcights  using  as few  crew  members  as possibl e. \n\ue001 An oil company wants to decide where to drill for o il. Siting a drill  at a particu-  \nlar location has an associated cost and, based on g eological surveys, an expected \npayoff of some number of barrels of oil. The compan y has a limited budget for \nlocating new drills and wants to maximize the amoun t of oil it expects  to \u00fbnd,  \ngiven this budget. \nLinear programs also model and solve graph and comb inatorial problems, such \nas those appearing in this book. We have already se en a special case of linear \nprogramming used to solve systems of difference con straints in Section  22.4.  In \nthis  section,  we\u2019ll  study  how  to formulate  several  graph  and  network-\u00fcow  problems  \nas linear  programs.  Section  35.4  uses  linear  programming  as a tool  to \u00fbnd  an \napproximate solution to another graph problem. \nPerhaps the most important aspect of linear program ming is to be able  to rec-  \nognize  when  you  can  formulate  a problem  as a linear  program.  Once you cast a \nproblem  as a polynomial-sized  linear  program,  you  can  solve  it in polynomial time \nby  the  ellipsoid  algorithm  or interior-point  methods.  Several  linear-programming  \nsoftware  packages  can  solve  problems  ef\u00fbciently,  so that  once the problem is in the \nform of a linear program, such a package can solve it. \nWe\u2019ll  look  at several  concrete  examples  of linear-programm ing problems. We \nstart with two problems that we have already studie d: the single-source  shortest-  \npaths  problem  from  Chapter  22  and  the  maximum-\u00fcow  problem  from  Chapter  24.  \nWe  then  describe  the  minimum-cost-\u00fcow  problem.  (Although  the  minimum-cost-  \n\u00fcow  problem  has  a polynomial-time  algorithm  that  is not  based  on  linear  program-  \nming,  we  won\u2019t  describe  the  algorithm.)  Finally,  we  describe  the  multicommodity-  \n\u00fcow  problem,  for  which  the  only  known  polynomial-time  algor ithm is based on \nlinear programming. \nWhen we solved graph problems in Part VI, we used a ttribute notation, such as \nv: d and .u;v/:  f . Linear programs typically use subscripted variabl es rather than 29.2  Formulating  problems  as linear  programs  861 \nobjects with attached attributes, however. Therefor e, when we express variables in \nlinear programs, we indicate vertices and edges thr ough subscripts. For example, \nwe  denote  the  shortest-path  weight  for  vertex  v not by v: d but by d v , and we denote \nthe  \u00fcow  from  vertex  u to vertex v not by .u;v/:  f but by f uv  . For quantities that \nare given as inputs to problems, such as edge weigh ts or capacities, we continue to \nuse notations such as w.u;v/  and c.u;v/ . \nShortest  paths  \nWe  can  formulate  the  single-source  shortest-paths  problem  as a linear program. \nWe\u2019ll  focus  on  how  to formulate  the  single-pair  shortest-pa th problem, leaving \nthe  extension  to the  more  general  single-source  shortest-paths  problem  as Exer-  \ncise  29.2-2.  \nIn the  single-pair  shortest-path  problem,  the  input  is a weighted, directed graph \nG D .V;E/ , with weight function w W E !  R mapping  edges  to real-valued  \nweights, a source vertex s , and destination vertex t . The goal is to compute the \nvalue d t , which is the weight of a shortest path from s to t . To  express  this  prob-  \nlem as a linear program, you need to determine a se t of variables and constraints \nthat  de\u00fbne  when  you  have  a shortest  path  from  s to t . The triangle inequality \n(Lemma  22.10  on  page  633)  gives  d v \u0dc4 d u C w.u;v/  for each edge .u;v/  2 E. \nThe source vertex initially receives a value d s D 0, which never changes. Thus the \nfollowing  linear  program  expresses  the  shortest-path  weig ht from s to t : \nmaximize d t (29.22) \nsubject to \nd v \u0dc4 d u C w.u;v/  for each edge .u;v/  2 E (29.23)  \nd s D 0 :  (29.24)  \nYou might be surprised that this linear program max imizes an objective function \nwhen it is supposed to compute shortest paths. Mini mizing the objective function \nwould be a mistake, because when all the edge weigh ts are nonnegative, setting \nN d v D 0 for all v 2 V (recall  that  a bar  over  a variable  name  denotes  a speci\u00fbc  \nsetting  of the  variable\u2019s  value)  would  yield  an optimal  solution  to the  linear  pro-  \ngram  without  solving  the  shortest-paths  problem.  Maximizi ng is the right thing \nto do  because  an optimal  solution  to the  shortest-paths  problem sets each N d v to \nmin \u02da N d u C w.u;v/  W u 2 V and .u;v/  2 E \ue009 \n, so that N d v is the largest value that is \nless than or equal to all of the values in the set \u02da N d u C w.u;v/  \ue009 . Therefore, it makes \nsense to maximize d v for all vertices v on a shortest path from s to t subject to these \nconstraints, and maximizing d t achieves this goal. \nThis linear program has jV j variables d v , one for each vertex v 2 V . It also \nhas jEj C  1 constraints: one for each edge, plus the additional  constraint that the \nsource  vertex\u2019s  shortest-path  weight  always  has  the  value  0. 862 Chapter 29 Linear Programming \nMaximum  \u00fcow  \nNext,  let\u2019s  express  the  maximum-\u00fcow  problem  as a linear  program. Recall that \nthe input is a directed graph G D .V;E/  in which each edge .u;v/  2 E has a \nnonnegative capacity c.u;v/  \ue004 0, and two distinguished vertices: a source s and \na sink t . As  de\u00fbned  in Section  24.1,  a \u00fcow  is a nonnegative  real-value d function \nf W V \ue005 V !  R that  satis\u00fbes  the  capacity  constraint  and  \u00fcow  conservation . A \nmaximum  \u00fcow  is a \u00fcow  that  satis\u00fbes  these  constraints  and  maximizes  the  \u00fcow  \nvalue,  which  is the  total  \u00fcow  coming  out  of the  source  minus  the  total  \u00fcow  into  the  \nsource.  A \u00fcow,  therefore,  satis\u00fbes  linear  constraints,  and  the  value  of a \u00fcow  is a \nlinear function. Recalling also that we assume that  c.u;v/  D 0 if .u;v/  \u2026 E and \nthat  there  are  no  antiparallel  edges,  the  maximum-\u00fcow  probl em can be expressed \nas a linear program: \nmaximize X  \nv2V f sv  \ue003 X  \nv2V f vs  (29.25)  \nsubject to \nf uv  \u0dc4 c.u;v/  for each u;v  2 V (29.26)  X  \nv2V f vu  D X  \nv2V f uv  for each u 2 V \ue003 fs;t  g (29.27)  \nf uv  \ue004 0 for each u;v  2 V :  (29.28)  \nThis linear program has jV j 2 variables,  corresponding  to the  \u00fcow  between  each  \npair of vertices, and it has 2 jV j 2 C jV j \ue003  2 constraints. \nIt is usually  more  ef\u00fbcient  to solve  a smaller-sized  linear  program. The linear \nprogram  in (29.25)3(29.28)  has,  for  ease  of notation,  a \u00fcow  and capacity of 0 for \neach pair of vertices u;v  with .u;v/  \u2026 E. It is more  ef\u00fbcient  to rewrite  the  linear  \nprogram so that it has O.V  C E/  constraints.  Exercise  29.2-4  asks  you  to do  so.  \nMinimum-cost  \u00fcow  \nIn this section, we have used linear programming to  solve problems for which we \nalready  knew  ef\u00fbcient  algorithms.  In fact,  an ef\u00fbcient  algorithm  designed  specif-  \nically  for  a problem,  such  as Dijkstra\u2019s  algorithm  for  the  single-source  shortest-  \npaths  problem,  will  often  be more  ef\u00fbcient  than  linear  progr amming, both in theory \nand in practice. \nThe real power of linear programming comes from the  ability to solve  new  prob-  \nlems. Recall the problem faced by the politician in  the beginning of this chapter. \nThe  problem  of obtaining  a suf\u00fbcient  number  of votes,  while  not spending too \nmuch money, is not solved by any of the algorithms that we have studied in this \nbook, yet it can be solved by linear programming. B ooks abound with  such  real-  \nworld problems that linear programming can solve. L inear programming is also 29.2  Formulating  problems  as linear  programs  863 \ns x \nt \ny \n(a) c = 1 \na = 3 c = 5 \na = 2 \nc = 4 \na = 1 c = 2 a = 7 \nc = 2 a = 5 s x \nt \ny \n(b) 1/1  \na = 3 2/5 \na = 2 \n3/4 \na = 1 1/2 a = 7 \n2/2 \na = 5 \nFigure  29.3  (a)  An  example  of a minimum-cost-\u00fcow  problem.  Capacities  are  denoted by c and \ncosts by a. Vertex s is the source, and vertex t is the sink. The goal is to send 4 units  of \u00fcow  from  s \nto t . (b)  A solution  to the  minimum-cost  \u00fcow  problem  in which  4 units  of \u00fcow  are  sent  from  s to t . \nFor  each  edge,  the  \u00fcow  and  capacity  are  written  as \u00fcow/capaci ty. \nparticularly useful for solving variants of problem s for which we may not already \nknow  of an ef\u00fbcient  algorithm.  \nConsider, for example, the following generalization  of the maximum-\u00fcow  prob-  \nlem. Suppose that, in addition to a capacity c.u;v/  for each edge .u;v/ , you are \ngiven  a real-valued  cost  a.u;v/. As  in the  maximum-\u00fcow  problem,  assume  that  \nc.u;v/  D 0 if .u;v/  \u2026 E and that there are no antiparallel edges. If you se nd f uv  \nunits  of \u00fcow  over  edge  .u;v/ , you incur a cost of a.u;v/  \ue001 f uv  . You are also given \na \u00fcow  demand  d . You wish to send d units  of \u00fcow  from  s to t while minimizing \nthe total cost P  \n.u;v/2E a.u;v/  \ue001 f uv  incurred  by  the  \u00fcow.  This  problem  is known  \nas the minimum-cost-\u00fcow  problem . \nFigure  29.3(a)  shows  an example  of the  minimum-cost-\u00fcow  problem, with a goal \nof sending 4 units  of \u00fcow  from  s to t while incurring the minimum total cost. Any \nparticular  legal  \u00fcow,  that  is, a function  f satisfying  constraints  (29.26)3(29.28),  \nincurs a total cost of P  \n.u;v/2E a.u;v/  \ue001 f uv  . What is the particular 4-unit  \u00fcow  \nthat  minimizes  this  cost?  Figure  29.3(b)  shows  an optimal  solution, with total cost P  \n.u;v/2E a.u;v/  \ue001 f uv  D .2 \ue001 2/ C .5 \ue001 2/ C .3 \ue001 1/ C .7 \ue001 1/ C .1 \ue001 3/ D 27:  \nThere  are  polynomial-time  algorithms  speci\u00fbcally  designed  for  the  minimum-  \ncost-\u00fcow  problem,  but  they  are  beyond  the  scope  of this  book.  The  minimum-cost-  \n\u00fcow  problem  can  be expressed  as a linear  program,  however.  The linear program \nlooks  similar  to the  one  for  the  maximum-\u00fcow  problem  with  the  additional  con-  \nstraint  that  the  value  of the  \u00fcow  must  be exactly  d units, and with the new objective \nfunction of minimizing the cost: 864 Chapter 29 Linear Programming \nminimize X  \n.u;v/2E a.u;v/  \ue001 f uv  (29.29) \nsubject to \nf uv  \u0dc4 c.u;v/  for each u;v  2 V X  \nv2V f vu  \ue003 X  \nv2V f uv  D 0 for each u 2 V \ue003 fs;t  g \nX  \nv2V f sv  \ue003 X  \nv2V f vs  D d \nf uv  \ue004 0 for each u;v  2 V :  (29.30)  \nMulticommodity  \u00fcow  \nAs  a \u00fbnal  example,  let\u2019s  consider  another  \u00fcow  problem.  Suppo se that the Lucky \nPuck  company  from  Section  24.1  decides  to diversify  its  product line and ship \nnot only hockey pucks, but also hockey sticks and h ockey helmets. Each piece of \nequipment is manufactured in its own factory, has i ts own warehouse, and must \nbe shipped, each day, from factory to warehouse. Th e sticks are manufactured \nin Vancouver and are needed in Saskatoon, and the h elmets are manufactured in \nEdmonton and must be shipped to Regina. The capacit y of the shipping network \ndoes not change, however, and the different items, or commodities , must share the \nsame network. \nThis example is an instance of a multicommodity-\u00fcow  problem . The input to this \nproblem is once again a directed graph G D .V;E/  in which each edge .u;v/  2 E \nhas a nonnegative capacity c.u;v/  \ue004 0. As  in the  maximum-\u00fcow  problem,  implic-  \nitly assume that c.u;v/  D 0 for .u;v/  \u2026 E and that the graph has no antiparallel \nedges. In addition, there are k different commodities, K 1 ;K  2 ;:::;K  k , with  com-  \nmodity i speci\u00fbed  by  the  triple  K i D .s i ;t i ;d  i /. Here, vertex s i is the source of \ncommodity i , vertex t i is the sink of commodity i , and d i is the  demand  for  com-  \nmodity i , which  is the  desired  \u00fcow  value  for  the  commodity  from  s i to t i . We \nde\u00fbne  a \u00fcow  for  commodity  i , denoted by f i , (so that f iuv  is the  \u00fcow  of com-  \nmodity i from vertex u to vertex v) to be a real-valued  function  that  satis\u00fbes  the  \n\u00fcow-conservation  and  capacity  constraints.  We  de\u00fbne  f uv  , the aggregate  \u00fcow, to \nbe the  sum  of the  various  commodity  \u00fcows,  so that  f uv  D P  k \ni D1 f iuv  . The  aggre-  \ngate  \u00fcow  on  edge  .u;v/  must be no more than the capacity of edge .u;v/ . This \nproblem has no objective function: the question is to determine  whether  such  a \u00fcow  \nexists. Thus the linear program for this problem ha s a <null= objective function: 29.2  Formulating  problems  as linear  programs  865 \nminimize 0 \nsubject to \nk X  \ni D1 f iuv  \u0dc4 c.u;v/  for each u;v  2 V \nX  \nv2V f iuv  \ue003 X  \nv2V f ivu  D 0 for each i D 1;2;:::;k  and \nfor each u 2 V \ue003 fs i ;t i g \nX  \nv2V f i;s  i ;v \ue003 X  \nv2V f i;v;s  i D d i for each i D 1;2;:::;k  \nf iuv  \ue004 0 for each u;v  2 V and \nfor each i D 1;2;:::;k :  \nThe  only  known  polynomial-time  algorithm  for  this  problem  expresses it as a linear \nprogram  and  then  solves  it with  a polynomial-time  linear-pr ogramming algorithm. \nExercises  \n29.2-1  \nWrite  out  explicitly  the  linear  program  corresponding  to \u00fbnding the shortest path \nfrom vertex s to vertex x in Figure  22.2(a)  on  page  609.  \n29.2-2  \nGiven  a graph  G, write  a linear  program  for  the  single-source  shortest-paths  prob-  \nlem. The solution should have the property that d v is the  shortest-path  weight  from  \nthe source vertex s to v for each vertex v 2 V . \n29.2-3  \nWrite  out  explicitly  the  linear  program  corresponding  to \u00fbnding  the  maximum  \u00fcow  \nin Figure  24.1(a).  \n29.2-4  \nRewrite  the  linear  program  for  maximum  \u00fcow  (29.25)3(29.28)  so that it uses only \nO.V  C E/  constraints. \n29.2-5  \nWrite a linear program that, given a bipartite grap h G D .V;E/, solves  the  maxi-  \nmum-bipartite-matching  problem.  \n29.2-6  \nThere can be more than one way to model a particula r problem as a linear program. \nThis exercise gives an alternative formulation for the maximum-\u00fcow  problem.  Let  \nP D fP 1 ;P  2 ;:::;P  p g be the set of all possible directed simple paths from source s 866 Chapter 29 Linear Programming \nto sink t . Using decision variables x 1 ;:::;x  p , where x i is the  amount  of \u00fcow  on  \npath i , formulate  a linear  program  for  the  maximum-\u00fcow  problem.  What is an \nupper bound on p, the number of directed simple paths from s to t ? \n29.2-7  \nIn the minimum-cost  multicommodity-\u00fcow  problem , the input is a directed graph \nG D .V;E/  in which each edge .u;v/  2 E has a nonnegative capacity c.u;v/  \ue004 0 \nand a cost a.u;v/. As  in the  multicommodity-\u00fcow  problem,  there  are  k dif-  \nferent commodities, K 1 ;K  2 ;:::;K  k , with commodity i speci\u00fbed  by  the  triple  \nK i D .s i ;t i ;d  i /. We  de\u00fbne  the  \u00fcow  f i for commodity i and  the  aggregate  \u00fcow  f uv  \non edge .u;v/  as in the  multicommodity-\u00fcow  problem.  A feasible  \u00fcow  is one  \nin which  the  aggregate  \u00fcow  on  each  edge  .u;v/  is no more than the capacity of \nedge .u;v/. The  cost  of a \u00fcow  is P  \nu;v2V a.u;v/  \ue001 f uv  , and  the  goal  is to \u00fbnd  the  \nfeasible  \u00fcow  of minimum  cost.  Express  this  problem  as a linea r program. \n29.3  Duality  \nWe will now introduce a powerful concept called linear-programming  duality . In \ngeneral, given a maximization problem, duality allo ws you to formulate a related \nminimization problem that has the same objective va lue. The idea of duality is \nactually more general than linear programming, but we restrict our attention to \nlinear programming in this section. \nDuality enables us to prove that a solution is inde ed optimal. We  saw  an exam-  \nple  of duality  in Chapter  24  with  Theorem  24.6,  the  max-\u00fcow  min-cut  theorem.  \nSuppose  that,  given  an instance  of a maximum-\u00fcow  problem,  you  \u00fbnd  a \u00fcow  f \nwith value jf j. How do you know whether f is a maximum  \u00fcow?  By  the  max-  \n\u00fcow  min-cut  theorem,  if you  can  \u00fbnd  a cut  whose  value  is also  jf j, then you have \nveri\u00fbed  that  f is indeed  a maximum  \u00fcow.  This  relationship  provides  an examp le \nof duality:  given  a maximization  problem,  de\u00fbne  a related  minimization problem \nsuch that the two problems have the same optimal ob jective values. \nGiven  a linear  program  in standard  form  in which  the  objectiv e is to maximize, \nlet\u2019s  see  how  to formulate  a dual  linear  program  in which  the  objective  is to min-  \nimize and whose optimal value is identical to that of the original linear program. \nWhen referring to dual linear programs, we call the  original linear program the \nprimal . \nGiven  the  primal  linear  program  29.3  Duality  867 \nmaximize n X  \nj D1 c j x j (29.31)  \nsubject to \nn X  \nj D1 a ij x j \u0dc4 b i for i D 1;2;:::;m  (29.32)  \nx j \ue004 0 for j D 1;2;:::;n ;  (29.33)  \nits dual is \nminimize m X  \ni D1 b i y i (29.34)  \nsubject to \nm X  \ni D1 a ij y i \ue004 c j for j D 1;2;:::;n  (29.35)  \ny i \ue004 0 for i D 1;2;:::;m :  (29.36)  \nMechanically, to form the dual, change the maximiza tion to a minimization, \nexchange  the  roles  of coef\u00fbcients  on  the  right-hand  sides  and  in the  objective  func-  \ntion, and replace each \u0dc4 by \ue004. Each of the m constraints in the primal corresponds \nto a variable y i in the dual. Likewise, each of the n constraints  in the  dual  corre-  \nsponds to a variable x j in the primal. For example, consider the following primal \nlinear program: \nmaximize 3x  1 C x 2 C 4x  3 (29.37)  \nsubject to \nx 1 C x 2 C 3x  3 \u0dc4 30  (29.38)  \n2x  1 C 2x  2 C 5x  3 \u0dc4 24  (29.39)  \n4x  1 C x 2 C 2x  3 \u0dc4 36  (29.40)  \nx 1 ;x  2 ;x  3 \ue004 0 :  (29.41)  \nIts dual is \nminimize 30y  1 C 24y  2 C 36y  3 (29.42)  \nsubject to \ny 1 C 2y  2 C 4y  3 \ue004 3 (29.43)  \ny 1 C 2y  2 C y 3 \ue004 1 (29.44)  \n3y  1 C 5y  2 C 2y  3 \ue004 4 (29.45)  \ny 1 ;y  2 ;y  3 \ue004 0 :  (29.46)  \nAlthough forming the dual can be considered a mecha nical operation, there is an \nintuitive explanation. Consider the primal maximiza tion problem  (29.37)3(29.41).  \nEach constraint gives an upper bound on the objecti ve function. In addition, if you 868 Chapter 29 Linear Programming \ntake one or more constraints and add together nonne gative multiples of them, you \nget a valid constraint. For example, you can add co nstraints (29.38)  and  (29.39)  to \nobtain the constraint 3x  1 C 3x  2 C 8x  3 \u0dc4 54. Any feasible solution to the primal \nmust satisfy this new constraint, but there is some thing else interesting about it. \nComparing this new constraint to the objective func tion (29.37),  you  can  see  that  \nfor  each  variable,  the  corresponding  coef\u00fbcient  is at least  as large  as the  coef\u00fbcient  \nin the objective function. Thus, since the variable s x 1 , x 2 and x 3 are nonnegative, \nwe have that \n3x  1 C x 2 C 4x  3 \u0dc4 3x  1 C 3x  2 C 8x  3 \u0dc4 54;  \nand so the solution value to the primal is at most 54. In other words, adding these \ntwo constraints together has generated an upper bou nd on the objective value. \nIn general, for any nonnegative multipliers y 1 , y 2 , and y 3 , you can generate a \nconstraint \ny 1 .x 1 Cx 2 C3x  3 /Cy 2 .2x  1 C2x  2 C5x  3 /Cy 3 .4x  1 Cx 2 C2x  3 / \u0dc4 30y  1 C24y  2 C36y  3 \nfrom the primal constraints or, by distributing and  regrouping, \n.y 1 C2y  2 C4y  3 /x 1 C.y 1 C2y  2 Cy 3 /x 2 C.3y  1 C5y  2 C2y  3 /x 3 \u0dc4 30y  1 C24y  2 C36y  3 : \nNow,  as long  as this  constraint  has  coef\u00fbcients  of x 1 , x 2 , and x 3 that are at least \ntheir  objective-function  coef\u00fbcients,  it is a valid  upper  bound. That is, as long as \ny 1 C 2y  2 C 4y  3 \ue004 3;  \ny 1 C 2y  2 C y 3 \ue004 1;  \n3y  1 C 5y  2 C 2y  3 \ue004 4;  \nyou have a valid upper bound of 30y  1 C24y  2 C36y  3 . The multipliers y 1 , y 2 , and y 3 \nmust be nonnegative, because otherwise you cannot c ombine the inequalities.  Of  \ncourse, you would like the upper bound to be as sma ll as possible, and so you want \nto choose y to minimize 30y  1 C 24y  2 C 36y  3 . Observe  that  we  have  just  described  \nthe  dual  linear  program  as the  problem  of \u00fbnding  the  smallest  possible upper bound \non the primal. \nWe\u2019ll  formalize  this  idea  and  show  in Theorem  29.4  that,  if the linear program \nand its dual are feasible and bounded, then the opt imal value of the dual linear \nprogram is always equal to the optimal value of the  primal linear program. We \nbegin by demonstrating weak  duality , which states that any feasible solution to the \nprimal linear program has a value no greater than t hat of any feasible solution to \nthe dual linear program. \nLemma  29.1  (Weak  linear-programming  duality)  \nLet N x be any feasible solution to the primal linear progr am in (29.31)3(29.33),  and  \nlet N y be any  feasible  solution  to its  dual  linear  program  in (29.34)3(29.36).  Then  29.3  Duality  869 \nn X  \nj D1 c j N x j \u0dc4 m X  \ni D1 b i N y i : \nProof  We have \nn X  \nj D1 c j N x j \u0dc4 n X  \nj D1 \ue001 m X  \ni D1 a ij N y i ! \nN x j (by  inequalities  (29.35))  \nD m X  \ni D1 \ue001 n X  \nj D1 a ij N x j ! \nN y i \n\u0dc4 m X  \ni D1 b i N y i (by  inequalities  (29.32))  . \nCorollary  29.2  \nLet N x be a feasible  solution  to the  primal  linear  program  in (29.31)3(29.33),  and  let  \nN y be a feasible  solution  to its  dual  linear  program  in (29.34)3(29.36).  If \nn X  \nj D1 c j N x j D m X  \ni D1 b i N y i ; \nthen N x and N y are optimal solutions to the primal and dual linear  programs, respec-  \ntively. \nProof  By  Lemma  29.1,  the  objective  value  of a feasible  solution  to the primal \ncannot exceed that of a feasible solution to the du al. The primal linear program is \na maximization problem and the dual is a minimizati on problem. Thus, if feasible \nsolutions N x and N y have the same objective value, neither can be impro ved. \nWe now show that, at optimality, the primal and dua l objective values are indeed \nequal. To prove linear programming duality, we will  require one lemma from linear \nalgebra,  known  as Farkas\u2019s  lemma,  the  proof  of which  Problem  29-4  asks  you  to \nprovide.  Farkas\u2019s  lemma  can  take  several  forms,  each  of whic h is about when a \nset of linear equalities has a solution. In stating  the lemma, we use m C 1 as a \ndimension because it matches our use below. \nLemma  29.3  (Farkas\u2019s  lemma)  \nGiven  M  2 R .mC1/\ue005n and g 2 R mC1 , exactly one of the following statements is \ntrue: \n1. There  exists  v 2 R n such that Mv  \u0dc4 g, \n2. There exists w 2 R mC1 such that w \ue004 0;w  T M  D 0 (an n-vector  of all  zeros),  \nand w T g<0 . 870 Chapter 29 Linear Programming \nTheorem  29.4  (Linear-programming  duality)  \nGiven  the  primal  linear  program  in (29.31)3(29.33)  and  its  corresponding dual in \n(29.34)3(29.36),  if both  are  feasible  and  bounded,  then  for  optimal solutions x \ue003 \nand y \ue003 , we have c T x \ue003 D b T y \ue003 . \nProof  Let \ufffd D b T y \ue003 be the optimal value of the dual linear program giv en in \n(29.34)3(29.36).  Consider  an augmented  set  of primal  const raints in which we add \na constraint  to (29.31)3(29.33)  that  the  objective  value  is at least \ufffd. We write out \nthis augmented  primal  as \nAx  \u0dc4 b;  (29.47)  \nc T x \ue004 \ufffd :  (29.48)  \nWe  can  multiply  (29.48)  through  by  \ue0031 and  rewrite  (29.47)3(29.48)  as \n\u00cf A \n\ue003c T \u00d0 \nx \u0dc4 \u00cf b \n\ue003\ufffd \u00d0 \n: (29.49)  \nHere, \u00cf A \n\ue003c T \u00d0 \ndenotes an .mC1/\ue005n matrix, x is an n-vector,  and  \u00cf b \n\ue003\ufffd \u00d0 \ndenotes \nan .m  C 1/-vector.  \nWe claim that if there is a feasible solution N x to the augmented primal, then the \ntheorem is proved. To establish this claim, observe  that N x is also a feasible solution \nto the original primal and that it has objective va lue at least \ufffd. We can then apply \nLemma  29.1,  which  states  that  the  objective  value  of the  prim al is at most \ufffd, to \ncomplete the proof of the theorem. \nIt therefore remains to show that the augmented pri mal has a feasible solution. \nSuppose, for the purpose of contradiction, that the  augmented primal is infeasible, \nwhich means that there is no v 2 R n such that \u00cf A \n\ue003c T \u00d0 \nv \u0dc4 \u00cf b \n\ue003\ufffd \u00d0 \n. We can \napply  Farkas\u2019s  lemma,  Lemma  29.3,  to inequalty  (29.49)  with  \nM  D \u00cf A \n\ue003c T \u00d0 \nand g D \u00cf b \n\ue003\ufffd \u00d0 \n: \nBecause  the  augmented  primal  is infeasible,  condition  1 of Farkas\u2019s  lemma  does  \nnot hold. Therefore, condition 2 must apply, so tha t there must exist a w 2 R mC1 \nsuch that w \ue004 0, w T M  D 0, and w T g<0. Let\u2019s  write  w as w D \u00cf N y \n\ufffd \u00d0 \nfor some \nN y 2 R m and \ufffd 2 R, where N y \ue004 0 and \ufffd \ue004 0. Substituting for w, M  , and g in \ncondition 2 gives \n\u00cf N y \n\ufffd \u00d0 T \u00cf A \n\ue003c T \u00d0 \nD 0 and \u00cf N y \n\ufffd \u00d0 T \u00cf b \n\ue003\ufffd \u00d0 \n<0:  29.3  Duality  871 \nUnpacking the matrix notation gives \nN y T A \ue003 \ufffdc  T D 0 and N y T b \ue003 \ufffd\ufffd<0:  (29.50)  \nWe  now  show  that  the  requirements  in (29.50)  contradict  the  assumption that \ufffd is \nthe optimal solution value for the dual linear prog ram. We consider two cases. \nThe  \u00fbrst  case  is when  \ufffd D 0. In this  case,  (29.50)  simpli\u00fbes  to \nN y T A D 0 and N y T b<0:  (29.51)  \nWe\u2019ll  now  construct  a dual  feasible  solution  y 0 with an objective value smaller \nthan b T y \ue003 . Set y 0 D y \ue003 C \ufffd N y , for any \ufffd > 0 . Since \ny 0 T A D .y \ue003 C \ufffd N y/  T A \nD y \ue003T A C \ufffd N y T A \nD y \ue003T A (by  (29.51))  \n\ue004 c T (because y \ue003 is feasible) , \ny 0 is feasible. Now consider the objective value \nb T y 0 D b T .y \ue003 C \ufffd N y/  \nD b T y \ue003 C \ufffdb  T N y \n< b  T y \ue003 ; \nwhere the last inequality follows because \ufffd > 0  and,  by  (29.51),  N y T b D b T N y <0  \n(since both N y T b and b T N y are the inner product of b and N y ), and so their product \nis negative. Thus we have a feasible dual solution of value less than \ufffd, which \ncontradicts \ufffd being the optimal objective value. \nWe now consider the second case, where \ufffd > 0. In this  case,  we  can  take  (29.50)  \nand divide through by \ufffd to obtain \n. N y T =\ufffd/A  \ue003 .\ufffd=\ufffd/c  T D 0 and . N y T =\ufffd/b  \ue003 .\ufffd=\ufffd/\ufffd<0:  (29.52)  \nNow set y 0 D N  y=\ufffd  in (29.52),  giving  \ny 0 T A D c T and y 0 T b<\ufffd:  \nThus, y 0 is a feasible dual solution with objective value st rictly less than \ufffd, a \ncontradiction. We conclude that the augmented prima l has a feasible solution, and \nthe theorem is proved. \nFundamental  theorem  of linear  programming  \nWe conclude this chapter by stating the fundamental  theorem of linear  program-  \nming,  which  extends  Theorem  29.4  to the  cases  when  the  linear  program may be \neither  feasible  or unbounded.  Exercise  29.3-8  asks  you  to provide the proof. 872 Chapter 29 Linear Programming \nTheorem  29.5  (Fundamental  theorem  of linear  programming)  \nAny linear program, given in standard form, either \n1. has  an optimal  solution  with  a \u00fbnite  objective  value,  \n2. is infeasible, or \n3. is unbounded.  \nExercises  \n29.3-1  \nFormulate  the  dual  of the  linear  program  given  in lines  (29.6)3(29.10)  on  page  852.  \n29.3-2  \nYou have a linear program that is not in standard f orm. You could produce the dual \nby  \u00fbrst  converting  it to standard  form,  and  then  taking  the  dual. It would be more \nconvenient, however, to produce the dual directly. Explain how to directly take the \ndual of an arbitrary linear program. \n29.3-3  \nWrite  down  the  dual  of the  maximum-\u00fcow  linear  program,  as given in lines \n(29.25)3(29.28)  on  page  862.  Explain  how  to interpret  this  formulation as a \nminimum-cut  problem.  \n29.3-4  \nWrite  down  the  dual  of the  minimum-cost-\u00fcow  linear  program,  as given in lines \n(29.29)3(29.30)  on  page  864.  Explain  how  to interpret  this  problem in terms of \ngraphs  and  \u00fcows.  \n29.3-5  \nShow that the dual of the dual of a linear program is the primal linear program. \n29.3-6  \nWhich  result  from  Chapter  24  can  be interpreted  as weak  duality  for  the  maximum-  \n\u00fcow  problem?  \n29.3-7  \nConsider the following 1-variable  primal  linear  program:  \nmaximize tx \nsubject to \nrx  \u0dc4 s \nx \ue004 0 ;  Problems for Chapter 29 873 \nwhere r , s , and t are arbitrary real numbers. State for which values of r , s , and t \nyou can assert that \n1. Both  the  primal  linear  program  and  its  dual  have  optimal  solutions  with  \u00fbnite  \nobjective values. \n2. The primal is feasible, but the dual is infeasib le. \n3. The  dual  is feasible,  but  the  primal  is infeasible.  \n4. Neither  the  primal  nor  the  dual  is feasible.  \n29.3-8  \nProve the fundamental theorem of linear programming , Theorem  29.5.  \nProblems  \n29-1  Linear-inequality  feasibility  \nGiven  a set  of m linear inequalities on n variables x 1 ;x  2 ;:::;x  n , the linear-  \ninequality  feasibility  problem  asks whether there is a setting of the variables th at \nsimultaneously  satis\u00fbes  each  of the  inequalities.  \na. Given  an algorithm  for  the  linear-programming  problem,  show how to use it to \nsolve  a linear-inequality  feasibility  problem.  The  number  of variables  and  con-  \nstraints  that  you  use  in the  linear-programming  problem  should be polynomial \nin n and m. \nb. Given  an algorithm  for  the  linear-inequality  feasibility  problem, show how to \nuse  it to solve  a linear-programming  problem.  The  number  of variables  and  lin-  \near  inequalities  that  you  use  in the  linear-inequality  feasibility problem should \nbe polynomial in n and m, the number of variables and constraints in the li near \nprogram. \n29-2  Complementary  slackness  \nComplementary  slackness  describes a relationship between the values of prim al \nvariables and dual constraints and between the valu es of dual variables  and  pri-  \nmal constraints. Let N x be a feasible solution to the primal linear program  given \nin (29.31)3(29.33),  and  let  N y be a feasible solution to the dual linear program g iven \nin (29.34)3(29.36).  Complementary  slackness  states  that  the following conditions \nare  necessary  and  suf\u00fbcient  for  N x and N y to be optimal: 874 Chapter 29 Linear Programming \nm X  \ni D1 a ij N y i D c j or N x j D 0 for j D 1;2;:::;n  \nand \nn X  \nj D1 a ij N x j D b i or N y i D 0 for i D 1;2;:::;m:  \na. Verify that complementary slackness holds for the l inear program in lines \n(29.37)3(29.41).  \nb. Prove that complementary slackness holds for any pr imal linear program and \nits corresponding dual. \nc. Prove that a feasible solution N x to a primal linear program given in lines \n(29.31)3(29.33)  is optimal  if and  only  if there  exist  values  N y D . N y 1 ; N y 2 ;:::;  N y m / \nsuch that \n1. N y is a feasible solution to the dual linear program g iven in (29.34)3(29.36),  \n2. P  m \ni D1 a ij N y i D c j for all j such that N x j >0, and \n3. N y i D 0 for all i such that P  n \nj D1 a ij N x j <b  i . \n29-3  Integer  linear  programming  \nAn integer  linear-programming  problem  is a linear-programming  problem  with  \nthe additional constraint that the variables x must  take  on  integer  values.  Exer-  \ncise  34.5-3  on  page  1098  shows  that  just  determining  whether  an integer linear \nprogram  has  a feasible  solution  is NP-hard,  which  means  that  there is no known \npolynomial-time  algorithm  for  this  problem.  \na. Show  that  weak  duality  (Lemma  29.1)  holds  for  an integer  linear program. \nb. Show  that  duality  (Theorem  29.4)  does  not  always  hold  for  an integer linear \nprogram. \nc. Given  a primal  linear  program  in standard  form,  let  P be the optimal objective \nvalue for the primal linear program, D be the optimal objective value for its \ndual, IP be the optimal objective value for the integer vers ion of the primal \n(that is, the primal with the added constraint that  the variables take on integer \nvalues), and ID be the optimal objective value for the integer vers ion of the dual. \nAssuming that both the primal integer program and t he dual integer program are \nfeasible and bounded, show that \nIP \u0dc4 P D D \u0dc4 ID : Notes for Chapter 29 875 \n29-4  Farkas\u2019s  lemma  \nProve  Farkas\u2019s  lemma,  Lemma  29.3.  \n29-5  Minimum-cost  circulation  \nThis  problem  considers  a variant  of the  minimum-cost-\u00fcow  problem  from  Sec-  \ntion 29.2 in which there is no demand, source, or s ink. Instead, the  input,  as be-  \nfore,  contains  a \u00fcow  network,  capacity  constraints  c.u;v/ , and edge costs a.u;v/ . \nA \u00fcow  is feasible  if it satis\u00fbes  the  capacity  constraint  on  every  edge  and  \u00fcow  con-  \nservation at every  vertex.  The  goal  is to \u00fbnd,  among  all  feasible  \u00fcows,  the  one  of \nminimum cost. We call this problem the minimum-cost-circulation  problem.  \na. Formulate  the  minimum-cost-circulation  problem  as a linea r program. \nb. Suppose that for all edges .u;v/  2 E, we have a.u;v/  > 0. What does an \noptimal  solution  to the  minimum-cost-circulation  problem  look  like?  \nc. Formulate  the  maximum-\u00fcow  problem  as a minimum-cost-circu lation problem \nlinear  program.  That  is, given  a maximum-\u00fcow  problem  instan ce G D .V;E/  \nwith source s , sink t and edge capacities c , create  a minimum-cost-circulation  \nproblem by giving a (possibly different) network G 0 D .V  0 ;E  0 / with  edge  ca-  \npacities c 0 and edge costs a 0 such  that  you  can  derive  a solution  to the  maximum-  \n\u00fcow  problem  from  a solution  to the  minimum-cost-circulatio n problem. \nd. Formulate  the  single-source  shortest-path  problem  as a minimum-cost-circu-  \nlation problem linear program. \nChapter  notes  \nThis  chapter  only  begins  to study  the  wide  \u00fbeld  of linear  programming.  A num-  \nber of books are devoted exclusively to linear prog ramming, including those by \nChv\u00b4  atal  [94],  Gass  [178],  Karloff  [246],  Schrijver  [398],  and  Vanderbei  [444].  \nMany other books give a good coverage of linear pro gramming, including those \nby  Papadimitriou  and  Steiglitz  [353]  and  Ahuja,  Magnanti,  and  Orlin  [7].  The  \ncoverage in this chapter draws on the approach take n by Chv\u00b4 atal. \nThe simplex algorithm for linear programming was in vented by G.  Dantzig  \nin 1947.  Shortly  after,  researchers  discovered  how  to formulate  a number  of prob-  \nlems  in a variety  of \u00fbelds  as linear  programs  and  solve  them  with the simplex \nalgorithm. As a result, applications of linear prog ramming \u00fcourished,  along  with  \nseveral algorithms. Variants of the simplex algorit hm remain the most popular 876 Chapter 29 Linear Programming \nmethods  for  solving  linear-programming  problems.  This  history  appears  in a num-  \nber  of places,  including  the  notes  in [94]  and  [246].  \nThe  ellipsoid  algorithm  was  the  \u00fbrst  polynomial-time  algorithm  for  linear  pro-  \ngramming  and  is due  to L. G.  Khachian  in 1979.  It was  based  on  earlier work by \nN.  Z. Shor,  D.  B. Judin,  and  A.  S. Nemirovskii.  Gr\u00a8  otschel,  Lov\u00b4 asz, and Schrijver \n[201]  describe  how  to use  the  ellipsoid  algorithm  to solve  a variety of problems in \ncombinatorial optimization. To date, the ellipsoid algorithm does not appear to be \ncompetitive with the simplex algorithm in practice.  \nKarmarkar\u2019s  paper  [247]  includes  a description  of the  \u00fbrst  interior-point  algo-  \nrithm.  Many  subsequent  researchers  designed  interior-point  algorithms.  Good  sur-  \nveys  appear  in the  article  of Goldfarb  and  Todd  [189]  and  the  book  by  Ye  [463].  \nAnalysis of the simplex algorithm remains an active  area of research.  V. Klee  \nand  G.  J. Minty  constructed  an example  on  which  the  simplex  algorithm runs \nthrough 2 n \ue003 1 iterations. The simplex algorithm usually performs well in practice, \nand  many  researchers  have  tried  to give  theoretical  justi\u00fbc ation for this empirical \nobservation.  A line  of research  begun  by  K.  H.  Borgwardt,  and  carried on by many \nothers, shows that under certain probabilistic assu mptions on  the  input,  the  sim-  \nplex algorithm converges in expected polynomial tim e. Spielman  and  Teng  [421]  \nmade progress in this area, introducing the <smooth ed analysis of algorithms= and \napplying it to the simplex algorithm. \nThe  simplex  algorithm  is known  to run  ef\u00fbciently  in certain  special  cases.  Par-  \nticularly  noteworthy  is the  network-simplex  algorithm,  which  is the  simplex  al-  \ngorithm,  specialized  to network-\u00fcow  problems.  For  certain  network problems, \nincluding  the  shortest-paths,  maximum-\u00fcow,  and  minimum-cost-\u00fcow  problems,  \nvariants  of the  network-simplex  algorithm  run  in polynomial  time.  See,  for  exam-  \nple,  the  article  by  Orlin  [349]  and  the  citations  therein.  30  Polynomials  and  the  FFT  \nThe straightforward method of adding two polynomial s of degree n takes \u201a.n/  \ntime, but the straightforward method of multiplying  them takes \u201a.n  2 / time. This \nchapter will show how the fast Fourier transform, o r FFT, can reduce the time to \nmultiply polynomials to \u201a.n  lg n/. \nThe most common use for Fourier transforms, and hen ce the FFT, is in signal \nprocessing. A signal is given in the time  domain : as a function mapping time \nto amplitude. Fourier analysis expresses the signal  as a weighted  sum  of phase-  \nshifted sinusoids of varying frequencies. The weigh ts and phases associated with \nthe frequencies characterize the signal in the frequency  domain . Among the many \neveryday  applications  of FFT\u2019s  are  compression  techniques  used to encode digital \nvideo  and  audio  information,  including  MP3  \u00fbles.  Many  \u00fbne  books delve into the \nrich area of signal processing, and the chapter not es reference a few of them. \nPolynomials  \nA polynomial  in the variable x over  an algebraic  \u00fbeld  F represents a function A.x/  \nas a formal sum: \nA.x/  D n\ue0021 X  \nj D0 a j x j : \nThe values a 0 ;a  1 ;:::;a  n\ue0021 are the coef\u00fbcients  of the  polynomial.  The  coef\u00fbcients  \nand x are  drawn  from  a \u00fbeld  F , typically the set C of complex  numbers.  A poly-  \nnomial A.x/  has degree  k if its  highest  nonzero  coef\u00fbcient  is a k , in which case we \nsay that degree .A/  D k. Any  integer  strictly  greater  than  the  degree  of a polyno-  \nmial is a degree-bound  of that polynomial. Therefore, the degree of a poly nomial \nof degree-bound  n may be any integer between 0 and n \ue003 1, inclusive. \nA variety of operations extend to polynomials. For polynomial  addition , if A.x/  \nand B.x/  are  polynomials  of degree-bound  n, their sum  is a polynomial C.x/ , also 878  Chapter  30  Polynomials  and  the  FFT  \nof degree-bound  n, such that C.x/  D A.x/  C B.x/  for all x in the  underlying  \u00fbeld.  \nThat is, if \nA.x/  D n\ue0021 X  \nj D0 a j x j and B.x/  D n\ue0021 X  \nj D0 b j x j ; \nthen \nC.x/  D n\ue0021 X  \nj D0 c j x j ; \nwhere c j D a j C b j for j D 0;1;:::;n  \ue003 1. For  example,  given  the  polyno-  \nmials A.x/  D 6x  3 C 7x  2 \ue003 10x  C 9 and B.x/  D \ue0032x  3 C 4x  \ue003 5, their sum is \nC.x/  D 4x  3 C 7x  2 \ue003 6x  C 4. \nFor polynomial  multiplication , if A.x/  and B.x/  are  polynomials  of degree-  \nbound n, their product  C.x/  is a polynomial  of degree-bound  2n  \ue003 1 such that \nC.x/  D A.x/B.x/  for all x in the  underlying  \u00fbeld.  You  probably  have  multi-  \nplied polynomials before, by multiplying each term in A.x/  by each term in B.x/  \nand then combining terms with equal powers. For exa mple, you can multiply \nA.x/  D 6x  3 C 7x  2 \ue003 10x  C 9 and B.x/  D \ue0032x  3 C 4x  \ue003 5 as follows: \n6x  3 C 7x  2 \ue003 10x  C 9 \n\ue003 2x  3 C 4x  \ue003 5 \n\ue003 30x  3 \ue003 35x  2 C 50x  \ue003 45  (multiply A.x/  by \ue0035) \n24x  4 C 28x  3 \ue003 40x  2 C 36x  (multiply A.x/  by 4x  ) \n\ue003 12x  6 \ue003 14x  5 C 20x  4 \ue003 18x  3 (multiply A.x/  by \ue0032x  3 ) \n\ue003 12x  6 \ue003 14x  5 C 44x  4 \ue003 20x  3 \ue003 75x  2 C 86x  \ue003 45  \nAnother way to express the product C.x/  is \nC.x/  D 2n\ue0022 X  \nj D0 c j x j ; (30.1)  \nwhere \nc j D j X  \nkD0 a k b j \ue002k ; (30.2)  \n(By  the  de\u00fbnition  of degree,  a k D 0 for all k >  degree.A/  and b k D 0 for all \nk >  degree.B/.) If A is a polynomial  of degree-bound  n a and B is a polynomial \nof degree-bound  n b , then C must  be a polynomial  of degree-bound  n a C n b \ue003 1, \nbecause degree .C/  D degree.A/  C degree.B/. Since  a polynomial  of degree-  \nbound k is also  a polynomial  of degree-bound  k C 1, we  normally  make  the  some-  \nwhat simpler statement that the product polynomial C is a polynomial  of degree-  \nbound n a C n b . 30.1  Representing  polynomials  879 \nChapter  outline  \nSection  30.1  presents  two  ways  to represent  polynomials:  the  coef\u00fbcient  represen-  \ntation  and  the  point-value  representation.  The  straightforward  method  for  multiply-  \ning polynomials of degree n4equations  (30.1)  and  (30.2)4takes  \u201a.n  2 / time with \npolynomials  represented  in coef\u00fbcient  form,  but  only  \u201a.n/  time  with  point-value  \nform. Converting between the two representations, h owever, reduces the time to \nmultiply polynomials to just \u201a.n  lg n/. To see why this approach works, you must \n\u00fbrst  understand  complex  roots  of unity,  which  Section  30.2  covers.  Section  30.2  \nthen uses the FFT and its inverse to perform the co nversions. Because the FFT is \nused so often in signal processing, it is often imp lemented as a circuit in hardware, \nand  Section  30.3  illustrates  the  structure  of such  circuits . \nThis chapter relies on complex numbers, and within this chapter the symbol i \ndenotes p \n\ue0031 exclusively. \n30.1  Representing  polynomials  \nThe  coef\u00fbcient  and  point-value  representations  of polynomials  are  in a sense  equiv-  \nalent:  a polynomial  in point-value  form  has  a unique  counterpart  in coef\u00fbcient  \nform. This section introduces the two representatio ns and shows how to combine \nthem  in order  to multiply  two  degree-bound  n polynomials in \u201a.n  lg n/ time. \nCoef\u00fbcient  representation  \nA coef\u00fbcient  representation  of a polynomial A.x/  D P  n\ue0021 \nj D0 a j x j of degree-  \nbound n is a vector  of coef\u00fbcients  a D .a 0 ;a  1 ;:::;a  n\ue0021 /. Matrix equations in \nthis chapter generally treat vectors as column vect ors. \nThe  coef\u00fbcient  representation  is convenient  for  certain  operations  on  polyno-  \nmials. For example, the operation of evaluating  the polynomial A.x/  at a given \npoint x 0 consists of computing the value of A.x  0 /. To evaluate a polynomial in \n\u201a.n/  time, use Horner\u2019s  rule: \nA.x  0 / D a 0 C x 0 \u00ce \na 1 C x 0 \ue002 \na 2 C \ue001 \ue001 \ue001 C  x 0 \u00e3 a n\ue0022 C x 0 .a n\ue0021 / \u00e4 \ue001 \ue001 \ue001  \u00cd \u00cf \n: \nSimilarly,  adding  two  polynomials  represented  by  the  coef\u00fb cient vectors a D \n.a 0 ;a  1 ;:::;a  n\ue0021 / and b D .b 0 ;b  1 ;:::;b  n\ue0021 / takes \u201a.n/  time:  just  produce  the  co-  \nef\u00fbcient  vector  c D .c 0 ;c 1 ;:::;c  n\ue0021 /, where c j D a j C b j for j D 0;1;:::;n  \ue003 1. \nNow,  consider  multiplying  two  degree-bound  n polynomials A.x/  and B.x/  rep-  \nresented  in coef\u00fbcient  form.  The  method  described  by  equations  (30.1)  and  (30.2)  \ntakes \u201a.n  2 / time,  since  it multiplies  each  coef\u00fbcient  in the  vector  a by  each  co-  880  Chapter  30  Polynomials  and  the  FFT  \nef\u00fbcient  in the  vector  b. The  operation  of multiplying  polynomials  in coef\u00fbcient  \nform  seems  to be considerably  more  dif\u00fbcult  than  that  of evaluating a polynomial \nor adding  two  polynomials.  The  resulting  coef\u00fbcient  vector  c , given  by  equa-  \ntion  (30.2),  is also  called  the  convolution  of the input vectors a and b, denoted \nc D a \u02dd b. Since multiplying polynomials and computing convo lutions are  funda-  \nmental computational problems of considerable pract ical importance, this chapter \nconcentrates  on  ef\u00fbcient  algorithms  for  them.  \nPoint-value  representation  \nA point-value  representation  of a polynomial A.x/  of degree-bound  n is a set of n \npoint-value  pairs  \nf.x 0 ;y  0 /;.x  1 ;y  1 /;:::;.x  n\ue0021 ;y  n\ue0021 /g \nsuch that all of the x k are distinct and \ny k D A.x  k / (30.3)  \nfor k D 0;1;:::;n  \ue003 1. A polynomial  has  many  different  point-value  representa-  \ntions, since any set of n distinct points x 0 ;x  1 ;:::;x  n\ue0021 can serve as a basis for the \nrepresentation. \nComputing  a point-value  representation  for  a polynomial  given  in coef\u00fbcient  \nform is in principle straightforward, since all you  have to do is select n distinct \npoints x 0 ;x  1 ;:::;x  n\ue0021 and then evaluate A.x  k / for k D 0;1;:::;n  \ue003 1. With \nHorner\u2019s  method,  evaluating  a polynomial  at n points takes \u201a.n  2 / time.  We\u2019ll  see  \nlater that if you choose the points x k cleverly, you can accelerate this computation \nto run in \u201a.n  lg n/ time. \nThe  inverse  of evaluation4determining  the  coef\u00fbcient  form  of a polynomial \nfrom  a point-value  representation4is  interpolation . The following theorem shows \nthat  interpolation  is well  de\u00fbned  when  the  desired  interpol ating polynomial must \nhave  a degree-bound  equal  to the  given  number  of point-value  pairs. \nTheorem  30.1  (Uniqueness  of an  interpolating  polynomial)  \nFor any set f.x 0 ;y  0 /;.x  1 ;y  1 /;:::;.x  n\ue0021 ;y  n\ue0021 /g of n point-value  pairs  such  that  \nall the x k values are distinct, there is a unique polynomial A.x/  of degree-bound  n \nsuch that y k D A.x  k / for k D 0;1;:::;n  \ue003 1. \nProof  The proof relies on the existence of the inverse of  a certain matrix.  Equa-  \ntion  (30.3)  is equivalent  to the  matrix  equation  30.1  Representing  polynomials  881 \n\u02d9 1 x  0 x 2 \n0 \ue001 \ue001 \ue001  x n\ue0021 \n0 \n1 x  1 x 2 \n1 \ue001 \ue001 \ue001  x n\ue0021 \n1 : : : : : : : : : : : : : : : \n1 x  n\ue0021 x 2 \nn\ue0021 \ue001 \ue001 \ue001  x n\ue0021 \nn\ue0021 \ue005\u02d9 a 0 \na 1 \n: : : \na n\ue0021 \ue005 \nD \u02d9 y 0 \ny 1 \n: : : \ny n\ue0021 \ue005 \n: (30.4)  \nThe matrix on the left is denoted V.x  0 ;x  1 ;:::;x  n\ue0021 / and is known as a Vander-  \nmonde  matrix. By  Problem  D-1  on  page  1223,  this  matrix  has  determinant  \nY  \n0\u0dc4j <k\u0dc4n\ue0021 .x k \ue003 x j /; \nand  therefore,  by  Theorem  D.5  on  page  1221,  it is invertible  (that is, nonsingular) \nif the x k are  distinct.  To  solve  for  the  coef\u00fbcients  a j uniquely  given  the  point-value  \nrepresentation, use the inverse of the Vandermonde matrix: \na D V.x  0 ;x  1 ;:::;x  n\ue0021 / \ue0021 y:  \nThe  proof  of Theorem  30.1  describes  an algorithm  for  interpo lation based on \nsolving  the  set  (30.4)  of linear  equations.  Section  28.1  shows how to solve these \nequations in O.n  3 / time. \nA faster algorithm for n-point  interpolation  is based  on  Lagrange\u2019s  formula : \nA.x/  D n\ue0021 X  \nkD0 y k Y  \nj \u00a4k .x \ue003 x j / \nY  \nj \u00a4k .x k \ue003 x j / : (30.5)  \nYou  might  want  to verify  that  the  right-hand  side  of equation  (30.5)  is a polynomial  \nof degree-bound  n that  satis\u00fbes  A.x  k / D y k for all k. Exercise  30.1-5  asks  you  \nhow  to compute  the  coef\u00fbcients  of A using  Lagrange\u2019s  formula  in \u201a.n  2 / time. \nThus, n-point  evaluation  and  interpolation  are  well-de\u00fbned  inver se operations \nthat  transform  between  the  coef\u00fbcient  representation  of a polynomial  and  a point-  \nvalue representation. 1 The algorithms described above for these problems t ake \n\u201a.n  2 / time. \nThe  point-value  representation  is quite  convenient  for  many  operations  on  poly-  \nnomials. For addition, if C.x/  D A.x/  C B.x/ , then C.x  k / D A.x  k / C B.x  k / for \nany point x k . More  precisely,  given  point-value  representations  for  A, \nf.x 0 ;y  0 /;.x  1 ;y  1 /;:::;.x  n\ue0021 ;y  n\ue0021 /g ; \n1 Interpolation is a notoriously tricky problem from the point of view of numerical stability. Although \nthe approaches described here are mathematically co rrect, small  differences  in the  inputs  or round-off  \nerrors during computation can cause large differenc es in the result. 882  Chapter  30  Polynomials  and  the  FFT  \nand for B , \nf.x 0 ;y  0 \n0 /;.x  1 ;y  0 \n1 /;:::;.x  n\ue0021 ;y  0 \nn\ue0021 /g ; \nwhere A and B are evaluated at the same n points,  then  a point-value  representation  \nfor C is \nf.x 0 ;y  0 C y 0 \n0 /;.x  1 ;y  1 C y 0 \n1 /;:::;.x  n\ue0021 ;y  n\ue0021 C y 0 \nn\ue0021 /g : \nThus  the  time  to add  two  polynomials  of degree-bound  n in point-value  form  \nis \u201a.n/ . \nSimilarly,  the  point-value  representation  is convenient  for  multiplying  polyno-  \nmials. If C.x/  D A.x/B.x/ , then C.x  k / D A.x  k /B.x  k / for any point x k , and \nto obtain  a point-value  representation  for  C , just  pointwise  multiply  a point-value  \nrepresentation for A by  a point-value  representation  for  B . Polynomial  multipli-  \ncation differs from polynomial addition in one key aspect, however: degree .C/  D \ndegree.A/  C degree.B/, so that if A and B have  degree-bound  n, then C has \ndegree-bound  2n. A standard  point-value  representation  for  A and B consists of \nn point-value  pairs  for  each  polynomial.  Multiplying  these  together gives n point-  \nvalue pairs, but 2n  pairs are necessary to interpolate a unique polynom ial C of \ndegree-bound  2n. (See  Exercise  30.1-4.)  Instead,  begin  with  <extended=  point-  \nvalue representations for A and for B consisting of 2n  point-value  pairs  each.  \nGiven  an extended  point-value  representation  for  A, \nf.x 0 ;y  0 /;.x  1 ;y  1 /;:::;.x  2n\ue0021 ;y  2n\ue0021 /g ; \nand  a corresponding  extended  point-value  representation  for B , \nf.x 0 ;y  0 \n0 /;.x  1 ;y  0 \n1 /;:::;.x  2n\ue0021 ;y  0 \n2n\ue0021 /g ; \nthen  a point-value  representation  for  C is \nf.x 0 ;y  0 y 0 \n0 /;.x  1 ;y  1 y 0 \n1 /;:::;.x  2n\ue0021 ;y  2n\ue0021 y 0 \n2n\ue0021 /g : \nGiven  two  input  polynomials  in extended  point-value  form,  multiplying them to \nobtain  the  point-value  form  of the  result  takes  just  \u201a.n/  time, much less than the \n\u201a.n  2 / time  required  to multiply  polynomials  in coef\u00fbcient  form.  \nFinally,  let\u2019s  consider  how  to evaluate  a polynomial  given  in point-value  form  at \na new point. For this problem, the simplest approac h known is to \u00fbrst  convert  the  \npolynomial  to coef\u00fbcient  form  and  then  evaluate  it at the  new  point. \nFast  multiplication  of polynomials  in coef\u00fbcient  form  \nCan  the  linear-time  multiplication  method  for  polynomials  in point-value  form  \nexpedite  polynomial  multiplication  in coef\u00fbcient  form?  The answer hinges on 30.1  Representing  polynomials  883 \na 0 ;a  1 ;:::;a  n\ue0021 \nb 0 ;b  1 ;:::;b  n\ue0021 c 0 ;c 1 ;:::;c  2n\ue0022 Ordinary  multiplication  \nTime \u201a.n  2 / \nEvaluation \nTime \u201a.n  lg n/ Time \u201a.n  lg n/ Interpolation \nPointwise multiplication \nTime \u201a.n/  A.!  0 \n2n  /;B.!  0 \n2n  / \nA.!  1 \n2n  /;B.!  1 \n2n  / \nA.!  2n\ue0021 \n2n  /;B.!  2n\ue0021 \n2n  / : : : : : : C.!  0 \n2n  / \nC.!  1 \n2n  / \nC.!  2n\ue0021 \n2n  / Coef\u00fbcient  \nPoint-value  \nrepresentations representations \nFigure  30.1  A graphical  outline  of an  ef\u00fbcient  polynomial-multiplicat ion process. Representations \non  the  top  are  in coef\u00fbcient  form,  and  those  on  the  bottom  are  in point-value  form.  The  arrows  from  \nleft to right correspond to the multiplication oper ation. The ! 2n  terms are complex .2n/th roots of \nunity. \nwhether it is possible convert a polynomial quickly  from coef\u00fbcient  form  to point-  \nvalue form (evaluate) and vice versa (interpolate).  \nAny points can serve as evaluation points, but cert ain evaluation points allow \nconversion between representations in only \u201a.n  lg n/ time.  As  we\u2019ll  see  in Sec-  \ntion  30.2,  if <complex  roots  of unity=  are  the  evaluation  points,  then  the  dis-  \ncrete Fourier transform (or DFT) evaluates and the inverse DFT  interpolates.  Sec-  \ntion  30.2  shows  how  the  FFT  accomplishes  the  DFT  and  inverse  DFT operations \nin \u201a.n  lg n/ time. \nFigure  30.1  shows  this  strategy  graphically.  One  minor  detail  concerns  degree-  \nbounds.  The  product  of two  polynomials  of degree-bound  n is a polynomial of \ndegree-bound  2n. Before evaluating the input polynomials A and B , therefore, \n\u00fbrst  double  their  degree-bounds  to 2n  by adding n high-order  coef\u00fbcients  of 0. \nBecause the vectors have 2n  elements, use <complex .2n/th roots of unity,= which \nare denoted by the ! 2n  terms  in Figure  30.1.  \nThe following procedure takes advantage of the FFT to multiply two  polyno-  \nmials A.x/  and B.x/  of degree-bound  n in \u201a.n  lg n/-time,  where  the  input  and  \noutput  representations  are  in coef\u00fbcient  form.  The  procedu re assumes that n is an \nexact power of 2, so if it isn\u2019t,  just  add  high-order  zero  coef\u00fbcients.  \n1. Double  degree-bound:  Create  coef\u00fbcient  representations  of A.x/  and B.x/  as \ndegree-bound  2n  polynomials by adding n high-order  zero  coef\u00fbcients  to each.  884  Chapter  30  Polynomials  and  the  FFT  \n2. Evaluate:  Compute  point-value  representations  of A.x/  and B.x/  of length 2n  \nby applying the FFT of order 2n  on each polynomial. These representations \ncontain the values of the two polynomials at the .2n/th roots of unity. \n3. Pointwise  multiply:  Compute  a point-value  representation  for  the  polynomial  \nC.x/  D A.x/B.x/  by multiplying these values together pointwise. Thi s repre- \nsentation contains the value of C.x/  at each .2n/th root of unity. \n4. Interpolate:  Create  the  coef\u00fbcient  representation  of the  polynomial  C.x/  by \napplying the FFT on 2n  point-value  pairs  to compute  the  inverse  DFT.  \nSteps  (1)  and  (3)  take  \u201a.n/  time,  and  steps  (2)  and  (4)  take  \u201a.n  lg n/ time. Thus, \nonce we show how to use the FFT, we will have prove n the following. \nTheorem  30.2  \nTwo  polynomials  of degree-bound  n with both the input and output representations \nin coef\u00fbcient  form  can  be multiplied  in \u201a.n  lg n/ time. \nExercises  \n30.1-1  \nMultiply the polynomials A.x/  D 7x  3 \ue003 x 2 C x \ue003 10  and B.x/  D 8x  3 \ue003 6x  C 3 \nusing  equations  (30.1)  and  (30.2).  \n30.1-2  \nAnother way to evaluate a polynomial A.x/  of degree-bound  n at a given point x 0 \nis to divide A.x/  by the polynomial .x \ue003 x 0 /, obtaining a quotient polynomial q.x/  \nof degree-bound  n \ue003 1 and a remainder r , such that \nA.x/  D q.x/.x  \ue003 x 0 / C r:  \nThen we have A.x  0 / D r . Show how to compute the remainder r and  the  coef\u00fb-  \ncients of q.x/  from x 0 and  the  coef\u00fbcients  of A in \u201a.n/  time. \n30.1-3  \nGiven  a polynomial  A.x/  D P  n\ue0021 \nj D0 a j x j , de\u00fbne  A rev .x/  D P  n\ue0021 \nj D0 a n\ue0021\ue002j x j . Show \nhow  to derive  a point-value  representation  for  A rev .x/  from  a point-value  represen-  \ntation for A.x/ , assuming that none of the points is 0. \n30.1-4  \nProve that n distinct  point-value  pairs  are  necessary  to uniquely  specify  a polyno-  \nmial  of degree-bound  n, that is, if fewer than n distinct  point-value  pairs  are  given,  \nthey  fail  to specify  a unique  polynomial  of degree-bound  n. (Hint: Using  Theo-  \nrem  30.1,  what  can  you  say  about  a set  of n \ue003 1 point-value  pairs  to which  you  add  \none  more  arbitrarily  chosen  point-value  pair?)  30.2 The DFT and FFT 885 \n30.1-5  \nShow  how  to use  equation  (30.5)  to interpolate  in \u201a.n  2 / time. ( Hint: First compute \nthe  coef\u00fbcient  representation  of the  polynomial  Q  \nj .x \ue003 x j / and then divide by \n.x \ue003 x k / as necessary  for  the  numerator  of each  term  (see  Exercise  30.1-2).  You  \ncan compute each of the n denominators in O.n/  time.) \n30.1-6  \nExplain what is wrong with the <obvious= approach t o polynomial division using \na point-value  representation:  dividing  the  corresponding  y values.  Discuss  sepa-  \nrately the case in which the division comes out exa ctly and the case in which it \ndoesn\u2019t.  \n30.1-7  \nConsider two sets A and B , each having n integers in the range from 0 to 10n. The \nCartesian  sum  of A and B is de\u00fbned  by  \nC D fx C y W x 2 A and y 2 B g : \nThe integers in C lie in the range from 0 to 20n. Show how, in O.n  lg n/ time, to \n\u00fbnd  the  elements  of C and the number of times each element of C is realized as a \nsum of elements in A and B . (Hint: Represent A and B as polynomials of degree \nat most 10n.) \n30.2  The  DFT  and  FFT  \nIn Section  30.1,  we  claimed  that  by  computing  the  DFT  and  its  inverse by using the \nFFT, it is possible to evaluate and interpolate a d egree n polynomial at the complex \nroots of unity in \u201a.n  lg n/ time.  This  section  de\u00fbnes  complex  roots  of unity,  studies  \ntheir  properties,  de\u00fbnes  the  DFT,  and  then  shows  how  the  FFT  computes the DFT \nand its inverse in \u201a.n  lg n/ time. \nComplex  roots  of unity  \nA complex  nth root  of unity  is a complex number ! such that \n! n D 1:  \nThere are exactly n complex nth roots of unity: e 2\ue003ik=n  for k D 0;1;:::;n  \ue003 1. To \ninterpret  this  formula,  use  the  de\u00fbnition  of the  exponentia l of a complex number: \ne iu  D cos.u/  C i sin.u/:  \nFigure  30.2  shows  that  the  n complex roots of unity are equally spaced around th e \ncircle of unit radius centered at the origin of the  complex plane. The value 886  Chapter  30  Polynomials  and  the  FFT  \n1 \ue0031 i \n\ue003i ! 0 \n8 D ! 8 \n8 ! 1 \n8 ! 2 \n8 \n! 3 \n8 \n! 4 \n8 \n! 5 \n8 \n! 6 \n8 ! 7 \n8 \nFigure  30.2  The values of ! 0 \n8 ;!  1 \n8 ;:::;!  7 \n8 in the complex plane, where ! 8 D e 2\ue003i=8  is the  prin-  \ncipal 8th root of unity. \n! n D e 2\ue003i=n  (30.6)  \nis the principal  nth root  of unity . 2 All other complex nth roots of unity are powers \nof ! n . \nThe n complex nth roots of unity, \n! 0 \nn ;!  1 \nn ;:::;!  n\ue0021 \nn ; \nform  a group  under  multiplication  (see  Section  31.3).  This  group has the same \nstructure as the additive group .Z n ; C/ modulo n, since ! n \nn D ! 0 \nn D 1 implies that \n! j \nn ! k \nn D ! j Ck \nn D ! .j Ck/  mod n \nn . Similarly, ! \ue0021 \nn D ! n\ue0021 \nn . The following lemmas \nfurnish some essential properties of the complex nth roots of unity. \nLemma  30.3  (Cancellation  lemma)  \nFor any integers n>0 , k \ue004 0, and d >0 , \n! dk  \ndn  D ! k \nn : (30.7)  \nProof  The  lemma  follows  directly  from  equation  (30.6),  since  \n! dk  \ndn  D \u00e3 \ne 2\ue003i=dn  \u00e4 dk  \nD \u00e3 \ne 2\ue003i=n  \u00e4 k \nD ! k \nn : \n2 Many  other  authors  de\u00fbne  ! n differently: ! n D e \ue0022\ue003i=n  . This  alternative  de\u00fbnition  tends  to be \nused  for  signal-processing  applications.  The  underlying  mathematics is substantially the same with \neither  de\u00fbnition  of ! n . 30.2 The DFT and FFT 887 \nCorollary  30.4  \nFor any even integer n>0 , \n! n=2  \nn D ! 2 D \ue0031:  \nProof  The  proof  is left  as Exercise  30.2-1.  \nLemma  30.5  (Halving  lemma)  \nIf n>0  is even, then the squares of the n complex nth roots of unity are the n=2  \ncomplex .n=2/ th roots of unity. \nProof  By the cancellation lemma, .!  k \nn / 2 D ! k \nn=2  for any nonnegative integer k. \nSquaring all of the complex nth roots of unity produces each .n=2/ th root of unity \nexactly twice, since \n.!  kCn=2  \nn / 2 D ! 2kCn \nn \nD ! 2k  \nn ! n \nn \nD ! 2k  \nn \nD .!  k \nn / 2 : \nThus ! k \nn and ! kCn=2  \nn have  the  same  square.  We  could  also  have  used  Corollary  30.4  \nto prove this property, since ! n=2  \nn D \ue0031 implies ! kCn=2  \nn D ! k \nn ! n=2  \nn D \ue003! k \nn , and \nthus .!  kCn=2  \nn / 2 D .\ue003! k \nn / 2 D .!  k \nn / 2 . \nAs  we\u2019ll  see,  the  halving  lemma  is essential  to the  divide-and-conquer  approach  \nfor  converting  between  coef\u00fbcient  and  point-value  represe ntations of polynomials, \nsince it guarantees that the recursive subproblems are only half as large. \nLemma  30.6  (Summation  lemma)  \nFor any integer n \ue004 1 and nonzero integer k not divisible by n, \nn\ue0021 X  \nj D0 \u00e3 \n! k \nn \u00e4 j D 0:  \nProof  Equation  (A.6)  on  page  1142  applies  to complex  values  as well  as to reals, \ngiving 888  Chapter  30  Polynomials  and  the  FFT  \nn\ue0021 X  \nj D0 \u00e3 \n! k \nn \u00e4 j D .!  k \nn / n \ue003 1 \n! k \nn \ue003 1 \nD .!  n \nn / k \ue003 1 \n! k \nn \ue003 1 \nD .1/  k \ue003 1 \n! k \nn \ue003 1 \nD 0:  \nTo see that the denominator is not 0, note that ! k \nn D 1 only when k is divisible \nby n, which the lemma statement prohibits. \nThe  DFT  \nRecall the goal of evaluating a polynomial \nA.x/  D n\ue0021 X  \nj D0 a j x j \nof degree-bound  n at ! 0 \nn ;!  1 \nn ;!  2 \nn ;:::;!  n\ue0021 \nn (that is, at the n complex nth roots of \nunity). 3 The polynomial A is given  in coef\u00fbcient  form:  a D .a 0 ;a  1 ;:::;a  n\ue0021 /. \nLet  us de\u00fbne  the  results  y k , for k D 0;1;:::;n  \ue003 1, by \ny k D A.!  k \nn / \nD n\ue0021 X  \nj D0 a j ! kj  \nn : (30.8)  \nThe vector y D .y 0 ;y  1 ;:::;y  n\ue0021 / is the discrete  Fourier  transform  (DFT)  of the \ncoef\u00fbcient  vector  a D .a 0 ;a  1 ;:::;a  n\ue0021 /. We also write y D DFT n .a/. \nThe  FFT  \nThe fast  Fourier  transform  (FFT)  takes advantage of the special properties of the \ncomplex roots of unity to compute DFT n .a/  in \u201a.n  lg n/ time, as opposed to the \n\u201a.n  2 / time of the straightforward method. Assume througho ut that n is an exact \npower of 2. Although strategies for dealing with sizes that a re not exact powers \nof 2 are known, they are beyond the scope of this book. \n3 The length n is actually  what  Section  30.1  referred  to as 2n, since  the  degree-bound  of the  given  \npolynomials doubles prior to evaluation. In the con text of polynomial multiplication, therefore, we \nare actually working with complex .2n/th roots of unity. 30.2 The DFT and FFT 889 \nThe  FFT  method  employs  a divide-and-conquer  strategy,  using  the  even-indexed  \nand  odd-indexed  coef\u00fbcients  of A.x/  separately  to de\u00fbne  the  two  new  polynomials  \nA even .x/  and A odd .x/  of degree-bound  n=2: \nA even .x/  D a 0 C a 2 x C a 4 x 2 C \ue001 \ue001 \ue001 C  a n\ue0022 x n=2\ue0021 ; \nA odd .x/  D a 1 C a 3 x C a 5 x 2 C \ue001 \ue001 \ue001 C  a n\ue0021 x n=2\ue0021 : \nNote that A even contains  all  the  even-indexed  coef\u00fbcients  of A (the  binary  repre-  \nsentation of the index ends in 0) and A odd contains  all  the  odd-indexed  coef\u00fbcients  \n(the binary representation of the index ends in 1). It follows that \nA.x/  D A even .x 2 / C xA  odd .x 2 /; (30.9)  \nso that the problem of evaluating A.x/  at ! 0 \nn ;!  1 \nn ;:::;!  n\ue0021 \nn reduces to \n1. evaluating  the  degree-bound  n=2  polynomials A even .x/  and A odd .x/  at the points \n.!  0 \nn / 2 ;.!  1 \nn / 2 ;:::;.!  n\ue0021 \nn / 2 ; (30.10)  \nand then \n2. combining  the  results  according  to equation  (30.9).  \nBy  the  halving  lemma,  the  list  of values  (30.10)  consists  not  of n distinct values \nbut only of the n=2  complex .n=2/ th roots of unity, with each root occurring exactly  \ntwice. Therefore, the FFT recursively evaluates the  polynomials A even and A odd of \ndegree-bound  n=2  at the n=2  complex .n=2/ th roots of unity. These subproblems \nhave exactly the same form as the original problem,  but are half the size, dividing \nan n-element  DFT  n computation into two n=2-element  DFT  n=2  computations. This \ndecomposition is the basis for the FFT procedure on  the next page, which computes \nthe DFT of an n-element  vector  a D .a 0 ;a  1 ;:::;a  n\ue0021 /, where n is an exact power \nof 2. \nThe  FFT  procedure  works  as follows.  Lines  132  represent  the  base case of the \nrecursion. The DFT of 1 element is the element itself, since in this case \ny 0 D a 0 ! 0 \n1 \nD a 0 \ue001 1 \nD a 0 : \nLines  536  de\u00fbne  the  coef\u00fbcient  vectors  for  the  polynomials  A even and A odd . Lines \n3, 4, and  12  guarantee  that  ! is updated  properly  so that  whenever  lines  10311  are  \nexecuted, ! D ! k \nn . (Keeping  a running  value  of ! from iteration to iteration saves 890  Chapter  30  Polynomials  and  the  FFT  \nFFT.a;n/  \n1 if n = = 1 \n2 return  a / / DFT of 1 element is the element itself \n3 ! n D e 2\ue003i=n  \n4 ! D 1 \n5 a even D .a 0 ;a  2 ;:::;a  n\ue0022 / \n6 a odd D .a 1 ;a  3 ;:::;a  n\ue0021 / \n7 y even D FFT.a even ;n=2/  \n8 y odd D FFT.a odd ;n=2/  \n9 for  k D 0 to n=2  \ue003 1 / / at this point, ! D ! k \nn \n10  y k D y even \nk C !y  odd \nk \n11  y kC.n=2/  D y even \nk \ue003 !y  odd \nk \n12  ! D !!  n \n13  return  y \ntime over computing ! k \nn from scratch each time through the for  loop. 4 ) Lines  738  \nperform the recursive DFT n=2  computations, setting, for k D 0;1;:::;n=2  \ue003 1, \ny even \nk D A even .!  k \nn=2  /; \ny odd \nk D A odd .!  k \nn=2  /; \nor, since ! k \nn=2  D ! 2k  \nn by the cancellation lemma, \ny even \nk D A even .!  2k  \nn /; \ny odd \nk D A odd .!  2k  \nn /: \nLines  10311  combine  the  results  of the  recursive  DFT  n=2  calculations.  For  the  \u00fbrst  \nn=2  results y 0 ;y  1 ;:::;y  n=2\ue0021 , line  10  yields  \ny k D y even \nk C ! k \nn y odd \nk \nD A even .!  2k  \nn / C ! k \nn A odd .!  2k  \nn / \nD A.!  k \nn / (by  equation  (30.9))  . \nFor y n=2  ;y  n=2C1 ;:::;y  n\ue0021 , letting k D 0;1;:::;n=2  \ue003 1, line  11  yields  \n4 The downside of iteratively updating ! is that  round-off  errors  can  accumulate,  especially  for  larger \ninput sizes. Several techniques to limit the magnit ude of FFT round-off  errors  have  been  proposed,  \nbut are beyond the scope of this book. If several F FTs are going to be run on inputs of the same size,  \nthen it might be worthwhile to directly precompute a table of all n=2  values of ! k \nn . 30.2 The DFT and FFT 891 \ny kC.n=2/  D y even \nk \ue003 ! k \nn y odd \nk \nD y even \nk C ! kC.n=2/  \nn y odd \nk (since ! kC.n=2/  \nn D \ue003! k \nn ) \nD A even .!  2k  \nn / C ! kC.n=2/  \nn A odd .!  2k  \nn / \nD A even .!  2kCn \nn / C ! kC.n=2/  \nn A odd .!  2kCn \nn / (since ! 2kCn \nn D ! 2k  \nn ) \nD A.!  kC.n=2/  \nn / (by  equation  (30.9))  . \nThus the vector y returned by FFT is indeed the DFT of the input vect or a. \nLines  10  and  11  multiply  each  value  y odd \nk by ! k \nn , for k D 0;1;:::;n=2  \ue003 1. \nLine  10  adds  this  product  to y even \nk , and  line  11  subtracts  it. Because  each  factor  ! k \nn \nappears in both its positive and negative forms, we  call the factors ! k \nn twiddle  \nfactors . \nTo determine the running time of the procedure FFT,  note that exclusive of the \nrecursive calls, each invocation takes \u201a.n/  time, where n is the length of the input \nvector. The recurrence for the running time is ther efore \nT.n/  D 2T.n=2/  C \u201a.n/  \nD \u201a.n  lg n/;  \nby  case  2 of the  master  theorem  (Theorem  4.1).  Thus  the  FFT  can  evaluate a \npolynomial  of degree-bound  n at the complex nth roots of unity in \u201a.n  lg n/ time. \nInterpolation  at the  complex  roots  of unity  \nThe polynomial multiplication scheme entails conver ting from  coef\u00fbcient  form  to \npoint-value  form  by  evaluating  the  polynomial  at the  complex  roots  of unity,  point-  \nwise  multiplying,  and  \u00fbnally  converting  from  point-value  form  back  to coef\u00fbcient  \nform  by  interpolating.  We\u2019ve  just  seen  how  to evaluate,  so now  we\u2019ll  see  how  to \ninterpolate the complex roots of unity by a polynom ial. To interpolate,  we\u2019ll  write  \nthe DFT as a matrix equation and then look at the f orm of the matrix inverse. \nFrom  equation  (30.4),  we  can  write  the  DFT  as the  matrix  produ ct y D V n a, \nwhere V n is a Vandermonde matrix containing the appropriate powers of ! n : \u00e4 \ny 0 \ny 1 \ny 2 \ny 3 \n: : : \ny n\ue0021 \u00e5 \nD \u00e4 \n1 1  1 1 \ue001 \ue001 \ue001  1 \n1 !  n ! 2 \nn ! 3 \nn \ue001 \ue001 \ue001  ! n\ue0021 \nn \n1 !  2 \nn ! 4 \nn ! 6 \nn \ue001 \ue001 \ue001  ! 2.n\ue0021/  \nn \n1 !  3 \nn ! 6 \nn ! 9 \nn \ue001 \ue001 \ue001  ! 3.n\ue0021/  \nn : : : : : : : : : : : : : : : : : : \n1 !  n\ue0021 \nn ! 2.n\ue0021/  \nn ! 3.n\ue0021/  \nn \ue001 \ue001 \ue001  ! .n\ue0021/.n\ue0021/  \nn \u00e5\u00e4 \na 0 \na 1 \na 2 \na 3 \n: : : \na n\ue0021 \u00e5 \n: \nThe .k;j/  entry of V n is ! kj  \nn , for j;k  D 0;1;:::;n  \ue003 1. The exponents of the \nentries of V n form a multiplication table for factors 0 to n \ue003 1. 892  Chapter  30  Polynomials  and  the  FFT  \nFor the inverse operation, which we write as a D DFT \ue0021 \nn .y/, multiply y by the \nmatrix V \ue0021 \nn , the inverse of V n . \nTheorem  30.7  \nFor j;k  D 0;1;:::;n  \ue003 1, the .j;k/  entry of V \ue0021 \nn is ! \ue002jk  \nn =n. \nProof  We show that V \ue0021 \nn V n D I n , the n \ue005 n identity matrix. Consider the .k;k  0 / \nentry of V \ue0021 \nn V n : \n\u0152V \ue0021 \nn V n \ufffd kk  0 D n\ue0021 X  \nj D0 .!  \ue002jk  \nn =n/.!  jk  0 \nn / \nD n\ue0021 X  \nj D0 ! j.k  0 \ue002k/  \nn =n:  \nThis summation equals 1 if k 0 D k, and it is 0 otherwise by the summation lemma \n(Lemma  30.6).  Note  that  in order  for  the  summation  lemma  to apply, k 0 \ue003 k must \nnot be divisible by n. Indeed, it is not, since \ue003.n \ue003 1/ \u0dc4 k 0 \ue003 k \u0dc4 n \ue003 1. \nWith the inverse matrix V \ue0021 \nn de\u00fbned,  DFT  \ue0021 \nn .y/  is given by \na j D n\ue0021 X  \nkD0 y k ! \ue002jk  \nn \nD 1 \nn n\ue0021 X  \nkD0 y k ! \ue002kj  \nn (30.11)  \nfor j D 0;1;:::;n  \ue003 1. By  comparing  equations  (30.8)  and  (30.11),  you  can  see  \nthat if you modify the FFT algorithm to switch the roles of a and y , replace ! n \nby ! \ue0021 \nn , and divide each element of the result by n, you get the inverse DFT (see \nExercise  30.2-4).  Thus,  DFT  \ue0021 \nn is computable in \u201a.n  lg n/ time as well. \nThus, the FFT and the inverse FFT provide a way to transform a polynomial of \ndegree-bound  n back  and  forth  between  its  coef\u00fbcient  representation  and  a point-  \nvalue representation in only \u201a.n  lg n/ time.  In the  context  of polynomial  multi-  \nplication, we have shown the following about the co nvolution a \u02dd b of vectors a \nand b: \nTheorem  30.8  (Convolution  theorem)  \nFor any two vectors a and b of length n, where n is an exact power of 2, \na \u02dd b D DFT \ue0021 \n2n  .DFT 2n  .a/  \ue001 DFT 2n  .b//;  \nwhere the vectors a and b are padded with 0s to length 2n  and \ue001 denotes  the  com-  \nponentwise product of two 2n-element  vectors.  30.2 The DFT and FFT 893 \nExercises  \n30.2-1  \nProve  Corollary  30.4.  \n30.2-2  \nCompute the DFT of the vector .0;1;2;3/ . \n30.2-3  \nDo  Exercise  30.1-1  by  using  the  \u201a.n  lg n/-time  scheme.  \n30.2-4  \nWrite pseudocode to compute DFT \ue0021 \nn in \u201a.n  lg n/ time. \n30.2-5  \nDescribe the generalization of the FFT procedure to  the case in which n is an exact \npower of 3. Give  a recurrence  for  the  running  time,  and  solve  the  recurr ence. \n? 30.2-6  \nInstead of performing an n-element  FFT  over  the  \u00fbeld  of complex  numbers  (where  \nn is an exact power of 2), let\u2019s  use  the  ring  Z m of integers modulo m, where \nm D 2 tn=2  C 1 and t is an arbitrary positive integer. We can use ! D 2 t instead \nof ! n as a principal nth root of unity, modulo m. Prove that the DFT and the inverse \nDFT  are  well  de\u00fbned  in this  system.  \n30.2-7  \nGiven  a list  of values  \u00b4 0 ;\u00b4  1 ;:::;\u00b4  n\ue0021 (possibly with repetitions), show how to \n\u00fbnd  the  coef\u00fbcients  of a polynomial  P.x/  of degree-bound  n C 1 that has zeros \nonly at \u00b4 0 ;\u00b4  1 ;:::;\u00b4  n\ue0021 (possibly with repetitions). Your procedure should run in \nO.n  lg 2 n/ time. ( Hint: The polynomial P.x/  has a zero at \u00b4 j if and only if P.x/  \nis a multiple of .x \ue003 \u00b4 j /.) \n? 30.2-8  \nThe chirp  transform  of a vector a D .a 0 ;a  1 ;:::;a  n\ue0021 / is the vector y D \n.y 0 ;y  1 ;:::;y  n\ue0021 /, where y k D P  n\ue0021 \nj D0 a j \u00b4 kj  and \u00b4 is any complex number. The \nDFT is therefore a special case of the chirp transf orm, obtained by taking \u00b4 D ! n . \nShow how to evaluate the chirp transform for any co mplex number \u00b4 in O.n  lg n/ \ntime. ( Hint: Use the equation \ny k D \u00b4 k 2 =2  n\ue0021 X  \nj D0 \ue002 \na j \u00b4 j 2 =2  \u00cd\ue002  \n\u00b4 \ue002.k\ue002j /  2 =2  \u00cd \nto view the chirp transform as a convolution.) 894  Chapter  30  Polynomials  and  the  FFT  \n30.3  FFT  circuits  \nMany  of the  FFT\u2019s  applications  in signal  processing  require  the utmost speed, and \nso the FFT is often implemented as a circuit in har dware. The F FT\u2019s  divide-and-  \nconquer structure enables the circuit to have a par allel structure so that the depth  of \nthe  circuit4the  maximum  number  of computational  elements  between any output \nand  any  input  that  can  reach  it4is  \u201a.lg n/. Moreover, the structure of the FFT \ncircuit has several interesting mathematical proper ties, which  we  won\u2019t  go  into  \nhere. \nButter\u00fcy  operations  \nNotice that the for  loop  of lines  9312  of the  FFT  procedure  computes  the  value  \n! k \nn y odd \nk twice  per  iteration:  once  in line  10  and  once  in line  11.  A good  optimizing \ncompiler produces code that evaluates this common  subexpression  just  once,  stor-  \ning  its  value  into  a temporary  variable,  so that  lines  10311  are treated like the three \nlines \nt D !y  odd \nk \ny k D y even \nk C t \ny kC.n=2/  D y even \nk \ue003 t \nThis operation, multiplying the twiddle factor ! D ! k \nn by y odd \nk , storing the product \ninto the temporary variable t , and adding and subtracting t from y even \nk , is known \nas a butter\u00fcy  operation. Figure  30.3  shows  it as a circuit,  and  you  can  see  how  it \nvaguely  resembles  the  shape  of a butter\u00fcy.  (Although  less  colorfully, it could have \nbeen called a <bowtie= operation.) \n+ \n\u2013 \u2022 \n(a) (b) y even \nk y even \nk \ny odd \nk y odd \nk ! k \nn ! k \nn y even \nk C ! k \nn y odd \nk y even \nk C ! k \nn y odd \nk \ny even \nk \ue003 ! k \nn y odd \nk y even \nk \ue003 ! k \nn y odd \nk \nFigure  30.3  A circuit  for  a butter\u00fcy  operation.  (a)  The two input values enter from the left, the \ntwiddle factor ! k \nn is multiplied by y odd \nk , and the sum and difference are output on the righ t. (b)  A \nsimpli\u00fbed  drawing  of a butter\u00fcy  operation,  which  we\u2019ll  use  when drawing the parallel FFT circuit. 30.3  FFT  circuits  895 \n! 0 \n8 \n! 1 \n8 \n! 2 \n8 \n! 3 \n8 \nFFT n FFT n=2  FFT n=2  \nFigure  30.4  The schema for the conquer and combine steps of an n-input,  n-output  FFT  circuit,  \nFFT n , shown for n D 8. Inputs enter from the left, and outputs exit from  the right. The input values \n\u00fbrst  go  through  two  FFT  n=2  circuits, and then n=2  butter\u00fcy  circuits  combine  the  results.  Only  the  \ntop  and  bottom  wires  entering  a butter\u00fcy  interact  with  it: wires that pass through the middle of a \nbutter\u00fcy  do  not  affect  that  butter\u00fcy,  nor  are  their  values  changed  by  that  butter\u00fcy.  \nRecursive  circuit  structure  \nThe  FFT  procedure  follows  the  divide-and-conquer  strategy  that  we  \u00fbrst  saw  in \nSection  2.3.1:  \nDivide  the n-element  input  vector  into  its  n=2  even-indexed  and  n=2  odd-indexed  \nelements. \nConquer  by recursively computing the DFTs of the two subpro blems, each of \nsize n=2. \nCombine  by performing n=2  butter\u00fcy  operations.  These  butter\u00fcy  operations  work  \nwith twiddle factors ! 0 \nn ;!  1 \nn ;:::;!  n=2\ue0021 \nn . \nThe  circuit  schema  in Figure  30.4  follows  the  conquer  and  combine steps of this \npattern for an FFT circuit with n inputs and n outputs, denoted by FFT n . Each line \nis a wire that carries a value. Inputs enter from t he left, one per wire, and outputs \nexit from the right. The conquer step runs the inpu ts through two FFT n=2  circuits, \nwhich are also constructed recursively. The values produced by the two FFT n=2  \ncircuits feed into n=2  butter\u00fcy  circuits,  with  twiddle  factors  ! 0 \nn ;!  1 \nn ;:::;!  n=2  \nn \ue003 1, 896  Chapter  30  Polynomials  and  the  FFT  \n(a 0 ,a 1 ,a 2 ,a 3 ,a 4 ,a 5 ,a 6 ,a 7 ) \n(a 0 ,a 2 ,a 4 ,a 6 ) \n(a 0 ,a 4 ) ( a 2 ,a 6 ) \n(a 0 ) ( a 4 ) ( a 2 ) ( a 6 ) (a 1 ,a 3 ,a 5 ,a 7 ) \n(a 1 ,a 5 ) \n(a 1 ) ( a 5 ) (a 3 ,a 7 ) \n(a 3 ) ( a 7 ) \nFigure  30.5  The tree of input vectors to the recursive calls of  the FFT procedure. The initial \ninvocation is for n D 8. \nto combine the results. The base case of the recurs ion occurs when n D 1, where \nthe sole output value equals the sole input value. An FFT 1 circuit, therefore, does \nnothing, and so the smallest nontrivial FFT circuit  is FFT 2 , a single  butter\u00fcy  oper-  \nation whose twiddle factor is ! 0 \n2 D 1. \nPermuting  the  inputs  \nHow  does  the  divide  step  enter  into  the  circuit  design?  Let\u2019s  examine how input \nvectors to the various recursive calls of the FFT p rocedure relate to the original \ninput vector, so that the circuit can emulate the d ivide step at the start for all levels \nof recursion.  Figure  30.5  arranges  the  input  vectors  to the  recursive calls in an \ninvocation of FFT in a tree structure, where the in itial call is for n D 8. The tree \nhas one node for each call of the procedure, labele d by the elements of the initial \ncall as they appear in the corresponding input vect or. Each FFT invocation makes \ntwo recursive calls, unless it has received a 1-element  vector.  The  \u00fbrst  call  appears  \nin the left child, and the second call appears in t he right child. \nLooking at the tree, observe that if you arrange th e elements of the initial vector a \ninto the order in which they appear in the leaves, you can trace the execution of the \nFFT procedure, but bottom up instead of top down. F irst, take the elements in \npairs,  compute  the  DFT  of each  pair  using  one  butter\u00fcy  operat ion, and replace the \npair with its DFT. The vector then holds n=2  two-element  DFTs.  Next,  take  these  \nn=2  DFTs in pairs and compute the DFT of the four vecto r elements they come \nfrom  by  executing  two  butter\u00fcy  operations,  replacing  two  two-element  DFTs  with  \none  four-element  DFT.  The  vector  then  holds  n=4  four-element  DFTs.  Continue  \nin this manner until the vector holds two .n=2/-element  DFTs,  which  n=2  butter\u00fcy  \noperations  combine  into  the  \u00fbnal  n-element  DFT.  In other  words,  you  can  start  with  \nthe elements of the initial vector a, but  rearranged  as in the  leaves  of Figure  30.5,  \nand then feed them directly into a circuit that fol lows the schema  in Figure  30.4.  30.3  FFT  circuits  897 \nLet\u2019s  think  about  the  permutation  that  rearranges  the  input  vector. The order \nin which  the  leaves  appear  in Figure  30.5  is a bit-reversal  permutation . That \nis, letting rev.k/  be the lg n-bit  integer  formed  by  reversing  the  bits  of the  bi-  \nnary representation of k, then vector element a k moves to position rev .k/. In \nFigure  30.5,  for  example,  the  leaves  appear  in the  order  0;4;2;6;1;5;3;7 . This \nsequence in binary is 000;100;010;110;001;101;011;111 , and you can obtain \nit by reversing the bits of each number in the sequ ence 0;1;2;3;4;6;7  or,  in bi-  \nnary, 000;001;010;011;100;101;110;111 . To see in general that the input vector \nshould  be rearranged  by  a bit-reversal  permutation,  note  that at the top level of the \ntree,  indices  whose  low-order  bit  is 0 go into the left subtree and indices whose \nlow-order  bit  is 1 go  into  the  right  subtree.  Stripping  off  the  low-order  bit  at each \nlevel, continue this process down the tree, until y ou get the order given by the \nbit-reversal  permutation  at the  leaves.  \nThe  full  FFT  circuit  \nFigure  30.6  depicts  the  entire  circuit  for  n D 8. The  circuit  begins  with  a bit-  \nreversal permutation of the inputs, followed by lg n stages, each stage consisting \nof n=2  butter\u00fcies  executed  in parallel.  Assuming  that  each  butter\u00fcy  circuit  has  \nconstant depth, the full circuit has depth \u201a.lg n/. The  butter\u00fcy  operations  at each  \nlevel of recursion in the FFT procedure are indepen dent, and so the  circuit  per-  \nforms  them  in parallel.  The  \u00fbgure  shows  wires  running  from  left to right, carrying \nvalues through the lg n stages. For s D 1;2;:::;  lg n, stage s consists of n=2  s \ngroups  of butter\u00fcies,  with  2 s\ue0021 butter\u00fcies  per  group.  The  twiddle  factors  in stage  s \nare ! 0 \nm ;!  1 \nm ;:::;!  m=2\ue0021 \nm , where m D 2 s . \nExercises  \n30.3-1  \nShow  the  values  on  the  wires  for  each  butter\u00fcy  input  and  outpu t in the FFT circuit \nof Figure  30.6,  given  the  input  vector  .0;2;3;  \ue0031;4;5;7;9/ . \n30.3-2  \nConsider an FFT n circuit,  such  as in Figure  30.6,  with  wires  0;1;:::;n  \ue003 1 (wire j \nhas output y j ) and  stages  numbered  as in the  \u00fbgure.  Stage  s , for s D 1;2:::;  lg n, \nconsists of n=2  s groups  of butter\u00fcies.  Which  two  wires  are  inputs  and  outputs  for \nthe j th butter\u00fcy  circuit  in the  gth group in stage s ? \n30.3-3  \nConsider a b-bit  integer  k in the range 0 \u0dc4 k < 2  b . Treating k as a b-element  \nvector over f0;1g, describe a b \ue005 b matrix M  such  that  the  matrix-vector  product  \nMk  is the binary representation of rev .k/. 898  Chapter  30  Polynomials  and  the  FFT  \na 0 \na 1 \na 2 \na 3 \na 4 \na 5 \na 6 \na 7 y 0 \ny 1 \ny 2 \ny 3 \ny 4 \ny 5 \ny 6 \ny 7 \nstage s D 1 stage s D 2 stage s D 3 ! 0 \n2 ! 0 \n2 ! 0 \n2 ! 0 \n2 \n! 0 \n4 ! 0 \n4 \n! 1 \n4 ! 1 \n4 \n! 0 \n8 \n! 1 \n8 \n! 2 \n8 \n! 3 \n8 \nFigure  30.6  A full circuit that computes the FFT in parallel, h ere shown for n D 8 inputs. It has \nlg n stages, and each stage comprises n=2  butter\u00fcies  that  can  operate  in parallel.  As  in Figure  30.4,  \nonly  the  top  and  bottom  wires  entering  a butter\u00fcy  interact  with  it. For  example,  the  top  butter\u00fcy  in \nstage 2 has inputs and outputs only on wires 0 and 2 (the wires with outputs y 0 and y 2 , respectively). \nThis circuit has depth \u201a.lg n/ and performs \u201a.n  lg n/ butter\u00fcy  operations  altogether.  \n30.3-4  \nWrite pseudocode for the procedure B IT-REVERSE-PERMUTATION  .a;n/ , which \nperforms  the  bit-reversal  permutation  on  a vector  a of length n in-place.  Assume  \nthat you may call the procedure B IT-REVERSE-OF .k;b/ , which returns an integer \nthat is the b-bit  reversal  of the  nonnegative  integer  k, where 0 \u0dc4 k<2  b . \n? 30.3-5  \nSuppose  that  the  adders  within  the  butter\u00fcy  operations  of a given  FFT  circuit  some-  \ntimes fail in such a manner that they always produc e a 0 output, independent of \ntheir inputs. In addition, suppose that exactly one  adder has failed,  but  you  don\u2019t  \nknow which one. Describe how you can identify the f ailed adder by supplying \ninputs to the overall FFT circuit and observing the  outputs. How  ef\u00fbcient  is your  \nmethod?  Problems for Chapter 30 899 \nProblems  \n30-1  Divide-and-conquer  multiplication  \na. Show how to multiply two linear polynomials ax  C b and cx  C d using only \nthree multiplications. ( Hint: One  of the  multiplications  is .a C b/ \ue001 .c C d/.) \nb. Give  two  divide-and-conquer  algorithms  for  multiplying  two polynomials of \ndegree-bound  n in \u201a.n  lg 3 / time.  The  \u00fbrst  algorithm  should  divide  the  input  \npolynomial  coef\u00fbcients  into  a high  half  and  a low  half,  and  the second algorithm \nshould divide them according to whether their index  is odd or even. \nc. Show how to multiply two n-bit  integers  in O.n  lg 3 / steps, where each step \noperates on at most a constant number of 1-bit  values.  \n30-2  Multidimensional  fast  Fourier  transform  \nThe 1-dimensional  discrete  Fourier  transform  de\u00fbned  by  equation  (30.8)  general-  \nizes to d dimensions. The input is a d -dimensional  array  A D .a j 1 ;j 2 ;:::;j  d / whose \ndimensions are n 1 ;n  2 ;:::;n  d , where n 1 n 2 \ue001 \ue001 \ue001  n d D n. The d -dimensional  discrete  \nFourier  transform  is de\u00fbned  by  the  equation  \ny k 1 ;k  2 ;:::;k  d D n 1 \ue0021 X  \nj 1 D0 n 2 \ue0021 X  \nj 2 D0 \ue001 \ue001 \ue001  n d \ue0021 X  \nj d D0 a j 1 ;j 2 ;:::;j  d ! j 1 k 1 \nn 1 ! j 2 k 2 \nn 2 \ue001 \ue001 \ue001  ! j d k d \nn d \nfor 0 \u0dc4 k 1 <n  1 , 0 \u0dc4 k 2 <n  2 , . . . , 0 \u0dc4 k d <n  d . \na. Show how to produce a d -dimensional  DFT  by  computing  1-dimensional  DFTs  \non  each  dimension  in turn.  That  is, \u00fbrst  compute  n=n  1 separate 1-dimensional  \nDFTs along dimension 1. Then,  using  the  result  of the  DFTs  along  dimen-  \nsion 1 as the input, compute n=n  2 separate 1-dimensional  DFTs  along  dimen-  \nsion 2. Using this result as the input, compute n=n  3 separate 1-dimensional  \nDFTs along dimension 3, and so on, through dimension d . \nb. Show that the ordering of dimensions does not matte r, so that if you compute \nthe 1-dimensional  DFTs  in any  order  of the  d dimensions, you compute the \nd -dimensional  DFT.  \nc. Show that if you compute each 1-dimensional  DFT  by  computing  the  fast  \nFourier transform, the total time to compute a d -dimensional  DFT  is O.n  lg n/, \nindependent of d . 900  Chapter  30  Polynomials  and  the  FFT  \n30-3  Evaluating  all  derivatives  of a polynomial  at a point  \nGiven  a polynomial  A.x/  of degree-bound  n, we  de\u00fbne  its  t th derivative by \nA .t/  .x/  D \u201e \nA.x/  if t D 0;  \nd \ndx  A .t \ue0021/  .x/  if 1 \u0dc4 t \u0dc4 n \ue003 1;  \n0 if t \ue004 n:  \nIn this problem, you will show how to determine A .t/  .x 0 / for t D 0;1;:::;n  \ue003 1, \ngiven  the  coef\u00fbcient  representation  .a 0 ;a  1 ;:::;a  n\ue0021 / of A.x/  and a point x 0 . \na. Given  coef\u00fbcients  b 0 ;b  1 ;:::;b  n\ue0021 such that \nA.x/  D n\ue0021 X  \nj D0 b j .x \ue003 x 0 / j ; \nshow how to compute A .t/  .x 0 /, for t D 0;1;:::;n  \ue003 1, in O.n/  time. \nb. Explain  how  to \u00fbnd  b 0 ;b  1 ;:::;b  n\ue0021 in O.n  lg n/ time, given A.x  0 C ! k \nn / for \nk D 0;1;:::;n  \ue003 1. \nc. Prove that \nA.x  0 C ! k \nn / D n\ue0021 X  \nr D0 \ue001 \n! kr  \nn \nr\u0160 n\ue0021 X  \nj D0 f.j/g.r  \ue003 j/  ! \n; \nwhere f.j/  D a j \ue001 j\u0160 and \ng.l/  D ( \nx \ue002l \n0 =.\ue003l/\u0160  if \ue003.n \ue003 1/ \u0dc4 l \u0dc4 0;  \n0 if 1 \u0dc4 l \u0dc4 n \ue003 1:  \nd. Explain how to evaluate A.x  0 C ! k \nn / for k D 0;1;:::;n  \ue003 1 in O.n  lg n/ \ntime. Conclude that you can evaluate all nontrivial  derivatives of A.x/  at x 0 in \nO.n  lg n/ time. \n30-4  Polynomial  evaluation  at multiple  points  \nProblem  2-3  showed  how  to evaluate  a polynomial  of degree-bo und n at a single \npoint in O.n/  time  using  Horner\u2019s  rule.  This  chapter  described  how  to evaluate \nsuch a polynomial at all n complex roots of unity in O.n  lg n/ time using the FFT. \nNow,  you  will  show  how  to evaluate  a polynomial  of degree-bou nd n at n arbitrary \npoints in O.n  lg 2 n/ time. Problems for Chapter 30 901 \nTo do so, assume that you can compute the polynomia l remainder when one such \npolynomial is divided by another in O.n  lg n/ time. For example, the remainder of \n3x  3 C x 2 \ue003 3x  C 1 when divided by x 2 C x C 2 is \n.3x  3 C x 2 \ue003 3x  C 1/ mod .x 2 C x C 2/ D \ue0037x  C 5:  \nGiven  the  coef\u00fbcient  representation  of a polynomial  A.x/  D P  n\ue0021 \nkD0 a k x k and \nn points x 0 ;x  1 ;:::;x  n\ue0021 , your goal is to compute the n values A.x  0 /;A.x  1 /;:::;  \nA.x  n\ue0021 /. For 0 \u0dc4 i \u0dc4 j \u0dc4 n \ue003 1, de\u00fbne  the  polynomials  P ij .x/  D Q  j \nkDi .x \ue003 x k / \nand Q ij .x/  D A.x/  mod P ij .x/. Note that Q ij .x/  has degree at most j \ue003 i . \na. Prove that A.x/  mod .x \ue003 \u00b4/ D A.\u00b4/  for any point \u00b4. \nb. Prove that Q kk  .x/  D A.x  k / and that Q 0;n\ue0021 .x/  D A.x/ . \nc. Prove that for i \u0dc4 k \u0dc4 j , we have both Q ik  .x/  D Q ij .x/  mod P ik  .x/  and \nQ kj  .x/  D Q ij .x/  mod P kj  .x/. \nd. Give  an O.n  lg 2 n/-time  algorithm  to evaluate  A.x  0 /;A.x  1 /;:::;A.x  n\ue0021 /. \n30-5  FFT  using  modular  arithmetic  \nAs  de\u00fbned,  the  discrete  Fourier  transform  requires  computa tion with complex \nnumbers,  which  can  result  in a loss  of precision  due  to round- off errors. For some \nproblems, the answer is known to contain only integ ers, and a variant of the FFT \nbased on modular arithmetic can guarantee that the answer is calculated exactly. \nAn example of such a problem is that of multiplying  two polynomials with integer \ncoef\u00fbcients.  Exercise  30.2-6  gives  one  approach,  using  a modulus of length \ufffd.n/  \nbits to handle a DFT on n points. This problem explores another approach that  \nuses a modulus of the more reasonable length O.lg n/, but it requires that you \nunderstand  the  material  of Chapter  31.  Let  n be an exact power of 2. \na. You wish to search for the smallest k such that p D kn  C 1 is prime.  Give  \na simple heuristic argument why you might expect k to be approximately ln n. \n(The value of k might be much larger or smaller, but you can reason ably expect \nto examine O.lg n/ candidate values of k on average.) How does the expected \nlength of p compare to the length of n? \nLet g be a generator of Z \ue003 \np , and let w D g k mod p. \nb. Argue  that  the  DFT  and  the  inverse  DFT  are  well-de\u00fbned  invers e operations \nmodulo p, where w is used as a principal nth root of unity. \nc. Show how to make the FFT and its inverse work modul o p in O.n  lg n/ time, \nwhere operations on words of O.lg n/ bits take unit time. Assume that the \nalgorithm is given p and w. 902  Chapter  30  Polynomials  and  the  FFT  \nd. Compute the DFT modulo p D 17  of the vector .0;5;3;7;7;2;1;6/ . (Hint: \nVerify and use the fact that g D 3 is a generator of Z \ue003 \n17  .) \nChapter  notes  \nVan  Loan\u2019s  book  [442]  provides  an outstanding  treatment  of the  fast  Fourier  trans-  \nform.  Press,  Teukolsky,  Vetterling,  and  Flannery  [365,  366]  offer  a good  descrip-  \ntion of the fast Fourier transform and its applicat ions. For an excellent introduction \nto signal processing, a popular FFT application are a, see the texts  by  Oppenheim  \nand  Schafer  [347]  and  Oppenheim  and  Willsky  [348].  The  Oppen heim and Schafer \nbook also shows how to handle cases in which n is not an exact power of 2. \nFourier analysis is not limited to 1-dimensional  data.  It is widely  used  in image  \nprocessing to analyze data in two or more dimension s. The books by  Gonzalez  \nand  Woods  [194]  and  Pratt  [363]  discuss  multidimensional  Fourier transforms and \ntheir use in image processing, and books by Tolimie ri, An, and Lu  [439]  and  Van  \nLoan  [442]  discuss  the  mathematics  of multidimensional  fast Fourier transforms. \nCooley  and  Tukey  [101]  are  widely  credited  with  devising  the  FFT  in the  1960s.  \nThe FFT had in fact been discovered many times prev iously, but its importance was \nnot fully realized before the advent of modern digi tal computers. Although Press, \nTeukolsky, Vetterling, and Flannery attribute the o rigins of the method to Runge \nand  K\u00a8  onig  in 1924,  an article  by  Heideman,  Johnson,  and  Burrus  [211]  traces  the  \nhistory  of the  FFT  as far  back  as C. F. Gauss  in 1805.  \nFrigo  and  Johnson  [161]  developed  a fast  and  \u00fcexible  impleme ntation of the \nFFT, called FFTW (<fastest Fourier transform in the  West=). FFTW is designed for \nsituations requiring multiple DFT computations on t he same problem size. Before \nactually computing the DFTs, FFTW executes a <plann er,= which, by a series of \ntrial runs, determines how best to decompose the FF T computation for the given \nproblem size on the host machine. FFTW adapts to us e the hardware  cache  ef-  \n\u00fbciently,  and  once  subproblems  are  small  enough,  FFTW  solves  them  with  opti-  \nmized,  straight-line  code.  Moreover,  FFTW  has  the  advantag e of taking \u201a.n  lg n/ \ntime for any problem size n, even when n is a large prime. \nAlthough the standard Fourier transform assumes tha t the input represents points \nthat are uniformly spaced in the time domain, other  techniques can approximate the \nFFT  on  <nonequispaced=  data.  The  article  by  Ware  [449]  provi des an overview. 31  Number-Theoretic  Algorithms  \nNumber theory was once viewed as a beautiful but la rgely useless subject in pure \nmathematics.  Today  number-theoretic  algorithms  are  used  widely, due in large part \nto the invention of cryptographic schemes based on large prime numbers. These \nschemes  are  feasible  because  we  can  \u00fbnd  large  primes  quickly  , and they are secure \nbecause we do not know how to factor the product of  large primes (or solve related \nproblems,  such  as computing  discrete  logarithms)  ef\u00fbcient ly. This chapter presents \nsome of the number theory and related algorithms th at underlie such applications. \nWe  start  in Section  31.1  by  introducing  basic  concepts  of number theory, such \nas divisibility, modular equivalence, and unique pr ime factorization.  Section  31.2  \nstudies  one  of the  world\u2019s  oldest  algorithms:  Euclid\u2019s  algorithm for computing \nthe  greatest  common  divisor  of two  integers,  and  Section  31.3  reviews  concepts  \nof modular  arithmetic.  Section  31.4  then  explores  the  set  of multiples of a given \nnumber a, modulo n, and  shows  how  to \u00fbnd  all  solutions  to the  equation  ax  D b \n.mod n/ by  using  Euclid\u2019s  algorithm.  The  Chinese  remainder  theorem  is presented \nin Section  31.5.  Section  31.6  considers  powers  of a given  number a, modulo n, \nand  presents  a repeated-squaring  algorithm  for  ef\u00fbciently  computing a b mod n, \ngiven a, b, and n. This  operation  is at the  heart  of ef\u00fbcient  primality  testin g and of \nmuch  modern  cryptography,  such  as the  RSA  public-key  crypto system described in \nSection  31.7.  We  wrap  up  in Section  31.8,  which  examines  a randomized primality \ntest.  This  test  \u00fbnds  large  primes  ef\u00fbciently,  an essential  step in creating keys for \nthe RSA cryptosystem. \nSize  of inputs  and  cost  of arithmetic  computations  \nBecause  we\u2019ll  be working  with  large  integers,  we  need  to adjust how to think about \nthe size of an input and about the cost of elementa ry arithmetic operations. \nIn this chapter, a <large input= typically means an  input containing  <large  in-  \ntegers= rather than an input containing <many integ ers= (as for sorting). Thus, \nthe size of an input depends on the number  of bits  required  to represent  that  in-  \nput, not just the number of integers in the input. An algorithm with  integer  in-  904  Chapter  31  Number-Theoretic  Algorithms  \nputs a 1 ;a  2 ;:::;a  k is a polynomial-time  algorithm  if it runs in time polynomial \nin lg a 1 ; lg a 2 ;:::;  lg a k , that  is, polynomial  in the  lengths  of its  binary-encoded  \ninputs. \nMost of this book considers the elementary arithmet ic operations  (multiplica-  \ntions, divisions, or computing remainders) as primi tive operations that take one unit \nof time. Counting the number of such arithmetic ope rations that  an algorithm  per-  \nforms provides a basis for making a reasonable esti mate of the algorithm\u2019s  actual  \nrunning time on a computer. Elementary operations c an be time-consuming,  how-  \never, when their inputs are large. It thus becomes appropriate to measure how many \nbit  operations  a number-theoretic  algorithm  requires.  In this  model,  multiplying \ntwo \u02c7-bit  integers  by  the  ordinary  method  uses  \u201a.\u02c7  2 / bit  operations.  Similarly,  di-  \nviding a \u02c7-bit  integer  by  a shorter  integer  or taking  the  remainder  of a \u02c7-bit  integer  \nwhen divided by a shorter integer requires \u201a.\u02c7  2 / time by simple algorithms. (See \nExercise  31.1-12.)  Faster  methods  are  known.  For  example,  a simple  divide-and-  \nconquer method for multiplying two \u02c7-bit  integers  has  a running  time  of \u201a.\u02c7  lg 3 /, \nand O.\u02c7  lg \u02c7 lg lg \u02c7/  time is possible. For practical purposes, however, the \u201a.\u02c7  2 / \nalgorithm is often best, and we use this bound as a  basis for our analyses. In this \nchapter,  we\u2019ll  usually  analyze  algorithms  in terms  of both  the number of arithmetic \noperations and the number of bit operations they re quire. \n31.1  Elementary  number-theoretic  notions  \nThis section provides a brief review of notions fro m elementary number theory \nconcerning the set Z D f:::;  \ue0032; \ue0031;0;1;2;:::  g of integers and the set N D \nf0;1;2;::: g of natural numbers. \nDivisibility  and  divisors  \nThe notion of one integer being divisible by anothe r is key to the theory of numbers. \nThe notation d j a (read <d divides  a=) means that a D kd  for some integer k. \nEvery integer divides 0. If a>0  and d j a, then jd j \u0dc4 jaj. If d j a, then we also \nsay that a is a multiple  of d . If d does not divide a, we write d \u2212 a. \nIf d j a and d \ue004 0, then d is a divisor  of a. Since d j a if and only if \ue003d j a, \nwithout  loss  of generality,  we  de\u00fbne  the  divisors  of a to be nonnegative, with the \nunderstanding that the negative of any divisor of a also divides a. A divisor of a \nnonzero integer a is at least 1 but not greater than jaj. For example, the divisors \nof 24  are 1, 2, 3, 4, 6, 8, 12, and 24. \nEvery positive integer a is divisible by the trivial  divisors  1 and a. The nontrivial \ndivisors of a are the factors  of a. For example, the factors of 20  are 2, 4, 5, and 10. 31.1  Elementary  number-theoretic  notions  905 \nPrime  and  composite  numbers  \nAn integer a > 1  whose only divisors are the trivial divisors 1 and a is a prime  \nnumber  or, more simply, a prime . Primes have many special properties and play a \ncritical  role  in number  theory.  The  \u00fbrst  20  primes, in order, are \n2; 3; 5; 7; 11;  13;  17;  19;  23;  29;  31;  37;  41;  43;  47;  53;  59;  61;  67;  71  : \nExercise  31.1-2  asks  you  to prove  that  there  are  in\u00fbnitely  many primes. An integer \na>1  that is not prime is a composite  number  or, more simply, a composite . For \nexample, 39  is composite because 3 j 39. We call the integer 1 a unit, and it is \nneither prime nor composite. Similarly, the integer  0 and all negative integers are \nneither prime nor composite. \nThe  division  theorem,  remainders,  and  modular  equivalence  \nGiven  an integer  n, we can partition the integers into those that are  multiples of n \nand those that are not multiples of n. Much  number  theory  is based  upon  re\u00fbning  \nthis partition by classifying the integers that are  not multiples of n according to \ntheir remainders when divided by n. The following theorem provides the basis for \nthis  re\u00fbnement.  We  omit  the  proof  (but  see,  for  example,  Nive n and Zuckerman \n[345]).  \nTheorem  31.1  (Division  theorem)  \nFor any integer a and any positive integer n, there exist unique integers q and r \nsuch that 0 \u0dc4 r<n  and a D qn  C r . \nThe value q D ba=nc is the quotient  of the division. The value r D a mod n is \nthe remainder  (or residue ) of the division, so that n j a if and only if a mod n D 0. \nThe integers partition into n equivalence classes according to their remainders \nmodulo n. The equivalence  class  modulo  n containing an integer a is \n\u0152a\ufffd  n D fa C kn  W k 2 Zg : \nFor example, \u01523\ufffd  7 D f:::;  \ue00311;  \ue0034;3;10;17;:::  g, and \u0152\ue0034\ufffd 7 and \u015210\ufffd  7 also denote \nthis  set.  With  the  notation  de\u00fbned  on  page  64,  writing  a 2 \u0152b\ufffd  n is the same as \nwriting a D b .mod n/. The set of all such equivalence classes is \nZ n D f\u0152a\ufffd  n W 0 \u0dc4 a \u0dc4 n \ue003 1g : (31.1)  \nWhen  you  see  the  de\u00fbnition  \nZ n D f0;1;:::;n  \ue003 1g ; (31.2)  \nyou  should  read  it as equivalent  to equation  (31.1)  with  the  understanding that \n0 represents \u01520\ufffd  n , 1 represents \u01521\ufffd  n , and so on. Each class is represented by its 906  Chapter  31  Number-Theoretic  Algorithms  \nsmallest nonnegative element. You should keep the u nderlying equivalence classes \nin mind, however. For example, if we refer to \ue0031 as a member of Z n , we are really \nreferring to \u0152n \ue003 1\ufffd n , since \ue0031 D n \ue003 1 .mod n/. \nCommon  divisors  and  greatest  common  divisors  \nIf d is a divisor of a and d is also a divisor of b, then d is a common  divisor  of \na and b. For example, the divisors of 30  are 1, 2, 3, 5, 6, 10, 15, and 30, and so \nthe common divisors of 24  and 30  are 1, 2, 3, and 6. Any pair of integers has a \ncommon divisor of 1. \nAn important property of common divisors is that \nif d j a and d j b, then d j .a C b/ and d j .a \ue003 b/:  (31.3)  \nMore generally, for any integers x and y , \nif d j a and d j b, then d j .ax  C by/:  (31.4)  \nAlso, if a j b, then either jaj \u0dc4 jbj or b D 0, which implies that \nif a j b and b j a, then a D \u00dbb:  (31.5)  \nThe greatest  common  divisor  of two integers a and b which are not both 0, de-  \nnoted by gcd.a;b/ , is the largest of the common divisors of a and b. For example, \ngcd.24;30/  D 6, gcd.5;7/  D 1, and gcd.0;9/  D 9. If a and b are both nonzero, \nthen gcd.a;b/  is an integer between 1 and min fjaj; jbjg. We  de\u00fbne  gcd.0;0/  to \nbe 0, so that standard properties of the gcd function ( such as equation  (31.9)  be-  \nlow) hold universally. \nExercise  31.1-9  asks  you  to prove  the  following  elementary  properties of the gcd \nfunction: \ngcd.a;b/  D gcd.b;a/;  (31.6)  \ngcd.a;b/  D gcd.\ue003a;b/;  (31.7)  \ngcd.a;b/  D gcd.jaj; jbj/; (31.8)  \ngcd.a;0/  D jaj ; (31.9)  \ngcd.a;ka/  D jaj for any k 2 Z : (31.10)  \nThe following theorem provides an alternative and u seful way to characterize \ngcd.a;b/ . \nTheorem  31.2  \nIf a and b are any integers, not both zero, then gcd .a;b/  is the smallest positive \nelement of the set fax  C by  W x;y  2 Zg of linear combinations of a and b. 31.1  Elementary  number-theoretic  notions  907 \nProof  Let s be the smallest positive such linear combination of  a and b, and let \ns D ax  C by  for some x;y  2 Z. Let q D ba=s  c. Equation  (3.11)  on  page  64  then  \nimplies \na mod s D a \ue003 qs  \nD a \ue003 q.ax  C by/  \nD a.1  \ue003 qx/  C b.\ue003qy/  ; \nso that a mod s is a linear combination of a and b as well. Because s is the  small-  \nest positive such linear combination and 0 \u0dc4 a mod s < s  (inequality  (3.12)  on  \npage  64),  a mod s cannot be positive. Hence, a mod s D 0. Therefore, we have \nthat s j a and, by analogous reasoning, s j b. Thus, s is a common divisor of a \nand b, so that gcd.a;b/  \ue004 s . By  de\u00fbnition,  gcd.a;b/  divides both a and b, and \ns is de\u00fbned  as a linear  combination  of a and b. Equation  (31.4)  therefore  implies  \nthat gcd.a;b/  j s . But gcd.a;b/  j s and s > 0  imply that gcd .a;b/  \u0dc4 s . Com-  \nbining gcd.a;b/  \ue004 s and gcd.a;b/  \u0dc4 s yields gcd.a;b/  D s . We conclude that s , \nthe smallest positive linear combination of a and b, is also their greatest common \ndivisor. \nTheorem  31.2  engenders  three  useful  corollaries.  \nCorollary  31.3  \nFor any integers a and b, if d j a and d j b, then d j gcd.a;b/ . \nProof  This  corollary  follows  from  equation  (31.4)  and  Theorem  31.2, because \ngcd.a;b/  is a linear combination of a and b, \nCorollary  31.4  \nFor all integers a and b and any nonnegative integer n, we have \ngcd.an;bn/  D n gcd.a;b/:  \nProof  If n D 0, the corollary is trivial. If n>0 , then gcd.an;bn/  is the smallest \npositive element of the set fanx  C bny  W x;y  2 Zg, which in turn is n times the \nsmallest positive element of the set fax  C by  W x;y  2 Zg. \nCorollary  31.5  \nFor all positive integers n, a, and b, if n j ab  and gcd.a;n/  D 1, then n j b. \nProof  Exercise  31.1-5  asks  you  to provide  the  proof.  908  Chapter  31  Number-Theoretic  Algorithms  \nRelatively  prime  integers  \nTwo integers a and b are relatively  prime  if their only common divisor is 1, that \nis, if gcd.a;b/  D 1. For example, 8 and 15  are relatively prime, since the divisors \nof 8 are 1, 2, 4, and 8, and the divisors of 15  are 1, 3, 5, and 15. The following \ntheorem states that if two integers are each relati vely prime to an integer p, then \ntheir product is relatively prime to p. \nTheorem  31.6  \nFor any integers a, b, and p, we have gcd.ab;p/  D 1 if and only if gcd .a;p/  D 1 \nand gcd.b;p/  D 1 both hold. \nProof  If gcd.a;p/  D 1 and gcd.b;p/  D 1, then  it follows  from  Theorem  31.2  \nthat there exist integers x , y , x 0 , and y 0 such that \nax  C py  D 1;  \nbx  0 C py  0 D 1:  \nMultiplying these equations and rearranging gives \nab.xx  0 / C p.ybx  0 C y 0 ax  C pyy  0 / D 1:  \nSince 1 is thus a positive linear combination of ab  and p, it is the smallest positive \nlinear  combination.  Applying  Theorem  31.2  implies  gcd.ab;p/  D 1, completing \nthe proof in this direction. \nConversely, if gcd .ab;p/  D 1, then  Theorem  31.2  implies  that  there  exist  inte-  \ngers x and y such that \nabx  C py  D 1:  \nWriting abx  as a.bx/  and  applying  Theorem  31.2  again  proves  that  gcd.a;p/  D 1. \nProving that gcd .b;p/  D 1 is similar. \nIntegers n 1 , n 2 , . . . , n k are pairwise  relatively  prime  if gcd.n i ;n  j / D 1 for \n1 \u0dc4 i<j  \u0dc4 k. \nUnique  prime  factorization  \nAn elementary but important fact about divisibility  by primes is the following. \nTheorem  31.7  \nFor all primes p and all integers a and b, if p j ab, then p j a or p j b (or both). \nProof  Assume for the purpose of contradiction that p j ab, but that p \u2212 a and \np \u2212 b. Because p > 1  and ab  D kp  for some k 2 Z, equation  (31.10)  gives  31.1  Elementary  number-theoretic  notions  909 \nthat gcd.ab;p/  D p. We also have that gcd .a;p/  D 1 and gcd.b;p/  D 1, since \nthe only divisors of p are 1 and p, and we assumed that p divides neither a nor b. \nTheorem  31.6  then  implies  that  gcd.ab;p/  D 1, contradicting gcd .ab;p/  D p. \nThis contradiction completes the proof. \nA consequence  of Theorem  31.7  is that  any  composite  integer  can be uniquely \nfactored  into  a product  of primes.  Exercise  31.1-11  asks  you  to provide a proof. \nTheorem  31.8  (Unique  prime  factorization)  \nThere is exactly one way to write any composite int eger a as a product of the form \na D p e 1 \n1 p e 2 \n2 \ue001 \ue001 \ue001  p e r \nr ; \nwhere the p i are prime, p 1 <p  2 < \ue001 \ue001 \ue001  <p  r , and the e i are positive integers. \nAs an example, the unique prime factorization of th e number 6000  is 2 4 \ue001 3 1 \ue001 5 3 . \nExercises  \n31.1-1  \nProve that if a>b>0  and c D a C b, then c mod a D b. \n31.1-2  \nProve  that  there  are  in\u00fbnitely  many  primes.  (Hint: Show that none of the primes \np 1 ;p  2 ;:::;p  k divide .p  1 p 2 \ue001 \ue001 \ue001  p k / C 1.) \n31.1-3  \nProve that if a j b and b j c , then a j c . \n31.1-4  \nProve that if p is prime and 0<k<p , then gcd.k;p/  D 1. \n31.1-5  \nProve  Corollary  31.5.  \n31.1-6  \nProve that if p is prime and 0<k<p , then p j \u00e3 p \nk \u00e4 \n. Conclude that for all integers \na and b and all primes p, \n.a C b/ p D a p C b p .mod p/:  \n31.1-7  \nProve that if a and b are any positive integers such that a j b, then 910  Chapter  31  Number-Theoretic  Algorithms  \n.x mod b/ mod a D x mod a \nfor any x . Prove, under the same assumptions, that \nx D y .mod b/ implies x D y .mod a/ \nfor any integers x and y . \n31.1-8  \nFor any integer k>0 , an integer n is a kth power  if there exists an integer a such \nthat a k D n. Furthermore, n > 1  is a nontrivial  power  if it is a kth power for \nsome integer k >1 . Show how to determine whether a given \u02c7-bit  integer  n is a \nnontrivial power in time polynomial in \u02c7. \n31.1-9  \nProve  equations  (31.6)3(31.10).  \n31.1-10  \nShow that the gcd operator is associative. That is,  prove that for all integers a, b, \nand c , we have \ngcd.a;  gcd.b;c//  D gcd.gcd.a;b/;c/:  \n? 31.1-11  \nProve  Theorem  31.8.  \n31.1-12  \nGive  ef\u00fbcient  algorithms  for  the  operations  of dividing  a \u02c7-bit  integer  by  a shorter  \ninteger and of taking the remainder of a \u02c7-bit  integer  when  divided  by  a shorter  \ninteger. Your algorithms should run in \u201a.\u02c7  2 / time. \n31.1-13  \nGive  an ef\u00fbcient  algorithm  to convert  a given  \u02c7-bit  (binary)  integer  to a decimal  \nrepresentation. Argue that if multiplication or div ision of integers whose length \nis at most \u02c7 takes M.\u02c7/  time, where M.\u02c7/  D \ufffd.\u02c7/, then  you  can  convert  bi-  \nnary to decimal in O.M.\u02c7/  lg \u02c7/  time. ( Hint: Use  a divide-and-conquer  approach,  \nobtaining the top and bottom halves of the result w ith separate recursions.) \n31.1-14  \nProfessor Marshall sets up n lightbulbs in a row. The lightbulbs all have switch es, \nso that if he presses a bulb, it toggles on if it w as off and off i f it was  on.  The  light-  \nbulbs all start off. For i D 1;2;3;:::;n , the professor presses bulb i;2i;3i;::: . \nAfter  the  last  press,  which  lightbulbs  are  on?  Prove  your  answer. 31.2  Greatest  common  divisor  911 \n31.2  Greatest  common  divisor  \nIn this  section,  we  describe  Euclid\u2019s  algorithm  for  ef\u00fbciently  computing  the  great-  \nest common divisor of two integers. When we analyze  the running  time,  we\u2019ll  see  a \nsurprising connection with the Fibonacci numbers, w hich yield  a worst-case  input  \nfor  Euclid\u2019s  algorithm.  \nWe restrict ourselves in this section to nonnegativ e integers. This restriction is \njusti\u00fbed  by  equation  (31.8),  which  states  that  gcd.a;b/  D gcd.jaj; jbj/. \nIn principle, for positive integers a and b, their  prime  factorizations  suf\u00fbce  to \ncompute gcd.a;b/ . Indeed, if \na D p e 1 \n1 p e 2 \n2 \ue001 \ue001 \ue001  p e r \nr ; (31.11)  \nb D p f 1 \n1 p f 2 \n2 \ue001 \ue001 \ue001  p f r \nr ; (31.12)  \nwith 0 exponents being used to make the set of primes p 1 ;p  2 ;:::;p  r the same for \nboth a and b, then,  as Exercise  31.2-1  asks  you  to show,  \ngcd.a;b/  D p minfe 1 ;f  1 g \n1 p minfe 2 ;f  2 g \n2 \ue001 \ue001 \ue001  p minfe r ;f  r g \nr : (31.13)  \nThe best algorithms to date for factoring do not ru n in polynomial time. Thus, \nthis approach to computing greatest common divisors  seems unlikely to yield an \nef\u00fbcient  algorithm.  \nEuclid\u2019s  algorithm  for  computing  greatest  common  divisors  relies  on  the  follow-  \ning theorem. \nTheorem  31.9  (GCD  recursion  theorem)  \nFor any nonnegative integer a and any positive integer b, \ngcd.a;b/  D gcd.b;a  mod b/:  \nProof  We will show that gcd .a;b/  and gcd.b;a  mod b/ divide each other. Since \nthey  are  both  nonnegative,  equation  (31.5)  then  implies  that they must be equal. \nWe  \u00fbrst  show  that  gcd.a;b/  j gcd.b;a  mod b/. If we let d D gcd.a;b/ , then \nd j a and d j b. By  equation  (3.11)  on  page  64,  a mod b D a \ue003 qb, where \nq D ba=bc. Since a mod b is thus a linear combination of a and b, equation  (31.4)  \nimplies that d j .a mod b/. Therefore, since d j b and d j .a mod b/, Corol-  \nlary  31.3  implies  that  d j gcd.b;a  mod b/, that is, \ngcd.a;b/  j gcd.b;a  mod b/:  (31.14)  \nShowing that gcd .b;a  mod b/ j gcd.a;b/  is almost the same. If we now let \nd D gcd.b;a  mod b/, then d j b and d j .a mod b/. Since a D qb  C .a mod b/, 912  Chapter  31  Number-Theoretic  Algorithms  \nwhere q D ba=bc, we have that a is a linear combination of b and .a mod b/. By \nequation  (31.4),  we  conclude  that  d j a. Since d j b and d j a, we have that \nd j gcd.a;b/  by  Corollary  31.3,  so that  \ngcd.b;a  mod b/ j gcd.a;b/:  (31.15)  \nUsing  equation  (31.5)  to combine  equations  (31.14)  and  (31.15)  completes  the  \nproof. \nEuclid\u2019s  algorithm  \nEuclid\u2019s  Elements (circa  300  B. C. E.) describes  the  following  gcd  algorithm,  al-  \nthough its origin might be even earlier. The recurs ive procedure E UCLID imple-  \nments  Euclid\u2019s  algorithm,  based  directly  on  Theorem  31.9.  The inputs a and b are \narbitrary nonnegative integers. \nEUCLID.a;b/  \n1 if b == 0 \n2 return  a \n3 else  return  EUCLID.b;a  mod b/ \nFor example, here is how the procedure computes gcd .30;21/ : \nEUCLID.30;21/  D EUCLID.21;9/  \nD EUCLID.9;3/  \nD EUCLID.3;0/  \nD 3:  \nThis computation calls E UCLID recursively three times. \nThe correctness of E UCLID follows  from  Theorem  31.9  and  the  property  that  \nif the algorithm returns a in line 2, then b D 0, so that  by  equation  (31.9),  \ngcd.a;b/  D gcd.a;0/  D a. The  algorithm  cannot  recurse  inde\u00fbnitely,  since  the  \nsecond argument strictly decreases in each recursiv e call and  is always  nonnega-  \ntive. Therefore, E UCLID always terminates with the correct answer. \nThe  running  time  of Euclid\u2019s  algorithm  \nLet\u2019s  analyze  the  worst-case  running  time  of EUCLID as a function of the size \nof a and b. The overall running time of E UCLID is proportional to the number \nof recursive calls it makes. The analysis assumes t hat a > b  \ue004 0, that is, the \n\u00fbrst  argument  is greater  than  the  second  argument.  Why?  If b D a > 0 , then \na mod b D 0 and the procedure terminates after one recursive ca ll. If b>a  \ue004 0, 31.2  Greatest  common  divisor  913 \nthen the procedure makes just one more recursive ca ll than when a>b , because in \nthis case E UCLID.a;b/  immediately makes the recursive call E UCLID.b;a/ , and \nnow  the  \u00fbrst  argument  is greater  than  the  second.  \nOur  analysis  relies  on  the  Fibonacci  numbers  F k , de\u00fbned  by  the  recurrence  equa-  \ntion  (3.31)  on  page  69.  \nLemma  31.10  \nIf a > b  \ue004 1 and the call E UCLID.a;b/  performs k \ue004 1 recursive calls, then \na \ue004 F kC2 and b \ue004 F kC1 . \nProof  The proof proceeds by induction on k. For the base case of the induction, \nlet k D 1. Then, b \ue004 1 D F 2 , and since a>b , we must have a \ue004 2 D F 3 . Since \nb >.a  mod b/, in each  recursive  call  the  \u00fbrst  argument  is strictly  larger  than the \nsecond. The assumption that a>b  therefore holds for each recursive call. \nAssuming inductively that the lemma holds if the pr ocedure makes k \ue003 1 recur-  \nsive calls, we shall prove that the lemma holds for  k recursive calls. Since k>0 , \nwe have b > 0 , and E UCLID.a;b/  calls E UCLID.b;a  mod b/ recursively, which \nin turn makes k \ue003 1 recursive calls. The inductive hypothesis then impl ies that \nb \ue004 F kC1 (thus proving part of the lemma), and a mod b \ue004 F k . We have \nb C .a mod b/ D b C .a \ue003 b ba=bc/ (by  equation  (3.11))  \n\u0dc4 a;  \nsince a>b>0  implies ba=bc \ue004  1. Thus, \na \ue004 b C .a mod b/ \n\ue004 F kC1 C F k \nD F kC2 : \nThe following theorem is an immediate corollary of this lemma. \nTheorem  31.11  (Lam\u00b4  e\u2019s  theorem)  \nFor any integer k \ue004 1, if a >b  \ue004 1 and b <F  kC1 , then the call E UCLID.a;b/  \nmakes fewer than k recursive calls. \nTo  show  that  the  upper  bound  of Theorem  31.11  is the  best  possible,  we\u2019ll  show  \nthat the call E UCLID.F  kC1 ;F  k / makes exactly k \ue003 1 recursive calls when k \ue004 2. \nWe use induction on k. For the base case, k D 2, and the call E UCLID.F  3 ;F  2 / \nmakes exactly one recursive call, to E UCLID.1;0/ . (We have to start at k D 2, \nbecause when k D 1 we do not have F 2 > F  1 .) For  the  inductive  step,  as-  \nsume that E UCLID.F  k ;F  k\ue0021 / makes exactly k \ue003 2 recursive calls. For k > 2 , \nwe have F k >F  k\ue0021 >0  and F kC1 D F k C F k\ue0021 , and  so by  Exercise  31.1-1,  we  914  Chapter  31  Number-Theoretic  Algorithms  \nhave F kC1 mod F k D F k\ue0021 . Because E UCLID.a;b/  calls E UCLID.b;a  mod b/ \nwhen b > 0 , the call E UCLID.F  kC1 ;F  k / recurses one time more than the call \nEUCLID.F  k ;F  k\ue0021 /, or exactly k \ue003 1 times, which meets the upper bound given by \nTheorem  31.11.  \nSince F k is approximately \ufffd k = p \n5, where \ufffd is the golden ratio .1 C p \n5/=2  \nde\u00fbned  by  equation  (3.32)  on  page  69,  the  number  of recursive  calls in E UCLID \nis O.lg b/. (See  Exercise  31.2-5  for  a tighter  bound.)  Therefore,  a call of E UCLID \non two \u02c7-bit  numbers  performs  O.\u02c7/  arithmetic operations and O.\u02c7  3 / bit  opera-  \ntions (assuming that multiplication and division of  \u02c7-bit  numbers  take  O.\u02c7  2 / bit \noperations).  Problem  31-2  asks  you  to prove  an O.\u02c7  2 / bound on the number of bit \noperations. \nThe  extended  form  of Euclid\u2019s  algorithm  \nBy  rewriting  Euclid\u2019s  algorithm,  we  can  gain  additional  useful  information.  Specif-  \nically,  let\u2019s  extend  the  algorithm  to compute  the  integer  coef\u00fbcients  x and y such \nthat \nd D gcd.a;b/  D ax  C by;  (31.16)  \nwhere either or both of x and y may  be zero  or negative.  These  coef\u00fbcients  will  \nprove useful later for computing modular multiplica tive inverses. The procedure \nEXTENDED-EUCLID takes as input a pair of nonnegative integers and r eturns a \ntriple of the form .d;x;y/  that  satis\u00fbes  equation  (31.16).  As  an example,  Fig-  \nure  31.1  traces  out  the  call  EXTENDED-EUCLID .99;78/ . \nEXTENDED-EUCLID .a;b/  \n1 if b == 0 \n2 return  .a;1;0/  \n3 else  .d 0 ;x  0 ;y  0 / D EXTENDED-EUCLID .b;a  mod b/ \n4 .d;x;y/  D .d 0 ;y  0 ;x  0 \ue003 ba=bc y 0 / \n5 return  .d;x;y/  \nThe E XTENDED-EUCLID procedure is a variation of the E UCLID procedure. \nLine  1 is equivalent  to the  test  <b == 0= in line  1 of EUCLID . If b D 0, then \nEXTENDED-EUCLID returns not only d D a in line  2, but  also  the  coef\u00fbcients  \nx D 1 and y D 0, so that a D ax  C by  . If b \u00a4 0, EXTENDED-EUCLID \u00fbrst  \ncomputes .d 0 ;x  0 ;y  0 / such that d 0 D gcd.b;a  mod b/ and \nd 0 D bx  0 C .a mod b/y  0 : (31.17)  \nAs in the E UCLID procedure, we have d D gcd.a;b/  D d 0 D gcd.b;a  mod b/. \nTo obtain x and y such that d D ax  C by  , let\u2019s  rewrite  equation  (31.17),  setting  31.2  Greatest  common  divisor  915 \na b  ba=bc d x y \n99  78  1 3 \ue00311  14  \n78  21  3 3 3 \ue00311  \n21  15  1 3 \ue0032 3 \n15  6 2 3 1 \ue0032 \n6 3 2 3 0 1 \n3 0 4  3 1 0 \nFigure  31.1  How E XTENDED-EUCLID computes gcd.99;78/ . Each line shows one level of the \nrecursion: the values of the inputs a and b, the computed value ba=bc, and the values d , x, and y \nreturned. The triple .d;x;y/  returned becomes the triple .d 0 ;x  0 ;y  0 / used at the next higher level \nof recursion. The call E XTENDED-EUCLID.99;78/  returns .3;  \ue00311;14/ , so that gcd.99;78/  D 3 D \n99  \ue001 .\ue00311/  C 78  \ue001 14. \nd D d 0 and  using  equation  (3.11):  \nd D bx  0 C .a \ue003 b ba=bc/y 0 \nD ay  0 C b.x  0 \ue003 ba=bc y 0 /: \nThus, choosing x D y 0 and y D x 0 \ue003 ba=bc y 0 satis\u00fbes  the  equation  d D ax  C by  , \nthereby proving the correctness of E XTENDED-EUCLID . \nSince the number of recursive calls made in E UCLID is equal to the number \nof recursive calls made in E XTENDED-EUCLID , the running times of E UCLID \nand E XTENDED-EUCLID are the same, to within a constant factor. That is,  for \na>b>0 , the number of recursive calls is O.lg b/. \nExercises  \n31.2-1  \nProve  that  equations  (31.11)  and  (31.12)  imply  equation  (31.13).  \n31.2-2  \nCompute the values .d;x;y/  that the call E XTENDED-EUCLID .899;493/  returns. \n31.2-3  \nProve that for all integers a, k, and n, \ngcd.a;n/  D gcd.a C kn;n/:  (31.18)  \nUse  equation  (31.18)  to show  that  a D 1 .mod n/ implies gcd.a;n/  D 1. \n31.2-4  \nRewrite E UCLID in an iterative form that uses only a constant amou nt of memory \n(that is, stores only a constant number of integer values). 916  Chapter  31  Number-Theoretic  Algorithms  \n31.2-5  \nIf a>b  \ue004 0, show that the call E UCLID.a;b/  makes at most 1 C log \ue005 b recursive \ncalls. Improve this bound to 1 C log \ue005 .b=  gcd.a;b// . \n31.2-6  \nWhat does E XTENDED-EUCLID .F  kC1 ;F  k / return?  Prove  your  answer  correct.  \n31.2-7  \nDe\u00fbne  the  gcd  function  for  more  than  two  arguments  by  the  recursive equation \ngcd.a 0 ;a  1 ;:::;a  n / D gcd.a 0 ; gcd.a 1 ;a  2 ;:::;a  n //. Show that the gcd function \nreturns the same answer independent of the order in  which its arguments  are  speci-  \n\u00fbed.  Also  show  how  to \u00fbnd  integers  x 0 ;x  1 ;:::;x  n such that gcd.a 0 ;a  1 ;:::;a  n / D \na 0 x 0 C a 1 x 1 C \ue001 \ue001 \ue001 C  a n x n . Show that the number of divisions performed by yo ur \nalgorithm is O.n  C lg.max fa 0 ;a  1 ;:::;a  n g//. \n31.2-8  \nThe least  common  multiple  lcm.a 1 ;a  2 ;:::;a  n / of integers a 1 ;a  2 ;:::;a  n is the \nsmallest nonnegative integer that is a multiple of each a i . Show how to compute \nlcm.a 1 ;a  2 ;:::;a  n / ef\u00fbciently  using  the  (two-argument)  gcd  operation  as a sub-  \nroutine. \n31.2-9  \nProve that n 1 , n 2 , n 3 , and n 4 are pairwise relatively prime if and only if \ngcd.n 1 n 2 ;n  3 n 4 / D gcd.n 1 n 3 ;n  2 n 4 / D 1:  \nMore generally, show that n 1 ;n  2 ;:::;n  k are pairwise relatively prime if and only \nif a set of dlg ke pairs of numbers derived from the n i are relatively prime. \n31.3  Modular  arithmetic  \nInformally, you can think of modular arithmetic as arithmetic as usual over the \nintegers, except that when working modulo n, then every result x is replaced by \nthe element of f0;1;:::;n  \ue003 1g that is equivalent to x , modulo n (so that x is \nreplaced by x mod n). This  informal  model  suf\u00fbces  if you  stick  to the  operations  \nof addition, subtraction, and multiplication. A mor e formal model for modular \narithmetic, which follows, is best described within  the framework of group theory. 31.3  Modular  arithmetic  917 \nFinite  groups  \nA group  .S;  \u00dc/ is a set S together with a binary operation \u00dc de\u00fbned  on  S for \nwhich the following properties hold: \n1. Closure:  For all a;b  2 S , we have a \u00dc b 2 S . \n2. Identity:  There exists an element e 2 S , called the identity  of the group, such \nthat e \u00dc a D a \u00dc e D a for all a 2 S . \n3. Associativity:  For all a;b;c  2 S , we have .a \u00dc b/ \u00dc c D a \u00dc .b \u00dc c/. \n4. Inverses:  For each a 2 S , there exists a unique element b 2 S , called the \ninverse  of a, such that a \u00dc b D b \u00dc a D e. \nAs an example, consider the familiar group .Z; C/ of the integers Z under the \noperation of addition: 0 is the identity, and the inverse of a is \ue003a. An abelian  \ngroup  .S;  \u00dc/ satis\u00fbes  the  commutative  law  a \u00dc b D b \u00dc a for all a;b  2 S . The \nsize  of group .S;  \u00dc/ is jS j, and if jS j < 1, then .S;  \u00dc/ is a \u00fbnite  group . \nThe  groups  de\u00fbned  by  modular  addition  and  multiplication  \nWe  can  form  two  \u00fbnite  abelian  groups  by  using  addition  and  multiplication  mod-  \nulo n, where n is a positive integer. These groups are based on th e equivalence \nclasses of the integers modulo n, de\u00fbned  in Section  31.1.  \nTo  de\u00fbne  a group  on  Z n , we need suitable binary operations, which we obta in \nby  rede\u00fbning  the  ordinary  operations  of addition  and  multiplication.  We  can  de\u00fbne  \naddition and multiplication operations for Z n , because the equivalence class of two \nintegers uniquely determines the equivalence class of their sum or product. That \nis, if a D a 0 .mod n/ and b D b 0 .mod n/, then \na C b D a 0 C b 0 .mod n/;  \nab  D a 0 b 0 .mod n/:  \nThus,  we  de\u00fbne  addition  and  multiplication  modulo  n, denoted C n and \ue001 n , by \n\u0152a\ufffd  n C n \u0152b\ufffd  n D \u0152a C b\ufffd n ; (31.19)  \n\u0152a\ufffd  n \ue001 n \u0152b\ufffd  n D \u0152ab\ufffd  n : \n(We  can  de\u00fbne  subtraction  similarly  on  Z n by \u0152a\ufffd  n \ue003 n \u0152b\ufffd  n D \u0152a \ue003 b\ufffd n , but  di-  \nvision  is more  complicated,  as we\u2019ll  see.)  These  facts  justify the common and \nconvenient practice of using the smallest nonnegati ve element of each equivalence \nclass as its representative when performing computa tions in Z n . We add, subtract, \nand multiply as usual on the representatives, but w e replace each result x by the \nrepresentative of its class, that is, by x mod n. 918  Chapter  31  Number-Theoretic  Algorithms  \n0 1 2 3 4 5 \n0 \n1 \n2 \n3 \n4 \n5 0 1 2 3 4 5 \n0 1 2 3 4 5 0 1 2 3 4 5 \n0 1 2 3 4 5 \n0 1 2 3 4 5 \n0 1 2 3 4 5 \n(a) 1 2 4 7 8 11  13  14  \n1 \n2 \n4 \n7 \n8 \n11  \n13  \n14  1 2 4 7 8 11  13  14  \n2 4 8 14  1 7 11  13  \n4 8 1 13  2 14  7 11  \n7 14  13  4 11  2 1 8 \n8 1 2 11  4 13  14  7 \n11  7 14  2 13  1 8 4 \n13  11  7 1 14  8 4 2 \n14  13  11  8 7 4 2 1 \n(b) + 6 \u00b7 15  \nFigure  31.2  Two  \u00fbnite  groups.  Equivalence  classes  are  denoted  by  their  representative elements. \n(a)  The group .Z 6 ; C 6 /. (b)  The group .Z \ue003 \n15  ; \ue001 15  /. \nUsing  this  de\u00fbnition  of addition  modulo  n, we  de\u00fbne  the  additive  group  \nmodulo  n as .Z n ; C n /. The size of the additive group modulo n is jZ n j D  n. \nFigure  31.2(a)  gives  the  operation  table  for  the  group  .Z 6 ; C 6 /. \nTheorem  31.12  \nThe system .Z n ; C n / is a \u00fbnite  abelian  group.  \nProof  Equation  (31.19)  shows  that  .Z n ; C n / is closed.  Associativity  and  com-  \nmutativity of C n follow from the associativity and commutativity of C: \n.\u0152a\ufffd  n C n \u0152b\ufffd  n / C n \u0152c\ufffd  n D \u0152a C b\ufffd n C n \u0152c\ufffd  n \nD \u0152.a  C b/ C c\ufffd n \nD \u0152a C .b C c/\ufffd  n \nD \u0152a\ufffd  n C n \u0152b C c\ufffd n \nD \u0152a\ufffd  n C n .\u0152b\ufffd  n C n \u0152c\ufffd  n /; \n\u0152a\ufffd  n C n \u0152b\ufffd  n D \u0152a C b\ufffd n \nD \u0152b C a\ufffd n \nD \u0152b\ufffd  n C n \u0152a\ufffd  n : \nThe identity element of .Z n ; C n / is 0 (that is, \u01520\ufffd  n ). The (additive) inverse of an \nelement a (that is, of \u0152a\ufffd  n ) is the element \ue003a (that is, \u0152\ue003a\ufffd n or \u0152n \ue003 a\ufffd n ), since \n\u0152a\ufffd  n C n \u0152\ue003a\ufffd n D \u0152a \ue003 a\ufffd n D \u01520\ufffd  n . 31.3  Modular  arithmetic  919 \nUsing  the  de\u00fbnition  of multiplication  modulo  n, we  de\u00fbne  the  multiplicative  \ngroup  modulo  n as .Z \ue003 \nn ; \ue001 n /. The elements of this group are the set Z \ue003 \nn of elements \nin Z n that are relatively prime to n, so that each one has a unique inverse, modulo n: \nZ \ue003 \nn D f\u0152a\ufffd  n 2 Z n W gcd.a;n/  D 1g : \nTo see that Z \ue003 \nn is well  de\u00fbned,  note  that  for  0 \u0dc4 a <n , we have a D .a C kn/  \n.mod n/ for all integers k. By  Exercise  31.2-3,  therefore,  gcd.a;n/  D 1 implies \ngcd.a C kn;n/  D 1 for all integers k. Since \u0152a\ufffd  n D fa C kn  W k 2 Zg, the set Z \ue003 \nn \nis well  de\u00fbned.  An  example  of such  a group  is \nZ \ue003 \n15  D f1;2;4;7;8;11;13;14 g ; \nwhere the group operation is multiplication modulo 15. (We  have  denoted  an ele-  \nment \u0152a\ufffd  15  as a, and thus, for example, we denote \u01527\ufffd  15  as 7.) Figure  31.2(b)  shows  \nthe group .Z \ue003 \n15  ; \ue001 15  /. For example, 8 \ue001 11  D 13  .mod 15/, working in Z \ue003 \n15  . The \nidentity for this group is 1. \nTheorem  31.13  \nThe system .Z \ue003 \nn ; \ue001 n / is a \u00fbnite  abelian  group.  \nProof  Theorem  31.6  implies  that  .Z \ue003 \nn ; \ue001 n / is closed.  Associativity  and  commu-  \ntativity can be proved for \ue001 n as they were for C n in the  proof  of Theorem  31.12.  \nThe identity element is \u01521\ufffd  n . To show the existence of inverses, let a be an element \nof Z \ue003 \nn and let .d;x;y/  be returned by E XTENDED-EUCLID .a;n/ . Then we have \nd D 1, since a 2 Z \ue003 \nn , and \nax  C ny  D 1;  (31.20)  \nor equivalently, \nax  D 1 .mod n/:  \nThus \u0152x\ufffd  n is a multiplicative inverse of \u0152a\ufffd  n , modulo n. Furthermore, we claim \nthat \u0152x\ufffd  n 2 Z \ue003 \nn . To  see  why,  equation  (31.20)  demonstrates  that  the  smallest  pos-  \nitive linear combination of x and n must be 1. Therefore,  Theorem  31.2  implies  \nthat gcd.x;n/  D 1. We  defer  the  proof  that  inverses  are  uniquely  de\u00fbned  until  \nCorollary  31.26  in Section  31.4.  \nAs an example of computing multiplicative inverses,  suppose that a D 5 and \nn D 11. Then E XTENDED-EUCLID .a;n/  returns .d;x;y/  D .1;  \ue0032;1/, so that \n1 D 5 \ue001 .\ue0032/ C 11  \ue001 1. Thus, \u0152\ue0032\ufffd 11  (i.e., \u01529\ufffd  11  ) is the multiplicative inverse of \u01525\ufffd  11  . \nWhen working with the groups .Z n ; C n / and .Z \ue003 \nn ; \ue001 n / in the remainder of this \nchapter, we follow the convenient practice of denot ing equivalence classes by \ntheir representative elements and denoting the oper ations C n and \ue001 n by the usual 920  Chapter  31  Number-Theoretic  Algorithms  \narithmetic notations C and \ue001 (or juxtaposition, so that ab  D a \ue001 b) respectively. \nFurthermore, equivalences modulo n may also be interpreted as equations in Z n . \nFor example, the following two statements are equiv alent: \nax  D b .mod n/ \nand \n\u0152a\ufffd  n \ue001 n \u0152x\ufffd  n D \u0152b\ufffd  n : \nAs a further convenience, we sometimes refer to a g roup .S;  \u00dc/ merely as S \nwhen the operation \u00dc is understood from context. We may thus refer to th e groups \n.Z n ; C n / and .Z \ue003 \nn ; \ue001 n / as just Z n and Z \ue003 \nn , respectively. \nWe denote the (multiplicative) inverse of an elemen t a by .a \ue0021 mod n/. Division \nin Z \ue003 \nn is de\u00fbned  by  the  equation  a=b  D ab  \ue0021 .mod n/. For example, in Z \ue003 \n15  \nwe have that 7 \ue0021 D 13  .mod 15/, since 7 \ue001 13  D 91  D 1 .mod 15/, so that \n2=7  D 2 \ue001 13  D 11  .mod 15/. \nThe size of Z \ue003 \nn is denoted \ufffd.n/ . This function, known as Euler\u2019s  phi  function , \nsatis\u00fbes  the  equation  \n\ufffd.n/  D n Y  \np prime such that p j n \u00ce \n1 \ue003 1 \np \u00cf \n; (31.21)  \nso that p runs over all the primes dividing n (including n itself, if n is prime). \nWe  won\u2019t  prove  this  formula  here.  Intuitively,  begin  with  a list of the n remainders \nf0;1;:::;n  \ue003 1g and then, for each prime p that divides n, cross out every multiple \nof p in the list. For example, since the prime divisors of 45  are 3 and 5, \n\ufffd.45/  D 45  \u00ce \n1 \ue003 1 \n3 \u00cf\u00ce  \n1 \ue003 1 \n5 \u00cf \nD 45  \u00ce 2 \n3 \u00cf\u00ce  4 \n5 \u00cf \nD 24:  \nIf p is prime, then Z \ue003 \np D f1;2;:::;p  \ue003 1g, and \n\ufffd.p/  D p \u00ce \n1 \ue003 1 \np \u00cf \nD p \ue003 1:  (31.22)  \nIf n is composite, then \ufffd.n/  < n \ue003 1, although it can be shown that \n\ufffd.n/  > n \ne \ue002 ln ln n C 3=  ln ln n (31.23)  31.3  Modular  arithmetic  921 \nfor n \ue004 3, where \ufffd D 0:5772156649:::  is Euler\u2019s  constant . A somewhat simpler \n(but looser) lower bound for n>5  is \n\ufffd.n/  > n \n6 ln ln n : (31.24)  \nThe  lower  bound  (31.23)  is essentially  the  best  possible,  since \nlim inf \nn!1  \ufffd.n/  \nn=  ln ln n D e \ue002\ue002 : (31.25)  \nSubgroups  \nIf .S;  \u00dc/ is a group, S 0 \u0dc2 S , and .S  0 ; \u00dc/ is also a group, then .S  0 ; \u00dc/ is a sub-  \ngroup  of .S;  \u00dc/. For example, the even integers form a subgroup of  the integers \nunder the operation of addition. The following theo rem, whose proof we leave as \nExercise  31.3-3,  provides  a useful  tool  for  recognizing  subgroups. \nTheorem  31.14  (A  nonempty  closed  subset  of a \u00fbnite  group  is a subgroup)  \nIf .S;  \u00dc/ is a \u00fbnite  group  and  S 0 is any nonempty subset of S such that a \u00dc b 2 S 0 \nfor all a;b  2 S 0 , then .S  0 ; \u00dc/ is a subgroup of .S;  \u00dc/. \nFor example, the set f0;2;4;6 g forms a subgroup of Z 8 , since it is nonempty \nand closed under the operation C (that is, it is closed under C 8 ). \nThe following theorem, whose proof is omitted, prov ides an extremely useful \nconstraint on the size of a subgroup. \nTheorem  31.15  (Lagrange\u2019s  theorem)  \nIf .S;  \u00dc/ is a \u00fbnite  group  and  .S  0 ; \u00dc/ is a subgroup of .S;  \u00dc/, then jS 0 j is a divisor \nof jS j. \nA subgroup S 0 of a group S is a proper  subgroup if S 0 \u00a4 S . We\u2019ll  use  the  \nfollowing  corollary  in the  analysis  in Section  31.8  of the  Miller-Rabin  primality  \ntest procedure. \nCorollary  31.16  \nIf S 0 is a proper  subgroup  of a \u00fbnite  group  S , then jS 0 j \u0dc4 jS j=2. \nSubgroups  generated  by  an  element  \nTheorem  31.14  affords  us a straightforward  way  to produce  a subgroup  of a \u00fbnite  \ngroup .S;  \u00dc/: choose an element a and take all elements that can be generated \nfrom a using  the  group  operation.  Speci\u00fbcally,  de\u00fbne  a .k/  for k \ue004 1 by 922  Chapter  31  Number-Theoretic  Algorithms  \na .k/  D k M  \ni D1 a D a \u00dc a \u00dc \ue001 \ue001 \ue001 \u00dc  a \u203a  \nk : \nFor example, taking a D 2 in the group Z 6 yields the sequence \na .1/  ;a  .2/  ;a  .3/  ;:::  D 2;4;0;2;4;0;2;4;0;::: :  \nWe have a .k/  D ka  mod n in the group Z n , and a .k/  D a k mod n in the group Z \ue003 \nn . \nWe  de\u00fbne  the  subgroup  generated  by a, denoted hai or .hai; \u00dc/, by \nhai D  \u02da a .k/  W k \ue004 1 \ue009 : \nWe say that a generates  the subgroup hai or that a is a generator  of hai. Since S is \n\u00fbnite,  hai is a \u00fbnite  subset  of S , possibly including all of S . Since the associativity \nof \u00dc implies \na .i/  \u00dc a .j / D a .i Cj /  ; \nhai is closed  and  therefore,  by  Theorem  31.14,  hai is a subgroup of S . For example, \nin Z 6 , we have \nh0i D f0g ; \nh1i D f0;1;2;3;4;5 g ; \nh2i D f0;2;4 g : \nSimilarly, in Z \ue003 \n7 , we have \nh1i D f1g ; \nh2i D f1;2;4 g ; \nh3i D f1;2;3;4;5;6 g : \nThe order  of a (in the group S ), denoted ord.a/, is de\u00fbned  as the  smallest  posi-  \ntive integer t such that a .t/  D e. (Recall that e 2 S is the group identity.) \nTheorem  31.17  \nFor  any  \u00fbnite  group  .S;  \u00dc/ and any a 2 S , the order of a is equal to the size of the \nsubgroup it generates, or ord .a/  D jhaij. \nProof  Let t D ord.a/. Since a .t/  D e and a .t Ck/  D a .t/  \u00dc a .k/  D a .k/  for k \ue004 1, \nif i > t  , then a .i/  D a .j / for some j < i  . Therefore, as we generate elements \nby a, we see no new elements after a .t/  . Thus, hai D  \u02da \na .1/  ;a  .2/  ;:::;a  .t/  \ue009 \n, and \nso jhaij \u0dc4 t . To show that jhaij \ue004 t , we  show  that  each  element  of the  se-  \nquence a .1/  ;a  .2/  ;:::;a  .t/  is distinct. Suppose for the purpose of contradicti on that \na .i/  D a .j / for some i and j satisfying 1 \u0dc4 i <j  \u0dc4 t . Then, a .i Ck/  D a .j Ck/  for 31.3  Modular  arithmetic  923 \nk \ue004 0. But this equation implies that a .i C.t \ue002j // D a .j C.t \ue002j // D e, a contradiction, \nsince i C .t \ue003 j/ <t  but t is the least positive value such that a .t/  D e. There-  \nfore, each element of the sequence a .1/  ;a  .2/  ;:::;a  .t/  is distinct, and jhaij \ue004  t . We \nconclude that ord .a/  D jhaij. \nCorollary  31.18  \nThe sequence a .1/  ;a  .2/  ;:::  is periodic with period t D ord.a/, that is, a .i/  D a .j / \nif and only if i D j .mod t/. \nConsistent  with  the  above  corollary,  we  de\u00fbne  a .0/  as e and a .i/  as a .i mod t/ , \nwhere t D ord.a/, for all integers i . \nCorollary  31.19  \nIf .S;  \u00dc/ is a \u00fbnite  group  with  identity  e, then for all a 2 S , \na .jSj/ D e:  \nProof  Lagrange\u2019s  theorem  (Theorem  31.15)  implies  that  ord.a/  j jS j, and so \njS j D  0 .mod t/, where t D ord.a/. Therefore, a .jSj/ D a .0/  D e. \nExercises  \n31.3-1  \nDraw the group operation tables for the groups .Z 4 ; C 4 / and .Z \ue003 \n5 ; \ue001 5 /. Show that \nthese  groups  are  isomorphic  by  exhibiting  a one-to-one  correspondence f between \nZ 4 and Z \ue003 \n5 such that aCb D c .mod 4/ if and only if f.a/ \ue001f.b/  D f.c/ . mod 5/. \n31.3-2  \nList all subgroups of Z 9 and of Z \ue003 \n13  . \n31.3-3  \nProve  Theorem  31.14.  \n31.3-4  \nShow that if p is prime and e is a positive integer, then \n\ufffd.p  e / D p e\ue0021 .p  \ue003 1/:  \n31.3-5  \nShow that for any integer n>1  and for any a 2 Z \ue003 \nn , the function f a W Z \ue003 \nn !  Z \ue003 \nn \nde\u00fbned  by  f a .x/  D ax  mod n is a permutation of Z \ue003 \nn . 924  Chapter  31  Number-Theoretic  Algorithms  \n31.4  Solving  modular  linear  equations  \nWe  now  consider  the  problem  of \u00fbnding  solutions  to the  equati on \nax  D b .mod n/;  (31.26)  \nwhere a>0  and n>0. This  problem  has  several  applications.  For  example,  we\u2019ll  \nuse  it in Section  31.7  as part  of the  procedure  to \u00fbnd  keys  in the  RSA  public-key  \ncryptosystem. We assume that a, b, and n are  given,  and  we  wish  to \u00fbnd  all  values  \nof x , modulo n, that  satisfy  equation  (31.26).  The  equation  may  have  zero,  one, or \nmore than one such solution. \nLet hai denote the subgroup of Z n generated by a. Since hai D fa .x/  W x>0 g D  \nfax  mod n W x>0 g, equation  (31.26)  has  a solution  if and  only  if \u0152b\ufffd  2 hai. \nLagrange\u2019s  theorem  (Theorem  31.15)  tells  us that  jhaij must be a divisor of n. \nThe following theorem gives us a precise characteri zation of hai. \nTheorem  31.20  \nFor any positive integers a and n, if d D gcd.a;n/ , then we have \nhai D hd i \nD f0;d;2d;:::;..n=d/  \ue003 1/d  g \nin Z n , and thus \njhaij D  n=d  : \nProof  We begin by showing that d 2 hai. Recall that E XTENDED-EUCLID .a;n/  \nreturns a triple .d;x;y/  such that ax  C ny  D d . Thus, ax  D d .mod n/, so that \nd 2 hai. In other words, d is a multiple of a in Z n . \nSince d 2 hai, it follows that every multiple of d belongs to hai, because any \nmultiple of a multiple of a is itself a multiple of a. Thus, hai contains every element \nin f0;d;2d;:::;..n=d/  \ue003 1/d  g. That is, hd i \u0dc2 hai. \nWe now show that hai \u0dc2 hd i. If m 2 hai, then m D ax  mod n for some \ninteger x , and so m D ax  C ny  for some integer y . Because d D gcd.a;n/ , we \nknow that d j a and d j n, and so d j m by  equation  (31.4).  Therefore,  m 2 hd i. \nCombining these results, we have that hai D hd i. To see that jhaij D  n=d  , \nobserve that there are exactly n=d  multiples of d between 0 and n \ue003 1, inclusive. \nCorollary  31.21  \nThe equation ax  D b .mod n/ is solvable for the unknown x if and only if d j b, \nwhere d D gcd.a;n/ . 31.4  Solving  modular  linear  equations  925 \nProof  The equation ax  D b .mod n/ is solvable if and only if \u0152b\ufffd  2 hai, which \nis the same as saying \n.b mod n/ 2 f0;d;2d;:::;..n=d/  \ue003 1/d  g ; \nby  Theorem  31.20.  If 0 \u0dc4 b < n , then b 2 hai if and only if d j b, since the \nmembers of hai are precisely the multiples of d . If b <0  or b \ue004 n, the corollary \nthen follows from the observation that d j b if and only if d j .b mod n/, since b \nand b mod n differ by a multiple of n, which is itself a multiple of d . \nCorollary  31.22  \nThe equation ax  D b .mod n/ either has d distinct solutions modulo n, where \nd D gcd.a;n/ , or it has no solutions. \nProof  If ax  D b .mod n/ has a solution, then b 2 hai. By  Theorem  31.17,  \nord.a/  D jhaij, and  so Corollary  31.18  and  Theorem  31.20  imply  that  the  sequence \nai mod n, for i D 0;1;::: , is periodic with period jhaij D  n=d  . If b 2 hai, then \nb appears exactly d times in the sequence ai mod n, for i D 0;1;:::;n  \ue003 1, since \nthe  length-.n=d/  block of values hai repeats exactly d times as i increases from 0 \nto n \ue0031. The indices x of the d positions for which ax  mod n D b are the solutions \nof the equation ax  D b .mod n/. \nTheorem  31.23  \nLet d D gcd.a;n/ , and suppose that d D ax  0 C ny  0 for some integers x 0 and y 0 \n(for example, as computed by E XTENDED-EUCLID ). If d j b, then the equation \nax  D b .mod n/ has as one of its solutions the value x 0 , where \nx 0 D x 0 .b=d/  mod n:  \nProof  We have \nax  0 D ax  0 .b=d/  .mod n/ \nD d.b=d/  .mod n/ (because ax  0 D d .mod n/) \nD b .mod n/;  \nand thus x 0 is a solution to ax  D b .mod n/. \nTheorem  31.24  \nSuppose that the equation ax  D b .mod n/ is solvable (that is, d j b, where \nd D gcd.a;n/ ) and that x 0 is any  solution  to this  equation.  Then,  this  equa-  \ntion has exactly d distinct solutions, modulo n, given by x i D x 0 C i.n=d/  for \ni D 0;1;:::;d  \ue003 1. 926  Chapter  31  Number-Theoretic  Algorithms  \nProof  Because n=d  > 0 and 0 \u0dc4 i.n=d/  < n for i D 0;1;:::;d  \ue003 1, the \nvalues x 0 ;x  1 ;:::;x  d \ue0021 are all distinct, modulo n. Since x 0 is a solution of ax  D b \n.mod n/, we have ax  0 mod n D b .mod n/. Thus, for i D 0;1;:::;d  \ue003 1, we \nhave \nax  i mod n D a.x  0 C in=d/  mod n \nD .ax  0 C ain=d/  mod n \nD ax  0 mod n (because d j a implies that ain=d  is a multiple of n) \nD b .mod n/;  \nand hence ax  i D b .mod n/, making x i a solution,  too.  By  Corollary  31.22,  the  \nequation ax  D b .mod n/ has exactly d solutions, so that x 0 ;x  1 ;:::;x  d \ue0021 must \nbe all of them. \nWe have now developed the mathematics needed to sol ve the equation ax  D b \n.mod n/. The procedure M ODULAR-LINEAR-EQUATION-SOLVER  prints  all  so-  \nlutions to this equation. The inputs a and n are arbitrary positive integers, and b is \nan arbitrary integer. \nMODULAR-LINEAR-EQUATION-SOLVER  .a;b;n/  \n1 .d;x  0 ;y  0 / D EXTENDED-EUCLID .a;n/  \n2 if d j b \n3 x 0 D x 0 .b=d/  mod n \n4 for  i D 0 to d \ue003 1 \n5 print .x 0 C i.n=d//  mod n \n6 else  print <no solutions= \nAs an example of the operation of M ODULAR-LINEAR-EQUATION-SOLVER , \nconsider the equation 14x  D 30  .mod 100/  (and thus a D 14, b D 30, and \nn D 100). Calling E XTENDED-EUCLID in line  1 gives  .d;x  0 ;y  0 / D .2;  \ue0037;1/. \nSince 2 j 30, lines  335  execute.  Line  3 computes  x 0 D .\ue0037/.15/  mod 100  D 95. \nThe for  loop  of lines  435  prints  the  two  solutions,  95  and 45. \nThe procedure M ODULAR-LINEAR-EQUATION-SOLVER  works as follows. \nThe call to E XTENDED-EUCLID in line  1 returns  a triple  .d;x  0 ;y  0 / such that \nd D gcd.a;n/  and d D ax  0 C ny  0 . Therefore, x 0 is a solution to the equation \nax  0 D d .mod n/. If d does not divide b, then the equation ax  D b .mod n/ \nhas  no  solution,  by  Corollary  31.21.  Line  2 checks  to see  whet her d j b, and if \nnot,  line  6 reports  that  there  are  no  solutions.  Otherwise,  line  3 computes  a so-  \nlution x 0 to ax  D b .mod n/, as Theorem  31.23  suggests.  Given  one  solution,  \nTheorem  31.24  states  that  adding  multiples  of .n=d/ , modulo n, yields the other 31.4  Solving  modular  linear  equations  927 \nd \ue003 1 solutions. The for  loop  of lines  435  prints  out  all  d solutions, beginning \nwith x 0 and spaced n=d  apart, modulo n. \nMODULAR-LINEAR-EQUATION-SOLVER  performs O.lg n C gcd.a;n//  arith-  \nmetic operations, since E XTENDED-EUCLID performs O.lg n/ arithmetic  opera-  \ntions, and each iteration of the for  loop  of lines  435  performs  a constant  number  of \narithmetic operations. \nThe  following  corollaries  of Theorem  31.24  give  specializa tions of particular \ninterest. \nCorollary  31.25  \nFor any n>1 , if gcd.a;n/  D 1, then the equation ax  D b .mod n/ has a unique \nsolution, modulo n. \nIf b D 1, a common case of considerable interest, the x that solves the equation \nis a multiplicative  inverse  of a, modulo n. \nCorollary  31.26  \nFor any n>1 , if gcd.a;n/  D 1, then the equation ax  D 1 .mod n/ has a unique \nsolution, modulo n. Otherwise,  it has  no  solution.  \nThanks  to Corollary  31.26,  the  notation  a \ue0021 mod n refers to the multiplicative \ninverse of a, modulo n, when a and n are relatively prime. If gcd .a;n/  D 1, then \nthe unique solution to the equation ax  D 1 .mod n/ is the integer x returned by \nEXTENDED-EUCLID , since the equation \ngcd.a;n/  D 1 D ax  C ny  \nimplies ax  D 1 .mod n/. Thus, E XTENDED-EUCLID can compute a \ue0021 mod n \nef\u00fbciently.  \nExercises  \n31.4-1  \nFind all solutions to the equation 35x  D 10  .mod 50/. \n31.4-2  \nProve that the equation ax  D ay  .mod n/ implies x D y .mod n/ whenever \ngcd.a;n/  D 1. Show that the condition gcd .a;n/  D 1 is necessary by supplying a \ncounterexample with gcd .a;n/>1 . 928  Chapter  31  Number-Theoretic  Algorithms  \n31.4-3  \nConsider  the  following  change  to line  3 of the  procedure  MODULAR-LINEAR- \nEQUATION-SOLVER : \n3 x 0 D x 0 .b=d/  mod .n=d/  \nWith  this  change,  will  the  procedure  still  work?  Explain  why  or why not. \n? 31.4-4  \nLet p be prime and f.x/  D .f 0 C f 1 x C \ue001 \ue001 \ue001 C  f t x t / .mod p/  be a polyno-  \nmial of degree t , with  coef\u00fbcients  f i drawn from Z p . We say that a 2 Z p \nis a zero  of f if f.a/  D 0 .mod p/. Prove that if a is a zero of f , then \nf.x/  D .x \ue003 a/g.x/  .mod p/  for some polynomial g.x/  of degree t \ue003 1. Prove \nby induction on t that if p is prime, then a polynomial f.x/  of degree t can have \nat most t distinct zeros modulo p. \n31.5  The  Chinese  remainder  theorem  \nAround  100  C. E., the  Chinese  mathematician  Sun-Ts\u02d8  u solved  the  problem  of \u00fbnd-  \ning those integers x that leave remainders 2, 3, and 2 when divided by 3, 5, and 7 re-  \nspectively.  One  such  solution  is x D 23, and all solutions are of the form 23  C105k  \nfor arbitrary integers k. The  <Chinese  remainder  theorem=  provides  a correspon-  \ndence between a system of equations modulo a set of  pairwise relatively prime \nmoduli (for example, 3, 5, and 7) and  an equation  modulo  their  product  (for  exam-  \nple, 105). \nThe Chinese remainder theorem has two major applica tions. Let the  inte-  \nger n be factored as n D n 1 n 2 \ue001 \ue001 \ue001  n k , where the factors n i are pairwise relatively \nprime. First, the Chinese remainder theorem is a de scriptive <structure theorem= \nthat describes the structure of Z n as identical to that of the Cartesian product \nZ n 1 \ue005 Z n 2 \ue005 \ue001 \ue001 \ue001 \ue005  Z n k with componentwise addition and multiplication modu lo n i \nin the i th component. Second, this description helps in des igning ef\u00fbcient  algo-  \nrithms, since working in each of the systems Z n i can  be more  ef\u00fbcient  (in  terms  of \nbit operations) than working modulo n. \nTheorem  31.27  (Chinese  remainder  theorem)  \nLet n D n 1 n 2 \ue001 \ue001 \ue001  n k , where the n i are pairwise relatively prime. Consider the \ncorrespondence \na $  .a 1 ;a  2 ;:::;a  k /; (31.27)  \nwhere a 2 Z n , a i 2 Z n i , and 31.5 The Chinese remainder theorem 929 \na i D a mod n i \nfor i D 1;2;:::;k. Then,  mapping  (31.27)  is a one-to-one  mapping  (bijection)  \nbetween Z n and the Cartesian product Z n 1 \ue005 Z n 2 \ue005 \ue001 \ue001 \ue001 \ue005  Z n k . Operations  per-  \nformed on the elements of Z n can be equivalently performed on the corresponding \nk-tuples  by  performing  the  operations  independently  in each  coordinate position in \nthe appropriate system. That is, if \na $  .a 1 ;a  2 ;:::;a  k /; \nb $  .b 1 ;b  2 ;:::;b  k /; \nthen \n.a C b/ mod n $  ..a  1 C b 1 / mod n 1 ;:::;.a  k C b k / mod n k /; (31.28)  \n.a \ue003 b/ mod n $  ..a  1 \ue003 b 1 / mod n 1 ;:::;.a  k \ue003 b k / mod n k /; (31.29)  \n.ab/  mod n $  .a 1 b 1 mod n 1 ;:::;a  k b k mod n k /: (31.30)  \nProof  Let\u2019s  see  how  to translate  between  the  two  representations.  Going  from  a \nto .a 1 ;a  2 ;:::;a  k / requires only k <mod=  operations.  The  reverse4computing  a \nfrom inputs .a 1 ;a  2 ;:::;a  k /4is  only  slightly  more  complicated.  \nWe  begin  by  de\u00fbning  m i D n=n  i for i D 1;2;:::;k . Thus, m i is the product of \nall of the n j \u2019s other  than  n i : m i D n 1 n 2 \ue001 \ue001 \ue001  n i \ue0021 n i C1 \ue001 \ue001 \ue001  n k . We  next  de\u00fbne  \nc i D m i .m  \ue0021 \ni mod n i / (31.31)  \nfor i D 1;2;:::;k. Equation  (31.31)  is well  de\u00fbned:  since  m i and n i are  rela-  \ntively  prime  (by  Theorem  31.6),  Corollary  31.26  guarantees  that m \ue0021 \ni mod n i ex-  \nists. Here is how to compute a as a function of the a i and c i : \na D .a 1 c 1 C a 2 c 2 C \ue001 \ue001 \ue001 C  a k c k / .mod n/:  (31.32)  \nWe  now  show  that  equation  (31.32)  ensures  that  a D a i .mod n i / for i D \n1;2;:::;k . If j \u00a4 i , then m j D 0 .mod n i /, which implies that c j D m j D 0 \n.mod n i /. Note also that c i D 1 .mod n i /, from  equation  (31.31).  We  thus  have  \nthe appealing and useful correspondence \nc i $  .0;0;:::;0;1;0;:::;0/;  \na vector that has 0s everywhere except in the i th coordinate, where it has a 1. The c i \nthus form a <basis= for the representation, in a ce rtain sense. For each i , therefore, \nwe have \na D a i c i .mod n i / \nD a i m i .m  \ue0021 \ni mod n i / .mod n i / \nD a i .mod n i /; 930  Chapter  31  Number-Theoretic  Algorithms  \nwhich is what we wished to show: our method of comp uting a from the a i \u2019s pro-  \nduces a result a that  satis\u00fbes  the  constraints  a D a i .mod n i / for i D 1;2;:::;k . \nThe  correspondence  is one-to-one,  since  we  can  transform  in both directions. \nFinally,  equations  (31.28)3(31.30)  follow  directly  from  Exercise  31.1-7,  since  \nx mod n i D .x mod n/ mod n i for any x and i D 1;2;:::;k . \nWe\u2019ll  use  the  following  corollaries  later  in this  chapter.  \nCorollary  31.28  \nIf n 1 ;n  2 ;:::;n  k are pairwise relatively prime and n D n 1 n 2 \ue001 \ue001 \ue001  n k , then for any \nintegers a 1 ;a  2 ;:::;a  k , the set of simultaneous equations \nx D a i .mod n i /; \nfor i D 1;2;:::;k , has a unique solution modulo n for the unknown x . \nCorollary  31.29  \nIf n 1 ;n  2 ;:::;n  k are pairwise relatively prime and n D n 1 n 2 \ue001 \ue001 \ue001  n k , then for all \nintegers x and a, \nx D a .mod n i / \nfor i D 1;2;:::;k  if and only if \nx D a .mod n/:  \nAs an example of the application of the Chinese rem ainder theorem, suppose \nthat you are given the two equations \na D 2 .mod 5/;  \na D 3 .mod 13/;  \nso that a 1 D 2, n 1 D m 2 D 5, a 2 D 3, and n 2 D m 1 D 13, and you wish \nto compute a mod 65, since n D n 1 n 2 D 65. Because 13  \ue0021 D 2 .mod 5/ and \n5 \ue0021 D 8 .mod 13/, you compute \nc 1 D 13  \ue001 .2 mod 5/ D 26;  \nc 2 D 5 \ue001 .8 mod 13/  D 40;  \nand \na D 2 \ue001 26  C 3 \ue001 40  .mod 65/  \nD 52  C 120  .mod 65/  \nD 42  .mod 65/:  31.5 The Chinese remainder theorem 931 \n0 1 2 3 4 5 6 7 8 9 10  11  12  \n0 0 40  15  55  30  5 45  20  60  35  10  50  25  \n1 26  1 41  16  56  31  6 46  21  61  36  11  51  \n2 52  27  2 42  17  57  32  7 47  22  62  37  12  \n3 13  53  28  3 43  18  58  33  8 48  23  63  38  \n4 39  14  54  29  4 44  19  59  34  9 49  24  64  \nFigure  31.3  An illustration of the Chinese remainder theorem fo r n 1 D 5 and n 2 D 13. For this \nexample, c 1 D 26  and c 2 D 40. In row i , column j is shown the value of a, modulo 65, such \nthat a mod 5 D i and a mod 13  D j . Note that row 0, column 0 contains a 0. Similarly, row 4, \ncolumn 12  contains a 64  (equivalent to \ue0031). Since c 1 D 26, moving down a row increases a by 26. \nSimilarly, c 2 D 40  means that moving right by a column increases a by 40. Increasing a by 1 \ncorresponds to moving diagonally downward and to th e right, wrapping around from the bottom to \nthe top and from the right to the left. \nSee  Figure  31.3  for  an illustration  of the  Chinese  remainder  theorem, modulo 65. \nThus, you can work modulo n by working modulo n directly or by working in the \ntransformed representation using separate modulo n i computations, as convenient. \nThe computations are entirely equivalent. \nExercises  \n31.5-1  \nFind all solutions to the equations x D 4 .mod 5/ and x D 5 .mod 11/. \n31.5-2  \nFind all integers x that leave remainders 1, 2, and 3 when divided by 9, 8, and 7, \nrespectively. \n31.5-3  \nArgue  that,  under  the  de\u00fbnitions  of Theorem  31.27,  if gcd.a;n/  D 1, then \n.a \ue0021 mod n/ $  ..a  \ue0021 \n1 mod n 1 /;.a  \ue0021 \n2 mod n 2 /;:::;.a  \ue0021 \nk mod n k //:  \n31.5-4  \nUnder  the  de\u00fbnitions  of Theorem  31.27,  prove  that  for  any  polynomial f , the  num-  \nber of roots of the equation f.x/  D 0 .mod n/ equals the product of the number \nof roots of each of the equations f.x/  D 0 .mod n 1 /, f.x/  D 0 .mod n 2 /, . . . , \nf.x/  D 0 .mod n k /. 932  Chapter  31  Number-Theoretic  Algorithms  \n31.6  Powers  of an  element  \nAlong with considering the multiples of a given ele ment a, modulo n, we often \nconsider the sequence of powers of a, modulo n, where a 2 Z \ue003 \nn : \na 0 ;a  1 ;a  2 ;a  3 ;:::;  \nmodulo n. Indexing from 0, the 0th value in this sequence is a 0 mod n D 1, and \nthe i th value is a i mod n. For example, the powers of 3 modulo 7 are \ni 0 1 2 3 4 5 6 7 8 9 10 11  \ue001 \ue001 \ue001  \n3 i mod 7 1 3 2 6 4 5 1 3 2 6 4 5  \ue001 \ue001 \ue001  \nand the powers of 2 modulo 7 are \ni 0 1 2 3 4 5 6 7 8 9 10 11  \ue001 \ue001 \ue001  \n2 i mod 7 1 2 4 1 2 4 1 2 4 1 2 4  \ue001 \ue001 \ue001  \nIn this section, let hai denote the subgroup of Z \ue003 \nn generated by a through  re-  \npeated multiplication, and let ord n .a/  (the <order of a, modulo n=) denote the \norder of a in Z \ue003 \nn . For example, h2i D f1;2;4 g in Z \ue003 \n7 , and ord 7 .2/  D 3. Using \nthe  de\u00fbnition  of the  Euler  phi  function  \ufffd.n/  as the size of Z \ue003 \nn (see  Section  31.3),  \nwe  now  translate  Corollary  31.19  into  the  notation  of Z \ue003 \nn to obtain  Euler\u2019s  theorem  \nand specialize it to Z \ue003 \np , where p is prime,  to obtain  Fermat\u2019s  theorem.  \nTheorem  31.30  (Euler\u2019s  theorem)  \nFor any integer n>1 , \na \ue005.n/  D 1 .mod n/ for all a 2 Z \ue003 \nn : \nTheorem  31.31  (Fermat\u2019s  theorem)  \nIf p is prime, then \na p\ue0021 D 1 .mod p/  for all a 2 Z \ue003 \np : \nProof  By  equation  (31.22),  \ufffd.p/  D p \ue003 1 if p is prime. \nFermat\u2019s  theorem  applies  to every  element  in Z p except 0, since 0 \u2026 Z \ue003 \np . For \nall a 2 Z p , however, we have a p D a .mod p/  if p is prime. \nIf ord n .g/  D jZ \ue003 \nn j, then every element in Z \ue003 \nn is a power of g, modulo n, and \ng is a primitive  root  or a generator  of Z \ue003 \nn . For example, 3 is a primitive root, \nmodulo 7, but 2 is not a primitive root, modulo 7. If Z \ue003 \nn possesses a primitive \nroot, the group Z \ue003 \nn is cyclic . We omit the proof of the following theorem, which  is \nproven  by  Niven  and  Zuckerman  [345].  31.6 Powers of an element 933 \nTheorem  31.32  \nThe values of n > 1  for which Z \ue003 \nn is cyclic are 2, 4, p e , and 2p  e , for all primes \np>2  and all positive integers e. \nIf g is a primitive root of Z \ue003 \nn and a is any element of Z \ue003 \nn , then there exists a \u00b4 such \nthat g \u00b4 D a .mod n/. This \u00b4 is a discrete  logarithm  or an index  of a, modulo n, \nto the base g. We denote this value as ind n;g  .a/. \nTheorem  31.33  (Discrete  logarithm  theorem)  \nIf g is a primitive root of Z \ue003 \nn , then the equation g x D g y .mod n/ holds if and \nonly if the equation x D y .mod \ufffd.n//  holds. \nProof  Suppose  \u00fbrst  that  x D y .mod \ufffd.n// . Then, we have x D y C k\ufffd.n/  for \nsome integer k, and thus \ng x D g yCk\ue005.n/  .mod n/ \nD g y \ue001 .g \ue005.n/  / k .mod n/ \nD g y \ue001 1 k .mod n/ (by  Euler\u2019s  theorem)  \nD g y .mod n/:  \nConversely, suppose that g x D g y .mod n/. Because the sequence of powers of g \ngenerates every element of hgi and jhgij D  \ufffd.n/, Corollary  31.18  implies  that  \nthe sequence of powers of g is periodic with period \ufffd.n/ . Therefore, if g x D g y \n.mod n/, we must have x D y .mod \ufffd.n// . \nLet\u2019s  now  turn  our  attention  to the  square  roots  of 1, modulo a prime power. \nThe following properties will be useful to justify the primality-testing  algorithm  in \nSection  31.8.  \nTheorem  31.34  \nIf p is an odd prime and e \ue004 1, then the equation \nx 2 D 1 .mod p e / (31.33)  \nhas only two solutions, namely x D 1 and x D \ue0031. \nProof  By  Exercise  31.6-2,  equation  (31.33)  is equivalent  to \np e j .x \ue003 1/.x  C 1/:  \nSince p >2 , we can have p j .x \ue003 1/ or p j .x C 1/, but  not  both.  (Otherwise,  \nby  property  (31.3),  p would also divide their difference .x C 1/ \ue003 .x \ue003 1/ D 2.) \nIf p \u2212 .x \ue003 1/, then gcd.p  e ;x  \ue003 1/ D 1, and  by  Corollary  31.5,  we  would  have  \np e j .x C 1/. That is, x D \ue0031 .mod p e /. Symmetrically, if p \u2212 .x C 1/, 934  Chapter  31  Number-Theoretic  Algorithms  \nthen gcd.p  e ;x  C 1/ D 1, and  Corollary  31.5  implies  that  p e j .x \ue003 1/, so that \nx D 1 .mod p e /. Therefore, either x D \ue0031 .mod p e / or x D 1 .mod p e /. \nA number x is a nontrivial  square  root  of 1, modulo  n, if it satis\u00fbes  the  equation  \nx 2 D 1 .mod n/ but x is equivalent to neither of the two <trivial= squar e roots: \n1 or \ue0031, modulo n. For example, 6 is a nontrivial square root of 1, modulo 35. \nWe\u2019ll  use  the  following  corollary  to Theorem  31.34  in Section  31.8  to prove  the  \nMiller-Rabin  primality-testing  procedure  correct.  \nCorollary  31.35  \nIf there exists a nontrivial square root of 1, modulo n, then n is composite. \nProof  By  the  contrapositive  of Theorem  31.34,  if there  exists  a nontrivial square \nroot of 1, modulo n, then n cannot be an odd prime or a power of an odd prime. \nNor can n be 2, because if x 2 D 1 .mod 2/, then x D 1 .mod 2/, and therefore, \nall square roots of 1, modulo 2, are trivial. Thus, n cannot be prime. Finally, we \nmust have n > 1  for a nontrivial square root of 1 to exist. Therefore, n must be \ncomposite. \nRaising  to powers  with  repeated  squaring  \nA frequently  occurring  operation  in number-theoretic  comp utations is raising one \nnumber to a power modulo another number, also known  as modular  exponentia-  \ntion. More  precisely,  we  would  like  an ef\u00fbcient  way  to compute  a b mod n, where \na and b are nonnegative integers and n is a positive  integer.  Modular  exponenti-  \nation  is an essential  operation  in many  primality-testing  routines and in the RSA \npublic-key  cryptosystem.  The  method  of repeated  squaring  solves this problem \nef\u00fbciently.  \nRepeated squaring is based on the following formula  to compute a b for  nonneg-  \native integers a and b: \na b D \u0128 \n1 if b D 0;  \n.a b=2  / 2 if b>0  and b is even ; \na \ue001 a b\ue0021 if b>0  and b is odd : (31.34)  \nThe last case, where b is odd,  reduces  to the  one  of the  \u00fbrst  two  cases,  since  if b \nis odd, then b \ue003 1 is even. The recursive procedure M ODULAR-EXPONENTIATION  \non the next page computes a b mod n using  equation  (31.34),  but  performing  all  \ncomputations modulo n. The term <repeated squaring= comes from squaring the \nintermediate result d D a b=2  in line  5. Figure  31.4  shows  the  values  of the  param-  \neter b, the local variable d , and the value returned at each level of the recur sion for \nthe call M ODULAR-EXPONENTIATION  .7;560;561/ , which returns the result 1. 31.6 Powers of an element 935 \nb 560  280  140  70  35  34  17  16  8 4 2 1 0  \nd 67  166  298  241  355  160  103  526  157  49  7 1 \u2013 \nreturned value 1 67  166  298  241  355  160  103  526  157  49  7 1 \nFigure  31.4  The values of the parameter b, the local variable d , and the value returned for recursive \ncalls of M ODULAR-EXPONENTIATION  with parameter values a D 7, b D 560, and n D 561. The \nvalue returned by each recursive call is assigned d irectly to d . The result of the call with a D 7, \nb D 560, and n D 561  is 1. \nMODULAR-EXPONENTIATION  .a;b;n/  \n1 if b = = 0 \n2 return  1 \n3 elseif  b mod 2 == 0 \n4 d D MODULAR-EXPONENTIATION  .a;b=2;n/  / / b is even \n5 return  .d \ue001 d/  mod n \n6 else  d D MODULAR-EXPONENTIATION  .a;b  \ue003 1;n/  / / b is odd \n7 return  .a \ue001 d/  mod n \nThe total number of recursive calls depends on the number of bits of b and the \nvalues of these bits. Assume that b > 0  and  that  the  most  signi\u00fbcant  bit  of b \nis a 1. Each 0 generates  one  recursive  call  (in  line  4),  and  each  1 generates two \nrecursive  calls  (one  in line  6 followed  by  one  in line  4 becaus e if b is odd, then \nb \ue003 1 is even). If the inputs a, b, and n are \u02c7-bit  numbers,  then  there  are  between  \n\u02c7 and 2\u02c7  \ue003 1 recursive calls altogether, the total number of ari thmetic operations \nrequired is O.\u02c7/ , and the total number of bit operations required i s O.\u02c7  3 /. \nExercises  \n31.6-1  \nDraw a table showing the order of every element in Z \ue003 \n11  . Pick the smallest primitive \nroot g and compute a table giving ind 11;g  .x/  for all x 2 Z \ue003 \n11  . \n31.6-2  \nShow that x 2 D 1 .mod p e / is equivalent to p e j .x \ue003 1/.x  C 1/. \n31.6-3  \nRewrite the third case of M ODULAR-EXPONENTIATION , where b is odd, so that \nif b has \u02c7 bits  and  the  most  signi\u00fbcant  bit  is 1, then there are always exactly \u02c7 \nrecursive calls. 936  Chapter  31  Number-Theoretic  Algorithms  \n31.6-4  \nGive  a nonrecursive  (i.e.,  iterative)  version  of MODULAR-EXPONENTIATION . \n31.6-5  \nAssuming that you know \ufffd.n/ , explain how to compute a \ue0021 mod n for any a 2 Z \ue003 \nn \nusing the procedure M ODULAR-EXPONENTIATION . \n31.7  The  RSA  public-key  cryptosystem  \nWith  a public-key  cryptosystem,  you  can  encrypt  messages  sent  between  two  com-  \nmunicating parties so that an eavesdropper who over hears the encrypted messages \nwill not be able to decode, or decrypt, them.  A public-key  cryptosystem  also  en-  \nables a party to append an unforgeable <digital sig nature= to the end of an electronic \nmessage. Such a signature is the electronic version  of a handwritten signature on \na paper document. It can be easily checked by anyon e, forged by no one, yet loses \nits validity if any bit of the message is altered. It therefore provides  authentica-  \ntion of both the identity of the signer and the con tents of the signed message. It \nis the perfect tool for electronically signed busin ess contracts, electronic checks, \nelectronic purchase orders, and other electronic co mmunications that parties wish \nto authenticate. \nThe  RSA  public-key  cryptosystem  relies  on  the  dramatic  difference between the \nease  of \u00fbnding  large  prime  numbers  and  the  dif\u00fbculty  of facto ring the product of \ntwo  large  prime  numbers.  Section  31.8  describes  an ef\u00fbcient  procedure  for  \u00fbnding  \nlarge prime numbers. \nPublic-key  cryptosystems  \nIn a public-key  cryptosystem,  each  participant  has  both  a public  key  and a secret  \nkey. Each key is a piece of information. For example, in the RSA cryptosystem, \neach key consists of a pair of integers. The partic ipants <Alice= and <Bob= are \ntraditionally used in cryptography examples. We den ote the public keys for Alice \nand Bob as P A and P B , respectively, and likewise the secret keys are S A for Alice \nand S B for Bob. \nEach participant creates his or her own public and secret keys. Secret keys are \nkept secret, but public keys can be revealed to any one or even published. In fact, \nit is often  convenient  to assume  that  everyone\u2019s  public  key  is available  in a pub-  \nlic directory, so that any participant can easily o btain the public key of any other \nparticipant. 31.7  The  RSA  public-key  cryptosystem  937 \ndecrypt communication channel \nencrypt Bob Alice \neavesdropper M  M  P A S A \nC C D P A .M/  \nFigure  31.5  Encryption in a public key system. Bob encrypts the  message M  using  Alice\u2019s  public  \nkey P A and transmits the resulting ciphertext C D P A .M/  over  a communication  channel  to Al-  \nice. An eavesdropper who captures the transmitted c iphertext gains no information about M  . Alice \nreceives C and decrypts it using her secret key to obtain the original message M  D S A .C/. \nThe public and secret keys specify functions that c an be applied to any message. \nLet D denote the set of permissible messages. For example , D might be the set of \nall  \u00fbnite-length  bit  sequences.  The  simplest,  and  original,  formulation  of public-  \nkey  cryptography  requires  one-to-one  functions  from  D to itself, based on the \npublic and secret keys. We denote the function base d on Alice\u2019s public  key  P A \nby P A ./ and the function based on her secret key S A by S A ./. The functions P A ./ \nand S A ./ are thus permutations of D . We assume that the functions P A ./ and S A ./ \nare  ef\u00fbciently  computable  given  the  corresponding  keys  P A and S A . \nThe public and secret keys for any participant are a <matched pair= in that they \nspecify functions that are inverses of each other. That is, \nM  D S A .P  A .M//;  (31.35)  \nM  D P A .S  A .M//  (31.36)  \nfor any message M  2 D . Transforming M  with the two keys P A and S A succes-  \nsively, in either order, yields back the original m essage M  . \nA public-key  cryptosystem  requires  that  Alice,  and  only  Alice,  be able  to com-  \npute the function S A ./ in any practical amount of time. This assumption is  crucial \nto keeping encrypted messages sent to Alice private  and to knowing  that  Alice\u2019s  \ndigital signatures are authentic. Alice must keep h er key S A secret. If she does not, \nwhoever else has access to S A can decrypt messages intended only for Alice and \ncan also forge her digital signature. The assumptio n that only Alice can reasonably \ncompute S A ./ must hold even though everyone knows P A and can compute P A ./, \nthe inverse function to S A ./, ef\u00fbciently.  These  requirements  appear  formidable,  but  \nwe\u2019ll  see  how  to satisfy  them.  \nIn a public-key  cryptosystem,  encryption  works  as shown  in Figure  31.5.  Sup-  \npose that Bob wishes to send Alice a message M  encrypted so that it looks like 938  Chapter  31  Number-Theoretic  Algorithms  \nsign \ncommunication channel verify \n=?  accept Bob Alice \nM  0 \nM  0 P A S A \ufffd \n.M  0 ; \ufffd /  \ufffd D S A .M  0 / \nFigure  31.6  Digital  signatures  in a public-key  system.  Alice  signs  the  message M  0 by appending \nher digital signature \ufffd D S A .M  0 / to it. She transmits the message/signature pair .M  0 ; \ufffd/  to Bob, \nwho  veri\u00fbes  it by  checking  the  equation  M  0 D P A .\ufffd/. If the equation holds, he accepts .M  0 ; \ufffd/  as \na message that Alice has signed. \nunintelligible gibberish to an eavesdropper. The sc enario for sending the message \ngoes as follows. \n\ue001 Bob  obtains  Alice\u2019s  public  key  P A , perhaps from a public directory or perhaps \ndirectly from Alice. \n\ue001 Bob computes the ciphertext  C D P A .M/  corresponding to the message M  \nand sends C to Alice. \n\ue001 When Alice receives the ciphertext C , she applies her secret key S A to retrieve \nthe original message: S A .C/  D S A .P  A .M//  D M  . \nBecause S A ./ and P A ./ are inverse functions, Alice can compute M  from C . Be-  \ncause only Alice is able to compute S A ./, only Alice can compute M  from C . \nBecause Bob encrypts M  using P A ./, only Alice can understand the transmitted \nmessage. \nDigital signatures can be implemented within this f ormulation  of a public-key  \ncryptosystem. (There are other ways to construct di gital signatures,  but  we  won\u2019t  \ngo into them here.) Suppose now that Alice wishes t o send Bob a digitally signed \nresponse M  0 . Figure  31.6  shows  how  the  digital-signature  scenario  proceeds. \n\ue001 Alice computes her digital  signature  \ufffd for the message M  0 using her secret \nkey S A and the equation \ufffd D S A .M  0 /. \n\ue001 Alice sends the message/signature pair .M  0 ; \ufffd /  to Bob. \n\ue001 When Bob receives .M  0 ; \ufffd /, he can verify that it originated from Alice by us ing \nAlice\u2019s  public  key  to verify  the  equation  M  0 D P A .\ufffd /. (Presumably, M  0 con-  \ntains  Alice\u2019s  name,  so that  Bob  knows  whose  public  key  to use.) If the equation \nholds, then Bob concludes that the message M  0 was actually signed by Alice. If 31.7  The  RSA  public-key  cryptosystem  939 \nthe equation fails to hold, Bob concludes either th at the information he received \nwas corrupted by transmission errors or that the pa ir .M  0 ; \ufffd /  is an attempted \nforgery. \nBecause a digital signature provides both authentic ation of the  signer\u2019s  identity  and  \nauthentication of the contents of the signed messag e, it is analogous  to a handwrit-  \nten signature at the end of a written document. \nA digital  signature  must  be veri\u00fbable  by  anyone  who  has  access  to the  signer\u2019s  \npublic  key.  A signed  message  can  be veri\u00fbed  by  one  party  and  then passed on to \nother parties who can also verify the signature. Fo r example, the message might \nbe an electronic  check  from  Alice  to Bob.  After  Bob  veri\u00fbes  Alice\u2019s  signature  on  \nthe check, he can give the check to his bank, who c an then also verify the signature \nand effect the appropriate funds transfer. \nA signed message may or may not be encrypted. The m essage can be <in the \nclear= and not protected from disclosure. By compos ing the above protocols for \nencryption and for signatures, Alice can create a m essage to Bob that is both signed \nand  encrypted.  Alice  \u00fbrst  appends  her  digital  signature  to the message and then \nencrypts  the  resulting  message/signature  pair  with  Bob\u2019s  public key. Bob decrypts \nthe received message with his secret key to obtain both the original message and its \ndigital signature. Bob can then verify the signatur e using Alice\u2019s  public  key.  The  \ncorresponding  combined  process  using  paper-based  systems  would be to sign the \npaper document and then seal the document inside a paper envelope that is opened \nonly by the intended recipient. \nThe  RSA  cryptosystem  \nIn the RSA  public-key  cryptosystem , a participant creates a public key and a secret \nkey with the following procedure: \n1. Select  at random  two  large  prime  numbers  p and q such that p \u00a4 q. The primes \np and q might be, say, 1024  bits each. \n2. Compute n D pq. \n3. Select  a small  odd  integer  e that is relatively prime to \ufffd.n/, which,  by  equa-  \ntion  (31.21),  equals  .p  \ue003 1/.q  \ue003 1/. \n4. Compute  d as the multiplicative inverse of e, modulo \ufffd.n/. (Corollary  31.26  \nguarantees that d exists  and  is uniquely  de\u00fbned.  You  can  use  the  technique  of \nSection  31.4  to compute  d , given e and \ufffd.n/ .) \n5. Publish  the  pair  P D .e;n/  as the  participant\u2019s  RSA  public  key. \n6. Keep  secret  the  pair  S D .d;n/  as the  participant\u2019s  RSA  secret  key. 940  Chapter  31  Number-Theoretic  Algorithms  \nFor this scheme, the domain D is the set Z n . To transform a message M  asso-  \nciated with a public key P D .e;n/ , compute \nP.M/  D M  e mod n:  (31.37)  \nTo transform a ciphertext C associated with a secret key S D .d;n/ , compute \nS.C/  D C d mod n:  (31.38)  \nThese equations apply to both encryption and signat ures. To create a signature, the \nsigner\u2019s  secret  key  is applied  to the  message  to be signed,  rather than to a ciphertext. \nTo verify a signature, the public key of the signer  is applied to the signature rather \nthan to a message to be encrypted. \nTo  implement  the  public-key  and  secret-key  operations  (31.37)  and  (31.38),  you  \ncan use the procedure M ODULAR-EXPONENTIATION  described  in Section  31.6.  \nTo analyze the running time of these operations, as sume that the public key .e;n/  \nand secret key .d;n/  satisfy lg e D O.1/ , lg d \u0dc4 \u02c7, and lg n \u0dc4 \u02c7. Then, applying \na public key requires O.1/  modular multiplications and uses O.\u02c7  2 / bit operations. \nApplying a secret key requires O.\u02c7/  modular multiplications, using O.\u02c7  3 / bit \noperations. \nTheorem  31.36  (Correctness  of RSA)  \nThe  RSA  equations  (31.37)  and  (31.38)  de\u00fbne  inverse  transfo rmations of Z n satis-  \nfying  equations  (31.35)  and  (31.36).  \nProof  From  equations  (31.37)  and  (31.38),  we  have  that  for  any  M  2 Z n , \nP.S.M//  D S.P.M//  D M  ed  .mod n/:  \nSince e and d are multiplicative inverses modulo \ufffd.n/  D .p  \ue003 1/.q  \ue003 1/, \ned  D 1 C k.p  \ue003 1/.q  \ue003 1/ \nfor some integer k. But then, if M  \u00a4 0 .mod p/, we have \nM  ed  D M.M  p\ue0021 / k.q\ue0021/  .mod p/  \nD M..M  mod p/  p\ue0021 / k.q\ue0021/  .mod p/  \nD M.1/  k.q\ue0021/  .mod p/  (by  Theorem  31.31)  \nD M  .mod p/:  \nAlso, M  ed  D M . mod p/  if M  D 0 .mod p/. Thus, \nM  ed  D M . mod p/  \nfor all M  . Similarly, 31.7  The  RSA  public-key  cryptosystem  941 \nM  ed  D M . mod q/ \nfor all M  . Thus,  by  Corollary  31.29  to the  Chinese  remainder  theorem,  \nM  ed  D M . mod n/ \nfor all M  . \nThe security of the RSA cryptosystem rests in large  part on the dif\u00fbculty  of fac-  \ntoring large integers. If an adversary can factor t he modulus n in a public key, then \nthe adversary can derive the secret key from the pu blic key, using the knowledge \nof the factors p and q in the same way that the creator of the public key used them. \nTherefore, if factoring large integers is easy, the n breaking the RSA cryptosystem \nis easy. The converse statement, that if factoring large integers  is hard,  then  break-  \ning RSA is hard, is unproven. After two decades of research, however, no easier \nmethod  has  been  found  to break  the  RSA  public-key  cryptosyst em than to factor \nthe modulus n. And  factoring  large  integers  is surprisingly  dif\u00fbcult.  By  randomly \nselecting and multiplying together two 1024-bit  primes,  you  can  create  a public  key  \nthat cannot be <broken= in any feasible amount of t ime with current technology. In \nthe absence of a fundamental breakthrough in the de sign of number-theoretic  al-  \ngorithms, and when implemented with care following recommended standards, the \nRSA cryptosystem is capable of providing a high deg ree of security in applications. \nIn order to achieve security with the RSA cryptosys tem, however, you should \nuse  integers  that  are  quite  long4more  than  1000  bits4to  resist  possible  advances  \nin the  art  of factoring.  In 2021,  RSA  moduli  are  commonly  in the range of 2048  \nto 4096  bits.  To  create  moduli  of such  sizes,  you  must  \u00fbnd  large  primes  ef\u00fbciently.  \nSection  31.8  addresses  this  problem.  \nFor  ef\u00fbciency,  RSA  is often  used  in a <hybrid=  or <key-manage ment= mode with \nfast  cryptosystems  that  are  not  public-key  cryptosystems.  With such a symmetric-  \nkey  system, the encryption and decryption keys are iden tical. If Alice wishes to \nsend a long message M  to Bob privately, she selects a random key K for the fast \nsymmetric-key  cryptosystem  and  encrypts  M  using K, obtaining ciphertext C , \nwhere C is as long as M  , but K is quite short. Then she encrypts K using  Bob\u2019s  \npublic RSA key. Since K is short, computing P B .K/  is fast (much faster than \ncomputing P B .M/). She then transmits .C;P  B .K//  to Bob, who decrypts P B .K/  \nto obtain K and then uses K to decrypt C , obtaining M  . \nA similar  hybrid  approach  creates  digital  signatures  ef\u00fbci ently. This approach \ncombines RSA with a public collision-resistant  hash  function  h4a  function  that  \nis easy to compute but for which it is computationa lly infeasible  to \u00fbnd  two  mes-  \nsages M  and M  0 such that h.M/  D h.M  0 /. The value h.M/  is a short (say, \n256-bit)  <\u00fbngerprint=  of the  message  M  . If Alice wishes to sign a message M  , \nshe  \u00fbrst  applies  h to M  to obtain  the  \u00fbngerprint  h.M/ , which she then encrypts \nwith her secret key. She sends .M;S  A .h.M///  to Bob as her signed version of M  . 942  Chapter  31  Number-Theoretic  Algorithms  \nBob can verify the signature by computing h.M/  and verifying that P A applied \nto S A .h.M//  as received equals h.M/ . Because no one can create two messages \nwith  the  same  \u00fbngerprint,  it is computationally  infeasible  to alter a signed message \nand preserve the validity of the signature. \nOne  way  to distribute  public  keys  uses  certi\u00fbcates . For example, assume that \nthere is a <trusted authority= T whose public key is known by everyone. Alice can \nobtain from T a signed  message  (her  certi\u00fbcate)  stating  that  <Alice\u2019s  public key \nis P A .= This  certi\u00fbcate  is <self-authenticating=  since  everyon e knows P T . Alice can \ninclude  her  certi\u00fbcate  with  her  signed  messages,  so that  the  recipient  has  Alice\u2019s  \npublic key immediately available in order to verify  her signature. Because her key \nwas signed by T , the  recipient  knows  that  Alice\u2019s  key  is really  Alice\u2019s.  \nExercises  \n31.7-1  \nConsider an RSA key set with p D 11, q D 29, n D 319, and e D 3. What \nvalue of d should  be used  in the  secret  key?  What  is the  encryption  of the  message \nM  D 100? \n31.7-2  \nProve  that  if Alice\u2019s  public  exponent  e is 3 and  an adversary  obtains  Alice\u2019s  secret  \nexponent d , where 0<d <\ufffd.n/ , then  the  adversary  can  factor  Alice\u2019s  modulus  n \nin time polynomial in the number of bits in n. (Although you are not asked to \nprove it, you might be interested to know that this  result remains true even if the \ncondition e D 3 is removed.  See  Miller  [327].)  \n? 31.7-3  \nProve that RSA is multiplicative in the sense that \nP A .M  1 /P  A .M  2 / D P A .M  1 M  2 / .mod n/:  \nUse this fact to prove that if an adversary had a p rocedure tha t could  ef\u00fbciently  \ndecrypt 1% of messages from Z n encrypted with P A , then the adversary could \nemploy a probabilistic algorithm to decrypt every m essage encrypted with P A with \nhigh probability. \n? 31.8  Primality  testing  \nThis  section  shows  how  to \u00fbnd  large  primes.  We  begin  with  a discussion of the \ndensity of primes, proceed to examine a plausible, but incomplete, approach to 31.8  Primality  testing  943 \nprimality testing, and then present an effective ra ndomized primality test due to \nMiller and Rabin. \nThe  density  of prime  numbers  \nMany  applications,  such  as cryptography,  call  for  \u00fbnding  large <random= primes. \nFortunately, large primes are not too rare, so that  it is feasible  to test  random  inte-  \ngers  of the  appropriate  size  until  you  \u00fbnd  one  that  is prime.  The prime  distribution  \nfunction  \ufffd.n/  speci\u00fbes  the  number  of primes  that  are  less  than  or equal  to n. For \nexample, \ufffd.10/  D 4, since there are 4 prime numbers less than or equal to 10, \nnamely, 2, 3, 5, and 7. The prime number theorem gives a useful approxima tion \nto \ufffd.n/ . \nTheorem  31.37  (Prime  number  theorem)  \nlim \nn!1  \ufffd.n/  \nn=  ln n D 1:  \nThe approximation n=  ln n gives reasonably accurate estimates of \ufffd.n/  even \nfor small n. For example, it is off by less than 6% at n D 10  9 , where \ufffd.n/  D \n50,847,534  and  n=  ln n \ue002 48,254,942.  (To  a number  theorist,  10  9 is a small  num-  \nber.) \nThe process of randomly selecting an integer n and determining whether it is \nprime  is really  just  a Bernoulli  trial  (see  Section  C.4).  By  the  prime  number  the-  \norem,  the  probability  of a success4that  is, the  probability  that n is prime4is  ap-  \nproximately 1=  ln n. The geometric distribution says how many trials m ust occur \nto obtain  a success,  and  by  equation  (C.36)  on  page  1197,  the  expected number \nof trials is approximately ln n. Thus,  in order  to \u00fbnd  a prime  that  has  the  same  \nlength as n by testing integers chosen randomly near n, the  expected  number  ex-  \namined would be approximately ln n. For  example,  the  expectation  is that  \u00fbnding  a \n1024-bit  prime  would  require  testing  approximately  ln 2 1024  \ue002 710  randomly  cho-  \nsen 1024-bit  numbers  for  primality.  (Of  course,  to cut  this  \u00fbgure  in half, choose \nonly odd integers.) \nThe remainder of this section shows how to determin e whether a large  odd  in-  \nteger n is prime. For notational convenience, we assume tha t n has the prime \nfactorization \nn D p e 1 \n1 p e 2 \n2 \ue001 \ue001 \ue001  p e r \nr ; \nwhere r \ue004 1, p 1 ;p  2 ;:::;p  r are the prime factors of n, and e 1 ;e 2 ;:::;e  r are  posi-  \ntive integers. The integer n is prime if and only if r D 1 and e 1 D 1. \nOne  simple  approach  to the  problem  of testing  for  primality  is trial  division : try \ndividing n by each integer 2;3;5;7;9;:::;  b p nc, skipping even integers greater 944  Chapter  31  Number-Theoretic  Algorithms  \nthan 2. We can conclude that n is prime if and only if none of the trial divisors \ndivides n. Assuming that each trial division takes constant time, the worst-case  \nrunning time is \u201a.  p n/, which is exponential in the length of n. (Recall that if n \nis encoded in binary using \u02c7 bits, then \u02c7 D dlg.n C 1/e, and so p n D \u201a.2  \u02c7=2  /.) \nThus, trial division works well only if n is very small or happens to have a small \nprime factor. When it works, trial division has the  advantage that  it not  only  deter-  \nmines whether n is prime or composite, it also determines one of n\u2019s prime  factors  \nif n is composite. \nThis  section  focuses  on  \u00fbnding  out  whether  a given  number  n is prime. If n \nis composite,  we  won\u2019t  worry  about  \u00fbnding  its  prime  factoriz ation. Computing \nthe prime factorization of a number is computationa lly expensive. You might be \nsurprised that it turns out to be much easier to as certain whether a given number \nis prime than it is to determine the prime factoriz ation of the number if it is not \nprime. \nPseudoprimality  testing  \nWe\u2019ll  start  with  a method  for  primality  testing  that  <almost  works= and, in fact, is \ngood  enough  for  many  practical  applications.  Later  on,  we\u2019ll  re\u00fbne  this  method  to \nremove the small defect. Let Z C \nn denote the nonzero elements of Z n : \nZ C \nn D f1;2;:::;n  \ue003 1g : \nIf n is prime, then Z C \nn D Z \ue003 \nn . \nWe say that n is a base- a pseudoprime  if n is composite and \na n\ue0021 D 1 .mod n/:  (31.39)  \nFermat\u2019s  theorem  (Theorem  31.31  on  page  932)  implies  that  if n is prime, then n \nsatis\u00fbes  equation  (31.39)  for  every  a in Z C \nn . Thus, if there is any a 2 Z C \nn such that \nn does not satisfy  equation  (31.39),  then  n is certainly composite. Surprisingly, \nthe converse almost holds, so that this criterion forms an almost perfe ct test for \nprimality. Instead of trying every value of a 2 Z C \nn , test to see whether n satis\u00fbes  \nequation  (31.39)  for  just  a D 2. If not, then declare n to be composite by returning \nCOMPOSITE. Otherwise,  return  PRIME , guessing that n is prime (when, in fact, all \nwe know is that n is either  prime  or a base-2 pseudoprime). \nThe procedure P SEUDOPRIME  on the next page pretends in this manner to check \nwhether n is prime. It uses the procedure M ODULAR-EXPONENTIATION  from \nSection  31.6.  It assumes  that  the  input  n is an odd integer greater than 2. This  pro-  \ncedure can make errors, but only of one type. That is, if it says that n is composite, \nthen it is always correct. If it says that n is prime, however, then it makes an error \nonly if n is a base-2 pseudoprime. \nHow often does P SEUDOPRIME  err?  Surprisingly  rarely.  There  are  only  22  val-  \nues of n less  than  10,000  for  which  it errs,  the  \u00fbrst  four  of which  are  341, 561, 645, 31.8  Primality  testing  945 \nPSEUDOPRIME  .n/  \n1 if MODULAR-EXPONENTIATION  .2;n  \ue003 1;n/  \u00a4 1 .mod n/ \n2 return  COMPOSITE  / / de\u00fbnitely  \n3 else  return  PRIME / / we hope! \nand 1105. We  won\u2019t  prove  it, but  the  probability  that  this  program  makes an error \non a randomly chosen \u02c7-bit  number  goes  to 0 as \u02c7 approaches 1. Using more \nprecise  estimates  due  to Pomerance  [361]  of the  number  of base-2 pseudoprimes \nof a given size, a randomly chosen 512-bit  number  that  is called  prime  by  PSEU- \nDOPRIME  has less than one chance in 10  20  of being  a base-2 pseudoprime, and a \nrandomly chosen 1024-bit  number  that  is called  prime  has  less  than  one  chance  in \n10  41  of being  a base-2 pseudoprime.  Thus,  if you  are  merely  trying  to \u00fbnd  a large  \nprime for some application, for all practical purpo ses you almost never go wrong \nby choosing large numbers at random until one of th em causes P SEUDOPRIME  to \nreturn PRIME . But when the numbers being tested for primality a re not randomly \nchosen, you might need a better approach for testin g primality.  As  we\u2019ll  see,  a lit-  \ntle more cleverness, and some randomization, will y ield a primality-testing  method  \nthat works well on all inputs. \nSince PSEUDOPRIME  checks  equation  (31.39)  for  only  a D 2, you might think \nthat you could eliminate all the errors by simply c hecking equation  (31.39)  for  a \nsecond base number, say a D 3. Better  yet,  you  could  check  equation  (31.39)  \nfor even more values of a. Unfortunately, even checking for several values o f a \ndoes not eliminate all errors, because there exist composite integers n, known as \nCarmichael  numbers, that  satisfy  equation  (31.39)  for  all a 2 Z \ue003 \nn . (The equation \ndoes fail when gcd .a;n/>14that  is, when  a \u2026 Z \ue003 \nn 4but  demonstrating  that  n is \ncomposite  by  \u00fbnding  such  an a can  be dif\u00fbcult  if n has only large prime factors.) \nThe  \u00fbrst  three  Carmichael  numbers  are  561, 1105 , and 1729 . Carmichael numbers \nare extremely rare. For example, only 255  of them  are  less  than  100,000,000.  \nExercise  31.8-2  helps  explain  why  they  are  so rare.  \nLet\u2019s  see  how  to improve  the  primality  test  so that  Carmichael  numbers  won\u2019t  \nfool it. \nThe  Miller-Rabin  randomized  primality  test  \nThe  Miller-Rabin  primality  test  overcomes  the  problems  of the simple procedure \nPSEUDOPRIME  with  two  modi\u00fbcations:  \n\ue001 It tries several randomly chosen base values a instead of just one base value. \n\ue001 While computing each modular exponentiation, it loo ks for a nontrivial square \nroot of 1, modulo n, during  the  \u00fbnal  set  of squarings.  If it \u00fbnds  one,  it stops  946  Chapter  31  Number-Theoretic  Algorithms  \nand returns COMPOSITE. Corollary  31.35  from  Section  31.6  justi\u00fbes  detecting  \ncomposites in this manner. \nThe  pseudocode  for  the  Miller-Rabin  primality  test  appears  in the procedures \nMILLER-RABIN and W ITNESS . The input n > 2  to M ILLER-RABIN is the odd \nnumber to be tested for primality, and s is the number of randomly chosen base \nvalues from Z C \nn to be tried.  The  code  uses  the  random-number  generator  RANDOM  \ndescribed  on  page  129:  RANDOM.2;n  \ue003 2/ returns a randomly chosen integer a \nsatisfying 2 \u0dc4 a \u0dc4 n \ue003 2. (This range of values avoids having a D \u00db1 .mod n/.) \nThe call of the auxiliary procedure W ITNESS .a;n/  returns TRUE if and only if a \nis a <witness= to the compositeness of n4that  is, if it is possible  using  a to prove \n(in a manner that we will see) that n is composite. The test W ITNESS .a;n/  is an \nextension of, but more effective than, the test in equation (31.39)  that  formed  the  \nbasis for P SEUDOPRIME , using a D 2. \nLet\u2019s  \u00fbrst  understand  how  WITNESS works,  and  then  we\u2019ll  see  how  the  Miller-  \nRabin primality test uses it. Let n \ue003 1 D 2 t u where t \ue004 1 and u is odd. That is, \nthe binary representation of n \ue003 1 is the binary representation of the odd integer u \nfollowed by exactly t zeros. Therefore, a n\ue0021 D .a u / 2 t .mod n/, so that one way \nto compute a n\ue0021 mod n is to \u00fbrst  compute  a u mod n and then square the result t \ntimes successively. \nMILLER-RABIN .n;s/  / / n>2  is odd \n1 for  j D 1 to s \n2 a D RANDOM.2;n  \ue003 2/ \n3 if WITNESS .a;n/  \n4 return  COMPOSITE  / / de\u00fbnitely  \n5 return  PRIME / / almost surely \nWITNESS .a;n/  \n1 let t and u be such that t \ue004 1, u is odd, and n \ue003 1 D 2 t u \n2 x 0 D MODULAR-EXPONENTIATION  .a;u;n/  \n3 for  i D 1 to t \n4 x i D x 2 \ni \ue0021 mod n \n5 if x i = = 1 and x i \ue0021 \u00a4 1 and x i \ue0021 \u00a4 n \ue003 1 \n6 return  TRUE / / found a nontrivial square root of 1 \n7 if x t \u00a4 1 \n8 return  TRUE / / composite, as in P SEUDOPRIME  \n9 return  FALSE 31.8  Primality  testing  947 \nThis pseudocode for W ITNESS computes a n\ue0021 mod n by  \u00fbrst  computing  the  \nvalue x 0 D a u mod n in line 2 and then repeatedly squaring the result t times \nin the for  loop  of lines  336.  By  induction  on  i , the sequence x 0 , x 1 , . . . , x t of \nvalues  computed  satis\u00fbes  the  equation  x i D a 2 i u .mod n/ for i D 0;1;:::;t  , \nso that in particular x t D a n\ue0021 .mod n/. After  line  4 performs  a squaring  step,  \nhowever,  the  loop  will  terminate  early  if lines  536  detect  that a nontrivial square \nroot of 1 has  just  been  discovered.  (We\u2019ll  explain  these  tests  shortl y.) If so, the \nprocedure stops and returns TRUE. Lines  738  return  TRUE if the value computed \nfor x t D a n\ue0021 .mod n/ is not  equal  to 1, just  as the  PSEUDOPRIME  procedure \nreturns COMPOSITE  in this case. Line 9 returns FALSE if lines  6 or 8 have  not  \nreturned TRUE . \nThe following lemma proves the correctness of W ITNESS . \nLemma  31.38  \nIf W ITNESS .a;n/  returns TRUE , then a proof that n is composite can be constructed \nusing a as a witness. \nProof  If W ITNESS returns TRUE from  line  8, it\u2019s  because  line  7 determined  that  \nx t D a n\ue0021 mod n \u00a4 1. If n is prime,  however,  Fermat\u2019s  theorem  (Theorem  31.31)  \nsays that a n\ue0021 D 1 .mod n/ for all a 2 Z \ue003 \nn . Since Z C \nn D Z \ue003 \nn if n is prime,  Fermat\u2019s  \ntheorem also says that a n\ue0021 D 1 .mod n/ for all a 2 Z C \nn . Therefore, n cannot be \nprime, and the equation a n\ue0021 mod n \u00a4 1 proves this fact. \nIf W ITNESS returns TRUE from  line  6, then  it has  discovered  that  x i \ue0021 is a non-  \ntrivial square root of 1, modulo n, since we have that x i \ue0021 \u00a4 \u00db1 .mod n/ yet \nx i D x 2 \ni \ue0021 D 1 .mod n/. Corollary  31.35  on  page  934  states  that  only  if n is com-  \nposite can there exist a nontrivial square root of 1, modulo n, so that demonstrating \nthat x i \ue0021 is a nontrivial square root of 1, modulo n proves that n is composite. \nThus, if the call W ITNESS .a;n/  returns TRUE , then n is surely composite, and \nthe witness a, along with the reason that the procedure returns TRUE (did it return \nfrom  line  6 or from  line  8?),  provides  a proof  that  n is composite. \nLet\u2019s  explore  an alternative  view  of the  behavior  of WITNESS as a function of \nthe sequence X D hx 0 ;x  1 ;:::;x  t i. We\u2019ll  \u00fbnd  this  view  useful  later  on,  when  we  \nanalyze  the  error  rate  of the  Miller-Rabin  primality  test.  Note that if x i D 1 for \nsome 0 \u0dc4 i <t  , W ITNESS might not compute the rest of the sequence. If it w ere \nto do so, however, each value x i C1 ;x  i C2 ;:::;x  t would be 1, so we can consider \nthese positions in the sequence X as being all 1s. There are four cases: \n1. X D h:::;d  i, where d \u00a4 1: the sequence X does not end in 1. Return TRUE \nin line  8, since  a is a witness to the compositeness of n (by  Fermat\u2019s  Theorem).  948  Chapter  31  Number-Theoretic  Algorithms  \n2. X D h1;1;:::;1 i: the sequence X is all 1s. Return FALSE , since a is not a \nwitness to the compositeness of n. \n3. X D h:::;  \ue0031;1;:::;1 i: the sequence X ends in 1, and  the  last  non-1 is equal \nto \ue0031. Return FALSE , since a is not a witness to the compositeness of n. \n4. X D h:::;d;1;:::;1 i, where d \u00a4 \u00db1: the sequence X ends in 1, but the last \nnon-1 is not \ue0031. Return TRUE in line  6: a is a witness to the compositeness \nof n, since d is a nontrivial square root of 1. \nNow,  let\u2019s  examine  the  Miller-Rabin  primality  test  based  on  how it uses the \nWITNESS procedure. As before, assume that n is an odd integer greater than 2. \nThe procedure M ILLER-RABIN is a probabilistic search for a proof that n is \ncomposite.  The  main  loop  (beginning  on  line  1) picks  up  to s random values of a \nfrom Z C \nn , except for 1 and n \ue003 1 (line 2). If it picks a value of a that is a witness to \nthe compositeness of n, then M ILLER-RABIN returns COMPOSITE  on  line  4. Such  \na result is always correct, by the correctness of W ITNESS . If M ILLER-RABIN \u00fbnds  \nno witness in s trials, then the procedure assumes that it found no  witness because \nno witnesses exist, and therefore it assumes that n is prime.  We\u2019ll  see  that  this  \nresult is likely to be correct if s is large enough, but there is still a tiny chance t hat \nthe procedure could be unlucky in its choice of s random values of a, so that even \nthough  the  procedure  failed  to \u00fbnd  a witness,  at least  one  witness exists. \nTo illustrate the operation of M ILLER-RABIN , let n be the  Carmichael  num-  \nber 561, so that n \ue003 1 D 560  D 2 4 \ue001 35, t D 4, and u D 35. If the procedure \nchooses a D 7 as a base, the column for b D 35  in Figure  31.4  (Section  31.6)  \nshows that W ITNESS computes x 0 D a 35  D 241  .mod 561/. Because of how \nthe MODULAR-EXPONENTIATION  procedure  operates  recursively  on  its  param-  \neter b, the  \u00fbrst  four  columns  in Figure  31.4  represent  the  factor  2 4 of 5604the  \nrightmost four zeros in the binary representation o f 5604reading  these  four  zeros  \nfrom right to left in the binary representation. Th us W ITNESS computes  the  se-  \nquence X D h241;  298;  166;  67;  1 i. Then, in the last squaring step, W ITNESS \ndiscovers that a 280  is a nontrivial square root of 1 since a 280  D 67  .mod n/ and \n.a 280  / 2 D a 560  D 1 .mod n/. Therefore, a D 7 is a witness to the compositeness \nof n, W ITNESS .7;n/  returns TRUE , and M ILLER-RABIN returns COMPOSITE . \nIf n is a \u02c7-bit  number,  MILLER-RABIN requires O.s\u02c7/  arithmetic operations \nand O.s\u02c7  3 / bit operations, since it requires asymptotically no  more work than s \nmodular exponentiations. \nError  rate  of the  Miller-Rabin  primality  test  \nIf M ILLER-RABIN returns PRIME , then there is a very slim chance that it has made  \nan error. Unlike P SEUDOPRIME , however, the chance of error does not depend \non n: there are no bad inputs for this procedure. Rathe r, it depends on the size of s 31.8  Primality  testing  949 \nand the <luck of the draw= in choosing base values a. Moreover, since each test is \nmore  stringent  than  a simple  check  of equation  (31.39),  we  can expect on general \nprinciples that the error rate should be small for randomly chosen integers n. The \nfollowing theorem presents a more precise argument.  \nTheorem  31.39  \nIf n is an odd composite number, then the number of witn esses to the composite-  \nness of n is at least .n \ue003 1/=2 . \nProof  The proof shows that the number of nonwitnesses is at most .n \ue003 1/=2 , \nwhich implies the theorem. \nWe start by claiming that any nonwitness must be a member of Z \ue003 \nn . Why?  \nConsider any nonwitness a. It must satisfy a n\ue0021 D 1 .mod n/ or, equivalently, \na \ue001 a n\ue0022 D 1 .mod n/. Thus the equation ax  D 1 .mod n/ has a solution, \nnamely a n\ue0022 . By  Corollary  31.21  on  page  924,  gcd.a;n/  j 1, which in turn implies \nthat gcd.a;n/  D 1. Therefore, a is a member of Z \ue003 \nn , and all nonwitnesses belong \nto Z \ue003 \nn . \nTo complete the proof, we show that not only are al l nonwitnesses contained \nin Z \ue003 \nn , they are all contained in a proper subgroup B of Z \ue003 \nn (recall that B is a \nproper subgroup of Z \ue003 \nn when B is subgroup of Z \ue003 \nn but B is not equal to Z \ue003 \nn ). By \nCorollary  31.16  on  page  921,  we  then  have  jB j \u0dc4 jZ \ue003 \nn j=2. Since jZ \ue003 \nn j \u0dc4  n \ue003 1, we \nobtain jB j \u0dc4  .n \ue003 1/=2 . Therefore, if all nonwitnesses are contained in a  proper \nsubgroup of Z \ue003 \nn , then the number of nonwitnesses is at most .n \ue003 1/=2 , so that the \nnumber of witnesses must be at least .n \ue003 1/=2 . \nTo  \u00fbnd  a proper  subgroup  B of Z \ue003 \nn containing  all  of the  nonwitnesses,  we  con-  \nsider two cases. \nCase 1: There exists an x 2 Z \ue003 \nn such that \nx n\ue0021 \u00a4 1 .mod n/:  \nIn other words, n is not a Carmichael number. Since, as noted earlier , Carmichael \nnumbers  are  extremely  rare,  case  1 is the  more  typical  case  (e.g., when n has been \nchosen randomly and is being tested for primality).  \nLet B D fb 2 Z \ue003 \nn W b n\ue0021 D 1 .mod n/g. The set B must be nonempty, since \n1 2 B . The set B is closed under multiplication modulo n, and so B is a subgroup \nof Z \ue003 \nn by  Theorem  31.14.  Every  nonwitness  belongs  to B , since a nonwitness a \nsatis\u00fbes  a n\ue0021 D 1 .mod n/. Since x 2 Z \ue003 \nn \ue003 B , we have that B is a proper \nsubgroup of Z \ue003 \nn . \nCase 2: For all x 2 Z \ue003 \nn , \nx n\ue0021 D 1 .mod n/:  (31.40)  950  Chapter  31  Number-Theoretic  Algorithms  \nIn other words, n is a Carmichael  number.  This  case  is extremely  rare  in prac-  \ntice.  Unlike  a pseudoprimality  test,  however,  the  Miller-Rabin  test  can  ef\u00fbciently  \ndetermine  that  Carmichael  numbers  are  composite,  as we\u2019re  about to see. \nIn this case, n cannot be a prime power. To see why, suppose to the  contrary \nthat n D p e , where p is a prime and e>1 . We derive a contradiction as follows. \nSince we assume that n is odd, p must  also  be odd.  Theorem  31.32  on  page  933  \nimplies that Z \ue003 \nn is a cyclic group: it contains a generator g such that ord n .g/  D \njZ \ue003 \nn j D  \ufffd.n/  D p e .1 \ue003 1=p/  D .p  \ue003 1/p  e\ue0021 . (The formula for \ufffd.n/  comes from \nequation  (31.21)  on  page  920.)  By  equation  (31.40),  we  have  g n\ue0021 D 1 .mod n/. \nThen  the  discrete  logarithm  theorem  (Theorem  31.33  on  page  933,  taking  y D 0) \nimplies that n \ue003 1 D 0 .mod \ufffd.n// , or \n.p  \ue003 1/p  e\ue0021 j p e \ue003 1:  \nThis statement is a contradiction for e >1 , since .p  \ue003 1/p  e\ue0021 is divisible by the \nprime p, but p e \ue003 1 is not. Thus n is not a prime power. \nSince the odd composite number n is not a prime power, we decompose it into \na product n 1 n 2 , where n 1 and n 2 are odd numbers greater than 1 that are relatively \nprime to each other. (There may be several ways to decompose n, and it does not \nmatter which one we choose. For example, if n D p e 1 \n1 p e 2 \n2 \ue001 \ue001 \ue001  p e r \nr , then we can \nchoose n 1 D p e 1 \n1 and n 2 D p e 2 \n2 p e 3 \n3 \ue001 \ue001 \ue001  p e r \nr .) \nRecall that t and u are such that n \ue003 1 D 2 t u, where t \ue004 1 and u is odd, and that \nfor an input a, the procedure W ITNESS computes the sequence \nX D ha u ;a  2u  ;a  2 2 u ;:::;a  2 t u i \nwhere all computations are performed modulo n. \nLet us call a pair .v;j/  of integers acceptable  if v 2 Z \ue003 \nn , j 2 f0;1;:::;t  g, and \nv 2 j u D \ue0031 .mod n/:  \nAcceptable pairs certainly exist, since u is odd. Choose v D n \ue003 1 and j D 0, \nand let u D 2k  C 1, so that v 2 j u D .n \ue003 1/ u D .n \ue003 1/ 2kC1 . Taking this number \nmodulo n gives .n \ue003 1/ 2kC1 D .n \ue003 1/ 2k  \ue001 .n \ue003 1/ D .\ue0031/ 2k  \ue001 \ue0031 D \ue0031 .mod n/. \nThus, .n \ue003 1;0/  is an acceptable pair. Now pick the largest possibl e j such that \nthere exists an acceptable pair .v;j/, and  \u00fbx  v so that .v;j/  is an acceptable pair. \nLet \nB D fx 2 Z \ue003 \nn W x 2 j u D \u00db1 .mod n/g : \nSince B is closed under multiplication modulo n, it is a subgroup of Z \ue003 \nn . By  The-  \norem  31.15  on  page  921,  therefore,  jB j divides jZ \ue003 \nn j. Every nonwitness must be \na member of B , since the sequence X produced by a nonwitness must either be \nall 1s or else contain a \ue0031 no later than the j th position, by the maximality of j . 31.8  Primality  testing  951 \n(If .a;j  0 / is acceptable, where a is a nonwitness, we must have j 0 \u0dc4 j by how we \nchose j .) \nWe now use the existence of v to demonstrate that there exists a w 2 Z \ue003 \nn \ue003 B , \nand hence that B is a proper subgroup of Z \ue003 \nn . Since v 2 j u D \ue0031 .mod n/, we also \nhave v 2 j u D \ue0031 .mod n 1 / by  Corollary  31.29  to the  Chinese  remainder  theorem.  \nBy  Corollary  31.28,  there  exists  a w simultaneously satisfying the equations \nw D v .mod n 1 /; \nw D 1 .mod n 2 /: \nTherefore, \nw 2 j u D \ue0031 .mod n 1 /; \nw 2 j u D 1 .mod n 2 /: \nCorollary  31.29  gives  that  w 2 j u \u00a4 1 .mod n 1 / implies w 2 j u \u00a4 1 .mod n/ and \nalso that w 2 j u \u00a4 \ue0031 .mod n 2 / implies w 2 j u \u00a4 \ue0031 .mod n/. Hence, we conclude \nthat w 2 j u \u00a4 \u00db1 .mod n/, and so w \u2026 B . \nIt remains to show that w 2 Z \ue003 \nn . We  start  by  working  separately  mod-  \nulo n 1 and modulo n 2 . Working modulo n 1 , since v 2 Z \ue003 \nn , we have that \ngcd.v;n/  D 1. Also, we have gcd .v;n  1 / D 1, since if v does not have any \ncommon divisors with n, then it certainly does not have any common diviso rs \nwith n 1 . Since w D v .mod n 1 /, we see that gcd .w;n  1 / D 1. Working  mod-  \nulo n 2 , we have w D 1 .mod n 2 / implies gcd.w;n  2 / D 1 by  Exercise  31.2-3.  \nSince gcd.w;n  1 / D 1 and gcd.w;n  2 / D 1, Theorem  31.6  on  page  908  yields  \ngcd.w;n  1 n 2 / D gcd.w;n/  D 1. That is, w 2 Z \ue003 \nn . \nTherefore, we have w 2 Z \ue003 \nn \ue003 B , and we can conclude in case 2 that B , which \nincludes all nonwitnesses, is a proper subgroup of Z \ue003 \nn and therefore has size at most \n.n \ue003 1/=2 . \nIn either case, the number of witnesses to the comp ositeness of n is at least \n.n \ue003 1/=2 . \nTheorem  31.40  \nFor any odd integer n > 2  and positive integer s , the probability that M ILLER- \nRABIN.n;s/  errs is at most 2 \ue002s . \nProof  By  Theorem  31.39,  if n is composite, then each execution of the for  loop \nof lines  134  of MILLER-RABIN has a probability of at least 1=2  of discovering a \nwitness to the compositeness of n. M ILLER-RABIN makes an error only if it is so \nunlucky as to miss discovering a witness to the com positeness of n on each of the \ns iterations of the main loop. The probability of suc h a sequence of misses is at \nmost 2 \ue002s . 952  Chapter  31  Number-Theoretic  Algorithms  \nIf n is prime, M ILLER-RABIN always reports P RIME , and if n is composite, the \nchance that M ILLER-RABIN reports P RIME is at most 2 \ue002s . \nWhen applying M ILLER-RABIN to a large randomly chosen integer n, however, \nwe need to consider as well the prior probability t hat n is prime,  in order  to cor-  \nrectly interpret M ILLER-RABIN\u2019s result.  Suppose  that  we  \u00fbx  a bit  length  \u02c7 and \nchoose at random an integer n of length \u02c7 bits to be tested for primality, so that \n\u02c7 \ue002 lg n \ue002 1:443  ln n. Let A denote the event that n is prime. By the prime \nnumber  theorem  (Theorem  31.37),  the  probability  that  n is prime is approximately \nPr fAg \ue002  1=  ln n \n\ue002 1:443=\u02c7  : \nNow let B denote the event that M ILLER-RABIN returns P RIME . We have that \nPr \u02da \nB j A \ue009 \nD 0 (or equivalently, that Pr fB j Ag D  1) and Pr \u02da \nB j A \ue009 \n\u0dc4 2 \ue002s (or \nequivalently, that Pr \u02da \nB j A \ue009 \n>1  \ue003 2 \ue002s ). \nBut what is Pr fA j B g, the probability that n is prime, given that M ILLER- \nRABIN has returned P RIME? By  the  alternate  form  of Bayes\u2019s  theorem  (equa-  \ntion  (C.20)  on  page  1189)  and  approximating  Pr \u02da B j A \ue009 by 2 \ue002s , we have \nPr fA j B g D  Pr fAg Pr fB j Ag \nPr fAg Pr fB j Ag C  Pr \u02da \nA \ue009 \nPr \u02da \nB j A \ue009 \n\ue002 .1=  ln n/ \ue001 1 \n.1=  ln n/ \ue001 1 C .1 \ue003 1=  ln n/ \ue001 2 \ue002s \n\ue002 1 \n1 C 2 \ue002s .ln n \ue003 1/ : \nThis probability does not exceed 1=2  until s exceeds lg.ln n \ue003 1/. Intuitively, that \nmany  initial  trials  are  needed  just  for  the  con\u00fbdence  derived  from  failing  to \u00fbnd  a \nwitness to the compositeness of n to overcome the prior bias in favor of n being \ncomposite. For a number with \u02c7 D 1024  bits, this initial testing requires about \nlg.ln n \ue003 1/ \ue002 lg.\u02c7=1:443/  \n\ue002 9 \ntrials. In any case, choosing s D 50  should  suf\u00fbce  for  almost  any  imaginable  \napplication. \nIn fact,  the  situation  is much  better.  If you  are  trying  to \u00fbnd  large primes by \napplying M ILLER-RABIN to large randomly chosen odd integers, then choosin g a \nsmall value of s (say 3) is unlikely  to lead  to erroneous  results,  though  we  won\u2019t  \nprove it here. The reason is that for a randomly ch osen odd composite integer n, \nthe expected number of nonwitnesses to the composit eness of n is likely to be \nconsiderably smaller than .n \ue003 1/=2 . Problems for Chapter 31 953 \nIf the integer n is not chosen randomly, however, the best that can be proven is \nthat the number of nonwitnesses is at most .n \ue003 1/=4, using an improved version \nof Theorem  31.39.  Furthermore,  there  do  exist  integers  n for which the number of \nnonwitnesses is .n \ue003 1/=4. \nExercises  \n31.8-1  \nProve that if an odd integer n>1  is not a prime or a prime power, then there exists \na nontrivial square root of 1, modulo n. \n? 31.8-2  \nIt is possible  to strengthen  Euler\u2019s  theorem  (Theorem  31.30 ) slightly to the form \na \ue006.n/  D 1 .mod n/ for all a 2 Z \ue003 \nn ; \nwhere n D p e 1 \n1 \ue001 \ue001 \ue001  p e r \nr and \ufffd.n/  is de\u00fbned  by  \n\ufffd.n/  D lcm.\ufffd.p  e 1 \n1 /; : : : ; \ufffd.p  e r \nr //:  \nProve that \ufffd.n/  j \ufffd.n/ . A composite number n is a Carmichael number if \n\ufffd.n/  j n \ue003 1. The smallest Carmichael number is 561  D 3 \ue001 11  \ue001 17, for which \n\ufffd.n/  D lcm.2;10;16/  D 80, which divides 560. Prove  that  Carmichael  num-  \nbers  must  be both  <square-free=  (not  divisible  by  the  square  of any prime) and the \nproduct of at least three primes. (For this reason,  they are not common.) \n31.8-3  \nProve that if x is a nontrivial square root of 1, modulo n, then gcd.x \ue003 1;n/  and \ngcd.x C 1;n/  are both nontrivial divisors of n. \nProblems  \n31-1  Binary  gcd  algorithm  \nMost computers can perform the operations of subtra ction, testing the parity (odd \nor even) of a binary integer, and halving more quic kly than computing remainders. \nThis problem investigates the binary  gcd  algorithm , which avoids the remainder \ncomputations  used  in Euclid\u2019s  algorithm.  \na. Prove that if a and b are both even, then gcd .a;b/  D 2 \ue001 gcd.a=2;b=2/ . \nb. Prove that if a is odd and b is even, then gcd .a;b/  D gcd.a;b=2/ . \nc. Prove that if a and b are both odd, then gcd .a;b/  D gcd..a  \ue003 b/=2;b/ . 954  Chapter  31  Number-Theoretic  Algorithms  \nd. Design  an ef\u00fbcient  binary  gcd  algorithm  for  input  integers  a and b, where \na \ue004 b, that runs in O.lg a/ time. Assume that each subtraction, parity test, \nand halving takes unit time. \n31-2  Analysis  of bit  operations  in Euclid\u2019s  algorithm  \na. Consider the ordinary <paper and pencil= algorithm for long division: dividing \na by b, which yields a quotient q and remainder r . Show that this method \nrequires O..1  C lg q/ lg b/ bit operations. \nb. De\u00fbne  \ufffd.a;  b/ D .1 C lg a/.1  C lg b/. Show that the number of bit operations \nperformed by E UCLID in reducing the problem of computing gcd .a;b/  to that \nof computing gcd .b;a  mod b/ is at most c.\ufffd.a; b/  \ue003 \ufffd.b;  a mod b//  for some \nsuf\u00fbciently  large  constant  c>0 . \nc. Show that E UCLID.a;b/  requires O.\ufffd.a; b//  bit operations in general and \nO.\u02c7  2 / bit operations when applied to two \u02c7-bit  inputs.  \n31-3  Three  algorithms  for  Fibonacci  numbers  \nThis  problem  compares  the  ef\u00fbciency  of three  methods  for  computing the nth Fi-  \nbonacci number F n , given n. Assume  that  the  cost  of adding,  subtracting,  or mul-  \ntiplying two numbers is O.1/ , independent of the size of the numbers. \na. Show that the running time of the straightforward r ecursive method  for  com-  \nputing F n based  on  recurrence  (3.31)  on  page  69  is exponential  in n. (See, for \nexample, the F IB procedure  on  page  751.)  \nb. Show how to compute F n in O.n/  time using memoization. \nc. Show how to compute F n in O.lg n/ time  using  only  integer  addition  and  mul-  \ntiplication. ( Hint: Consider the matrix \ue002 0 1  \n1 1  \u00cd \nand its powers.) \nd. Assume now that adding two \u02c7-bit  numbers  takes  \u201a.\u02c7/  time  and  that  multi-  \nplying two \u02c7-bit  numbers  takes  \u201a.\u02c7  2 / time. What is the running time of these \nthree methods under this more reasonable cost measu re for the elementary  arith-  \nmetic  operations?  \n31-4  Quadratic  residues  \nLet p be an odd prime. A number a 2 Z \ue003 \np is a quadratic  residue  modulo p, if the \nequation x 2 D a .mod p/  has a solution for the unknown x . \na. Show that there are exactly .p  \ue003 1/=2  quadratic residues, modulo p. Notes for Chapter 31 955 \nb. If p is prime,  we  de\u00fbne  the  Legendre  symbol  \u00e3 a \np \u00e4 \n, for a 2 Z \ue003 \np , to be 1 if a is a \nquadratic residue, modulo p, and \ue0031 otherwise. Prove that if a 2 Z \ue003 \np , then \n\ue002 a \np \u00cd \nD a .p\ue0021/=2  .mod p/:  \nGive  an ef\u00fbcient  algorithm  that  determines  whether  a given  number a is a qua-  \ndratic residue, modulo p. Analyze  the  ef\u00fbciency  of your  algorithm.  \nc. Prove that if p is a prime of the form 4k  C 3 and a is a quadratic residue in Z \ue003 \np , \nthen a kC1 mod p is a square root of a, modulo p. How much time is required \nto \u00fbnd  the  square  root  of a quadratic  residue  a, modulo p? \nd. Describe  an ef\u00fbcient  randomized  algorithm  for  \u00fbnding  a nonq uadratic residue, \nmodulo an arbitrary prime p, that is, a member of Z \ue003 \np that is not a quadratic \nresidue. How many arithmetic operations does your a lgorithm require  on  aver-  \nage?  \nChapter  notes  \nKnuth  [260]  contains  a good  discussion  of algorithms  for  \u00fbnding  the  greatest  com-  \nmon  divisor,  as well  as other  basic  number-theoretic  algorithms.  Dixon  [121]  gives  \nan overview  of factorization  and  primality  testing.  Bach  [33],  Riesel  [378],  and  \nBach  and  Shallit  [34]  provide  overviews  of the  basics  of comp utational number \ntheory;  Shoup  [411]  provides  a more  recent  survey.  The  confe rence proceedings \nedited  by  Pomerance  [362]  contains  several  excellent  surve y articles. \nKnuth  [260]  discusses  the  origin  of Euclid\u2019s  algorithm.  It appears  in Book  7, \nPropositions  1 and  2, of the  Greek  mathematician  Euclid\u2019s  Elements , which was \nwritten  around  300  B. C. E. Euclid\u2019s  description  may  have  been  derived  from  an \nalgorithm  due  to Eudoxus  around  375  B. C. E. Euclid\u2019s  algorithm  may  hold  the  \nhonor of being the oldest nontrivial algorithm, riv aled only by an algorithm for \nmultiplication  known  to the  ancient  Egyptians.  Shallit  [407]  chronicles  the  history  \nof the  analysis  of Euclid\u2019s  algorithm.  \nKnuth  attributes  a special  case  of the  Chinese  remainder  theorem  (Theo-  \nrem  31.27)  to the  Chinese  mathematician  Sun-Ts\u02d8  u, who  lived  sometime between \n200 B. C. E. and 200 C. E.4the  date  is quite  uncertain.  The  same  special  case  was  \ngiven  by  the  Greek  mathematician  Nichomachus  around  100  C. E. It was  general-  \nized  by  Qin  Jiushao  in 1247.  The  Chinese  remainder  theorem  was  \u00fbnally  stated  \nand  proved  in its  full  generality  by  L. Euler  in 1734.  \nThe  randomized  primality-testing  algorithm  presented  here  is due  to Miller  [327]  \nand  Rabin  [373]  and  is the  fastest  randomized  primality-tes ting algorithm known, 956  Chapter  31  Number-Theoretic  Algorithms  \nto within  constant  factors.  The  proof  of Theorem  31.40  is a slight adaptation of \none  suggested  by  Bach  [32].  A proof  of a stronger  result  for  MILLER-RABIN \nwas  given  by  Monier  [332,  333].  For  many  years  primality-tes ting was the classic \nexample of a problem where randomization appeared t o be necessary to obtain \nan ef\u00fbcient  (polynomial-time)  algorithm.  In 2002,  however,  Agrawal,  Kayal,  and  \nSaxena  [4]  surprised  everyone  with  their  deterministic  polynomial-time  primality-  \ntesting algorithm. Until then, the fastest determin istic primality testing algorithm \nknown,  due  to Cohen  and  Lenstra  [97],  ran  in .lg n/ O.lg lg lg n/  time on input n, which \nis just slightly superpolynomial. Nonetheless, for practical purposes, randomized \nprimality-testing  algorithms  remain  more  ef\u00fbcient  and  are  generally preferred. \nBeauchemin,  Brassard,  Cr\u00b4  epeau,  Goutier,  and  Pomerance  [40] nicely discuss the \nproblem  of \u00fbnding  large  <random=  primes.  \nThe  concept  of a public-key  cryptosystem  is due  to Dif\u00fbe  and  Hellman  [115].  \nThe  RSA  cryptosystem  was  proposed  in 1977  by  Rivest,  Shamir,  and Adleman \n[380].  Since  then,  the  \u00fbeld  of cryptography  has  blossomed.  Our understanding of \nthe RSA cryptosystem has deepened, and modern imple mentations  use  signi\u00fbcant  \nre\u00fbnements  of the  basic  techniques  presented  here.  In addition,  many  new  tech-  \nniques have been developed for proving cryptosystem s to be secure. For example, \nGoldwasser  and  Micali  [190]  show  that  randomization  can  be an effective tool in \nthe  design  of secure  public-key  encryption  schemes.  For  signature  schemes,  Gold-  \nwasser,  Micali,  and  Rivest  [191]  present  a digital-signatu re scheme for which every \nconceivable  type  of forgery  is provably  as dif\u00fbcult  as factoring.  Katz  and  Lindell  \n[253]  provide  an overview  of modern  cryptography.  \nThe best algorithms for factoring large numbers hav e a running time that grows \nroughly exponentially with the cube root of the len gth of the number n to be fac-  \ntored.  The  general  number-\u00fbeld  sieve  factoring  algorithm  (as  developed  by  Buh-  \nler,  Lenstra,  and  Pomerance  [77]  as an extension  of the  ideas  in the  number-\u00fbeld  \nsieve  factoring  algorithm  by  Pollard  [360]  and  Lenstra  et al.  [295]  and  re\u00fbned  by  \nCoppersmith  [102]  and  others)  is perhaps  the  most  ef\u00fbcient  such  algorithm  in gen-  \neral  for  large  inputs.  Although  it is dif\u00fbcult  to give  a rigor ous analysis of this \nalgorithm, under reasonable assumptions we can deri ve a running-time  estimate  of \nL.1=3;n/  1:902Co.1/  , where L.\u02db;n/  D e .ln n/  \u02db .ln ln n/  1\ue003\u02db . \nThe  elliptic-curve  method  due  to Lenstra  [296]  may  be more  effective for some \ninputs  than  the  number-\u00fbeld  sieve  method,  since  it can  \u00fbnd  a small  prime  fac-  \ntor p quite  quickly.  With  this  method,  the  time  to \u00fbnd  p is estimated to be \nL.1=2;p/  p  \n2Co.1/  . 32  String  Matching  \nText-editing  programs  frequently  need  to \u00fbnd  all  occurrenc es of a pattern in the \ntext. Typically, the text is a document being edite d, and the pattern searched for \nis a particular  word  supplied  by  the  user.  Ef\u00fbcient  algorith ms for this problem \n4called  <string  matching=4can  greatly  aid  the  responsiveness  of the  text-editing  \nprogram.  Among  their  many  other  applications,  string-matc hing algorithms search \nfor particular patterns in DNA sequences. Internet search engines also use them to \n\u00fbnd  web  pages  relevant  to queries.  \nThe  string-matching  problem  can  be stated  formally  as follo ws. The text is given \nas an array T\u01521  W n\ufffd of length n, and the pattern is an array P\u01521  W m\ufffd  of length m \u0dc4 n. \nThe elements of P and T are characters drawn from an alphabet \u2020, which  is a \u00fbnite  \nset of characters. For example, \u2020 could be the set f0; 1g, or it could be the set \nfa; b;:::;  zg. The character arrays P and T are often called strings  of characters. \nAs  Figure  32.1  shows,  pattern  P occurs  with  shift  s in text T (or, equivalently, \nthat pattern P occurs  beginning  at position  s C 1 in text T ) if 0 \u0dc4 s \u0dc4 n \ue003 m and \nT\u0152s  C 1 W s C m\ufffd  D P\u01521  W m\ufffd, that is, if T\u0152s  C j\ufffd D P\u0152j\ufffd , for 1 \u0dc4 j \u0dc4 m. If P \noccurs with shift s in T , then s is a valid  shift, and otherwise, s is an invalid  shift. \nThe string-matching  problem  is the  problem  of \u00fbnding  all  valid  shifts  with  which  \na given pattern P occurs in a given text T . \na b c a b a a b c a b a c  \na b a a  pattern P text T \ns = 3 \nFigure  32.1  An  example  of the  string-matching  problem  to \u00fbnd  all  occurre nces of the pattern \nP D abaa  in the text T D abcabaabcabac . The pattern occurs only once in the text, at \nshift s D 3, which is a valid shift. A vertical line connects each character of the pattern to its \nmatching character in the text, and all matched cha racters are shaded blue. 958  Chapter  32  String  Matching  \nExcept  for  the  naive  brute-force  algorithm  in Section  32.1,  each  string-matching  \nalgorithm in this chapter performs some preprocessi ng based on the pattern and \nthen  \u00fbnds  all  valid  shifts.  We  call  this  latter  phase  <matching.=  Here  are  the  pre-  \nprocessing  and  matching  times  for  each  of the  string-matchi ng algorithms in this \nchapter. The total running time of each algorithm i s the sum of the preprocessing \nand matching times: \nAlgorithm Preprocessing time Matching time \nNaive 0 O..n  \ue003 m C 1/m/  \nRabin-Karp  \u201a.m/  O..n  \ue003 m C 1/m/  \nFinite automaton O.m  j\u2020j/ \u201a.n/  \nKnuth-Morris-Pratt  \u201a.m/  \u201a.n/  \nSuf\u00fbx  array  1 O.n  lg n/ O.m  lg n C km/  \nSection  32.2  presents  an interesting  string-matching  algorithm, due to Rabin and \nKarp.  Although  the  \u201a..n  \ue003 m C 1/m/  worst-case  running  time  of this  algorithm  \nis no better than that of the naive method, it work s much better on average and \nin practice.  It also  generalizes  nicely  to other  pattern-matching  problems.  Sec-  \ntion  32.3  then  describes  a string-matching  algorithm  that  begins by constructing a \n\u00fbnite  automaton  speci\u00fbcally  designed  to search  for  occurrences  of the  given  pat-  \ntern P in a text. This algorithm takes O.m  j\u2020j/ preprocessing time, but only \u201a.n/  \nmatching  time.  Section  32.4  presents  the  similar,  but  much  cleverer,  Knuth-Morris-  \nPratt  (or  KMP)  algorithm,  which  has  the  same  \u201a.n/  matching time, but it reduces \nthe preprocessing time to only \u201a.m/ . \nA completely  different  approach  appears  in Section  32.5,  which  examines  suf\u00fbx  \narrays  and  the  longest  common  pre\u00fbx  array.  You  can  use  these  arrays not only \nto \u00fbnd  a pattern  in a text,  but  also  to answer  other  questions,  such as what is the \nlongest repeated substring in the text and what is the longest common substring \nbetween  two  texts.  The  algorithm  to form  the  suf\u00fbx  array  in Section  32.5  takes  \nO.n  lg n/ time  and,  given  the  suf\u00fbx  array,  the  section  shows  how  to comp ute the \nlongest  common  pre\u00fbx  array  in O.n/  time. \nNotation  and  terminology  \nWe denote by \u2020 \ue003 (read  <sigma-star=)  the  set  of all  \u00fbnite-length  strings  formed \nusing characters from the alphabet \u2020. This  chapter  considers  only  \u00fbnite-length  \n1 For  suf\u00fbx  arrays,  the  preprocessing  time  of O.n  lg n/ comes  from  the  algorithm  presented  in Sec-  \ntion  32.5.  It can  be reduced  to \u201a.n/  by  using  the  algorithm  in Problem  32-2.  The  factor  k in the \nmatching time denotes the number of occurrences of the pattern in the text. Chapter  32  String  Matching  959 \nx \nz \nx y \ny \n(a) x \nz \nx y \ny \n(b) x \nz \nx y \ny \n(c) \nFigure  32.2  A graphical  proof  of Lemma  32.1.  Suppose  that  x \u2742 \u00b4 and y \u2742 \u00b4. The three parts \nof the  \u00fbgure  illustrate  the  three  cases  of the  lemma.  Vertica l lines connect matching regions (shown \nin blue) of the strings. (a)  If jxj \u0dc4 jyj, then x \u2742 y. (b)  If jxj \ue004 jyj, then y \u2742 x. (c)  If jxj D jyj, \nthen x D y. \nstrings. The 0-length  empty  string , denoted \", also belongs to \u2020 \ue003 . The length of a \nstring x is denoted jx j. The concatenation  of two strings x and y , denoted xy  , has \nlength jx j C jy j and consists of the characters from x followed by the characters \nfrom y . \nA string w is a pre\u00fbx  of a string x , denoted w g x , if x D wy  for some \nstring y 2 \u2020 \ue003 . Note that if w g x , then jwj \u0dc4 jx j. Similarly, a string w is a suf\u00fbx  \nof a string x , denoted w h x , if x D yw  for some y 2 \u2020 \ue003 . As  with  a pre\u00fbx,  \nw h x implies jwj \u0dc4 jx j. For example, ab  g abcca  and cca  h abcca . A \nstring w is a proper  pre\u00fbx  of x if w g x and jwj < jx j, and likewise for a proper  \nsuf\u00fbx . The empty string \" is both  a suf\u00fbx  and  a pre\u00fbx  of every  string.  For  any  \nstrings x and y and any character a, we have x h y if and only if xa  h ya. The \ng and h relations are transitive. The following lemma will be useful later. \nLemma  32.1  (Overlapping-suf\u00fbx  lemma)  \nSuppose that x , y , and \u00b4 are strings such that x h \u00b4 and y h \u00b4. If jx j \u0dc4 jy j, \nthen x h y . If jx j \ue004 jy j, then y h x . If jx j D jy j, then x D y . \nProof  See  Figure  32.2  for  a graphical  proof.  \nFor convenience, denote the k-character  pre\u00fbx  P\u01521  W k\ufffd of the pattern P\u01521  W m\ufffd  \nby P\u0152  W k\ufffd. Thus, we can write P\u0152  W 0\ufffd D \" and P\u0152  W m\ufffd  D P D P\u01521  W m\ufffd. Similarly, \ndenote the k-character  pre\u00fbx  of the  text  T by T\u0152  W k\ufffd. Using this notation, we 960  Chapter  32  String  Matching  \ncan  state  the  string-matching  problem  as that  of \u00fbnding  all  shifts s in the range \n0 \u0dc4 s \u0dc4 n \ue003 m such that P h T\u0152  W s C m\ufffd. \nOur  pseudocode  allows  two  equal-length  strings  to be compar ed for equality \nas a primitive operation. If the strings are compar ed from left to right and the \ncomparison stops when a mismatch is discovered, we assume that the time taken \nby such a test is a linear function of the number o f matching characters discovered. \nTo be precise, the test < x == y = is assumed to take \u201a.t/  time, where t is the length \nof the longest string \u00b4 such that \u00b4 g x and \u00b4 g y . \n32.1  The  naive  string-matching  algorithm  \nThe N AIVE-STRING-MATCHER procedure  \u00fbnds  all  valid  shifts  using  a loop  that  \nchecks the condition P\u01521  W m\ufffd  D T\u0152s  C 1 W s C m\ufffd  for each of the n \ue003 m C 1 possible \nvalues of s . \nNAIVE-STRING-MATCHER .T;P;n;m/  \n1 for  s D 0 to n \ue003 m \n2 if P\u01521  W m\ufffd  == T\u0152s  C 1 W s C m\ufffd  \n3 print <Pattern occurs with shift= s \nFigure  32.3  portrays  the  naive  string-matching  procedure  as sliding a <template= \ncontaining the pattern over the text, noting for wh ich shifts all of the characters \non the template equal the corresponding characters in the text. The for  loop of \nlines  133  considers  each  possible  shift  explicitly.  The  test in line 2 determines \nwhether the current shift is valid. This test impli citly loops to check corresponding \ncharacter positions until all positions match succe ssfully or a mismatch is found. \nLine  3 prints  out  each  valid  shift  s . \nProcedure N AIVE-STRING-MATCHER takes O..n  \ue003 m C 1/m/  time, and this \nbound is tight in the worst case. For example, cons ider the text string a n (a string \nof n a\u2019s)  and  the  pattern  a m . For each of the n \ue003 m C1 possible values of the shift s , \nthe implicit loop on line 2 to compare correspondin g characters must execute m \ntimes  to validate  the  shift.  The  worst-case  running  time  is thus \u201a..n  \ue003 m C 1/m/ , \nwhich is \u201a.n  2 / if m D bn=2c. Because it requires no preprocessing, N AIVE- \nSTRING-MATCHER\u2019s running  time  equals  its  matching  time.  \nNAIVE-STRING-MATCHER is far from an optimal procedure for this problem. \nIndeed,  this  chapter  will  show  that  the  Knuth-Morris-Pratt  algorithm is much better \nin the  worst  case.  The  naive  string-matcher  is inef\u00fbcient  because it entirely ignores \ninformation gained about the text for one value of s when it considers other values \nof s . Such information can be quite valuable, however. For example, if P D aaab  32.1  The  naive  string-matching  algorithm  961 \na c a a b c \na a b s = 0 \n(a) a c a a b c \na a b s = 1 \n(b) a c a a b c \na a b s = 2 \n(c) a c a a b c \na a b s = 3 \n(d) \nFigure  32.3  The operation of the N AIVE-STRING-MATCHER procedure for the pattern P D aab  \nand the text T D acaabc . Imagine the pattern P as a template that slides next to the text. \n(a)\u2013(d)  The four successive alignments tried by the naive s tring matcher. In each part, vertical \nlines connect corresponding regions found to match (shown in blue), and a red jagged line connects \nthe  \u00fbrst  mismatched  character  found,  if any.  The  algorithm  \u00fbnds one occurrence of the pattern, at \nshift s D 2, shown in part (c). \nand s D 0 is valid, then none of the shifts 1, 2, or 3 are valid, since T\u01524\ufffd  D b. \nThe following sections examine several ways to make  effective use of this sort of \ninformation. \nExercises  \n32.1-1  \nShow the comparisons the naive string matcher makes  for the pattern P D 0001  \nin the text T D 000010001010001  . \n32.1-2  \nSuppose that all characters in the pattern P are different. Show how to accelerate \nNAIVE-STRING-MATCHER to run in O.n/  time on an n-character  text  T . \n32.1-3  \nSuppose that pattern P and text T are randomly  chosen strings of length m and n, \nrespectively, from the d -ary  alphabet  \u2020 d D f0;1;:::;d  \ue003 1g, where d \ue004 2. Show \nthat the expected  number  of character-to-character  comparisons  made  by  the  im-  \nplicit loop in line 2 of the naive algorithm is \n.n \ue003 m C 1/ 1 \ue003 d \ue002m \n1 \ue003 d \ue0021 \u0dc4 2.n  \ue003 m C 1/ \nover all executions of this loop. (Assume that the naive algorithm stops comparing \ncharacters  for  a given  shift  once  it \u00fbnds  a mismatch  or matche s the entire pattern.) \nThus, for randomly chosen strings, the naive algori thm is quite  ef\u00fbcient.  \n32.1-4  \nSuppose that the pattern P may contain occurrences of a gap  character  } that can \nmatch an arbitrary  string of characters (even one of 0 length). For example, the \npattern ab}ba}c occurs in the text cabccbacbacab  as 962  Chapter  32  String  Matching  \nc ab  \u2019 \nab  cc  \u2019 \n} ba  \u2019 \nba  cba  \u201c  \n} c \u2019 \nc ab  \nand as \nc ab  \u2019 \nab  ccbac  \u2014  \n} ba  \u2019 \nba  \u2019 \n} c \u2019 \nc ab  : \nThe gap character may occur an arbitrary number of times in the pattern but not \nat all  in the  text.  Give  a polynomial-time  algorithm  to deter mine whether such a \npattern P occurs in a given text T , and analyze the running time of your algorithm. \n32.2  The  Rabin-Karp  algorithm  \nRabin  and  Karp  proposed  a string-matching  algorithm  that  performs  well  in prac-  \ntice and that also generalizes to other algorithms for related problems, such as \ntwo-dimensional  pattern  matching.  The  Rabin-Karp  algorit hm uses \u201a.m/  prepro-  \ncessing  time,  and  its  worst-case  running  time  is \u201a..n  \ue003 m C 1/m/ . Based on certain \nassumptions,  however,  its  average-case  running  time  is better. \nThis  algorithm  makes  use  of elementary  number-theoretic  notions such as the \nequivalence of two numbers modulo a third number. Y ou might want to refer to \nSection  31.1  for  the  relevant  de\u00fbnitions.  \nFor  expository  purposes,  let\u2019s  assume  that  \u2020 D f0; 1; 2;:::;  9g, so that each \ncharacter is a decimal digit. (In the general case,  you can assume  that  each  char-  \nacter  is a digit  in radix-d notation, so that it has a numerical value in the r ange 0 \nto d \ue0031, where d D j\u2020j.) You can then view a string of k consecutive characters as \nrepresenting  a length-k decimal number. For example, the character string 31415  \ncorresponds  to the  decimal  number  31,415.  Because  we  interpret  the  input  char-  \nacters as both graphical symbols and digits, it wil l be convenient in this section to \ndenote them as digits in standard text font. \nGiven  a pattern  P\u01521  W m\ufffd, let p denote its corresponding decimal value. In a \nsimilar manner, given a text T\u01521  W n\ufffd, let t s denote  the  decimal  value  of the  length-m \nsubstring T\u0152s  C 1 W s C m\ufffd, for s D 0;1;:::;n  \ue003 m. Certainly, t s D p if and only \nif T\u0152s  C 1 W s C m\ufffd  D P\u01521  W m\ufffd, and thus, s is a valid shift if and only if t s D p. If \nyou could compute p in \u201a.m/  time and all the t s values in a total of \u201a.n  \ue003 m C 1/ \ntime, 2 then you could determine all valid shifts s in \u201a.m/  C \u201a.n  \ue003 m C 1/ D \u201a.n/  \n2 We write \u201a.n  \ue003 m C 1/ instead of \u201a.n  \ue003 m/  because s takes on n \ue003 m C 1 different values. The \n<C1= is signi\u00fbcant  in an  asymptotic  sense  because  when  m D n, computing the lone t s value takes \n\u201a.1/  time, not \u201a.0/  time. 32.2 The Rabin-Karp algorithm 963 \ntime by comparing p with each of the t s values.  (For  the  moment,  let\u2019s  not  worry  \nabout the possibility that p and the t s values might be very large numbers.) \nIndeed, you can compute p in \u201a.m/  time  using  Horner\u2019s  rule  (see  Problem  2-3):  \np D P\u0152m\ufffd  C 10  \ue002 \nP\u0152m  \ue003 1\ufffd C 10  \u00e3 P\u0152m  \ue003 2\ufffd C \ue001 \ue001 \ue001 C  10.P\u01522\ufffd  C 10P\u01521\ufffd/  \ue001 \ue001 \ue001  \u00e4 \u00cd \n: \nSimilarly, you can compute t 0 from T\u01521  W m\ufffd  in \u201a.m/  time. \nTo compute the remaining values t 1 ;t 2 ;:::;t  n\ue002m in \u201a.n  \ue003 m/  time, observe that \nyou can compute t sC1 from t s in constant time, since \nt sC1 D 10.t  s \ue003 10  m\ue0021 T\u0152s  C 1\ufffd/  C T\u0152s  C m C 1\ufffd:  (32.1)  \nSubtracting 10  m\ue0021 T\u0152s  C 1\ufffd removes  the  high-order  digit  from  t s , multiplying the \nresult by 10  shifts the number left by one digit position, and a dding T\u0152s  C m C 1\ufffd \nbrings  in the  appropriate  low-order  digit.  For  example,  suppose that m D 5, \nt s D 31415, and  the  new  low-order  digit  is T\u0152s  C 5 C 1\ufffd D 2. The  high-order  \ndigit to remove is T\u0152s  C 1\ufffd D 3, and so \nt sC1 D 10.31415  \ue003 10000  \ue001 3/ C 2 \nD 14152  : \nIf you precompute the constant 10  m\ue0021 (which you can do in O.lg m/  time  us-  \ning  the  techniques  of Section  31.6,  although  for  this  applic ation a straightforward \nO.m/-time  method  suf\u00fbces),  then  each  execution  of equation  (32.1)  takes  a con-  \nstant number of arithmetic operations. Thus, you ca n compute p in \u201a.m/  time, \nand you can compute all of t 0 ;t 1 ;:::;t  n\ue002m in \u201a.n  \ue003 m C 1/ time. Therefore, \nyou  can  \u00fbnd  all  occurrences  of the  pattern  P\u01521  W m\ufffd  in the text T\u01521  W n\ufffd with \u201a.m/  \npreprocessing time and \u201a.n  \ue003 m C 1/ matching time. \nThis scheme works well if P is short enough and the alphabet \u2020 is small enough \nthat arithmetic operations on p and t s take constant time. But what if P is long, or if \nthe size of \u2020 means that instead of powers of 10  in equation  (32.1)  you  have  to use  \npowers of a larger number (such as powers of 256  for the extended ASCII character \nset)?  Then  the  values  of p and t s might be too large to work with in constant time. \nFortunately,  this  problem  can  be solved,  as Figure  32.4  show s: compute p and \nthe t s values modulo a suitable modulus q. You can compute p modulo q in \u201a.m/  \ntime and all the t s values modulo q in \u201a.n  \ue003 m C 1/ time. With j\u2020j D  10, if \nyou choose the modulus q as a prime such that 10q  just  \u00fbts  within  one  computer  \nword, then you can perform all the necessary comput ations with single-precision  \narithmetic. In general, with a d -ary  alphabet  f0;1;:::;d  \ue003 1g, choose q so that \ndq  \u00fbts  within  a computer  word  and  adjust  the  recurrence  equation  (32.1)  to work  \nmodulo q, so that it becomes \nt sC1 D \u00e3 \nd.t  s \ue003 T\u0152s  C 1\ufffdh/  C T\u0152s  C m C 1\ufffd \u00e4 \nmod q;  (32.2)  964  Chapter  32  String  Matching  \n2 3 5 9 0 2 3 1 4 1 5 2 6 7 3 9 9 2 1 \n7 \n(a) mod  13  \n2 3 5 9 0 2 3 1 4 1 5 2 6 7 3 9 9 2 1 \n7 \n(b) mod  13  1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  16  17  18  19  \n8 9 3 11  0 1 8 5 11  9 11  7 10  4 \nvalid \nmatch spurious \nhit \u2026 \u2026 \u2026 \n3 1 4 1 5 2 \n7 8 old \nhigh-order  \ndigit new \nlow-order  \ndigit \n= (31415  3 3\u00b710000)\u00b710  + 2 (mod  13)  old \nhigh-order  \ndigit new \nlow-order  \ndigit shift \n= (7 3 3\u00b73)\u00b710  + 2 (mod  13)  \n= 8 (mod  13)  \n(c) 14152  \nFigure  32.4  The  Rabin-Karp  algorithm.  Each  character  is a decimal  digit . Values are computed \nmodulo 13. (a)  A text string. A window of length 5 is shaded blue. The numerical value of the blue \nnumber, computed modulo 13, yields the value 7. (b)  The same text string with values computed \nmodulo 13  for  each  possible  position  of a length-5 window. Assuming the pattern P D 31415 , look \nfor windows whose value modulo 13  is 7, since 31415  D 7 .mod 13/. The  algorithm  \u00fbnds  two  such  \nwindows,  shaded  blue  in the  \u00fbgure.  The  \u00fbrst,  beginning  at text position 7, is indeed an occurrence \nof the pattern. The second window, beginning at tex t position 13, is a spurious hit. (c)  How to \ncompute the value for a window in constant time, gi ven the value for  the  previous  window.  The  \u00fbrst  \nwindow has value 31415. Dropping  the  high-order  digit  3, shifting left (multiplying by 10), and then \nadding  in the  low-order  digit  2 gives the new value 14152 . Because all computations are performed \nmodulo 13, the  value  for  the  \u00fbrst  window  is 7, and the value for the new window is 8. 32.2 The Rabin-Karp algorithm 965 \nwhere h D d m\ue0021 mod q is the value of the digit < 1= in the  high-order  position  of \nan m-digit  text  window.  \nThe solution of working modulo q is not perfect, however: t s D p .mod q/ \ndoes not automatically mean that t s D p. On  the  other  hand,  if t s \u00a4 p .mod q/, \nthen  you  de\u00fbnitely  know  that  t s \u00a4 p, so that shift s is invalid. Thus you can \nuse the test t s D p .mod q/ as a fast heuristic test to rule out invalid shifts . If \nt s D p .mod q/4a  hit4then  you  need  to test  further  to see  whether  s is really \nvalid or you just have a spurious  hit. This additional test explicitly checks the \ncondition P\u01521  W m\ufffd  D T\u0152s  C 1 W s C m\ufffd. If q is large enough, then you would hope \nthat spurious hits occur infrequently enough that t he cost of the extra checking is \nlow. \nThe procedure R ABIN-KARP-MATCHER on the next page makes these ideas \nprecise. The inputs to the procedure are the text T , the pattern P , their lengths \nn and m, the radix d to use (which is typically taken to be j\u2020j), and the prime q \nto use. The procedure works as follows. All charact ers are interpreted  as radix-d \ndigits. The subscripts on t are provided only for clarity: the procedure works \ncorrectly  if all  the  subscripts  are  dropped.  Line  1 initiali zes h to the value of the \nhigh-order  digit  position  of an m-digit  window.  Lines  236  compute  p as the value \nof P\u01521  W m\ufffd  mod q and t 0 as the value of T\u01521  W m\ufffd  mod q. The for  loop  of lines  7312  \niterates through all possible shifts s , maintaining the following invariant: \nWhenever  line  8 is executed,  t s D T\u0152s  C 1 W s C m\ufffd  mod q. \nIf a hit occurs because p D t s in line  8, then  line  9 determines  whether  s is a valid \nshift or the hit was spurious via the test P\u01521  W m\ufffd  = = T\u0152s  C 1 W s C m\ufffd. Line  10  prints  \nout any valid shifts that are found. If s < n  \ue003 m (checked  in line  11),  then  the  \nfor  loop  will  iterate  at least  one  more  time,  and  so line  12  \u00fbrst  executes to ensure \nthat  the  loop  invariant  holds  upon  the  next  iteration.  Line  12 computes the value \nof t sC1 mod q from the value of t s mod q in constant  time  using  equation  (32.2)  \ndirectly. \nRABIN-KARP-MATCHER takes \u201a.m/  preprocessing time, and its matching time \nis \u201a..n  \ue003 m C 1/m/  in the  worst  case,  since  (like  the  naive  string-matching  algo-  \nrithm)  the  Rabin-Karp  algorithm  explicitly  veri\u00fbes  every  valid shift. If P D a m \nand T D a n , then verifying takes \u201a..n  \ue003mC1/m/  time, since each of the n \ue003mC1 \npossible shifts is valid. \nIn many  applications,  you  expect  few  valid  shifts4perhaps  some constant c of \nthem. In such applications, the expected matching t ime of the algorithm is only \nO..n  \ue003 m C 1/ C cm/  D O.n  C m/, plus the time required to process spurious hits. \nWe can base a heuristic analysis on the assumption that reducing values modulo q \nacts like a random mapping from \u2020 \ue003 to Z q . The expected number of spurious hits \nis then O.n=q/ , because we can estimate the chance that an arbitr ary t s will be \nequivalent to p, modulo q, as 1=q. Since there are O.n/  positions at which the 966  Chapter  32  String  Matching  \nRABIN-KARP-MATCHER .T;P;n;m;d;q/  \n1 h D d m\ue0021 mod q \n2 p D 0 \n3 t 0 D 0 \n4 for  i D 1 to m / / preprocessing \n5 p D .dp  C P\u0152i\ufffd/  mod q \n6 t 0 D .dt  0 C T\u0152i\ufffd/  mod q \n7 for  s D 0 to n \ue003 m / / matching4try  all  possible  shifts  \n8 if p = = t s / / a hit?  \n9 if P\u01521  W m\ufffd  == T\u0152s  C 1 W s C m\ufffd  / / valid  shift?  \n10  print <Pattern occurs with shift= s \n11  if s<n  \ue003 m \n12  t sC1 D \u00e3 \nd.t  s \ue003 T\u0152s  C 1\ufffdh/  C T\u0152s  C m C 1\ufffd \u00e4 \nmod q \ntest  of line  8 fails  (actually,  at most  n \ue003 m C 1 positions) and checking each hit \ntakes O.m/  time  in line  9, the  expected  matching  time  taken  by  the  Rabin-Karp  \nalgorithm is \nO.n/  C O.m.v  C n=q//;  \nwhere v is the number of valid shifts. This running time is  O.n/  if v D O.1/  and \nyou choose q \ue004 m. That is, if the expected number of valid shifts i s small (O.1/ ) \nand you choose the prime q to be larger than the length of the pattern, then y ou \ncan  expect  the  Rabin-Karp  procedure  to use  only  O.n  C m/  matching time. Since \nm \u0dc4 n, this expected matching time is O.n/ . \nExercises  \n32.2-1  \nWorking modulo q D 11, how  many  spurious  hits  does  the  Rabin-Karp  matcher  en-  \ncounter in the text T D 3141592653589793  when looking for the pattern P D 26? \n32.2-2  \nDescribe  how  to extend  the  Rabin-Karp  method  to the  problem  of searching a text \nstring for an occurrence of any one of a given set of k patterns. Start by assuming \nthat all k patterns have the same length. Then generalize your  solution to allow the \npatterns to have different lengths. \n32.2-3  \nShow  how  to extend  the  Rabin-Karp  method  to handle  the  proble m of looking for \na given m \ue005 m pattern in an n \ue005 n array of characters. (The pattern may be shifted \nvertically and horizontally, but it may not be rota ted.) 32.3  String  matching  with  \ufb01nite  automata  967 \n32.2-4  \nAlice has a copy of a long n-bit  \u00fble  A D ha n\ue0021 ;a  n\ue0022 ;:::;a  0 i, and Bob similarly \nhas an n-bit  \u00fble  B D hb n\ue0021 ;b  n\ue0022 ;:::;b  0 i. Alice and Bob wish to know if their \n\u00fbles  are  identical.  To  avoid  transmitting  all  of A or B , they use the following fast \nprobabilistic check. Together, they select a prime q > 1000n  and randomly select \nan integer x from f0;1;:::;q  \ue003 1g. Letting \nA.x/  D \ue001 n\ue0021 X  \ni D0 a i x i ! \nmod q and B.x/  D \ue001 n\ue0021 X  \ni D0 b i x i ! \nmod q;  \nAlice evaluates A.x/  and Bob evaluates B.x/ . Prove that if A \u00a4 B , there is at \nmost one chance in 1000  that A.x/  D B.x/, whereas  if the  two  \u00fbles  are  the  same,  \nA.x/  is necessarily the same as B.x/ . (Hint: See  Exercise  31.4-4.)  \n32.3  String  matching  with  \u00fbnite  automata  \nMany  string-matching  algorithms  build  a \u00fbnite  automaton4a  simple machine for \nprocessing  information4that  scans  the  text  string  T for  all  occurrences  of the  pat-  \ntern P . This section presents a method for building such an automaton. These \nstring-matching  automata  are  ef\u00fbcient:  they  examine  each  text character exactly  \nonce , taking constant time per text character. The matc hing time used4after  pre-  \nprocessing  the  pattern  to build  the  automaton4is  therefore  \u201a.n/ . The time to build \nthe automaton, however, can be large if \u2020 is large.  Section  32.4  describes  a clever  \nway around this problem. \nWe  begin  this  section  with  the  de\u00fbnition  of a \u00fbnite  automaton . We then examine \na special  string-matching  automaton  and  show  how  to use  it to \u00fbnd  occurrences  of a \npattern  in a text.  Finally,  we\u2019ll  see  how  to construct  the  string-matching  automaton  \nfor a given input pattern. \nFinite  automata  \nA \u00fbnite  automaton  M  , illustrated  in Figure  32.5,  is a 5-tuple  .Q;q  0 ;A;\u2020;\u0131/ , \nwhere \n\ue001 Q is a \u00fbnite  set  of states , \n\ue001 q 0 2 Q is the start  state , \n\ue001 A \u0dc2 Q is a distinguished set of accepting  states , \n\ue001 \u2020 is a \u00fbnite  input  alphabet , \n\ue001 \u0131 is a function from Q \ue005 \u2020 into Q, called the transition  function  of M  . 968  Chapter  32  String  Matching  \n1 0 \n0 0 a b  input \nstate \n0 \n1 \n(a) a \na \nb b \n(b) 0 1 \nFigure  32.5  A simple  two-state  \u00fbnite  automaton  with  state  set  Q D f0;1g, start state q 0 D 0, and \ninput alphabet \u2020 D fa; bg. (a)  A tabular representation of the transition function  \u0131. (b)  An equivalent \nstate-transition  diagram.  State  1, in orange, is the only accepting state. Directed edges represent \ntransitions. For example, the edge from state 1 to state 0 labeled b indicates that \u0131.1;  b/ D 0. This \nautomaton accepts those strings that end in an odd number of a\u2019s. More  precisely,  it accepts  a string  x \nif and only if x D y\u00b4, where y D \" or y ends with a b, and \u00b4 D a k , where k is odd. For example, on \ninput abaaa , including the start state, this automaton enters the sequence of states h0;1;0;1;0;1 i, \nand so it accepts this input. For input abbaa , it enters the sequence of states h0;1;0;0;1;0 i, and so \nit rejects this input. \nThe  \u00fbnite  automaton  begins  in state  q 0 and reads the characters of its input string \none at a time. If the automaton is in state q and reads input character a, it moves \n(<makes a transition=) from state q to state \u0131.q;a/ . Whenever its current state q is \na member of A, the machine M  has accepted  the string read so far. An input that \nis not accepted is rejected . \nA \u00fbnite  automaton  M  induces a function \ufffd, called the \u00fbnal-state  function , \nfrom \u2020 \ue003 to Q such that \ufffd.w/  is the state M  ends up in after reading the string w. \nThus, M  accepts a string w if and only if \ufffd.w/  2 A. We  de\u00fbne  the  function  \ufffd \nrecursively, using the transition function: \n\ufffd.\"/  D q 0 ; \n\ufffd.wa/  D \u0131.\ufffd.w/; a/  for w 2 \u2020 \ue003 ;a  2 \u2020 . \nString-matching  automata  \nFor a given pattern P , a preprocessing  step  constructs  a string-matching  automa ton \nspeci\u00fbc  to P . The automaton then searches the text string for o ccurrences of P . \nFigure  32.6  illustrates  the  automaton  for  the  pattern  P D ababaca . From now \non,  let\u2019s  assume  that  P is \u00fbxed,  and  for  brevity,  we  won\u2019t  bother  to indicate  the  \ndependence upon P in our notation. \nIn order  to specify  the  string-matching  automaton  corresponding  to a given  pat-  \ntern P\u01521  W m\ufffd, we  \u00fbrst  de\u00fbne  an auxiliary  function  \ufffd , called the suf\u00fbx  function  \ncorresponding to the pattern P . The function \ufffd maps \u2020 \ue003 to f0;1;:::;m g such that \n\ufffd.x/  is the  length  of the  longest  pre\u00fbx  of P that  is also  a suf\u00fbx  of x : \n\ufffd.x/  D max fk W P\u0152  W k\ufffd h x g : (32.3)  32.3  String  matching  with  \ufb01nite  automata  969 \n0 1 2 3 4 5 6 7 a b a b a c a \nb a a a \na \nb \n(a) \n1 0 0 \n1 2 0 \n3 0 0 \n1 4 0 \n5 0 0 \n1 4 6 \n7 0 0 \n1 2 0 0 \n1 \n2 \n3 \n4 \n5 \n6 \n7 state input \na b c  \na \nb \na \nb \na \nc \na P \n(b) 1 2 3 4 5 6 7 8 9 10  11  \na b a b a b a c a b a  \n0 1 2 3 4 5 4 5 6 7 2 3 4  \n4  \n(c) i \nT\u0152i\ufffd  \nstate \ufffd.T  i / \nFigure  32.6  (a)  A state-transition  diagram  for  the  string-matching  automa ton that accepts all \nstrings ending in the string ababaca . State 0 is the start state, and state 7 (in  orange)  is the  only  ac-  \ncepting state. The transition function \u0131 is de\u00fbned  by  equation  (32.4),  and  a directed  edge  from  state  i \nto state j labeled a represents \u0131.i;a/  D j . The  right-going  edges  forming  the  <spine=  of the  automa-  \nton, shown in blue, correspond to successful matche s between pattern and input characters. Except \nfor the edges from state 7 to states 1 and 2, the  left-going  edges  correspond  to mismatches.  Some  \nedges corresponding to mismatches are omitted: by c onvention, if a state i has  no  outgoing  edge  la-  \nbeled a for some a 2 \u2020, then \u0131.i;a/  D 0. (b)  The corresponding transition function \u0131, and the pattern \nstring P D ababaca . The entries corresponding to successful matches b etween pattern and input \ncharacters are shown in blue. (c)  The operation of the automaton on the text T D abababacaba . \nUnder each text character T\u0152i\ufffd  appears the state \ufffd.T \u0152  W i\ufffd/  that the automaton is in after processing \nthe  pre\u00fbx  T\u0152  W i\ufffd. The substring of the pattern that occurs in the t ext is highlighted in blue. The \nautomaton  \u00fbnds  this  one  occurrence  of the  pattern,  ending  in position 9. \nThe  suf\u00fbx  function  \ufffd is well  de\u00fbned  since  the  empty  string  P\u0152  W 0\ufffd D \" is a suf-  \n\u00fbx  of every  string.  As  examples,  for  the  pattern  P D ab, we have \ufffd.\"/  D 0, \n\ufffd.ccaca/ D 1, and \ufffd.ccab/ D 2. For a pattern P of length m, we have \n\ufffd.x/  D m if and only if P h x . From  the  de\u00fbnition  of the  suf\u00fbx  function,  \nx h y implies \ufffd.x/  \u0dc4 \ufffd.y/  (see  Exercise  32.3-4).  \nWe  are  now  ready  to de\u00fbne  the  string-matching  automaton  that  corresponds to a \ngiven pattern P\u01521  W m\ufffd: 970  Chapter  32  String  Matching  \n\ue001 The state set Q is f0;1;:::;m g. The start state q 0 is state 0, and state m is the \nonly accepting state. \n\ue001 The transition function \u0131 is de\u00fbned,  for  any  state  q and character a, by \n\u0131.q;a/  D \ufffd.P \u0152  W q\ufffda/:  (32.4)  \nAs the automaton consumes characters of the text T , it is trying to build a match \nof the pattern P against the most recently seen characters of T . At any time, the \nstate number q gives  the  length  of the  longest  pre\u00fbx  of P that matches the most \nrecently seen text characters. Whenever the automat on reaches state m, the m \nmost  recently  seen  text  characters  match  the  \u00fbrst  m characters of P . Since P has \nlength m, reaching state m means that the m most recently seen text characters \nmatch the entire pattern, so that the automaton has  found a match. \nWith this intuition behind the design of the automa ton, here is the  reasoning  be-  \nhind  de\u00fbning  \u0131.q;a/  D \ufffd.P \u0152  W q\ufffda/. Suppose that the automaton is in state q after \nreading  the  \u00fbrst  i characters of the text, that is, q D \ufffd.T  \u0152 W i\ufffd/. The intuitive idea \nthen says that q also  equals  the  length  of the  longest  pre\u00fbx  of P that matches \na suf\u00fbx  of T\u0152  W i\ufffd or, equivalently, that q D \ufffd.T \u0152  W i\ufffd/. Thus, since \ufffd.T  \u0152 W i\ufffd/  \nand \ufffd.T \u0152  W i\ufffd/  both equal q, we  will  see  (in  Theorem  32.4  on  page  973)  that  the  \nautomaton maintains the following invariant: \n\ufffd.T  \u0152 W i\ufffd/  D \ufffd.T \u0152  W i\ufffd/:  (32.5)  \nIf the automaton is in state q and reads the next character T\u0152i  C 1\ufffd D a, then the \ntransition should lead to the state corresponding t o the longest  pre\u00fbx  of P that is a \nsuf\u00fbx  of T\u0152  W i\ufffda. That state is \ufffd.T \u0152  W i\ufffda/, and  equation  (32.5)  gives  \ufffd.T  \u0152 W i\ufffda/  D \n\ufffd.T \u0152  W i\ufffda/. Because P\u0152  W q\ufffd is the  longest  pre\u00fbx  of P that  is a suf\u00fbx  of T\u0152  W i\ufffd, the \nlongest  pre\u00fbx  of P that  is a suf\u00fbx  of T\u0152  W i\ufffda  has length not only \ufffd.T \u0152  W i\ufffda/, but \nalso \ufffd.P \u0152  W q\ufffda/, and so \ufffd.T  \u0152 W i\ufffda/  D \ufffd.P \u0152  W q\ufffda/. (Lemma  32.3  on  page  972  will  \nprove that \ufffd.T \u0152  W i\ufffda/  D \ufffd.P \u0152  W q\ufffda/.) Thus, when the automaton is in state q, the \ntransition function \u0131 on character a should take the automaton to state \u0131.q;a/  D \n\u0131.\ufffd.T \u0152  W i\ufffd/;a/  D \ufffd.T  \u0152 W i\ufffda/  D \ufffd.P \u0152  W q\ufffda/  (with the last equality following from \nequation  (32.5)).  \nThere are two cases to consider, depending on wheth er the next character  con-  \ntinues  to match  the  pattern.  In the  \u00fbrst  case,  a D P\u0152q  C 1\ufffd, so that  the  charac-  \nter a continues to match the pattern. In this case, becau se \u0131.q;a/  D q C 1, the \ntransition continues to go along the <spine= of the  automaton (the blue edges in \nFigure  32.6(a)).  In the  second  case,  a \u00a4 P\u0152q  C 1\ufffd, so that a does not extend the \nmatch  being  built.  In this  case,  we  need  to \u00fbnd  the  longest  pre\u00fbx  of P that is also a \nsuf\u00fbx  of T\u0152  W i\ufffda, which will have length at most q. The preprocessing step matches \nthe  pattern  against  itself  when  creating  the  string-matchi ng automaton, so that the \ntransition function can quickly identify the longes t such smaller  pre\u00fbx  of P . 32.3  String  matching  with  \ufb01nite  automata  971 \nLet\u2019s  look  at an example.  Consider  state  5 in the  string-matching  automaton  of \nFigure  32.6.  In state  5, the  \u00fbve  most  recently  read  characters  of T are ababa , the \ncharacters along the spine of the automaton that re ach state 5. If the next character \nof T is c, then the most recently read characters of T are ababac , which is the \npre\u00fbx  of P with length 6. The automaton should continue along the spine to state 6. \nThis  is the  \u00fbrst  case,  in which  the  match  continues,  and  \u0131.5;  c/ D 6. To illustrate \nthe second case, suppose that in state 5, the next character of T is b, so the most \nrecently read characters of T are ababab. Here,  the  longest  pre\u00fbx  of P that \nmatches the most recently read characters of T 4that  is, a suf\u00fbx  of the  portion  \nof T read  so far4is  abab , with length 4, so \u0131.5;  b/ D 4. \nTo  clarify  the  operation  of a string-matching  automaton,  the  simple  and  ef\u00fb-  \ncient procedure F INITE-AUTOMATON-MATCHER simulates the behavior of such \nan automaton (represented by its transition functio n \u0131 ) in \u00fbnding  occurrences  of \na pattern P of length m in an input text T\u01521  W n\ufffd. As  for  any  string-matching  au-  \ntomaton for a pattern of length m, the state set Q is f0;1;:::;m g, the start state \nis 0, and the only accepting state is state m. From the simple loop structure of \nFINITE-AUTOMATON-MATCHER , you can see that its matching time on a text \nstring of length n is \u201a.n/ , assuming that each lookup of the transition funct ion \u0131 \ntakes constant time. This matching time, however, d oes not include  the  prepro-  \ncessing time required to compute the transition fun ction. We address this problem \nlater,  after  \u00fbrst  proving  that  the  procedure  FINITE-AUTOMATON-MATCHER oper-  \nates correctly. \nFINITE-AUTOMATON-MATCHER .T;\u0131;n;m/  \n1 q D 0 \n2 for  i D 1 to n \n3 q D \u0131.q;T\u0152i\ufffd/  \n4 if q == m \n5 print <Pattern occurs with shift= i \ue003 m \nLet\u2019s  examine  how  the  automaton  operates  on  an input  text  T\u01521  W n\ufffd. We will \nprove that the automaton is in state \ufffd.T \u0152  W i\ufffd/  after reading character T\u0152i\ufffd. Since \n\ufffd.T \u0152  W i\ufffd/  D m if and only if P h T\u0152  W i\ufffd, the machine is in the accepting state m \nif and only if it has just read the pattern P . We start with two lemmas about the \nsuf\u00fbx  function  \ufffd . \nLemma  32.2  (Suf\u00fbx-function  inequality)  \nFor any string x and character a, we have \ufffd.xa/  \u0dc4 \ufffd.x/  C 1. 972  Chapter  32  String  Matching  \nx \na \nP\u0152  W r\ufffd P\u0152  W r \ue003 1\ufffd \nFigure  32.7  An  illustration  for  the  proof  of Lemma  32.2.  The  \u00fbgure  shows  that r \u0dc4 \ufffd.x/  C 1, \nwhere r D \ufffd.xa/ . \nx \na a \nP\u0152  W r\ufffd P\u0152  W q\ufffd \nFigure  32.8  An  illustration  for  the  proof  of Lemma  32.3.  The  \u00fbgure  shows  that r D \ufffd.P \u0152  W q\ufffda/, \nwhere q D \ufffd.x/  and r D \ufffd.xa/ . \nProof  Referring  to Figure  32.7,  let  r D \ufffd.xa/ . If r D 0, then the conclusion \n\ufffd.xa/  D r \u0dc4 \ufffd.x/  C1 is trivially  satis\u00fbed  since  \ufffd.x/  is nonnegative. Now assume \nthat r > 0 . Then, P\u0152  W r\ufffd h xa, by  the  de\u00fbnition  of \ufffd . Thus, P\u0152  W r \ue003 1\ufffd h x , \nby dropping the a from both the end of P\u0152  W r\ufffd and the end of xa. Therefore, \nr \ue003 1 \u0dc4 \ufffd.x/ , since \ufffd.x/  is the largest k such that P\u0152  W k\ufffd h x , and thus \ufffd.xa/  D \nr \u0dc4 \ufffd.x/  C 1. \nLemma  32.3  (Suf\u00fbx-function  recursion  lemma)  \nFor any string x and character a, if q D \ufffd.x/ , then \ufffd.xa/  D \ufffd.P \u0152  W q\ufffda/. \nProof  The  de\u00fbnition  of \ufffd gives that P\u0152  W q\ufffd h x . As  Figure  32.8  shows,  we  also  \nhave P\u0152  W q\ufffda  h xa. Let r D \ufffd.xa/ . Then P\u0152  W r\ufffd h xa  and,  by  Lemma  32.2,  \nr \u0dc4 q C 1. Thus, we have jP\u0152  W r\ufffdj D  r \u0dc4 q C 1 D jP\u0152  W q\ufffdaj. Since P\u0152  W q\ufffda  h xa, \nP\u0152  W r\ufffd h xa, and jP\u0152  W r\ufffdj \u0dc4 jP\u0152  W q\ufffdaj, Lemma  32.1  on  page  959  implies  that  \nP\u0152  W r\ufffd h P\u0152  W q\ufffda. Therefore, r \u0dc4 \ufffd.P \u0152  W q\ufffda/, that is, \ufffd.xa/  \u0dc4 \ufffd.P \u0152  W q\ufffda/. \nBut we also have \ufffd.P \u0152  W q\ufffda/  \u0dc4 \ufffd.xa/ , since P\u0152  W q\ufffda  h xa. Thus, \ufffd.xa/  D \n\ufffd.P \u0152  W q\ufffda/. 32.3  String  matching  with  \ufb01nite  automata  973 \nWe are now ready to prove the main theorem characte rizing the behavior of a \nstring-matching  automaton  on  a given  input  text.  As  noted  above, this theorem \nshows that the automaton is merely keeping track, a t each step, of the longest \npre\u00fbx  of the  pattern  that  is a suf\u00fbx  of what  has  been  read  so far  . In other words, \nthe  automaton  maintains  the  invariant  (32.5).  \nTheorem  32.4  \nIf \ufffd is the  \u00fbnal-state  function  of a string-matching  automaton  for a given pattern P \nand T\u01521  W n\ufffd is an input text for the automaton, then \n\ufffd.T \u0152  W i\ufffd/  D \ufffd.T \u0152  W i\ufffd/  \nfor i D 0;1;:::;n . \nProof  The proof is by induction on i . For i D 0, the theorem is trivially true, \nsince T\u0152  W 0\ufffd D \". Thus, \ufffd.T  \u0152 W 0\ufffd/  D 0 D \ufffd.T \u0152  W 0\ufffd/. \nNow assume that \ufffd.T  \u0152 W i\ufffd/  D \ufffd.T \u0152  W i\ufffd/. We will prove that \ufffd.T \u0152  W i C 1\ufffd/  D \n\ufffd.T \u0152  W i C 1\ufffd/. Let q denote \ufffd.T  \u0152 W i\ufffd/, so that q D \ufffd.T \u0152  W i\ufffd/, and let a denote \nT\u0152i  C 1\ufffd. Then, \n\ufffd.T \u0152  W i C 1\ufffd/  D \ufffd.T \u0152  W i\ufffda/  (by  the  de\u00fbnitions  of T\u0152  W i C 1\ufffd and a) \nD \u0131.\ufffd.T \u0152  W i\ufffd/;a/  (by  the  de\u00fbnition  of \ufffd) \nD \u0131.q;a/  (by  the  de\u00fbnition  of q) \nD \ufffd.P \u0152  W q\ufffda/  (by  the  de\u00fbnition  (32.4)  of \u0131 ) \nD \ufffd.T \u0152  W i\ufffda/  (by  Lemma  32.3)  \nD \ufffd.T \u0152  W i C 1\ufffd/  (by  the  de\u00fbnition  of T\u0152  W i C 1\ufffd) . \nBy  Theorem  32.4,  if the  machine  enters  state  q on  line  3, then  q is the largest \nvalue such that P\u0152  W q\ufffd h T\u0152  W i\ufffd. Thus,  in line  4, q D m if and only if the machine \nhas just read an occurrence of the pattern P . Therefore, F INITE-AUTOMATON- \nMATCHER operates correctly. \nComputing  the  transition  function  \nThe procedure C OMPUTE-TRANSITION-FUNCTION  on  the  following  page  com-  \nputes the transition function \u0131 from a given pattern P\u01521  W m\ufffd. It computes \u0131.q;a/  in \na straightforward  manner  according  to its  de\u00fbnition  in equation  (32.4).  The  nested  \nloops  beginning  on  lines  1 and  2 consider  all  states  q and all characters a, and \nlines  336  set  \u0131.q;a/  to be the largest k such that P\u0152  W k\ufffd h P\u0152  W q\ufffda. The code starts \nwith the largest conceivable value of k, which is q C1, unless q D m, in which case \nk cannot be larger than m. It then decreases k until P\u0152  W k\ufffd is a suf\u00fbx  of P\u0152  W q\ufffda, \nwhich must eventually occur, since P\u0152  W 0\ufffd D \" is a suf\u00fbx  of every  string.  974  Chapter  32  String  Matching  \nCOMPUTE-TRANSITION-FUNCTION  .P;\u2020;m/  \n1 for  q D 0 to m \n2 for  each character a 2 \u2020 \n3 k D min fm;q  C 1g \n4 while  P\u0152  W k\ufffd is not  a suf\u00fbx  of P\u0152  W q\ufffda  \n5 k D k \ue003 1 \n6 \u0131.q;a/  D k \n7 return  \u0131 \nThe running time of C OMPUTE-TRANSITION-FUNCTION  is O.m  3 j\u2020j/, be-  \ncause the outer loops contribute a factor of m j\u2020j, the inner while  loop can run \nat most m C 1 times, and the test for whether P\u0152  W k\ufffd is a suf\u00fbx  of P\u0152  W q\ufffda  on  line  4 \ncan require comparing up to m characters.  Much  faster  procedures  exist.  By  utiliz-  \ning some cleverly computed information about the pa ttern P (see  Exercise  32.4-8),  \nthe time required to compute \u0131 from P improves to O.m  j\u2020j/. This  improved  pro-  \ncedure for computing \u0131 provides  a way  to \u00fbnd  all  occurrences  of a length-m pattern \nin a length-n text over an alphabet \u2020 with O.m  j\u2020j/ preprocessing time and \u201a.n/  \nmatching time. \nExercises  \n32.3-1  \nDraw  a state-transition  diagram  for  the  string-matching  automaton for the pattern \nP D aabab  over the alphabet \u2020 D fa; bg and illustrate its operation on the text \nstring T D aaababaabaababaab  . \n32.3-2  \nDraw  a state-transition  diagram  for  the  string-matching  automaton for the pattern \nP D ababbabbababbababbabb  over the alphabet \u2020 D fa; bg. \n32.3-3  \nA pattern P is nonoverlappable  if P\u0152  W k\ufffd h P\u0152  W q\ufffd implies k D 0 or k D q. De-  \nscribe  the  state-transition  diagram  of the  string-matching  automaton  for  a nonover-  \nlappable pattern. \n32.3-4  \nLet x and y be pre\u00fbxes  of the  pattern  P . Prove that x h y implies \ufffd.x/  \u0dc4 \ufffd.y/ . 32.4  The  Knuth-Morris-Pratt  algorithm  975 \n? 32.3-5  \nGiven  two  patterns  P and P 0 , describe  how  to construct  a \u00fbnite  automaton  that  \ndetermines all occurrences of either pattern. Try to minimize the number of states \nin your automaton. \n32.3-6  \nGiven  a pattern  P containing  gap  characters  (see  Exercise  32.1-4),  show  how  to \nbuild  a \u00fbnite  automaton  that  can  \u00fbnd  an occurrence  of P in a text T in O.n/  \nmatching time, where n D jT j. \n? 32.4  The  Knuth-Morris-Pratt  algorithm  \nKnuth,  Morris,  and  Pratt  developed  a linear-time  string  matching algorithm that \navoids computing the transition function \u0131 altogether.  Instead,  the  KMP  algorithm  \nuses an auxiliary function \ufffd , which it precomputes from the pattern in \u201a.m/  time \nand stores in an array \ufffd\u01521  W m\ufffd. The array \ufffd allows the algorithm to compute the \ntransition function \u0131 ef\u00fbciently  (in  an amortized  sense)  <on  the  \u00fcy=  as needed.  \nLoosely speaking, for any state q D 0;1;:::;m  and any character a 2 \u2020, the \nvalue \ufffd\u0152q\ufffd contains the information needed to compute \u0131.q;a/  but that does not \ndepend on a. Since the array \ufffd has only m entries, whereas \u0131 has \u201a.m  j\u2020j/ en-  \ntries,  the  KMP  algorithm  saves  a factor  of j\u2020j in the  preprocessing  time  by  com-  \nputing \ufffd rather than \u0131 . Like the procedure F INITE-AUTOMATON-MATCHER , once \npreprocessing  has  completed,  the  KMP  algorithm  uses  \u201a.n/  matching time. \nThe  pre\u00fbx  function  for  a pattern  \nThe  pre\u00fbx  function  \ufffd for a pattern encapsulates knowledge about how the pattern \nmatches  against  shifts  of itself.  The  KMP  algorithm  takes  advantage  of this  infor-  \nmation  to avoid  testing  useless  shifts  in the  naive  pattern- matching algorithm and to \navoid precomputing the full transition function \u0131 for  a string-matching  automaton.  \nConsider  the  operation  of the  naive  string  matcher.  Figure  32.9(a)  shows  a par-  \nticular shift s of a template containing the pattern P D ababaca  against a text T . \nFor this example, q D 5 of the characters have matched successfully, but th e 6th \npattern character fails to match the corresponding text character.  The  informa-  \ntion that q characters have matched successfully determines the  corresponding text \ncharacters. Because these q text characters match, certain shifts must be inval id. \nIn the  example  of the  \u00fbgure,  the  shift  s C 1 is necessarily  invalid,  since  the  \u00fbrst  \npattern character ( a) would be aligned with a text character that does not match the \n\u00fbrst  pattern  character,  but  does  match  the  second  pattern  character ( b). The shift 976  Chapter  32  String  Matching  \ns 0 D s C 2 shown  in part  (b)  of the  \u00fbgure,  however,  aligns  the  \u00fbrst  three  pattern \ncharacters with three text characters that necessar ily match. \nMore generally, suppose that you know that P\u0152  W q\ufffd h T\u0152  W s C q\ufffd or,  equiva-  \nlently, that P\u01521  W q\ufffd D T\u0152s  C 1 W s C q\ufffd. You want to shift P so that some shorter \npre\u00fbx  P\u0152  W k\ufffd of P matches  a suf\u00fbx  of T\u0152  W s C q\ufffd, if possible. You might have more \nthan  one  choice  for  how  much  to shift,  however.  In Figure  32.9(b), shifting P by 2 \npositions works, so that P\u0152  W 3\ufffd h T\u0152  W s C q\ufffd, but so does shifting P by 4 positions, \nso that P\u0152  W 1\ufffd h T\u0152  W s C q\ufffd in Figure  32.9(c).  If more  than  one  shift  amount  works,  \nyou should choose the smallest shift amount so that  you do not miss any potential \nmatches. Put more precisely, you want to answer thi s question: \nGiven  that  pattern  characters  P\u01521  W q\ufffd match text characters T\u0152s  C 1 W s C q\ufffd \n(that is, P\u0152  W q\ufffd h T\u0152  W s C q\ufffd), what is the least shift s 0 > s  such that for \nsome k<q , \nP\u01521  W k\ufffd D T\u0152s  0 C 1 W s 0 C k\ufffd;  (32.6)  \n(that is, P\u0152  W k\ufffd h T\u0152  W s 0 C k\ufffd), where s 0 C k D s C q? \nHere\u2019s  another  way  to look  at this  question.  If you  know  P\u0152  W q\ufffd h T\u0152  W s C q\ufffd, \nthen  how  do  you  \u00fbnd  the  longest  proper  pre\u00fbx  P\u0152  W k\ufffd of P\u0152  W q\ufffd that  is also  a suf\u00fbx  \nof T\u0152  W s C q\ufffd? These  questions  are  equivalent  because  given  s and q, requiring \ns 0 C k D s C q means  that  \u00fbnding  the  smallest  shift  s 0 (2 in Figure  32.9(b))  is \ntantamount  to \u00fbnding  the  longest  pre\u00fbx  length  k (3 in Figure  32.9(b)).  If you  add  \nthe difference q \ue003 k in the  lengths  of these  pre\u00fbxes  of P to the shift s , you get the \nnew shift s 0 , so that s 0 D s C .q \ue003 k/. In the best case, k D 0, so that s 0 D s C q, \nimmediately ruling out shifts s C 1;s  C 2;:::;s  C q \ue003 1. In any case, at the new \nshift s 0 , it is redundant  to compare  the  \u00fbrst  k characters of P with the corresponding \ncharacters of T , since  equation  (32.6)  guarantees  that  they  match.  \nAs  Figure  32.9(d)  demonstrates,  you  can  precompute  the  necessary information \nby comparing the pattern against itself. Since T\u0152s  0 C 1 W s 0 C k\ufffd is part of the \nmatched  portion  of the  text,  it is a suf\u00fbx  of the  string  P\u0152  W q\ufffd. Therefore, think \nof equation  (32.6)  as asking  for  the  greatest  k < q  such that P\u0152  W k\ufffd h P\u0152  W q\ufffd. \nThen, the new shift s 0 D s C .q \ue003 k/  is the next potentially valid shift. It will be \nconvenient to store, for each value of q, the number k of matching characters at the \nnew shift s 0 , rather than storing, say, the amount s 0 \ue003 s to shift by. \nLet\u2019s  look  at the  precomputed  information  a little  more  form ally. For a given \npattern P\u01521  W m\ufffd, the pre\u00fbx  function  for P is the function \ufffd W f1;2;:::;m g !  \nf0;1;:::;m  \ue003 1g such that \n\ufffd\u0152q\ufffd D max fk W k<q  and P\u0152  W k\ufffd h P\u0152  W q\ufffdg : \nThat is, \ufffd\u0152q\ufffd is the  length  of the  longest  pre\u00fbx  of P that  is a proper  suf\u00fbx  of P\u0152  W q\ufffd. \nHere  is the  complete  pre\u00fbx  function  \ufffd for the pattern ababaca : 32.4  The  Knuth-Morris-Pratt  algorithm  977 \nb a c b a b \na b a \n(a) a b a a b c b a b \nb a c a s T \nP \nq b a c b a b \na b a \n(b) a b a a b c b a b \nb a c a s\u02b9 = s + 2 T \nP \nk \na b \na b a a b a \n(d) b a c b a b \na b a \n(c) a b a a b c b a b \nb a c a s + 4 T \nP P\u0152  W k\ufffd P\u0152  W q\ufffd \nFigure  32.9  The  pre\u00fbx  function  \ufffd . (a)  The pattern P D ababaca  aligns with a text T so that the \n\u00fbrst  q D 5 characters match. Matching characters, in blue, are  connected by blue lines. (b)  Knowing  \nthese particular 5 matched characters ( P\u0152  W 5\ufffd) suf\u00fbces  to deduce  that  a shift  of s C 1 is invalid, \nbut that a shift of s 0 D s C 2 is consistent with everything known about the text and therefore is \npotentially  valid.  The  pre\u00fbx  P\u0152  W k\ufffd, where k D 3, aligns with the text seen so far. (c)  A shift of s C 4 \nis also  potentially  valid,  but  it leaves  only  the  pre\u00fbx  P\u0152  W 1\ufffd aligned with the text seen so far. (d)  To \nprecompute useful information for such deductions, compare the pattern with itself. Here, the longest \npre\u00fbx  of P that  is also  a proper  suf\u00fbx  of P\u0152  W 5\ufffd is P\u0152  W 3\ufffd. The array \ufffd represents this precomputed \ninformation, so that \ufffd\u01525\ufffd D 3. Given  that  q characters have matched successfully at shift s , the next \npotentially valid shift is at s 0 D s C .q \ue003 \ufffd\u0152q\ufffd/ as shown in part (b). \ni 1 2 3 4 5 6 7 \nP\u0152i\ufffd  a b a b a c a  \n\ufffd\u0152i  \ufffd 0 0 1 2 3 0 1 \nThe  procedure  KMP-M ATCHER on  the  following  page  gives  the  Knuth-Morris-  \nPratt matching algorithm. The procedure follows fro m F INITE-AUTOMATON- \nMATCHER for the most part. To compute \ufffd , KMP-M ATCHER calls the auxiliary \nprocedure C OMPUTE-PREFIX-FUNCTION . These two procedures have much in \ncommon, because both match a string against the pat tern P : KMP-M ATCHER \nmatches the text T against P , and COMPUTE-PREFIX-FUNCTION  matches P \nagainst itself. \nNext,  let\u2019s  analyze  the  running  times  of these  procedures.  Then  we\u2019ll  prove  them  \ncorrect, which will be more complicated. \nRunning-time  analysis  \nThe running time of C OMPUTE-PREFIX-FUNCTION  is \u201a.m/ , which we show by \nusing the aggregate method of amortized analysis (s ee Section  16.1).  The  only  \ntricky part is showing that the while  loop  of lines  536  executes  O.m/  times  alto-  978  Chapter  32  String  Matching  \nKMP-M ATCHER .T;P;n;m/  \n1 \ufffd D COMPUTE-PREFIX-FUNCTION  .P;m/  \n2 q D 0 / / number of characters matched \n3 for  i D 1 to n / / scan the text from left to right \n4 while  q>0  and P\u0152q  C 1\ufffd \u00a4 T\u0152i\ufffd  \n5 q D \ufffd\u0152q\ufffd / / next character does not match \n6 if P\u0152q  C 1\ufffd = = T\u0152i\ufffd  \n7 q D q C 1 / / next character matches \n8 if q == m / / is all of P matched?  \n9 print <Pattern occurs with shift= i \ue003 m \n10  q D \ufffd\u0152q\ufffd / / look for the next match \nCOMPUTE-PREFIX-FUNCTION  .P;m/  \n1 let \ufffd\u01521  W m\ufffd  be a new array \n2 \ufffd\u01521\ufffd D 0 \n3 k D 0 \n4 for  q D 2 to m \n5 while  k>0  and P\u0152k  C 1\ufffd \u00a4 P\u0152q\ufffd  \n6 k D \ufffd\u0152k\ufffd \n7 if P\u0152k  C 1\ufffd == P\u0152q\ufffd  \n8 k D k C 1 \n9 \ufffd\u0152q\ufffd D k \n10  return  \ufffd \ngether. Starting with some observations about k, we\u2019ll  show  that  it makes  at most  \nm\ue0031 iterations.  First,  line  3 starts  k at 0, and the only way that k increases is by the \nincrement  operation  in line  8, which  executes  at most  once  per iteration of the for  \nloop  of lines  439.  Thus,  the  total  increase  in k is at most m\ue0031. Second, since k<q  \nupon entering the for  loop and each iteration of the loop increments q, we always \nhave k <q . Therefore, the assignments in lines 2 and 9 ensur e that \ufffd\u0152q\ufffd<q  for \nall q D 1;2;:::;m , which means that each iteration of the while  loop decreases k. \nThird, k never becomes negative. Putting these facts togethe r, we see that the total \ndecrease in k from the while  loop is bounded from above by the total increase in  k \nover all iterations of the for  loop, which is m \ue003 1. Thus, the while  loop iterates at \nmost m \ue003 1 times in all, and C OMPUTE-PREFIX-FUNCTION  runs in \u201a.m/  time. \nExercise  32.4-4  asks  you  to show,  by  a similar  aggregate  analysis,  that  the  match-  \ning  time  of KMP-M ATCHER is \u201a.n/ . 32.4  The  Knuth-Morris-Pratt  algorithm  979 \n1 2 3 4 5 6 7 \n0 0 1 2 3 0 1 a b a b a c a  \n(a) a b a b a c a  \na b a b a c a  \na b a b a c a  \na b a b a c a  \n(b) \" i \nP\u0152i\ufffd  \n\ufffd\u0152i  \ufffd P 5 \nP 3 \nP 1 \nP 0 \ufffd\u01525\ufffd D 3 \n\ufffd\u01523\ufffd D 1 \n\ufffd\u01521\ufffd D 0 \nFigure  32.10  An  illustration  of Lemma  32.5  for  the  pattern  P D ababaca  and q D 5. (a)  The \n\ufffd function for the given pattern. Since \ufffd\u01525\ufffd D 3, \ufffd\u01523\ufffd D 1, and \ufffd\u01521\ufffd D 0, iterating \ufffd gives \n\ufffd \ue003 \u01525\ufffd  D f3;1;0 g. (b)  Sliding the template containing the pattern P to the right and noting when \nsome  pre\u00fbx  P\u0152  W k\ufffd of P matches  up  with  some  proper  suf\u00fbx  of P\u0152  W 5\ufffd. Matches occur when k D 3, \n1, and 0. In the  \u00fbgure,  the  \u00fbrst  row  gives  P , and the vertical red line is drawn just after P\u0152  W 5\ufffd. \nSuccessive rows show all the shifts of P that  cause  some  pre\u00fbx  P\u0152  W k\ufffd of P to match  some  suf\u00fbx  \nof P\u0152  W 5\ufffd. Successfully matched characters are shown in blue . Blue lines connect aligned matching \ncharacters. Thus, fk W k<5  and P\u0152  W k\ufffd \u2742 P\u0152  W 5\ufffdg D f3;1;0 g. Lemma  32.5  claims  that  \ufffd \ue003 \u0152q\ufffd  D \nfk W k<q  and P\u0152  W k\ufffd \u2742 P\u0152  W q\ufffdg for all q. \nCompared with F INITE-AUTOMATON-MATCHER , by using \ufffd rather than \u0131 , the \nKMP  algorithm  reduces  the  time  for  preprocessing  the  patter n from O.m  j\u2020j/ \nto \u201a.m/ , while keeping the actual matching time bounded by  \u201a.n/ . \nCorrectness  of the  pre\ufb01x-function  computation  \nWe\u2019ll  see  a little  later  that  the  pre\u00fbx  function  \ufffd helps to simulate the transition \nfunction \u0131 in a string-matching  automaton.  But  \u00fbrst,  we  need  to prove  that the \nprocedure C OMPUTE-PREFIX-FUNCTION  does  indeed  compute  the  pre\u00fbx  func-  \ntion  correctly.  Doing  so requires  \u00fbnding  all  pre\u00fbxes  P\u0152  W k\ufffd that  are  proper  suf\u00fbxes  \nof a given  pre\u00fbx  P\u0152  W q\ufffd. The value of \ufffd\u0152q\ufffd gives us the length of the longest such \npre\u00fbx,  but  the  following  lemma,  illustrated  in Figure  32.10 , shows that iterating the \npre\u00fbx  function  \ufffd generates  all  the  pre\u00fbxes  P\u0152  W k\ufffd that  are  proper  suf\u00fbxes  of P\u0152  W q\ufffd. \nLet \n\ufffd \ue003 \u0152q\ufffd  D \u02da \n\ufffd\u0152q\ufffd; \ufffd .2/  \u0152q\ufffd;  \ufffd .3/  \u0152q\ufffd;:::;  \ufffd .t/  \u0152q\ufffd  \ue009 \n; \nwhere \ufffd .i/  \u0152q\ufffd  is de\u00fbned  in terms  of functional  iteration,  so that  \ufffd .0/  \u0152q\ufffd  D q and \n\ufffd .i/  \u0152q\ufffd  D \ufffd\u0152\ufffd  .i \ue0021/  \u0152q\ufffd\ufffd  for i \ue004 1 (so that \ufffd\u0152q\ufffd D \ufffd .1/  \u0152q\ufffd), and where the sequence \nin \ufffd \ue003 \u0152q\ufffd  stops upon reaching \ufffd .t/  \u0152q\ufffd  D 0 for some t \ue004 1. 980  Chapter  32  String  Matching  \nLemma  32.5  (Pre\ufb01x-function  iteration  lemma)  \nLet P be a pattern of length m with  pre\u00fbx  function  \ufffd . Then, for q D 1;2;:::;m , \nwe have \ufffd \ue003 \u0152q\ufffd  D fk W k<q  and P\u0152  W k\ufffd \u2742 P\u0152  W q\ufffdg. \nProof  We  \u00fbrst  prove  that  \ufffd \ue003 \u0152q\ufffd  \u0dc2 fk W k<q  and P\u0152  W k\ufffd \u2742 P\u0152  W q\ufffdg or,  equiva-  \nlently, \ni 2 \ufffd \ue003 \u0152q\ufffd  implies P\u0152  W i\ufffd \u2742 P\u0152  W q\ufffd:  (32.7)  \nIf i 2 \ufffd \ue003 \u0152q\ufffd, then i D \ufffd .u/  \u0152q\ufffd  for some u > 0. We  prove  equation  (32.7)  \nby induction on u. For u D 1, we have i D \ufffd\u0152q\ufffd, and the claim follows since \ni <q  and P\u0152  W \ufffd\u0152q\ufffd\ufffd \u2742 P\u0152  W q\ufffd by  the  de\u00fbnition  of \ufffd . Now consider some u \ue004 1 \nsuch that both \ufffd .u/  \u0152q\ufffd  and \ufffd .uC1/  \u0152q\ufffd  belong to \ufffd \ue003 \u0152q\ufffd. Let i D \ufffd .u/  \u0152q\ufffd, so that \n\ufffd\u0152i  \ufffd D \ufffd .uC1/  \u0152q\ufffd. The inductive hypothesis is that P\u0152  W i\ufffd \u2742 P\u0152  W q\ufffd. Because \nthe relations < and \u2742 are transitive, we have \ufffd\u0152i  \ufffd < i < q  and P\u0152  W \ufffd\u0152i  \ufffd\ufffd \u2742 \nP\u0152  W i\ufffd \u2742 P\u0152  W q\ufffd, which  establishes  equation  (32.7)  for  all  i in \ufffd \ue003 \u0152q\ufffd. Therefore, \n\ufffd \ue003 \u0152q\ufffd  \u0dc2 fk W k<q  and P\u0152  W k\ufffd \u2742 P\u0152  W q\ufffdg. \nWe now prove that fk W k<q  and P\u0152  W k\ufffd \u2742 P\u0152  W q\ufffdg \u0dc2  \ufffd \ue003 \u0152q\ufffd  by contradiction. \nSuppose to the contrary that the set fk W k<q  and P\u0152  W k\ufffd \u2742 P\u0152  W q\ufffdg \ue003  \ufffd \ue003 \u0152q\ufffd  is \nnonempty, and let j be the largest number in the set. Because \ufffd\u0152q\ufffd is the largest \nvalue in fk W k<q  and P\u0152  W k\ufffd \u2742 P\u0152  W q\ufffdg and \ufffd\u0152q\ufffd 2 \ufffd \ue003 \u0152q\ufffd, it must be the case \nthat j <\ufffd\u0152q\ufffd. Having established that \ufffd \ue003 \u0152q\ufffd  contains at least one integer greater \nthan j , let j 0 denote the smallest such integer. (We can choose j 0 D \ufffd\u0152q\ufffd if \nno other number in \ufffd \ue003 \u0152q\ufffd  is greater than j .) We have P\u0152  W j\ufffd \u2742 P\u0152  W q\ufffd because \nj 2 fk W k<q  and P\u0152  W k\ufffd \u2742 P\u0152  W q\ufffdg, and from j 0 2 \ufffd \ue003 \u0152q\ufffd  and  equation  (32.7),  \nwe have P\u0152  W j 0 \ufffd \u2742 P\u0152  W q\ufffd. Thus, P\u0152  W j\ufffd \u2742 P\u0152  W j 0 \ufffd by  Lemma  32.1,  and  j is the \nlargest value less than j 0 with this property. Therefore, we must have \ufffd\u0152j  0 \ufffd D j \nand, since j 0 2 \ufffd \ue003 \u0152q\ufffd, we must have j 2 \ufffd \ue003 \u0152q\ufffd  as well. This contradiction proves \nthe lemma. \nThe algorithm C OMPUTE-PREFIX-FUNCTION  computes \ufffd\u0152q\ufffd, in order, for q D \n1;2;:::;m . Setting \ufffd\u01521\ufffd to 0 in line 2 of C OMPUTE-PREFIX-FUNCTION  is cer-  \ntainly correct, since \ufffd\u0152q\ufffd < q  for all q. We\u2019ll  use  the  following  lemma  and  its  \ncorollary to prove that C OMPUTE-PREFIX-FUNCTION  computes \ufffd\u0152q\ufffd correctly \nfor q>1 . \nLemma  32.6  \nLet P be a pattern of length m, and let \ufffd be the  pre\u00fbx  function  for  P . For q D \n1;2;:::;m , if \ufffd\u0152q\ufffd>0 , then \ufffd\u0152q\ufffd \ue003 1 2 \ufffd \ue003 \u0152q \ue003 1\ufffd. \nProof  Let r D \ufffd\u0152q\ufffd > 0 , so that r < q  and P\u0152  W r\ufffd \u2742 P\u0152  W q\ufffd, and thus, \nr \ue003 1<q  \ue003 1 and P\u0152  W r \ue003 1\ufffd \u2742 P\u0152  W q \ue003 1\ufffd (by dropping the last character from 32.4  The  Knuth-Morris-Pratt  algorithm  981 \nP\u0152  W r\ufffd and P\u0152  W q\ufffd, which we can do because r >0). By  Lemma  32.5,  therefore,  \nr \ue003 1 2 \ufffd \ue003 \u0152q \ue003 1\ufffd. Thus, we have \ufffd\u0152q\ufffd \ue003 1 D r \ue003 1 2 \ufffd \ue003 \u0152q \ue003 1\ufffd. \nFor q D 2;3;:::;m, de\u00fbne  the  subset  E q\ue0021 \u0dc2 \ufffd \ue003 \u0152q \ue003 1\ufffd by \nE q\ue0021 D fk 2 \ufffd \ue003 \u0152q \ue003 1\ufffd W P\u0152k  C 1\ufffd D P\u0152q\ufffdg \nD fk W k<q  \ue003 1 and P\u0152  W k\ufffd \u2742 P\u0152  W q \ue003 1\ufffd and P\u0152k  C 1\ufffd D P\u0152q\ufffdg \n(by  Lemma  32.5)  \nD fk W k<q  \ue003 1 and P\u0152  W k C 1\ufffd \u2742 P\u0152  W q\ufffdg : \nThe set E q\ue0021 consists of the values k<q  \ue003 1 for which P\u0152  W k\ufffd \u2742 P\u0152  W q \ue003 1\ufffd and \nfor which, because P\u0152k  C 1\ufffd D P\u0152q\ufffd , we have P\u0152  W k C 1\ufffd \u2742 P\u0152  W q\ufffd. Thus, E q\ue0021 \nconsists of those values k 2 \ufffd \ue003 \u0152q \ue003 1\ufffd such that extending P\u0152  W k\ufffd to P\u0152  W k C 1\ufffd \nproduces  a proper  suf\u00fbx  of P\u0152  W q\ufffd. \nCorollary  32.7  \nLet P be a pattern of length m, and let \ufffd be the  pre\u00fbx  function  for  P . Then, for \nq D 2;3;:::;m , \n\ufffd\u0152q\ufffd D ( \n0 if E q\ue0021 D ;  ; \n1 C max E q\ue0021 if E q\ue0021 \u00a4 ;  : \nProof  If E q\ue0021 is empty, there is no k 2 \ufffd \ue003 \u0152q \ue003 1\ufffd (including k D 0) such that \nextending P\u0152  W k\ufffd to P\u0152  W k C 1\ufffd produces  a proper  suf\u00fbx  of P\u0152  W q\ufffd. Therefore, \n\ufffd\u0152q\ufffd D 0. \nIf, instead, E q\ue0021 is nonempty, then for each k 2 E q\ue0021 , we have k C 1<q  and \nP\u0152  W k C 1\ufffd \u2742 P\u0152  W q\ufffd. Therefore,  the  de\u00fbnition  of \ufffd\u0152q\ufffd gives \n\ufffd\u0152q\ufffd \ue004 1 C max E q\ue0021 : (32.8)  \nNote that \ufffd\u0152q\ufffd>0 . Let r D \ufffd\u0152q\ufffd \ue003 1, so that r C 1 D \ufffd\u0152q\ufffd>0 , and therefore \nP\u0152  W r C 1\ufffd \u2742 P\u0152  W q\ufffd. If a nonempty  string  is a suf\u00fbx  of another,  then  the  two  \nstrings must have the same last character. Since r C 1>0, the  pre\u00fbx  P\u0152  W r C 1\ufffd is \nnonempty, and so P\u0152r  C 1\ufffd D P\u0152q\ufffd . Furthermore, r 2 \ufffd \ue003 \u0152q \ue003 1\ufffd by  Lemma  32.6.  \nTherefore, r 2 E q\ue0021 , and so \ufffd\u0152q\ufffd \ue003 1 D r \u0dc4 max E q\ue0021 or, equivalently, \n\ufffd\u0152q\ufffd \u0dc4 1 C max E q\ue0021 : (32.9)  \nCombining  equations  (32.8)  and  (32.9)  completes  the  proof.  \nWe  now  \u00fbnish  the  proof  that  COMPUTE-PREFIX-FUNCTION  computes \ufffd cor-  \nrectly.  The  key  is to combine  the  de\u00fbnition  of E q\ue0021 with  the  statement  of Corol-  \nlary  32.7,  so that  \ufffd\u0152q\ufffd equals 1 plus the greatest value of k in \ufffd \ue003 \u0152q \ue003 1\ufffd such that 982  Chapter  32  String  Matching  \nP\u0152k  C 1\ufffd D P\u0152q\ufffd . First, in C OMPUTE-PREFIX-FUNCTION , k D \ufffd\u0152q  \ue003 1\ufffd at the \nstart of each iteration of the for  loop  of lines  439.  This  condition  is enforced  by  \nlines  2 and  3 when  the  loop  is \u00fbrst  entered,  and  it remains  true  in each successive \niteration  because  of line  9. Lines  538  adjust  k so that it becomes the correct value \nof \ufffd\u0152q\ufffd. The while  loop  of lines  536  searches  through  all  values  k 2 \ufffd \ue003 \u0152q \ue003 1\ufffd in \ndecreasing  order  to \u00fbnd  the  value  of \ufffd\u0152q\ufffd. The loop terminates either because k \nreaches 0 or P\u0152k  C 1\ufffd D P\u0152q\ufffd. Because  the  <and=  operator  short-circuits,  if the  \nloop terminates because P\u0152k  C 1\ufffd D P\u0152q\ufffd , then k must have also been positive, \nand so k is the greatest value in E q\ue0021 . In this  case,  lines  739  set  \ufffd\u0152q\ufffd to k C 1, \naccording  to Corollary  32.7.  If, instead,  the  while  loop terminates because k D 0, \nthen there are two possibilities. If P\u01521\ufffd  D P\u0152q\ufffd , then E q\ue0021 D f0g, and  lines  739  \nset both k and \ufffd\u0152q\ufffd to 1. If k D 0 and P\u01521\ufffd  \u00a4 P\u0152q\ufffd , however, then E q\ue0021 D ;. In \nthis case, line 9 sets \ufffd\u0152q\ufffd to 0, again  according  to Corollary  32.7,  which  completes  \nthe proof of the correctness of C OMPUTE-PREFIX-FUNCTION . \nCorrectness  of the  Knuth-Morris-Pratt  algorithm  \nYou  can  think  of the  procedure  KMP-M ATCHER as a reimplemented version \nof the procedure F INITE-AUTOMATON-MATCHER, but  using  the  pre\u00fbx  func-  \ntion \ufffd to compute  state  transitions.  Speci\u00fbcally,  we\u2019ll  prove  that in the i th \niteration of the for  loops  of both  KMP-M ATCHER and F INITE-AUTOMATON- \nMATCHER , the state q has the same value upon testing for equality with m (at \nline  8 in KMP-M ATCHER and  at line  4 in FINITE-AUTOMATON-MATCHER ). \nOnce  we  have  argued  that  KMP-M ATCHER simulates the behavior of F INITE- \nAUTOMATON-MATCHER, the  correctness  of KMP-M ATCHER follows from the \ncorrectness of F INITE-AUTOMATON-MATCHER (though  we\u2019ll  see  a little  later  why  \nline  10  in KMP-M ATCHER is necessary). \nBefore  formally  proving  that  KMP-M ATCHER correctly simulates F INITE- \nAUTOMATON-MATCHER, let\u2019s  take  a moment  to understand  how  the  pre\u00fbx  func-  \ntion \ufffd replaces the \u0131 transition  function.  Recall  that  when  a string-matching  \nautomaton is in state q and it scans a character a D T\u0152i\ufffd, it moves to a new \nstate \u0131.q;a/ . If a D P\u0152q  C 1\ufffd, so that a continues to match the pattern, then the \nstate number is incremented: \u0131.q;a/  D q C 1. Otherwise,  a \u00a4 P\u0152q  C 1\ufffd, so that \na does not continue to match the pattern, and the sta te number does not increase: \n0 \u0dc4 \u0131.q;a/  \u0dc4 q. In the  \u00fbrst  case,  when  a continues  to match,  KMP-M ATCHER \nmoves to state q C 1 without referring to the \ufffd function: the while  loop test in \nline  4 immediately  comes  up  false,  the  test  in line  6 comes  up  true,  and  line  7 \nincrements q. \nThe \ufffd function comes into play when the character a does not continue to match \nthe pattern, so that the new state \u0131.q;a/  is either q or to the left of q along the spine \nof the automaton. The while  loop  of lines  435  in KMP-M ATCHER iterates through 32.4  The  Knuth-Morris-Pratt  algorithm  983 \nthe states in \ufffd \ue003 \u0152q\ufffd, stopping either when it arrives in a state, say q 0 , such that a \nmatches P\u0152q  0 C 1\ufffd or q 0 has gone all the way down to 0. If a matches P\u0152q  0 C 1\ufffd, \nthen  line  7 sets  the  new  state  to q 0 C1, which should equal \u0131.q;a/  for the simulation \nto work correctly. In other words, the new state \u0131.q;a/  should be either state 0 or \na state numbered 1 more than some state in \ufffd \ue003 \u0152q\ufffd. \nLet\u2019s  look  at the  example  in Figures  32.6  and  32.10,  which  are  for the pattern \nP D ababaca . Suppose that the automaton is in state q D 5, having matched \nababa . The states in \ufffd \ue003 \u01525\ufffd  are, in descending order, 3, 1, and 0. If the  next  char-  \nacter scanned is c, then you can see that the automaton moves to stat e \u0131.5;  c/ D 6 \nin both F INITE-AUTOMATON-MATCHER (line  3) and  KMP-M ATCHER (line  7).  \nNow suppose that the next character scanned is inst ead b, so that the automaton \nshould move to state \u0131.5;  b/ D 4. The while  loop  in KMP-M ATCHER exits after \nexecuting  line  5 once,  and  the  automaton  arrives  in state  q 0 D \ufffd\u01525\ufffd D 3. Since \nP\u0152q  0 C 1\ufffd D P\u01524\ufffd  D b, the  test  in line  6 comes  up  true,  and  the  automaton  moves  \nto the new state q 0 C 1 D 4 D \u0131.5;  b/. Finally, suppose that the next character \nscanned is instead a, so that the automaton should move to state \u0131.5;  a/ D 1. The \n\u00fbrst  three  times  that  the  test  in line  4 executes,  the  test  comes  up  true.  The  \u00fbrst  time  \n\u00fbnds  that  P\u01526\ufffd  D c \u00a4 a, and the automaton moves to state \ufffd\u01525\ufffd D 3 (the  \u00fbrst  state  \nin \ufffd \ue003 \u01525\ufffd). The  second  time  \u00fbnds  that  P\u01524\ufffd  D b \u00a4 a, and the automaton moves to \nstate \ufffd\u01523\ufffd D 1 (the second state in \ufffd \ue003 \u01525\ufffd). The  third  time  \u00fbnds  that  P\u01522\ufffd  D b \u00a4 a, \nand the automaton moves to state \ufffd\u01521\ufffd D 0 (the last state in \ufffd \ue003 \u01525\ufffd). The while  loop \nexits once it arrives in state q 0 D 0. Now  line  6 \u00fbnds  that  P\u0152q  0 C 1\ufffd D P\u01521\ufffd  D a, \nand  line  7 moves  the  automaton  to the  new  state  q 0 C 1 D 1 D \u0131.5;  a/. \nThus,  the  intuition  is that  KMP-M ATCHER iterates through the states in \ufffd \ue003 \u0152q\ufffd  in \ndecreasing order, stopping at some state q 0 and then possibly moving to state q 0 C1. \nAlthough that might seem like a lot of work just to  simulate computing \u0131.q;a/ , \nbear  in mind  that  asymptotically,  KMP-M ATCHER is no slower than F INITE- \nAUTOMATON-MATCHER . \nWe  are  now  ready  to formally  prove  the  correctness  of the  Knuth-Morris-Pratt  \nalgorithm.  By  Theorem  32.4,  we  have  that  q D \ufffd.T\u0152  W i\ufffd/  after  each  time  line  3 of \nFINITE-AUTOMATON-MATCHER executes.  Therefore,  it suf\u00fbces  to show  that  the  \nsame property holds with regard to the for  loop  in KMP-M ATCHER . The proof \nproceeds by induction on the number of loop iterati ons. Initially, both procedures \nset q to 0 as they enter their respective for  loops  for  the  \u00fbrst  time.  Consider  iter-  \nation i of the for  loop  in KMP-M ATCHER . By the inductive hypothesis, the state \nnumber q equals \ufffd.T\u0152  W i \ue003 1\ufffd/  at the start of the loop iteration. We need to show  \nthat  when  line  8 is reached,  the  new  value  of q is \ufffd.T\u0152  W i\ufffd/. (Again,  we\u2019ll  handle  \nline  10  separately.)  \nConsidering q to be the state number at the start of the for  loop iteration, when \nKMP-M ATCHER considers the character T\u0152i\ufffd, the  longest  pre\u00fbx  of P that is a \nsuf\u00fbx  of T\u0152  W i\ufffd is either P\u0152  W q C 1\ufffd (if P\u0152q  C 1\ufffd D T\u0152i\ufffd) or some  pre\u00fbx  (not  984  Chapter  32  String  Matching  \nnecessarily proper, and possibly empty) of P\u0152  W q\ufffd. We consider separately the \nthree cases in which \ufffd.T\u0152  W i\ufffd/  D 0, \ufffd.T\u0152  W i\ufffd/  D q C 1, and 0<\ufffd.T\u0152  W i\ufffd/  \u0dc4 q. \n\ue001 If \ufffd.T\u0152  W i\ufffd/  D 0, then P\u0152  W 0\ufffd D \" is the  only  pre\u00fbx  of P that  is a suf\u00fbx  of T\u0152  W i\ufffd. \nThe while  loop  of lines  435  iterates  through  each  value  q 0 in \ufffd \ue003 \u0152q\ufffd, but although \nP\u0152  W q 0 \ufffd \u2742 P\u0152  W q\ufffd \u2742 T\u0152  W i \ue003 1\ufffd for every q 0 2 \ufffd \ue003 \u0152q\ufffd  (because < are \u2742 are  tran-  \nsitive  relations),  the  loop  never  \u00fbnds  a q 0 such that P\u0152q  0 C 1\ufffd D T\u0152i\ufffd. The loop \nterminates when q reaches 0, and  of course  line  7 does  not  execute.  Therefore,  \nq D 0 at line  8, so that  now  q D \ufffd.T\u0152  W i\ufffd/. \n\ue001 If \ufffd.T\u0152  W i\ufffd/  D q C1, then P\u0152q  C1\ufffd D T\u0152i\ufffd, and the while  loop  test  in line  4 fails  \nthe  \u00fbrst  time  through.  Line  7 executes,  incrementing  the  state number to q C 1, \nwhich equals \ufffd.T\u0152  W i\ufffd/. \n\ue001 If 0 < \ufffd.T\u0152  W i\ufffd/  \u0dc4 q 0 , then the while  loop  of lines  435  iterates  at least  once,  \nchecking in decreasing order each value in \ufffd \ue003 \u0152q\ufffd  until it stops at some q 0 <q. \nThus, P\u0152  W q 0 \ufffd is the  longest  pre\u00fbx  of P\u0152  W q\ufffd for which P\u0152q  0 C 1\ufffd D T\u0152i\ufffd, so \nthat when the while  loop terminates, q 0 C 1 D \ufffd.P\u0152  W q\ufffdT\u0152i\ufffd/ . Since q D \n\ufffd.T\u0152  W i \ue003 1\ufffd/, Lemma  32.3  implies  that  \ufffd.T\u0152  W i \ue003 1\ufffdT\u0152i\ufffd/  D \ufffd.P\u0152  W q\ufffdT\u0152i\ufffd/ . \nThus we have \nq 0 C 1 D \ufffd.P\u0152  W q\ufffdT\u0152i\ufffd/  \nD \ufffd.T\u0152  W i \ue003 1\ufffdT\u0152i\ufffd/  \nD \ufffd.T\u0152  W i\ufffd/  \nwhen the while  loop  terminates.  After  line  7 increments  q, the  new  state  num-  \nber q equals \ufffd.T\u0152  W i\ufffd/. \nLine  10  is necessary  in KMP-M ATCHER, because  otherwise,  line  4 might  try  \nto reference P\u0152m  C 1\ufffd after  \u00fbnding  an occurrence  of P . (The argument that \nq D \ufffd.T\u0152  W i \ue003 1\ufffd/  upon  the  next  execution  of line  4 remains  valid  by  the  hint  \ngiven  in Exercise  32.4-8:  that  \u0131.m;a/  D \u0131.\ufffd\u0152m\ufffd; a/ or, equivalently, \ufffd.Pa/  D \n\ufffd.P\u0152  W \ufffd\u0152m\ufffd\ufffda/  for any a 2 \u2020.) The remaining argument for the correctness \nof the  Knuth-Morris-Pratt  algorithm  follows  from  the  corre ctness of F INITE- \nAUTOMATON-MATCHER, since  we  have  shown  that  KMP-M ATCHER simulates \nthe behavior of F INITE-AUTOMATON-MATCHER . \nExercises  \n32.4-1  \nCompute  the  pre\u00fbx  function  \ufffd for the pattern ababbabbabbababbabb  . \n32.4-2  \nGive  an upper  bound  on  the  size  of \ufffd \ue003 \u0152q\ufffd  as a function of q. Give  an example  to \nshow that your bound is tight. 32.5  Suf\ufb01x  arrays  985 \n32.4-3  \nExplain how to determine the occurrences of pattern  P in the text T by examining \nthe \ufffd function for the string PT  (the string of length mCn that is the concatenation \nof P and T ). \n32.4-4  \nUse  an aggregate  analysis  to show  that  the  running  time  of KMP-M ATCHER \nis \u201a.n/ . \n32.4-5  \nUse  a potential  function  to show  that  the  running  time  of KMP-  MATCHER is \u201a.n/ . \n32.4-6  \nShow  how  to improve  KMP-M ATCHER by replacing the occurrence of \ufffd in line  5 \n(but  not  line  10)  by  \ufffd 0 , where \ufffd 0 is de\u00fbned  recursively  for  q D 1;2;:::;m  \ue003 1 by \nthe equation \n\ufffd 0 \u0152q\ufffd  D \u0128 \n0 if \ufffd\u0152q\ufffd D 0;  \n\ufffd 0 \u0152\ufffd\u0152q\ufffd\ufffd if \ufffd\u0152q\ufffd \u00a4 0 and P\u0152\ufffd\u0152q\ufffd C 1\ufffd D P\u0152q  C 1\ufffd;  \n\ufffd\u0152q\ufffd if \ufffd\u0152q\ufffd \u00a4 0 and P\u0152\ufffd\u0152q\ufffd C 1\ufffd \u00a4 P\u0152q  C 1\ufffd:  \nExplain  why  the  modi\u00fbed  algorithm  is correct,  and  explain  in what sense this \nchange constitutes an improvement. \n32.4-7  \nGive  a linear-time  algorithm  to determine  whether  a text  T is a cyclic rotation of \nanother string T 0 . For example, braze  and zebra  are cyclic rotations of each \nother. \n? 32.4-8  \nGive  an O.m  j\u2020j/-time  algorithm  for  computing  the  transition  function  \u0131 for the \nstring-matching  automaton  corresponding  to a given  patter n P . (Hint: Prove that \n\u0131.q;a/  D \u0131.\ufffd\u0152q\ufffd; a/ if q D m or P\u0152q  C 1\ufffd \u00a4 a.) \n32.5  Suf\ufb01x  arrays  \nThe  algorithms  we  have  seen  thus  far  in this  chapter  can  ef\u00fbciently  \u00fbnd  all  occur-  \nrences of a pattern in a text. That is, however, al l they can do. This section presents \na different  approach4suf\u00fbx  arrays4with  which  you  can  \u00fbnd  all occurrences of a \npattern  in a text,  but  also  quite  a bit  more.  A suf\u00fbx  array  won\u2019t  \u00fbnd  all  occurrences  986  Chapter  32  String  Matching  \ni 1 2 3 4 5 6 7 \nT\u0152i\ufffd  r a t a t a t  i SA\u0152i\ufffd  rank\u0152i\ufffd  LCP\u0152i\ufffd  suf\u00fbx  T\u0152SA\u0152i\ufffd  W \ufffd \n1 6 4 0 at  \n2 4 3 2 atat  \n3 2 7 4 atatat  \n4 1 2 0 ratatat  \n5 7 6 0 t \n6 5 1 1 tat  \n7 3 5 3 tatat  \nFigure  32.11  The  suf\u00fbx  array  SA, rank array rank, longest  common  pre\u00fbx  array  LCP, and  lexi-  \ncographically  sorted  suf\u00fbxes  of the  text  T D ratatat  with length n D 7. The value of rank\u0152i\ufffd  \nindicates  the  position  of the  suf\u00fbx  T\u0152i  W \ufffd in the lexicographically sorted order: rank\u0152SA\u0152i\ufffd\ufffd  D i for \ni D 1;2;:::;n . The rank array is used to compute the LCP array. \nof a pattern  as quickly  as,  say,  the  Knuth-Morris-Pratt  algorithm, but its additional \n\u00fcexibility  makes  it well  worth  studying.  \nA suf\u00fbx  array  is simply  a compact  way  to represent  the  lexicog raphically sorted \norder of all n suf\u00fbxes  of a length-n text.  Given  a text  T\u01521  W n\ufffd, let T\u0152i  W \ufffd denote the \nsuf\u00fbx  T\u0152i  W n\ufffd. The suf\ufb01x  array  SA\u01521 W n\ufffd of T is de\u00fbned  such  that  if SA\u0152i\ufffd  D j , then \nT\u0152j  W \ufffd is the i th suf\u00fbx  of T in lexicographic order. 3 That is, the i th suf\u00fbx  of T in \nlexicographic order is T\u0152SA\u0152i\ufffd  W \ufffd. Along  with  the  suf\u00fbx  array,  another  useful  array  \nis the longest  common  pre\ufb01x  array  LCP\u01521 W n\ufffd. The entry LCP\u0152i\ufffd  gives the length \nof the  longest  common  pre\u00fbx  between  the  i th and .i \ue003 1/st suf\u00fbxes  in the  sorted  \norder (with LCP\u0152SA\u01521\ufffd\ufffd  de\u00fbned  to be 0, since  there  is no  pre\u00fbx  lexicographically  \nsmaller than T\u0152SA\u01521\ufffd  W \ufffd). Figure  32.11  shows  the  suf\u00fbx  array  and  longest  common  \npre\u00fbx  array  for  the  7-character  text  ratatat . \nGiven  the  suf\u00fbx  array  for  a text,  you  can  search  for  a pattern  via binary search \non  the  suf\u00fbx  array.  Each  occurrence  of a pattern  in the  text  starts  some  suf\u00fbx  \nof the  text,  and  because  the  suf\u00fbx  array  is in lexicographica lly sorted order, all \noccurrences of a pattern will appear at the start o f consecutive  entries  of the  suf\u00fbx  \narray.  For  example,  in Figure  32.11,  the  three  occurrences  of at  in ratatat  \nappear in entries 1 through 3 of the  suf\u00fbx  array.  If you  \u00fbnd  the  length-m pattern \nin the  length-n suf\u00fbx  array  via  binary  search  (taking  O.m  lg n/ time because each \ncomparison takes O.m/  time),  then  you  can  \u00fbnd  all  occurrences  of the  pattern  in \nthe text by searching backward and forward from tha t spot until you  \u00fbnd  a suf\u00fbx  \nthat does not start with the pattern (or you go bey ond the boun ds of the  suf\u00fbx  \narray). If the pattern occurs k times,  then  the  time  to \u00fbnd  all  k occurrences is \nO.m  lg n C km/. \n3 Informally, lexicographic order is <alphabetical or der= in the underlying character set. A more \nprecise  de\u00fbnition  of lexicographic  order  appears  in Problem  12-2  on  page  327.  32.5  Suf\ufb01x  arrays  987 \nWith  the  longest  common  pre\u00fbx  array,  you  can  \u00fbnd  a longest  repeated substring, \nthat is, the longest substring that occurs more tha n once in the text. If LCP\u0152i\ufffd  \ncontains a maximum value in the LCP array, then a longest repeated substring \nappears in T\u0152SA\u0152i\ufffd  W SA\u0152i\ufffd  C LCP\u0152i\ufffd  \ue003 1\ufffd. In the  example  of Figure  32.11,  the  \nLCP array has one maximum value: LCP\u01523\ufffd  D 4. Therefore, since SA\u01523\ufffd  D 2, \nthe longest repeated substring is T\u01522  W 5\ufffd D atat. Exercise  32.5-3  asks  you  to \nuse  the  suf\u00fbx  array  and  longest  common  pre\u00fbx  array  to \u00fbnd  the  longest common \nsubstrings  between  two  texts.  Next,  we\u2019ll  see  how  to compute  the  suf\u00fbx  array  for  \nan n-character  text  in O.n  lg n/ time  and,  given  the  suf\u00fbx  array  and  the  text,  how  \nto compute  the  longest  common  pre\u00fbx  array  in \u201a.n/  time. \nComputing  the  suf\ufb01x  array  \nThere  are  several  algorithms  to compute  the  suf\u00fbx  array  of a length-n text. Some \nrun  in linear  time,  but  are  rather  complicated.  One  such  algorithm is given in \nProblem  32-2.  Here  we\u2019ll  explore  a simpler  algorithm  that  runs in \u201a.n  lg n/ time. \nThe idea behind the O.n  lg n/-time  procedure  COMPUTE-SUFFIX-ARRAY on \nthe following page is to lexicographically sort sub strings of the text with increasing \nlengths. The procedure makes several passes over th e text, with the substring length \ndoubling each time. By the dlg neth pass,  the  procedure  is sorting  all  the  suf\u00fbxes,  \nthereby gaining the information needed to construct  the suf\u00fbx  array.  The  key  to \nattaining an O.n  lg n/-time  algorithm  will  be to have  each  pass  after  the  \u00fbrst  sort  \nin linear time, which will indeed be possible by us ing radix sort. \nLet\u2019s  start  with  a simple  observation.  Consider  any  two  strings, s 1 and s 2 . De-  \ncompose s 1 into s 0 \n1 and s 00 \n1 , so that s 1 is s 0 \n1 concatenated with s 00 \n1 . Likewise, let s 2 be \ns 0 \n2 concatenated with s 00 \n2 . Now, suppose that s 0 \n1 is lexicographically smaller than s 0 \n2 . \nThen, regardless of s 00 \n1 and s 00 \n2 , it must be the case that s 1 is lexicographically smaller \nthan s 2 . For example, let s 1 D aaz  and s 2 D aba, and decompose s 1 into s 0 \n1 D aa  \nand s 00 \n1 D z and s 2 into s 0 \n2 D ab  and s 00 \n2 D a. Because s 0 \n1 is lexicographically \nsmaller than s 0 \n2 , it follows that s 1 is lexicographically smaller than s 2 , even though \ns 00 \n2 is lexicographically smaller than s 00 \n1 . \nInstead of comparing substrings directly, C OMPUTE-SUFFIX-ARRAY represents \nsubstrings of the text with integer ranks . Ranks have the simple property that one \nsubstring is lexicographically smaller then another  if and only if it has a smaller \nrank. Identical substrings have equal ranks. \nWhere  do  these  ranks  come  from?  Initially,  the  substrings  being considered are \njust single characters from the text. Assume that, as in many programming  lan-  \nguages, there is a function, ord, that maps a chara cter to its underlying encoding, \nwhich is a positive integer. The ord function could  be the ASCII or Unicode  encod-  \nings or any other function that produces a relative  ordering of the characters. For \nexample if all the characters are known to be lower case letters, then ord .a/ D 1, 988  Chapter  32  String  Matching  \nCOMPUTE-SUFFIX-ARRAY .T;n/  \n1 allocate arrays substr-rank \u01521 W n\ufffd, rank\u01521 W n\ufffd, and SA\u01521 W n\ufffd \n2 for  i D 1 to n \n3 substr-rank \u0152i\ufffd:  left-rank D ord.T\u0152i\ufffd/  \n4 if i <n  \n5 substr-rank \u0152i\ufffd:  right-rank D ord.T\u0152i  C 1\ufffd/  \n6 else  substr-rank \u0152i\ufffd:  right-rank D 0 \n7 substr-rank \u0152i\ufffd:  index D i \n8 sort the array substr-rank into monotonically increasing order based \non the left-rank attributes, using the right-rank attributes to break ties; \nif still a tie, the order does not matter \n9 l D 2 \n10  while  l<n  \n11  MAKE-RANKS.substr-rank ; rank;n/  \n12  for  i D 1 to n \n13  substr-rank \u0152i\ufffd:  left-rank D rank\u0152i\ufffd  \n14  if i C l \u0dc4 n \n15  substr-rank \u0152i\ufffd:  right-rank D rank\u0152i C l\ufffd \n16  else  substr-rank \u0152i\ufffd:  right-rank D 0 \n17  substr-rank \u0152i\ufffd:  index D i \n18  sort the array substr-rank into monotonically increasing order based \non the left-rank attributes, using the right-rank attributes \nto break ties; if still a tie, the order does not m atter \n19  l D 2l \n20 for  i D 1 to n \n21  SA\u0152i\ufffd  D substr-rank \u0152i\ufffd:  index \n22 return  SA \nMAKE-RANKS.substr-rank ; rank;n/  \n1 r D 1 \n2 rank\u0152substr-rank \u01521\ufffd:  index\ufffd D r \n3 for  i D 2 to n \n4 if substr-rank \u0152i\ufffd:  left-rank \u00a4 substr-rank \u0152i \ue003 1\ufffd:  left-rank \nor substr-rank \u0152i\ufffd:  right-rank \u00a4 substr-rank \u0152i \ue003 1\ufffd:  right-rank \n5 r D r C 1 \n6 rank\u0152substr-rank \u0152i\ufffd:  index\ufffd D r 32.5  Suf\ufb01x  arrays  989 \nAfter lines 2\u20137 \ni left-rank right-rank index substring \n1 114  97  1 ra  \n2 97  116  2 at  \n3 116  97  3 ta  \n4 97  116  4 at  \n5 116  97  5 ta  \n6 97  116  6 at  \n7 116  0 7 t After line 8 \ni left-rank right-rank index substring \n1 97  116  2 at  \n2 97  116  4 at  \n3 97  116  6 at  \n4 114  97  1 ra  \n5 116  0 7 t \n6 116  97  3 ta  \n7 116  97  5 ta  \nFigure  32.12  The substr-rank array for indices i D 1;2;:::;7  after the for  loop  of lines  237  and  \nafter  the  sorting  step  in line  8 for  input  string  T D ratatat . \nord.b/ D 2, . . . , ord.z/ D 26  would  work.  Once  the  substrings  being  consid-  \nered contain multiple characters, their ranks will be positive integers less than or \nequal to n, coming from their relative order after being sort ed. An empty substring \nalways has rank 0, since it is lexicographically less than any nonem pty substring. \nThe COMPUTE-SUFFIX-ARRAY procedure uses objects internally to keep track \nof the relative ordering of the substrings accordin g to their ranks.  When  con-  \nsidering substrings of a given length, the procedur e creates and sorts an array \nsubstr-rank \u01521 W n\ufffd of n objects, each with the following attributes: \n\ue001 left-rank contains the rank of the left part of the substring . \n\ue001 right-rank contains the rank of the right part of the substrin g. \n\ue001 index contains the index into the text T of where the substring starts. \nBefore delving into the details of how the procedur e works, let\u2019s  look  at how  it \noperates on the input text ratatat , with n D 7. Assuming  that  the  ord  func-  \ntion  returns  the  ASCII  code  for  a character,  Figure  32.12  shows the substr-rank \narray after the for  loop  of lines  237  and  then  after  the  sorting  step  in line  8. The  \nleft-rank and right-rank values  after  lines  237  are  the  ranks  of length-1 substrings \nin positions i and i C 1, for i D 1;2;:::;n . These initial ranks are the ASCII \nvalues of the characters. At this point, the left-rank and right-rank values give the \nranks of the left and right part of each substring of length 2. Because the substring \nstarting at index 7 consists of only one character, its right part is e mpty and so its \nright-rank is 0. After  the  sorting  step  in line  8, the  substr-rank array gives the \nrelative lexicographic order of all the substrings of length 2, with starting points of \nthese substrings in the index attribute.  For  example,  the  lexicographically  small-  \nest  length-2 substring is at, which starts at position substr-rank \u01521\ufffd:  index , which \nequals 2. This substring also occurs at positions substr-rank \u01522\ufffd:  index D 4 and \nsubstr-rank \u01523\ufffd:  index D 6. \nThe procedure then enters the while  loop  of lines  10319.  The  loop  variable  l \ngives an upper bound on the length of substrings th at have been sorted thus far. 990  Chapter  32  String  Matching  \nAfter line 11 \ni rank \n1 2  \n2 1  \n3 4  \n4 1  \n5 4  \n6 1  \n7 3  After lines 12\u201317 \ni left-rank right-rank index substring \n1 2 4 1 rata  \n2 1 1 2 atat  \n3 4 4 3 tata  \n4 1 1 4 atat  \n5 4 3 5 tat  \n6 1 0 6 at  \n7 3 0 7 t After line 18 \ni left-rank right-rank index substring \n1 1 0 6 at  \n2 1 1 2 atat  \n3 1 1 4 atat  \n4 2 4 1 rata  \n5 3 0 7 t \n6 4 3 5 tat  \n7 4 4 3 tata  \nFigure  32.13  The rank array  after  line  11  and  the  substr-rank array  after  lines  12317  and  after  \nline  18  in the  \u00fbrst  iteration  of the  while  loop  of lines  10319,  where  l D 2. \nEntering the while  loop, therefore, the substrings of length at most l D 2 are \nsorted. The call of M AKE-RANKS  in line  11  gives  each  of these  substrings  its  \nrank in the sorted order, from 1 up  to the  number  of unique  length-2 substrings, \nbased  on  the  values  it \u00fbnds  in the  substr-rank array. With l D 2, MAKE-RANKS  \nsets rank\u0152i\ufffd  to be the  rank  of the  length-2 substring T\u0152i  W i C 1\ufffd. Figure  32.13  \nshows these new ranks, which are not necessarily un ique. For example, since the \nlength-2 substring at  occurs at positions 2, 4, and 6, MAKE-RANKS  \u00fbnds  that  \nsubstr-rank \u01521\ufffd, substr-rank \u01522\ufffd, and substr-rank \u01523\ufffd  have equal values in left-rank \nand in right-rank. Since substr-rank \u01521\ufffd:  index D 2, substr-rank \u01522\ufffd:  index D 4, and \nsubstr-rank \u01523\ufffd:  index D 6, and since at  is the smallest substring in lexicographic \norder, MAKE-RANKS  sets rank\u01522\ufffd  D rank\u01524\ufffd  D rank\u01526\ufffd  D 1. \nThis iteration of the while  loop will sort the substrings of length at most 4 based \non the ranks from sorting the substrings of length at most 2. The for  loop of lines \n12317  reconstitutes  the  substr-rank array, with substr-rank \u0152i\ufffd:  left-rank based on \nrank\u0152i\ufffd  (the  rank  of the  length-2 substring T\u0152i  W i C1\ufffd) and substr-rank \u0152i\ufffd:  right-rank \nbased on rank\u0152i C2\ufffd (the  rank  of the  length-2 substring T\u0152i  C2 W i C3\ufffd, which is 0 if \nthis  substring  starts  beyond  the  end  of the  length-n text). Together, these two ranks \ngive  the  relative  rank  of the  length-4 substring T\u0152i  W i C 3\ufffd. Figure  32.13  shows  the  \neffect  of lines  12317.  The  \u00fbgure  also  shows  the  result  of sorting the substr-rank \narray  in line  18,  based  on  the  left-rank attribute, and using the right-rank attribute \nto break ties. Now substr-rank gives  the  lexicographically  sorted  order  of all  sub-  \nstrings with length at most 4. \nThe next iteration of the while  loop, with l D 4, sorts the substrings of length \nat most 8 based on the ranks from sorting the substrings of l ength at most 4 4. \nFigure  32.14  shows  the  ranks  of the  length-4 substrings and the substr-rank array \n4 Why  keep  saying  <length  at most=?  Because  for  a given  value  of l , a substring of length l starting \nat position i is T\u0152i  W i C l \ue003 1\ufffd. If i C l \ue003 1>n , then the substring cuts off at the end of the tex t. 32.5  Suf\ufb01x  arrays  991 \nAfter line 11 \ni rank \n1 3  \n2 2  \n3 6  \n4 2  \n5 5  \n6 1  \n7 4  After lines 12\u201317 \ni left-rank right-rank index substring \n1 3 5 1 ratatat  \n2 2 1 2 atatat  \n3 6 4 3 tatat  \n4 2 0 4 atat  \n5 5 0 5 tat  \n6 1 0 6 at  \n7 4 0 7 t After line 18 \ni left-rank right-rank index substring \n1 1 0 6 at  \n2 2 0 4 atat  \n3 2 1 2 atatat  \n4 3 5 1 ratatat  \n5 4 0 7 t \n6 5 0 5 tat  \n7 6 4 3 tatat  \nFigure  32.14  The rank array  after  line  11  and  the  substr-rank array  after  lines  12317  and  after  \nline  18  in the  second4and  \u00fbnal4iteration  of the  while  loop  of lines  10319,  where  l D 4. \nbefore  and  after  sorting.  This  iteration  is the  \u00fbnal  one,  since with the length n of \nthe text equaling 7, the procedure has sorted all substrings. \nIn general, as the loop variable l increases, more and more of the right parts of \nthe substrings are empty. Therefore, more of the right-rank values are 0. Because i \nis at most n within  the  loop  of lines  12317,  the  left  part  of each  substrin g is always \nnonempty, and so all left-rank values are always positive. \nThis example illuminates why the C OMPUTE-SUFFIX-ARRAY procedure works. \nThe  initial  ranks  established  in lines  237  are  simply  the  ord  values  of the  charac-  \nters  in the  text,  and  so when  line  8 sorts  the  substr-rank array,  its  ordering  cor-  \nresponds  to the  lexicographic  ordering  of the  length-2 substrings. Each iteration \nof the while  loop  of lines  10319  takes  sorted  substrings  of length  l and produces \nsorted substrings of length 2l . Once  l reaches or exceeds n, all substrings have \nbeen sorted. \nWithin an iteration of the while  loop, the M AKE-RANKS  procedure  <re-ranks=  \nthe  substrings  that  were  sorted,  either  by  line  8 before  the  \u00fbrst  iteration  or by  line  18  \nin the previous iteration. M AKE-RANKS  takes a substr-rank array, which has been \nsorted,  and  \u00fblls  in an array  rank\u01521 W n\ufffd so that rank\u0152i\ufffd  is the rank of the i th substring \nrepresented in the substr-rank array. Each rank is a positive integer, starting fr om 1, \nand going up to the number of unique substrings of length 2l . Substrings with equal \nvalues of left-rank and right-rank receive  the  same  rank.  Otherwise,  a substring  \nthat is lexicographically smaller than another appe ars earlier in the substr-rank \narray,  and  it receives  a smaller  rank.  Once  the  substrings  of length 2l are  re-ranked,  \nline  18  sorts  them  by  rank,  preparing  for  the  next  iteration  of the while  loop. \nOnce  l reaches or exceeds n and all substrings are sorted, the values in the index \nattributes give the starting positions of the sorte d substrings. These indices are \nprecisely  the  values  that  constitute  the  suf\u00fbx  array.  \nLet\u2019s  analyze  the  running  time  of COMPUTE-SUFFIX-ARRAY. Lines  137  take  \n\u201a.n/  time.  Line  8 takes  O.n  lg n/ time,  using  either  merge  sort  (see  Section  2.3.1)  \nor heapsort  (see  Chapter  6).  Because  the  value  of l doubles in each iteration of 992  Chapter  32  String  Matching  \nthe while  loop  of lines  10319,  this  loop  makes  dlg ne \ue003  1 iterations. Within each \niteration, the call of M AKE-RANKS  takes \u201a.n/  time, as does the for  loop of lines \n12317.  Line  18,  like  line  8, takes  O.n  lg n/ time,  using  either  merge  sort  or heap-  \nsort. Finally, the for  loop  of lines  20321  takes  \u201a.n/  time. The total time works out \nto O.n  lg 2 n/. \nA simple observation allows us to reduce the runnin g time to \u201a.n  lg n/. The \nvalues of left-rank and right-rank being  sorted  in line  18  are  always  integers  in the  \nrange 0 to n. Therefore, radix sort can sort the substr-rank array in \u201a.n/  time by \n\u00fbrst  running  counting  sort  (see  Chapter  8) based  on  right-rank and then running \ncounting sort based on left-rank. Now each iteration of the while  loop of lines \n10319  takes  only  \u201a.n/  time, giving a total time of \u201a.n  lg n/. \nExercise  32.5-2  asks  you  to make  a simple  modi\u00fbcation  to COMPUTE-SUFFIX- \nARRAY that allows the while  loop  of lines  10319  to iterate  fewer  than  dlg ne \ue003  1 \ntimes for certain inputs. \nComputing  the  LCP  array  \nRecall that LCP\u0152i\ufffd  is de\u00fbned  as the  length  of the  longest  common  pre\u00fbx  of the  \n.i \ue003 1/st and i th lexicographically  smallest  suf\u00fbxes  T\u0152SA\u0152i \ue003 1\ufffd W \ufffd and T\u0152SA\u0152i\ufffd  W \ufffd. \nBecause T\u0152SA\u01521\ufffd  W \ufffd is the  lexicographically  smallest  suf\u00fbx,  we  de\u00fbne  LCP\u01521\ufffd  to \nbe 0. \nIn order to compute the LCP array, we need an array rank that is the inverse \nof the SA array,  just  like  the  \u00fbnal  rank array in C OMPUTE-SUFFIX-ARRAY : if \nSA\u0152i\ufffd  D j , then rank\u0152j\ufffd  D i . That is, we have rank\u0152SA\u0152i\ufffd\ufffd  D i for i D 1;2;:::;n . \nFor  a suf\u00fbx  T\u0152i  W \ufffd, the value of rank\u0152i\ufffd  gives  the  position  of this  suf\u00fbx  in the  lexi-  \ncographically  sorted  order.  Figure  32.11  includes  the  rank array for the ratatat  \nexample.  For  example,  the  suf\u00fbx  tat  is T\u01525  W \ufffd. To  \u00fbnd  this  suf\u00fbx\u2019s  position  in the  \nsorted order, look up rank\u01525\ufffd  D 6. \nTo compute the LCP array,  we  will  need  to determine  where  in the  lexicograph-  \nically  sorted  order  a suf\u00fbx  appears,  but  with  its  \u00fbrst  charac ter removed. The rank \narray helps. Consider the i th smallest  suf\u00fbx,  which  is T\u0152SA\u0152i\ufffd  W \ufffd. Dropping its \n\u00fbrst  character  gives  the  suf\u00fbx  T\u0152SA\u0152i\ufffd  C 1 W \ufffd, that  is, the  suf\u00fbx  starting  at posi-  \ntion SA\u0152i\ufffd  C 1 in the  text.  The  location  of this  suf\u00fbx  in the  sorted  order  is given \nby rank\u0152SA\u0152i\ufffd  C 1\ufffd. For  example,  for  the  suf\u00fbx  atat, let\u2019s  see  where  to \u00fbnd  \ntat  (atat  with  its  \u00fbrst  character  removed)  in the  lexicographically  sorted order. \nThe  suf\u00fbx  atat  appears in position 2 of the  suf\u00fbx  array,  and  SA\u01522\ufffd  D 4. Thus, \nrank\u0152SA\u01522\ufffd  C 1\ufffd D rank\u01525\ufffd  D 6, and  sure  enough  the  suf\u00fbx  tat  appears  in loca-  \ntion 6 in the sorted order. \nThe procedure C OMPUTE-LCP  on  the  next  page  produces  the  LCP array. The \nfollowing lemma helps show that the procedure is co rrect. 32.5  Suf\ufb01x  arrays  993 \nCOMPUTE-LCP  .T;  SA;n/  \n1 allocate arrays rank\u01521 W n\ufffd and LCP\u01521 W n\ufffd \n2 for  i D 1 to n \n3 rank\u0152SA\u0152i\ufffd\ufffd  D i / / by  de\u00fbnition  \n4 LCP\u01521\ufffd  D 0 / / also  by  de\u00fbnition  \n5 l D 0 / / initialize length of LCP \n6 for  i D 1 to n \n7 if rank\u0152i\ufffd>1  \n8 j D SA\u0152rank\u0152i\ufffd  \ue003 1\ufffd / / T\u0152j  W \ufffd precedes T\u0152i  W \ufffd lexicographically \n9 m D max fi;j  g \n10  while  m C l \u0dc4 n and T\u0152i  C l\ufffd == T\u0152j  C l\ufffd \n11  l D l C 1 / / next  character  is in common  pre\u00fbx  \n12  LCP\u0152rank\u0152i\ufffd\ufffd  D l / / length of LCP of T\u0152j  W \ufffd and T\u0152i  W \ufffd \n13  if l>0  \n14  l D l \ue003 1 / / peel  off  \u00fbrst  character  of common  pre\u00fbx  \n15  return  LCP \nLemma  32.8  \nConsider  suf\u00fbxes  T\u0152i  \ue003 1 W \ufffd and T\u0152i  W \ufffd, which appear at positions rank\u0152i \ue003 1\ufffd \nand rank\u0152i\ufffd, respectively, in the lexicographically sorted ord er of suf\u00fbxes.  If \nLCP\u0152rank\u0152i \ue003 1\ufffd\ufffd  D l > 1, then  the  suf\u00fbx  T\u0152i  W \ufffd, which is T\u0152i  \ue003 1 W \ufffd with its \n\u00fbrst  character  removed,  has  LCP\u0152rank\u0152i\ufffd\ufffd  \ue004 l \ue003 1. \nProof  The  suf\u00fbx  T\u0152i  \ue003 1 W \ufffd appears at position rank\u0152i \ue003 1\ufffd in the lexicographically \nsorted  order.  The  suf\u00fbx  immediately  preceding  it in the  sorted order appears at \nposition rank\u0152i \ue003 1\ufffd \ue003 1 and is T\u0152SA\u0152rank\u0152i \ue003 1\ufffd \ue003 1\ufffd W \ufffd. By assumption and the \nde\u00fbnition  of the  LCP array,  these  two  suf\u00fbxes,  T\u0152SA\u0152rank\u0152i \ue0031\ufffd\ue0031\ufffd W \ufffd and T\u0152i  \ue0031 W \ufffd, \nhave  a longest  common  pre\u00fbx  of length  l >1. Removing  the  \u00fbrst  character  from  \neach  of these  suf\u00fbxes  gives  the  suf\u00fbxes  T\u0152SA\u0152rank\u0152i \ue003 1\ufffd \ue003 1\ufffd C 1 W \ufffd and T\u0152i  W \ufffd, \nrespectively.  These  suf\u00fbxes  have  a longest  common  pre\u00fbx  of length l \ue003 1. If \nT\u0152SA\u0152rank\u0152i \ue003 1\ufffd \ue003 1\ufffd C 1 W \ufffd immediately precedes T\u0152i  W \ufffd in the lexicographically \nsorted order (that is, if rank\u0152SA\u0152rank\u0152i \ue003 1\ufffd \ue003 1\ufffd C 1\ufffd D rank\u0152i\ufffd  \ue003 1), then the lemma \nis proven. \nSo now assume that T\u0152SA\u0152rank\u0152i \ue003 1\ufffd \ue003 1\ufffd C 1 W \ufffd does not immediately precede \nT\u0152i  W \ufffd in the sorted order. Since T\u0152SA\u0152rank\u0152i \ue003 1\ufffd \ue003 1\ufffd W \ufffd immediately precedes \nT\u0152i  \ue003 1 W \ufffd and  they  have  the  same  \u00fbrst  l>1  characters, T\u0152SA\u0152rank\u0152i \ue003 1\ufffd \ue003 1\ufffd C 1 W \ufffd \nmust appear in the sorted order somewhere before T\u0152i  W \ufffd, with one or more other \nsuf\u00fbxes  intervening.  Each  of these  suf\u00fbxes  must  start  with  the same l \ue0031 characters \nas T\u0152SA\u0152rank\u0152i \ue0031\ufffd \ue0031\ufffd C1 W \ufffd and T\u0152i  W \ufffd, for otherwise it would appear either before 994  Chapter  32  String  Matching  \nT\u0152SA\u0152rank\u0152i \ue003 1\ufffd \ue003 1\ufffd C 1 W \ufffd or after T\u0152i  W \ufffd. Therefore,  whichever  suf\u00fbx  appears  in \nposition rank\u0152i\ufffd  \ue003 1, immediately before T\u0152i  W \ufffd, has  at least  its  \u00fbrst  l \ue003 1 characters \nin common with T\u0152i  W \ufffd. Thus, LCP\u0152rank\u0152i\ufffd\ufffd  \ue004 l \ue003 1. \nThe COMPUTE-LCP  procedure  works  as follows.  After  allocating  the  rank and \nLCP arrays  in line  1, lines  233  \u00fbll  in the  rank array  and  line  4 pegs  LCP\u01521\ufffd  to 0, \nper  the  de\u00fbnition  of the  LCP array. \nThe for  loop  of lines  6314  \u00fblls  in the  rest  of the  LCP array  going  by  decreasing-  \nlength  suf\u00fbxes.  That  is, it \u00fblls  the  position  of the  LCP array in the order rank\u01521\ufffd;  \nrank\u01522\ufffd;  rank\u01523\ufffd;:::;  rank\u0152n\ufffd, with  the  assignment  occurring  in line  12.  Upon  con-  \nsidering  a suf\u00fbx  T\u0152i  W \ufffd, line  8 determines  the  suf\u00fbx  T\u0152j  W \ufffd that  immediately  pre-  \ncedes T\u0152i  W \ufffd in the lexicographically sorted order. At this poin t, the longest  com-  \nmon  pre\u00fbx  of T\u0152j  W \ufffd and T\u0152i  W \ufffd has length at least l . This property certainly holds \nupon  the  \u00fbrst  iteration  of the  for  loop, when l D 0. Assuming  that  line  12  \nsets LCP\u0152rank\u0152i\ufffd\ufffd  correctly,  line  14  (which  decrements  l if it is positive) and \nLemma  32.8  maintain  this  property  for  the  next  iteration.  The longest common \npre\u00fbx  of T\u0152j  W \ufffd and T\u0152i  W \ufffd might be even longer than the value of l at the start of \nthe  iteration,  however.  Lines  9311  increment  l for each additional character the \npre\u00fbxes  have  in common  so that  it achieves  the  length  of the  longest  common  pre-  \n\u00fbx.  The  index  m is set  in line  9 and  used  in the  test  in line  10  to make  sure  that  the \ntest T\u0152i  C l\ufffd = = T\u0152j  C l\ufffd for  extending  the  longest  common  pre\u00fbx  does  not  run  \noff the end of the text T . When the while  loop  of lines  10311  terminates,  l is the \nlength  of the  longest  common  pre\u00fbx  of T\u0152j  W \ufffd and T\u0152i  W \ufffd. \nAs a simple aggregate analysis shows, the C OMPUTE-LCP  procedure  runs  in \n\u201a.n/  time. Each of the two for  loops iterates n times, and so it remains only \nto bound the total number of iterations by the while  loop  of lines  10311.  Each  \niteration increases l by 1, and the test m C l \u0dc4 n ensures that l is always less \nthan n. Because l has an initial value of 0 and decreases at most n \ue003 1 times in \nline  14,  line  11  increments  l fewer than 2n  times. Thus, C OMPUTE-LCP  takes  \n\u201a.n/  time. \nExercises  \n32.5-1  \nShow the substr-rank and rank arrays before each iteration of the while  loop of \nlines  10319  and  after  the  last  iteration  of the  while  loop,  the  suf\u00fbx  array  SA re-  \nturned,  and  the  sorted  suf\u00fbxes  when  COMPUTE-SUFFIX-ARRAY is run on the text \nhippityhoppity . Use the position of each letter in the alphabet a s its ord \nvalue, so that ord .b/ D 2. Then show the LCP array after each iteration of the for  \nloop  of lines  6314  of COMPUTE-LCP  given  the  text  hippityhoppity  and its \nsuf\u00fbx  array.  32.5  Suf\ufb01x  arrays  995 \n32.5-2  \nFor some inputs, the C OMPUTE-SUFFIX-ARRAY procedure  can  produce  the  cor-  \nrect result with fewer than dlg ne \ue003  1 iterations of the while  loop  of lines  10319.  \nModify COMPUTE-SUFFIX-ARRAY (and, if necessary, M AKE-RANKS ) so that the \nprocedure can stop before making all dlg ne \ue003  1 iterations in some cases. Describe \nan input that allows the procedure to make O.1/  iterations. Describe an input that \nforces the procedure to make the maximum number of iterations. \n32.5-3  \nGiven  two  texts,  T 1 of length n 1 and T 2 of length n 2 , show  how  to use  the  suf\u00fbx  ar-  \nray  and  longest  common  pre\u00fbx  array  to \u00fbnd  all  of the  longest  common  substrings , \nthat is, the longest substrings that appear in both  T 1 and T 2 . Your algorithm should \nrun in O.n  lg n C kl/  time, where n D n 1 C n 2 and there are k such longest \nsubstrings, each with length l . \n32.5-4  \nProfessor  Markram  proposes  the  following  method  to \u00fbnd  the  longest palindromes \nin a string T\u01521  W n\ufffd by  using  its  suf\u00fbx  array  and  LCP  array.  (Recall  from  Prob-  \nlem  14-2  that  a palindrome  is a nonempty  string  that  reads  the  same forward and \nbackward.) \nLet @ be a character that does not appear in T . Construct the text T 0 as the \nconcatenation of T , @, and the reverse of T . Denote the length of T 0 by \nn 0 D 2n  C 1. Create  the  suf\u00fbx  array  SA and LCP array LCP for T 0 . Since \nthe indices for a palindrome and its reverse appear  in consecutive positions \nin the  suf\u00fbx  array,  \u00fbnd  the  entries  with  the  maximum  LCP value LCP\u0152i\ufffd  \nsuch that SA\u0152i \ue003 1\ufffd D n 0 \ue003 SA\u0152i\ufffd  \ue003 LCP\u0152i\ufffd  C 2. (This constraint prevents \na substring4and  its  reverse4from  being  construed  as a palin drome unless \nit really is one.) For each such index i , one of the longest palindromes is \nT 0 \u0152SA\u0152i\ufffd  W SA\u0152i\ufffd  C LCP\u0152i\ufffd  \ue003 1\ufffd. \nFor example, if the text T is unreferenced , with n D 12, then the text T 0 is \nunreferenced@decnerefernu , with n 0 D 25  and  the  following  suf\u00fbx  array  \nand LCP array: \ni 1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  \nT 0 \u0152i\ufffd  u n r e f e r e n c e d @ d e c n e r e f e r n u \nSA\u0152i\ufffd  13  10  16  12  14  15  11  4 20  8 18  6 22  5 21  9 17  2 24  3 19  7 23  25  1 \nLCP\u0152i\ufffd  0 0 1 0 1 0 1 1 4 1 1 3 2 0 3 0 1 1 1 0 5 2 1 0 1 \nThe maximum LCP value is achieved at LCP\u015221\ufffd  D 5, and SA\u015220\ufffd  D 3 D n 0 \ue003 \nSA\u015221\ufffd  \ue003 LCP\u015221\ufffd  C 2. The  suf\u00fbxes  of T 0 starting at indices SA\u015220\ufffd  and SA\u015221\ufffd  \nare referenced@decnerefernu  and refernu , both of which start with the \nlength-5 palindrome refer . 996  Chapter  32  String  Matching  \nAlas,  this  method  is not  foolproof.  Give  an input  string  T that causes this method \nto give results that are shorter than the longest p alindrome contained within T , and \nexplain why your input causes the method to fail. \nProblems  \n32-1  String  matching  based  on  repetition  factors  \nLet y i denote the concatenation of string y with itself i times. For example, \n.ab/ 3 D ababab . We say that a string x 2 \u2020 \ue003 has repetition  factor  r if x D y r \nfor some string y 2 \u2020 \ue003 and some r >0 . Let \ufffd.x/  denote the largest r such that x \nhas repetition factor r . \na. Give  an ef\u00fbcient  algorithm  that  takes  as input  a pattern  P\u01521  W m\ufffd  and computes \nthe value \ufffd.P  \u0152 W i\ufffd/  for i D 1;2;:::;m . What is the running time of your \nalgorithm?  \nb. For any pattern P\u01521  W m\ufffd, let \ufffd \ue003 .P/  be de\u00fbned  as max  f\ufffd.P  \u0152 W i\ufffd/  W 1 \u0dc4 i \u0dc4 mg. \nProve that if the pattern P is chosen randomly from the set of all binary strin gs \nof length m, then the expected value of \ufffd \ue003 .P/  is O.1/ . \nc. Argue that the procedure R EPETITION-MATCHER correctly  \u00fbnds  all  occur-  \nrences of pattern P\u01521  W m\ufffd  in text T\u01521  W n\ufffd in O.\ufffd  \ue003 .P/n  C m/  time.  (This  al-  \ngorithm  is due  to Galil  and  Seiferas.  By  extending  these  ideas greatly, they \nobtained  a linear-time  string-matching  algorithm  that  uses only O.1/  storage \nbeyond what is required for P and T .) \nREPETITION-MATCHER .T;P;n;m/  \n1 k D 1 C \ufffd \ue003 .P/  \n2 q D 0 \n3 s D 0 \n4 while  s \u0dc4 n \ue003 m \n5 if T\u0152s  C q C 1\ufffd = = P\u0152q  C 1\ufffd \n6 q D q C 1 \n7 if q == m \n8 print <Pattern occurs with shift= s \n9 if q == m or T\u0152s  C q C 1\ufffd \u00a4 P\u0152q  C 1\ufffd \n10  s D s C max f1; dq=keg \n11  q D 0 Problems for Chapter 32 997 \n32-2  A linear-time  suf\ufb01x-array  algorithm  \nIn this  problem,  you  will  develop  and  analyze  a linear-time  divide-and-conquer  \nalgorithm  to compute  the  suf\u00fbx  array  of a text  T\u01521  W n\ufffd. As  in Section  32.5,  assume  \nthat each character in the text is represented by a n underlying encoding, which is a \npositive integer. \nThe  idea  behind  the  linear-time  algorithm  is to compute  the  suf\u00fbx  array  for  the  \nsuf\u00fbxes  starting  at 2=3  of the positions in the text, recursing as needed, use the \nresulting  information  to sort  the  suf\u00fbxes  starting  at the  remaining 1=3  of the  posi-  \ntions, and then merge the sorted information in lin ear time to produce  the  full  suf\u00fbx  \narray. \nFor i D 1;2;:::;n , if i mod 3 equals 1 or 2, then i is a sample  position , and the \nsuf\u00fbxes  starting  at such  positions  are  sample  suf\ufb01xes . Positions 3;6;9;:::  are non-  \nsample  positions, and  the  suf\u00fbxes  starting  at nonsample  positions  are  nonsample  \nsuf\ufb01xes . \nThe  algorithm  sorts  the  sample  suf\u00fbxes,  sorts  the  nonsample  suf\u00fbxes  (aided  by  \nthe  result  of sorting  the  sample  suf\u00fbxes),  and  merges  the  sorted  sample  and  non-  \nsample  suf\u00fbxes.  Using  the  example  text  T D bippityboppityboo  , here is the \nalgorithm in detail, listing substeps of each of th e above steps: \n1. The  sample  suf\u00fbxes  comprise  about  2=3  of the  suf\u00fbxes.  Sort  them  by  the  fol-  \nlowing  substeps,  which  work  with  a heavily  modi\u00fbed  version  of T and may \nrequire recursion. In part (a) of this problem on p age 999, you will show that \nthe  orders  of the  suf\u00fbxes  of T and  the  suf\u00fbxes  of the  modi\u00fbed  version  of T are \nthe same. \nA. Construct two texts P 1 and P 2 made up of <metacharacters= that are actually \nsubstrings of three consecutive characters from T . We delimit each such \nmetacharacter with parentheses. Construct \nP 1 D .T\u01521  W 3\ufffd/.T\u01524  W 6\ufffd/.T\u01527  W 9\ufffd/  \ue001 \ue001 \ue001  .T\u0152n  0 W n 0 C 2\ufffd/;  \nwhere n 0 is the largest integer congruent to 1, modulo 3, that is less than or \nequal to n and T is extended beyond position n with the special character \u00bf, \nwith encoding 0. With the example text T D bippityboppityboo  , we \nget that \nP 1 D .bip/.pit/.ybo/.ppi/.tyb/.oo\u00bf/: \nSimilarly, construct \nP 2 D .T\u01522  W 4\ufffd/.T\u01525  W 7\ufffd/.T\u01528  W 10\ufffd/  \ue001 \ue001 \ue001  .T\u0152n  00 W n 00 C 2\ufffd/;  \nwhere n 00 is the largest integer congruent to 2, modulo 3, that is less than or \nequal to n. For our example, we have \nP 2 D .ipp/.ity/.bop/.pit/.ybo/.o\u00bf\u00bf/: 998  Chapter  32  String  Matching  \nposition in T 1 4 7 10  13  16  2 5 8 11  14  17  \nmetacharacter in P .bip/ .pit/ .ybo/ .ppi/ .tyb/ .oo\u00bf/ .ipp/ .ity/ .bop/ .pit/ .ybo/ .o\u00bf\u00bf/ \ncharacter in P 0 1 7 10  8 9 6 3 4 2 7 10  5 \nposition in P 0 1 2 3 4 5 6 7 8 9 10  11  12  \nSA P 0 1 9 7 8 12  6 10  2 4 5 11  3 \npositions in T 1 8 2 5 17  16  11  4 10  13  14  7 \nof sorted sample \nsuf\u00fbxes  of T \nFigure  32.15  Computed  values  when  sorting  the  sample  suf\u00fbxes  of the  linear-time  suf\u00fbx-array  \nalgorithm for the text T D bippityboppityboo . \nIf n is a multiple of 3, append the metacharacter .\u00bf\u00bf\u00bf/ to the end of P 1 . In \nthis way, P 1 is guaranteed to end with a metacharacter containin g \u00bf. (This \nproperty helps in part (a) of this problem.) The te xt P 2 may or may not end \nwith a metacharacter containing \u00bf. \nB. Concatenate P 1 and P 2 to form a new text P . Figure  32.15  shows  P for our \nexample, along with the corresponding positions of T . \nC. Sort and rank the unique metacharacters of P , with ranks starting from 1. \nIn the example, P has 10  unique metacharacters: in sorted order, they are \n.bip/, .bop/, .ipp/, .ity/, .o\u00bf\u00bf/, .oo\u00bf/, .pit/, .ppi/, .tyb/, .ybo/. \nThe metacharacters .pit/ and .ybo/ each appear twice. \nD.  As  Figure  32.15  shows,  construct  a new  <text=  P 0 by renaming each \nmetacharacter in P by its rank. If P contains k unique metacharacters, then \neach <character= in P 0 is an integer from 1 to k. The  suf\u00fbx  arrays  for  P \nand P 0 are identical. \nE. Compute  the  suf\u00fbx  array  SA P 0 of P 0 . If the characters of P 0 (i.e., the ranks \nof metacharacters in P ) are  unique,  then  you  can  compute  its  suf\u00fbx  array  \ndirectly, since the ordering of the individual char acters gives  the  suf\u00fbx  array.  \nOtherwise,  recurse  to compute  the  suf\u00fbx  array  of P 0 , treating the ranks in P 0 \nas the  input  characters  in the  recursive  call.  Figure  32.15  shows  the  suf\u00fbx  \narray SA P 0 for our example. Since the number of metacharacters  in P , and \nhence the length of P 0 , is approximately 2n=3 , this recursive subproblem is \nsmaller than the current problem. \nF. From SA P 0 and the positions in T corresponding to the sample positions, \ncompute  the  list  of positions  of the  sorted  sample  suf\u00fbxes  of the original \ntext T . Figure  32.15  shows  the  list  of positions  in T of the sorted sample \nsuf\u00fbxes  in our  example.  \n2. The  nonsample  suf\u00fbxes  comprise  about  1=3  of the  suf\u00fbxes.  Using  the  sorted  \nsample  suf\u00fbxes,  sort  the  nonsample  suf\u00fbxes  by  the  following  substeps. Problems for Chapter 32 999 \ni 1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  16  17  18  19  \nT\u0152i\ufffd  b i p p i t y b o p p i t y b o o  \u00bf \u00bf \nr i 1 3 \ufffd 8 4 \ufffd 12  2 \ufffd 9 7 \ufffd 10  11  \ufffd 6 5 0 0 \nFigure  32.16  The ranks r 1 through r nC3 for the text T D bippityboppityboo  with n D 17. \nG.  Extending  the  text  T by the two special characters \u00bf\u00bf, so that T now has \nn C 2 characters,  consider  each  suf\u00fbx  T\u0152i  W \ufffd for i D 1;2;:::;n  C 2. Assign \na rank r i to each  suf\u00fbx  T\u0152i  W \ufffd. For the two special characters \u00bf\u00bf, set r nC1 D \nr nC2 D 0. For the sample positions of T , base the rank on the list of sorted \nsample positions of T . The  rank  is currently  unde\u00fbned  for  the  nonsample  \npositions of T . For these positions, set r i D \ufffd. Figure  32.16  shows  the  \nranks for T D bippityboppityboo  with n D 17. \nH.  Sort  the  nonsample  suf\u00fbxes  by  comparing  tuples  .T\u0152i\ufffd;r  i C1 /. In our  ex-  \nample, we get T\u015215  W \ufffd < T\u015212  W \ufffd < T\u01529  W \ufffd < T\u01523  W \ufffd < T\u01526  W \ufffd because \n.b;6/<. i;10/<. o;9/<. p;8/<. t;12/. \n3. Merge  the  sorted  sets  of suf\u00fbxes.  From  the  sorted  set  of suf\u00fbxes,  determine  the  \nsuf\u00fbx  array  of T . \nThis  completes  the  description  of a linear-time  algorithm  for  computing  suf\u00fbx  ar-  \nrays. The following parts of this problem ask you t o show that certain steps of this \nalgorithm  are  correct  and  to analyze  the  algorithm\u2019s  runnin g time. \na. De\u00fbne  a nonempty  suf\ufb01x  at position i of the text P created in substep B as \nall metacharacters from position i of P up  to and  including  the  \u00fbrst  metachar-  \nacter of P in which \u00bf appears or the end of P . In the example shown in \nFigure  32.15,  the  nonempty  suf\u00fbxes  of P starting at positions 1, 4, and 11  \nof P are .bip/.pit/.ybo/.ppi/.tyb/.oo\u00bf/, .ppi/.tyb/.oo\u00bf/, and \n.ybo/.o\u00bf\u00bf/, respectively.  Prove  that  the  order  of suf\u00fbxes  of P is the same \nas the  order  of its  nonempty  suf\u00fbxes.  Conclude  that  the  order  of suf\u00fbxes  of P \ngives  the  order  of the  sample  suf\u00fbxes  of T . (Hint: If P contains duplicate \nmetacharacters, consider separately the cases in wh ich two suf\u00fbxes  both  start  \nin P 1 , both start in P 2 , and one starts in P 1 and the other starts in P 2 . Use the \nproperty that \u00bf appears in the last metacharacter of P 1 .) \nb. Show how to perform substep C in \u201a.n/  time,  bearing  in mind  that  in a recur-  \nsive call, the characters in T are actually ranks in P 0 in the caller. \nc. Argue that the tuples in substep H are unique. Then  show how to perform this \nsubstep in \u201a.n/  time. 1000  Chapter  32  String  Matching  \nd. Consider  two  suf\u00fbxes  T\u0152i  W \ufffd and T\u0152j  W \ufffd, where T\u0152i  W \ufffd is a sample  suf\u00fbx  and  \nT\u0152j  W \ufffd is a nonsample  suf\u00fbx.  Show  how  to determine  in \u201a.1/  time whether \nT\u0152i  W \ufffd is lexicographically smaller than T\u0152j  W \ufffd. (Hint: Consider separately the \ncases in which i mod 3 D 1 and i mod 3 D 2. Compare tuples whose elements \nare characters in T and  ranks  as shown  in Figure  32.16.  The  number  of elements  \nper tuple may depend on whether i mod 3 equals 1 or 2.) Conclude  that  step  3 \ncan be performed in \u201a.n/  time. \ne. Justify  the  recurrence  T.n/  \u0dc4 T.2n=3  C 2/ C \u201a.n/  for the running time of the \nfull algorithm, and show that its solution is O.n/ . Conclude that the algorithm \nruns in \u201a.n/  time. \n32-3  Burrows-Wheeler  transform  \nThe Burrows-Wheeler  transform , or BWT , for a text T is de\u00fbned  as follows.  First,  \nappend a new character that compares as lexicograph ically less  than  every  charac-  \nter of T , and denote this character by $ and the resulting string by T 0 . Letting n be \nthe length of T 0 , create n rows of characters, where each row is one of the n cyclic \nrotations of T 0 . Next, sort the rows lexicographically. The BWT is  then the string \nof n characters in the rightmost column, read top to bot tom. \nFor example, let T D rutabaga , so that T 0 D rutabaga$ . The cyclic \nrotations are \nrutabaga$  \nutabaga$r  \ntabaga$ru  \nabaga$rut  \nbaga$ruta  \naga$rutab  \nga$rutaba  \na$rutabag  \n$rutabaga  \nSorting the rows and numbering the sorted rows give s \n1 $rutabaga  \n2 a$rutabag  \n3 abaga$rut  \n4 aga$rutab  \n5 baga$ruta  \n6 ga$rutaba  \n7 rutabaga$  \n8 tabaga$ru  \n9 utabaga$r  Problems for Chapter 32 1001 \nThe BWT is the rightmost column, agtbaa$ur . (The row numbering will be \nhelpful in understanding how to compute the inverse  BWT.) \nThe BWT has applications in bioinformatics, and it can also be a step in text \ncompression. That is because it tends to place iden tical characters together, as in \nthe BWT of rutabaga , which places two of the instances of a together. When \nidentical characters are placed together, or even n earby, additional  means  of com-  \npressing become available. Following the BWT, combi nations of move-to-front  \nencoding,  run-length  encoding,  and  Huffman  coding  (see  Section  15.3)  can  pro-  \nvide  signi\u00fbcant  text  compression.  Compression  ratios  with  the BWT tend improve \nas the text length increases. \na. Given  the  suf\u00fbx  array  for  T 0 , show how to compute the BWT in \u201a.n/  time. \nIn order to decompress, the BWT must be invertible.  Assuming that the alphabet \nsize is constant, the inverse BWT can be computed i n \u201a.n/  time from the BWT. \nLet\u2019s  look  at the  BWT  of rutabaga , denoting it by BWT \u01521 W n\ufffd. Each character in \nthe BWT has a unique lexicographic rank from 1 to n. Denote the rank of BWT \u0152i\ufffd  \nby rank\u0152i\ufffd. If a character appears multiple times in the BWT,  each instance of the \ncharacter has a rank 1 greater than the previous instance of the character . Here are \nBWT and rank for rutabaga : \ni 1 2 3 4 5 6 7 8 9  \nBWT \u0152i\ufffd  a g t b a a $ u r  \nrank\u0152i\ufffd  2 6 8 5 3 4 1 9 7 \nFor example, rank\u01521\ufffd  D 2 because BWT \u01521\ufffd  D a and  the  only  character  that  pre-  \ncedes  the  \u00fbrst  a lexicographically is $ (which  we  de\u00fbned  to precede  all  other  char-  \nacters, so that $ has rank 1). Next, we have rank\u01522\ufffd  D 6 because BWT \u01522\ufffd  D g and \n\u00fbve  characters  in the  BWT  precede  g lexicographically: $, the three instances of a, \nand b. Jumping  ahead  to rank\u01525\ufffd  D 3, that is because BWT \u01525\ufffd  D a, and because \nthis a is the second instance of a in the BWT, its rank value is 1 greater than the \nrank value for the previous instance of a, in position 1. \nThere is enough information in BWT and rank to reconstruct T 0 from back to \nfront. Suppose that you know the rank r of a character c in T 0 . Then c is the  \u00fbrst  \ncharacter in row r of the sorted cyclic rotations. The last character in row r must \nbe the character that precedes c in T 0 . But you know which character is the last \ncharacter in row r , because it is BWT \u0152r\ufffd. To reconstruct T 0 from back to front, start \nwith $, which  you  can  \u00fbnd  in BWT . Then work backward using BWT and rank to \nreconstruct T 0 . \nLet\u2019s  see  how  this  strategy  works  for  rutabaga . The last character of T 0 , $, \nappears in position 7 of BWT . Since rank\u01527\ufffd  D 1, row 1 of the  sorted  cyclic  rota-  \ntions of T 0 begins with $. The character that precedes $ in T 0 is the last character \nin row 1, which is BWT \u01521\ufffd: a. Now we know that the last two characters of T 0 1002  Chapter  32  String  Matching  \nare a$. Looking up rank\u01521\ufffd, it equals 2, so that row 2 of the sorted cyclic rotations \nof T 0 begins with a. The last character in row 2 precedes a in T 0 , and  that  char-  \nacter is BWT \u01522\ufffd  D g. Now we know that the last three characters of T 0 are ga$. \nContinuing on, we have rank\u01522\ufffd  D 6, so that row 6 of the sorted cyclic rotations \nbegins with g. The character preceding g in T 0 is BWT \u01526\ufffd  D a, and so the last \nfour characters of T 0 are aga$ . Because rank\u01526\ufffd  D 4, a begins row 4 of the sorted \ncyclic rotations of T 0 . The character preceding a in T 0 is the last character in row 4, \nBWT \u01524\ufffd  D b, and  the  last  \u00fbve  characters  of T 0 are baga$ . And so on, until all n \ncharacters of T 0 have  been  identi\u00fbed,  from  back  to front.  \nb. Given  the  array  BWT \u01521 W n\ufffd, write pseudcode to compute the array rank\u01521 W n\ufffd in \n\u201a.n/  time, assuming that the alphabet size is constant. \nc. Given  the  arrays  BWT \u01521 W n\ufffd and rank\u01521 W n\ufffd, write pseudocode to compute T 0 in \n\u201a.n/  time. \nChapter  notes  \nThe  relation  of string  matching  to the  theory  of \u00fbnite  automa ta is discussed by Aho, \nHopcroft,  and  Ullman  [5].  The  Knuth-Morris-Pratt  algorithm  [267]  was  invented  \nindependently  by  Knuth  and  Pratt  and  by  Morris,  but  they  published their work \njointly.  Matiyasevich  [317]  earlier  discovered  a similar  algorithm, which applied \nonly  to an alphabet  with  two  characters  and  was  speci\u00fbed  for  a Turing machine \nwith  a two-dimensional  tape.  Reingold,  Urban,  and  Gries  [377]  give  an alterna-  \ntive  treatment  of the  Knuth-Morris-Pratt  algorithm.  The  Rabin-Karp  algorithm  \nwas  proposed  by  Karp  and  Rabin  [250].  Galil  and  Seiferas  [173]  give  an interest-  \ning  deterministic  linear-time  string-matching  algorithm  that uses only O.1/  space \nbeyond that required to store the pattern and text.  \nThe  suf\u00fbx-array  algorithm  in Section  32.5  is by  Manber  and  Myers  [312],  who  \n\u00fbrst  proposed  the  notion  of suf\u00fbx  arrays.  The  linear-time  algorithm to compute the \nlongest  common  pre\u00fbx  array  presented  here  is by  Kasai  et al.  [252].  Problem  32-2  \nis based  on  the  DC3  algorithm  by  K\u00a8  arkk\u00a8  ainen,  Sanders,  and  Burkhardt  [245].  For  \na survey  of suf\u00fbx-array  algorithms,  see  the  article  by  Pugli si, Smyth, and Turpin \n[370].  To  learn  more  about  the  Burrows-Wheeler  transform  from  Problem  32-3,  \nsee  the  articles  by  Burrows  and  Wheeler  [78]  and  Manzini  [314 ]. 33  Machine-Learning  Algorithms  \nMachine  learning  may  be viewed  as a sub\u00fbeld  of arti\u00fbcial  intelligence. Broadly \nspeaking,  arti\u00fbcial  intelligence  aims  to enable  computers  to carry  out  complex  per-  \nception  and  information-processing  tasks  with  human-like  performance.  The  \u00fbeld  \nof AI is vast and uses many different algorithmic m ethods. \nMachine learning is rich and fascinating, with stro ng ties to statistics  and  opti-  \nmization. Technology today produces enormous amount s of data,  providing  myr-  \niad  opportunities  for  machine-learning  algorithms  to form ulate and test hypotheses \nabout patterns within the data. These hypotheses ca n then be used  to make  pre-  \ndictions  about  the  characteristics  or classi\u00fbcations  in new data. Because machine \nlearning is particularly good with challenging task s involving uncertainty, where \nobserved data follows unknown rules, it has markedl y transformed  \u00fbelds  such  as \nmedicine, advertising, and speech recognition. \nThis  chapter  presents  three  important  machine-learning  algorithms: k-means  \nclustering, multiplicative weights, and gradient de scent. You can view each of \nthese tasks as a learning problem, whereby an algor ithm uses the data collected \nso far to produce a hypothesis that describes the r egularities learned and/or makes \npredictions about new data. The boundaries of machi ne learning are imprecise \nand  evolving4some  might  say  that  the  k-means  clustering  algorithm  should  be \ncalled <data science= and not <machine learning,= a nd gradient descent, though \nan immensely important algorithm for machine learni ng, also has a multitude of \napplications outside of machine learning (most nota bly for optimization problems). \nMachine learning typically starts with a training  phase  followed by a prediction  \nphase  in which predictions are made about new data. For online  learning , the \ntraining and prediction phases are intermingled. Th e training phase takes as input \ntraining  data, where each input data point has an associated out put or label ; the \nlabel  might  be a category  name  or some  real-valued  attribute . It then produces as \nan output one or more hypotheses  about how the labels depend on the attributes \nof the input data points. Hypotheses can take many forms, typically some type \nof formula or algorithm. The learning algorithm use d is often a form of gradient 1004  Chapter  33  Machine-Learning  Algorithms  \ndescent. The prediction phase then uses the hypothe sis on new data in order to \nmake predictions  regarding the labels of new data points. \nThe type of learning just described is known as supervised  learning , since it \nstarts with a set of inputs that are each labeled. As an exampl e, consider  a machine-  \nlearning algorithm to recognize spam emails. The tr aining data  comprises  a collec-  \ntion of emails, each of which is labeled either <sp am= or <not spam.=  The  machine-  \nlearning algorithm frames a hypothesis, possibly a rule of the form <if an email has \none  of a set  of words,  then  it is likely  to be spam.=  Or  it might  learn rules that \nassign a spam score to each word and then evaluates  a document by the sum of the \nspam scores of its constituent words, so that a doc ument with a total score above a \ncertain  threshold  value  is classi\u00fbed  as spam.  The  machine-l earning algorithm can \nthen predict whether a new email is spam or not. \nA second form of machine learning is unsupervised  learning , where the training \ndata  is unlabeled,  as in the  clustering  problem  of Section  33.1.  Here  the  machine-  \nlearning algorithm produces hypotheses regarding th e centers of groups of input \ndata points. \nA third form of machine learning (not covered furth er here) is reinforcement  \nlearning, where  the  machine-learning  algorithm  takes  actions  in an environment, \nreceives feedback for those actions from the enviro nment, and then updates its \nmodel of the environment based on the feedback. The  learner is in an environment \nthat has some state, and the actions of the learner  have an effect on that state. \nReinforcement learning is a natural choice for situ ations such as game playing or \noperating  a self-driving  car.  \nSometimes  the  goal  in a supervised  machine-learning  applic ation is not making \naccurate predictions of labels for new examples, bu t rather performing causal in-  \nference: \u00fbnding  an explanatory  model  that  describes  how  the  various  features of \nan input data point affect its associated label. Fi nding a model  that  \u00fbts  a given  set  \nof training data well can be tricky. It may involve  sophisticated  optimization  meth-  \nods that need to balance between producing a hypoth esis that \u00fbts  the  data  well  and  \nproducing a hypothesis that is simple. \nThis  chapter  focuses  on  three  problem  domains:  \u00fbnding  hypot heses that group \nthe input data points well (using a clustering algo rithm), learning which predictors \n(experts) to rely upon for making predictions in an  online learning problem (using \nthe  multiplicative-weights  algorithm),  and  \u00fbtting  a model  to data (using gradient \ndescent). \nSection  33.1  considers  the  clustering  problem:  how  to divid e a given set of n \ntraining data points into a given number k of groups,  or <clusters,=  based  on  a mea-  \nsure of how similar (or more accurately, how dissim ilar) points are to each other. \nThe approach is iterative, beginning with an arbitr ary initial  clustering  and  incor-  \nporating successive improvements until no further i mprovements occur. Clustering 33.1  Clustering  1005 \nis often  used  as an initial  step  when  working  on  a machine-lea rning problem to \ndiscover what structure exists in the data. \nSection  33.2  shows  how  to make  online  predictions  quite  accurately when you \nhave a set of predictors, often called <experts,= t o rely on, many of which might be \npoor  predictors,  but  some  of which  are  good  predictors.  At  \u00fbrst, you do not know \nwhich predictors are poor and which are good. The g oal is to make predictions on \nnew examples that are nearly as good as the predict ions made by the best predictor. \nWe  study  an effective  multiplicative-weights  prediction  method that associates a \npositive real weight with each predictor and multip licatively decreases the weights \nassociated with predictors when they make poor pred ictions. The model in this \nsection  is online  (see  Chapter  27):  at each  step,  we  do  not  know anything about the \nfuture examples. In addition, we are able to make p redictions even in the presence \nof adversarial experts, who are collaborating again st us, a situation that actually \nhappens  in game-playing  settings.  \nFinally,  Section  33.3  introduces  gradient  descent,  a powerful  optimization  tech-  \nnique  used  to \u00fbnd  parameter  settings  in machine-learning  models.  Gradient  descent  \nalso has many applications outside of machine learn ing. Intuitively,  gradient  de-  \nscent  \u00fbnds  the  value  that  produces  a local  minimum  for  a funct ion by <walking \ndownhill.= In a learning application, a <downhill s tep= is a step  that  adjusts  hy-  \npothesis parameters so that the hypothesis does bet ter on the given set of labeled \nexamples. \nThis chapter makes extensive use of vectors. In con trast to the rest of the book, \nvector names in this chapter appear in boldface, su ch as x, to more clearly delineate \nwhich quantities are vectors. Components of vectors  do not appear in boldface, so \nif vector x has d dimensions, we might write x D .x 1 ;x  2 ;:::;x  d /. \n33.1  Clustering  \nSuppose that you have a large number of data points  (examples), and you wish to \ngroup them into classes based on how similar they a re to each other. For example, \neach data point might represent a celestial star, g iving its temperature, size, and \nspectral  characteristics.  Or,  each  data  point  might  repres ent a fragment of recorded \nspeech.  Grouping  these  speech  fragments  appropriately  might reveal the set of \naccents  of the  fragments.  Once  a grouping  of the  training  data points is found, new \ndata can be placed into an appropriate group, facil itating star-type  recognition  or \nspeech recognition. \nThese situations, along with many others, fall unde r the umbrella of clustering. \nThe input to a clustering  problem is a set of n examples (objects) and an integer k, \nwith the goal of dividing the examples into at most  k disjoint clusters such that 1006  Chapter  33  Machine-Learning  Algorithms  \nthe examples in each cluster are similar to each ot her. The clustering problem has \nseveral variations. For example, the integer k might not be given, but instead arises \nout of the clustering procedure. In this section we  presume that k is given. \nFeature  vectors  and  similarity  \nLet\u2019s  formally  de\u00fbne  the  clustering  problem.  The  input  is a set of n examples . \nEach example has a set of attributes  in common with all other examples, though the \nattribute values may vary among examples. For examp le, the clustering problem \nshown  in Figure  33.1  clusters  n D 49  examples448  state capitals plus the District \nof Columbia4into  k D 4 clusters. Each example has two attributes: the lati tude \nand longitude of the capital. In a given clustering  problem, each example has d \nattributes, with an example x speci\u00fbed  by  a d -dimensional  feature  vector  \nx D .x 1 ;x  2 ;:::;x  d /: \nHere, x a for a D 1;2;:::;d  is a real number giving the value of attribute a for \nexample x. We call x the point  in R d representing the example. For the example \nin Figure  33.1,  each  capital  x has its latitude in x 1 and its longitude in x 2 . \nIn order  to cluster  similar  points  together,  we  need  to de\u00fbne  similarity. Instead, \nlet\u2019s  de\u00fbne  the  opposite:  the  dissimilarity  \ufffd.x; y / of points x and y is the squared \nEuclidean distance between them: \n\ufffd.x; y / D kx \ue003 y k 2 \nD d X  \naD1 .x a \ue003 y a / 2 : (33.1)  \nOf  course,  for  \ufffd.x; y / to be well  de\u00fbned,  all  attribute  values  must  be present.  If \nany are missing, then you might just ignore that ex ample, or you  could  \u00fbll  in a \nmissing attribute value with the median value for t hat attribute. \nThe attribute values are often <messy= in other way s, so that some  <data  clean-  \ning= is necessary before the clustering algorithm i s run. For example, the scale of \nattribute values can vary widely across attributes.  In the example  of Figure  33.1,  \nthe scales of the two attributes vary by a factor o f 2, since latitude ranges from \ue00390  \nto C90  degrees but longitude ranges from \ue003180  to C180  degrees.  You  can  imag-  \nine other scenarios where the differences in scales  are even greater. If the examples \ncontain information about students, one attribute m ight be grade-point  average  but  \nanother might be family income. Therefore, the attr ibute values are usually scaled \nor normalized, so that no single attribute can domi nate the others when computing \ndissimilarities.  One  way  to do  so is by  scaling  attribute  values  with  a linear  trans-  \nform so that the minimum value becomes 0 and the maximum value becomes 1. \nIf the attribute values are binary values, then no scaling may be needed. Another (j) Iteration 9: f D 1406:74 . (k) Iteration 10: f D 1395:73 . (l) Iteration 11: f D 1395:73 . \nFigure  33.1  The  iterations  of Lloyd\u2019s  procedure  when  clustering  the  capitals of the lower 48  states \nand the District of Columbia into k D 4 clusters. Each capital has two attributes: latitude  and \nlongitude. Each iteration reduces the value f , measuring the sum of squares of distances of all \ncapitals to their cluster centers, until the value of f does not change. (a)  The initial four clusters, \nwith  the  capitals  of Arkansas,  Kansas,  Louisiana,  and  Tenne ssee chosen as centers. (b)\u2013(k)  Iterations \nof Lloyd\u2019s  procedure.  (l)  The 11th iteration results in the same value of f as the 10th iteration in \npart (k), and so the procedure terminates. 33.1  Clustering  1007 \n(a) Initial clustering: f D 3659:13 . (b) Iteration 1: f D 2129:76 . (c) Iteration 2: f D 1788:67 . \n(d) Iteration 3: f D 1694:64 . (e) Iteration 4: f D 1661:55 . (f) Iteration 5: f D 1644:05 . \n(g) Iteration 6: f D 1625:42 . (h) Iteration 7: f D 1565:79 . (i) Iteration 8: f D 1494:49 . 1008  Chapter  33  Machine-Learning  Algorithms  \noption is scaling so that the values for each attri bute have mean 0 and  unit  vari-  \nance. Sometimes it makes sense to choose the same s caling rule for several related \nattributes (for example, if they are lengths measur ed to the same scale). \nAlso, the choice of dissimilarity measure is somewh at arbitrary. The use of the \nsum  of squared  differences  as in equation  (33.1)  is not  required,  but  it is a conven-  \ntional choice and mathematically convenient. For th e example of Figure  33.1,  you  \nmight use the actual distance between capitals rath er than equation  (33.1).  \nClusterings  \nWith the notion of similarity (actually, dissimilarity)  de\u00fbned,  let\u2019s  see  how  to de\u00fbne  \nclusters of similar points. Let S denote the given set of n points in R d . In some \napplications the points are not necessarily distinc t, so that S is a multiset rather \nthan a set. \nBecause the goal is to create k clusters,  we  de\u00fbne  a k-clustering  of S as a \ndecomposition of S into a sequence hS .1/  ;S  .2/  ;:::;S  .k/  i of k disjoint subsets, or \nclusters , so that \nS D S .1/  [ S .2/  [ \ue001 \ue001 \ue001 [  S .k/  : \nA cluster may be empty, for example if k >1  but all of the points in S have the \nsame attribute values. \nThere  are  many  ways  to de\u00fbne  a k-clustering  of S and many ways to evaluate \nthe quality of a given k-clustering.  We  consider  here  only  k-clusterings  of S that \nare  de\u00fbned  by  a sequence  C of k centers  \nC D hc .1/  ; c .2/  ;:::;  c .k/  i ; \nwhere each center is a point in R d , and the nearest-center  rule  says that a point x \nmay belong to cluster S .`/  if the center of no other cluster is closer to x than the \ncenter c .`/  of S .`/  : \nx 2 S .`/  only if \ufffd.x; c .`/  / D min f\ufffd.x; c .j  / / W 1 \u0dc4 j \u0dc4 kg : \nA center can be anywhere, and not necessarily a poi nt in S . \nTies are possible and must be broken so that each p oint lies in exactly one cluster. \nIn general,  ties  may  be broken  arbitrarily,  although  we\u2019ll  need the property that we \nnever change which cluster a point x is assigned to unless the distance from x to \nits new cluster center is strictly  smaller  than the distance from x to its old cluster \ncenter. That is, if the current cluster has a cente r that is one of the closest cluster \ncenters to x, then  don\u2019t  change  which  cluster  x is assigned to. \nThe k-means  problem  is then the following: given a set S of n points and a \npositive integer k, \u00fbnd  a sequence  C D hc .1/  ; c .2/  ;:::;  c .k/  i of k center points 33.1  Clustering  1009 \nminimizing the sum f.S;C/  of the squared distance from each point to its near est \ncenter, where \nf.S;C/  D X  \nx2S min f\ufffd.x; c .j  / / W 1 \u0dc4 j \u0dc4 kg \nD k X  \n`D1 X  \nx2S .`/  \ufffd.x; c .`/  /: (33.2)  \nIn the second line, the k-clustering  hS .1/  ;S  .2/  ;:::;S  .k/  i is de\u00fbned  by  the  centers  C \nand  the  nearest-center  rule.  See  Exercise  33.1-1  for  an alternative formulation \nbased on pairwise interpoint distances. \nIs there  a polynomial-time  algorithm  for  the  k-means  problem?  Probably  not,  \nbecause  it is NP-hard  [310].  As  we\u2019ll  see  in Chapter  34,  NP-ha rd problems have no \nknown  polynomial-time  algorithm,  but  nobody  has  ever  proven  that  polynomial-  \ntime  algorithms  for  NP-hard  problems  cannot  exist.  Althoug h we know of no \npolynomial-time  algorithm  that  \u00fbnds  the  global  minimum  over  all  clusterings  (ac-  \ncording  to equation  (33.2)),  we  can  \u00fbnd  a local  minimum.  \nLloyd  [304]  proposed  a simple  procedure  that  \u00fbnds  a sequence  C of k centers \nthat yields a local minimum of f.S;C/ . A local minimum in the k-means  prob-  \nlem  satis\u00fbes  two  simple  properties:  each  cluster  has  an optimal  center  (de\u00fbned  \nbelow), and each point is assigned to the cluster ( or one of the clusters) with the \nclosest  center.  Lloyd\u2019s  procedure  \u00fbnds  a good  clustering4possibly  optimal4that  \nsatis\u00fbes  these  two  properties.  These  properties  are  necessary,  but  not  suf\u00fbcient,  for  \noptimality. \nOptimal  center  for  a given  cluster  \nIn an optimal solution to the k-means  problem,  each  center  point  must  be the  \ncentroid , or mean , of the points in its cluster. The centroid is a d -dimensional  \npoint, where the value in each dimension is the mea n of the values of all the points \nin the cluster in that dimension (that is, the mean  of the corresponding  attribute  val-  \nues in the cluster). That is, if c .`/  is the centroid for cluster S .`/  , then for attributes \na D 1;2;:::;d  , we have \nc .`/  \na D 1 \njS .`/  j X  \nx2S .`/  x a : \nOver  all  attributes,  we  write  \nc .`/  D 1 \njS .`/  j X  \nx2S .`/  x : (33.3)  1010  Chapter  33  Machine-Learning  Algorithms  \nTheorem  33.1  \nGiven  a nonempty  cluster  S .`/  , its centroid (or mean) is the unique choice for t he \ncluster center c .`/  2 R d that minimizes \nX  \nx2S .`/  \ufffd.x; c .`/  /: \nProof  We wish to minimize, by choosing c .`/  2 R d , the sum \nX  \nx2S .`/  \ufffd.x; c .`/  / D X  \nx2S .`/  d X  \naD1 .x a \ue003 c .`/  \na / 2 \nD d X  \naD1 \ue001 X  \nx2S .`/  x 2 \na \ue003 2 \ue001 X  \nx2S .`/  x a ! \nc .`/  \na C \u02c7 \u02c7 S .`/  \u02c7 \u02c7 .c .`/  \na / 2 ! \n: \nFor each attribute a, the term summed is a convex quadratic function in  c .`/  \na . To \nminimize this function, take its derivative with re spect to c .`/  \na and set it to 0: \n\ue0032 X  \nx2S .`/  x a C 2 \u02c7 \u02c7 S .`/  \u02c7 \u02c7 c .`/  \na D 0 \nor, equivalently, \nc .`/  \na D 1 \njS .`/  j X  \nx2S .`/  x a : \nSince the minimum is obtained uniquely when each co ordinate of c .`/  \na is the average \nof the corresponding coordinate for x 2 S .`/  , the overall minimum is obtained \nwhen c .`/  is the centroid of the points x, as in equation  (33.3).  \nOptimal  clusters  for  given  centers  \nThe  following  theorem  shows  that  the  nearest-center  rule4a ssigning each point x \nto one of the clusters whose center is nearest to x4yields  an optimal  solution  to \nthe k-means  problem.  \nTheorem  33.2  \nGiven  a set  S of n points and a sequence hc .1/  ; c .2/  ;:::;  c .k/  i of k centers, a \nclustering hS .1/  ;S  .2/  ;:::;S  .k/  i minimizes \nk X  \n`D1 X  \nx2S .`/  \ufffd.x; c .`/  / (33.4)  \nif and only if it assigns each point x 2 S to a cluster S .`/  that minimizes \ufffd.x; c .`/  /. 33.1  Clustering  1011 \nProof  The proof is straightforward: each point x 2 S contributes exactly once to \nthe  sum  (33.4),  and  choosing  to put  x in a cluster whose center is nearest minimizes \nthe contribution from x. \nLloyd\u2019s  procedure  \nLloyd\u2019s  procedure  just  iterates  two  operations4assigning  points to clusters based \non  the  nearest-center  rule,  followed  by  recomputing  the  centers of clusters to be \ntheir  centroids4until  the  results  converge.  Here  is Lloyd\u2019  s procedure: \nInput:  A set S of points in R d , and a positive integer k. \nOutput:  A k-clustering  hS .1/  ;S  .2/  ;:::;S  .k/  i of S with a sequence of centers \nhc .1/  ; c .2/  ;:::;  c .k/  i. \n1. Initialize  centers:  Generate  an initial  sequence  hc .1/  ; c .2/  ;:::;  c .k/  i of k cen-  \nters by picking k points independently from S at random. (If the points are not \nnecessarily  distinct,  see  Exercise  33.1-3.)  Assign  all  points to cluster S .1/  to \nbegin. \n2. Assign  points  to clusters:  Use  the  nearest-center  rule  to de\u00fbne  the  clustering  \nhS .1/  ;S  .2/  ;:::;S  .k/  i. That is, assign each point x 2 S to a cluster S .`/  having \na nearest center (breaking ties arbitrarily, but no t changing the assignment for a \npoint x unless the new cluster center is strictly closer to  x than the old one). \n3. Stop  if no  change:  If step 2 did not change the assignments of any poi nts \nto clusters, then stop and return the clustering hS .1/  ;S  .2/  ;:::;S  .k/  i and the \nassociated centers hc .1/  ; c .2/  ;:::;  c .k/  i. Otherwise,  go  to step  4. \n4. Recompute  centers  as centroids:  For ` D 1;2;:::;k , compute the center c .`/  \nof cluster S .`/  as the centroid of the points in S .`/  . (If S .`/  is empty, let c .`/  be \nthe zero vector.) Then go to step 2. \nIt is possible for some of the clusters returned to  be empty, particularly if many of \nthe input points are identical. \nLloyd\u2019s  procedure  always  terminates.  By  Theorem  33.1,  recomputing  the  cen-  \nters of each cluster as the cluster centroid cannot  increase f.S;C/. Lloyd\u2019s  pro-  \ncedure ensures that a point is reassigned to a diff erent cluster only when such an \noperation strictly decreases f.S;C/. Thus  each  iteration  of Lloyd\u2019s  procedure,  \nexcept the last iteration, must strictly decrease f.S;C/ . Since there are only a \n\u00fbnite  number  of possible  k-clusterings  of S (at most k n ), the  procedure  must  ter-  \nminate.  Furthermore,  once  one  iteration  of Lloyd\u2019s  procedu re yields no decrease \nin f , further iterations would not change anything, and  the procedure can stop at \nthis locally optimum assignment of points to cluste rs. 1012  Chapter  33  Machine-Learning  Algorithms  \nIf Lloyd\u2019s  procedure  really  required  k n iterations, it would be impractical. In \npractice,  it sometimes  suf\u00fbces  to terminate  the  procedure  when  the  percentage  de-  \ncrease in f.S;C/  in the latest iteration falls below a predetermined  threshold.  Be-  \ncause  Lloyd\u2019s  procedure  is guaranteed  to \u00fbnd  only  a locally  optimal clustering, one \napproach  to \u00fbnding  a good  clustering  is to run  Lloyd\u2019s  proced ure many times with \ndifferent randomly chosen initial centers, taking t he best result. \nThe  running  time  of Lloyd\u2019s  procedure  is proportional  to the  number T of it- \nerations. In one iteration, assigning points to clu sters based  on  the  nearest-center  \nrule requires O.dkn/  time, and recomputing new centers for each cluster requires \nO.dn/  time (because each point is in one cluster). The ov erall running time of the \nk-means  procedure  is thus  O.Tdkn/ . \nLloyd\u2019s  algorithm  illustrates  an approach  common  to many  machine-learning  \nalgorithms: \n\ue001 First,  de\u00fbne  a hypothesis  space  in terms  an appropriate  sequence \u0dc2 of pa-  \nrameters, so that each \u0dc2 is associated  with  a speci\u00fbc  hypothesis  h \u0dc2 . (For the \nk-means  problem,  \u0dc2 is a dk-dimensional  vector,  equivalent  to C , containing \nthe d -dimensional  center  of each  of the  k clusters, and h \u0dc2 is the hypothesis that \neach data point x should be grouped with a cluster having a center cl osest to x.) \n\ue001 Second,  de\u00fbne  a measure  f .E; \u0dc2/  describing how poorly hypothesis h \u0dc2 \u00fbts  the  \ngiven training data E. Smaller values of f .E; \u0dc2/  are  better,  and  a (locally)  opti-  \nmal solution (locally) minimizes f .E; \u0dc2/ . (For the k-means  problem,  f .E; \u0dc2/  \nis just f.S;C/ .) \n\ue001 Third, given a set of training data E, use a suitable optimization procedure to \n\u00fbnd  a value  of \u0dc2 \ue003 that minimizes f .E; \u0dc2  \ue003 /, at least locally. (For the k-means  \nproblem, this value of \u0dc2 \ue003 is the sequence C of k center points returned by \nLloyd\u2019s  algorithm.)  \n\ue001 Return \u0dc2 \ue003 as the answer. \nIn this framework, we see that optimization becomes  a powerful tool for machine \nlearning.  Using  optimization  in this  way  is \u00fcexible.  For  example, regularization  \nterms can be incorporated in the function to be min imized, in order to penalize \nhypotheses  that  are  <too  complicated=  and  that  <over\u00fbt=  the  training  data.  (Regu-  \nlarization  is a complex  topic  that  isn\u2019t  pursued  further  here.) \nExamples  \nFigure  33.1  demonstrates  Lloyd\u2019s  procedure  on  a set  of n D 49  cities: 48  U.S. \nstate capitals and the District of Columbia. Each c ity has d D 2 dimensions: \nlatitude and longitude. The initial clustering in p art (a) of the  \u00fbgure  has  the  initial  \ncluster centers arbitrarily chosen as the capitals of Arkansas,  Kansas,  Louisiana,  33.1  Clustering  1013 \nand Tennessee. As the procedure iterates, the value  of the function f decreases, \nuntil the 11th iteration in part (l), where it remains the same  as in the 10th iteration \nin part  (k).  Lloyd\u2019s  procedure  then  terminates  with  the  clusters shown in part (l). \nAs  Figure  33.2  shows,  Lloyd\u2019s  procedure  can  also  apply  to <vector quantization.= \nHere, the goal is to reduce the number of distinct colors required to represent a \nphotograph, thereby allowing the photograph to be g reatly compressed (albeit in a \nlossy  manner).  In part  (a)  of the  \u00fbgure,  an original  photogra ph 700  pixels wide and \n500  pixels high uses 24  bits (three bytes) per pixel to encode a triple of red, green, \nand  blue  (RGB)  primary  color  intensities.  Parts  (b)3(e)  of the  \u00fbgure  show  the  \nresults  of using  Lloyd\u2019s  procedure  to compress  the  picture  from a initial space of \n2 24  possible values per pixel to a space of only k D 4, k D 16, k D 64, or k D 256  \npossible values per pixel; these k values are the cluster centers. The photograph \ncan then be represented with only 2, 4, 6, or 8 bits per pixel, respectively, instead \nof the  24-bits  per  pixel  needed  by  the  initial  photograph.  An  auxiliary table, the \n<palette,= accompanies the compressed image; it hol ds the k 24-bit  cluster  centers  \nand  is used  to map  each  pixel  value  to its  24-bit  cluster  cente r when the photo is \ndecompressed. \nExercises  \n33.1-1  \nShow that the objective function f.S;C/  of equation  (33.2)  may  be alternatively  \nwritten as \nf.S;C/  D k X  \n`D1 1 \n2 jS .`/  j X  \nx2S .`/  X  \ny2S .`/  Wx\u00a4y \ufffd.x; y /: \n33.1-2  \nGive  an example  in the  plane  with  n D 4 points and k D 2 clusters where an \niteration  of Lloyd\u2019s  procedure  does  not  improve  f.S;C/ , yet the k-clustering  is \nnot optimal. \n33.1-3  \nWhen  the  input  to Lloyd\u2019s  procedure  contains  many  repeated  points, a different \ninitialization procedure might be used. Describe a way to pick a number  of cen-  \nters at random that maximizes the number of distinc t centers picked. ( Hint: See \nExercise  5.3-5.)  \n33.1-4  \nShow  how  to \u00fbnd  an optimal  k-clustering  in polynomial  time  when  there  is just  \none attribute (d D 1). 1014  Chapter  33  Machine-Learning  Algorithms  \n(a)  Original  \n(b) k D 4 (f D 1:29  \ue005 10  9 ; 31  iterations)  (c)  k D 16  (f D 3:31  \ue005 10  8 ; 36  iterations)  \n(d) k D 64  (f D 5:50  \ue005 10  7 ; 59  iterations)  (e)  k D 256  (f D 1:52  \ue005 10  7 ; 104  iterations)  \nFigure  33.2  Using  Lloyd\u2019s  procedure  for  vector  quantization  to compres s a photo by using fewer \ncolors. (a)  The  original  photo  has  350,000  pixels  (700  \ue005 500), each a 24-bit  RGB  (red/blue/green)  \ntriple of 8-bit  values;  these  pixels  (colors)  are  the  <points=  to be clustered. Points repeat, so there \nare  only  79,083  distinct  colors  (less  than  2 24  ). After compression, only k distinct colors are used, \nso each pixel is represented by only dlg ke bits instead of 24. A <palette= maps these values back to \n24-bit  RGB  values  (the  cluster  centers).  (b)\u2013(e)  The same photo with k D 4, 16, 64, and 256  colors. \n(Photo from standuppaddle, pixabay.com.) 33.2  Multiplicative-weights  algorithms  1015 \n33.2  Multiplicative-weights  algorithms  \nThis section considers problems that require you to  make a series  of decisions.  Af-  \nter each decision you receive feedback as to whethe r your decision was correct. We \nwill study a class of algorithms that are called multiplicative-weights  algorithms . \nThis class of algorithms has a wide variety of appl ications, including game playing \nin economics,  approximately  solving  linear-programming  and  multicommodity-  \n\u00fcow  problems,  and  various  applications  in online  machine  learning. We emphasize \nthe online nature of the problem here: you have to make a sequence of decisions, \nbut some of the information needed to make the i th decision appears only after \nyou have already made the .i \ue003 1/st decision.  In this  section,  we  look  at one  par-  \nticular problem, known as <learning from experts,= and develop an example of a \nmultiplicative-weights  algorithm,  called  the  weighted-m ajority algorithm. \nSuppose that a series of events will occur, and you  want to make predictions \nabout these events. For example, over a series of d ays, you want to predict whether \nit is going  to rain.  Or  perhaps  you  want  to predict  whether  the  price of a stock will \nincrease  or decrease.  One  way  to approach  this  problem  is to assemble a group \nof <experts= and use their collective wisdom in ord er to make good predictions. \nLet\u2019s  denote  the  experts,  n of them, by E 1 ;E  2 ;:::;E  n , and  let\u2019s  say  that  T events \nare going to take place. Each event has an outcome of either 0 or 1, with o .t/  \ndenoting the outcome of the t th event. Before event t , each expert E .i/  makes \na prediction q .t/  \ni 2 f0;1g. You, as the <learner,= then take the set of n expert \npredictions for event t and produce a single prediction p .t/  2 f0;1g of your own. \nYou base your prediction only on the predictions of  the experts and anything you \nhave learned about the experts from their previous predictions. You do not use any \nadditional  information  about  the  event.  Only  after  making  your prediction do you \nascertain the outcome o .t/  of event t . If your prediction p .t/  matches o .t/  , then you \nwere correct; otherwise, you made a mistake. The go al is to minimize the total \nnumber m of mistakes, where m D P  T \nt D1 \u02c7 \u02c7 p .t/  \ue003 o .t/  \u02c7 \u02c7 . You can also keep track of \nthe number of mistakes each expert makes: expert E i makes m i mistakes, where \nm i D P  T \nt D1 \u02c7 \u02c7 q .t/  \ni \ue003 o .t/  \u02c7 \u02c7 . \nFor example, suppose that you are following the pri ce of a stock, and each day \nyou decide whether to invest in it for just that da y by buying it at the beginning of \nthe day and selling it at the end of the day. If, o n some day, you buy the stock and \nit goes up, then you made the correct decision, but  if the stock goes down, then you \nmade a mistake. Similarly, if on some day, you do n ot buy the stock and it goes \ndown, then you made the correct decision, but if th e stock goes up, then you made \na mistake. Since you would like to make as few mist akes as possible, you use the \nadvice of the experts to make your decisions. 1016  Chapter  33  Machine-Learning  Algorithms  \nWe\u2019ll  assume  nothing  about  the  movement  of the  stock.  We\u2019ll  also  assume  noth-  \ning  about  the  experts:  the  experts\u2019  predictions  could  be correlated, they could be \nchosen to deceive you, or perhaps some are not real ly experts after  all.  What  algo-  \nrithm  would  you  use?  \nBefore designing an algorithm for this problem, we need to consider what is a \nfair way to evaluate our algorithm. It is reasonabl e to expect that  our  algorithm  per-  \nforms better when the expert predictions are better , and that it performs worse when \nthe expert predictions are worse. The goal of the a lgorithm is to limit the number \nof mistakes you make to be close to the number of m istakes that the best of the \nexperts  makes.  At  \u00fbrst,  this  goal  might  seem  impossible,  because you do not know \nuntil  the  end  which  expert  is best.  We\u2019ll  see,  however,  that  by taking the advice \nprovided by all the experts into account, you can a chieve this goal. More formally, \nwe use the notion of <regret,= which compares our a lgorithm to the performance \nof the best expert (in hindsight) over all. Letting  m \ue003 D min fm i W 1 \u0dc4 i \u0dc4 ng de-  \nnote the number of mistakes made by the best expert , the regret  is m \ue003 m \ue003 . The \ngoal is to design an algorithm with low regret. (Re gret can be negative, although it \ntypically  isn\u2019t,  since  it is rare  that  you  do  better  than  the  best expert.) \nAs  a warm-up,  let\u2019s  consider  the  case  in which  one  of the  experts  makes  a cor-  \nrect prediction each time. Even without knowing who  that expert is, you can still \nachieve good results. \nLemma  33.3  \nSuppose that out of n experts, there is one who always makes the correct prediction \nfor all T events. Then there is an algorithm that makes at mo st dlg ne mistakes. \nProof  The algorithm maintains a set S consisting of experts who have not yet \nmade a mistake. Initially, S contains all n experts.  The  algorithm\u2019s  prediction  is \nalways the majority vote of the predictions of the experts remaining in set S . In \ncase of a tie, the algorithm makes any prediction. After each outcome is learned, \nset S is updated to remove all the experts who made an in correct prediction about \nthat outcome. \nWe now analyze the algorithm. The expert who always  makes the correct  pre-  \ndiction will always be in set S . Every time the algorithm makes a mistake, at leas t \nhalf of the experts who were still in S also make a mistake, and these experts are \nremoved from S . If S 0 is the set of experts remaining after removing thos e who \nmade a mistake, we have that jS 0 j \u0dc4 jS j =2. The size of S can be halved at most \ndlg ne times until jS j D  1. From this point on, we know that the algorithm ne ver \nmakes a mistake, since the set S consists only of the one expert who never makes \na mistake. Therefore, overall the algorithm makes a t most dlg ne mistakes. 33.2  Multiplicative-weights  algorithms  1017 \nExercise  33.2-1  asks  you  to generalize  this  result  to the  case when there is no \nexpert who makes perfect predictions and show that,  for any set of experts, there \nis an algorithm that makes at most m \ue003 dlg ne mistakes. The generalized algorithm \nbegins in the same way. The set S might become empty at some point, however. If \nthat ever happens, reset S to contain all the experts and continue the algorit hm. \nYou can substantially improve your prediction abili ty by not just tracking which \nexperts have not made any mistakes, or have not mad e any mistakes recently, to a \nmore nuanced evaluation of the quality of each expe rt. The key idea is to use the \nfeedback you receive to update your evaluation of h ow much trust to put in each \nexpert. As the experts make predictions, you observ e whether they were correct \nand  decrease  your  con\u00fbdence  in the  experts  who  make  more  mistakes. In this way, \nyou can learn over time which experts are more reli able and which are less reliable, \nand weight their predictions accordlingly. The chan ge in weights is accomplished \nvia multiplication, hence the term <multiplicative weights.= \nThe algorithm appears in the procedure W EIGHTED-MAJORITY  on  the  follow-  \ning page, which takes a set E D fE 1 ;E  2 ;:::;E  n g of experts, a number T of \nevents, the number n of experts, and a parameter 0<\ufffd  \u0dc4 1=2  that controls how \nthe weights change. The algorithm maintains weights  w .t/  \ni for i D 1;2;:::;n  and \nt D 1;2;:::;T  , where 0 < w  .t/  \ni \u0dc4 1. The for  loop  of lines  132  sets  the  initial  \nweights w .1/  \ni to 1, capturing the idea that with no knowledge, you tr ust each expert \nequally. Each iteration of the main for  loop  of lines  3318  does  the  following  for  \nan event t D 1;2;:::;T  . Each expert E i makes a prediction for event t in line  4. \nLines  538  compute  upweight  .t/  , the sum of the weights of the experts who predict  1 \nfor event t , and downweight .t/  , the sum of the weights of the experts who predict  0 \nfor  the  event.  Lines  9311  decide  the  algorithm\u2019s  prediction  p .t/  for event t based \non whichever weighted sum is larger (breaking ties in favor of deciding 1). The \noutcome of event t is revealed  in line  12.  Finally,  lines  14317  decrease  the  weights \nof the experts who made an incorrect prediction for  event t by multiplying their \nweights by 1 \ue003 \ufffd , leaving alone the weights of the experts who corr ectly predicted \nthe  event\u2019s  outcome.  Thus,  the  fewer  mistakes  each  expert  makes, the higher that \nexpert\u2019s  weight.  \nThe WEIGHTED-MAJORITY  procedure  doesn\u2019t  do  much  worse  than  any  expert.  \nIn particular,  it doesn\u2019t  do  much  worse  than  the  best  expert.  To quantify this claim, \nlet m .t/  be the number of mistakes made by the procedure thr ough event t , and let \nm .t/  \ni be the number of mistakes made by expert E i through event t . The following \ntheorem is the key. 1018  Chapter  33  Machine-Learning  Algorithms  \nWEIGHTED-MAJORITY  .E;T;n;\ufffd/  \n1 for  i D 1 to n \n2 w .1/  \ni D 1 / / trust each expert equally \n3 for  t D 1 to T \n4 each expert E i 2 E makes a prediction q .t/  \ni \n5 U D \u02da \nE i W q .t/  \ni D 1 \ue009 \n/ / experts who predicted 1 \n6 upweight  .t/  D P  \ni WE i 2U w .t/  \ni / / sum of weights of who predicted 1 \n7 D D \u02da \nE i W q .t/  \ni D 0 \ue009 \n/ / experts who predicted 0 \n8 downweight .t/  D P  \ni WE i 2D  w .t/  \ni / / sum of weights of who predicted 0 \n9 if upweight  .t/  \ue004 downweight .t/  \n10  p .t/  D 1 / / algorithm predicts 1 \n11  else  p .t/  D 0 / / algorithm predicts 0 \n12  outcome o .t/  is revealed \n13  / / If p .t/  \u00a4 o .t/  , the algorithm made a mistake. \n14  for  i D 1 to n \n15  if q .t/  \ni \u00a4 o .t/  / / if expert E .i/  made a mistake . . . \n16  w .t C1/  \ni D .1 \ue003 \ufffd/w  .t/  \ni / / . . . then  decrease  that  expert\u2019s  weight  \n17  else  w .t C1/  \ni D w .t/  \ni \n18  return  p .t/  \nTheorem  33.4  \nWhen running W EIGHTED-MAJORITY , we have, for every expert E i and every \nevent T 0 \u0dc4 T , \nm .T  0 / \u0dc4 2.1  C \ufffd/m  .T  0 / \ni C 2 ln n \n\ufffd : (33.5)  \nProof  Every time an expert E i makes a mistake, its weight, which is initially 1, \nis multiplied by 1 \ue003 \ufffd , and so we have \nw .t/  \ni D .1 \ue003 \ufffd/  m .t/  \ni (33.6)  \nfor t D 1;2;:::;T  . \nWe use a potential function W.t/  D P  n \ni D1 w .t/  \ni , summing the weights for all n \nexperts after iteration t of the for  loop  of lines  3318.  Initially,  we  have  W.0/  D n \nsince all n weights start out with the value 1. Because each expert belongs to either \nthe set U or the set D (de\u00fbned  in lines  5 and  7 of WEIGHTED-MAJORITY ), we \nalways have W.t/  D upweight  .t/  C downweight .t/  after  each  execution  of line  8. \nConsider an iteration t in which the algorithm makes a mistake in its predi ction, \nwhich means that either the algorithm predicts 1 and the outcome is 0 or the  al-  33.2  Multiplicative-weights  algorithms  1019 \ngorithm predicts 0 and the outcome is 1. Without loss of generality, assume that \nthe algorithm predicts 1 and the outcome is 0. The algorithm predicted 1 because \nupweight  .t/  \ue004 downweight .t/  in line 9, which implies that \nupweight  .t/  \ue004 W.t/=2:  (33.7)  \nEach expert in U then has its weight multiplied by 1 \ue003 \ufffd , and each expert in D has \nits weight unchanged. Thus, we have \nW.t  C 1/ D upweight  .t/  .1 \ue003 \ufffd/  C downweight .t/  \nD upweight  .t/  C downweight .t/  \ue003 \ufffd \ue001 upweight  .t/  \nD W.t/  \ue003 \ufffd \ue001 upweight  .t/  \n\u0dc4 W.t/  \ue003 \ufffd W.t/  \n2 (by  inequality  (33.7))  \nD W.t/.1  \ue003 \ufffd=2/  : \nTherefore, for every iteration t in which the algorithm makes a mistake, we have \nW.t  C 1/ \u0dc4 .1 \ue003 \ufffd=2/W.t/  : (33.8)  \nIn an iteration where the algorithm does not make a  mistake, some of the weights \ndecrease and some remain unchanged, so that we have  \nW.t  C 1/ \u0dc4 W.t/:  (33.9)  \nSince there are m .T  0 / mistakes made through iteration T 0 , and W.1/  D n, we \ncan  repeatedly  apply  inequality  (33.8)  to iterations  where  the algorithm makes a \nmistake  and  inequality  (33.9)  to iterations  where  the  algor ithm does not make a \nmistake, obtaining \nW.T  0 / \u0dc4 n.1  \ue003 \ufffd=2/  m .T  0 / : (33.10)  \nBecause the function W is the sum of the weights and all weights are posit ive, \nits value exceeds any single weight. Therefore, usi ng equation  (33.6)  we  have,  for  \nany expert E i and for any iteration T 0 \u0dc4 T , \nW.T  0 / \ue004 w .T  0 / \ni D .1 \ue003 \ufffd/  m .T  0 / \ni : (33.11)  \nCombining  inequalities  (33.10)  and  (33.11)  gives  \n.1 \ue003 \ufffd/  m .T  0 / \ni \u0dc4 n.1  \ue003 \ufffd=2/  m .T  0 / : \nTaking the natural logarithm of both sides yields \nm .T  0 / \ni ln.1 \ue003 \ufffd/  \u0dc4 m .T  0 / ln.1 \ue003 \ufffd=2/  C ln n:  (33.12)  1020  Chapter  33  Machine-Learning  Algorithms  \nWe now use the Taylor series expansion to derive up per and lower bounds on the \nlogarithmic  factors  in inequality  (33.12).  The  Taylor  series for ln.1 C x/  is given in \nequation  (3.22)  on  page  67.  Substituting  \ue003x for x , we have that for 0<x  \u0dc4 1=2, \nln.1 \ue003 x/  D \ue003x \ue003 x 2 \n2 \ue003 x 3 \n3 \ue003 x 4 \n4 \ue003 \ue001 \ue001 \ue001  : (33.13)  \nSince  each  term  on  the  right-hand  side  is negative,  we  can  drop all terms except the \n\u00fbrst  and  obtain  an upper  bound  of ln.1 \ue003 x/  \u0dc4 \ue003x . Since 0<\ufffd  \u0dc4 1=2, we have \nln.1 \ue003 \ufffd=2/  \u0dc4 \ue003\ufffd=2  : (33.14)  \nFor  the  lower  bound,  Exercise  33.2-2  asks  you  to show  that  ln.1 \ue003 x/  \ue004 \ue003x \ue003 x 2 \nwhen 0<x  \u0dc4 1=2, so that \n\ue003\ufffd \ue003 \ufffd 2 \u0dc4 ln.1 \ue003 \ufffd/:  (33.15)  \nThus, we have \nm .T  0 / \ni .\ue003\ufffd \ue003 \ufffd 2 / \u0dc4 m .T  0 / \ni ln.1 \ue003 \ufffd/  (by  inequality  (33.15))  \n\u0dc4 m .T  0 / ln.1 \ue003 \ufffd=2/  C ln n (by  inequality  (33.12)  \n\u0dc4 m .T  0 / .\ue003\ufffd=2/  C ln n (by  inequality  (33.14))  , \nso that \nm .T  0 / \ni .\ue003\ufffd \ue003 \ufffd 2 / \u0dc4 m .T  0 / .\ue003\ufffd=2/  C ln n:  (33.16)  \nSubtracting ln n from  both  sides  of inequality  (33.16)  and  then  multiplying  both \nsides by \ue0032=\ufffd  yields m .T  0 / \u0dc4 2.1  C \ufffd/m  .T  0 / \ni C .2 ln n/=\ufffd  , thus  proving  the  theo-  \nrem. \nTheorem  33.4  applies  to any  expert  and  any  event  T 0 \u0dc4 T . In particular, we \ncan compare against the best expert after all event s have occurred, producing the \nfollowing corollary. \nCorollary  33.5  \nAt the end of procedure W EIGHTED-MAJORITY , we have \nm .T  / \u0dc4 2.1  C \ufffd/m  \ue003 C 2 ln n \n\ufffd : (33.17)  \nLet\u2019s  explore  this  bound.  Assuming  that  p \nln n=m  \ue003 \u0dc4 1=2, we can choose \n\ufffd D p \nln n=m  \ue003 and  plug  into  inequality  (33.17)  to obtain  33.2  Multiplicative-weights  algorithms  1021 \nm .T  / \u0dc4 2 \ue001 \n1 C r  \nln n \nm \ue003 ! \nm \ue003 C 2 ln n p \nln n=m  \ue003 \nD 2m  \ue003 C 2 p \nm \ue003 ln n C 2 p \nm \ue003 ln n \nD 2m  \ue003 C 4 p \nm \ue003 ln n;  \nand so the number of errors is at most twice the nu mber of errors made by the \nbest expert plus a term that is often slower growin g than m \ue003 . Exercise  33.2-4  \nshows that you can decrease the bound on the number  of errors by a factor of 2 by \nusing randomization, which leads to much stronger b ounds. In particular, the upper \nbound on regret ( m \ue003 m \ue003 ) is reduced from .1 C 2\ufffd/m  \ue003 C .2 ln n/=\ufffd  to an expected \nvalue of \ufffdm  \ue003 C .ln n/=\ufffd  , where both \ufffd and \ufffd are at most 1=2. Numerically, we can \nsee that if \ufffd D 1=2, WEIGHTED-MAJORITY  makes at most 3 times the number \nof errors as the best expert, plus 4 ln n errors. As another example, suppose that \nT D 1000  predictions are being made by n D 20  experts, and the best expert is \ncorrect 95% of the time, making 50  errors. Then W EIGHTED-MAJORITY  makes at \nmost 100.1 C\ufffd/C2 ln 20=\ufffd  errors. By choosing \ufffd D 1=4, WEIGHTED-MAJORITY  \nmakes at most 149  errors, or a success rate of at least 85%. \nMultiplicative weights methods typically refer to a  broader class of algorithms \nthat includes W EIGHTED-MAJORITY . The outcomes and predictions need not be \nonly 0 or 1, but can be real numbers, and there can be a loss associated with a \nparticular outcome and prediction. The weights can be updated by a multiplicative \nfactor that depends on the loss, and the algorithm can, given a set of weights, treat \nthem as a distribution on experts and use them to c hoose an expert to follow in each \nevent. Even in these more general settings, bounds similar to Theorem  33.4  hold.  \nExercises  \n33.2-1  \nThe  proof  of Lemma  33.3  assumes  that  some  expert  never  makes  a mistake. It is \npossible to generalize the algorithm and analysis t o remove this assumption. The \nnew algorithm begins in the same way. The set S might become empty at some \npoint, however. If that ever happens, reset S to contain all the experts and continue \nthe algorithm. Show that the number of mistakes tha t this algorithm makes is at \nmost m \ue003 dlg ne. \n33.2-2  \nShow that ln.1 \ue003 x/  \ue004 \ue003x \ue003 x 2 when 0 < x  \u0dc4 1=2. (Hint: Start  with  equa-  \ntion  (33.13),  group  all  the  terms  after  the  \u00fbrst  three,  and  use  equation  (A.7)  on  \npage  1142.)  1022  Chapter  33  Machine-Learning  Algorithms  \n33.2-3  \nConsider a randomized variant of the algorithm give n in the proof  of Lemma  33.3,  \nin which some expert never makes a mistake. At each  step, choose an expert E i \nuniformly at random from the set S and then make the same predication as E i . \nShow that the expected number of mistakes made by t his algorithm is dlg ne. \n33.2-4  \nConsider a randomized version of W EIGHTED-MAJORITY . The algorithm is the \nsame, except for the prediction step, which interpr ets the weights as a probability \ndistribution over the experts and chooses an expert  E i according  to that  distri-  \nbution. It then chooses its prediction to be the sa me as the prediction made by \nexpert E i . Show that, for any 0<\ufffd<1=2 , the expected number of mistakes made \nby this algorithm is at most .1 C \ufffd/m  \ue003 C .ln n/=\ufffd  . \n33.3  Gradient  descent  \nSuppose that you have a set fp 1 ;p  2 ;:::;p  n g of points  and  you  want  to \u00fbnd  the  \nline  that  best  \u00fbts  these  points.  For  any  line  `, there is a distance d i between each \npoint p i and  the  line.  You  want  to \u00fbnd  the  line  that  minimizes  some  function \nf.d  1 ;:::;d  n /. There  are  many  possible  choices  for  the  de\u00fbnition  of distan ce and \nfor the function f . For example, the distance can be the projection d istance to the \nline and the function can be the sum of the squares  of the distances. This type of \nproblem  is common  in data  science  and  machine  learning4the  line  is the  hypoth-  \nesis  that  best  describes  the  data4where  the  particular  de\u00fbnition  of best  is deter-  \nmined  by  the  de\u00fbnition  of distance  and  the  objective  f . If the  de\u00fbnition  of distance  \nand the function f are  linear,  then  we  have  a linear-programming  problem,  as dis-  \ncussed  in Chapter  29.  Although  the  linear-programming  framework  captures  sev-  \neral important problems, many other problems, inclu ding various  machine-learning  \nproblems, have objectives and constraints that are not necessarily linear. We need \nframeworks and algorithms to solve such problems. \nIn this section, we consider the problem of optimiz ing a continuous function \nand discuss one of the most popular methods to do s o: gradient descent.  Gra-  \ndient  descent  is a general  method  for  \u00fbnding  a local  minimum  of a function \nf W R n !  R, where informally, a local minimum of a function f is a point x \nfor which f.x/ \u0dc4 f.x 0 / for all x 0 that are <near= x. When  the  function  is con-  \nvex,  it can  \u00fbnd  a point  near  the  global  minimizer  of f : an n-vector  argument  \nx D .x 1 ;x  2 ;:::;x  n / such that f.x/ is minimum. For the intuitive idea behind \ngradient descent, imagine being in a landscape of h ills and valleys, and wanting \nto get to a low point as quickly as possible. You s urvey the terrain and choose to 33.3  Gradient  descent  1023 \nmove in the direction that takes you downhill the f astest from your current position. \nYou move in that direction, but only for a short wh ile, because as you proceed, the \nterrain changes and you might need to choose a diff erent direction. So you stop, \nreevaluate the possible directions and move another  short distance in the steepest \ndownhill direction, which might differ from the dir ection of your  previous  move-  \nment. You continue this process until you reach a p oint from which all directions \nlead up. Such a point is a local minimum. \nIn order to make this informal procedure more forma l, we need to de\u00fbne  the  \ngradient of a function, which in the analogy above is a measure of the steepness of \nthe  various  directions.  Given  a function  f W R n !  R, its gradient  r f is a function \nr f W R n !  R n comprising n partial derivatives: .r f/.x/ D \u00e3 @f  \n@x  1 ; @f  \n@x  2 ;:::;  @f  \n@x  n \u00e4 . \nAnalogous to the derivative of a function of a sing le variable, the gradient can be \nviewed as a direction in which the function value l ocally increases the fastest, and \nthe rate of that increase. This view is informal; i n order to make it formal we would \nhave  to de\u00fbne  what  local  means  and  place  certain  conditions,  such as continuity or \nexistence of derivatives, on the function. Neverthe less, this view motivates the \nkey  step  of gradient  descent4move  in the  direction  opposite  to the gradient, by a \ndistance  in\u00fcuenced  by  the  magnitude  of the  gradient.  \nThe general procedure of gradient descent proceeds in steps. You start at some \ninitial point x .0/  , which is an n-vector.  At  each  step  t , you compute the value of \nthe gradient of f at point x .t/  , that is, .r f/.x .t/  ), which is also an n-vector.  You  \nthen move in the direction opposite to the gradient  in each dimension at x .t/  to \narrive at the next point x .t C1/  , which again is an n-vector.  Because  you  moved  \nin a monotonically decreasing direction in each dim ension, you should have that \nf.x .t C1/  / \u0dc4 f.x .t/  /. Several details are needed to turn this idea into  an actual \nalgorithm. The two main details are that you need a n initial point and that you \nneed to decide how far to move in the direction of the negative gradient. You also \nneed to understand when to stop and what you can co nclude about the quality of \nthe solution found. We will explore these issues fu rther in this section, for both \nconstrained minimization, where there are additiona l constraints on the points, and \nunconstrained minimization, where there are none. \nUnconstrained  gradient  descent  \nIn order  to gain  intuition,  let\u2019s  consider  unconstrained  gradient descent in just one \ndimension, that is, when f is a function of a scalar x , so that f W R !  R. In \nthis case, the gradient r f of f is just f 0 .x/, the derivative of f with respect \nto x . Consider the function f shown  in blue  in Figure  33.3,  with  minimizer  x \ue003 \nand starting point x .0/  . The gradient (derivative) f 0 .x .0/  /, shown in orange, has a \nnegative slope, so that a small step from x .0/  in the direction of increasing x results \nin a point x 0 for which f.x  0 / < f.x  .0/  /. Too large a step, however, results in a 1024  Chapter  33  Machine-Learning  Algorithms  \nx .0/  x 0 x 00 y x x \ue003 \nFigure  33.3  A function f W R !  R, shown in blue. Its gradient at point x .0/  , in orange, has \na negative slope, and so a small increase in x from x .0/  to x 0 results in f.x  0 / < f.x  .0/  /. Small \nincreases in x from x .0/  head toward y x, which gives a local minimum. Too large an increas e in x \ncan end up at x 00 , where f.x  00 / > f.x  .0/  /. Small steps starting from x .0/  and going only in the \ndirection of decreasing values of f cannot end up at the global minimizer x \ue003 . \npoint x 00 for which f.x  00 />f.x  .0/  /, so this is a bad idea. Restricting ourselves to \nsmall steps, where each one has f.x  0 /<f.x/ , eventually results in getting close \nto point y x, which gives a local minimum. By taking only small  downhill steps, \nhowever, gradient descent has no chance to get to t he global minimizer x \ue003 , given \nthe starting point x .0/  . \nWe draw two observations from this simple example. First, gradient descent \nconverges toward a local minimum, and not necessari ly a global minimum.  Sec-  \nond, the speed at which it converges and how it beh aves are related to properties of \nthe function, to the initial point, and to the step  size of the algorithm. \nThe  procedure  GRADIENT-DESCENT on  the  facing  page  takes  as input  a func-  \ntion f , an initial point x .0/  2 R n , a \u00fbxed  step-size  multiplier  \ufffd >0, and  a num-  \nber T >0  of steps to take. Each iteration of the for  loop  of lines  234  performs  a \nstep by computing the n-dimensional  gradient  at point  x .t/  and  then  moving  dis-  \ntance \ufffd in the opposite direction in the n-dimensional  space.  The  complexity  of \ncomputing the gradient depends on the function f and  can  sometimes  be expen-  \nsive.  Line  3 sums  the  points  visited.  After  the  loop  terminates,  line  6 returns  x-avg , \nthe average of all the points visited except for th e last one, x .T  / . It might seem more \nnatural to return x .T  / , and in fact, in many circumstances, you might pre fer to have \nthe function return x .T  / . For the version we will analyze, however, we use x-avg . 33.3  Gradient  descent  1025 \nGRADIENT-DESCENT .f;  x .0/  ;\ufffd;T/  \n1 sum  D 0 / / n-dimensional  vector,  initially  all  0 \n2 for  t D 0 to T \ue003 1 \n3 sum  D sum  C x .t/  / / add each of n dimensions into sum  \n4 x .t C1/  D x .t/  \ue003 \ufffd \ue001 .r f/.x .t/  / / / .r f/.x .t/  /, x .t C1/  are n-dimensional  \n5 x-avg  D sum=T  / / divide each of n dimensions by T \n6 return  x-avg  \nFigure  33.4  depicts  how  gradient  descent  ideally  runs  on  a convex 1-dimensional  \nfunction. 1 We\u2019ll  de\u00fbne  convexity  more  formally  below,  but  the  \u00fbgure  shows that \neach iteration moves in the direction opposite to t he gradient, with the distance \nmoved being proportional to the magnitude of the gr adient. As the  iterations  pro-  \nceed, the magnitude of the gradient decreases, and thus the distance moved along \nthe horizontal axis decreases. After each iteration , the distance to the optimal \npoint x \ue003 decreases. This ideal behavior is not guaranteed to  occur in general, but \nthe analysis in the remainder of this section forma lizes when this behavior occurs \nand  quanti\u00fbes  the  number  of iterations  needed.  Gradient  descent does not always \nwork, however. We have already seen that if the func tion is not convex, gradient \ndescent can converge to a local, rather than global , minimum. We have also seen \nthat  if the  step  size  is too  large,  GRADIENT-DESCENT can overshoot the minimum \nand wind up farther away. (It is also possible to o vershoot the minimum and wind \nup closer to the optimum.) \nAnalysis  of unconstrained  gradient  descent  for  convex  functions  \nOur  analysis  of gradient  descent  focuses  on  convex  function s. Inequality (C.29) on \npage  1194  de\u00fbnes  a convex  function  of one  variable,  as shown  in Figure  33.5.  We  \ncan  extend  that  de\u00fbnition  to a function  f W R n !  R and say that f is convex  if \nfor all x; y 2 R n and for all 0 \u0dc4 \ufffd \u0dc4 1, we have \nf.\ufffdx C .1 \ue003 \ufffd/y / \u0dc4 \ufffdf  .x/ C .1 \ue003 \ufffd/f  .y /: (33.18)  \n(Inequalities  (33.18)  and  (C.29)  are  the  same,  except  for  the dimensions of x \nand y .) We also assume that our convex functions are clo sed 2 and differentiable. \n1 Although  the  curve  in Figure  33.4  looks  concave,  according  to the  de\u00fbnition  of convexity  that  we\u2019ll  \nsee below, the function f in the  \u00fbgure  is convex.  \n2 A function f W R n !  R is closed if, for each \u02db 2 R, the set fx 2 dom.f/  W f.x/ \u0dc4 \u02dbg is closed, \nwhere dom.f/  is the domain of f . 1026  Chapter  33  Machine-Learning  Algorithms  \nx \ue003 x .0/  x .1/  x .2/  x .3/  x .4/  \ue003\ufffd \ue001 .r f/.x .0/  / \n\ue003\ufffd \ue001 .r f/.x .1/  / \n\ue003\ufffd \ue001 .r f/.x .2/  / \n\ue003\ufffd \ue001 .r f/.x .3/  / \nFigure  33.4  An example of running gradient descent on a convex function f W R !  R, shown in \nblue. Beginning at point x .0/  , each iteration moves in the direction opposite to  the gradient, and the \ndistance moved is proportional to the magnitude of the gradient.  Orange  lines  represent  the  negative  \nof the gradient at each point, scaled by the step s ize \ufffd . As the iterations proceed, the magnitude of \nthe gradient decreases, and the distance moved decr eases correspondingly. After each iteration, the \ndistance to the optimal point x \ue003 decreases. \nx y x \ue003 f.x/ \nf.y / \n\ufffdx C .1 \ue003 \ufffd/y f.\ufffdx C .1 \ue003 \ufffd/y / \ufffdf  .x/ C .1 \ue003 \ufffd/f  .y / \nFigure  33.5  A convex function f W R !  R, shown in blue, with local and global minimizer x \ue003 . \nBecause f is convex, f.\ufffdx C .1 \ue003 \ufffd/y / \u0dc4 \ufffdf  .x/ C .1 \ue003 \ufffd/f  .y / for any two values x and y and \nall 0 \u0dc4 \ufffd \u0dc4 1, shown for a particular value of \ufffd. Here, the orange line segment represents all valu es \n\ufffdf  .x/ C .1 \ue003 \ufffd/f  .y / for 0 \u0dc4 \ufffd \u0dc4 1, and it is above the blue line. \nA convex function has the property that any local m inimum is also a global \nminimum.  To  verify  this  property,  consider  inequality  (33.18),  and  suppose  for  the  \npurpose of contradiction that x is a local minimum but not a global minimum and \ny \u00a4 x is a global minimum, so f.y /<f. x/. Then we have \nf.\ufffdx C .1 \ue003 \ufffd/y / \u0dc4 \ufffdf  .x/ C .1 \ue003 \ufffd/f  .y / (by  inequality  (33.18))  \n< \ufffdf.x/ C .1 \ue003 \ufffd/f  .x/ \nD f.x/: 33.3  Gradient  descent  1027 \nThus, letting \ufffd approach 1, we see that there is another point near x, say x 0 , such \nthat f.x 0 /<f. x/, so x is not a local minimum. \nConvex  functions  have  several  useful  properties.  The  \u00fbrst  property, whose proof \nwe  leave  as Exercise  33.3-1,  says  that  a convex  function  always  lies  above  its  tan-  \ngent hyperplane. In the context of gradient descent , angle brackets denote the \nnotation  for  inner  product  de\u00fbned  on  page  1219  rather  than  denoting a sequence. \nLemma  33.6  \nFor any convex differentiable function f W R n !  R and for all x;y  2 R n , we have \nf.x/ \u0dc4 f.y / C h.r f/.x/; x \ue003 y i. \nThe  second  property,  which  Exercise  33.3-2  asks  you  to prove , is a repeated \napplication  of the  de\u00fbnition  of convexity  in inequality  (33.18).  \nLemma  33.7  \nFor any convex function f W R n !  R, for any integer T \ue004 1, and for all \nx .0/  ;:::;  x .T  \ue0021/  2 R n , we have \nf \u00ce x .0/  C \ue001 \ue001 \ue001 C  x .T  \ue0021/  \nT \u00cf \n\u0dc4 f.x .0/  / C \ue001 \ue001 \ue001 C  f.x .T  \ue0021/  / \nT : (33.19)  \nThe  left-hand  side  of inequality  (33.19)  is the  value  of f at the vector x-avg  that \nGRADIENT-DESCENT returns. \nWe  now  proceed  to analyze  GRADIENT-DESCENT . It might not return the exact \nglobal minimizer x \ue003 . We use an error bound \ufffd , and we want to choose T so that \nf.x-avg/ \ue003 f.x \ue003 / \u0dc4 \ufffd at termination. The value of \ufffd depends on the number T of \niterations and two additional values. First, since you expect it to be better to start \nclose to the global minimizer, \ufffd is a function of \nR D kx .0/  \ue003 x \ue003 k ; (33.20)  \nthe  euclidean  norm  (or  distance,  de\u00fbned  on  page  1219)  of the  difference between \nx .0/  and x \ue003 . The error bound \ufffd is also a function of a quantity we call L, which is \nan upper bound on the magnitude k.r f/.x/k of the gradient, so that \nk.r f/.x/k \u0dc4  L;  (33.21)  \nwhere x ranges over all the points x .0/  ;:::;  x .T  \ue0021/  whose gradients are computed \nby  GRADIENT-DESCENT. Of  course,  we  don\u2019t  know  the  values  of L and R, but for \nnow  let\u2019s  assume  that  we  do.  We\u2019ll  discuss  later  how  to remove  these assumptions. \nThe  analysis  of GRADIENT-DESCENT is summarized in the following theorem. 1028  Chapter  33  Machine-Learning  Algorithms  \nTheorem  33.8  \nLet x \ue003 2 R n be the minimizer of a convex function f , and  suppose  that  an execu-  \ntion  of GRADIENT-DESCENT .f;  x .0/  ;\ufffd;T/  returns x-avg , where \ufffd D R=.L  p \nT/  \nand R and L are  de\u00fbned  in equations  (33.20)  and  (33.21).  Let  \ufffd D RL=  p \nT . Then \nwe have f.x-avg/ \ue003 f.x \ue003 / \u0dc4 \ufffd . \nWe now prove this theorem. We do not give an absolu te bound on how much \nprogress each iteration makes. Instead, we use a po tential function,  as in Sec-  \ntion  16.3.  Here,  we  de\u00fbne  a potential  \u02c6.t/  after computing x .t/  , such that \u02c6.t/  \ue004 0 \nfor t D 0;:::;T  . We  de\u00fbne  the  amortized  progress  in the  iteration  that  com-  \nputes x .t/  as \np.t/  D f.x .t/  / \ue003 f.x \ue003 / C \u02c6.t  C 1/ \ue003 \u02c6.t/:  (33.22)  \nAlong with including the change in potential ( \u02c6.t  C 1/ \ue003 \u02c6.t/), equation  (33.22)  \nalso subtracts the minimum value f.x \ue003 / because ultimately, you care not about the \nvalues f.x .t/  / but about how close they are to f.x \ue003 /. Suppose that we can show \nthat p.t/  \u0dc4 B for some value B and t D 0;:::;T  \ue003 1. Then we can substitute \nfor p.t/  using  equation  (33.22),  giving  \nf.x .t/  / \ue003 f.x \ue003 / \u0dc4 B \ue003 \u02c6.t  C 1/ C \u02c6.t/:  (33.23)  \nSumming  inequality  (33.23)  over  t D 0;:::;T  \ue003 1 yields \nT \ue0021 X  \nt D0 .f.x .t/  / \ue003 f.x \ue003 // \u0dc4 T \ue0021 X  \nt D0 .B  \ue003 \u02c6.t  C 1/ C \u02c6.t//:  \nObserving  that  we  have  a telescoping  series  on  the  right  and  regrouping terms, we \nhave that \ue001 T \ue0021 X  \nt D0 f.x .t/  / ! \n\ue003 T \ue001 f.x \ue003 / \u0dc4 TB  \ue003 \u02c6.T/  C \u02c6.0/:  \nDividing by T and dropping the positive term \u02c6.T/  gives \nP  T \ue0021 \nt D0 f.x .t/  / \nT \ue003 f.x \ue003 / \u0dc4 B C \u02c6.0/  \nT ; (33.24)  \nand thus we have \nf.x-avg/ \ue003 f.x \ue003 / D f \u00ceP  T \ue0021 \nt D0 x .t/  \nT \u00cf \n\ue003 f.x \ue003 / (by  the  de\u00fbnition  of x-avg ) \n\u0dc4 P  T \ue0021 \nt D0 f.x .t/  / \nT \ue003 f.x \ue003 / (by  Lemma  33.7)  \n\u0dc4 B C \u02c6.0/  \nT (by  inequality  (33.24))  . (33.25)  33.3  Gradient  descent  1029 \nIn other words, if we can show that p.t/  \u0dc4 B for some value B and choose a \npotential function where \u02c6.0/  is not  too  large,  then  inequality  (33.25)  tells  us how  \nclose the function value f.x-avg/ is to the function value f.x \ue003 / after T iterations. \nThat is, we can set the error bound \ufffd to B C \u02c6.0/=T  . \nIn order to bound the amortized progress, we need t o come up with a concrete \npotential  function.  De\u00fbne  the  potential  function  \u02c6.t/  by \n\u02c6.t/  D \ue011 \ue011 x .t/  \ue003 x \ue003 \ue011 \ue011 2 \n2\ufffd  ; (33.26)  \nthat is, the potential function is proportional to the square of the distance between \nthe current point and the minimizer x \ue003 . With this potential function in hand, the \nnext lemma provides a bound on the amortized progre ss made in any iteration of \nGRADIENT-DESCENT . \nLemma  33.9  \nLet x \ue003 2 R n be the minimizer of a convex function f , and consider an execution \nof GRADIENT-DESCENT.f;  x .0/  ; \ufffd; T / . Then for each point x .t/  computed by the \nprocedure, we have that \np.t/  D f.x .t/  / \ue003 f.x \ue003 / C \u02c6.t  C 1/ \ue003 \u02c6.t/  \u0dc4 \ufffdL  2 \n2 : \nProof  We  \u00fbrst  bound  the  potential  change  \u02c6.t  C 1/ \ue003 \u02c6.t/. Using  the  de\u00fbnition  \nof \u02c6.t/  from  equation  (33.26),  we  have  \n\u02c6.t  C 1/ \ue003 \u02c6.t/  D 1 \n2\ufffd  \ue011 \ue011 x .t C1/  \ue003 x \ue003 \ue011 \ue011 2 \ue003 1 \n2\ufffd  \ue011 \ue011 x .t/  \ue003 x \ue003 \ue011 \ue011 2 : (33.27)  \nFrom  line  4 in GRADIENT-DESCENT , we know that \nx .t C1/  \ue003 x .t/  D \ue003\ufffd \ue001 .r f/.x .t/  /; (33.28)  \nand  so we  would  like  to rewrite  equation  (33.27)  to have  x .t C1/  \ue003 x .t/  terms. As \nExercise  33.3-3  asks  you  to prove,  for  any  two  vectors  a; b 2 R n , we have \nka C bk 2 \ue003 kak 2 D 2hb; ai C kbk 2 : (33.29)  \nLetting a D x .t/  \ue003 x \ue003 and b D x .t C1/  \ue003 x .t/  , we  can  write  the  right-hand  side  \nof equation  (33.27)  as 1 \n2\ue002  \u00e3 \nka C bk 2 \ue003 kak 2 \u00e4 \n. Then we can express the potential \nchange as 1030  Chapter  33  Machine-Learning  Algorithms  \n\u02c6.t  C 1/ \ue003 \u02c6.t/  \nD 1 \n2\ufffd  \ue011 \ue011 x .t C1/  \ue003 x \ue003 \ue011 \ue011 2 \ue003 1 \n2\ufffd  \ue011 \ue011 x .t/  \ue003 x \ue003 \ue011 \ue011 2 (by  equation  (33.27))  \nD 1 \n2\ufffd  \ue002 \n2hx .t C1/  \ue003 x .t/  ; x .t/  \ue003 x \ue003 i C  \ue011 \ue011 x .t C1/  \ue003 x .t/  \ue011 \ue011 2 \u00cd \n(by  equation  (33.29))  \nD 1 \n2\ufffd  \ue002 \n2h\ue003\ufffd \ue001 .r f/.x .t/  /; x .t/  \ue003 x \ue003 i C  \ue011 \ue011 \ue003\ufffd \ue001 .r f/.x .t/  / \ue011 \ue011 2 \u00cd \n(by  equation  (33.28))  \nD \ue003h.r f/.x .t/  /; x .t/  \ue003 x \ue003 i C  \ufffd \n2 \ue011 \ue011 .r f/.x .t/  / \ue011 \ue011 2 (33.30)  \n(by  equation  (D.3)  on  page  1219)  \n\u0dc4 \ue003.f.x .t/  / \ue003 f.x \ue003 // C \ufffd \n2 \ue011 \ue011 .r f/.x .t/  / \ue011 \ue011 2 (by  Lemma  33.6)  , \nand thus we have \n\u02c6.t  C 1/ \ue003 \u02c6.t/  \u0dc4 \ue003.f.x .t/  / \ue003 f.x \ue003 // C \ufffd \n2 \ue011 \ue011 .r f/.x .t/  / \ue011 \ue011 2 (33.31)  \nWe can now proceed to bound p.t/. By the bound on the potential change from \ninequality  (33.31),  and  using  the  de\u00fbnition  of L (inequality  (33.21)),  we  have  \np.t/  D f.x .t/  / \ue003 f.x \ue003 / C \u02c6.t  C 1/ \ue003 \u02c6.t/  (by  equation  (33.22))  \n\u0dc4 f.x .t/  / \ue003 f.x \ue003 / \ue003 .f.x .t/  / \ue003 f.x \ue003 // C \ufffd \n2 \ue011 \ue011 .r f/.x .t/  / \ue011 \ue011 2 \n(by  inequality  (33.31))  \nD \ufffd \n2 \ue011 \ue011 .r f/.x .t/  / \ue011 \ue011 2 \n\u0dc4 \ufffdL  2 \n2 (by  inequality  (33.21))  . \nHaving bounded the amortized progress in one step, we now analyze the entire \nGRADIENT-DESCENT procedure,  completing  the  proof  of Theorem  33.8.  \nProof  of Theorem  33.8  Inequality  (33.25)  tells  us that  if we  have  an upper  bound  \nof B for p.t/, then we also have the bound f.x-avg/ \ue003 f.x \ue003 / \u0dc4 B C \u02c6.0/=T  . By \nequations  (33.20)  and  (33.26),  we  have  that  \u02c6.0/  D R 2 =.2\ufffd/. Lemma  33.9  gives  \nus the upper bound of B D \ufffdL  2 =2, and so we have \nf.x-avg/ \ue003 f.x \ue003 / \u0dc4 B C \u02c6.0/  \nT (by  inequality  (33.25))  \nD \ufffdL  2 \n2 C R 2 \n2\ufffdT  : 33.3  Gradient  descent  1031 \nOur  choice  of \ufffd D R=.L  p \nT/  in the  statement  of Theorem  33.8  balances  the  two  \nterms, and we obtain \n\ufffdL  2 \n2 C R 2 \n2\ufffdT  D R \nL p \nT \ue001 L 2 \n2 C R 2 \n2T  \ue001 L p \nT \nR \nD RL  \n2 p \nT C RL  \n2 p \nT \nD RL  p \nT : \nSince we chose \ufffd D RL=  p \nT in the theorem statement, the proof is complete. \nContinuing under the assumption that we know R (from  equation  (33.20))  and  L \n(from  inequality  (33.21)),  we  can  think  of the  analysis  in a slightly different way. \nWe can presume that we have a target accuracy \ufffd and  then  compute  the  num-  \nber of iterations needed. That is, we can solve \ufffd D RL=  p \nT for T , obtaining \nT D R 2 L 2 =\ufffd 2 . The number of iterations thus depends on the squa re of R and L \nand, most importantly, on 1=\ufffd  2 . (The  de\u00fbnition  of L from  inequality  (33.21)  de-  \npends on T , but we may know an upper bound on L that  doesn\u2019t  depend  on  the  \nparticular value of T .) Thus, if you want to halve your error bound, you  need to \nrun four times as many iterations. \nIt is quite  possible  that  we  don\u2019t  really  know  R and L, since  you\u2019d  need  to \nknow x \ue003 in order to know R (since R D kx .0/  \ue003 x \ue003 k), and you might not have an \nexplicit upper bound on the gradient, which would p rovide L. You can, however, \ninterpret the analysis of gradient descent as a pro of that there is some step size for \nwhich the procedure makes progress toward the minim um. You can then compute \na step size \ufffd for which f.x .t/  / \ue003 f.x .t C1/  / is large enough. In fact, not having a \n\u00fbxed  step  size  multiplier  can  actually  help  in practice,  as you are free to use any \nstep size s that  achieves  suf\u00fbcient  decrease  in the  value  of f . You can search for \na step  size  that  achieves  a large  decrease  via  a binary-search-like  routine,  which  is \noften called line  search . For a given function f and step size s , de\u00fbne  the  func-  \ntion g.x .t/  ;s/  D f.x .t/  / \ue003 s.r f/.x .t/  /. Start with a small step size s for which \ng.x .t/  ;s/  \u0dc4 f.x .t/  /. Then repeatedly double s until g.x .t/  ;2s/  \ue004 g.x .t/  ;s/, and \nthen perform a binary search in the interval \u0152s; 2s\ufffd . This procedure can produce \na step  size  that  achieves  a signi\u00fbcant  decrease  in the  object ive function. In other \ncircumstances, however, you may know good upper bou nds on R and L, typically \nfrom  problem-speci\u00fbc  information,  which  can  suf\u00fbce.  \nThe dominant computational step in each iteration o f the for  loop  of lines  234  \nis computing the gradient. The complexity of comput ing and evaluating  a gra-  \ndient varies widely, depending on the application a t hand. We\u2019ll  discuss  several  \napplications later. 1032  Chapter  33  Machine-Learning  Algorithms  \nConstrained  gradient  descent  \nWe can adapt gradient descent for constrained minim ization to minimize a closed \nconvex function f.x/, subject to the additional requirement that x 2 K, where K \nis a closed convex body. A body  K \u0dc2 R n is convex  if for all x; y 2 K, the convex \ncombination \ufffdx C .1 \ue003 \ufffd/y 2 K for all 0 \u0dc4 \ufffd \u0dc4 1. A closed  convex body contains \nits limit points. Somewhat surprisingly, restrictin g to the constrained problem does \nnot  signi\u00fbcantly  increase  the  number  of iterations  of gradi ent descent. The idea is \nthat you run the same algorithm, but in each iterat ion, check whether the current \npoint x .t/  is still within the convex body K. If it is not, just move to the closest \npoint in K. Moving to the closest point is known as projection. We  formally  de\u00fbne  \nthe projection \u2026 K .x/ of a point x in n dimensions onto a convex body K as the \npoint y 2 K such that kx \ue003 y k D  min fkx \ue003 zk W  \u00b4 2 Kg. If we have x 2 K, then \n\u2026 K .x/ D x. \nThis  one  change  yields  the  procedure  GRADIENT-DESCENT-CONSTRAINED , \nin which  line  4 of GRADIENT-DESCENT is replaced by two lines. It assumes that \nx .0/  2 K. Line  4 of GRADIENT-DESCENT-CONSTRAINED  moves in the direction \nof the  negative  gradient,  and  line  5 projects  back  onto  K. The lemma that follows \nhelps to show that when x \ue003 2 K, if the  projection  step  in line  5 moves  from  a point  \noutside of K to a point in K, it cannot be moving away from x \ue003 . \nGRADIENT-DESCENT-CONSTRAINED  .f;  x .0/  ; \ufffd; T; K/  \n1 sum  D 0 / / n-dimensional  vector,  initially  all  0 \n2 for  t D 0 to T \ue003 1 \n3 sum  D sum  C x .t/  / / add each of n dimensions into sum  \n4 x 0 .t C1/  D x .t/  \ue003 \ufffd \ue001 .r f/.x .t/  / / / .r f/.x .t/  /, x 0 .t C1/  are n-dimensional  \n5 x .t C1/  D \u2026 K .x 0 .t C1/  / / / project onto K \n6 x-avg  D sum=T  / / divide each of n dimensions by T \n7 return  x-avg  \nLemma  33.10  \nConsider a convex body K \u0dc2 R n and points a 2 K and b 0 2 R n . Let b D \u2026 K .b 0 /. \nThen kb \ue003 ak 2 \u0dc4 kb 0 \ue003 ak 2 . \nProof  If b 0 2 K, then b D b 0 and  the  claim  is true.  Otherwise,  b 0 \u00a4 b, and as \nFigure  33.6  shows,  we  can  extend  the  line  segment  between  b and b 0 to a line `. \nLet c be the projection of a onto `. Point c may or may not be in K, and if a \nis on the boundary of K, then c could coincide with b. If c coincides with b \n(part  (c)  of the  \u00fbgure),  then  abb  0 is a right triangle, and so kb \ue003 ak 2 \u0dc4 kb 0 \ue003 ak 2 . 33.3  Gradient  descent  1033 \n(a) (b) (c) K K \nK a \na a b 0 b 0 b 0 b D \u2026 K .b 0 / b D \u2026 K .b 0 / c D b D \u2026 K .b 0 / ` ` ` \nc c \nFigure  33.6  Projecting a point b 0 outside the convex body K to the closest point b D \u2026 K .b 0 / \nin K. Line ` is the line containing b and b 0 , and point c is the projection of a onto `. (a)  When c is \nin K. (b)  When c is not in K. (c)  When a is on the boundary of K and c coincides with b. \nIf c does not coincide with b (parts  (a)  and  (b)  of the  \u00fbgure),  then  because  of \nconvexity, the angle \u2020abb  0 must be obtuse. Because angle \u2020abb  0 is obtuse, \nb lies between c and b 0 on `. Furthermore, because c is the projection of a onto \nline `, acb  and acb  0 must be right triangles. By the Pythagorean theorem , we have \nthat kb 0 \ue003 ak 2 D ka \ue003 ck 2 Ckc \ue003 b 0 k 2 and kb \ue003 ak 2 D ka \ue003 ck 2 Ckc \ue003 bk 2 . Sub-  \ntracting these two equations gives kb 0 \ue003 ak 2 \ue003 kb \ue003 ak 2 D kc \ue003 b 0 k 2 \ue003 kc \ue003 bk 2 . \nBecause b is between c and b 0 , we must have kc \ue003 b 0 k 2 \ue004 kc \ue003 bk 2 , and thus \nkb 0 \ue003 ak 2 \ue003 kb \ue003 ak 2 \ue004 0. The lemma follows. \nWe can now repeat the entire proof for the unconstr ained case and obtain the \nsame  bounds.  Lemma  33.10  with  a D x \ue003 , b D x .t C1/  , and b 0 D x 0 .t C1/  tells us \nthat kx .t C1/  \ue003x \ue003 k 2 \u0dc4 kx 0 .t C1/  \ue003x \ue003 k 2 . We can therefore derive an upper bound that \nmatches  inequality  (33.31).  We  continue  to de\u00fbne  \u02c6.t/  as in equation  (33.26),  but  \nnoting that x .t C1/  , computed  in line  5 of GRADIENT-DESCENT-CONSTRAINED , \nhas  a different  meaning  here  from  in inequality  (33.31):  \n\u02c6.t  C 1/ \ue003 \u02c6.t/  \nD 1 \n2\ufffd  \ue011 \ue011 x .t C1/  \ue003 x \ue003 \ue011 \ue011 2 \ue003 1 \n2\ufffd  \ue011 \ue011 x .t/  \ue003 x \ue003 \ue011 \ue011 2 (by  equation  (33.27))  \n\u0dc4 1 \n2\ufffd  \ue011 \ue011 x 0 .t C1/  \ue003 x \ue003 \ue011 \ue011 2 \ue003 1 \n2\ufffd  \ue011 \ue011 x .t/  \ue003 x \ue003 \ue011 \ue011 2 (by  Lemma  33.10)  \nD 1 \n2\ufffd  \ue002 \n2hx 0 .t C1/  \ue003 x .t/  ; x .t/  \ue003 x \ue003 i C  \ue011 \ue011 x 0 .t C1/  \ue003 x \ue003 \ue011 \ue011 2 \u00cd \n(by  equation  (33.29))  \nD 1 \n2\ufffd  \ue002 \n2h\ue003\ufffd \ue001 .r f/.x .t/  /; x .t/  \ue003 x \ue003 i C  \ue011 \ue011 \ue003\ufffd \ue001 .r f/.x .t/  / \ue011 \ue011 2 \u00cd \n(by  line  4 of GRADIENT-DESCENT-CONSTRAINED ) \nD \ue003h.r f/.x .t/  /; x .t/  \ue003 x \ue003 i C  \ufffd \n2 \ue011 \ue011 .r f/.x .t/  / \ue011 \ue011 2 : 1034  Chapter  33  Machine-Learning  Algorithms  \nWith the same upper bound on the change in the pote ntial function  as in equa-  \ntion  (33.30),  the  entire  proof  of Lemma  33.9  can  proceed  as before. We can \ntherefore conclude that the procedure GRADIENT- DESCENT- CONSTRAINED  has \nthe same asymptotic complexity as GRADIENT- DESCENT. We  summarize  this  re-  \nsult in the following theorem. \nTheorem  33.11  \nLet K \u0dc2 R n be a convex body, x \ue003 2 R n be the  minimizer  of a convex  func-  \ntion f over K, and \ufffd D R=.L  p \nT/, where R and L are  de\u00fbned  in equations  \n(33.20)  and  (33.21).  Suppose  that  the  vector  x-avg  is returned by an execution of \nGRADIENT-DESCENT-CONSTRAINED  .f;  x .0/  ; \ufffd; T; K/ . Let \ufffd D RL=  p \nT . Then \nwe have f.x-avg/ \ue003 f.x \ue003 / \u0dc4 \ufffd . \nApplications  of gradient  descent  \nGradient  descent  has  many  applications  to minimizing  funct ions and is widely used \nin optimization and machine learning. Here we sketc h how it can be used to solve \nlinear systems. Then we discuss an application to m achine learning: prediction \nusing linear regression. \nIn Chapter  28,  we  saw  how  to use  Gaussian  elimination  to solve  a system  of lin-  \near equations Ax D b, thereby computing x D A \ue0021 b. If A is an n \ue005 n matrix and b \nis a length-n vector,  then  the  running  time  of Gaussian  elimination  is \u201a.n  3 /, which \nfor large matrices might be prohibitively expensive . If an approximate solution is \nacceptable, however, you can use gradient descent. \nFirst,  let\u2019s  see  how  to use  gradient  descent  as a roundabout4and  admittedly  inef-  \n\u00fbcient4way  to solve  for  x in the scalar equation ax  D b, where a;x;b  2 R. This \nequation is equivalent to ax  \ue003 b D 0. If ax  \ue003 b is the  derivative  of a convex  func-  \ntion f.x/ , then ax  \ue003 b D 0 for the value of x that minimizes f.x/. Given  f.x/ , \ngradient  descent  can  then  determine  this  minimizer.  Of  course, f.x/  is just  the  in-  \ntegral of ax  \ue003 b, that is, f.x/  D 1 \n2 ax  2 \ue003 bx  , which is convex if a \ue004 0. Therefore, \none way to solve ax  D b for a \ue004 0 is to \u00fbnd  the  minimizer  for  1 \n2 ax  2 \ue003 bx  via \ngradient descent. \nWe now generalize this idea to higher dimensions, w here using gradient descent \nmay  actually  lead  to a faster  algorithm.  One  n-dimensional  analog  is the  function  \nf.x/ D 1 \n2 x T Ax \ue003 b T x, where A is an n \ue005 n matrix. The gradient of f with respect \nto x is the function Ax \ue003 b. To  \u00fbnd  the  value  of x that minimizes f , we set the \ngradient of f to 0 and solve for x. Solving Ax \ue003b D 0 for x, we obtain x D A \ue0021 b, \nThus, minimizing f.x/ is equivalent to solving Ax D b. If f.x/ is convex, then \ngradient descent can approximately compute this min imum. \nA 1-dimensional  function  is convex  when  its  second  derivative  is positive. The \nequivalent  de\u00fbnition  for  a multidimensional  function  is that it is convex when its 33.3  Gradient  descent  1035 \nHessian  matrix  is positive-semide\u00fbnite  (see  page  1222  for  a de\u00fbnition),  where  the  \nHessian  matrix  .r 2 f/.x/ of a function f.x/ is the matrix in which entry .i;j/  is \nthe partial derivative of f with respect to i and j : \n.r 2 f/.x/ D \u00e2 \n@ 2 f \n@x  1 @x  1 @ 2 f \n@x  1 @x  2 \ue001 \ue001 \ue001  @ 2 f \n@x  1 @x  n \n@ 2 f \n@x  2 @x  1 @ 2 f \n@x  2 @x  2 \ue001 \ue001 \ue001  @ 2 f \n@x  2 @x  n : : : : : : : : : : : : \n@ 2 f \n@x  n @x  1 @ 2 f \n@x  n @x  2 \ue001 \ue001 \ue001  @ 2 f \n@x  n @x  n \u00e3 \n: \nAnalogous to the 1-dimensional  case,  the  Hessian  of f is just A, and so if A is \na positive-semide\u00fbnite  matrix,  then  we  can  use  gradient  descent  to \u00fbnd  a point  x \nwhere Ax \ue002 b. If R and L are not too large, then this method is faster than using \nGaussian  elimination.  \nGradient  descent  in machine  learning  \nAs a concrete example of supervised learning for pr ediction, suppose that you want \nto predict whether a patient will develop heart dis ease. For each of m patients, you \nhave n different attributes. For example, you might have n D 4 and the four pieces \nof data are age, height, blood pressure, and number  of close family members with \nheart disease. Denote the data for patient i as a vector x .i/  2 R n , with x .i/  \nj giving \nthe j th entry in vector x .i/  . The label  of patient i is denoted by a scalar y .i/  2 R, \nsignifying  the  severity  of the  patient\u2019s  heart  disease.  The  hypothesis should capture \na relationship between the x .i/  values and y .i/  . For this example, we make the \nmodeling assumption that the relationship is linear , and therefore the goal is to \ncompute the <best= linear relationship between the x .i/  values and y .i/  : a linear \nfunction f W R n !  R such that f.x .i/  / \ue002 y .i/  for each patient i . Of  course,  no  \nsuch function may exist, but you would like one tha t comes as close as possible. \nA linear function f can  be de\u00fbned  by  a vector  of weights  w D .w  0 ;w  1 ;:::;w  n /, \nwith \nf.x/ D w 0 C n X  \nj D1 w j x j : (33.32)  \nWhen  evaluating  a machine-learning  model,  you  need  to measu re how close \neach value f.x .i/  / is to its corresponding label y .i/  . In this  example,  we  de\u00fbne  \nthe error e .i/  2 R associated with patient i as e .i/  D f.x .i/  / \ue003 y .i/  . The objective \nfunction we choose is to minimize the sum of square s of the errors, which is 1036  Chapter  33  Machine-Learning  Algorithms  \nm X  \ni D1 \u00e3 e .i/  \u00e4 2 D m X  \ni D1 \u00e3 f.x .i/  / \ue003 y .i/  \u00e4 2 \nD m X  \ni D1 \ue001 \nw 0 C n X  \nj D1 w j x .i/  \nj \ue003 y .i/  ! 2 \n: (33.33)  \nThe objective function is typically called the loss  function , and the least-squares  \nerror  given  by  equation  (33.33)  is just  one  example  of many  possible  loss  func-  \ntions. The goal is then, given the x .i/  and y .i/  values, to compute the weights \nw 0 ;w  1 ;:::;w  n so as to minimize  the  loss  function  in equation  (33.33).  The  vari-  \nables here are the weights w 0 ;w  1 ;:::;w  n and not the x .i/  or y .i/  values. \nThis particular objective is sometimes known as a least-squares  \ufb01t, and  the  prob-  \nlem  of \u00fbnding  a linear  function  to \u00fbt data  and  minimize  the  least-squares  error  \nis called linear  regression. Finding  a least-squares  \u00fbt is also  addressed  in Sec-  \ntion  28.3.  \nWhen the function f is linear,  the  loss  function  de\u00fbned  in equation  (33.33)  is \nconvex, because it is the sum of squares of linear functions, which are themselves \nconvex. Therefore, we can apply gradient descent to  compute a set of weights to \napproximately  minimize  the  least-squares  error.  The  concr ete goal of learning is to \nbe able to make predictions on new data. Informally , if the features are all reported \nin the same units and are from the same range (perh aps from being normalized), \nthen the weights tend to have a natural interpretat ion because the features of the \ndata that are better predictors of the label have a  larger associated weight. For \nexample, you would expect that, after normalization , the weight associated with \nthe number of family members with heart disease wou ld be larger than the weight \nassociated with height. \nThe  computed  weights  form  a model  of the  data.  Once  you  have  a model, you \ncan make predictions, so that given new data, you c an predict its label. In our \nexample, given a new patient x 0 who is not part of the original training data set, you \nwould still hope to predict the chance that the new  patient develops heart disease. \nYou can do so by computing the label f.x 0 /, incorporating the weights computed \nby gradient descent. \nFor  this  linear-regression  problem,  the  objective  is to minimize the expression in \nequation  (33.33),  which  is a quadratic  in each  of the  nC1 weights w j . Thus, entry j \nin the gradient is linear in w j . Exercise  33.3-5  asks  you  to explicitly  compute  the  \ngradient and see that it can be computed in O.nm/  time, which is linear in the input \nsize.  Compared  with  the  exact  method  of solving  equation  (33.33)  in Chapter  28,  \nwhich needs to invert a matrix, gradient descent is  typically much faster. \nSection  33.1  brie\u00fcy  discussed  regularization4the  idea  that  a complicated  hy-  \npothesis  should  be penalized  in order  to avoid  over\u00fbtting  the  training  data.  Reg-  \nularization often involves adding a term to the obj ective function, but it can also 33.3  Gradient  descent  1037 \nbe achieved  by  adding  a constraint.  One  way  to regularize  this example would be \nto explicitly limit the norm of the weights, adding  a constraint that kw k \u0dc4  B for \nsome bound B>0 . (Recall again that the components of the vector w are  the  vari-  \nables in the present application.) Adding this cons traint controls the complexity of \nthe model, as the number of values w j that can have large absolute value is now \nlimited. \nIn order  to run  GRADIENT-DESCENT-CONSTRAINED  for any problem, you \nneed to implement the projection step, as well as t o compute bounds on R and L. \nWe conclude this section by describing these calcul ations for gradient descent with \nthe constraint kw k \u0dc4  B . First,  consider  the  projection  step  in line  5. Suppose  \nthat  the  update  in line  4 results  in a vector  w 0 . The projection is implemented \nby computing \u2026 k .w 0 / where K is de\u00fbned  by  kw k \u0dc4  B . This  particular  pro-  \njection can be accomplished by simply scaling w 0 , since we know that closest \npoint in K to w 0 must be the point along the vector whose norm is ex actly B . \nThe amount \u00b4 by which we need to scale w 0 to hit the boundary of K is the  so-  \nlution to the equation \u00b4 kw 0 k D  B , which is solved by \u00b4 D B=  kw 0 k. Hence \nline  5 is implemented  by  computing  w D w 0 B=  kw 0 k. Because we always have \nkw k \u0dc4  B , Exercise  33.3-6  asks  you  to show  that  the  upper  bound  on  the  mag-  \nnitude L of the gradient is O.B/ . We also get a bound on R, as follows. By \nthe constraint kw k \u0dc4  B , we know that both kw .0/  k \u0dc4  B and kw \ue003 k \u0dc4  B , and \nthus kw .0/  \ue003 w \ue003 k \u0dc4  2B  . Using  the  de\u00fbnition  of R in equation  (33.20),  we  have  \nR D O.B/ . The bound RL=  p \nT on the accuracy of the solution after T iterations \nin Theorem  33.11  becomes  O.B/L=  p \nT D O.B  2 = p \nT/. \nExercises  \n33.3-1  \nProve  Lemma  33.6.  Start  from  the  de\u00fbnition  of a convex  function  given  in equa-  \ntion  (33.18).  (Hint: You can prove the statement when n D 1 \u00fbrst.  The  proof  for  \ngeneral values of n is similar.) \n33.3-2  \nProve  Lemma  33.7.  \n33.3-3  \nProve  equation  (33.29).  (Hint: The proof for n D 1 dimension is straightforward. \nThe proof for general values of n dimensions follows along similar lines.) \n33.3-4  \nShow that the function f in equation  (33.32)  is a convex  function  of the  variables  \nw 0 ;w  1 ;:::;w  n . 1038  Chapter  33  Machine-Learning  Algorithms  \n33.3-5  \nCompute  the  gradient  of expression  (33.33)  and  explain  how  to evaluate  the  gradi-  \nent in O.nm/  time. \n33.3-6  \nConsider the function f de\u00fbned  in equation  (33.32),  and  suppose  that  you  have  a \nbound kw k \u0dc4  B , as is considered in the discussion on regularizat ion. Show that \nL D O.B/  in this case. \n33.3-7  \nEquation  (33.2)  on  page  1009  gives  a function  that,  when  mini mized, gives an \noptimal solution to the k-means  problem.  Explain  how  to use  gradient  descent  to \nsolve the k-means  problem.  \nProblems  \n33-1  Newton\u2019s  method  \nGradient  descent  iteratively  moves  closer  to a desired  value (the minimum) of a \nfunction. Another algorithm in this spirit is known  as Newton\u2019s  method , which is \nan iterative  algorithm  that  \u00fbnds  the  root  of a function.  Here,  we  consider  Newton\u2019s  \nmethod which, given a function f W R !  R, \u00fbnds  a value  x \ue003 such that f.x  \ue003 / D 0. \nThe algorithm moves through a series of points x .0/  ;x  .1/  ;:::. If the algorithm is \ncurrently at a point x .t/  , then  to \u00fbnd  point  x .t C1/  , it \u00fbrst  takes  the  equation  of the  \nline tangent to the curve at x D x .t/  , \ny D f 0 .x .t/  /.x  \ue003 x .t/  / C f.x  .t/  /: \nIt then uses the x -intercept  of this  line  as the  next  point  x .t C1/  . \na. Show that the algorithm described above can be summ arized by the update rule \nx .t C1/  D x .t/  \ue003 f.x  .t/  / \nf 0 .x .t/  / : \nWe restrict our attention to some domain I and assume that f 0 .x/  \u00a4 0 for all \nx 2 I and that f 00 .x/  is continuous. We also assume that the starting poi nt x .0/  is \nsuf\u00fbciently  close  to x \ue003 , where  <suf\u00fbciently  close=  means  that  we  can  use  only  the  \n\u00fbrst  two  terms  of the  Taylor  expansion  of f.x  \ue003 / about x .0/  , namely \nf.x  \ue003 / D f.x  .0/  / C f 0 .x .0/  /.x  \ue003 \ue003 x .0/  / C 1 \n2 f 00 .\ufffd .0/  /.x  \ue003 \ue003 x .0/  / 2 ; (33.34)  Problems for Chapter 33 1039 \nwhere \ufffd .0/  is some value between x .0/  and x \ue003 . If the  approximation  in equa-  \ntion  (33.34)  holds  for  x .0/  , it also holds for any point closer to x \ue003 . \nb. Assume that the function f has exactly one point x \ue003 for which f.x  \ue003 / D 0. Let \n\ufffd .t/  D \u02c7 \u02c7 x .t/  \ue003 x \ue003 \u02c7 \u02c7 . Using  the  Taylor  expansion  in equation  (33.34),  show  that  \n\ufffd .t C1/  D \u02c7 \u02c7 f 00 .\ufffd .t/  / \u02c7 \u02c7 \n2 jf 0 .\ufffd .t/  /j \ufffd .t/  ; \nwhere \ufffd .t/  is some value between x .t/  and x \ue003 . \nc. If \n\u02c7 \u02c7 f 00 .\ufffd .t/  / \u02c7 \u02c7 \n2 jf 0 .\ufffd .t/  /j \u0dc4 c \nfor some constant c and \ufffd .0/  <1, then we say that the function f has quadratic  \nconvergence , since the error decreases quadratically. Assuming  that f has  qua-  \ndratic  convergence,  how  many  iterations  are  needed  to \u00fbnd  a root of f.x/  to an \naccuracy of \u0131 ? Your  answer  should  include  \u0131 . \nd. Suppose  you  wish  to \u00fbnd  a root  of the  function  f.x/  D .x \ue003 3/ 2 , which is also \nthe minimizer, and you start at x .0/  D 3:5. Compare the number of iterations \nneeded  by  gradient  descent  to \u00fbnd  the  minimizer  and  Newton\u2019s  method  to \u00fbnd  \nthe root. \n33-2  Hedge  \nAnother  variant  in the  multiplicative-weights  framework  is known as H EDGE . It \ndiffers from W EIGHTED  MAJORITY  in two ways. First, H EDGE  makes  the  pre-  \ndiction  randomly4in  iteration  t , it assigns a probability p .t/  \ni D w .t/  \ni =Z  .t/  to ex-  \npert E i , where Z .t/  D P  n \ni D1 w .t/  \ni . It then chooses an expert E i 0 according to this \nprobability distribution and predicts according to E i 0 . Second, the update rule is \ndifferent.  If an expert  makes  a mistake,  line  16  updates  that  expert\u2019s  weight  by  the  \nrule w .t C1/  \ni D w .t/  \ni e \ue002\ue001 , for some 0 <\ufffd <1 . Show that the expected number of \nmistakes made by H EDGE , running for T rounds, is at most m \ue003 C .ln n/=\ufffd  C \ufffdT  . \n33-3  Nonoptimality  of Lloyd\u2019s  procedure  in one  dimension  \nGive  an example  to show  that  even  in one  dimension,  Lloyd\u2019s  procedure  for  \u00fbnding  \nclusters does not always return an optimum result. That is, Lloyd\u2019s  procedure  may  \nterminate and return as a result a set C of clusters that does not minimize f.S;C/ , \neven when S is a set of points on a line. 1040  Chapter  33  Machine-Learning  Algorithms  \n33-4  Stochastic  gradient  descent  \nConsider  the  problem  described  in Section  33.3  of \u00fbtting  a line f.x/  D ax  C b \nto a given set of point/value pairs S D f.x 1 ;y  1 /;:::;.x  T ;y  T /g by optimizing the \nchoice of the parameters a and b using  gradient  descent  to \u00fbnd  a best  least-squares  \n\u00fbt.  Here  we  consider  the  case  where  x is a real-valued  variable,  rather  than  a vector.  \nSuppose that you are not given the point/value pair s in S all at once, but only \none at a time in an online manner. Furthermore, the  points are given in random \norder. That is, you know that there are n points, but in iteration t you are given \nonly .x i ;y  i / where i is independently and randomly chosen from f1;:::;T  g. \nYou can use gradient descent to compute an estimate  to the function. As each \npoint .x i ;y  i / is considered, you can update the current values of  a and b by taking \nthe derivative with respect to a and b of the  term  of the  objective  function  depend-  \ning on .x i ;y  i /. Doing so gives you a stochastic estimate of the g radient, and you \ncan then take a small step in the opposite directio n. \nGive  pseudcode  to implement  this  variant  of gradient  descen t. What would the \nexpected value of the error be as a function of T , L, and R? (Hint: Replicate the \nanalysis  of GRADIENT-DESCENT in Section  33.3  for  this  variant.)  \nThis procedure and its variants are known as stochastic  gradient  descent . \nChapter  notes  \nFor  a general  introduction  to arti\u00fbcial  intelligence,  we  recommend Russell and \nNorvig  [391].  For  a general  introduction  to machine  learnin g, we recommend \nMurphy  [340].  \nLloyd\u2019s  procedure  for  the  k-means  problem  was  \u00fbrst  proposed  by  Lloyd  [304]  \nand  also  later  by  Forgy  [151].  It is sometimes  called  <Lloyd\u2019  s algorithm= or the \n<Lloyd-Forgy  algorithm.=  Although  Mahajan  et al.  [310]  showed  that  \u00fbnding  an \noptimal  clustering  is NP-hard,  even  in the  plane,  Kanungo  et al.  [241]  have  shown  \nthat there is an approximation algorithm for the k-means  problem  with  approxima-  \ntion ratio 9 C \ufffd , for any \ufffd>0 . \nThe  multiplicative-weights  method  is surveyed  by  Arora,  Hazan,  and  Kale  [25].  \nThe main idea of updating weights based on feedback  has been rediscovered many \ntimes.  One  early  use  is in game  theory,  where  Brown  de\u00fbned  <Fictitious  Play=  [74]  \nand  conjectured  its  convergence  to the  value  of a zero-sum  game. The convergence \nproperties  were  established  by  Robinson  [382].  \nIn machine  learning,  the  \u00fbrst  use  of multiplicative  weights  was by Littlestone in \nthe  Winnow  algorithm  [300],  which  was  later  extended  by  Littlestone and Warmuth \nto the  weighted-majority  algorithm  described  in Section  33.2  [301].  This  work  is \nclosely connected to the boosting algorithm, origin ally due to Freund and Shapire Notes for Chapter 33 1041 \n[159].  The  multiplicative-weights  idea  is also  closely  related  to several  more  gen-  \neral optimization algorithms, including the percept ron algorithm  [328]  and  algo-  \nrithms for optimization problems such as packing li near programs  [177,  359].  \nThe treatment of gradient descent in this chapter d raws heavily  on  the  unpub-  \nlished  manuscript  of Bansal  and  Gupta  [35].  They  emphasize  the idea of using \na potential function and using ideas from amortized  analysis to explain gradient \ndescent.  Other  presentations  and  analyses  of gradient  descent include works by \nBubeck  [75],  Boyd  and  Vanderberghe  [69],  and  Nesterov  [343] . \nGradient  descent  is known  to converge  faster  when  functions  obey  stronger  prop-  \nerties than general convexity. For example, a funct ion f is \u02db-strongly  convex  if \nf.y / \ue004 f.x/ C h.r f/.x/;.y \ue003 x/i C  \u02db ky \ue003 xk for all x; y 2 R n . In this case, \nGRADIENT-DESCENT can use a variable step size and return x .T  / . The step size \nat step t becomes \ufffd t D 1=.\u02db.t  C 1//, and the procedure returns a point such that \nf.x-avg/ \ue003 f.x \ue003 / \u0dc4 L 2 =.\u02db.T  C 1//. This  convergence  is better  than  that  of The-  \norem  33.8  because  the  number  of iterations  needed  is linear,  rather than quadratic, \nin the desired error parameter \ufffd , and because the performance is independent of the  \ninitial point. \nAnother case in which gradient descent can be shown  to perform better than \nthe  analysis  in Section  33.3  suggests  is for  smooth  convex  functions. We say that a \nfunction is \u02c7-smooth  if f.y / \u0dc4 f.x/ Ch.r f/.x/;.y \ue003 x/iC  \u02c7 \n2 ky \ue003 xk 2 . This  in-  \nequality goes in the opposite direction from the on e for \u02db-strong  convexity.  Better  \nbounds on gradient descent are possible here as wel l. 34  NP-Completeness  \nAlmost all the algorithms we have studied thus far have been polynomial-time  \nalgorithms : on inputs of size n, their  worst-case  running  time  is O.n  k / for some \nconstant k. You might wonder whether all problems can be solved in polynomial \ntime. The answer is no. For example, there are prob lems, such as Turing\u2019s  famous  \n<Halting Problem,= that cannot be solved by any com puter, no matter how long \nyou\u2019re  willing  to wait  for  an answer.  1 There are also problems that can be solved, \nbut not in O.n  k / time for any constant k. Generally,  we  think  of problems  that  are  \nsolvable  by  polynomial-time  algorithms  as being  tractable , or <easy,= and problems \nthat require superpolynomial time as being intracta ble, or <hard.= \nThe subject of this chapter, however, is an interes ting class of problems, called \nthe  <NP-complete=  problems,  whose  status  is unknown.  No  polynomial-time  al-  \ngorithm  has  yet  been  discovered  for  an NP-complete  problem,  nor has anyone yet \nbeen  able  to prove  that  no  polynomial-time  algorithm  can  exist for any one of them. \nThis  so-called  P \u00a4 NP question has been one of the deepest, most perpl exing open \nresearch problems in theoretical computer science s ince it was  \u00fbrst  posed  in 1971.  \nSeveral  NP-complete  problems  are  particularly  tantalizin g because they seem \non the surface to be similar to problems that we kn ow how to solve in polynomial \ntime. In each of the following pairs of problems, o ne is solvable in polynomial time \nand  the  other  is NP-complete,  but  the  difference  between  the  problems appears to \nbe slight: \nShortest  versus  longest  simple  paths:  In Chapter  22,  we  saw  that  even  with  neg-  \native  edge  weights,  we  can  \u00fbnd  shortest paths from a single source in a directed \n1 For the Halting Problem and other unsolvable proble ms, there are proofs that no algorithm can \nexist that, for every input, eventually produces th e correct answer. A procedure attempting to solve \nan unsolvable problem might always produce an answe r but is sometimes incorrect, or all the answers \nit produces might be correct but for some inputs it  never produces an answer. Chapter 34 NP-Completeness 1043 \ngraph G D .V;E/  in O.VE/  time. Finding a longest simple path between two \nvertices  is dif\u00fbcult,  however.  Merely  determining  whether  a graph contains a \nsimple  path  with  at least  a given  number  of edges  is NP-comple te. \nEuler  tour  versus  hamiltonian  cycle:  An Euler  tour  of a strongly connected, \ndirected graph G D .V;E/  is a cycle that traverses each edge of G exactly \nonce, although it is allowed to visit each vertex m ore than once.  Problem  20-3  \non  page  583  asks  you  to show  how  to determine  whether  a strongl y connected, \ndirected graph has an Euler tour and, if it does, t he order of the edges  in the  Eu-  \nler tour, all in O.E/  time. A hamiltonian  cycle  of a directed graph G D .V;E/  \nis a simple cycle that contains each vertex in V . Determining  whether  a di-  \nrected  graph  has  a hamiltonian  cycle  is NP-complete.  (Later  in this chapter, \nwe\u2019ll  prove  that  determining  whether  an undirected  graph has a hamiltonian \ncycle  is NP-complete.)  \n2-CNF  satis\ufb01ability  versus  3-CNF  satis\ufb01ability:  Boolean  formulas  contain  bi-  \nnary variables whose values are 0 or 1; boolean connectives such as ^ (AND), \n_ (OR),  and  : (NOT);  and  parentheses.  A boolean  formula  is satis\ufb01able  if \nthere exists some assignment of the values 0 and 1 to its variables that causes \nit to evaluate to 1. We\u2019ll  de\u00fbne  terms  more  formally  later  in this  chapter,  but  \ninformally, a boolean formula is in k-conjunctive  normal  form , or k-CNF  if \nit is the  AND  of clauses  of ORs  of exactly  k variables or their negations. For \nexample, the boolean formula .x 1 _ x 2 / ^ .:x 1 _ x 3 / ^ .:x 2 _ :x 3 / is in \n2-CNF  (with  satisfying  assignment  x 1 D 1, x 2 D 0, and x 3 D 1). Although \nthere  is a polynomial-time  algorithm  to determine  whether  a 2-CNF  formula  \nis satis\u00fbable,  we\u2019ll  see  later  in this  chapter  that  determining  whether  a 3-CNF  \nformula  is satis\u00fbable  is NP-complete.  \nNP-completeness  and  the  classes  P and  NP  \nThroughout this chapter, we refer to three classes of problems: P, NP, and NPC, the \nlatter  class  being  the  NP-complete  problems.  We  describe  them informally here, \nwith  formal  de\u00fbnitions  to appear  later  on.  \nThe class P consists of those problems that are sol vable in polynomial time. \nMore  speci\u00fbcally,  they  are  problems  that  can  be solved  in O.n  k / time for some \nconstant k, where n is the size of the input to the problem. Most of th e problems \nexamined in previous chapters belong to P. \nThe  class  NP  consists  of those  problems  that  are  <veri\u00fbable=  in polynomial time. \nWhat  do  we  mean  by  a problem  being  veri\u00fbable?  If you  were  someh ow given \na <certi\u00fbcate=  of a solution,  then  you  could  verify  that  the  certi\u00fbcate  is correct  \nin time polynomial in the size of the input to the problem. For example, in the \nhamiltonian-cycle  problem,  given  a directed  graph  G D .V;E/, a certi\u00fbcate  would  1044 Chapter 34 NP-Completeness \nbe a sequence hv 1 ;v  2 ;v  3 ;:::;v  jV j i of jV j vertices.  You  could  check  in polyno-  \nmial time that the sequence contains each of the jV j vertices exactly once, that \n.v i ;v  i C1 / 2 E for i D 1;2;3;:::;  jV j \ue003  1, and that .v jV j ;v  1 / 2 E. As another \nexample,  for  3-CNF  satis\u00fbability,  a certi\u00fbcate  could  be an assignment of values to \nvariables. You could check in polynomial time that this assignment  satis\u00fbes  the  \nboolean formula. \nAny problem in P also belongs to NP, since if a pro blem belongs to P then it \nis solvable in polynomial time without even being s upplied a certi\u00fbcate.  We\u2019ll  \nformalize this notion later in this chapter, but fo r now you can believe that P \u0dc2 NP. \nThe famous open question is whether P is a proper s ubset of NP. \nInformally,  a problem  belongs  to the  class  NPC4and  we  call  it NP-complete  \n4if  it belongs  to NP  and  is as <hard=  as any  problem  in NP.  We\u2019ll  formally  de-  \n\u00fbne  what  it means  to be as hard  as any  problem  in NP  later  in this  chapter. In the \nmeantime, we state without proof that if any  NP-complete  problem  can  be solved  \nin polynomial time, then every  problem  in NP  has  a polynomial-time  algorithm.  \nMost  theoretical  computer  scientists  believe  that  the  NP-c omplete problems are \nintractable,  since  given  the  wide  range  of NP-complete  problems that have been \nstudied  to date4without  anyone  having  discovered  a polynomial-time  solution  to \nany  of them4it  would  be truly  astounding  if all  of them  could  be solved  in poly-  \nnomial time. Yet, given the effort devoted thus far  to proving that  NP-complete  \nproblems  are  intractable4without  a conclusive  outcome4we  cannot rule out the \npossibility  that  the  NP-complete  problems  could  turn  out  to be solvable  in polyno-  \nmial time. \nTo become a good algorithm designer, you must under stand the rudiments of the \ntheory  of NP-completeness.  If you  can  establish  a problem  as NP-complete,  you  \nprovide good evidence for its intractability. As an  engineer, you would then do \nbetter to spend your time developing an approximati on algorithm  (see  Chapter  35)  \nor solving a tractable special case, rather than se arching for a fast algorithm that \nsolves the problem exactly. Moreover, many natural and interesting problems that \non the surface seem no harder than sorting, graph s earching, or network  \u00fcow  are  \nin fact  NP-complete.  Therefore,  you  should  become  familiar  with this remarkable \nclass of problems. \nOverview  of showing  problems  to be  NP-complete  \nThe  techniques  used  to show  that  a particular  problem  is NP-complete  differ  fun-  \ndamentally from the techniques used throughout most  of this book to design and \nanalyze algorithms. If you can demonstrate that a p roblem is NP-complete,  you  \nare making a statement about how hard it is (or at least how hard we think it is), \nrather  than  about  how  easy  it is. If you  prove  a problem  NP-complete,  you  are  say-  \ning  that  searching  for  ef\u00fbcient  algorithm  is likely  to be a fruitless endeavor. In this Chapter 34 NP-Completeness 1045 \nway,  NP-completeness  proofs  bear  some  similarity  to the  proof  in Section  8.1  of an \n\ufffd.n  lg n/-time  lower  bound  for  any  comparison  sort  algorithm,  although  the  spe-  \nci\u00fbc  techniques  used  for  showing  NP-completeness  differ  from  the  decision-tree  \nmethod  used  in Section  8.1.  \nWe  rely  on  three  key  concepts  in showing  a problem  to be NP-com plete: \nDecision  problems  versus  optimization  problems  \nMany problems of interest are optimization  problems , in which each feasible (i.e., \n<legal=) solution has an associated value, and the goal is to \u00fbnd  a feasible  solution  \nwith  the  best  value.  For  example,  in a problem  that  we  call  SHORTEST-PATH,  \nthe input is an undirected graph G and vertices u and v, and  the  goal  is to \u00fbnd  a \npath from u to v that  uses  the  fewest  edges.  In other  words,  SHORTEST-PATH  \nis the  single-pair  shortest-path  problem  in an unweighted,  undirected  graph.  NP-  \ncompleteness applies directly not to optimization p roblems, however, but to deci-  \nsion  problems , in which the answer is simply <yes= or <no= (or, more formall y, <1=  \nor <0=). \nAlthough  NP-complete  problems  are  con\u00fbned  to the  realm  of decision problems, \nthere is usually a way to cast a given optimization  problem as a related decision \nproblem by imposing a bound on the value to be opti mized. For e xample,  a deci-  \nsion  problem  related  to SHORTEST-PATHis  PATH:  given  an undirected graph G, \nvertices u and v, and an integer k, does a path exist from u to v consisting of at \nmost k edges?  \nThe relationship between an optimization problem an d its related  decision  prob-  \nlem works in your favor when you try to show that t he optimization problem is \n<hard.= That is because the decision problem is in a sense <easier,= or at least <no \nharder.=  As  a speci\u00fbc  example,  you  can  solve  PATH  by  solving  SHORTEST-PATH  \nand then comparing the number of edges in the short est path found to the value \nof the  decision-problem  parameter  k. In other  words,  if an optimization  prob-  \nlem is easy, its related decision problem is easy a s well. Stated in a way that has \nmore  relevance  to NP-completeness,  if you  can  provide  evide nce that a decision \nproblem is hard, you also provide evidence that its  related optimization problem is \nhard. Thus, even though it restricts attention to d ecision problems, the theory of \nNP-completeness  often  has  implications  for  optimization  problems as well. \nReductions  \nThe above notion of showing that one problem is no harder or no easier  than  an-  \nother applies even when both problems are decision problems. Almost  every  NP-  \ncompleteness proof takes advantage of this idea, as  follows. Consider a decision \nproblem A, which you would like to solve in polynomial time.  We call the input \nto a particular problem an instance  of that problem. For example, in PATH, an 1046 Chapter 34 NP-Completeness \ninstance \u02db \nof A instance \u02c7 \nof B yes \nno yes \nno \npolynomial-time  algorithm  to decide  A polynomial-time  \nreduction algorithm polynomial-time  \nalgorithm to decide B \nFigure  34.1  How  to use  a polynomial-time  reduction  algorithm  to solve  a decision problem A in \npolynomial  time,  given  a polynomial-time  decision  algorit hm for another problem B. In polynomial \ntime, transform an instance \u02db of A into an instance \u02c7 of B, solve B in polynomial time, and use the \nanswer for \u02c7 as the answer for \u02db. \ninstance is a particular graph G, particular vertices u and v of G, and a particular \ninteger k. Now suppose that you already know how to solve a different decision \nproblem B in polynomial time. Finally, suppose that you have a procedure that \ntransforms any instance \u02db of A into some instance \u02c7 of B with  the  following  char-  \nacteristics: \n\ue001 The transformation takes polynomial time. \n\ue001 The answers are the same. That is, the answer for \u02db is <yes= if and only if the \nanswer for \u02c7 is also <yes.= \nWe  call  such  a procedure  a polynomial-time  reduction  algorithm  and,  as Fig-  \nure  34.1  shows,  it provides  us a way  to solve  problem  A in polynomial time: \n1. Given  an instance  \u02db of problem A, use  a polynomial-time  reduction  algorithm  \nto transform it to an instance \u02c7 of problem B . \n2. Run  the  polynomial-time  decision  algorithm  for  B on the instance \u02c7. \n3. Use  the  answer  for  \u02c7 as the answer for \u02db. \nAs long as each of these steps takes polynomial tim e, all three together do also, \nand so you have a way to decide on \u02db in polynomial time. In other words, by \n<reducing= solving problem A to solving problem B , you use the <easiness= of B \nto prove the <easiness= of A. \nRecalling  that  NP-completeness  is about  showing  how  hard  a problem is rather \nthan  how  easy  it is, you  use  polynomial-time  reductions  in the opposite way to \nshow  that  a problem  is NP-complete.  Let\u2019s  take  the  idea  a step  further and show \nhow  you  can  use  polynomial-time  reductions  to show  that  no  polynomial-time  al-  \ngorithm can exist for a particular problem B . Suppose that you have a decision \nproblem A for  which  you  already  know  that  no  polynomial-time  algorith m can \nexist.  (Ignore  for  the  moment  how  to \u00fbnd  such  a problem  A.) Suppose further \nthat  you  have  a polynomial-time  reduction  transforming  instances of A to instances \nof B . Now you can use a simple proof by contradiction t o show that n o polynomial-  \ntime algorithm can exist for B . Suppose otherwise, that is, suppose that B has a Chapter 34 NP-Completeness 1047 \npolynomial-time  algorithm.  Then,  using  the  method  shown  in Figure  34.1,  you  \nwould have a way to solve problem A in polynomial time, which contradicts the \nassumption  that  there  is no  polynomial-time  algorithm  for  A. \nTo prove that a problem B is NP-complete,  the  methodology  is similar.  Al-  \nthough you cannot assume that there is absolutely n o polynomial-time  algorithm  \nfor problem A, you prove that problem B is NP-complete  on  the  assumption  that  \nproblem A is also  NP-complete.  \nA \ufb01rst  NP-complete  problem  \nBecause the technique of reduction relies on having  a problem already known to \nbe NP-complete  in order  to prove  a different  problem  NP-comp lete, there must be \nsome  <\u00fbrst=  NP-complete  problem.  We\u2019ll  use  the  circuit-satis\u00fbability  problem,  in \nwhich the input is a boolean combinational circuit composed of AND,  OR,  and  \nNOT  gates,  and  the  question  is whether  there  exists  some  set  of boolean inputs \nto this circuit that causes its output to be 1. Section  34.3  will  prove  that  this  \u00fbrst  \nproblem  is NP-complete.  \nChapter  outline  \nThis  chapter  studies  the  aspects  of NP-completeness  that  bear most directly on the \nanalysis  of algorithms.  Section  34.1  formalizes  the  notion  of <problem=  and  de-  \n\u00fbnes  the  complexity  class  P of polynomial-time  solvable  decision  problems.  We\u2019ll  \nalso  see  how  these  notions  \u00fbt into  the  framework  of formal-language  theory.  Sec-  \ntion  34.2  de\u00fbnes  the  class  NP  of decision  problems  whose  solutions  are  veri\u00fbable  \nin polynomial time. It also formally poses the P \u00a4 NP question. \nSection  34.3  shows  how  to relate  problems  via  polynomial-ti me <reductions.= It \nde\u00fbnes  NP-completeness  and  sketches  a proof  that  the  circuit-satis\u00fbability  prob-  \nlem  is NP-complete.  With  one  problem  proven  NP-complete,  Section  34.4  demon-  \nstrates  how  to prove  other  problems  to be NP-complete  much  more simply by the \nmethodology of reductions. To illustrate this metho dology, the section shows that \ntwo  formula-satis\u00fbability  problems  are  NP-complete.  Section  34.5  proves  a variety  \nof other  problems  to be NP-complete  by  using  reductions.  You  will  probably  \u00fbnd  \nseveral of these reductions to be quite creative, b ecause they convert a problem in \none domain to a problem in a completely different d omain. 1048 Chapter 34 NP-Completeness \n34.1  Polynomial  time  \nSince  NP-completeness  relies  on  notions  of solving  a problem  and  verifying  a cer-  \nti\u00fbcate  in polynomial  time,  let\u2019s  \u00fbrst  examine  what  it means  for a problem to be \nsolvable in polynomial time. \nRecall that we generally regard problems that have polynomial-time  solutions  as \ntractable. Here are three reasons why: \n1. Although  no  reasonable  person  considers  a problem  that  requires \u201a.n  100  / time \nto be tractable, few practical problems require tim e on the order  of such  a high-  \ndegree  polynomial.  The  polynomial-time  computable  proble ms encountered in \npractice typically require much less time. Experien ce has shown that once the \n\u00fbrst  polynomial-time  algorithm  for  a problem  has  been  discovered,  more  ef\u00fb-  \ncient algorithms often follow. Even if the current best algorithm for a problem \nhas a running time of \u201a.n  100  /, an algorithm with a much better running time \nwill likely soon be discovered. \n2. For many reasonable models of computation, a pro blem that can be solved in \npolynomial time in one model can be solved in polyn omial time in another. \nFor example, the class of problems solvable in poly nomial time by the serial \nrandom-access  machine  used  throughout  most  of this  book  is the same as the \nclass of problems solvable in polynomial time on ab stract Turing machines. 2 \nIt is also the same as the class of problems solvab le in polynomial time on a \nparallel computer when the number of processors gro ws polynomially with the \ninput size. \n3. The  class  of polynomial-time  solvable  problems  has  nice  closure properties, \nsince polynomials are closed under addition, multip lication, and composition. \nFor  example,  if the  output  of one  polynomial-time  algorithm  is fed into the input \nof another, the composite algorithm is polynomial. Exercise 34.1-5  asks  you  to \nshow that if an algorithm makes a constant number o f calls to polynomial-time  \nsubroutines and performs an additional amount of wo rk that also  takes  polyno-  \nmial time, then the running time of the composite a lgorithm is polynomial. \nAbstract  problems  \nTo  understand  the  class  of polynomial-time  solvable  problems,  you  must  \u00fbrst  have  \na formal  notion  of what  a <problem=  is. We  de\u00fbne  an abstract  problem  Q to be a \n2 See  the  books  by  Hopcroft  and  Ullman  [228],  Lewis  and  Papadimitriou  [299],  or Sipser  [413]  for  \na thorough  treatment  of the  Turing-machine  model.  34.1  Polynomial  time  1049 \nbinary relation on a set I of problem instances  and a set S of problem solutions . \nFor  example,  an instance  for  SHORTEST-PATHis  a triple  consi sting of a graph \nand two vertices. A solution is a sequence of verti ces in the graph, with perhaps \nthe empty sequence denoting that no path exists. Th e problem SHORTEST-PATH  \nitself is the relation that associates each instanc e of a graph and two vertices with \na shortest path in the graph that connects the two vertices. Since shortest paths are \nnot necessarily unique, a given problem instance ma y have more than one solution. \nThis formulation of an abstract problem is more gen eral than necessary for our \npurposes.  As  we  saw  above,  the  theory  of NP-completeness  restricts attention to \ndecision  problems : those having a yes/no solution. In this case, we can view an \nabstract decision problem as a function that maps t he instance set I to the solution \nset f0;1g. For  example,  a decision  problem  related  to SHORTEST-PATHi s the \nproblem PATH that we saw earlier. If i D hG;u;v;k i is an instance of PATH, \nthen PATH.i/  D 1 (yes) if G contains a path from u to v with at most k edges, and \nPATH.i/  D 0 (no) otherwise. Many abstract problems are not deci sion problems, \nbut rather optimization  problems , which require some value to be minimized or \nmaximized. As we saw above, however, you can usuall y recast an optimization \nproblem as a decision problem that is no harder. \nEncodings  \nIn order for a computer program to solve an abstrac t problem, its problem instances \nmust appear in a way that the program understands. An encoding  of a set S of \nabstract objects is a mapping e from S to the set of binary strings. 3 For example, \nwe are all familiar with encoding the natural numbe rs N D f0;1;2;3;4;:::  g as \nthe strings f0;1;10;11;100;:::  g. Using this encoding, e.17/  D 10001 . If you \nhave looked at computer representations of keyboard  characters, you probably have \nseen the ASCII code, where, for example, the encodi ng of A is 01000001 . You can \nencode a compound object as a binary string by comb ining the representations of \nits constituent parts. Polygons, graphs, functions,  ordered pairs,  programs4all  can  \nbe encoded as binary strings. \nThus, a computer algorithm that <solves= some abstr act decision  problem  actu-  \nally takes an encoding of a problem instance as inp ut. The size  of an instance i \nis just the length of its string, which we denote b y ji j. We call a problem whose \ninstance set is the set of binary strings a concrete  problem. We  say  that  an algo-  \nrithm solves  a concrete problem in O.T.n//  time if, when it is provided a problem \ninstance i of length n D ji j, the algorithm can produce the solution in O.T.n//  \n3 The codomain of e need not be binary  strings:  any  set  of strings  over  a \u00fbnite  alphabet  having  at \nleast two symbols will do. 1050 Chapter 34 NP-Completeness \ntime. 4 A concrete problem is polynomial-time  solvable , therefore, if there exists \nan algorithm to solve it in O.n  k / time for some constant k. \nWe  can  now  formally  de\u00fbne  the  complexity  class  P as the  set  of concrete  deci-  \nsion  problems  that  are  polynomial-time  solvable.  \nEncodings  map  abstract  problems  to concrete  problems.  Given  an abstract  deci-  \nsion problem Q mapping an instance set I to f0;1g, an encoding e W I ! f0;1g \ue003 \ncan induce a related concrete decision problem, whi ch we denote by e.Q/ . 5 If the \nsolution  to an abstract-problem  instance  i 2 I is Q.i/  2 f0;1g, then the solution \nto the  concrete-problem  instance  e.i/  2 f0;1g \ue003 is also Q.i/ . As a technicality, \nsome binary strings might represent no meaningful a bstract-problem  instance.  For  \nconvenience, assume that any such string maps arbit rarily to 0. Thus,  the  con-  \ncrete problem produces the same solutions as the ab stract problem  on  binary-string  \ninstances  that  represent  the  encodings  of abstract-proble m instances. \nWe  would  like  to extend  the  de\u00fbnition  of polynomial-time  solvability  from  con-  \ncrete problems to abstract problems by using encodi ngs as the bridge, ideally with \nthe  de\u00fbnition  independent  of any  particular  encoding.  That  is, the  ef\u00fbciency  of \nsolving a problem should not depend on how the prob lem is encoded.  Unfortu-  \nnately, it depends quite heavily on the encoding. F or example, suppose that the \nsole input to an algorithm is an integer k, and suppose that the running time of the \nalgorithm is \u201a.k/ . If the integer k is provided in unary4a  string  of k 1s4then  \nthe running time of the algorithm is O.n/  on  length-n inputs, which is polynomial \ntime. If the input k is provided using the more natural binary represent ation, how-  \never, then the input length is n D blg kc C  1, so the size of the unary encoding \nis exponential in the size of the binary encoding. With the binary representation, \nthe running time of the algorithm is \u201a.k/  D \u201a.2  n /, which is exponential in the \nsize of the input. Thus, depending on the encoding,  the algorithm runs in either \npolynomial or superpolynomial time. \nThe encoding of an abstract problem matters quite a  bit to how we understand \npolynomial time. We cannot really talk about solvin g an abstract problem without \n\u00fbrst  specifying  an encoding.  Nevertheless,  in practice,  if we rule out <expensive= \nencodings such as unary ones, the actual encoding o f a problem makes  little  dif-  \nference to whether the problem can be solved in pol ynomial time. For example, \nrepresenting integers in base 3 instead  of binary  has  no  effect  on  whether  a prob-  \nlem is solvable in polynomial time, since we can co nvert an integer represented in \nbase 3 to an integer represented in base 2 in polynomial time. \n4 We  assume  that  the  algorithm\u2019s  output  is separate  from  its  input. Because it takes at least one time \nstep to produce each bit of the output and the algo rithm takes O.T.n//  time steps, the size of the \noutput is O.T.n// . \n5 The notation f0;1g \ue003 denotes the set of all strings composed of symbols from the set f0;1g. 34.1  Polynomial  time  1051 \nWe say that a function f W f0;1g \ue003 ! f0;1g \ue003 is polynomial-time  computable  \nif there  exists  a polynomial-time  algorithm  A that, given any input x 2 f0;1g \ue003 , \nproduces as output f.x/ . For some set I of problem  instances,  we  say  that  two  en-  \ncodings e 1 and e 2 are polynomially  related  if there  exist  two  polynomial-time  com-  \nputable functions f 12  and f 21  such that for any i 2 I , we have f 12  .e 1 .i//  D e 2 .i/  \nand f 21  .e 2 .i//  D e 1 .i/. 6 That  is, a polynomial-time  algorithm  can  compute  the  en-  \ncoding e 2 .i/  from the encoding e 1 .i/, and vice versa. If two encodings e 1 and e 2 of \nan abstract problem are polynomially related, wheth er the problem  is polynomial-  \ntime solvable or not is independent of which encodi ng we use, as the following \nlemma shows. \nLemma  34.1  \nLet Q be an abstract decision problem on an instance set I , and let e 1 and e 2 be \npolynomially related encodings on I . Then, e 1 .Q/  2 P if and only if e 2 .Q/  2 P. \nProof  We need only prove the forward direction, since the  backward direction \nis symmetric. Suppose, therefore, that e 1 .Q/  can be solved in O.n  k / time for \nsome constant k. Furthermore, suppose that for any problem instanc e i , the  en-  \ncoding e 1 .i/  can be computed from the encoding e 2 .i/  in O.n  c / time for some \nconstant c , where n D je 2 .i/j. To solve problem e 2 .Q/  on input e 2 .i/, \u00fbrst  com-  \npute e 1 .i/  and then run the algorithm for e 1 .Q/  on e 1 .i/. How  long  does  this  proce-  \ndure  take?  Converting  encodings  takes  O.n  c / time, and therefore je 1 .i/j D  O.n  c /, \nsince the output of a serial computer cannot be lon ger than its running  time.  Solv-  \ning the problem on e 1 .i/  takes O.je 1 .i/j k / D O.n  ck  / time, which is polynomial \nsince both c and k are constants. \nThus, whether an abstract problem has its instances  encoded in binary or base 3 \ndoes not affect its <complexity,= that is, whether it is polynomial-time  solvable  or \nnot. If instances are encoded in unary, however, it s complexity may change. In \norder  to be able  to converse  in an encoding-independent  fashion,  we  generally  as-  \nsume that problem instances are encoded in any reas onable, concise fashion, unless \nwe  speci\u00fbcally  say  otherwise.  To  be precise,  we  assume  that  the encoding of an \ninteger is polynomially related to its binary repre sentation, and that the encoding of \na \u00fbnite  set  is polynomially  related  to its  encoding  as a list  of its elements, enclosed \nin braces and separated by commas. (ASCII is one su ch encoding scheme.) With \n6 Technically, we also require the functions f 12  and f 21  to <map noninstances to noninstances.= \nA noninstance  of an encoding e is a string x 2 f0;1g \ue003 such that there is no instance i for which \ne.i/  D x. We require that f 12  .x/  D y for every noninstance x of encoding e 1 , where y is some  non-  \ninstance of e 2 , and that f 21  .x 0 / D y 0 for every noninstance x 0 of e 2 , where y 0 is some noninstance \nof e 1 . 1052 Chapter 34 NP-Completeness \nsuch a <standard= encoding in hand, we can derive r easonable encodings of other \nmathematical objects, such as tuples, graphs, and f ormulas. To denote the standard \nencoding of an object, we enclose the object in ang le brackets. Thus, hGi denotes \nthe standard encoding of a graph G. \nAs long as the encoding implicitly used is polynomi ally related to this standard \nencoding, we can talk directly about abstract probl ems without reference to any \nparticular encoding, knowing that the choice of enc oding has no effect on whether \nthe  abstract  problem  is polynomial-time  solvable.  From  now  on, we will generally \nassume that all problem instances are binary string s encoded using the standard \nencoding,  unless  we  explicitly  specify  the  contrary.  We\u2019ll  also typically neglect \nthe distinction between abstract and concrete probl ems. You should watch out \nfor problems that arise in practice, however, in wh ich a standard encoding is not \nobvious and the encoding does make a difference. \nA formal-language  framework  \nBy focusing on decision problems, we can take advan tage of the machinery of \nformal-language  theory.  Let\u2019s  review  some  de\u00fbnitions  from  that theory. An al-  \nphabet  \u2020 is a \u00fbnite  set  of symbols.  A language  L over \u2020 is any set of strings \nmade up of symbols from \u2020. For example, if \u2020 D f0;1g, the set L D f10;  \n11;101;111;1011;1101;10001;:::  g is the language of binary representations of \nprime numbers. We denote the empty  string  by \", the empty  language  by ;, \nand the language of all strings over \u2020 by \u2020 \ue003 . For example, if \u2020 D f0;1g, then \n\u2020 \ue003 D f\";0;1;00;01;10;11;000;:::  g is the  set  of all  binary  strings.  Every  lan-  \nguage L over \u2020 is a subset of \u2020 \ue003 . \nLanguages  support  a variety  of operations.  Set-theoretic  operations, such as \nunion  and intersection, follow  directly  from  the  set-theoretic  de\u00fbnitions.  We  de-  \n\u00fbne  the  complement  of a language L by L D \u2020 \ue003 \ue003 L. The concatenation  L 1 L 2 \nof two languages L 1 and L 2 is the language \nL D fx 1 x 2 W x 1 2 L 1 and x 2 2 L 2 g : \nThe closure  or Kleene  star  of a language L is the language \nL \ue003 D f\"g [  L [ L 2 [ L 3 [ \ue001 \ue001 \ue001  ; \nwhere L k is the language obtained by concatenating L to itself k times. \nFrom the point of view of language theory, the set of instances for any decision \nproblem Q is simply the set \u2020 \ue003 , where \u2020 D f0;1g. Since Q is entirely  character-  \nized by those problem instances that produce a 1 (yes) answer, we can view Q as \na language L over \u2020 D f0;1g, where \nL D fx 2 \u2020 \ue003 W Q.x/  D 1g : 34.1  Polynomial  time  1053 \nFor example, the decision problem PATH has the corr esponding language \nPATH D fhG;u;v;k i W G D .V;E/  is an undirected graph, \nu;v  2 V; \nk \ue004 0 is an integer, and \nG contains a path from u to v with at most k edges g : \n(Where  convenient,  we\u2019ll  sometimes  use  the  same  name4PATH  in this  case4to  \nrefer to both a decision problem and its correspond ing language.) \nThe  formal-language  framework  allows  us to express  concisely  the  relation  be-  \ntween decision problems and algorithms that solve t hem. We s ay that  an al-  \ngorithm A accepts  a string x 2 f0;1g \ue003 if, given input x , the  algorithm\u2019s  out-  \nput A.x/  is 1. The language accepted  by an algorithm A is the set of strings \nL D fx 2 f0;1g \ue003 W A.x/  D 1g, that is, the set of strings that the algorithm ac cepts. \nAn algorithm A rejects  a string x if A.x/  D 0. \nEven if language L is accepted by an algorithm A, the  algorithm  does  not  nec-  \nessarily reject a string x \u2026 L provided as input to it. For example, the algorithm  \nmight loop forever. A language L is decided  by an algorithm A if every binary \nstring in L is accepted by A and every binary string not in L is rejected by A. A \nlanguage L is accepted  in polynomial  time  by an algorithm A if it is accepted by A \nand if in addition there exists a constant k such  that  for  any  length-n string x 2 L, \nalgorithm A accepts x in O.n  k / time. A language L is decided  in polynomial  \ntime  by an algorithm A if there exists a constant k such  that  for  any  length-n \nstring x 2 f0;1g \ue003 , the algorithm correctly decides whether x 2 L in O.n  k / time. \nThus, to accept a language, an algorithm need only produce an answer  when  pro-  \nvided a string in L, but to decide a language, it must correctly accep t or reject every \nstring in f0;1g \ue003 . \nAs an example, the language PATH can be accepted in  polynomial time.  One  \npolynomial-time  accepting  algorithm  veri\u00fbes  that  G encodes an undirected graph, \nveri\u00fbes  that  u and v are vertices in G, uses  breadth-\u00fbrst  search  to compute  a path  \nfrom u to v in G with the fewest edges, and then compares the number  of edges \non the path obtained with k. If G encodes an undirected graph and the path found \nfrom u to v has at most k edges, the algorithm outputs 1 and  halts.  Otherwise,  the  \nalgorithm runs forever. This algorithm does not dec ide PATH, however, since it \ndoes not explicitly output 0 for instances in which a shortest path has more tha n k \nedges. A decision algorithm for PATH must explicitl y reject binary strings that \ndo not belong to PATH. For a decision problem such as PATH, such a decision \nalgorithm is straightforward to design: instead of running forever when there is \nnot a path from u to v with at most k edges, it outputs 0 and halts. (It must \nalso output 0 and halt if the input encoding is faulty.) For othe r problems, such \nas Turing\u2019s  Halting  Problem,  there  exists  an accepting  algorithm, but no decision \nalgorithm exists. 1054 Chapter 34 NP-Completeness \nWe  can  informally  de\u00fbne  a complexity  class  as a set of languages, membership \nin which is determined by a complexity  measure , such as running time, of an \nalgorithm that determines whether a given string x belongs to language L. The \nactual  de\u00fbnition  of a complexity  class  is somewhat  more  technical. 7 \nUsing  this  language-theoretic  framework,  we  can  provide  an alternative  de\u00fbni-  \ntion of the complexity class P: \nP D fL \u0dc2 f0;1g \ue003 W there exists an algorithm A that decides L \nin polynomial time g : \nIn fact, as the following theorem shows, P is also the class of languages that can be \naccepted in polynomial time. \nTheorem  34.2  \nP D fL W L is accepted  by  a polynomial-time  algorithm g : \nProof  Because  the  class  of languages  decided  by  polynomial-time  algorithms is a \nsubset  of the  class  of languages  accepted  by  polynomial-tim e algorithms, we need \nonly show that if L is accepted  by  a polynomial-time  algorithm,  it is decided  by  a \npolynomial-time  algorithm.  Let  L be the  language  accepted  by  some  polynomial-  \ntime algorithm A. We use a classic <simulation= argument to constru ct another \npolynomial-time  algorithm  A 0 that decides L. Because A accepts L in O.n  k / time \nfor some constant k, there also exists a constant c such that A accepts L in at most \ncn  k steps. For any input string x , the algorithm A 0 simulates cn  k steps of A. After \nsimulating cn  k steps, algorithm A 0 inspects the behavior of A. If A has accepted x , \nthen A 0 accepts x by outputting a 1. If A has not accepted x , then A 0 rejects x by \noutputting a 0. The overhead of A 0 simulating A does not increase the running time \nby more than a polynomial factor, and thus A 0 is a polynomial-time  algorithm  that  \ndecides L. \nThe  proof  of Theorem  34.2  is nonconstructive.  For  a given  language L 2 P, \nwe may not actually know a bound on the running tim e for the algorithm A that \naccepts L. Nevertheless, we know that such a bound exists, a nd therefore, that an \nalgorithm A 0 exists that can check the bound, even though we may  not be able to \n\u00fbnd  the  algorithm  A 0 easily. \n7 For more on complexity classes, see the seminal pap er by Hartmanis  and  Stearns  [210].  34.1  Polynomial  time  1055 \nExercises  \n34.1-1  \nDe\u00fbne  the  optimization  problem  LONGEST-PATH-LENGTH  as the  relation that \nassociates each instance of an undirected graph and  two vertices  with  the  num-  \nber of edges in a longest simple path between the t wo vertices. De\u00fbne  the  deci-  \nsion  problem  LONGEST-PATH  D fhG;u;v;k i W  G D .V;E/  is an undirected \ngraph, u;v  2 V , k \ue004 0 is an integer, and there exists a simple path from u \nto v in G consisting of at least k edges g. Show  that  the  optimization  prob-  \nlem  LONGEST-PATH-LENGTH  can  be solved  in polynomial  time  if and only if \nLONGEST-PATH  2 P. \n34.1-2  \nGive  a formal  de\u00fbnition  for  the  problem  of \u00fbnding  the  longest  simple cycle in an \nundirected  graph.  Give  a related  decision  problem.  Give  the  language  correspond-  \ning to the decision problem. \n34.1-3  \nGive  a formal  encoding  of directed  graphs  as binary  strings  using  an adjacency-  \nmatrix  representation.  Do  the  same  using  an adjacency-list  representation. Argue \nthat the two representations are polynomially relat ed. \n34.1-4  \nIs the  dynamic-programming  algorithm  for  the  0-1  knapsack  problem that is asked \nfor  in Exercise  15.2-2  a polynomial-time  algorithm?  Explai n your answer. \n34.1-5  \nShow that if an algorithm makes at most a constant number of ca lls  to polynomial-  \ntime subroutines and performs an additional amount of work that  also  takes  polyno-  \nmial time, then it runs in polynomial time. Also sh ow that a polynomial number of \ncalls  to polynomial-time  subroutines  may  result  in an exponential-time  algorithm.  \n34.1-6  \nShow that the class P, viewed as a set of languages , is closed u nder  union,  inter-  \nsection,  concatenation,  complement,  and  Kleene  star.  That  is, if L 1 ;L  2 2 P, then \nL 1 [ L 2 2 P, L 1 \\ L 2 2 P, L 1 L 2 2 P, L 1 2 P, and L \ue003 \n1 2 P. 1056 Chapter 34 NP-Completeness \n34.2  Polynomial-time  veri\ufb01cation  \nNow,  let\u2019s  look  at algorithms  that  verify  membership  in languages. For example, \nsuppose that for a given instance hG;u;v;k i of the decision problem PATH, you \nare also given a path p from u to v. You can check whether p is a path in G and \nwhether the length of p is at most k, and if so, you can view p as a <certi\u00fbcate=  \nthat the instance indeed belongs to PATH. For the d ecision problem PATH, this \ncerti\u00fbcate  doesn\u2019t  seem  to buy  much.  After  all,  PATH  belongs  to P4in  fact,  you  \ncan  solve  PATH  in linear  time4and  so verifying  membership  from  a given  cer-  \nti\u00fbcate  takes  as long  as solving  the  problem  from  scratch.  Instead,  let\u2019s  examine  \na problem  for  which  we  know  of no  polynomial-time  decision  algorithm and yet, \ngiven  a certi\u00fbcate,  veri\u00fbcation  is easy.  \nHamiltonian  cycles  \nThe  problem  of \u00fbnding  a hamiltonian  cycle  in an undirected  graph  has  been  stud-  \nied for over a hundred years. Formally, a hamiltonian  cycle  of an undirected graph \nG D .V;E/  is a simple cycle that contains each vertex in V . A graph that contains \na hamiltonian cycle is said to be hamiltonian , and otherwise, it is nonhamilto-  \nnian . The name honors W. R. Hamilton, who described a m athematical game on \nthe  dodecahedron  (Figure  34.2(a))  in which  one  player  sticks  \u00fbve  pins  in any  \u00fbve  \nconsecutive vertices and the other player must comp lete the path to form a cycle \ncontaining all the vertices. 8 The  dodecahedron  is hamiltonian,  and  Figure  34.2(a)  \nshows one hamiltonian cycle. Not all graphs are ham iltonian, however.  For  ex-  \nample,  Figure  34.2(b)  shows  a bipartite  graph  with  an odd  number of vertices. \nExercise  34.2-2  asks  you  to show  that  all  such  graphs  are  nonh amiltonian. \nHere  is how  to de\u00fbne  the  hamiltonian-cycle  problem , <Does a graph G have a \nhamiltonian  cycle?=  as a formal  language:  \nHAM-CYCLE  D fhGi W G is a hamiltonian graph g : \nHow  might  an algorithm  decide  the  language  HAM-CYCLE?  Given  a problem \ninstance hGi, one possible decision algorithm lists all permuta tions of the vertices \nof G and then checks each permutation to see whether it is a hamiltonian cycle. \n8 In a letter  dated  17  October  1856  to his  friend  John  T. Graves,  Hamilton  [206,  p. 624]  wrote,  <I \nhave found that some young persons have been much a mused by trying a new mathematical game \nwhich  the  Icosion  furnishes,  one  person  sticking  \u00fbve  pins  in any  \u00fbve  consecutive  points  . . . and  the  \nother player then aiming to insert, which by the th eory in this letter  can  always  be done,  \u00fbfteen  other  \npins, in cyclical succession, so as to cover all th e other points, and to end in immediate proximity t o \nthe pin wherewith his antagonist had begun.= 34.2  Polynomial-time  veri\ufb01cation  1057 \n(a) (b) \nFigure  34.2  (a)  A graph representing the vertices, edges, and faces  of a dodecahedron, with a \nhamiltonian cycle shown by edges highlighted in blu e. (b)  A bipartite graph with an odd number of \nvertices. Any such graph is nonhamiltonian. \nWhat  is the  running  time  of this  algorithm?  It depends  on  the  encoding of the \ngraph G. Let\u2019s  say  that  G is encoded as its adjacency matrix. If the adjacenc y \nmatrix contains n entries, so that the length of the encoding of G equals n, then the \nnumber m of vertices in the graph is \ufffd.  p n/. There are m\u0160  possible permutations \nof the vertices, and therefore the running time is \ufffd.m\u0160/  D \ufffd.  p n\u0160/  D \ufffd.2  p  n /, \nwhich is not O.n  k / for any constant k. Thus, this naive algorithm does not run in \npolynomial  time.  In fact,  the  hamiltonian-cycle  problem  is NP-complete,  as we\u2019ll  \nprove  in Section  34.5.  \nVeri\ufb01cation  algorithms  \nConsider a slightly easier problem. Suppose that a friend tells you that a given \ngraph G is hamiltonian, and then the friend offers to prove  it by giving you the \nvertices in order along the hamiltonian cycle. It w ould certainly be easy enough to \nverify the proof: simply verify that the provided c ycle is hamiltonian by checking \nwhether it is a permutation of the vertices of V and whether each of the consecutive \nedges along the cycle actually exists in the graph.  You could certainly implement \nthis  veri\u00fbcation  algorithm  to run  in O.n  2 / time, where n is the  length  of the  encod-  \ning of G. Thus, a proof that a hamiltonian cycle exists in a graph can b e veri\u00fbed  in \npolynomial time. 1058 Chapter 34 NP-Completeness \nWe  de\u00fbne  a veri\ufb01cation  algorithm  as being  a two-argument  algorithm  A, where \none argument is an ordinary input string x and the other is a binary string y called \na certi\ufb01cate. A two-argument  algorithm  A veri\ufb01es  an input string x if there exists \na certi\u00fbcate  y such that A.x;y/  D 1. The language  veri\ufb01ed  by  a veri\u00fbcation  \nalgorithm A is \nL D fx 2 f0;1g \ue003 W there exists y 2 f0;1g \ue003 such that A.x;y/  D 1g : \nThink of an algorithm A as verifying a language L if, for any string x 2 L, \nthere  exists  a certi\u00fbcate  y that A can use to prove that x 2 L. Moreover, for any \nstring x \u2026 L, there  must  be no  certi\u00fbcate  proving  that  x 2 L. For example, in \nthe  hamiltonian-cycle  problem,  the  certi\u00fbcate  is the  list  of vertices  in some  hamil-  \ntonian cycle. If a graph is hamiltonian, the hamilt onian cycle itself offers enough \ninformation to verify that the graph is indeed hami ltonian. Conversely, if a graph \nis not hamiltonian, there can be no list of vertice s that fools the  veri\u00fbcation  algo-  \nrithm into believing that the graph is hamiltonian,  since the veri\u00fbcation  algorithm  \ncarefully  checks  the  so-called  cycle  to be sure.  \nThe  complexity  class  NP  \nThe complexity  class  NP  is the  class  of languages  that  can  be veri\u00fbed  by  a poly-  \nnomial-time  algorithm.  9 More precisely, a language L belongs to NP if and only if \nthere  exist  a two-input  polynomial-time  algorithm  A and a constant c such that \nL D fx 2 f0;1g \ue003 W there  exists  a certi\u00fbcate  y with jy j D  O.jx j c / \nsuch that A.x;y/  D 1g : \nWe say that algorithm A veri\ufb01es  language L in polynomial  time. \nFrom  our  earlier  discussion  about  the  hamiltonian-cycle  problem, you can see \nthat  HAM-CYCLE  2 NP. (It is always nice to know that an important se t is \nnonempty.) Moreover, if L 2 P, then L 2 NP,  since  if there  is a polynomial-  \ntime algorithm to decide L, the  algorithm  can  be converted  to a two-argument  \nveri\u00fbcation  algorithm  that  simply  ignores  any  certi\u00fbcate  and accepts exactly those \ninput strings it determines to belong to L. Thus, P \u0dc2 NP. \nThat leaves the question of whether P D NP.  A de\u00fbnitive  answer  is unknown,  \nbut most researchers believe that P and NP are not the same class. Think of the \nclass P as consisting of problems that can be solve d quickly and the class NP as \n9 The name <NP= stands for <nondeterministic polynomi al time.= The  class  NP  was  originally  stud-  \nied in the context of nondeterminism, but this book  uses the somewhat simpler yet equivalent notion \nof veri\u00fbcation.  Hopcroft  and  Ullman  [228]  give  a good  presentation  of NP-completeness  in terms  of \nnondeterministic models of computation. 34.2  Polynomial-time  veri\ufb01cation  1059 \nco-NP  NP \n(c) P = NP \u2229 co-NP  co-NP  NP \n(d) P P = NP  = co-NP  \n(a) NP  = co-NP  \n(b) P \nNP \u2229 co-NP  \nFigure  34.3  Four possibilities for relationships among complexi ty classes. In each diagram, one \nregion  enclosing  another  indicates  a proper-subset  relati on. (a)  P D NP D co-NP.  Most  researchers  \nregard this possibility as the most unlikely. (b)  If NP is closed under complement, then NP D co-NP,  \nbut it need not be the case that P D NP. (c)  P D NP \\ co-NP,  but  NP  is not  closed  under  complement.  \n(d)  NP \u00a4 co-NP  and  P \u00a4 NP \\ co-NP.  Most  researchers  regard  this  possibility  as the  most  likely. \nconsisting  of problems  for  which  a solution  can  be veri\u00fbed  quickly. You may have \nlearned  from  experience  that  it is often  more  dif\u00fbcult  to solve a problem from \nscratch than to verify a clearly presented solution , especially when working under \ntime constraints. Theoretical computer scientists g enerally believe that this analogy \nextends to the classes P and NP, and thus that NP i ncludes languages that do not \nbelong to P. \nThere is more compelling, though not conclusive, ev idence that P \u00a4 NP4the  \nexistence  of languages  that  are  <NP-complete.=  Section  34.3  will  study  this  class.  \nMany other fundamental questions beyond the P \u00a4 NP  question  remain  unre-  \nsolved.  Figure  34.3  shows  some  possible  scenarios.  Despite  much work by many \nresearchers, no one even knows whether the class NP  is closed under complement. \nThat is, does L 2 NP imply L 2 NP?  We  de\u00fbne  the  complexity  class  co-NP  as \nthe set of languages L such that L 2 NP, so that the question of whether NP is \nclosed under complement is also whether NP D co-NP.  Since  P is closed  under  \ncomplement  (Exercise  34.1-6),  it follows  from  Exercise  34.2-9  (P \u0dc2 co-NP)  that  \nP \u0dc2 NP \\ co-NP.  Once  again,  however,  no  one  knows  whether  P D NP \\ co-NP  \nor whether there is some language in .NP \\ co-NP/ \ue003 P. \nThus our understanding of the precise relationship between P and  NP  is woe-  \nfully incomplete. Nevertheless, even though we migh t not be able to prove that a \nparticular problem is intractable, if we can prove that it is NP-complete,  then  we  \nhave gained valuable information about it. 1060 Chapter 34 NP-Completeness \nExercises  \n34.2-1  \nConsider  the  language  GRAPH-ISOMORPHISM  D fhG 1 ;G  2 i W  G 1 and G 2 are \nisomorphic graphs g. Prove  that  GRAPH-ISOMORPHISM  2 NP by describing a \npolynomial-time  algorithm  to verify  the  language.  \n34.2-2  \nProve that if G is an undirected bipartite graph with an odd number  of vertices, \nthen G is nonhamiltonian. \n34.2-3  \nShow  that  if HAM-CYCLE  2 P, then the problem of listing the vertices of a \nhamiltonian  cycle,  in order,  is polynomial-time  solvable.  \n34.2-4  \nProve that the class NP of languages is closed unde r union, intersection,  concate-  \nnation,  and  Kleene  star.  Discuss  the  closure  of NP  under  comp lement. \n34.2-5  \nShow that any language in NP can be decided by an a lgorithm with a running time \nof 2 O.n  k / for some constant k. \n34.2-6  \nA hamiltonian  path  in a graph is a simple path that visits every verte x exactly \nonce.  Show  that  the  language  HAM-PATH  D fhG;u;v i W  there is a hamiltonian \npath from u to v in graph Gg belongs to NP. \n34.2-7  \nShow  that  the  hamiltonian-path  problem  from  Exercise  34.2-6  can  be solved  in \npolynomial  time  on  directed  acyclic  graphs.  Give  an ef\u00fbcien t algorithm for the \nproblem. \n34.2-8  \nLet \ufffd be a boolean formula constructed from the boolean i nput variables x 1 ;x  2 ; \n:::;x  k , negations ( :), ANDs ( ^), ORs  (_), and parentheses. The formula \ufffd is a \ntautology  if it evaluates to 1 for every assignment of 1 and 0 to the input variables. \nDe\u00fbne  TAUTOLOGY  as the  language  of boolean  formulas  that  are  tautologies. \nShow  that  TAUTOLOGY  2 co-NP.  \n34.2-9  \nProve that P \u0dc2 co-NP.  34.3  NP-completeness  and  reducibility  1061 \n34.2-10  \nProve that if NP \u00a4 co-NP,  then  P \u00a4 NP. \n34.2-11  \nLet G be a connected, undirected graph with at least thre e vertices, and let G 3 be \nthe graph obtained by connecting all pairs of verti ces that are connected by a path \nin G of length at most 3. Prove that G 3 is hamiltonian. ( Hint: Construct a spanning \ntree for G, and use an inductive argument.) \n34.3  NP-completeness  and  reducibility  \nPerhaps the most compelling reason why theoretical computer scientists believe \nthat P \u00a4 NP  comes  from  the  existence  of the  class  of NP-complete  probl ems. This \nclass has the intriguing property that if any  NP-complete  problem  can  be solved  in \npolynomial time, then every  problem  in NP  has  a polynomial-time  solution,  that  is, \nP D NP.  Despite  decades  of study,  though,  no  polynomial-time  algorithm has ever \nbeen  discovered  for  any  NP-complete  problem.  \nThe  language  HAM-CYCLE  is one  NP-complete  problem.  If there  were an \nalgorithm  to decide  HAM-CYCLE  in polynomial  time,  then  every problem in NP \ncould  be solved  in polynomial  time.  The  NP-complete  languag es are, in a sense, \nthe <hardest= languages in NP. In fact, if NP \ue003 P turns out to be nonempty, we will \nbe able  to say  with  certainty  that  HAM-CYCLE  2 NP \ue003 P. \nThis section starts by showing how to compare the r elative <hardness=  of lan-  \nguages  using  a precise  notion  called  <polynomial-time  reducibility.=  It then  for-  \nmally  de\u00fbnes  the  NP-complete  languages,  \u00fbnishing  by  sketch ing a proof that one \nsuch  language,  called  CIRCUIT-SAT,  is NP-complete.  Sections  34.4  and  34.5  will  \nuse the notion of reducibility to show that many ot her problems  are  NP-complete.  \nReducibility  \nOne  way  that  sometimes  works  for  solving  a problem  is to recas t it as a different \nproblem. We call that strategy <reducing= one probl em to another. Think of a \nproblem Q as being reducible to another problem Q 0 if any instance of Q can be \nrecast as an instance of Q 0 , and the solution to the instance of Q 0 provides a solution \nto the instance of Q. For example, the problem of solving linear equati ons in an \nindeterminate x reduces  to the  problem  of solving  quadratic  equations.  Give n a \nlinear-equation  instance  ax  C b D 0 (with solution x D \ue003b=a), you can transform \nit to the quadratic equation ax  2 C bx  C 0 D 0. This quadratic equation has the \nsolutions x D .\ue003b \u02d9 p \nb 2 \ue003 4ac/=2a , where c D 0, so that p \nb 2 \ue003 4ac  D b. The 1062 Chapter 34 NP-Completeness \nL 2 \nL 1 {0,1}*  {0,1}*  f \nFigure  34.4  A function f that reduces language L 1 to language L 2 . For any input x 2 f0;1g \ue003 , \nthe question of whether x 2 L 1 has the same answer as the question of whether f.x/  2 L 2 . \nsolutions are then x D .\ue003b C b/=2a  D 0 and x D .\ue003b \ue003 b/=2a  D \ue003b=a, thereby \nproviding a solution to ax  C b D 0. Thus, if a problem Q reduces to another \nproblem Q 0 , then Q is, in a sense, <no harder to solve= than Q 0 . \nReturning  to our  formal-language  framework  for  decision  problems, we say that \na language L 1 is polynomial-time  reducible  to a language L 2 , written L 1 \u0dc4 P L 2 , \nif there  exists  a polynomial-time  computable  function  f W f0;1g \ue003 ! f0;1g \ue003 such \nthat for all x 2 f0;1g \ue003 , \nx 2 L 1 if and only if f.x/  2 L 2 : (34.1)  \nWe call the function f the reduction  function, and  a polynomial-time  algorithm  F \nthat computes f is a reduction  algorithm . \nFigure  34.4  illustrates  the  idea  of a reduction  from  a langua ge L 1 to another \nlanguage L 2 . Each language is a subset of f0;1g \ue003 . The reduction function f pro-  \nvides a mapping such that if x 2 L 1 , then f.x/  2 L 2 . Moreover, if x \u2026 L 1 , \nthen f.x/  \u2026 L 2 . Thus, the reduction function maps any instance x of the decision \nproblem represented by the language L 1 to an instance f.x/  of the  problem  rep-  \nresented by L 2 . Providing an answer to whether f.x/  2 L 2 directly provides the \nanswer to whether x 2 L 1 . If, in addition, f can be computed in polynomial time, \nit is a polynomial-time  reduction  function.  \nPolynomial-time  reductions  give  us a powerful  tool  for  proving  that  various  lan-  \nguages belong to P. \nLemma  34.3  \nIf L 1 ;L  2 \u0dc2 f0;1g \ue003 are languages such that L 1 \u0dc4 P L 2 , then L 2 2 P implies \nL 1 2 P. 34.3  NP-completeness  and  reducibility  1063 \nx \nF f.x/  \nA 1 A 2 yes, f.x/  2 L 2 \nno, f.x/  62 L 2 yes, x 2 L 1 \nno, x 62 L 1 \nFigure  34.5  The  proof  of Lemma  34.3.  The  algorithm  F is a reduction algorithm that computes the \nreduction function f from L 1 to L 2 in polynomial time, and A 2 is a polynomial-time  algorithm  that  \ndecides L 2 . Algorithm A 1 decides whether x 2 L 1 by using F to transform any input x into f.x/  \nand then using A 2 to decide whether f.x/  2 L 2 . \nProof  Let A 2 be a polynomial-time  algorithm  that  decides  L 2 , and let F be a \npolynomial-time  reduction  algorithm  that  computes  the  reduction function f . We \nshow  how  to construct  a polynomial-time  algorithm  A 1 that decides L 1 . \nFigure  34.5  illustrates  how  we  construct  A 1 . For a given input x 2 f0;1g \ue003 , \nalgorithm A 1 uses F to transform x into f.x/ , and then it uses A 2 to test whether \nf.x/  2 L 2 . Algorithm A 1 takes the output from algorithm A 2 and produces that \nanswer as its own output. \nThe correctness of A 1 follows  from  condition  (34.1).  The  algorithm  runs  in poly-  \nnomial time, since both F and A 2 run  in polynomial  time  (see  Exercise  34.1-5).  \nNP-completeness  \nPolynomial-time  reductions  allow  us to formally  show  that  one problem is at least \nas hard  as another,  to within  a polynomial-time  factor.  That  is, if L 1 \u0dc4 P L 2 , then \nL 1 is not more than a polynomial factor harder than L 2 , which is why the <less \nthan or equal to= notation for reduction is mnemoni c. We can now  de\u00fbne  the  set  of \nNP-complete  languages,  which  are  the  hardest  problems  in NP. \nA language L \u0dc2 f0;1g \ue003 is NP-complete  if \n1. L 2 NP, and \n2. L 0 \u0dc4 P L for every L 0 2 NP. \nIf a language L satis\u00fbes  property  2, but  not  necessarily  property  1, we  say  that L \nis NP-hard. We  also  de\u00fbne  NPC  to be the  class  of NP-complete  languages.  \nAs  the  following  theorem  shows,  NP-completeness  is at the  crux of deciding \nwhether P is in fact equal to NP. \nTheorem  34.4  \nIf any  NP-complete  problem  is polynomial-time  solvable,  then P D NP.  Equiva-  \nlently,  if any  problem  in NP  is not  polynomial-time  solvable,  then  no  NP-complete  \nproblem  is polynomial-time  solvable.  1064 Chapter 34 NP-Completeness \nNPC \nP NP \nFigure  34.6  How most theoretical computer scientists view the r elationships among P, NP, \nand NPC. Both P and NPC are wholly contained within  NP, and P \\ NPC D ;. \nProof  Suppose that L 2 P and also that L 2 NPC. For any L 0 2 NP, we \nhave L 0 \u0dc4 P L by  property  2 of the  de\u00fbnition  of NP-completeness.  Thus,  by  \nLemma  34.3,  we  also  have  that  L 0 2 P, which  proves  the  \u00fbrst  statement  of the  \ntheorem. \nTo prove the second statement, consider the contrap ositive of the  \u00fbrst  statement:  \nif P \u00a4 NP,  then  there  does  not  exist  an NP-complete  problem  that  is polynomial-  \ntime solvable. But P \u00a4 NP means that there is some problem in NP that is n ot \npolynomial-time  solvable,  and  hence  the  second  statement  is the contrapositive of \nthe  \u00fbrst  statement.  \nIt is for this reason that research into the P \u00a4 NP question centers around the \nNP-complete  problems.  Most  theoretical  computer  scientis ts believe that P \u00a4 NP, \nwhich leads to the relationships among P, NP, and N PC shown in Figure  34.6.  \nFor all we know, however, someone may yet come up w ith a polyno mial-time  \nalgorithm  for  an NP-complete  problem,  thus  proving  that  P D NP. Nevertheless, \nsince  no  polynomial-time  algorithm  for  any  NP-complete  problem has yet been \ndiscovered,  a proof  that  a problem  is NP-complete  provides  excellent evidence that \nit is intractable. \nCircuit  satis\ufb01ability  \nWe  have  de\u00fbned  the  notion  of an NP-complete  problem,  but  up  to this point, we \nhave  not  actually  proved  that  any  problem  is NP-complete.  Once we prove that at \nleast  one  problem  is NP-complete,  polynomial-time  reducib ility becomes a tool to \nprove  other  problems  to be NP-complete.  Thus,  we  now  focus  on  demonstrating \nthe  existence  of an NP-complete  problem:  the  circuit-satis\u00fbability  problem.  \nUnfortunately,  the  formal  proof  that  the  circuit-satis\u00fbability  problem  is NP-  \ncomplete requires technical detail beyond the scope  of this text.  Instead,  we\u2019ll  \ninformally describe a proof that relies on a basic understanding  of boolean  combi-  \nnational circuits. 34.3  NP-completeness  and  reducibility  1065 \nx \ny z x \ny z \n0 0 0 \n0 1 0 \n1 0 0 \n1 1 1 0 0 0 \n0 1 1 \n1 0 1 \n1 1 1 \n(b) (c) x z \n0 1 \n1 0 \n(a) x x x y y :x x ^ y x _ y \nFigure  34.7  Three basic logic gates, with binary inputs and out puts. Under each gate is the truth \ntable  that  describes  the  gate\u2019s  operation.  (a)  The  NOT  gate.  (b)  The AND gate. (c)  The  OR  gate.  \nBoolean combinational circuits are built from boole an combinational elements \nthat are interconnected by wires. A boolean  combinational  element  is any circuit \nelement that has a constant number of boolean input s and outputs and that performs \na well-de\u00fbned  function.  Boolean  values  are  drawn  from  the  set f0;1g, where 0 \nrepresents FALSE and 1 represents TRUE . \nThe boolean combinational elements appearing in the  circuit-satis\u00fbability  prob-  \nlem compute simple boolean functions, and they are known as logic  gates. Fig-  \nure  34.7  shows  the  three  basic  logic  gates  used  in the  circuit-satis\u00fbability  problem:  \nthe NOT  gate  (or inverter ), the AND  gate, and the OR  gate. The  NOT  gate  takes  a \nsingle binary input  x , whose value is either 0 or 1, and produces a binary output  \u00b4 \nwhose value is opposite that of the input value. Ea ch of the other two gates takes \ntwo binary inputs x and y and produces a single binary output \u00b4. \nThe operation of each gate, or of any boolean combi national element,  is de\u00fbned  \nby a truth  table, shown  under  each  gate  in Figure  34.7.  A truth  table  gives  the  \noutputs of the combinational element for each possi ble setting of the inputs. For \nexample,  the  truth  table  for  the  OR  gate  says  that  when  the  inputs are x D 0 \nand y D 1, the output value is \u00b4 D 1. The symbol : denotes  the  NOT  function,  \n^ denotes the AND function, and _ denotes  the  OR  function.  Thus,  for  example,  \n0 _ 1 D 1. \nAND  and  OR  gates  are  not  limited  to just  two  inputs.  An  AND  gate\u2019s  output  is 1 \nif all of its inputs are 1, and its output is 0 otherwise.  An  OR  gate\u2019s  output  is 1 if \nany of its inputs are 1, and its output is 0 otherwise. \nA boolean  combinational  circuit  consists of one or more boolean combinational \nelements interconnected by wires . A wire can connect the output of one element \nto the  input  of another,  so that  the  output  value  of the  \u00fbrst  element becomes an \ninput  value  of the  second.  Figure  34.8  shows  two  similar  boolean combinational \ncircuits,  differing  in only  one  gate.  Part  (a)  of the  \u00fbgure  also shows the values on 1066 Chapter 34 NP-Completeness \nx 3 x 2 x 1 \n(a) 1 \n1 \n0 \n1 1 1 1 1 1 \n1 1 \n0 \n0 \n1 1 1 1 \nx 3 x 2 x 1 \n(b) \nFigure  34.8  Two  instances  of the  circuit-satis\u00fbability  problem.  (a)  The assignment hx 1 D 1; \nx 2 D 1;x  3 D 0i to the inputs of this circuit causes the output of the circuit to be 1. The circuit \nis therefore  satis\u00fbable.  (b)  No assignment to the inputs of this circuit can cau se the output of the \ncircuit to be 1. The  circuit  is therefore  unsatis\u00fbable.  \nthe individual wires, given the input hx 1 D 1;x  2 D 1;x  3 D 0i. Although a single \nwire  may  have  no  more  than  one  combinational-element  output  connected to it, it \ncan feed several element inputs. The number of elem ent inputs fed by a wire is \ncalled the fan-out  of the wire. If no element output is connected to a  wire, the wire \nis a circuit  input , accepting input values from an external source. I f no element \ninput is connected to a wire, the wire is a circuit  output , providing the results of \nthe  circuit\u2019s  computation  to the  outside  world.  (An  interna l wire can also fan out \nto a circuit  output.)  For  the  purpose  of de\u00fbning  the  circuit-satis\u00fbability  problem,  \nwe limit the number of circuit outputs to 1, though in actual hardware design, a \nboolean combinational circuit may have multiple out puts. \nBoolean combinational circuits contain no cycles. I n other words, for a given \ncombinational circuit, imagine a directed graph G D .V;E/  with one vertex for \neach combinational element and with k directed  edges  for  each  wire  whose  fan-out  \nis k, where the graph contains a directed edge .u;v/  if a wire connects the output \nof element u to an input of element v. Then G must be acyclic. \nA truth  assignment  for a boolean combinational circuit is a set of boo lean input \nvalues. We say that a 1-output  boolean  combinational  circuit  is satis\ufb01able  if it has \na satisfying  assignment : a truth assignment that causes the output of the circuit \nto be 1. For  example,  the  circuit  in Figure  34.8(a)  has  the  satisfyi ng assignment \nhx 1 D 1;x  2 D 1;x  3 D 0i, and  so it is satis\u00fbable.  As  Exercise  34.3-1  asks  you  to \nshow, no assignment of values to x 1 , x 2 , and x 3 causes  the  circuit  in Figure  34.8(b)  \nto produce a 1 output. Since it always produces 0, it is unsatis\u00fbable.  \nThe circuit-satis\ufb01ability  problem  is, <Given  a boolean  combinational  circuit  \ncomposed  of AND,  OR,  and  NOT  gates,  is it satis\u00fbable?=  In order to pose this 34.3  NP-completeness  and  reducibility  1067 \nquestion formally, however, we must agree on a stan dard encoding for circuits. \nThe size  of a boolean combinational circuit is the number of  boolean combinational \nelements plus the number of wires in the circuit. W e could devise  a graph-like  en-  \ncoding that maps any given circuit C into a binary string hC i whose length is \npolynomial in the size of the circuit itself. As a formal language, we can therefore \nde\u00fbne  \nCIRCUIT-SAT  D fhC i W C is a satis\u00fbable  boolean  combinational  circuit g : \nThe  circuit-satis\u00fbability  problem  arises  in the  area  of computer-aided  hardware  \noptimization. If a subcircuit always produces 0, that subcircuit is unnecessary: \nthe designer can replace it by a simpler subcircuit  that omits all logic gates and \nprovides the constant 0 value as its output. You can see the value in havin g a \npolynomial-time  algorithm  for  this  problem.  \nGiven  a circuit  C , you  can  determine  whether  it is satis\u00fbable  by  simply  check-  \ning all possible assignments to the inputs. Unfortu nately, if the circuit has k in-  \nputs, then you would have to check up to 2 k possible assignments. When the \nsize of C is polynomial in k, checking all possible assignments to the inputs \ntakes \ufffd.2  k / time, which is superpolynomial in the size of the c ircuit. 10  In fact, \nas we have claimed, there is strong evidence that n o polynomial-time  algorithm  \nexists  that  solves  the  circuit-satis\u00fbability  problem  because  circuit  satis\u00fbability  is \nNP-complete.  We  break  the  proof  of this  fact  into  two  parts,  based on the two parts \nof the  de\u00fbnition  of NP-completeness.  \nLemma  34.5  \nThe  circuit-satis\u00fbability  problem  belongs  to the  class  NP.  \nProof  We  provide  a two-input,  polynomial-time  algorithm  A that can verify \nCIRCUIT-SAT.  One  of the  inputs  to A is (a standard  encoding  of)  a boolean  com-  \nbinational circuit C . The  other  input  is a certi\u00fbcate  corresponding  to an assignm ent \nof a boolean value to each of the wires in C . (See  Exercise  34.3-4  for  a smaller  \ncerti\u00fbcate.)  \nThe algorithm A works as follows. For each logic gate in the circui t, it checks \nthat  the  value  provided  by  the  certi\u00fbcate  on  the  output  wire  is correctly computed \nas a function of the values on the input wires. The n, if the output of the entire \ncircuit is 1, algorithm A outputs 1, since the values assigned to the inputs of C \nprovide  a satisfying  assignment.  Otherwise,  A outputs 0. \n10  On  the  other  hand,  if the  size  of the  circuit  C is \u201a.2  k /, then an algorithm whose running time \nis O.2  k / has a running time that is polynomial in the circui t size. Even if P \u00a4 NP,  this  situa-  \ntion  would  not  contradict  the  NP-completeness  of the  problem.  The  existence  of a polynomial-time  \nalgorithm for a special case does not imply that th ere is a polynomial-time  algorithm  for  all  cases.  1068 Chapter 34 NP-Completeness \nWhenever  a satis\u00fbable  circuit  C is input to algorithm A, there  exists  a certi\u00fbcate  \nwhose length is polynomial in the size of C and that causes A to output a 1. When-  \never  an unsatis\u00fbable  circuit  is input,  no  certi\u00fbcate  can  fool A into believing that the \ncircuit  is satis\u00fbable.  Algorithm  A runs  in polynomial  time,  and  with  a good  imple-  \nmentation,  linear  time  suf\u00fbces.  Thus,  CIRCUIT-SAT  is veri\u00fb able in polynomial \ntime,  and  CIRCUIT-SAT  2 NP. \nThe  second  part  of proving  that  CIRCUIT-SAT  is NP-complete  is to show that \nthe  language  is NP-hard:  that  every  language  in NP  is polynomial-time  reducible  \nto CIRCUIT-SAT.  The  actual  proof  of this  fact  is full  of techn ical intricacies, and \nso instead  we\u2019ll  sketch  the  proof  based  on  some  understandin g of the workings of \ncomputer hardware. \nA computer  program  is stored  in the  computer\u2019s  memory  as a sequence  of in-  \nstructions. A typical instruction encodes an operat ion to be performed, addresses \nof operands in memory, and an address where the res ult is to be stored. A special \nmemory location, called the program  counter , keeps track of which instruction \nis to be executed next. The program counter automat ically increments when each \ninstruction is fetched, thereby causing the compute r to execute  instructions  sequen-  \ntially. Certain instructions can cause a value to b e written to the program counter, \nhowever, which alters the normal sequential executi on and allows the computer to \nloop and perform conditional branches. \nAt  any  point  while  a program  executes,  the  computer\u2019s  memory  holds  the  en-  \ntire state of the computation. (Consider the memory  to include the program itself, \nthe program counter, working storage, and any of th e various bits of state that a \ncomputer maintains for bookkeeping.) We call any pa rticular state of computer \nmemory a con\ufb01guration . When  an instruction  executes,  it transforms  the  con\u00fbgu-  \nration.  Think  of an instruction  as mapping  one  con\u00fbguration  to another.  The  com-  \nputer hardware that accomplishes this mapping can b e implemented as a boolean \ncombinational circuit, which we denote by M  in the proof of the following lemma. \nLemma  34.6  \nThe  circuit-satis\u00fbability  problem  is NP-hard.  \nProof  Let L be any  language  in NP.  We\u2019ll  describe  a polynomial-time  algo-  \nrithm F computing a reduction function f that maps every binary string x to a \ncircuit C D f.x/  such that x 2 L if and only if C 2 CIRCUIT-SAT.  \nSince L 2 NP, there must exist an algorithm A that  veri\u00fbes  L in polynomial \ntime. The algorithm F that  we  construct  uses  the  two-input  algorithm  A to compute \nthe reduction function f . \nLet T.n/  denote  the  worst-case  running  time  of algorithm  A on  length-n input \nstrings, and let k \ue004 1 be a constant such that T.n/  D O.n  k / and the length of the 34.3  NP-completeness  and  reducibility  1069 \nM \nA PC y working storage A PC auxiliary machine state x y working storage \nM \nA PC y working storage \nM \nA PC y \n\u2026 \nworking storage \n0/1  output  M c 0 \nc 1 \nc 2 \nc T(n) auxiliary machine state x \nauxiliary machine state x \nauxiliary machine state x \nFigure  34.9  The  sequence  of con\u00fbgurations  produced  by  an  algorithm  A running on an input x and \ncerti\u00fbcate  y. Each  con\u00fbguration  represents  the  state  of the  computer  for  one step of the computation \nand, besides A, x, and y, includes the program counter (PC), auxiliary mach ine state, and working \nstorage.  Except  for  the  certi\u00fbcate  y, the  initial  con\u00fbguration  c 0 is constant. A boolean combinational \ncircuit M  maps  each  con\u00fbguration  to the  next  con\u00fbguration.  The  output  is a distinguished bit in the \nworking storage. \ncerti\u00fbcate  is O.n  k /. (The running time of A is actually a polynomial in the total \ninput  size,  which  includes  both  an input  string  and  a certi\u00fbc ate, but since the length \nof the  certi\u00fbcate  is polynomial  in the  length  n of the input string, the running time \nis polynomial in n.) \nThe basic idea of the proof is to represent the com putation of A as a sequence \nof con\u00fbgurations.  As  Figure  34.9  illustrates,  consider  each  con\u00fbguration  as com-  1070 Chapter 34 NP-Completeness \nprising a few parts: the program for A, the program counter and auxiliary machine \nstate, the input x , the  certi\u00fbcate  y , and  working  storage.  The  combinational  cir-  \ncuit M  , which  implements  the  computer  hardware,  maps  each  con\u00fbgur ation c i to \nthe  next  con\u00fbguration  c i C1 , starting  from  the  initial  con\u00fbguration  c 0 . Algorithm A \nwrites  its  output4 0 or 14to  some  designated  location  by  the  time  it \u00fbnishes  exe-  \ncuting. After A halts, the output value never changes. Thus, if the  algorithm runs \nfor at most T .n/  steps, the output appears as one of the bits in c T .n/  . \nThe reduction algorithm F constructs  a single  combinational  circuit  that  com-  \nputes  all  con\u00fbgurations  produced  by  a given  initial  con\u00fbgur ation. The idea is to \npaste together T .n/  copies of the circuit M  . The output of the i th circuit, which \nproduces  con\u00fbguration  c i , feeds directly into the input of the .i C1/st circuit. Thus, \nthe  con\u00fbgurations,  rather  than  being  stored  in the  computer\u2019s  memory,  simply  re-  \nside as values on the wires connecting copies of M  . \nRecall  what  the  polynomial-time  reduction  algorithm  F must  do.  Given  an in-  \nput x , it must compute a circuit C D f .x/  that  is satis\u00fbable  if and  only  if there  \nexists  a certi\u00fbcate  y such that A.x; y/  D 1. When F obtains an input x , it \u00fbrst  \ncomputes n D jx j and constructs a combinational circuit C 0 consisting of T .n/  \ncopies of M  . The input to C 0 is an initial  con\u00fbguration  corresponding  to a compu-  \ntation on A.x; y/, and  the  output  is the  con\u00fbguration  c T .n/  . \nAlgorithm F modi\u00fbes  circuit  C 0 slightly to construct the circuit C D f .x/ . \nFirst, it wires the inputs to C 0 corresponding to the program for A, the  initial  pro-  \ngram counter, the input x , and the initial state of memory directly to these  known \nvalues. Thus, the only remaining inputs to the circ uit correspond  to the  certi\u00fb-  \ncate y . Second, it ignores all outputs from C 0 , except for the one bit of c T .n/  \ncorresponding to the output of A. This circuit C , so constructed, computes \nC.y/  D A.x; y/  for any input y of length O.n  k /. The reduction algorithm F , \nwhen provided an input string x , computes such a circuit C and outputs it. \nWe need to prove two properties. First, we must sho w that F correctly computes \na reduction function f . That is, we must show that C is satis\u00fbable  if and  only  if \nthere  exists  a certi\u00fbcate  y such that A.x; y/  D 1. Second, we must show that F \nruns in polynomial time. \nTo show that F correctly computes a reduction function, suppose th at there ex-  \nists  a certi\u00fbcate  y of length O.n  k / such that A.x; y/  D 1. Then, upon applying \nthe bits of y to the inputs of C , the output of C is C.y/  D A.x; y/  D 1. Thus, if \na certi\u00fbcate  exists,  then  C is satis\u00fbable.  For  the  other  direction,  suppose  that  C is \nsatis\u00fbable.  Hence,  there  exists  an input  y to C such that C.y/  D 1, from which \nwe conclude that A.x; y/  D 1. Thus, F correctly computes a reduction function. \nTo complete the proof sketch, we need to show that F runs in time polynomial \nin n D jx j. First,  the  number  of bits  required  to represent  a con\u00fbguration  is poly-  \nnomial in n. Why?  The  program  for  A itself has constant size, independent of the \nlength of its input x . The length of the input x is n, and  the  length  of the  certi\u00fb-  34.3  NP-completeness  and  reducibility  1071 \ncate y is O.n  k /. Since the algorithm runs for at most O.n  k / steps, the amount of \nworking storage required by A is polynomial in n as well. (We implicitly assume \nthat  this  memory  is contiguous.  Exercise  34.3-5  asks  you  to extend the argument \nto the situation in which the locations accessed by  A are scattered across a much \nlarger region of memory and the particular pattern of scattering can differ for each \ninput x .) \nThe combinational circuit M  implementing the computer hardware has size \npolynomial  in the  length  of a con\u00fbguration,  which  is O.n  k /, and hence, the size \nof M  is polynomial in n. (Most  of this  circuitry  implements  the  logic  of the  mem-  \nory system.) The circuit C consists of O.n  k / copies of M  , and hence it has size \npolynomial in n. The reduction algorithm F can construct C from x in polynomial \ntime, since each step of the construction takes pol ynomial time. \nThe  language  CIRCUIT-SAT  is therefore  at least  as hard  as any  language in NP, \nand  since  it belongs  to NP,  it is NP-complete.  \nTheorem  34.7  \nThe  circuit-satis\u00fbability  problem  is NP-complete.  \nProof  Immediate  from  Lemmas  34.5  and  34.6  and  from  the  de\u00fbnition  of NP-  \ncompleteness. \nExercises  \n34.3-1  \nVerify  that  the  circuit  in Figure  34.8(b)  is unsatis\u00fbable.  \n34.3-2  \nShow that the \u0dc4 P relation is a transitive relation on languages. Tha t is, show that if \nL 1 \u0dc4 P L 2 and L 2 \u0dc4 P L 3 , then L 1 \u0dc4 P L 3 . \n34.3-3  \nProve that L \u0dc4 P L if and only if L \u0dc4 P L. \n34.3-4  \nShow  that  an alternative  proof  of Lemma  34.5  can  use  a satisfy ing assignment as a \ncerti\u00fbcate.  Which  certi\u00fbcate  makes  for  an easier  proof?  \n34.3-5  \nThe  proof  of Lemma  34.6  assumes  that  the  working  storage  for  algorithm A oc-  \ncupies a contiguous region of polynomial size. Wher e does the proof exploit this \nassumption?  Argue  that  this  assumption  does  not  involve  any  loss of generality. 1072 Chapter 34 NP-Completeness \n34.3-6  \nA language L is complete  for a language class C with  respect  to polynomial-time  \nreductions if L 2 C and L 0 \u0dc4 P L for all L 0 2 C . Show that ; and f0; 1g \ue003 are the \nonly languages in P that are not complete for P wit h respect to polynomial-time  \nreductions. \n34.3-7  \nShow  that,  with  respect  to polynomial-time  reductions  (see  Exercise  34.3-6),  L is \ncomplete for NP if and only if L is complete  for  co-NP.  \n34.3-8  \nThe reduction algorithm F in the  proof  of Lemma  34.6  constructs  the  circuit  \nC D f .x/  based on knowledge of x , A, and k. Professor Sartre observes that \nthe string x is input to F , but only the existence of A, k, and the constant factor \nimplicit in the O.n  k / running time is known to F (since the language L belongs \nto NP), not their actual values. Thus, the professo r concludes that F cannot  possi-  \nbly construct the circuit C and  that  the  language  CIRCUIT-SAT  is not  necessarily  \nNP-hard.  Explain  the  \u00fcaw  in the  professor\u2019s  reasoning.  \n34.4  NP-completeness  proofs  \nThe  proof  that  the  circuit-satis\u00fbability  problem  is NP-com plete showed directly \nthat L \u0dc4 P CIRCUIT-SAT  for  every  language  L 2 NP. This section shows how \nto prove  that  languages  are  NP-complete  without  directly  reducing every  language \nin NP  to the  given  language.  We\u2019ll  explore  examples  of this  methodology  by  prov-  \ning  that  various  formula-satis\u00fbability  problems  are  NP-complete.  Section  34.5  pro-  \nvides many more examples. \nThe following lemma provides a foundation for showi ng that a given language \nis NP-complete.  \nLemma  34.8  \nIf L is a language such that L 0 \u0dc4 P L for some L 0 2 NPC, then L is NP-hard.  If, in \naddition, we have L 2 NP, then L 2 NPC. \nProof  Since L 0 is NP-complete,  for  all  L 00 2 NP, we have L 00 \u0dc4 P L 0 . By  sup-  \nposition, we have L 0 \u0dc4 P L, and  thus  by  transitivity  (Exercise  34.3-2),  we  have  \nL 00 \u0dc4 P L, which shows that L is NP-hard.  If L 2 NP, we also have L 2 NPC. 34.4  NP-completeness  proofs  1073 \nIn other  words,  by  reducing  a known  NP-complete  language  L 0 to L, we  implic-  \nitly reduce every language in NP to L. Thus,  Lemma  34.8  provides  a method  for  \nproving that a language L is NP-complete:  \n1. Prove  L 2 NP. \n2. Prove that L is NP-hard:  \na. Select  a known  NP-complete  language  L 0 . \nb. Describe an algorithm that computes a function f mapping every instance \nx 2 f0; 1g \ue003 of L 0 to an instance f .x/  of L. \nc. Prove that the function f satis\u00fbes  x 2 L 0 if and only if f .x/  2 L for all \nx 2 f0; 1g \ue003 . \nd. Prove that the algorithm computing f runs in polynomial time. \nThis  methodology  of reducing  from  a single  known  NP-complet e language is far \nsimpler than the more complicated process of showin g directly how to reduce from \nevery  language  in NP.  Proving  CIRCUIT-SAT  2 NPC furnishes a starting point. \nKnowing  that  the  circuit-satis\u00fbability  problem  is NP-complete  makes  it much  eas-  \nier  to prove  that  other  problems  are  NP-complete.  Moreover,  as the catalog of \nknown  NP-complete  problems  grows,  so will  the  choices  for  languages from which \nto reduce. \nFormula  satis\ufb01ability  \nTo  illustrate  the  reduction  methodology,  let\u2019s  see  an NP-co mpleteness proof for \nthe problem of determining whether a boolean formula , not a circuit, is satis\u00fbable.  \nThis  problem  has  the  historical  honor  of being  the  \u00fbrst  probl em ever shown to be \nNP-complete.  \nWe formulate the (formula)  satis\ufb01ability  problem in terms of the language SAT \nas follows. An instance of SAT is a boolean formula  \ufffd composed of \n1. n boolean variables: x 1 ; x  2 ; : : : ; x  n ; \n2. m boolean connectives: any boolean function with one or two inputs and one \noutput, such as ^ (AND), _ (OR),  : (NOT),  !  (implication), $  (if and only \nif); and \n3. parentheses.  (Without  loss  of generality,  assume  that  there are no redundant \nparentheses, i.e., a formula contains at most one p air of parentheses per boolean \nconnective.) \nWe can encode a boolean formula \ufffd in a length that is polynomial in n C m. As \nin boolean combinational circuits, a truth  assignment  for a boolean formula \ufffd 1074 Chapter 34 NP-Completeness \nis a set of values for the variables of \ufffd, and a satisfying  assignment  is a truth \nassignment that causes it to evaluate to 1. A formula with a satisfying assignment \nis a satis\ufb01able  formula.  The  satis\u00fbability  problem  asks  whether  a given  boolean \nformula  is satis\u00fbable,  which  we  can  express  in formal-langu age terms as \nSAT D fh\ufffdi W \ufffd is a satis\u00fbable  boolean  formula g : \nAs an example, the formula \n\ufffd D ..x  1 !  x 2 / _ :..:x 1 $  x 3 / _ x 4 // ^ :x 2 \nhas the satisfying assignment hx 1 D 0; x  2 D 0; x  3 D 1; x  4 D 1i, since \n\ufffd D ..0  !  0/ _ :..:0 $  1/ _ 1//  ^ :0 (34.2)  \nD .1 _ :.1 _ 1//  ^ 1 \nD .1 _ 0/ ^ 1 \nD 1 ;  \nand thus this formula \ufffd belongs to SAT. \nThe naive algorithm to determine whether an arbitra ry boolean formula  is satis-  \n\u00fbable  does  not  run  in polynomial  time.  A formula  with  n variables has 2 n possible \nassignments. If the length of h\ufffdi is polynomial in n, then  checking  every  assign-  \nment requires \ufffd.2  n / time, which is superpolynomial in the length of h\ufffdi. As the \nfollowing  theorem  shows,  a polynomial-time  algorithm  is unlikely to exist. \nTheorem  34.9  \nSatis\u00fbability  of boolean  formulas  is NP-complete.  \nProof  We start by arguing that SAT 2 NP.  Then  we  prove  that  SAT  is NP-hard  \nby  showing  that  CIRCUIT-SAT  \u0dc4 P SAT,  which  by  Lemma  34.8  will  prove  the  \ntheorem. \nTo  show  that  SAT  belongs  to NP,  we  show  that  a certi\u00fbcate  consi sting of a \nsatisfying assignment for an input formula \ufffd can  be veri\u00fbed  in polynomial  time.  \nThe verifying algorithm simply replaces each variab le in the formula  with  its  cor-  \nresponding value and then evaluates the expression,  much as we  did  in equa-  \ntion  (34.2)  above.  This  task  can  be done  in polynomial  time.  If the expression \nevaluates to 1, then  the  algorithm  has  veri\u00fbed  that  the  formula  is satis\u00fbab le. Thus, \nSAT belongs to NP. \nTo  prove  that  SATis  NP-hard,  we  show  that  CIRCUIT-SAT  \u0dc4 P SAT. In other \nwords, we need to show how to reduce any instance o f circuit satis\u00fbability  to an \ninstance  of formula  satis\u00fbability  in polynomial  time.  We  can use induction to \nexpress any boolean combinational circuit as a bool ean formula. We simply look \nat the gate that produces the circuit output and in ductively express each of the 34.4  NP-completeness  proofs  1075 \nx 6 \nx 3 x 4 x 7 x 10  x 9 x 8 x 5 \nx 2 x 1 \nFigure  34.10  Reducing  circuit  satis\u00fbability  to formula  satis\u00fbability.  The formula produced by the \nreduction algorithm has a variable for each wire in  the circuit and a clause for each logic gate. \ngate\u2019s  inputs  as formulas.  We  then  obtain  the  formula  for  the  circuit by writing an \nexpression  that  applies  the  gate\u2019s  function  to its  inputs\u2019  formulas. \nUnfortunately, this straightforward method does not  amount to a polynomial-  \ntime  reduction.  As  Exercise  34.4-1  asks  you  to show,  shared  subformulas4which  \narise  from  gates  whose  output  wires  have  fan-out  of 2 or more4can  cause  the  \nsize of the generated formula to grow exponentially . Thus, the reduction algorithm \nmust be somewhat more clever. \nFigure  34.10  illustrates  how  to overcome  this  problem,  using as an example the \ncircuit  from  Figure  34.8(a).  For  each  wire  x i in the circuit C , the formula \ufffd has a \nvariable x i . To express how each gate operates, construct a sm all formula involving \nthe variables of its incident wires. The formula ha s the form of an <if and only if= \n($), with  the  variable  for  the  gate\u2019s  output  on  the  left  and  on  the  right  a logical  ex-  \npression  encapsulating  the  gate\u2019s  function  on  its  inputs.  For example, the operation \nof the  output  AND  gate  (the  rightmost  gate  in the  \u00fbgure)  is x 10  $  .x 7 ^ x 8 ^ x 9 /. \nWe call each of these small formulas a clause . \nThe formula \ufffd produced by the reduction algorithm is the AND of t he circuit- \noutput variable with the conjunction of clauses des cribing the operation of each \ngate.  For  the  circuit  in the  \u00fbgure,  the  formula  is \n\ufffd D x 10  ^ .x 4 $ :x 3 / \n^ .x 5 $  .x 1 _ x 2 // \n^ .x 6 $ :x 4 / \n^ .x 7 $  .x 1 ^ x 2 ^ x 4 // \n^ .x 8 $  .x 5 _ x 6 // \n^ .x 9 $  .x 6 _ x 7 // \n^ .x 10  $  .x 7 ^ x 8 ^ x 9 // :  1076 Chapter 34 NP-Completeness \nGiven  a circuit  C , it is straightforward to produce such a formula \ufffd in polynomial \ntime. \nWhy is the circuit C satis\u00fbable  exactly  when  the  formula  \ufffd is satis\u00fbable?  If \nC has a satisfying assignment, then each wire of the circuit has a well-de\u00fbned  \nvalue, and the output of the circuit is 1. Therefore,  when  wire  values  are  as-  \nsigned to variables in \ufffd, each clause of \ufffd evaluates to 1, and thus the conjunction \nof all evaluates to 1. Conversely, if some assignment causes \ufffd to evaluate to 1, \nthe circuit C is satis\u00fbable  by  an analogous  argument.  Thus,  we  have  shown  that \nCIRCUIT-SAT  \u0dc4 P SAT, which completes the proof. \n3-CNF  satis\ufb01ability  \nReducing  from  formula  satis\u00fbability  gives  us an avenue  to prove many problems \nNP-complete.  The  reduction  algorithm  must  handle  any  input  formula, though, \nand this requirement can lead to a huge number of c ases to consider. Instead, \nit is usually simpler to reduce from a restricted l anguage of boolean formulas. \nOf  course,  the  restricted  language  must  not  be polynomial-time  solvable.  One  \nconvenient  language  is 3-CNF  satis\u00fbability,  or 3-CNF-SAT.  \nIn order  to de\u00fbne  3-CNF  satis\u00fbability,  we  \u00fbrst  need  to de\u00fbne  a few terms. A \nliteral  in a boolean formula is an occurrence of a variable  (such as x 1 ) or its  nega-  \ntion ( :x 1 ). A clause  is the  OR  of one  or more  literals,  such  as x 1 _ :x 2 _ :x 3 . \nA boolean formula is in conjunctive  normal  form , or CNF , if it is expressed as an \nAND  of clauses,  and  it\u2019s  in 3-conjunctive  normal  form , or 3-CNF , if each clause \ncontains exactly three distinct literals. \nFor example, the boolean formula \n.x 1 _ :x 1 _ :x 2 / ^ .x 3 _ x 2 _ x 4 / ^ .:x 1 _ :x 3 _ :x 4 / \nis in 3-CNF.  The  \u00fbrst  of its  three  clauses  is .x 1 _ :x 1 _ :x 2 /, which contains the \nthree literals x 1 , :x 1 , and :x 2 . \nThe  language  3-CNF-SAT  consists  of encodings  of boolean  formulas  in 3-CNF  \nthat  are  satis\u00fbable.  The  following  theorem  shows  that  a polynomial-time  algorithm  \nthat  can  determine  the  satis\u00fbability  of boolean  formulas  is unlikely to exist, even \nwhen they are expressed in this simple normal form.  \nTheorem  34.10  \nSatis\u00fbability  of boolean  formulas  in 3-conjunctive  normal  form  is NP-complete.  \nProof  The  argument  from  the  proof  of Theorem  34.9  to show  that  SAT  2 NP  ap-  \nplies  equally  well  here  to show  that  3-CNF-SAT  2 NP.  By  Lemma  34.8,  therefore,  \nwe need only show that SAT \u0dc4 P 3-CNF-SAT.  34.4  NP-completeness  proofs  1077 \n:x 1 x 1 :x 2 \nx 2 \nx 3 x 4 y 1 \ny 2 \ny 3 y 4 \ny 5 \ny 6 ^ \n$  _ \n_ : !  \nFigure  34.11  The tree corresponding to the formula \ufffd D ..x  1 !x 2 /_:..:x 1 $x 3 /_x 4 //^:x 2 : \nWe break the reduction algorithm into three basic s teps. Each step progressively \ntransforms the input formula \ufffd closer  to the  desired  3-conjunctive  normal  form.  \nThe  \u00fbrst  step  is similar  to the  one  used  to prove  CIRCUIT-SAT  \u0dc4 P SAT in \nTheorem  34.9.  First,  construct  a binary  <parse=  tree  for  the  input formula \ufffd, with \nliterals as leaves and connectives as internal node s. Figure 34.11  shows  such  a \nparse tree for the formula \n\ufffd D ..x  1 !  x 2 / _ :..:x 1 $  x 3 / _ x 4 // ^ :x 2 : (34.3)  \nIf the  input  formula  contains  a clause  such  as the  OR  of several  literals,  use  as-  \nsociativity to parenthesize the expression fully so  that every internal node in the \nresulting tree has just one or two children. The bi nary parse tree is like a circuit for \ncomputing the function. \nMimicking  the  reduction  in the  proof  of Theorem  34.9,  introd uce a variable y i \nfor the output of each internal node. Then rewrite the original formula \ufffd as the \nAND of the variable at the root of the parse tree a nd a conjunction of clauses \ndescribing  the  operation  of each  node.  For  the  formula  (34.3),  the  resulting  expres-  \nsion is \n\ufffd 0 D y 1 ^ .y 1 $  .y 2 ^ :x 2 // \n^ .y 2 $  .y 3 _ y 4 // \n^ .y 3 $  .x 1 !  x 2 // \n^ .y 4 $ :y 5 / \n^ .y 5 $  .y 6 _ x 4 // \n^ .y 6 $  .:x 1 $  x 3 // :  1078 Chapter 34 NP-Completeness \ny 1 y 2 x 2 .y 1 $  .y 2 ^ :x 2 // \n1 1 1 0 \n1 1 0 1 \n1 0 1 0 \n1 0 0 0 \n0 1 1 1 \n0 1 0 0 \n0 0 1 1 \n0 0 0 1 \nFigure  34.12  The truth table for the clause .y 1 $  .y 2 ^ :x 2 //. \nThe formula \ufffd 0 thus obtained is a conjunction of clauses \ufffd 0 \ni , each of which has at \nmost  three  literals.  These  clauses  are  not  yet  ORs  of three  literals. \nThe second step of the reduction converts each clau se \ufffd 0 \ni into  conjunctive  nor-  \nmal form. Construct a truth table for \ufffd 0 \ni by evaluating all possible assignments to \nits variables. Each row of the truth table consists  of a possible assignment of the \nvariables of the clause, together with the value of  the clause under that assignment. \nUsing  the  truth-table  entries  that  evaluate  to 0, build a formula in disjunctive  nor-  \nmal  form  (or DNF)4an  OR  of ANDs4that  is equivalent  to :\ufffd 0 \ni . Then negate \nthis formula and convert it into a CNF formula \ufffd 00 \ni by using DeMorgan\u2019s  laws  for \npropositional logic, \n:.a ^ b/ D :a _ :b ;  \n:.a _ b/ D :a ^ :b ;  \nto complement  all  literals,  change  ORs  into  ANDs,  and  change  ANDs  into  ORs.  \nIn our example, the clause \ufffd 0 \n1 D .y 1 $  .y 2 ^ :x 2 // converts  into  CNF  as fol-  \nlows. The truth table for \ufffd 0 \n1 appears  in Figure  34.12.  The  DNF  formula  equivalent  \nto :\ufffd 0 \n1 is \n.y 1 ^ y 2 ^ x 2 / _ .y 1 ^ :y 2 ^ x 2 / _ .y 1 ^ :y 2 ^ :x 2 / _ .:y 1 ^ y 2 ^ :x 2 / : \nNegating  and  applying  DeMorgan\u2019s  laws  yields  the  CNF  formul a \n\ufffd 00 \n1 D .:y 1 _ :y 2 _ :x 2 / ^ .:y 1 _ y 2 _ :x 2 / \n^ .:y 1 _ y 2 _ x 2 / ^ .y 1 _ :y 2 _ x 2 / ; \nwhich is equivalent to the original clause \ufffd 0 \n1 . \nAt this point, each clause \ufffd 0 \ni of the formula \ufffd 0 has been converted into a CNF \nformula \ufffd 00 \ni , and thus \ufffd 0 is equivalent to the CNF formula \ufffd 00 consisting of the \nconjunction of the \ufffd 00 \ni . Moreover, each clause of \ufffd 00 has at most three literals. 34.4  NP-completeness  proofs  1079 \nThe  third  and  \u00fbnal  step  of the  reduction  further  transforms  the formula so that \neach clause has exactly  three  distinct  literals.  From  the  clauses  of the  CNF  for-  \nmula \ufffd 00 , construct  the  \u00fbnal  3-CNF  formula  \ufffd 000 . This  formula  also  uses  two  aux-  \niliary variables, p and q. For each clause C i of \ufffd 00 , include the following clauses \nin \ufffd 000 : \n\ue001 If C i contains three distinct literals, then simply inclu de C i as a clause of \ufffd 000 . \n\ue001 If C i contains exactly two distinct literals, that is, if  C i D .l 1 _ l 2 /, where l 1 \nand l 2 are literals, then include .l 1 _ l 2 _ p/  ^ .l 1 _ l 2 _ :p/  as clauses of \ufffd 000 . \nThe literals p and :p merely  ful\u00fbll  the  syntactic  requirement  that  each  clause  \nof \ufffd 000 contain exactly three distinct literals. Whether p D 0 or p D 1, one of \nthe clauses is equivalent to l 1 _ l 2 , and the other evaluates to 1, which is the \nidentity for AND. \n\ue001 If C i contains just one distinct literal l , then include .l _ p _ q/ ^ .l _ p _:q/ ^ \n.l _ :p _ q/ ^ .l _ :p _ :q/ as clauses of \ufffd 000 . Regardless of the values of \np and q, one of the four clauses is equivalent to l , and the other three evaluate \nto 1. \nWe  can  see  that  the  3-CNF  formula  \ufffd 000 is satis\u00fbable  if and  only  if \ufffd is satis\u00fbable  \nby inspecting each of the three steps. Like the red uction from CIRCUIT-SAT  to \nSAT, the construction of \ufffd 0 from \ufffd in the  \u00fbrst  step  preserves  satis\u00fbability.  The  sec-  \nond step produces a CNF formula \ufffd 00 that is algebraically equivalent to \ufffd 0 . Then the \nthird  step  produces  a 3-CNF  formula  \ufffd 000 that is effectively equivalent to \ufffd 00 , since \nany assignment to the variables p and q produces a formula that is algebraically \nequivalent to \ufffd 00 . \nWe must also show that the reduction can be compute d in polynomial  time.  Con-  \nstructing \ufffd 0 from \ufffd introduces at most one variable and one clause per connective \nin \ufffd. Constructing \ufffd 00 from \ufffd 0 can introduce at most eight clauses into \ufffd 00 for \neach clause from \ufffd 0 , since each clause of \ufffd 0 contains at most three variables, and \nthe truth table for each clause has at most 2 3 D 8 rows. The construction of \ufffd 000 \nfrom \ufffd 00 introduces at most four clauses into \ufffd 000 for each clause of \ufffd 00 . Thus the \nsize of the resulting formula \ufffd 000 is polynomial in the length of the original formula . \nEach of the constructions can be accomplished in po lynomial time. \nExercises  \n34.4-1  \nConsider  the  straightforward  (nonpolynomial-time)  reduction  in the  proof  of The-  \norem  34.9.  Describe  a circuit  of size  n that, when converted to a formula by this \nmethod, yields a formula whose size is exponential in n. 1080 Chapter 34 NP-Completeness \n34.4-2  \nShow  the  3-CNF  formula  that  results  upon  using  the  method  of Theorem  34.10  on  \nthe  formula  (34.3).  \n34.4-3  \nProfessor  Jagger  proposes  to show  that  SAT  \u0dc4 P 3-CNF-SAT  by  using  only  the  \ntruth-table  technique  in the  proof  of Theorem  34.10,  and  not  the other steps. That \nis, the professor proposes to take the boolean form ula \ufffd, form a truth table for \nits  variables,  derive  from  the  truth  table  a formula  in 3-DNF  that is equivalent \nto :\ufffd, and  then  negate  and  apply  DeMorgan\u2019s  laws  to produce  a 3-CNF  formula \nequivalent to \ufffd. Show  that  this  strategy  does  not  yield  a polynomial-time  reduction. \n34.4-4  \nShow that the problem of determining whether a bool ean formula is a tautology is \ncomplete  for  co-NP.  (Hint: See  Exercise  34.3-7.)  \n34.4-5  \nShow  that  the  problem  of determining  the  satis\u00fbability  of boolean  formulas  in dis-  \njunctive  normal  form  is polynomial-time  solvable.  \n34.4-6  \nSomeone  gives  you  a polynomial-time  algorithm  to decide  formula  satis\u00fbability.  \nDescribe  how  to use  this  algorithm  to \u00fbnd  satisfying  assignm ents in polynomial \ntime. \n34.4-7  \nLet  2-CNF-SAT  be the  set  of satis\u00fbable  boolean  formulas  in CNF with exactly two \nliterals  per  clause.  Show  that  2-CNF-SAT  2 P. Make  your  algorithm  as ef\u00fbcient  as \npossible. ( Hint: Observe  that  x _ y is equivalent to :x !  y . Reduce  2-CNF-SAT  \nto an ef\u00fbciently  solvable  problem  on  a directed  graph.)  \n34.5  NP-complete  problems  \nNP-complete  problems  arise  in diverse  domains:  boolean  logic,  graphs,  arith-  \nmetic, network design, sets and partitions, storage  and retrieval, sequencing and \nscheduling, mathematical programming, algebra and n umber theory, games and \npuzzles, automata and language theory, program opti mization, biology, chemistry, \nphysics, and more. This section uses the reduction methodology  to provide  NP-  \ncompleteness proofs for a variety of problems drawn  from graph theory and set \npartitioning. 34.5  NP-complete  problems  1081 \nCIRCUIT-SAT  \nSAT \n3-CNF-SAT  \nCLIQUE  \nVERTEX-COVER  SUBSET-SUM  \nHAM-CYCLE  \nTSP \nFigure  34.13  The  structure  of NP-completeness  proofs  in Sections  34.4  and  34.5.  All  proofs  ulti-  \nmately  follow  by  reduction  from  the  NP-completeness  of CIRCUIT-SAT.  \nFigure  34.13  outlines  the  structure  of the  NP-completeness  proofs in this section \nand  Section  34.4.  We  prove  each  language  in the  \u00fbgure  to be NP-complete by \nreduction from the language that points to it. At t he root is CIRCUIT-SAT,  which  \nwe  proved  NP-complete  in Theorem  34.7.  This  section  conclud es with a recap of \nreduction strategies. \n34.5.1  The  clique  problem  \nA clique  in an undirected graph G D .V;E/  is a subset V 0 \u0dc2 V of vertices, each \npair of which is connected by an edge in E. In other words, a clique is a complete \nsubgraph of G. The size  of a clique is the number of vertices it contains. The \nclique  problem  is the  optimization  problem  of \u00fbnding  a clique  of maximum  size \nin a graph. The corresponding decision problem asks  simply whether a clique of a \ngiven size k exists  in the  graph.  The  formal  de\u00fbnition  is \nCLIQUE  D fhG;ki W G is a graph containing a clique of size kg : \nA naive algorithm for determining whether a graph G D .V;E/  with jV j ver-  \ntices contains a clique of size k lists all k-subsets  of V and checks each one to \nsee whether it forms a clique. The running time of this algorithm is \ufffd.k  2 \u00e3 jV j \nk \u00e4 \n/, \nwhich is polynomial if k is a constant. In general, however, k could be near jV j =2, \nin which case the algorithm runs in superpolynomial  time. Indeed,  an ef\u00fbcient  \nalgorithm for the clique problem is unlikely to exi st. 1082 Chapter 34 NP-Completeness \nTheorem  34.11  \nThe  clique  problem  is NP-complete.  \nProof  First,  we  show  that  CLIQUE  2 NP. For a given graph G D .V;E/ , use the \nset V 0 \u0dc2 V of vertices  in the  clique  as a certi\u00fbcate  for  G. To check whether V 0 is a \nclique in polynomial time, check whether, for each pair u;v  2 V 0 , the edge .u;v/  \nbelongs to E. \nWe  next  prove  that  3-CNF-SAT  \u0dc4 P CLIQUE,  which  shows  that  the  clique  prob-  \nlem  is NP-hard.  You  might  be surprised  that  the  proof  reduces  an instance of \n3-CNF-SAT  to an instance  of CLIQUE,  since  on  the  surface  logical formulas seem \nto have little to do with graphs. \nThe  reduction  algorithm  begins  with  an instance  of 3-CNF-SA  T. Let \ufffd D \nC 1 ^ C 2 ^ \ue001 \ue001 \ue001 ^  C k be a boolean  formula  in 3-CNF  with  k clauses. For r D \n1;2;:::;k , each clause C r contains exactly three distinct literals: l r \n1 , l r \n2 , and l r \n3 . \nWe will construct a graph G such that \ufffd is satis\u00fbable  if and  only  if G contains a \nclique of size k. \nWe construct the undirected graph G D .V;E/  as follows. For each clause C r D \n.l r \n1 _ l r \n2 _ l r \n3 / in \ufffd, place a triple of vertices v r \n1 , v r \n2 , and v r \n3 into V . Add edge .v r \ni ;v  s \nj / \ninto E if both of the following hold: \n\ue001 v r \ni and v s \nj are in different triples, that is, r \u00a4 s , and \n\ue001 their corresponding literals are consistent , that is, l r \ni is not the negation of l s \nj . \nWe can build this graph from \ufffd in polynomial  time.  As  an example  of this  con-  \nstruction, if \n\ufffd D .x 1 _ :x 2 _ :x 3 / ^ .:x 1 _ x 2 _ x 3 / ^ .x 1 _ x 2 _ x 3 /; \nthen G is the  graph  shown  in Figure  34.14.  \nWe must show that this transformation of \ufffd into G is a reduction. First, suppose \nthat \ufffd has a satisfying assignment. Then each clause C r contains at least one \nliteral l r \ni that is assigned 1, and each such literal corresponds to a vertex v r \ni . Picking \none such <true= literal from each clause yields a s et V 0 of k vertices. We claim that \nV 0 is a clique. For any two vertices v r \ni ;v  s \nj 2 V 0 , where r \u00a4 s , both corresponding \nliterals l r \ni and l s \nj map to 1 by the given satisfying assignment, and thus the li terals \ncannot be complements. Thus, by the construction of  G, the edge .v r \ni ;v  s \nj / belongs \nto E. \nConversely, suppose that G contains a clique V 0 of size k. No edges in G con-  \nnect vertices in the same triple, and so V 0 contains exactly one vertex per triple. If \nv r \ni 2 V 0 , then assign 1 to the corresponding literal l r \ni . Since G contains no edges \nbetween inconsistent literals, no literal and its c omplement are both assigned 1. \nEach  clause  is satis\u00fbed,  and  so \ufffd is satis\u00fbed.  (Any  variables  that  do  not  correspond  \nto a vertex in the clique may be set arbitrarily.) 34.5  NP-complete  problems  1083 \nx 1 x 1 \nx 2 x 2 \nx 3 x 3 :x 1 :x 2 :x 3 C 1 D x 1 _ :x 2 _ :x 3 \nC 2 D :x 1 _ x 2 _ x 3 C 3 D x 1 _ x 2 _ x 3 \nFigure  34.14  The graph G derived  from  the  3-CNF  formula  \ufffd D C 1 ^ C 2 ^ C 3 , where C 1 D \n.x 1 _ :x 2 _ :x 3 /, C 2 D .:x 1 _ x 2 _ x 3 /, and C 3 D .x 1 _ x 2 _ x 3 /, in reducing  3-CNF-SAT  \nto CLIQUE.  A satisfying  assignment  of the  formula  has  x 2 D 0, x 3 D 1, and x 1 set to either 0 \nor 1. This  assignment  satis\u00fbes  C 1 with :x 2 , and  it satis\u00fbes  C 2 and C 3 with x 3 , corresponding to \nthe clique with blue vertices. \nIn the  example  of Figure  34.14,  a satisfying  assignment  of \ufffd has x 2 D 0 \nand x 3 D 1. A corresponding clique of size k D 3 consists  of the  vertices  cor-  \nresponding to :x 2 from  the  \u00fbrst  clause,  x 3 from the second clause, and x 3 from \nthe third clause. Because the clique contains no ve rtices corresponding to either x 1 \nor :x 1 , this satisfying assignment can set x 1 to either 0 or 1. \nThe  proof  of Theorem  34.11  reduced  an arbitrary  instance  of 3-CNF-SAT  to an \ninstance  of CLIQUE  with  a particular  structure.  You  might  think that we have \nshown  only  that  CLIQUE  is NP-hard  in graphs  in which  the  vertices are restricted \nto occur in triples and in which there are no edges  between vertices in the same \ntriple.  Indeed,  we  have  shown  that  CLIQUE  is NP-hard  only  in this restricted case, \nbut  this  proof  suf\u00fbces  to show  that  CLIQUE  is NP-hard  in general  graphs.  Why?  \nIf there  were  a polynomial-time  algorithm  that  solves  CLIQU E on general graphs, \nit would  also  solve  CLIQUE  on  restricted  graphs.  \nThe  opposite  approach4reducing  instances  of 3-CNF-SAT  with  a special  struc-  \nture  to general  instances  of CLIQUE4does  not  suf\u00fbce,  however.  Why  not?  Per-  \nhaps  the  instances  of 3-CNF-SAT  that  we  choose  to reduce  from  are <easy,= and so \nwe  would  not  have  reduced  an NP-hard  problem  to CLIQUE.  \nMoreover,  the  reduction  uses  the  instance  of 3-CNF-SAT,  but  not the solution. \nWe  would  have  erred  if the  polynomial-time  reduction  had  relied on knowing 1084 Chapter 34 NP-Completeness \nu \ny x z w \n(a) u \ny x z w \n(b) v v \nFigure  34.15  Reducing  CLIQUE  to VERTEX-COVER.  (a)  An undirected graph G D .V;E/  with \nclique V 0 D fu;v;x;y g, shown in blue. (b)  The graph G produced by the reduction algorithm that \nhas vertex cover V \ue003 V 0 D fw;\u00b4g, in blue. \nwhether the formula \ufffd is satis\u00fbable,  since  we  do  not  know  how  to decide  whether  \n\ufffd is satis\u00fbable  in polynomial  time.  \n34.5.2  The  vertex-cover  problem  \nA vertex  cover  of an undirected graph G D .V;E/  is a subset V 0 \u0dc2 V such that \nif .u;v/  2 E, then u 2 V 0 or v 2 V 0 (or both). That is, each vertex <covers= its \nincident edges, and a vertex cover for G is a set of vertices that covers all the edges \nin E. The size  of a vertex cover is the number of vertices in it. For example, the \ngraph  in Figure  34.15(b)  has  a vertex  cover  fw;\u00b4g of size 2. \nThe vertex-cover  problem  is to \u00fbnd  a vertex  cover  of minimum  size  in a given  \ngraph. For this optimization problem, the correspon ding decision problem asks \nwhether a graph has a vertex cover of a given size k. As  a language,  we  de\u00fbne  \nVERTEX-COVER  D fhG;ki W graph G has a vertex cover of size kg : \nThe  following  theorem  shows  that  this  problem  is NP-complet e. \nTheorem  34.12  \nThe  vertex-cover  problem  is NP-complete.  \nProof  We  \u00fbrst  show  that  VERTEX-COVER  2 NP.  Given  a graph  G D .V;E/  \nand an integer k, the  certi\u00fbcate  is the  vertex  cover  V 0 \u0dc2 V itself.  The  veri\u00fbcation  \nalgorithm  af\u00fbrms  that  jV 0 j D  k, and then it checks, for each edge .u;v/  2 E, that \nu 2 V 0 or v 2 V 0 . It is easy  to verify  the  certi\u00fbcate  in polynomial  time.  \nTo  prove  that  the  vertex-cover  problem  is NP-hard,  we  reduce  from the clique \nproblem,  showing  that  CLIQUE  \u0dc4 P VERTEX-COVER.  This  reduction  relies  34.5  NP-complete  problems  1085 \non  the  notion  of the  complement  of a graph.  Given  an undirecte d graph G D \n.V;E/, we  de\u00fbne  the  complement  of G as a graph G D .V;  E/, where E D \nf.u;v/  W u;v  2 V;u  \u00a4 v; and .u;v/  \u2026 Eg. In other words, G is the  graph  con-  \ntaining exactly those edges that are not in G. Figure  34.15  shows  a graph  and  its  \ncomplement  and  illustrates  the  reduction  from  CLIQUE  to VERTEX-COVER.  \nThe reduction algorithm takes as input an instance hG;ki of the clique problem \nand computes the complement G in polynomial time. The output of the reduction \nalgorithm is the instance h G;  jV j \ue003  ki of the  vertex-cover  problem.  To  complete  \nthe proof, we show that this transformation is inde ed a reduction: the graph G \ncontains a clique of size k if and only if the graph G has a vertex cover of size \njV j \ue003  k. \nSuppose that G contains a clique V 0 \u0dc2 V with jV 0 j D  k. We claim that V \ue003 V 0 \nis a vertex cover in G. Let .u;v/  be any edge in E. Then, .u;v/  \u2026 E, which \nimplies that at least one of u or v does not belong to V 0 , since every pair of vertices \nin V 0 is connected by an edge of E. Equivalently, at least one of u or v belongs \nto V \ue003 V 0 , which means that edge .u;v/  is covered by V \ue003 V 0 . Since .u;v/  was \nchosen arbitrarily from E, every edge of E is covered by a vertex in V \ue003 V 0 . Hence \nthe set V \ue003 V 0 , which has size jV j \ue003  k, forms a vertex cover for G. \nConversely, suppose that G has a vertex cover V 0 \u0dc2 V , where jV 0 j D jV j \ue003  k. \nThen for all u;v  2 V , if .u;v/  2 E, then u 2 V 0 or v 2 V 0 or both. The \ncontrapositive of this implication is that for all u;v  2 V , if u \u2026 V 0 and v \u2026 V 0 , \nthen .u;v/  2 E. In other words, V \ue003V 0 is a clique, and it has size jV j\ue003jV 0 j D  k. \nSince  VERTEX-COVER  is NP-complete,  we  don\u2019t  expect  to \u00fbnd  a polynomial-  \ntime  algorithm  for  \u00fbnding  a minimum-size  vertex  cover.  Section  35.1  presents  a \npolynomial-time  <approximation  algorithm,=  however,  which  produces  <approxi-  \nmate=  solutions  for  the  vertex-cover  problem.  The  size  of a vertex cover produced \nby the algorithm is at most twice the minimum size of a vertex cover. \nThus,  you  shouldn\u2019t  give  up  hope  just  because  a problem  is NP-complete. You \nmight  be able  to design  a polynomial-time  approximation  algorithm that obtains \nnear-optimal  solutions,  even  though  \u00fbnding  an optimal  solution  is NP-complete.  \nChapter  35  gives  several  approximation  algorithms  for  NP-c omplete problems. \n34.5.3  The  hamiltonian-cycle  problem  \nWe  now  return  to the  hamiltonian-cycle  problem  de\u00fbned  in Section  34.2.  \nTheorem  34.13  \nThe  hamiltonian  cycle  problem  is NP-complete.  1086 Chapter 34 NP-Completeness \n(a) (b) (c) (d) \ufffd uv  \ufffd uv  \ufffd uv  \ufffd uv  \u0152u; v; 1\ufffd  \u0152u; v; 1\ufffd  \u0152u; v; 1\ufffd  \u0152u; v; 1\ufffd  \n\u0152u; v; 2\ufffd  \n\u0152u; v; 3\ufffd  \n\u0152u; v; 4\ufffd  \n\u0152u; v; 5\ufffd  \n\u0152u; v; 6\ufffd  \u0152u; v; 6\ufffd  \u0152u; v; 6\ufffd  \u0152u; v; 6\ufffd  \u0152v; u; 1\ufffd  \u0152v; u; 1\ufffd  \u0152v; u; 1\ufffd  \u0152v; u; 1\ufffd  \n\u0152v; u; 2\ufffd  \n\u0152v; u; 3\ufffd  \n\u0152v; u; 4\ufffd  \n\u0152v; u; 5\ufffd  \n\u0152v; u; 6\ufffd  \u0152v; u; 6\ufffd  \u0152v; u; 6\ufffd  \u0152v; u; 6\ufffd  \nFigure  34.16  The  gadget  used  in reducing  the  vertex-cover  problem  to the  hamiltonian-cycle  prob-  \nlem. An edge .u;v/  of graph G corresponds to gadget \ufffd uv  in the graph G 0 created in the reduction. \n(a)  The gadget, with individual vertices labeled. (b)\u2013(d)  The paths highlighted in blue are the only \npossible ones through the gadget that include all v ertices, assuming that the only connections from \nthe gadget to the remainder of G 0 are through vertices \u0152u; v; 1\ufffd , \u0152u; v; 6\ufffd , \u0152v; u; 1\ufffd , and \u0152v; u; 6\ufffd . \nProof  We  \u00fbrst  show  that  HAM-CYCLE  2 NP.  Given  an undirected  graph  \nG D .V;E/, the  certi\u00fbcate  is the  sequence  of jV j vertices  that  makes  up  the  hamil-  \ntonian  cycle.  The  veri\u00fbcation  algorithm  checks  that  this  sequence contains each \nvertex in V exactly  once  and  that  with  the  \u00fbrst  vertex  repeated  at the  end, it forms \na cycle in G. That is, it checks that there is an edge between each pair of c onsecu-  \ntive  vertices  and  between  the  \u00fbrst  and  last  vertices.  This  certi\u00fbcate  can  be veri\u00fbed  \nin polynomial time. \nWe  now  prove  that  VERTEX-COVER  \u0dc4 P HAM-CYCLE,  which  shows  that  \nHAM-CYCLE  is NP-complete.  Given  an undirected  graph  G D .V;E/  and an \ninteger k, we construct an undirected graph G 0 D .V  0 ;E  0 / that has a hamiltonian \ncycle if and only if G has a vertex cover of size k. We assume without loss of \ngenerality that G contains no isolated vertices (that is, every verte x in V has at \nleast one incident edge) and that k \u0dc4 jV j. (If an isolated vertex belongs to a vertex \ncover of size k, then there also exists a vertex cover of size k \ue003 1, and for any graph, \nthe entire set V is always a vertex cover.) \nOur  construction  uses  a gadget , which is a piece of a graph that enforces certain  \nproperties.  Figure  34.16(a)  shows  the  gadget  we  use.  For  each edge .u;v/  2 E, the \nconstructed graph G 0 contains one copy of this gadget, which we denote b y \ufffd uv  . \nWe denote each vertex in \ufffd uv  by \u0152u; v; i\ufffd  or \u0152v; u; i\ufffd , where 1 \u0dc4 i \u0dc4 6, so that each \ngadget \ufffd uv  contains 12  vertices.  Gadget  \ufffd uv  also contains the 14  edges shown in \nFigure  34.16(a).  \nAlong with the internal structure of the gadget, we  enforce the properties we \nwant by limiting the connections between the gadget  and the remainder of the \ngraph G 0 that we construct. In particular, only vertices \u0152u; v; 1\ufffd , \u0152u; v; 6\ufffd , \u0152v; u; 1\ufffd , \nand \u0152v; u; 6\ufffd  will have edges incident from outside \ufffd uv  . Any hamiltonian cycle 34.5  NP-complete  problems  1087 \nof G 0 must traverse the edges of \ufffd uv  in one  of the  three  ways  shown  in Fig-  \nures  34.16(b)3(d).  If the  cycle  enters  through  vertex  \u0152u; v; 1\ufffd , it must exit through \nvertex \u0152u; v; 6\ufffd , and it either visits all 12  of the  gadget\u2019s  vertices  (Figure  34.16(b))  \nor the six vertices \u0152u; v; 1\ufffd  through \u0152u; v; 6\ufffd  (Figure  34.16(c)).  In the  latter  case,  the  \ncycle will have to reenter the gadget to visit vert ices \u0152v; u; 1\ufffd  through \u0152v; u; 6\ufffd. Simi-  \nlarly, if the cycle enters through vertex \u0152v; u; 1\ufffd , it must exit through vertex \u0152v; u; 6\ufffd , \nand either it visits all 12  of the  gadget\u2019s  vertices  (Figure  34.16(d))  or it visits  the  \nsix vertices \u0152v; u; 1\ufffd  through \u0152v; u; 6\ufffd  and reenters to visit \u0152u; v; 1\ufffd  through \u0152u; v; 6\ufffd  \n(Figure  34.16(c)).  No  other  paths  through  the  gadget  that  visit all 12  vertices are \npossible. In particular, it is impossible to constr uct two vertex-disjoint  paths,  one  \nof which connects \u0152u; v; 1\ufffd  to \u0152v; u; 6\ufffd  and the other of which connects \u0152v; u; 1\ufffd  \nto \u0152u; v; 6\ufffd , such that the union of the two paths contains all  of the gadge t\u2019s  ver-  \ntices. \nThe only other vertices in V 0 other than those of gadgets are selector  vertices  \ns 1 ;s 2 ;:::;s  k . We\u2019ll  use  edges  incident  on  selector  vertices  in G 0 to select the k \nvertices of the cover in G. \nIn addition to the edges in gadgets, E 0 contains two other types of edges, which \nFigure  34.17  shows.  First,  for  each  vertex  u 2 V , edges join pairs of gadgets \nin order to form a path containing all gadgets corr esponding to edges incident \non u in G. We arbitrarily order the vertices adjacent to eac h vertex u 2 V as \nu .1/  ;u  .2/  ;:::;u  .degree .u//  , where degree .u/  is the number of vertices adjacent to u. \nTo create a path in G 0 through all the gadgets corresponding to edges inci dent \non u, E 0 contains the edges f.\u0152u;u  .i/  ; 6\ufffd; \u0152u; u  .i C1/  ; 1\ufffd/  W 1 \u0dc4 i \u0dc4 degree.u/  \ue003 1g. \nIn Figure  34.17,  for  example,  we  order  the  vertices  adjacent  to w as hx;y;\u00b4 i, \nand so graph G 0 in part  (b)  of the  \u00fbgure  includes  the  edges  .\u0152w; x; 6\ufffd; \u0152w; y; 1\ufffd/  \nand .\u0152w; y; 6\ufffd; \u0152w; \u00b4; 1\ufffd/ . The vertices adjacent to x are ordered as hw;y  i, so that \nG 0 includes the edge .\u0152x; w; 6\ufffd; \u0152x; y; 1\ufffd/ . For each vertex u 2 V , these edges in G 0 \n\u00fbll  in a path  containing  all  gadgets  corresponding  to edges  incident on u in G. \nThe intuition behind these edges is that if vertex u 2 V belongs to the vertex \ncover of G, then G 0 contains a path from \u0152u;u  .1/  ; 1\ufffd  to \u0152u;u  .degree .u//  ; 6\ufffd  that  <cov-  \ners= all gadgets corresponding to edges incident on  u. That is, for each of these \ngadgets, say \ufffd u;u  .i/  , the path either includes all 12  vertices (if u belongs  to the  ver-  \ntex cover but u .i/  does not) or just the six vertices \u0152u;u  .i/  ; 1\ufffd  through \u0152u;u  .i/  ; 6\ufffd  (if \nboth u and u .i/  belong to the vertex cover). \nThe  \u00fbnal  type  of edge  in E 0 joins  the  \u00fbrst  vertex  \u0152u;u  .1/  ; 1\ufffd  and the last vertex \n\u0152u;u  .degree .u//  ; 6\ufffd  of each of these paths to each of the selector vert ices. That is, E 0 \nincludes the edges \nf.s j ;\u0152u;u  .1/  ; 1\ufffd/  W u 2 V and 1 \u0dc4 j \u0dc4 kg \n[ f.s j ;\u0152u;u  .degree .u//  ; 6\ufffd/  W u 2 V and 1 \u0dc4 j \u0dc4 kg : 1088 Chapter 34 NP-Completeness \n[w,x,1]  \n[w,x,6]  [x,w,1]  \n[x,w,6]  (b) \n[x,y,1]  \n[x,y,6]  [y,x,1]  \n[y,x,6]  [w,y,1]  \n[w,y,6]  [y,w,1]  \n[y,w,6]  [w,z,1]  \n[w,z,6]  [z,w,1]  \n[z,w,6]  s 1 \ns 2 w x \nz y (a) \n\ufffd wx  \ufffd xy  \ufffd wy  \ufffd w\u00b4  \nFigure  34.17  Reducing  an  instance  of the  vertex-cover  problem  to an  instance  of the  hamiltonian-  \ncycle problem. (a)  An undirected graph G with a vertex cover of size 2, consisting of the blue \nvertices w and y. (b)  The undirected graph G 0 produced by the reduction, with the hamiltonian \ncycle corresponding to the vertex cover highlighted  in blue. The vertex cover fw;yg corresponds to \nedges .s 1 ; \u0152w; x; 1\ufffd/  and .s 2 ; \u0152y; x; 1\ufffd/  appearing in the hamiltonian cycle. \nNext we show that the size of G 0 is polynomial in the size of G, and hence it \ntakes time polynomial in the size of G to construct G 0 . The vertices of G 0 are those \nin the gadgets, plus the selector vertices. With 12  vertices per gadget, plus k \u0dc4 jV j \nselector vertices, G 0 contains a total of \njV 0 j D  12  jEj C  k \n\u0dc4 12  jEj C jV j \nvertices. The edges of G 0 are those in the gadgets, those that go between gad gets, \nand those connecting selector vertices to gadgets. Each gadget contains 14  edges, \ntotaling 14  jEj in all gadgets. For each vertex u 2 V , graph G 0 has degree.u/  \ue003 1 \nedges going between gadgets, so that summed over al l vertices in V , 34.5  NP-complete  problems  1089 \nX  \nu2V .degree.u/  \ue003 1/ D 2 jEj \ue003 jV j \nedges go between gadgets. Finally, G 0 has two edges for each pair consisting of a \nselector vertex and a vertex of V , totaling 2k  jV j such edges. The total number of \nedges of G 0 is therefore \njE 0 j D  .14  jEj/ C .2 jEj \ue003 jV j/ C .2k  jV j/ \nD 16  jEj C  .2k  \ue003 1/ jV j \n\u0dc4 16  jEj C  .2 jV j \ue003  1/ jV j : \nNow we show that the transformation from graph G to G 0 is a reduction. That is, \nwe must show that G has a vertex cover of size k if and only if G 0 has a hamiltonian \ncycle. \nSuppose that G D .V;E/  has a vertex cover V \ue003 \u0dc2 V , where jV \ue003 j D  k. Let \nV \ue003 D fu 1 ;u  2 ;:::;u  k g. As  Figure  34.17  shows,  we  can  construct  a hamiltonian  \ncycle in G 0 by including the following edges 11  for each vertex u j 2 V \ue003 . Start \nby including edges \u02da \n.\u0152u  j ;u  .i/  \nj ; 6\ufffd; \u0152u  j ;u  .i C1/  \nj ; 1\ufffd/  W 1 \u0dc4 i \u0dc4 degree.u  j / \ue003 1 \ue009 \n, which \nconnect all gadgets corresponding to edges incident  on u j . Also include the edges \nwithin  these  gadgets  as Figures  34.16(b)3(d)  show,  dependi ng on whether the edge \nis covered by one or two vertices in V \ue003 . The hamiltonian cycle also includes the \nedges \nf.s j ;\u0152u  j ;u  .1/  \nj ; 1\ufffd/  W 1 \u0dc4 j \u0dc4 kg \n[ f.s j C1 ;\u0152u  j ;u  .degree .u  j // \nj ; 6\ufffd/  W 1 \u0dc4 j \u0dc4 k \ue003 1g \n[ f.s 1 ;\u0152u  k ;u  .degree .u  k // \nk ; 6\ufffd/g : \nBy  inspecting  Figure  34.17,  you  can  verify  that  these  edges  form a cycle, where \nu 1 D w and u 2 D y . The cycle starts at s 1 , visits all gadgets corresponding to \nedges incident on u 1 , then visits s 2 , visits  all  gadgets  corresponding  to edges  inci-  \ndent on u 2 , and so on, until it returns to s 1 . The cycle visits each gadget either once \nor twice, depending on whether one or two vertices of V \ue003 cover its corresponding \nedge. Because V \ue003 is a vertex cover for G, each edge in E is incident on some \nvertex in V \ue003 , and so the cycle visits each vertex in each gadge t of G 0 . Because the \ncycle also visits every selector vertex, it is hami ltonian. \nConversely, suppose that G 0 D .V  0 ;E  0 / contains a hamiltonian cycle C \u0dc2 E 0 . \nWe claim that the set \nV \ue003 D fu 2 V W .s j ;\u0152u;u  .1/  ; 1\ufffd/  2 C for some 1 \u0dc4 j \u0dc4 kg (34.4)  \n11  Technically,  a cycle  is de\u00fbned  as a sequence  of vertices  rather  than  edges  (see  Section  B.4).  In the  \ninterest  of clarity,  we  abuse  notation  here  and  de\u00fbne  the  hamiltonian cycle by its edges. 1090 Chapter 34 NP-Completeness \nis a vertex cover for G. \nWe  \u00fbrst  argue  that  the  set  V \ue003 is well  de\u00fbned,  that  is, for  each  selector  ver-  \ntex s j , exactly one of the incident edges in the hamilton ian cycle C is of the form \n.s j ;\u0152u;u  .1/  ; 1\ufffd/  for some vertex u 2 V . To  see  why,  partition  the  hamiltonian  cy-  \ncle C into maximal paths that start at some selector vert ex s i , visit  one  or more  gad-  \ngets, and end at some selector vertex s j without passing through any other selector \nvertex.  Let\u2019s  call  each  of these  maximal  paths  a <cover  path.  = Let P be one such \ncover path, and orient it going from s i to s j . If P contains the edge .s i ;\u0152u;u  .1/  ; 1\ufffd/  \nfor some vertex u 2 V , then we have shown that one edge incident on s i has the \nrequired form. Assume, then, that P contains the edge .s i ;\u0152v;v  .degree .v//  ; 6\ufffd/  for \nsome vertex v 2 V . This path enters a gadget from the bottom, as dra wn in Figures \n34.16  and  34.17,  and  it leaves  from  the  top.  It might  go  throug h several gadgets, \nbut it always enters from the bottom of a gadget an d leaves from the top. The only \nedges incident on vertices at the top of a gadget e ither go to the bottoms of other \ngadgets or to selector vertices. Therefore, after t he last gadget  in the  series  of gad-  \ngets visited by P , the edge taken must go to a selector vertex s j , so that P contains \nan edge of the form .s j ;\u0152u;u  .1/  ; 1\ufffd/, where \u0152u;u  .1/  ; 1\ufffd  is a vertex at the top of some \ngadget. To see that not both edges incident on s j have this form, simply reverse the \ndirection of traversing P in the above argument. \nHaving established that the set V \ue003 is well  de\u00fbned,  let\u2019s  see  why  it is a vertex  \ncover for G. We have already established that each cover path starts at some s i , \ntakes the edge .s i ;\u0152u;u  .1/  ; 1\ufffd/  for some vertex u 2 V , passes  through  all  the  gad-  \ngets corresponding to edges in E incident on u, and  then  ends  at some  selec-  \ntor vertex s j . (This orientation is the reverse of the orientati on in the paragraph \nabove.)  Let\u2019s  call  this  cover  path  P u , and  by  equation  (34.4),  the  vertex  cover  V \ue003 \nincludes u. Each gadget visited by P u must be \ufffd uv  or \ufffd vu  for some v 2 V . For \neach gadget visited by P u , its vertices are visited by either one or two cov er paths. \nIf they are visited by one cover path, then edge .u;v/  2 E is covered in G by \nvertex u. If two cover paths visit the gadget, then the oth er cover path must be P v , \nwhich implies that v 2 V \ue003 , and edge .u;v/  2 E is covered by both u and v. Be-  \ncause each vertex in each gadget is visited by some  cover path, we see that each \nedge in E is covered by some vertex in V \ue003 . \n34.5.4  The  traveling-salesperson  problem  \nIn the traveling-salesperson  problem, which  is closely  related  to the  hamiltonian-  \ncycle problem, a salesperson must visit n cities.  Let\u2019s  model  the  problem  as a \ncomplete graph with n vertices, so that the salesperson wishes to make a tour, \nor hamiltonian  cycle,  visiting  each  city  exactly  once  and  \u00fbnishing at the starting \ncity. The salesperson incurs a nonnegative integer cost c.i;j/  to travel from city i 34.5  NP-complete  problems  1091 \nu \nx w 4 \n2 3 \n5 1 \n1 v \nFigure  34.18  An  instance  of the  traveling-salesperson  problem.  Edges  highlighted  in blue  repre-  \nsent  a minimum-cost  tour,  with  cost  7. \nto city j . In the optimization version of the problem, the s alesperson wishes to \nmake the tour whose total cost is minimum, where th e total cost is the sum of \nthe individual costs along the edges of the tour. F or example, in Figure  34.18,  a \nminimum-cost  tour  is hu;w;v;x;u i, with cost 7. The formal language for the \ncorresponding decision problem is \nTSP D fhG;c;k i W G D .V;E/  is a complete graph ; \nc is a function from V \ue005 V !  N; \nk 2 N, and \nG has  a traveling-salesperson  tour  with  cost  at most  kg : \nThe following theorem shows that a fast algorithm f or the traveling-salesperson  \nproblem is unlikely to exist. \nTheorem  34.14  \nThe  traveling-salesperson  problem  is NP-complete.  \nProof  We  \u00fbrst  show  that  TSP  2 NP.  Given  an instance  of the  problem,  the  \ncerti\u00fbcate  is the  sequence  of n vertices  in the  tour.  The  veri\u00fbcation  algorithm  \nchecks that this sequence contains each vertex exac tly once, sums up the edge \ncosts, and checks that the sum is at most k. This process can certainly be done in \npolynomial time. \nTo  prove  that  TSP  is NP-hard,  we  show  that  HAM-CYCLE  \u0dc4 P TSP.  Given  an \ninstance G D .V;E/  of HAM-CYCLE,  construct  an instance  of TSP  by  forming  \nthe complete graph G 0 D .V;E  0 /, where E 0 D f.i;j/  W i;j  2 V and i \u00a4 j g, with \nthe cost function c de\u00fbned  as \nc.i;j/  D ( \n0 if .i;j/  2 E;  \n1 if .i;j/  \u2026 E:  \n(Because G is undirected,  it contains  no  self-loops,  and  so c.v;v/  D 1 for all \nvertices v 2 V .) The instance of TSP is then hG 0 ;c;0i, which can be created in \npolynomial time. 1092 Chapter 34 NP-Completeness \nWe now show that graph G has a hamiltonian cycle if and only if graph G 0 has \na tour of cost at most 0. Suppose that graph G has a hamiltonian cycle H . Each \nedge in H belongs to E and thus has cost 0 in G 0 . Thus, H is a tour in G 0 with \ncost 0. Conversely, suppose that graph G 0 has a tour H 0 of cost at most 0. Since \nthe costs of the edges in E 0 are 0 and 1, the cost of tour H 0 is exactly 0 and each \nedge on the tour must have cost 0. Therefore, H 0 contains only edges in E. We \nconclude that H 0 is a hamiltonian cycle in graph G. \n34.5.5  The  subset-sum  problem  \nWe  next  consider  an arithmetic  NP-complete  problem.  The  subset-sum  problem  \ntakes  as inputs  a \u00fbnite  set  S of positive integers and an integer target  t > 0 . It \nasks whether there exists a subset S 0 \u0dc2 S whose elements sum to exactly t . For \nexample, if S D f1;2;7;14;49;98;343;686;2409;2793;16808;17206;117705 ; \n117993 g and t D 138457 , then the subset S 0 D f1;2;7;98;343;686;2409;17206;  \n117705 g is a solution. \nAs usual, we express the problem as a language: \nSUBSET-SUM  D \u02da \nhS;t  i W  there exists a subset S 0 \u0dc2 S such that t D P  \ns2S 0 s \ue009 \n: \nAs with any arithmetic problem, it is important to recall that our standard encoding \nassumes that the input integers are coded in binary . With this assumption in mind, \nwe  can  show  that  the  subset-sum  problem  is unlikely  to have  a fast algorithm. \nTheorem  34.15  \nThe  subset-sum  problem  is NP-complete.  \nProof  To  show  that  SUBSET-SUM  2 NP, for an instance hS;t  i of the problem, \nlet the subset S 0 be the  certi\u00fbcate.  A veri\u00fbcation  algorithm  can  check  whethe r \nt D P  \ns2S 0 s in polynomial time. \nWe  now  show  that  3-CNF-SAT  \u0dc4 P SUBSET-SUM.  Given  a 3-CNF  formula  \ufffd \nover variables x 1 ;x  2 ;:::;x  n with clauses C 1 ;C  2 ;:::;C  k , each containing exactly \nthree distinct literals, the reduction algorithm co nstructs an instance hS;t  i of the \nsubset-sum  problem  such  that  \ufffd is satis\u00fbable  if and  only  if there  exists  a subset  \nof S whose sum is exactly t . Without loss of generality, we make two simplifyi ng \nassumptions about the formula \ufffd. First, no clause contains both a variable and its  \nnegation,  for  such  a clause  is automatically  satis\u00fbed  by  any  assignment of values \nto the variables. Second, each variable appears in at least one clause, because it \ndoes not matter what value is assigned to a variabl e that appears in no clauses. \nThe reduction creates two numbers in set S for each variable x i and two numbers \nin S for each clause C j . The numbers will be represented in base 10, with each \nnumber containing n C k digits and each digit corresponding to either one v ariable 34.5  NP-complete  problems  1093 \n= 1 0 0 1 0 0 1 \n= 1 0 0 0 1 1 0 \n= 0 1 0 0 0 0 1 \n= 0 1 0 1 1 1 0 \n= 0 0 1 0 0 1 1 \n= 0 0 1 1 1 0 0 \n= 0 0 0 1 0 0 0 \n= 0 0 0 2 0 0 0 \n= 0 0 0 0 1 0 0 \n= 0 0 0 0 2 0 0 \n= 0 0 0 0 0 1 0 \n= 0 0 0 0 0 2 0 \n= 0 0 0 0 0 0 1 \n= 0 0 0 0 0 0 2 \n= 1 1 1 4 4 4 4 x 1 x 2 x 3 C 1 C 2 C 3 C 4 \nv 1 \nv 0 \n1 \nv 2 \nv 0 \n2 \nv 3 \nv 0 \n3 \ns 1 \ns 0 \n1 \ns 2 \ns 0 \n2 \ns 3 \ns 0 \n3 \ns 4 \ns 0 \n4 \nt \nFigure  34.19  The  reduction  of 3-CNF-SAT  to SUBSET-SUM.  The  formula  in 3-CNF is \ufffd D \nC 1 ^C 2 ^C 3 ^C 4 , where C 1 D .x 1 _:x 2 _:x 3 /, C 2 D .:x 1 _:x 2 _:x 3 /, C 3 D .:x 1 _:x 2 _x 3 /, \nand C 4 D .x 1 _ x 2 _ x 3 /. A satisfying assignment of \ufffd is hx 1 D 0;x  2 D 0;x  3 D 1i. The set S \nproduced  by  the  reduction  consists  of the  base-10  numbers shown: reading from top to bottom, S D \nf1001001;1000110;100001;101110;10011;11100;1000;2000 ;100;200;10;20;1;2 g. The target t \nis 1114444 . The subset S 0 \u0dc2 S is shaded blue, and it contains v 0 \n1 , v 0 \n2 , and v 3 , corresponding to the \nsatisfying assignment. Subset S 0 also contains slack variables s 1 , s 0 \n1 , s 0 \n2 , s 3 , s 4 , and s 0 \n4 to achieve the \ntarget value of 4 in the digits labeled by C 1 through C 4 . \nor one clause. Base 10  (and other bases, as we shall see) has the property  we need \nof preventing carries from lower digits to higher d igits. \nAs  Figure  34.19  shows,  we  construct  set  S and target t as follows. Label each \ndigit position by either a variable or a clause. Th e least signi\u00fbcant  k digits are \nlabeled  by  the  clauses,  and  the  most  signi\u00fbcant  n digits are labeled by variables. \n\ue001 The target t has a 1 in each digit labeled by a variable and a 4 in each digit \nlabeled by a clause. \n\ue001 For each variable x i , set S contains two integers v i and v 0 \ni . Each of v i and v 0 \ni \nhas a 1 in the digit labeled by x i and 0s in the other variable digits. If literal x i \nappears in clause C j , then the digit labeled by C j in v i contains a 1. If lit-  \neral :x i appears in clause C j , then the digit labeled by C j in v 0 \ni contains a 1. \nAll other digits labeled by clauses in v i and v 0 \ni are 0. 1094 Chapter 34 NP-Completeness \nAll v i and v 0 \ni values in set S are  unique.  Why?  For  ` \u00a4 i , no v ` or v 0 \n` values can \nequal v i and v 0 \ni in the  most  signi\u00fbcant  n digits. Furthermore, by our simplifying \nassumptions above, no v i and v 0 \ni can be equal in all k least  signi\u00fbcant  digits.  If \nv i and v 0 \ni were equal, then x i and :x i would have to appear in exactly the same \nset of clauses. But we assume that no clause contai ns both x i and :x i and that \neither x i or :x i appears in some clause, and so there must be some c lause C j \nfor which v i and v 0 \ni differ. \n\ue001 For each clause C j , set S contains two integers s j and s 0 \nj . Each of s j and s 0 \nj has \n0s in all digits other than the one labeled by C j . For s j , there is a 1 in the C j \ndigit, and s 0 \nj has a 2 in this digit. These integers are <slack variables, = which we \nuse  to get  each  clause-labeled  digit  position  to add  to the  target value of 4. \nSimple  inspection  of Figure  34.19  demonstrates  that  all  s j and s 0 \nj values in S \nare unique in set S . \nThe greatest sum of digits in any one digit positio n is 6, which occurs in the \ndigits labeled by clauses (three 1s from the v i and v 0 \ni values, plus 1 and 2 from the \ns j and s 0 \nj values). Interpreting these numbers in base 10, therefore, no carries can \noccur from lower digits to higher digits. 12  \nThe reduction can be performed in polynomial time. The set S consists of \n2n  C 2k  values, each of which has n C k digits, and the time to produce each \ndigit is polynomial in n C k. The target t has n C k digits, and the reduction \nproduces each in constant time. \nLet\u2019s  now  show  that  the  3-CNF  formula  \ufffd is satis\u00fbable  if and  only  if there  exists  \na subset S 0 \u0dc2 S whose sum is t . First, suppose that \ufffd has a satisfying assignment. \nFor i D 1;2;:::;n , if x i D 1 in this assignment, then include v i in S 0 . Otherwise,  \ninclude v 0 \ni . In other words, S 0 includes exactly the v i and v 0 \ni values that correspond \nto literals with the value 1 in the satisfying assignment. Having included eithe r v i \nor v 0 \ni , but not both, for all i , and having put 0 in the digits labeled by variables \nin all s j and s 0 \nj , we  see  that  for  each  variable-labeled  digit,  the  sum  of the  values \nof S 0 must be 1, which matches those digits of the target t . Because each clause \nis satis\u00fbed,  the  clause  contains  some  literal  with  the  value  1. Therefore, each digit \nlabeled by a clause has at least one 1 contributed to its sum by a v i or v 0 \ni value \nin S 0 . In fact, one, two, or three literals may be 1 in each clause, and so each \nclause-labeled  digit  has  a sum  of 1, 2, or 3 from the v i and v 0 \ni values in S 0 . In \nFigure  34.19  for  example,  literals  :x 1 , :x 2 , and x 3 have the value 1 in a satisfying \nassignment. Each of clauses C 1 and C 4 contains exactly one of these literals, and \nso together v 0 \n1 , v 0 \n2 , and v 3 contribute 1 to the sum in the digits for C 1 and C 4 . \n12  In fact, any base b \ue004 7 works. The instance at the beginning of this subsec tion is the set S and \ntarget t in Figure  34.19  interpreted  in base  7, with S listed in sorted order. 34.5  NP-complete  problems  1095 \nClause C 2 contains two of these literals, and v 0 \n1 , v 0 \n2 , and v 3 contribute 2 to the \nsum in the digit for C 2 . Clause C 3 contains all three of these literals, and v 0 \n1 , v 0 \n2 , \nand v 3 contribute 3 to the sum in the digit for C 3 . To achieve the target of 4 in each \ndigit labeled by clause C j , include in S 0 the appropriate nonempty subset of slack \nvariables fs j ;s 0 \nj g. In Figure  34.19,  S 0 includes s 1 , s 0 \n1 , s 0 \n2 , s 3 , s 4 , and s 0 \n4 . Since S 0 \nmatches the target in all digits of the sum, and no  carries can occur, the values of S 0 \nsum to t . \nNow suppose that some subset S 0 \u0dc2 S sums to t . The subset S 0 must include \nexactly one of v i and v 0 \ni for each i D 1;2;:::;n , for otherwise the digits labeled \nby variables would not sum to 1. If v i 2 S 0 , then set x i D 1. Otherwise,  v 0 \ni 2 S 0 , \nand set x i D 0. We claim that every clause C j , for j D 1;2;:::;k, is satis\u00fbed  by  \nthis assignment. To prove this claim, note that to achieve a sum of 4 in the digit \nlabeled by C j , the subset S 0 must include at least one v i or v 0 \ni value  that  has  a 1 \nin the digit labeled by C j , since the contributions of the slack variables s j and s 0 \nj \ntogether sum to at most 3. If S 0 includes a v i that has a 1 in C j \u2019s position,  then  the  \nliteral x i appears in clause C j . Since x i D 1 when v i 2 S 0 , clause C j is satis\u00fbed.  \nIf S 0 includes a v 0 \ni that has a 1 in that position, then the literal :x i appears in C j . \nSince x i D 0 when v 0 \ni 2 S 0 , clause C j is again  satis\u00fbed.  Thus,  all  clauses  of \ufffd are \nsatis\u00fbed,  which  completes  the  proof.  \n34.5.6  Reduction  strategies  \nFrom the reductions in this section, you can see th at no single strategy applies to \nall  NP-complete  problems.  Some  reductions  are  straightfor ward, such as reducing \nthe  hamiltonian-cycle  problem  to the  traveling-salesperson  problem.  Others  are  \nconsiderably more complicated. Here are a few thing s to keep in mind and some \nstrategies that you can often bring to bear. \nPitfalls  \nMake  sure  that  you  don\u2019t  get  the  reduction  backward.  That  is, in trying to show \nthat problem Y is NP-complete,  you  might  take  a known  NP-complete  problem  X \nand  give  a polynomial-time  reduction  from  Y to X . That is the wrong direction. \nThe reduction should be from X to Y, so that a solution to Y gives a solution to X . \nRemember  also  that  reducing  a known  NP-complete  problem  X to a problem Y \ndoes not in itself prove that Y is NP-complete.  It proves  that  Y is NP-hard.  In \norder to show that Y is NP-complete,  you  additionally  need  to prove  that  it\u2019s  in NP \nby  showing  how  to verify  a certi\u00fbcate  for  Y in polynomial time. 1096 Chapter 34 NP-Completeness \nGo  from  general  to speci\ufb01c  \nWhen reducing problem X to problem Y, you always have to start with an arbitrary \ninput to problem X. But you are allowed to restrict the input to prob lem Y as much \nas you  like.  For  example,  when  reducing  3-CNF  satis\u00fbability  to the  subset-sum  \nproblem, the reduction had to be able to handle any  3-CNF  formula  as its  input,  \nbut  the  input  to the  subset-sum  problem  that  it produced  had  a particular structure: \n2n  C 2k  integers in the set, and each integer was formed in  a particular way. The \nreduction did not need to produce every  possible  input  to the  subset-sum  problem.  \nThe  point  is that  one  way  to solve  the  3-CNF  satis\u00fbability  problem transforms \nthe  input  into  an input  to the  subset-sum  problem  and  then  uses the answer to the \nsubset-sum  problem  as the  answer  to the  3-CNF  satis\u00fbability  problem. \nTake  advantage  of structure  in the  problem  you  are  reducing  from  \nWhen you are choosing a problem to reduce from, you  might consider  two  prob-  \nlems in the same domain, but one problem has more s tructure than the other. For \nexample,  it\u2019s  almost  always  much  easier  to reduce  from  3-CNF  satis\u00fbability  than  \nto reduce  from  formula  satis\u00fbability.  Boolean  formulas  can  be arbitrarily  compli-  \ncated,  but  you  can  exploit  the  structure  of 3-CNF  formulas  when reducing. \nLikewise, it is usually more straightforward to red uce from the  hamiltonian-  \ncycle  problem  than  from  the  traveling-salesperson  problem , even though they are \nso similar.  That\u2019s  because  you  can  view  the  hamiltonian-cyc le problem as taking \na complete graph but with edge weights of just 0 or 1, as they would appear in the \nadjacency  matrix.  In that  sense,  the  hamiltonian-cycle  problem has more structure \nthan  the  traveling-salesperson  problem,  in which  edge  weig hts are unrestricted. \nLook  for  special  cases  \nSeveral  NP-complete  problems  are  just  special  cases  of other  NP-complete  prob-  \nlems.  For  example,  consider  the  decision  version  of the  0-1  knapsack problem: \ngiven a set of n items, each with a weight and a value, does there e xist a subset of \nitems whose total weight is at most a given weight W and whose total value is at \nleast a given value V ? You  can  view  the  set-partition  problem  in Exercise  34.5-5  \nas a special  case  of the  0-1  knapsack  problem:  let  the  value  of each item equal its \nweight, and set both W and V to half the total weight. If problem X is NP-hard  \nand it is a special case of problem Y, then problem Y must  be NP-hard  as well.  \nThat  is because  a polynomial-time  solution  for  problem  Y automatically gives a \npolynomial-time  solution  for  problem  X. More intuitively, problem Y, being more \ngeneral than problem X, is at least as hard. 34.5  NP-complete  problems  1097 \nSelect  an  appropriate  problem  to reduce  from  \nIt\u2019s  often  a good  strategy  to reduce  from  a problem  in a domain  that is the same \nas,  or at least  related  to,  the  domain  of the  problem  that  you\u2019  re trying to prove \nNP-complete.  For  example,  we  saw  that  the  vertex-cover  problem4a  graph  prob-  \nlem4was  NP-hard  by  reducing  from  the  clique  problem4also  a graph problem. \nFrom  the  vertex-cover  problem,  we  reduced  to the  hamiltonian-cycle  problem,  and  \nfrom  the  hamiltonian-cycle  problem,  we  reduced  to the  traveling-salesperson  prob-  \nlem. All of these problems take undirected graphs a s inputs. \nSometimes,  however,  you  will  \u00fbnd  that  is it better  to cross  over  from  one  do-  \nmain  to another,  such  as when  we  reduced  from  3-CNF  satis\u00fbabi lity to the clique \nproblem  or to the  subset-sum  problem.  3-CNF  satis\u00fbability  often turns out to be a \ngood choice as a problem to reduce from when crossi ng domains. \nWithin graph problems, if you need to select a port ion of the graph, without \nregard  to ordering,  then  the  vertex-cover  problem  is often  a good place to start. If \nordering matters, then consider starting from the h amiltonian-cycle  or hamiltonian-  \npath  problem  (see  Exercise  34.5-6).  \nMake  big  rewards  and  big  penalties  \nThe  strategy  for  reducing  the  hamiltonian-cycle  problem  with a graph G to the \ntraveling-salesperson  problem  encouraged  using  edges  present in G when choosing \nedges  for  the  traveling-salesperson  tour.  The  reduction  did so by giving these edges \na low weight: 0. In other words, we gave a big reward for using th ese edges. \nAlternatively, the reduction could have given the e dges in G a \u00fbnite  weight  and  \ngiven edges not in G in\u00fbnite  weight,  thereby  exacting  a hefty  penalty  for  using  \nedges not in G. With this approach, if each edge in G has weight W , then the \ntarget  weight  of the  traveling-salesperson  tour  becomes  W \ue001 jV j. You  can  some-  \ntimes think of the penalties as a way to enforce re quirements. For example, if the \ntraveling-salesperson  tour  includes  an edge  with  in\u00fbnite  weight, then it violates the \nrequirement that the tour should include only edges  belonging to G. \nDesign  gadgets  \nThe  reduction  from  the  vertex-cover  problem  to the  hamiltonian-cycle  problem  \nuses  the  gadget  shown  in Figure  34.16.  This  gadget  is a subgra ph that is connected \nto other parts of the constructed graph in order to  restrict the ways that a cycle \ncan visit each vertex in the gadget once. More gene rally, a gadget is a component \nthat  enforces  certain  properties.  Gadgets  can  be complicat ed, as in the reduction to \nthe  hamiltonian-cycle  problem.  Or  they  can  be simple:  in the  reduction  of 3-CNF  \nsatis\u00fbability  to the  subset-sum  problem,  you  can  view  the  slack variables s j and s 0 \nj 1098 Chapter 34 NP-Completeness \nas gadgets  enabling  each  clause-labeled  digit  position  to achieve the target value \nof 4. \nExercises  \n34.5-1  \nThe subgraph-isomorphism  problem  takes two undirected graphs G 1 and G 2 , and \nasks whether G 1 is isomorphic to a subgraph of G 2 . Show  that  the  subgraph-  \nisomorphism  problem  is NP-complete.  \n34.5-2  \nGiven  an integer  m \ue005 n matrix A and an integer m-vector  b, the 0-1  integer-  \nprogramming  problem  asks whether there exists an integer n-vector  x with  ele-  \nments in the set f0;1g such that Ax  \u0dc4 b. Prove  that  0-1  integer  programming  is \nNP-complete.  (Hint: Reduce  from  3-CNF-SAT.)  \n34.5-3  \nThe integer  linear-programming  problem  is like  the  0-1  integer-programming  \nproblem  given  in Exercise  34.5-2,  except  that  the  values  of the vector x may be \nany integers rather than just 0 or 1. Assuming  that  the  0-1  integer-programming  \nproblem  is NP-hard,  show  that  the  integer  linear-programming  problem  is NP-  \ncomplete. \n34.5-4  \nShow  how  to solve  the  subset-sum  problem  in polynomial  time  if the target value t \nis expressed in unary. \n34.5-5  \nThe set-partition  problem  takes as input a set S of numbers. The question is \nwhether the numbers can be partitioned into two set s A and A D S \ue003 A such \nthat P  \nx2A x D P  \nx2 A x . Show  that  the  set-partition  problem  is NP-complete.  \n34.5-6  \nShow  that  the  hamiltonian-path  problem  is NP-complete.  \n34.5-7  \nThe longest-simple-cycle  problem  is the problem of determining a simple cycle \n(no repeated vertices) of maximum length in a graph . Formulate a related decision \nproblem,  and  show  that  the  decision  problem  is NP-complete.  Problems for Chapter 34 1099 \n34.5-8  \nIn the half  3-CNF  satis\u00fbability  problem,  the  input  is a 3-CNF  formula  \ufffd with n \nvariables and m clauses, where m is even. The question is whether there exists a \ntruth assignment to the variables of \ufffd such that exactly half the clauses evaluate to 0 \nand exactly half the clauses evaluate to 1. Prove  that  the  half  3-CNF  satis\u00fbability  \nproblem  is NP-complete.  \n34.5-9  \nThe  proof  that  VERTEX-COVER  \u0dc4 P HAM-CYCLE  assumes  that  the  graph  G \ngiven  as input  to the  vertex-cover  problem  has  no  isolated  vertices. Show how the \nreduction in the proof can break down if G has an isolated vertex. \nProblems  \n34-1  Independent  set  \nAn independent  set  of a graph G D .V;E/  is a subset V 0 \u0dc2 V of vertices such \nthat each edge in E is incident on at most one vertex in V 0 . The independent-set  \nproblem  is to \u00fbnd  a maximum-size  independent  set  in G. \na. Formulate  a related  decision  problem  for  the  independent-s et problem, and \nprove  that  it is NP-complete.  (Hint: Reduce from the clique problem.) \nb. You  are  given  a <black-box=  subroutine  to solve  the  decision  problem  you  de-  \n\u00fbned  in part  (a).  Give  an algorithm  to \u00fbnd  an independent  set  of maximum \nsize. The running time of your algorithm should be polynomial in jV j and jEj, \ncounting queries to the black box as a single step.  \nAlthough  the  independent-set  decision  problem  is NP-compl ete, certain special \ncases  are  polynomial-time  solvable.  \nc. Give  an ef\u00fbcient  algorithm  to solve  the  independent-set  problem  when  each  ver-  \ntex in G has degree 2. Analyze the running time, and prove that your alg orithm \nworks correctly. \nd. Give  an ef\u00fbcient  algorithm  to solve  the  independent-set  problem when G is \nbipartite. Analyze the running time, and prove that  your algorithm  works  cor-  \nrectly. ( Hint: First prove that in a bipartite graph, the size of the maximimum \nindependent set plus the size of the maximum matchi ng is equal to jV j. Then \nuse  a maximum-matching  algorithm  (see  Section  25.1)  as a \u00fbrst  step  in an al-  \ngorithm  to \u00fbnd  an independent  set.)  1100 Chapter 34 NP-Completeness \n34-2  Bonnie  and  Clyde  \nBonnie and Clyde have just robbed a bank. They have  a bag of money and want \nto divide it up. For each of the following scenario s, either give  a polynomial-time  \nalgorithm to divide the money or prove that the pro blem of dividing the money in \nthe  manner  described  is NP-complete.  The  input  in each  case  is a list of the n items \nin the bag, along with the value of each. \na. The bag contains n coins, but only two different denominations: some c oins \nare worth x dollars, and some are worth y dollars. Bonnie and Clyde wish to \ndivide the money exactly evenly. \nb. The bag contains n coins, with an arbitrary number of different denomi nations, \nbut each denomination is a nonnegative exact power of 2, so that the possible \ndenominations are 1 dollar, 2 dollars, 4 dollars, etc. Bonnie and Clyde wish to \ndivide the money exactly evenly. \nc. The bag contains n checks, which are, in an amazing coincidence, made out to \n<Bonnie or Clyde.= They wish to divide the checks s o that they each get the \nexact same amount of money. \nd. The bag contains n checks as in part (c), but this time Bonnie and Cly de are \nwilling to accept a split in which the difference i s no larger than 100  dollars. \n34-3  Graph  coloring  \nMapmakers try to use as few colors as possible when  coloring countries on a map, \nsubject to the restriction that if two countries sh are a border,  they  must  have  dif-  \nferent colors. You can model this problem with an u ndirected graph G D .V;E/  \nin which each vertex represents a country and verti ces whose respective countries \nshare a border are adjacent. Then, a k-coloring  is a function c W V ! f1;2;:::;k g \nsuch that c.u/  \u00a4 c.v/  for every edge .u;v/  2 E. In other words, the numbers \n1;2;:::;k  represent the k colors,  and  adjacent  vertices  must  have  different  col-  \nors. The graph-coloring  problem  is to determine the minimum number of colors \nneeded to color a given graph. \na. Give  an ef\u00fbcient  algorithm  to determine  a 2-coloring  of a graph,  if one  exists.  \nb. Cast  the  graph-coloring  problem  as a decision  problem.  Show  that  your  deci-  \nsion problem is solvable in polynomial time if and only if the graph-coloring  \nproblem is solvable in polynomial time. \nc. Let  the  language  3-COLOR  be the  set  of graphs  that  can  be 3-colored.  Show  \nthat  if 3-COLOR  is NP-complete,  then  your  decision  problem  from part (b) is \nNP-complete.  Problems for Chapter 34 1101 \n\u2026 \nRED \nTRUE FALSE x 1 :x 1 x 2 :x 2 x n :x n \nFigure  34.20  The subgraph of G in Problem  34-3  formed  by  the  literal  edges.  The  special  vertices \nTRUE , FALSE , and RED form a triangle, and for each variable x i , the vertices x i , :x i , and RED form \na triangle. \nx \ny \nz TRUE \nFigure  34.21  The gadget corresponding to a clause .x _ y _ \u00b4/, used  in Problem  34-3.  \nTo  prove  that  3-COLOR  is NP-complete,  you  can  reduce  from  3-CNF-SAT.  \nGiven  a formula  \ufffd of m clauses on n variables x 1 ;x  2 ;:::;x  n , construct a graph \nG D .V;E/  as follows. The set V consists of a vertex for each variable, a vertex \nfor  the  negation  of each  variable,  \u00fbve  vertices  for  each  clause, and three special \nvertices: TRUE , FALSE , and RED. The  edges  of the  graph  are  of two  types:  <lit-  \neral= edges that are independent of the clauses and  <clause= edges that depend on \nthe  clauses.  As  Figure  34.20  shows,  the  literal  edges  form  a triangle on the three \nspecial vertices TRUE , FALSE , and RED, and they also form a triangle on x i , :x i , \nand RED for i D 1;2;:::;n . \nd. Consider a graph containing the literal edges. Argu e that in any 3-coloring  c of \nsuch a graph, exactly one of a variable and its neg ation is colored c.TRUE/ and \nthe other is colored c.FALSE/. Then argue that for any truth assignment for \ufffd, \nthere exists a 3-coloring  of the  graph  containing  just  the  literal  edges.  \nThe  gadget  shown  in Figure  34.21  helps  to enforce  the  conditi on corresponding to \na clause .x _ y _ \u00b4/, where x , y , and \u00b4 are literals. Each clause requires a unique \ncopy  of the  \u00fbve  blue  vertices  in the  \u00fbgure.  They  connect  as shown to the literals of \nthe clause and the special vertex TRUE . 1102 Chapter 34 NP-Completeness \ne. Argue that if each of x , y , and \u00b4 is colored c.TRUE/ or c.FALSE/, then the \ngadget is 3-colorable  if and  only  if at least  one  of x , y , or \u00b4 is colored c.TRUE/. \nf. Complete  the  proof  that  3-COLOR  is NP-complete.  \n34-4  Scheduling  with  pro\u00fbts  and  deadlines  \nYou have one computer and a set of n tasks fa 1 ;a  2 ;:::;a  n g requiring time on the \ncomputer. Each task a j requires t j time units on the computer (its processing time), \nyields  a pro\u00fbt  of p j , and has a deadline d j . The computer can process only one task \nat a time, and task a j must run without interruption for t j consecutive time units. \nIf task a j completes by its deadline d j , you  receive  a pro\u00fbt  p j . If instead task a j \ncompletes  after  its  deadline,  you  receive  no  pro\u00fbt.  As  an optimization problem, \ngiven  the  processing  times,  pro\u00fbts,  and  deadlines  for  a set  of n tasks, you wish \nto \u00fbnd  a schedule  that  completes  all  the  tasks  and  returns  the  greatest amount of \npro\u00fbt.  The  processing  times,  pro\u00fbts,  and  deadlines  are  all  nonnegative numbers. \na. State this problem as a decision problem. \nb. Show  that  the  decision  problem  is NP-complete.  \nc. Give  a polynomial-time  algorithm  for  the  decision  problem,  assuming that all \nprocessing times are integers from 1 to n. (Hint: Use dynamic programming.) \nd. Give  a polynomial-time  algorithm  for  the  optimization  problem, assuming that \nall processing times are integers from 1 to n. \nChapter  notes  \nThe  book  by  Garey  and  Johnson  [176]  provides  a wonderful  guide  to NP-complete-  \nness, discussing the theory at length and providing  a catalogue of many problems \nthat  were  known  to be NP-complete  in 1979.  The  proof  of Theorem  34.13  is \nadapted  from  their  book,  and  the  list  of NP-complete  problem  domains  at the  be-  \nginning  of Section  34.5  is drawn  from  their  table  of contents.  Johnson  wrote  a se-  \nries  of 23  columns  in the  Journal  of Algorithms  between  1981  and  1992  reporting  \nnew  developments  in NP-completeness.  Fortnow\u2019s  book  [152]  gives a history of \nNP-completeness,  along  with  societal  implications.  Hopcroft,  Motwani,  and  Ull-  \nman  [225],  Lewis  and  Papadimitriou  [299],  Papadimitriou  [352],  and  Sipser  [413]  \nhave  good  treatments  of NP-completeness  in the  context  of complexity theory. \nNP-completeness  and  several  reductions  also  appear  in book s by Aho, Hopcroft, \nand  Ullman  [5],  Dasgupta,  Papadimitriou,  and  Vazirani  [107],  Johnsonbaugh  and  Notes for Chapter 34 1103 \nSchaefer  [239],  and  Kleinberg  and  Tardos  [257].  The  book  by  Hromkovi\u02c7  c [229]  \nstudies various methods for solving hard problems. \nThe  class  P was  introduced  in 1964  by  Cobham  [96]  and,  independently,  in 1965  \nby  Edmonds  [130],  who  also  introduced  the  class  NP  and  conjec tured that P \u00a4 NP. \nThe  notion  of NP-completeness  was  proposed  in 1971  by  Cook  [100], who gave \nthe  \u00fbrst  NP-completeness  proofs  for  formula  satis\u00fbability  and  3-CNF  satis\u00fbabil-  \nity.  Levin  [297]  independently  discovered  the  notion,  giving  an NP-completeness  \nproof  for  a tiling  problem.  Karp  [248]  introduced  the  method ology of reductions \nin 1972  and  demonstrated  the  rich  variety  of NP-complete  problems.  Karp\u2019s  pa-  \nper  included  the  original  NP-completeness  proofs  of the  clique,  vertex-cover,  and  \nhamiltonian-cycle  problems.  Since  then,  thousands  of problems have been proven \nto be NP-complete  by  many  researchers.  \nWork in complexity theory has shed light on the com plexity of computing  ap-  \nproximate  solutions.  This  work  gives  a new  de\u00fbnition  of NP  using  <probabilis-  \ntically  checkable  proofs.=  This  new  de\u00fbnition  implies  that  for problems such as \nclique,  vertex  cover,  the  traveling-salesperson  problem  with  the  triangle  inequal-  \nity, and many others, computing good approximate so lutions (see  Chapter  35)  is \nNP-hard  and  hence  no  easier  than  computing  optimal  solution s. An introduction \nto this  area  can  be found  in Arora\u2019s  thesis  [21],  a chapter  by  Arora and Lund in \nHochbaum  [221],  a survey  article  by  Arora  [22],  a book  edited  by  Mayr,  Pr\u00a8  omel,  \nand  Steger  [319],  a survey  article  by  Johnson  [237],  and  a chapter in the textbook \nby  Arora  and  Barak  [24].  35  Approximation  Algorithms  \nMany  problems  of practical  signi\u00fbcance  are  NP-complete,  yet  they  are  too  impor-  \ntant  to abandon  merely  because  nobody  knows  how  to \u00fbnd  an optimal solution in \npolynomial  time.  Even  if a problem  is NP-complete,  there  may  be hope. You have \nat least  three  options  to get  around  NP-completeness.  First , if the actual inputs are \nsmall, an algorithm with exponential running time m ight be fast enough. Second, \nyou might be able to isolate important special case s that you can  solve  in polyno-  \nmial  time.  Third,  you  can  try  to devise  an approach  to \u00fbnd  a near-optimal solution \nin polynomial time (either in the worst case or the  expected case).  In practice,  near-  \noptimality is often good enough. We call an algorit hm that returns  near-optimal  \nsolutions an approximation  algorithm. This  chapter  presents  polynomial-time  ap-  \nproximation  algorithms  for  several  NP-complete  problems.  \nPerformance  ratios  for  approximation  algorithms  \nSuppose that you are working on an optimization pro blem in which each potential \nsolution  has  a positive  cost,  and  you  want  to \u00fbnd  a near-optimal  solution.  Depend-  \ning  on  the  problem,  you  could  de\u00fbne  an optimal  solution  as one  with maximum \npossible cost or as one with minimum possible cost,  which is to say  that  the  prob-  \nlem might be either a maximization or a minimizatio n problem. \nWe say that an algorithm for a problem has an approximation  ratio  of \ufffd.n/  if, \nfor any input of size n, the cost C of the solution produced by the algorithm is \nwithin a factor of \ufffd.n/  of the cost C \ue003 of an optimal solution: \nmax \u00ef C \nC \ue003 ; C \ue003 \nC \u00f0 \n\u0dc4 \ufffd.n/  : (35.1)  \nIf an algorithm achieves an approximation ratio of \ufffd.n/, we call it a \ue003.n/ -approxi-  \nmation  algorithm. The  de\u00fbnitions  of approximation  ratio  and  \ufffd.n/-approximation  \nalgorithm apply to both minimization and maximizati on problems.  For  a maxi-  \nmization problem, 0 < C  \u0dc4 C \ue003 , and the ratio C \ue003 =C  gives the factor by which Chapter 35 Approximation Algorithms 1105 \nthe cost of an optimal solution is larger than the cost of the approximate solution. \nSimilarly, for a minimization problem, 0<C  \ue003 \u0dc4 C , and the ratio C=C  \ue003 gives the \nfactor by which the cost of the approximate solutio n is larger than the cost of an \noptimal solution. Because we assume that all soluti ons have positive cost, these \nratios  are  always  well  de\u00fbned.  The  approximation  ratio  of an approximation  al-  \ngorithm is never less than 1, since C=C  \ue003 \u0dc4 1 implies C \ue003 =C  \ue004 1. Therefore, \na 1-approximation  algorithm  1 produces an optimal solution, and an approximation \nalgorithm with a large approximation ratio may retu rn a solution that is much worse \nthan optimal. \nFor  many  problems,  we  know  of polynomial-time  approximatio n algorithms \nwith small constant approximation ratios, although for other problems, the best \nknown  polynomial-time  approximation  algorithms  have  approximation ratios that \ngrow as functions of the input size n. An  example  of such  a problem  is the  set-cover  \nproblem  presented  in Section  35.3.  \nSome  polynomial-time  approximation  algorithms  can  achieve  increasingly  bet-  \nter approximation ratios by using more and more com putation time. For such \nproblems, you can trade computation time for the qu ality of the approximation. \nAn  example  is the  subset-sum  problem  studied  in Section  35.5. This situation is \nimportant enough to deserve a name of its own. \nAn approximation  scheme  for  an optimization  problem  is an approximation  al-  \ngorithm that takes as input not only an instance of  the problem, but also a value \n\ufffd > 0  such  that  for  any  \u00fbxed  \ufffd , the scheme is a .1 C \ufffd/-approximation  algorithm.  \nWe say that an approximation scheme is a polynomial-time  approximation  scheme  \nif for  any  \u00fbxed  \ufffd > 0 , the scheme runs in time polynomial in the size n of its input \ninstance. \nThe  running  time  of a polynomial-time  approximation  scheme  can increase very \nrapidly as \ufffd decreases.  For  example,  the  running  time  of a polynomial-time  ap-  \nproximation scheme might be O.n  2=\ue001  /. Ideally, if \ufffd decreases by a constant factor, \nthe running time to achieve the desired approximati on should not increase by more \nthan a constant factor (though not necessarily the same constant factor by which \ufffd \ndecreased). \nWe say that an approximation scheme is a fully  polynomial-time  approximation  \nscheme  if it is an approximation scheme and its running ti me is polynomial in \nboth 1=\ufffd  and the size n of the input instance. For example, the scheme migh t have \na running time of O..1=\ufffd/  2 n 3 /. With  such  a scheme,  any  constant-factor  decrease  \nin \ufffd comes  with  a corresponding  constant-factor  increase  in the  running time. \n1 When the approximation ratio is independent of n, we use the terms <approximation ratio of \ufffd= \nand < \ufffd-approximation  algorithm,=  indicating  no  dependence  on  n. 1106 Chapter 35 Approximation Algorithms \nChapter  outline  \nThe  \u00fbrst  four  sections  of this  chapter  present  some  examples  of polynomial-time  \napproximation  algorithms  for  NP-complete  problems,  and  the  \u00fbfth  section  gives  \na fully  polynomial-time  approximation  scheme.  We  begin  in Section  35.1  with  a \nstudy  of the  vertex-cover  problem,  an NP-complete  minimiza tion problem that has \nan approximation algorithm with an approximation ra tio of 2. Section  35.2  looks  at \na version  of the  traveling-salesperson  problem  in which  the  cost  function  satis\u00fbes  \nthe triangle inequality and presents an approximati on algorithm  with  an approxi-  \nmation ratio of 2. The section also shows that without the triangle inequality, for \nany constant \ufffd \ue004 1, a \ufffd-approximation  algorithm  cannot  exist  unless  P D NP. \nSection  35.3  applies  a greedy  method  as an effective  approxi mation algorithm for \nthe  set-covering  problem,  obtaining  a covering  whose  cost  is at worst a logarithmic \nfactor  larger  than  the  optimal  cost.  Section  35.4  uses  randomization  and  linear  pro-  \ngramming to develop two more approximation algorith ms. The section  \u00fbrst  de\u00fbnes  \nthe  optimization  version  of 3-CNF  satis\u00fbability  and  gives  a simple randomized \nalgorithm that produces a solution with an expected  approximation ratio of 8=7. \nThen  Section  35.4  examines  a weighted  variant  of the  vertex- cover problem and \nexhibits how to use linear programming to develop a  2-approximation  algorithm.  \nFinally,  Section  35.5  presents  a fully  polynomial-time  approximation scheme for \nthe  subset-sum  problem.  \n35.1  The  vertex-cover  problem  \nSection  34.5.2  de\u00fbned  the  vertex-cover  problem  and  proved  it NP-complete.  Recall  \nthat a vertex  cover  of an undirected graph G D .V;E/  is a subset V 0 \u0dc2 V such \nthat if .u;v/  is an edge of G, then either u 2 V 0 or v 2 V 0 (or both). The size of a \nvertex cover is the number of vertices in it. \nThe vertex-cover  problem  is to \u00fbnd  a vertex  cover  of minimum  size  in a given  \nundirected graph. We call such a vertex cover an optimal  vertex  cover. This  prob-  \nlem  is the  optimization  version  of an NP-complete  decision  problem. \nEven  though  nobody  knows  how  to \u00fbnd  an optimal  vertex  cover  in a graph G in \npolynomial  time,  there  is an ef\u00fbcient  algorithm  to \u00fbnd  a vertex  cover  that  is near-  \noptimal. The approximation algorithm A PPROX-VERTEX-COVER  on the facing \npage takes as input an undirected graph G and returns a vertex cover whose size is \nguaranteed to be no more than twice the size of an optimal vertex cover. \nFigure  35.1  illustrates  how  APPROX-VERTEX-COVER  operates on an example \ngraph. The variable C contains  the  vertex  cover  being  constructed.  Line  1 initial-  \nizes C to the empty set. Line 2 sets E 0 to be a copy of the edge set G:  E of the \ngraph. The while  loop  of lines  336  repeatedly  picks  an edge  .u;v/  from E 0 , adds 35.1  The  vertex-cover  problem  1107 \nAPPROX-VERTEX-COVER  .G/  \n1 C D ;  \n2 E 0 D G:  E \n3 while  E 0 \u00a4 ;  \n4 let .u;v/  be an arbitrary edge of E 0 \n5 C D C [ fu;vg \n6 remove from E 0 edge .u;v/  and every edge incident on either u or v \n7 return  C \nits endpoints u and v into C , and deletes all edges in E 0 that u or v covers. Finally, \nline  7 returns  the  vertex  cover  C . The running time of this algorithm is O.V  C E/, \nusing adjacency lists to represent E 0 . \nTheorem  35.1  \nAPPROX-VERTEX-COVER  is a polynomial-time  2-approximation  algorithm.  \nProof  We have already shown that A PPROX-VERTEX-COVER  runs  in polyno-  \nmial time. \nThe set C of vertices that is returned by A PPROX-VERTEX-COVER  is a vertex \ncover, since the algorithm loops until every edge i n G:  E has been covered by some \nvertex in C . \nTo see that A PPROX-VERTEX-COVER  returns a vertex cover that is at most twice \nthe size of an optimal cover, let A denote  the  set  of edges  that  line  4 of APPROX- \nVERTEX-COVER  picked. In order to cover the edges in A, any  vertex  cover4in  \nparticular, an optimal cover C \ue003 4must  include  at least  one  endpoint  of each  edge  \nin A. No two edges in A share  an endpoint,  since  once  an edge  is picked  in line  4, \nall other edges that are incident on its endpoints are deleted from E 0 in line  6. Thus,  \nno two edges in A are covered by the same vertex from C \ue003 , meaning that for every \nvertex in C \ue003 , there is at most one edge in A, giving the lower bound \njC \ue003 j \ue004 jAj (35.2)  \non the size of an optimal vertex cover. Each execut ion of line 4 picks  an edge  for  \nwhich neither of its endpoints is already in C , yielding an upper bound (an exact \nupper bound, in fact) on the size of the vertex cov er returned: \njC j D  2 jAj : (35.3)  \nCombining  equations  (35.2)  and  (35.3)  yields  \njC j D  2 jAj \n\u0dc4 2 jC \ue003 j ; \nthereby proving the theorem. 1108 Chapter 35 Approximation Algorithms \nb c d \na e f g \n(a) b c d \na e f g \n(b) \nb c d \na e f g \n(c) b c d \na e f g \n(d) \nb c d \na e f g \n(e) b c d \na e f g \n(f) \nFigure  35.1  The operation of A PPROX-VERTEX-COVER . (a)  The input graph G, which has 7 \nvertices and 8 edges. (b)  The highlighted edge .b;c/  is the  \u00fbrst  edge  chosen  by  APPROX-VERTEX- \nCOVER . Vertices b and c, in blue, are added to the set C containing the vertex cover being created. \nDashed edges .a;b/ , .c;e/ , and .c;d/  are removed since they are now covered by some vert ex \nin C . (c)  Edge .e;f/  is chosen, and vertices e and f are added to C . (d)  Edge .d;g/  is cho-  \nsen, and vertices d and g are added to C . (e)  The set C , which is the vertex cover produced by \nAPPROX-VERTEX-COVER , contains the six vertices b;c;d;e;f;g . (f)  The optimal vertex cover for \nthis problem contains only three vertices: b, d , and e. \nLet  us re\u00fcect  on  this  proof.  At  \u00fbrst,  you  might  wonder  how  you  can possibly \nprove that the size of the vertex cover returned by  APPROX-VERTEX-COVER  is at \nmost  twice  the  size  of an optimal  vertex  cover,  when  you  don\u2019t  even know the size \nof an optimal vertex cover. Instead of requiring th at you know the exact size of an \noptimal  vertex  cover,  you  \u00fbnd  a lower  bound  on  the  size.  As  Exercise  35.1-2  asks  \nyou to show, the set A of edges  that  line  4 of APPROX-VERTEX-COVER  selects is \nactually a maximal matching in the graph G. (A maximal  matching  is a matching \nto which no edges can be added and still have a mat ching.) The size of a maximal \nmatching  is, as we  argued  in the  proof  of Theorem  35.1,  a lower  bound on the size \nof an optimal vertex cover. The algorithm returns a  vertex cover whose size is at \nmost twice the size of the maximal matching A. The approximation ratio comes \nfrom relating the size of the solution returned to the lower bound. We will use this \nmethodology in later sections as well. 35.2 The traveling-salesperson problem 1109 \nExercises  \n35.1-1  \nGive  an example  of a graph  for  which  APPROX-VERTEX-COVER  always yields a \nsuboptimal solution. \n35.1-2  \nProve  that  the  set  of edges  picked  in line  4 of APPROX-VERTEX-COVER  forms a \nmaximal matching in the graph G. \n? 35.1-3  \nConsider  the  following  heuristic  to solve  the  vertex-cover  problem. Repeatedly \nselect a vertex of highest degree, and remove all o f its incident  edges.  Give  an \nexample to show that this heuristic does not provid e an approximation ratio of 2. \n(Hint: Try a bipartite graph with vertices of uniform degr ee on the left and vertices \nof varying degree on the right.) \n35.1-4  \nGive  an ef\u00fbcient  greedy  algorithm  that  \u00fbnds  an optimal  verte x cover for a tree in \nlinear time. \n35.1-5  \nThe  proof  of Theorem  34.12  on  page  1084  illustrates  that  the  vertex-cover  problem  \nand  the  NP-complete  clique  problem  are  complementary  in the  sense  that  an opti-  \nmal  vertex  cover  is the  complement  of a maximum-size  clique  in the complement \ngraph. Does this relationship imply that there is a  polynomial-time  approximation  \nalgorithm with a constant approximation ratio for t he clique problem?  Justify  your  \nanswer. \n35.2  The  traveling-salesperson  problem  \nThe  input  to the  traveling-salesperson  problem,  introduced  in Section  34.5.4,  is a \ncomplete undirected graph G D .V;E/  that has a nonnegative integer cost c.u;v/  \nassociated with each edge .u;v/  2 E. The  goal  is to \u00fbnd  a hamiltonian  cycle  (a \ntour) of G with minimum cost. As an extension of our notation,  let c.A/  denote \nthe total cost of the edges in the subset A \u0dc2 E: \nc.A/  D X  \n.u;v/2A c.u;v/:  1110 Chapter 35 Approximation Algorithms \nIn many practical situations, the least costly way to go from a place u to a place w \nis to go directly, with no intermediate steps. Put another way, cutting  out  an inter-  \nmediate stop never increases the cost. Such a cost function c satis\u00fbes  the  triangle  \ninequality : for all vertices u;v;w  2 V , \nc.u;w/  \u0dc4 c.u;v/  C c.v;w/:  \nThe triangle inequality seems as though it should n aturally hold,  and  it is au-  \ntomatically  satis\u00fbed  in several  applications.  For  example , if the vertices of the \ngraph are points in the plane and the cost of trave ling between two vertices is the \nordinary euclidean distance between them, then the triangle inequality  is satis\u00fbed.  \nFurthermore, many cost functions other than euclide an distance satisfy the triangle \ninequality. \nAs  Exercise  35.2-2  shows,  the  traveling-salesperson  problem  is NP-complete  \neven if you require the cost function to satisfy th e triangle inequality. Thus, you \nshould  not  expect  to \u00fbnd  a polynomial-time  algorithm  for  solving  this  problem  ex-  \nactly. Your time would be better spent looking for good approximation algorithms. \nIn Section  35.2.1,  we  examine  a 2-approximation  algorithm  for  the  traveling-  \nsalesperson problem with the triangle inequality. I n Section  35.2.2,  we  show  that  \nwithout  the  triangle  inequality,  a polynomial-time  approx imation algorithm with a \nconstant approximation ratio does not exist unless P D NP. \n35.2.1  The  traveling-salesperson  problem  with  the  triangle  inequality  \nApplying the methodology of the previous section, s tart by computing a structure \n4a  minimum  spanning  tree4whose  weight  gives  a lower  bound  on  the length of \nan optimal  traveling-salesperson  tour.  Then  use  the  minimum  spanning  tree  to cre-  \nate a tour whose cost is no more than twice that of  the minimum s panning  tree\u2019s  \nweight,  as long  as the  cost  function  satis\u00fbes  the  triangle  inequality.  The  proce-  \ndure APPROX-TSP-TOUR  on the next page implements this approach, calling the \nminimum-spanning-tree  algorithm  MST-P RIM on  page  596  as a subroutine.  The  \nparameter G is a complete undirected graph, and the cost functi on c satis\u00fbes  the  \ntriangle inequality. \nRecall  from  Section  12.1  that  a preorder  tree  walk  recursive ly visits every vertex \nin the  tree,  listing  a vertex  when  it is \u00fbrst  encountered,  before visiting any of its \nchildren. \nFigure  35.2  illustrates  the  operation  of APPROX-TSP-TOUR. Part  (a)  of the  \u00fbg-  \nure shows a complete undirected graph, and part (b)  shows the minimum spanning \ntree T grown from root vertex a by  MST-P RIM. Part (c) shows how a preorder \nwalk of T visits the vertices, and part (d) displays the corr esponding tour, which is \nthe tour returned by A PPROX-TSP-TOUR. Part (e) displays an optimal tour, which \nis about 23% shorter. 35.2 The traveling-salesperson problem 1111 \n(a) a d \nb f e \ng \nc \nh \n(b) a d \nb f e \ng \nc \nh \n(c) \na d \ne \nc \nh \n(d) a d \nb f e \ng \nc \nh \n(e) b f g e \nh c a \nb f g d \nFigure  35.2  The operation of A PPROX-TSP-TOUR. (a)  A complete undirected graph. Vertices lie \non intersections of integer grid lines. For example , f is one unit to the right and two units up from h. \nThe cost function between two points is the ordinar y euclidean distance. (b)  A minimum spanning \ntree T of the  complete  graph,  as computed  by  MST-P RIM. Vertex a is the  root  vertex.  Only  edges  \nin the minimum spanning tree are shown. The vertice s happen to be labeled in such a way that they \nare  added  to the  main  tree  by  MST-P RIM in alphabetical order. (c)  A walk of T , starting at a. A \nfull walk of the tree visits the vertices in the or der a;b;c;b;h;b;a;d;e;f;e;g;e;d;a . A preorder \nwalk of T lists  a vertex  just  when  it is \u00fbrst  encountered,  as indicated  by the dot next to each vertex, \nyielding the ordering a;b;c;h;d;e;f;g . (d)  A tour obtained by visiting the vertices in the ord er \ngiven by the preorder walk, which is the tour H returned by A PPROX-TSP-TOUR. Its total cost \nis approximately 19:074 . (e)  An optimal tour H \ue003 for the original complete graph. Its total cost is \napproximately 14:715 . \nAPPROX-TSP-TOUR.G;c/  \n1 select a vertex r 2 G:  V to be a <root= vertex \n2 compute a minimum spanning tree T for G from root r \nusing  MST-P RIM.G;c;r/  \n3 let H be a list  of vertices,  ordered  according  to when  they  are  \u00fbrst  visited \nin a preorder tree walk of T \n4 return  the hamiltonian cycle H 1112 Chapter 35 Approximation Algorithms \nBy  Exercise  21.2-2,  even  with  a simple  implementation  of MST-P RIM, the  run-  \nning time of A PPROX-TSP-TOUR  is \u201a.V  2 /. We now show that if the cost function \nfor  an instance  of the  traveling-salesperson  problem  satis\u00fbes  the  triangle  inequal-  \nity, then A PPROX-TSP-TOUR  returns a tour whose cost is at most twice the cost  \nof an optimal tour. \nTheorem  35.2  \nWhen the triangle inequality holds, A PPROX-TSP-TOUR  is a polynomial-time  \n2-approximation  algorithm  for  the  traveling-salesperson  problem. \nProof  We have already seen that A PPROX-TSP-TOUR  runs in polynomial time. \nLet H \ue003 denote an optimal tour for the given set of vertice s. Deleting any edge \nfrom a tour yields a spanning tree, and each edge c ost is nonnegative. Therefore, \nthe weight of the minimum spanning tree T computed in line 2 of A PPROX-TSP-  \nTOUR  provides a lower bound on the cost of an optimal to ur: \nc.T/  \u0dc4 c.H  \ue003 /: (35.4)  \nA full  walk  of T lists  the  vertices  when  they  are  \u00fbrst  visited  and  also  whenev er \nthey  are  returned  to after  a visit  to a subtree.  Let\u2019s  call  this full walk W . The full \nwalk of our example gives the order \na;b;c;b;h;b;a;d;e;f;e;g;e;d;a:  \nSince the full walk traverses every edge of T exactly  twice,  by  extending  the  de\u00fb-  \nnition of the cost c in the natural manner to handle multisets of edges,  we have \nc.W/  D 2c.T/:  (35.5)  \nInequality  (35.4)  and  equation  (35.5)  imply  that  \nc.W/  \u0dc4 2c.H  \ue003 /; (35.6)  \nand so the cost of W is within a factor of 2 of the cost of an optimal tour. \nOf  course,  the  full  walk  W is not a tour, since it visits some vertices more t han \nonce. By the triangle inequality, however, deleting  a visit to any vertex from W \ndoes not increase the cost. (When a vertex v is deleted from W between visits to \nu and w, the  resulting  ordering  speci\u00fbes  going  directly  from  u to w.) Repeatedly \napply  this  operation  on  each  visit  to a vertex  after  the  \u00fbrst  time  it\u2019s  visited  in W , so \nthat W is left  with  only  the  \u00fbrst  visit  to each  vertex.  In our  example , this process \nleaves the ordering \na;b;c;h;d;e;f;g:  \nThis ordering is the same as that obtained by a pre order walk of the tree T . Let H \nbe the cycle corresponding to this preorder walk. I t is a hamiltonian  cycle,  since  ev-  35.2 The traveling-salesperson problem 1113 \nery vertex is visited exactly once, and in fact it is the cycle computed by A PPROX- \nTSP-TOUR. Since H is obtained by deleting vertices from the full walk  W , we \nhave \nc.H/  \u0dc4 c.W/:  (35.7)  \nCombining  inequalities  (35.6)  and  (35.7)  gives  c.H/  \u0dc4 2c.H  \ue003 /, which completes \nthe proof. \nDespite  the  small  approximation  ratio  provided  by  Theorem  35.2,  APPROX- \nTSP-TOUR  is usually not the best practical choice for this p roblem. There are other \napproximation algorithms that typically perform muc h better in practice. (See the \nreferences at the end of this chapter.) \n35.2.2  The  general  traveling-salesperson  problem  \nWhen the cost function c does not satisfy the triangle inequality, there is no way to \n\u00fbnd  good  approximate  tours  in polynomial  time  unless  P D NP. \nTheorem  35.3  \nIf P \u00a4 NP, then for any constant \ufffd \ue004 1, there  is no  polynomial-time  approxi-  \nmation algorithm with approximation ratio \ufffd for  the  general  traveling-salesperson  \nproblem. \nProof  The proof is by contradiction. Suppose to the contr ary that for some  num-  \nber \ufffd \ue004 1, there  is a polynomial-time  approximation  algorithm  A with  approxima-  \ntion ratio \ufffd. Without loss of generality, assume that \ufffd is an integer, by rounding it \nup if necessary. We will show how to use A to solve  instances  of the  hamiltonian-  \ncycle  problem  (de\u00fbned  in Section  34.2)  in polynomial  time.  Since  Theorem  34.13  \non  page  1085  says  that  the  hamiltonian-cycle  problem  is NP-complete,  Theo-  \nrem  34.4  on  page  1063  implies  that  if it has  a polynomial-time  algorithm, then \nP D NP. \nLet G D .V;E/  be an instance  of the  hamiltonian-cycle  problem.  We  will  show \nhow  to determine  ef\u00fbciently  whether  G contains a hamiltonian cycle by making \nuse of the hypothesized approximation algorithm A. Convert G into an instance of \nthe  traveling-salesperson  problem  as follows.  Let  G 0 D .V;E  0 / be the complete \ngraph on V , that is, \nE 0 D f.u;v/  W u;v  2 V and u \u00a4 vg : \nAssign an integer cost to each edge in E 0 as follows: \nc.u;v/  D ( \n1 if .u;v/  2 E;  \n\ufffd jV j C  1 otherwise : 1114 Chapter 35 Approximation Algorithms \nGiven  a representation  of G, it takes time polynomial in jV j and jEj to create \nrepresentations of G 0 and c . \nNow  consider  the  traveling-salesperson  problem  .G  0 ;c/. If the original graph G \nhas a hamiltonian cycle H , then the cost function c assigns to each edge of H a \ncost of 1, and so .G  0 ;c/  contains a tour of cost jV j. On  the  other  hand,  if G does \nnot contain a hamiltonian cycle, then any tour of G 0 must use some edge not in E. \nBut any tour that uses an edge not in E has a cost of at least \n.\ufffd jV j C  1/ C .jV j \ue003  1/ D \ufffd jV j C jV j \n> \ufffd  jV j : \nBecause edges not in G are so costly, there is a gap of at least \ufffd jV j between the cost \nof a tour that is a hamiltonian cycle in G (cost jV j) and the cost of any other tour \n(cost at least \ufffd jV j C jV j). Therefore, the cost of a tour that is not a hami ltonian \ncycle in G is at least a factor of \ufffd C 1 greater than the cost of a tour that is a \nhamiltonian cycle in G. \nWhat happens upon applying the approximation algori thm A to the  traveling-  \nsalesperson problem .G  0 ;c/? Because  A is guaranteed to return a tour of cost no \nmore than \ufffd times the cost of an optimal tour, if G contains a hamiltonian cycle, \nthen A must return it. If G has no hamiltonian cycle, then A returns a tour of \ncost more than \ufffd jV j. Therefore, using A solves  the  hamiltonian-cycle  problem  in \npolynomial time. \nThe  proof  of Theorem  35.3  serves  as an example  of a general  technique to prove \nthat no good approximation algorithm exists for a p articular problem.  Given  an \nNP-hard  decision  problem  X , produce  in polynomial  time  a minimization  prob-  \nlem Y such that <yes= instances of X correspond to instances of Y with value at \nmost k (for some k), but that <no= instances of X correspond to instances of Y \nwith value greater than \ufffdk. This technique shows that, unless P D NP, there is no \npolynomial-time  \ufffd-approximation  algorithm  for  problem  Y . \nExercises  \n35.2-1  \nLet G D .V;E/  be a complete undirected graph containing at least 3 vertices, and \nlet c be a cost  function  that  satis\u00fbes  the  triangle  inequality.  Prove that c.u;v/  \ue004 0 \nfor all u;v  2 V . \n35.2-2  \nShow how in polynomial time to transform one instan ce of the traveling-sales-  \nperson problem into another instance whose cost fun ction satis\u00fbes  the  triangle  in-  \nequality. The two instances must have the same set of optimal tours. Explain why 35.3  The  set-covering  problem  1115 \nsuch  a polynomial-time  transformation  does  not  contradict  Theorem  35.3,  assum-  \ning that P \u00a4 NP. \n35.2-3  \nConsider the following closest-point  heuristic  for  building  an approximate  trav-  \neling-salesperson  tour  whose  cost  function  satis\u00fbes  the  triangle inequality. Begin \nwith a trivial cycle consisting of a single arbitra rily chosen vertex. At each step, \nidentify the vertex u that is not on the cycle but whose distance to any vertex on the \ncycle is minimum. Suppose that the vertex on the cy cle that is nearest u is vertex v. \nExtend the cycle to include u by inserting u just after v. Repeat until all vertices \nare on the cycle. Prove that this heuristic returns  a tour whose total cost is not more \nthan twice the cost of an optimal tour. \n35.2-4  \nA solution to the bottleneck  traveling-salesperson  problem  is the  hamiltonian  cy-  \ncle that minimizes the cost of the most costly edge  in the cycle. Assuming that the \ncost  function  satis\u00fbes  the  triangle  inequality,  show  that  there  exists  a polynomial-  \ntime approximation algorithm with approximation rat io 3 for this problem. ( Hint: \nShow recursively how to visit all the nodes in a bo ttleneck spanning  tree,  as dis-  \ncussed  in Problem  21-4  on  page  601,  exactly  once  by  taking  a full walk of the tree \nand skipping nodes, but without skipping more than two consecutive  intermedi-  \nate nodes. Show that the costliest edge in a bottle neck spanning tree has a cost \nbounded from above by the cost of the costliest edg e in a bottleneck hamiltonian \ncycle.) \n35.2-5  \nSuppose  that  the  vertices  for  an instance  of the  traveling-s alesperson problem are \npoints in the plane and that the cost c.u;v/  is the euclidean distance between points \nu and v. Show that an optimal tour never crosses itself. \n35.2-6  \nAdapt  the  proof  of Theorem  35.3  to show  that  for  any  constant  c \ue004 0, there is no \npolynomial-time  approximation  algorithm  with  approximat ion ratio jV j c for the \ngeneral  traveling-salesperson  problem.  \n35.3  The  set-covering  problem  \nThe  set-covering  problem  is an optimization  problem  that  models many problems \nthat require resources to be allocated. Its corresp onding decision  problem  gener-  \nalizes  the  NP-complete  vertex-cover  problem  and  is therefore  also  NP-hard.  The  1116 Chapter 35 Approximation Algorithms \napproximation  algorithm  developed  to handle  the  vertex-cover  problem  doesn\u2019t  ap-  \nply here, however. Instead, this section investigat es a simple greedy heuristic with \na logarithmic approximation ratio. That is, as the size of the instance gets larger, \nthe size of the approximate solution may grow, rela tive to the size of an optimal \nsolution. Because the logarithm function grows rath er slowly,  however,  this  ap-  \nproximation algorithm may nonetheless give useful r esults. \nAn instance .X;  F / of the set-covering  problem  consists  of a \u00fbnite  set  X and \na family F of subsets of X , such that every element of X belongs to at least one \nsubset in F : \nX D [  \nS2F S:  \nWe say that a subfamily C \u0dc2 F covers  a set of elements U if \nU \u0dc2 [  \nS2C S:  \nThe  problem  is to \u00fbnd  a minimum-size  subfamily  C \u0dc2 F whose members cover \nall of X : \nX D [  \nS2C S:  \nFigure  35.3  illustrates  the  set-covering  problem.  The  size  of C is the number of \nsets it contains, rather than the number of individ ual elements in these sets, since \nevery subfamily C that covers X must contain all jX j individual elements. In \nFigure  35.3,  the  minimum  set  cover  has  size  3. \nThe  set-covering  problem  abstracts  many  commonly  arising  combinatorial  prob-  \nlems. As a simple example, suppose that X represents a set of skills that are needed \nto solve a problem and that you have a given set of  people available to work on the \nproblem. You wish to form a committee, containing a s few people as possible, such \nthat for every requisite skill in X , at least one member of the committee has that \nskill.  The  decision  version  of the  set-covering  problem  asks  whether  a covering  ex-  \nists with size at most k, where k is an additional  parameter  speci\u00fbed  in the  problem  \ninstance.  The  decision  version  of the  problem  is NP-complete,  as Exercise  35.3-2  \nasks you to show. \nA greedy  approximation  algorithm  \nThe  greedy  method  in the  procedure  GREEDY-SET-COVER  on the facing page \nworks by picking, at each stage, the set S that  covers  the  greatest  number  of re-  \nmaining elements that are uncovered. In the example  of Figure 35.3,  GREEDY- \nSET-COVER  adds to C , in order, the sets S 1 , S 4 , and S 5 , followed by either S 3 \nor S 6 . 35.3  The  set-covering  problem  1117 \nS 3 S 6 \nS 4 S 5 S 2 S 1 \nFigure  35.3  An instance .X;  F / of the  set-covering  problem,  where  X consists of the 12  tan points \nand F D fS 1 ;S  2 ;S  3 ;S  4 ;S  5 ;S  6 g. Each set S i 2 F is outlined  in blue.  A minimum-size  set  cover  \nis C D fS 3 ;S  4 ;S  5 g, with size 3. The greedy algorithm produces a cover of size 4 by selecting either \nthe sets S 1 , S 4 , S 5 , and S 3 or the sets S 1 , S 4 , S 5 , and S 6 , in order. \nGREEDY-SET-COVER  .X;  F / \n1 U 0 D X \n2 C D ;  \n3 i D 0 \n4 while  U i \u00a4 ;  \n5 select S 2 F that maximizes jS \\ U i j \n6 U i C1 D U i \ue003 S \n7 C D C [ fS g \n8 i D i C 1 \n9 return  C \nThe greedy algorithm works as follows. At the start  of each iteration, U i is a \nsubset of X containing the remaining uncovered elements, with t he initial  sub-  \nset U 0 containing all the elements in X . The set C contains the subfamily being \nconstructed.  Line  5 is the  greedy  decision-making  step,  choosing a subset S that \ncovers as many uncovered elements as possible (brea king ties arbitrarily). After \nS is selected,  line  6 updates  the  set  of remaining  uncovered  elements, denoting \nit by U i C1 , and  line  7 places  S into C . When the algorithm terminates, C is a \nsubfamily of F that covers X . \nAnalysis  \nWe now show that the greedy algorithm returns a set  cover that is not too much \nlarger than an optimal set cover. 1118 Chapter 35 Approximation Algorithms \nTheorem  35.4  \nThe  procedure  GREEDY-SET-COVER  run on a set X and family of subsets F is a \npolynomial-time  O.lg X/-approximation  algorithm.  \nProof  Let\u2019s  \u00fbrst  show  that  the  algorithm  runs  in time  that  is polyno mial in jX j \nand jF j. The  number  of iterations  of the  loop  in lines  437  is bounded  above by \nmin fjX j ; jF jg D  O.jX j C jF j/. The loop body can be implemented to run in \nO.jX j\ue001jF j/ time. Thus the algorithm runs in O.jX j\ue001jF j\ue001 .jX jCjF j// time, which \nis polynomial  in the  input  size.  (Exercise  35.3-3  asks  for  a linear-time  algorithm.)  \nTo prove the approximation bound, let C \ue003 be an optimal set cover for the original \ninstance .X;  F /, and let k D jC \ue003 j. Since C \ue003 is also a set cover of each subset U i \nof X constructed by the algorithm, we know that any subs et U i constructed by the \nalgorithm can be covered by k sets. Therefore, if .U  i ; F / is an instance of the \nset-covering  problem,  its  optimal  set  cover  has  size  at most  k. \nIf an optimal set cover for an instance .U  i ; F / has size at most k, at least one \nof the sets in C covers at least jU i j =k  new  elements.  Thus,  line  5 of GREEDY- \nSET-COVER , which chooses a set with the maximum number of un covered ele- \nments, must choose a set in which the number of new ly covered elements is at \nleast jU i j =k. These elements are removed when constructing U i C1 , giving \njU i C1 j \u0dc4 jU i j \ue003 jU i j =k  \nD jU i j .1 \ue003 1=k/:  (35.8)  \nIterating  inequality  (35.8)  gives  \njU 0 j D jX j ; \njU 1 j \u0dc4 jU 0 j .1 \ue003 1=k/;  \njU 2 j \u0dc4 jU 1 j .1 \ue003 1=k/  D jU j .1 \ue003 1=k/  2 ; \nand in general \njU i j \u0dc4 jU 0 j .1 \ue003 1=k/  i D jX j .1 \ue003 1=k/  i : (35.9)  \nThe algorithm stops when U i D ;, which means that jU i j < 1. Thus an upper \nbound on the number of iterations of the algorithm is the smallest value of i for \nwhich jU i j <1. \nSince 1 C x \u0dc4 e x for all real x (see  inequality  (3.14)  on  page  66),  by  letting  \nx D \ue0031=k, we have 1 \ue003 1=k  \u0dc4 e \ue0021=k  , so that .1 \ue003 1=k/  k \u0dc4 .e \ue0021=k  / k D 1=e. \nDenoting the number i of iterations by ck  for some nonnegative integer c , we want \nc such that \njX j .1 \ue003 1=k/  ck  \u0dc4 jX j e \ue002c <1:  (35.10)  \nMultiplying both sides by e c and then taking the natural logarithm of both sides  \ngives c \ue004 ln jX j, so we can choose for c any integer that is at least ln jX j. We 35.4  Randomization  and  linear  programming  1119 \nchoose c D dln jX je. Since i D ck  is an upper bound on the number of iterations, \nwhich equals the size of C , and k D jC \ue003 j, we have jC j \u0dc4  i D ck  D c jC \ue003 j D  \njC \ue003 j dln jX je, and the theorem follows. \nExercises  \n35.3-1  \nConsider each of the following words as a set of le tters: farid; dash; drain; \nheard; lost; nose; shun; slate; snare; thread g. Show which set cover \nGREEDY-SET-COVER  produces  when  you  break  ties  in favor  of the  word  that  ap-  \npears  \u00fbrst  in the  dictionary.  \n35.3-2  \nShow  that  the  decision  version  of the  set-covering  problem  is NP-complete  by  \nreducing  the  vertex-cover  problem  to it. \n35.3-3  \nShow  how  to implement  GREEDY-SET-COVER  to run in O \ue002 P  \nS2F jS j \u00cd \ntime. \n35.3-4  \nThe  proof  of Theorem  35.4  says  that  when  GREEDY-SET-COVER, run  on  the  in-  \nstance .X;  F /, returns the subfamily C , then jC j \u0dc4 jC \ue003 j dln X e. Show that the \nfollowing weaker bound is trivially true: \njC j \u0dc4 jC \ue003 j max fjS j W S 2 F g : \n35.3-5  \nGREEDY-SET-COVER  can return a number of different solutions, dependi ng on \nhow  it breaks  ties  in line  5. Give  a procedure  BAD-SET-COVER-I NSTANCE .n/  that \nreturns an n-element  instance  of the  set-covering  problem  for  which,  depending \non  how  line  5 breaks  ties,  GREEDY-SET-COVER  can return a number of different \nsolutions that is exponential in n. \n35.4  Randomization  and  linear  programming  \nThis section studies two useful techniques for desi gning approximation algorithms: \nrandomization and linear programming. It starts wit h a simple randomized  algo-  \nrithm  for  an optimization  version  of 3-CNF  satis\u00fbability,  and then it shows how \nto design an approximation algorithm for a weighted  version of the  vertex-cover  \nproblem based on linear programming. This section o nly scratches the surface of 1120 Chapter 35 Approximation Algorithms \nthese two powerful techniques. The chapter notes gi ve references for further study \nof these areas. \nA randomized  approximation  algorithm  for  MAX-3-CNF  satis\ufb01ability  \nJust  as some  randomized  algorithms  compute  exact  solutions , some randomized \nalgorithms compute approximate solutions. We say th at a randomized algorithm \nfor a problem has an approximation  ratio  of \ufffd.n/  if, for any input of size n, the \nexpected  cost C of the solution produced by the randomized algorith m is within a \nfactor of \ufffd.n/  of the cost C \ue003 of an optimal solution: \nmax \u00ef C \nC \ue003 ; C \ue003 \nC \u00f0 \n\u0dc4 \ufffd.n/  : (35.11)  \nWe call a randomized algorithm that achieves an app roximation ratio of \ufffd.n/  a \nrandomized  \ue003.n/ -approximation  algorithm.  In other  words,  a randomized  ap-  \nproximation algorithm is like a deterministic appro ximation algorithm, except that \nthe approximation ratio is for an expected cost. \nA particular  instance  of 3-CNF  satis\u00fbability,  as de\u00fbned  in Section  34.4,  may  or \nmay  not  be satis\u00fbable.  In order  to be satis\u00fbable,  there  must  exist an assignment of \nthe variables so that every clause evaluates to 1. If an instance  is not  satis\u00fbable,  you  \nmight  instead  want  to know  how  <close=  to satis\u00fbable  it is, that  is, \u00fbnd  an assign-  \nment  of the  variables  that  satis\u00fbes  as many  clauses  as possib le. We call the resulting \nmaximization problem MAX-3-CNF  satis\u00fbability. The  input  to MAX-3-CNF  sat-  \nis\u00fbability  is the  same  as for  3-CNF  satis\u00fbability,  and  the  goal  is to return  an assign-  \nment of the variables that maximizes the number of clauses evaluating to 1. You \nmight be surprised that randomly setting each varia ble to 1 with probability 1=2  \nand to 0 with probability 1=2  yields a randomized 8=7-approximation  algorithm,  \nbut  we\u2019re  about  to see  why.  Recall  that  the  de\u00fbnition  of 3-CNF  satis\u00fbability  from  \nSection  34.4  requires  each  clause  to consist  of exactly  three distinct literals. We \nnow further assume that no clause contains both a v ariable and its  negation.  Exer-  \ncise  35.4-1  asks  you  to remove  this  last  assumption.  \nTheorem  35.5  \nGiven  an instance  of MAX-3-CNF  satis\u00fbability  with  n variables x 1 ;x  2 ;:::;x  n \nand m clauses, the randomized algorithm that independentl y sets each variable to 1 \nwith probability 1=2  and to 0 with probability 1=2  is a randomized 8=7-approxi-  \nmation algorithm. \nProof  Suppose that each variable is independently set to 1 with probability 1=2  \nand to 0 with probability 1=2. De\u00fbne,  for  i D 1;2;:::;m , the indicator random \nvariable 35.4  Randomization  and  linear  programming  1121 \nY i D I fclause i is satis\u00fbed g ; \nso that Y i D 1 as long as at least one of the literals in the i th clause is set to 1. \nSince no literal appears more than once in the same  clause, and since we assume \nthat no variable and its negation appear in the sam e clause, the settings of the three \nliterals in each clause are independent. A clause i s not satis\u00fbed  only  if all  three  \nof its literals are set to 0, and so Pr fclause i is not  satis\u00fbed g D  .1=2/  3 D 1=8. \nThus, we have Pr fclause i is satis\u00fbed g D  1 \ue003 1=8  D 7=8, and  Lemma  5.1  on  \npage  130  gives  E \u0152Y i \ufffd D 7=8. Let Y be the  number  of satis\u00fbed  clauses  overall,  so \nthat Y D Y 1 C Y 2 C \ue001 \ue001 \ue001 C  Y m . Then, we have \nE \u0152Y \ufffd  D E \" m X  \ni D1 Y i # \nD m X  \ni D1 E \u0152Y i \ufffd (by linearity of expectation) \nD m X  \ni D1 7=8  \nD 7m=8:  \nSince m is an upper  bound  on  the  number  of satis\u00fbed  clauses,  the  appro ximation \nratio is at most m=.7m=8/  D 8=7. \nApproximating  weighted  vertex  cover  using  linear  programming  \nThe minimum-weight  vertex-cover  problem  takes as input an undirected graph \nG D .V;E/  in which each vertex v 2 V has an associated positive weight w.v/ . \nThe weight w.V  0 / of a vertex cover V 0 \u0dc2 V is the sum of the weights of its \nvertices: w.V  0 / D P  \nv2V 0 w.v/. The  goal  is to \u00fbnd  a vertex  cover  of minimum  \nweight. \nThe approximation algorithm for unweighted vertex c over from  Section  35.1  \nwon\u2019t  work  here,  because  the  solution  it returns  could  be far  from optimal for the \nweighted  problem.  Instead,  we\u2019ll  \u00fbrst  compute  a lower  bound  on the weight of the \nminimum-weight  vertex  cover,  by  using  a linear  program.  Then  we\u2019ll  <round=  this  \nsolution and use it to obtain a vertex cover. \nStart by associating a variable x.v/  with each vertex v 2 V , and require that \nx.v/  equals either 0 or 1 for each v 2 V . The vertex cover includes v if and only if \nx.v/  D 1. Then the constraint that for any edge .u;v/ , at least one of u and v must \nbelong to the vertex cover can be expressed as x.u/  C x.v/  \ue004 1. This view gives \nrise to the following 0-1  integer  program  for  \u00fbnding  a minimum-weight  vertex  \ncover: 1122 Chapter 35 Approximation Algorithms \nminimize X  \nv2V w.v/x.v/  (35.12)  \nsubject to \nx.u/  C x.v/  \ue004 1 for each .u;v/  2 E (35.13)  \nx.v/  2 f0;1g for each v 2 V :  (35.14)  \nIn the special case in which all the weights w.v/  equal 1, this formulation is \nthe  optimization  version  of the  NP-hard  vertex-cover  problem.  Let\u2019s  remove  the  \nconstraint that x.v/  2 f0;1g and replace it by 0 \u0dc4 x.v/  \u0dc4 1, resulting in the \nfollowing linear program: \nminimize X  \nv2V w.v/x.v/  (35.15)  \nsubject to \nx.u/  C x.v/  \ue004 1 for each .u;v/  2 E (35.16)  \nx.v/  \u0dc4 1 for each v 2 V (35.17)  \nx.v/  \ue004 0 for each v 2 V :  (35.18)  \nWe refer to this linear program as the linear-programming  relaxation. Any  fea-  \nsible  solution  to the  0-1  integer  program  in lines  (35.12)3(35.14)  is also  a feasible  \nsolution  to its  linear-programming  relaxation  in lines  (35.15)3(35.18).  Therefore,  \nthe  value  of an optimal  solution  to the  linear-programming  relaxation provides a \nlower  bound  on  the  value  of an optimal  solution  to the  0-1  integer program, and \nhence  a lower  bound  on  the  optimal  weight  in the  minimum-weight  vertex-cover  \nproblem. \nThe procedure A PPROX-MIN-WEIGHT-VC  on  the  facing  page  starts  with  a so-  \nlution  to the  linear-programming  relaxation  and  uses  it to construct an approximate \nsolution  to the  minimum-weight  vertex-cover  problem.  The  procedure works as \nfollows.  Line  1 initializes  the  vertex  cover  to be empty.  Line 2 formulates the \nlinear-programming  relaxation  in lines  (35.15)3(35.18)  and then solves this linear \nprogram. An optimal solution gives each vertex v an associated value N x.v/ , where \n0 \u0dc4 N  x.v/  \u0dc4 1. The procedure uses this value to guide the choice  of which vertices \nto add to the vertex cover C in lines  335:  the  vertex  cover  C includes vertex v if \nand only if N x.v/  \ue004 1=2. In effect, the procedure <rounds= each fractional  variable \nin the  solution  to the  linear-programming  relaxation  to either 0 or 1 in order  to ob-  \ntain  a solution  to the  0-1  integer  program  in lines  (35.12)3(35.14).  Finally,  line  6 \nreturns the vertex cover C . \nTheorem  35.6  \nAlgorithm A PPROX-MIN-WEIGHT-VC  is a polynomial-time  2-approximation  al-  \ngorithm  for  the  minimum-weight  vertex-cover  problem.  35.4  Randomization  and  linear  programming  1123 \nAPPROX-MIN-WEIGHT-VC  .G;w/  \n1 C D ;  \n2 compute N x, an optimal  solution  to the  linear-programming  relaxation  \nin lines  (35.15)3(35.18)  \n3 for  each vertex v 2 V \n4 if N x.v/  \ue004 1=2  \n5 C D C [ fvg \n6 return  C \nProof  Because  there  is a polynomial-time  algorithm  to solve  the  linear program \nin line 2, and because the for  loop  of lines  335  runs  in polynomial  time,  APPROX- \nMIN-WEIGHT-VC  is a polynomial-time  algorithm.  \nIt remains to show that A PPROX-MIN-WEIGHT-VC  is a 2-approximation  algo-  \nrithm. Let C \ue003 be an optimal  solution  to the  minimum-weight  vertex-cover  prob-  \nlem, and let \u00b4 \ue003 be the  value  of an optimal  solution  to the  linear-programming  relax-  \nation  in lines  (35.15)3(35.18).  Since  an optimal  vertex  cover is a feasible solution \nto the  linear-programming  relaxation,  \u00b4 \ue003 must be a lower bound on w.C  \ue003 /, that is, \n\u00b4 \ue003 \u0dc4 w.C  \ue003 /: (35.19)  \nNext, we claim that rounding the fractional values of the variables N x.v/  in lines  335  \nproduces a set C that  is a vertex  cover  and  satis\u00fbes  w.C/  \u0dc4 2\u00b4  \ue003 . To see that C is \na vertex cover, consider any edge .u;v/  2 E. By  constraint  (35.16),  we  know  that  \nx.u/  C x.v/  \ue004 1, which implies that at least one of N x.u/  and N x.v/  is at least 1=2. \nTherefore, at least one of u and v is included in the vertex cover, and so every edge \nis covered. \nNow we consider the weight of the cover. We have \n\u00b4 \ue003 D X  \nv2V w.v/  N x.v/  \n\ue004 X  \nv2V W N  x.v/  \ue004 1=2  w.v/  N x.v/  \n\ue004 X  \nv2V W N  x.v/  \ue004 1=2  w.v/  \ue001 1 \n2 \nD X  \nv2C w.v/  \ue001 1 \n2 \nD 1 \n2 X  \nv2C w.v/  \nD 1 \n2 w.C/:  (35.20)  1124 Chapter 35 Approximation Algorithms \nCombining  inequalities  (35.19)  and  (35.20)  gives  \nw.C/  \u0dc4 2\u00b4  \ue003 \u0dc4 2w.C  \ue003 /; \nand hence A PPROX-MIN-WEIGHT-VC  is a 2-approximation  algorithm.  \nExercises  \n35.4-1  \nShow that even if a clause is allowed to contain bo th a variable and its negation, \nrandomly setting each variable to 1 with probability 1=2  and to 0 with  probabil-  \nity 1=2  still yields a randomized 8=7-approximation  algorithm.  \n35.4-2  \nThe MAX-CNF  satis\u00fbability  problem  is like  the  MAX-3-CNF  satis\u00fbability  prob-  \nlem, except that it does not restrict each clause t o have exactly  three  literals.  Give  a \nrandomized 2-approximation  algorithm  for  the  MAX-CNF  satis\u00fbability  problem. \n35.4-3  \nIn the  MAX-CUT  problem,  the  input  is an unweighted  undirecte d graph G D \n.V;E/. We  de\u00fbne  a cut  .S;V  \ue003 S/  as in Chapter  21  and  the  weight  of a cut \nas the  number  of edges  crossing  the  cut.  The  goal  is to \u00fbnd  a cut  of maximum \nweight. Suppose that each vertex v is randomly and independently placed into S \nwith probability 1=2  and into V \ue003 S with probability 1=2. Show that this algorithm \nis a randomized 2-approximation  algorithm.  \n35.4-4  \nShow  that  the  constraints  in line  (35.17)  are  redundant  in the  sense  that  remov-  \ning  them  from  the  linear-programming  relaxation  in lines  (35.15)3(35.18)  yields  a \nlinear program for which any optimal solution x must satisfy x.v/  \u0dc4 1 for each \nv 2 V . \n35.5  The  subset-sum  problem  \nRecall  from  Section  34.5.5  that  an instance  of the  subset-su m problem is given \nby a pair .S;t/ , where S is a set fx 1 ;x  2 ;:::;x  n g of positive integers and t is a \npositive integer. This decision problem asks whethe r there exists a subset of S that \nadds up exactly to the target value t . As  we  saw  in Section  34.5.5,  this  problem  is \nNP-complete.  \nThe optimization problem associated with this decis ion problem  arises  in prac-  \ntical applications. The optimization problem seeks a subset of fx 1 ;x  2 ;:::;x  n g 35.5  The  subset-sum  problem  1125 \nwhose sum is as large as possible but not larger th an t . For example, consider a \ntruck that can carry no more than t pounds, which is to be loaded with up to n dif-  \nferent boxes, the i th of which weighs x i pounds. How heavy a load can the truck \ntake without exceeding the t -pound  weight  limit?  \nWe  start  this  section  with  an exponential-time  algorithm  to compute the optimal \nvalue for this optimization problem. Then we show h ow to modify the algorithm \nso that  it becomes  a fully  polynomial-time  approximation  scheme. (Recall that a \nfully  polynomial-time  approximation  scheme  has  a running  time that is polynomial \nin 1=\ufffd  as well as in the size of the input.) \nAn  exponential-time  exact  algorithm  \nSuppose that you compute, for each subset S 0 of S , the sum of the elements in S 0 , \nand then you select, among the subsets whose sum do es not exceed t , the one whose \nsum is closest to t . This algorithm returns the optimal solution, but it might take \nexponential time. To implement this algorithm, you can use an iterative procedure \nthat, in iteration i , computes the sums of all subsets of fx 1 ;x  2 ;:::;x  i g, using as a \nstarting point the sums of all subsets of fx 1 ;x  2 ;:::;x  i \ue0021 g. In doing so, you would \nrealize that once a particular subset S 0 has a sum exceeding t , there is no reason \nto maintain it, since no superset of S 0 can  be an optimal  solution.  Let\u2019s  see  how  to \nimplement this strategy. \nThe procedure E XACT-SUBSET-SUM takes an input set S D fx 1 ;x  2 ;:::;x  n g, \nthe size n D jS j, and a target value t . This procedure iteratively computes L i , the \nlist of sums of all subsets of fx 1 ;:::;x  i g that do not exceed t , and then it returns \nthe maximum value in L n . \nIf L is a list of positive integers and x is another positive integer, then let L C x \ndenote the list of integers derived from L by increasing each element of L by x . \nFor example, if L D h1;2;3;5;9 i, then L C 2 D h3;4;5;7;11 i. This notation \nextends to sets, so that \nS C x D fs C x W s 2 S g : \nEXACT-SUBSET-SUM.S;n;t/  \n1 L 0 D h0i \n2 for  i D 1 to n \n3 L i D MERGE-LISTS .L  i \ue0021 ;L  i \ue0021 C x i / \n4 remove from L i every element that is greater than t \n5 return  the largest element in L n \nEXACT-SUBSET-SUM invokes an auxiliary procedure M ERGE-LISTS .L;L  0 /, \nwhich returns the sorted list that is the merge of its two sorted input lists L and L 0 , 1126 Chapter 35 Approximation Algorithms \nwith duplicate values removed. Like the M ERGE  procedure we used in merge sort \non  page  36,  MERGE-LISTS runs in O.jLj C jL 0 j/ time. We omit the pseudocode \nfor MERGE-LISTS. \nTo see how E XACT-SUBSET-SUM works, let P i denote  the  set  of values  ob-  \ntained by selecting each (possibly empty) subset of  fx 1 ;x  2 ;:::;x  i g and summing \nits members. For example, if S D f1;4;5 g, then \nP 1 D f0;1g ; \nP 2 D f0;1;4;5 g ; \nP 3 D f0;1;4;5;6;9;10 g : \nGiven  the  identity  \nP i D P i \ue0021 [ .P  i \ue0021 C x i /; (35.21)  \nyou can prove by induction on i (see  Exercise  35.5-1)  that  the  list  L i is a sorted list \ncontaining every element of P i whose value is not more than t . Since the length \nof L i can be as much as 2 i , EXACT-SUBSET-SUM is an exponential-time  algorithm  \nin general,  although  it is a polynomial-time  algorithm  in the special cases in which t \nis polynomial in jS j or all the numbers in S are bounded by a polynomial in jS j. \nA fully  polynomial-time  approximation  scheme  \nThe  key  to devising  a fully  polynomial-time  approximation  scheme  for  the  subset-  \nsum problem is to <trim= each list L i after  it is created.  Here\u2019s  the  idea  behind  \ntrimming: if two values in L are close to each other, then since the goal is jus t an \napproximate solution, there is no need to maintain both of them explicitly. More \nprecisely, use a trimming parameter \u0131 such that 0 < \u0131 < 1 . When trimming  a \nlist L by \u0131 , remove as many elements from L as possible, in such a way that if L 0 \nis the result of trimming L, then for every element y that was removed from L, \nsome element \u00b4 still in L 0 approximates y . For \u00b4 to approximate y , it must be no \ngreater than y and also within a factor of 1 C \u0131 of y , so that \ny \n1 C \u0131 \u0dc4 \u00b4 \u0dc4 y:  (35.22)  \nYou can think of such a \u00b4 as <representing= y in the new list L 0 . Each removed \nelement y is represented by a remaining element \u00b4 satisfying  inequality  (35.22).  \nFor example, suppose that \u0131 D 0:1  and \nL D h10;11;12;15;20;21;22;23;24;29 i : \nThen trimming L results in \nL 0 D h10;12;15;20;23;29 i ; 35.5  The  subset-sum  problem  1127 \nwhere the deleted value 11  is represented by 10, the deleted values 21  and 22  \nare represented by 20, and the deleted value 24  is represented by 23. Because \nevery element of the trimmed version of the list is  also an element of the original \nversion of the list, trimming can dramatically decr ease the number of elements kept \nwhile keeping a close (and slightly smaller) repres entative value in the list for each \ndeleted element. \nThe procedure T RIM trims list L D hy 1 ;y  2 ;:::;y  m i in \u201a.m/  time, given L and \nthe trimming parameter \u0131 . It assumes that L is sorted into monotonically increasing \norder. The output of the procedure is a trimmed, so rted list. The procedure scans \nthe elements of L in monotonically increasing order. A number is appe nded onto \nthe returned list L 0 only  if it is the  \u00fbrst  element  of L or if it cannot be represented \nby the most recent number placed into L 0 . \nTRIM.L;\u0131/  \n1 let m be the length of L \n2 L 0 D hy 1 i \n3 last D y 1 \n4 for  i D 2 to m \n5 if y i > last \ue001 .1 C \u0131/ / / y i \ue004 last because L is sorted \n6 append y i onto the end of L 0 \n7 last D y i \n8 return  L 0 \nGiven  the  procedure  TRIM, the procedure A PPROX-SUBSET-SUM on  the  fol-  \nlowing page implements the approximation scheme. Th is procedure takes as input \na set S D fx 1 ;x  2 ;:::;x  n g of n integers (in arbitrary order), the size n D jS j, the \ntarget integer t , and an approximation parameter \ufffd , where \n0<\ufffd<1:  (35.23)  \nIt returns a value \u00b4 \ue003 whose value is within a factor of 1 C \ufffd of the optimal solution. \nThe APPROX-SUBSET-SUM procedure  works  as follows.  Line  1 initializes  the  \nlist L 0 to be the list containing just the element 0. The for  loop  in lines  235  com-  \nputes L i as a sorted list containing a suitably trimmed vers ion of the set P i , with \nall elements larger than t removed. Since the procedure creates L i from L i \ue0021 , it \nmust  ensure  that  the  repeated  trimming  doesn\u2019t  introduce  too much compounded \ninaccuracy.  That\u2019s  why  instead  of the  trimming  parameter  being \ufffd in the call to \nTRIM, it has the smaller value \ufffd=2n. We\u2019ll  soon  see  that  APPROX-SUBSET-SUM \nreturns a correct approximation if one exists. 1128 Chapter 35 Approximation Algorithms \nAPPROX-SUBSET-SUM .S;n;t;\ufffd/  \n1 L 0 D h0i \n2 for  i D 1 to n \n3 L i D MERGE-LISTS .L  i \ue0021 ;L  i \ue0021 C x i / \n4 L i D TRIM.L  i ;\ufffd=2n/  \n5 remove from L i every element that is greater than t \n6 let \u00b4 \ue003 be the largest value in L n \n7 return  \u00b4 \ue003 \nAs an example, suppose that A PPROX-SUBSET-SUM is given \nS D h104;102;201;101 i \nwith t D 308  and \ufffd D 0:40. The trimming parameter \u0131 is \ufffd=2n  D 0:40=8  D 0:05. \nThe procedure computes the following values on the indicated lines: \nline  1: L 0 D h0i ; \nline  3: L 1 D h0;104 i ; \nline  4: L 1 D h0;104 i ; \nline  5: L 1 D h0;104 i ; \nline  3: L 2 D h0;102;104;206 i ; \nline  4: L 2 D h0;102;206 i ; \nline  5: L 2 D h0;102;206 i ; \nline  3: L 3 D h0;102;201;206;303;407 i ; \nline  4: L 3 D h0;102;201;303;407 i ; \nline  5: L 3 D h0;102;201;303 i ; \nline  3: L 4 D h0;101;102;201;203;302;303;404 i ; \nline  4: L 4 D h0;101;201;302;404 i ; \nline  5: L 4 D h0;101;201;302 i : \nThe procedure returns \u00b4 \ue003 D 302  as its answer, which is well within \ufffd D 40% of \nthe optimal answer 307  D 104  C 102  C 101. In fact, it is within 2%. \nTheorem  35.7  \nAPPROX-SUBSET-SUM is a fully  polynomial-time  approximation  scheme  for  the  \nsubset-sum  problem.  35.5  The  subset-sum  problem  1129 \nProof  The operations of trimming L i in line  4 and  removing  from  L i every  ele-  \nment that is greater than t maintain the property that every element of L i is also a \nmember of P i . Therefore, the value \u00b4 \ue003 returned  in line  7 is indeed  the  sum  of some  \nsubset of S , that is, \u00b4 \ue003 2 P n . Let y \ue003 2 P n denote  an optimal  solution  to the  subset-  \nsum problem, so that it is the greatest value in P n that is less than or equal to t . \nBecause  line  5 ensures  that  \u00b4 \ue003 \u0dc4 t , we know that \u00b4 \ue003 \u0dc4 y \ue003 . By  inequality  (35.1),  \nwe need to show that y \ue003 =\u00b4  \ue003 \u0dc4 1 C \ufffd . We must also show that the running time of \nthis algorithm is polynomial in both 1=\ufffd  and the size of the input. \nAs  Exercise  35.5-2  asks  you  to show,  for  every  element  y in P i that is at most t , \nthere exists an element \u00b4 2 L i such that \ny \n.1 C \ufffd=2n/  i \u0dc4 \u00b4 \u0dc4 y:  (35.24)  \nInequality  (35.24)  must  hold  for  y \ue003 2 P n , and therefore there exists an element \n\u00b4 2 L n such that \ny \ue003 \n.1 C \ufffd=2n/  n \u0dc4 \u00b4 \u0dc4 y \ue003 ; \nand thus \ny \ue003 \n\u00b4 \u0dc4 \ue002 \n1 C \ufffd \n2n  \u00cd n \n: (35.25)  \nSince there exists an element \u00b4 2 L n ful\u00fblling  inequality  (35.25),  the  inequality  \nmust hold for \u00b4 \ue003 , which is the largest value in L n , which is to say \ny \ue003 \n\u00b4 \ue003 \u0dc4 \ue002 \n1 C \ufffd \n2n  \u00cd n \n: (35.26)  \nNow we show that y \ue003 =\u00b4  \ue003 \u0dc4 1C\ufffd . We do so by showing that .1C\ufffd=2n/  n \u0dc4 1C\ufffd . \nFirst,  inequality  (35.23),  0<\ufffd<1 , implies that \n.\ufffd=2/  2 \u0dc4 \ufffd=2  : (35.27)  \nNext,  from  equation  (3.16)  on  page  66,  we  have  lim  n!1  .1 C \ufffd=2n/  n D e \ue001=2  . \nExercise  35.5-3  asks  you  to show  that  \nd \ndn  \ue002 \n1 C \ufffd \n2n  \u00cd n \n>0:  (35.28)  \nTherefore, the function .1 C \ufffd=2n/  n increases with n as it approaches its limit \nof e \ue001=2  , and we have \n\ue002 \n1 C \ufffd \n2n  \u00cd n \n\u0dc4 e \ue001=2  \n\u0dc4 1 C \ufffd=2  C .\ufffd=2/  2 (by  inequality  (3.15)  on  page  66)  \n\u0dc4 1 C \ufffd (by  inequality  (35.27))  . (35.29)  1130 Chapter 35 Approximation Algorithms \nCombining  inequalities  (35.26)  and  (35.29)  completes  the  analysis  of the  approxi-  \nmation ratio. \nTo show that A PPROX-SUBSET-SUM is a fully  polynomial-time  approximation  \nscheme, we derive a bound on the length of L i . After  trimming,  successive  ele-  \nments \u00b4 and \u00b4 0 of L i must have the relationship \u00b4 0 =\u00b4>1 C\ufffd=2n . That is, they must \ndiffer by a factor of at least 1 C \ufffd=2n . Each list, therefore, contains the value 0, \npossibly the value 1, and up to blog 1C\ue001=2n  t c additional values. The number of \nelements in each list L i is at most \nlog 1C\ue001=2n  t C 2 D ln t \nln.1 C \ufffd=2n/  C 2 \n\u0dc4 2n.1  C \ufffd=2n/  ln t \n\ufffd C 2 (by  inequality  (3.23)  on  page  67)  \n< 3n  ln t \n\ufffd C 2 (by  inequality  (35.23),  0<\ufffd<1 ) . \nThis  bound  is polynomial  in the  size  of the  input4which  is the  number of bits lg t \nneeded to represent t plus the number of bits needed to represent the set  S , which in \nturn is polynomial in n4and  in 1=\ufffd  . Since the running time of A PPROX-SUBSET- \nSUM is polynomial in the lengths of the lists L i , we conclude that A PPROX- \nSUBSET-SUM is a fully  polynomial-time  approximation  scheme.  \nExercises  \n35.5-1  \nProve  equation  (35.21).  Then  show  that  after  executing  line  4 of EXACT-SUBSET- \nSUM, L i is a sorted list containing every element of P i whose value is not more \nthan t . \n35.5-2  \nUsing induction on i , prove  inequality  (35.24).  \n35.5-3  \nProve  inequality  (35.28).  \n35.5-4  \nHow can you modify the approximation scheme present ed in this section  to \u00fbnd  \na good approximation to the smallest value not less  than t that is a sum of some \nsubset  of the  given  input  list?  \n35.5-5  \nModify the A PPROX-SUBSET-SUM procedure to also return the subset of S that \nsums to the value \u00b4 \ue003 . Problems for Chapter 35 1131 \nProblems  \n35-1  Bin  packing  \nYou are given a set of n objects, where the size s i of the i th object  satis\u00fbes  \n0<s  i <1. Your goal is to pack all the objects into the min imum number o f unit-  \nsize bins. Each bin can hold any subset of the obje cts whose total size does not \nexceed 1. \na. Prove that the problem of determining the minimum n umber of bins required is \nNP-hard.  (Hint: Reduce  from  the  subset-sum  problem.)  \nThe \u00fbrst-\u00fbt  heuristic  takes  each  object  in turn  and  places  it into  the  \u00fbrst bin that \ncan accommodate it, as follows. It maintains an ord ered list of bins. Let b denote \nthe number of bins in the list, where b increases over the course of the algorithm, \nand let hB 1 ;:::;B  b i be the list of bins. Initially b D 0 and the list is empty. \nThe algorithm takes each object i in turn  and  places  it in the  lowest-numbered  \nbin that can still accommodate it. If no bin can ac commodate object i , then b is \nincremented and a new bin B b is opened, containing object i . Let S D P  n \ni D1 s i . \nb. Argue that the optimal number of bins required is a t least dS e. \nc. Argue  that  the  \u00fbrst-\u00fbt  heuristic  leaves  at most  one  bin  at most half full. \nd. Prove  that  the  number  of bins  used  by  the  \u00fbrst-\u00fbt  heuristic  never exceeds d2S  e. \ne. Prove an approximation ratio of 2 for  the  \u00fbrst-\u00fbt  heuristic.  \nf. Give  an ef\u00fbcient  implementation  of the  \u00fbrst-\u00fbt  heuristic,  and analyze its running \ntime. \n35-2  Approximating  the  size  of a maximum  clique  \nLet G D .V;E/  be an undirected graph. For any k \ue004 1, de\u00fbne  G .k/  to be the  undi-  \nrected graph .V  .k/  ;E  .k/  /, where V .k/  is the set of all ordered k-tuples  of vertices  \nfrom V and E .k/  is de\u00fbned  so that  .v 1 ;v  2 ;:::;v  k / is adjacent to .w  1 ;w  2 ;:::;w  k / \nif and only if for i D 1;2;:::;k , either vertex v i is adjacent to w i in G, or else \nv i D w i . \na. Prove that the size of the maximum clique in G .k/  is equal to the kth power of \nthe size of the maximum clique in G. \nb. Argue that if there is an approximation algorithm t hat has a constant  approxi-  \nmation  ratio  for  \u00fbnding  a maximum-size  clique,  then  there  is a polynomial-time  \napproximation scheme for the problem. 1132 Chapter 35 Approximation Algorithms \n35-3  Weighted  set-covering  problem  \nSuppose  that  sets  have  weights  in the  set-covering  problem,  so that each set S i in \nthe family F has an associated weight w i . The weight of a cover C is P  \nS i 2C w i . \nThe  goal  is wish  to determine  a minimum-weight  cover.  (Section  35.3  handles  the  \ncase in which w i D 1 for all i .) \nShow  how  to generalize  the  greedy  set-covering  heuristic  in a natural manner \nto provide an approximate solution for any instance  of the weighted  set-covering  \nproblem. Letting d be the maximum size of any set S i , show that your heuristic \nhas an approximation ratio of H.d/  D P  d \ni D1 1=i  . \n35-4  Maximum  matching  \nRecall that for an undirected graph G, a matching is a set of edges such that no \ntwo edges in the set are incident on the same verte x. Section 2 5.1  showed  how  \nto \u00fbnd  a maximum  matching  in a bipartite  graph,  that  is, a matc hing such that no \nother matching in G contains more edges. This problem examines matching s in \nundirected graphs that are not required to be bipar tite. \na. Show that a maximal matching need not be a maximum matching by exhibiting \nan undirected graph G and a maximal matching M  in G that is not a maximum \nmatching. ( Hint: You  can  \u00fbnd  such  a graph  with  only  four  vertices.)  \nb. Consider a connected, undirected graph G D .V;E/. Give  an O.E/-time  \ngreedy  algorithm  to \u00fbnd  a maximal  matching  in G. \nThis  problem  concentrates  on  a polynomial-time  approximation  algorithm  for  max-  \nimum matching. Whereas the fastest known algorithm for maximum matching \ntakes superlinear (but polynomial) time, the approx imation algorithm here will run \nin linear  time.  You  will  show  that  the  linear-time  greedy  algorithm for maximal \nmatching in part (b) is a 2-approximation  algorithm  for  maximum  matching.  \nc. Show that the size of a maximum matching in G is a lower bound on the size \nof any vertex cover for G. \nd. Consider a maximal matching M  in G D .V;E/ . Let T D fv 2 V W some edge \nin M  is incident on vg. What can you say about the subgraph of G induced by \nthe vertices of G that are not in T ? \ne. Conclude from part (d) that 2 jM  j is the size of a vertex cover for G. \nf. Using parts (c) and (e), prove that the greedy algo rithm in part (b) is a 2-approx-  \nimation algorithm for maximum matching. Problems for Chapter 35 1133 \n35-5  Parallel  machine  scheduling  \nIn the parallel-machine-scheduling  problem , the input has two parts: n jobs, \nJ 1 ;J  2 ;:::;J  n , where each job J k has an associated nonnegative processing time \nof p k , and m identical machines, M  1 ;M  2 ;:::;M  m . Any  job  can  run  on  any  ma-  \nchine. A schedule  speci\u00fbes,  for  each  job  J k , the machine on which it runs and the \ntime period during which it runs. Each job J k must run on some machine M  i for \np k consecutive time units, and during that time period  no other job may run on M  i . \nLet C k denote the completion  time  of job J k , that is, the time at which job J k \ncompletes  processing.  Given  a schedule,  de\u00fbne  C max D max fC j W 1 \u0dc4 j \u0dc4 ng to \nbe the makespan  of the  schedule.  The  goal  is to \u00fbnd  a schedule  whose  makespan  \nis minimum. \nFor example, consider an input with two machines M  1 and M  2 , and four jobs \nJ 1 , J 2 , J 3 , and J 4 with p 1 D 2, p 2 D 12, p 3 D 4, and p 4 D 5. Then one possible \nschedule runs, on machine M  1 , job J 1 followed by job J 2 , and on machine M  2 , \njob J 4 followed by job J 3 . For this schedule, C 1 D 2, C 2 D 14, C 3 D 9, C 4 D 5, \nand C max D 14. An optimal schedule runs job J 2 on machine M  1 and jobs J 1 , J 3 , \nand J 4 on machine M  2 . For this schedule, we have C 1 D 2, C 2 D 12, C 3 D 6, and \nC 4 D 11, and so C max D 12. \nGiven  the  input  to a parallel-machine-scheduling  problem,  let C \ue003 \nmax denote the \nmakespan of an optimal schedule. \na. Show that the optimal makespan is at least as large  as the greatest processing \ntime, that is, \nC \ue003 \nmax \ue004 max fp k W 1 \u0dc4 k \u0dc4 ng : \nb. Show that the optimal makespan is at least as large  as the average machine load, \nthat is, \nC \ue003 \nmax \ue004 1 \nm n X  \nkD1 p k : \nConsider the following greedy algorithm for paralle l machine scheduling:  when-  \never a machine is idle, schedule any job that has n ot yet been scheduled. \nc. Write pseudocode to implement this greedy algorithm . What is the running \ntime  of your  algorithm?  \nd. For the schedule returned by the greedy algorithm, show that \nC max \u0dc4 1 \nm n X  \nkD1 p k C max fp k W 1 \u0dc4 k \u0dc4 ng : \nConclude  that  this  algorithm  is a polynomial-time  2-approximation  algorithm.  1134 Chapter 35 Approximation Algorithms \n35-6  Approximating  a maximum  spanning  tree  \nLet G D .V;E/  be an undirected graph with distinct edge weights w.u;v/  on each \nedge .u;v/  2 E. For each vertex v 2 V , denote by max .v/  the  maximum-weight  \nedge incident on that vertex. Let S G D fmax.v/  W v 2 V g be the  set  of maximum-  \nweight edges incident on each vertex, and let T G be the  maximum-weight  spanning  \ntree of G, that is, the spanning tree of maximum total weigh t. For any subset of \nedges E 0 \u0dc2 E, de\u00fbne  w.E  0 / D P  \n.u;v/2E 0 w.u;v/ . \na. Give  an example  of a graph  with  at least  4 vertices for which S G D T G . \nb. Give  an example  of a graph  with  at least  4 vertices for which S G \u00a4 T G . \nc. Prove that S G \u0dc2 T G for any graph G. \nd. Prove that w.S  G / \ue004 w.T  G /=2  for any graph G. \ne. Give  an O.V  C E/-time  algorithm  to compute  a 2-approximation  to the  maxi-  \nmum spanning tree. \n35-7  An  approximation  algorithm  for  the  0-1  knapsack  problem  \nRecall  the  knapsack  problem  from  Section  15.2.  The  input  includes n items, where \nthe i th item is worth v i dollars and weighs w i pounds. The input also includes the \ncapacity of a knapsack, which is W pounds. Here, we add the further assumptions \nthat each weight w i is at most W and that the items are indexed in monotonically \ndecreasing order of their values: v 1 \ue004 v 2 \ue004 \ue001 \ue001 \ue001 \ue004  v n . \nIn the  0-1  knapsack  problem,  the  goal  is to \u00fbnd  a subset  of the  items whose total \nweight is at most W and whose total value is maximum. The fractional kn apsack \nproblem  is like  the  0-1  knapsack  problem,  except  that  a fraction of each item may \nbe put into the knapsack, rather than either all or  none of each item. If a fraction x i \nof item i goes into the knapsack, where 0 \u0dc4 x i \u0dc4 1, it contributes x i w i to the \nweight of the knapsack and adds value x i v i . The goal of this problem is to develop \na polynomial-time  2-approximation  algorithm  for  the  0-1  knapsack  problem.  \nIn order  to design  a polynomial-time  algorithm,  let\u2019s  consider  restricted  in-  \nstances  of the  0-1  knapsack  problem.  Given  an instance  I of the knapsack problem, \nform restricted instances I j , for j D 1;2;:::;n , by removing items 1;2;:::;j  \ue003 1 \nand requiring the solution to include item j (all of item j in both the fractional and \n0-1  knapsack  problems).  No  items  are  removed  in instance  I 1 . For instance I j , \nlet P j denote  an optimal  solution  to the  0-1  problem  and  Q j denote an optimal \nsolution to the fractional problem. \na. Argue that an optimal solution to instance I of the  0-1  knapsack  problem  is one  \nof fP 1 ;P  2 ;:::;P  n g. Notes for Chapter 35 1135 \nb. Prove  that  to \u00fbnd  an optimal  solution  Q j to the  fractional  problem  for  in-  \nstance I j , you can include item j and then use the greedy algorithm in which \neach step takes as much as possible of the unchosen  item with the maximum \nvalue per pound v i =w  i in the set fj C 1;j  C 2;:::;n g. \nc. Prove that there is always an optimal solution Q j to the fractional problem for \ninstance I j that includes at most one item fractionally. That i s, for all items \nexcept possibly one, either all of the item or none  of the item goes into the \nknapsack. \nd. Given  an optimal  solution  Q j to the fractional problem for instance I j , form \nsolution R j from Q j by deleting any fractional items from Q j . Let v.S/  denote \nthe total value of items taken in a solution S . Prove that v.R  j / \ue004 v.Q  j /=2  \ue004 \nv.P  j /=2. \ne. Give  a polynomial-time  algorithm  that  returns  a maximum-va lue solution from \nthe set fR 1 ;R  2 ;:::;R  n g, and  prove  that  your  algorithm  is a polynomial-time  \n2-approximation  algorithm  for  the  0-1  knapsack  problem.  \nChapter  notes  \nAlthough methods that do not necessarily compute ex act solutions have been \nknown for thousands of years (for example, methods to approximate the value \nof \ufffd ), the notion of an approximation algorithm is much  more recent. Hochbaum \n[221]  credits  Garey,  Graham,  and  Ullman  [175]  and  Johnson  [236]  with  formal-  \nizing  the  concept  of a polynomial-time  approximation  algorithm.  The  \u00fbrst  such  \nalgorithm  is often  credited  to Graham  [197].  \nSince this early work, thousands of approximation a lgorithms  have  been  de-  \nsigned for a wide range of problems, and there is a  wealth of literature  on  this  \u00fbeld.  \nTexts  by  Ausiello  et al.  [29],  Hochbaum  [221],  Vazirani  [446], and Williamson and \nShmoys  [459]  deal  exclusively  with  approximation  algorith ms, as do surveys by \nShmoys  [409]  and  Klein  and  Young  [256].  Several  other  texts,  such  as Garey  and  \nJohnson  [176]  and  Papadimitriou  and  Steiglitz  [353],  have  signi\u00fbcant  coverage  of \napproximation algorithms as well. Books edited by L awler, Lenstra,  Rinnooy  Kan,  \nand  Shmoys  [277]  and  by  Gutin  and  Punnen  [204]  provide  extens ive treatments of \napproximation algorithms and heuristics for the tra veling-salesperson  problem.  \nPapadimitriou and Steiglitz attribute the algorithm  APPROX-VERTEX-COVER  \nto F. Gavril  and  M.  Yannakakis.  The  vertex-cover  problem  has  been  studied  exten-  \nsively  (Hochbaum  [221]  lists  16  different  approximation  algorithms  for  this  prob-  \nlem), but all the approximation ratios are at least  2 \ue003 o.1/. 1136 Chapter 35 Approximation Algorithms \nThe algorithm A PPROX-TSP-TOUR  appears in a paper by Rosenkrantz, Stearns, \nand  Lewis  [384].  Christo\u00fbdes  improved  on  this  algorithm  and  gave a 3=2-approxi-  \nmation  algorithm  for  the  traveling-salesperson  problem  with the triangle inequality. \nArora  [23]  and  Mitchell  [330]  have  shown  that  if the  points  lie in the euclidean \nplane,  there  is a polynomial-time  approximation  scheme.  Theorem  35.3  is due  to \nSahni  and  Gonzalez  [392].  \nThe algorithm A PPROX-SUBSET-SUM and its analysis are loosely modeled after \nrelated approximation algorithms for the knapsack a nd subset-sum  problems  by  \nIbarra  and  Kim  [234].  \nProblem  35-7  is a combinatorial  version  of a more  general  result  on  approximat-  \ning  knapsack-type  integer  programs  by  Bienstock  and  McClosky  [55].  \nThe  randomized  algorithm  for  MAX-3-CNF  satis\u00fbability  is implicit in the work \nof Johnson  [236].  The  weighted  vertex-cover  algorithm  is by  Hochbaum [220]. \nSection  35.4  only  touches  on  the  power  of randomization  and  linear programming \nin the design of approximation algorithms. A combin ation of these two ideas yields \na technique called <randomized rounding,= which for mulates a problem  as an in-  \nteger  linear  program,  solves  the  linear-programming  relax ation, and interprets the \nvariables in the solution as probabilities. These p robabilities then help guide the \nsolution  of the  original  problem.  This  technique  was  \u00fbrst  used by Raghavan and \nThompson  [374],  and  it has  had  many  subsequent  uses.  (See  Motwani, Naor, and \nRaghavan  [335]  for  a survey.)  Several  other  notable  ideas  in the  \u00fbeld  of approxi-  \nmation  algorithms  include  the  primal-dual  method  (see  Goem ans and Williamson \n[184]  for  a survey),  \u00fbnding  sparse  cuts  for  use  in divide-and-conquer  algorithms  \n[288],  and  the  use  of semide\u00fbnite  programming  [183].  \nAs  mentioned  in the  chapter  notes  for  Chapter  34,  results  in probabilistically \ncheckable proofs have led to lower bounds on the ap proximability  of many  prob-  \nlems, including several in this chapter. In additio n to the references there, the \nchapter  by  Arora  and  Lund  [26]  contains  a good  description  of the relationship \nbetween probabilistically checkable proofs and the hardness of approximating  var-  \nious problems. Part  VIII  Appendix:  Mathematical  Background  Introduction  \nWhen you analyze algorithms, you often need to draw  upon a body of mathematical \ntools.  Some  of these  tools  are  as simple  as high-school  algeb ra, but others may be \nnew to you. In Part I, we saw how to manipulate asy mptotic notations and solve \nrecurrences. This appendix comprises a compendium o f several other concepts and \nmethods used in analyzing algorithms. As noted in t he introduction to Part I, you \nmay have seen much of the material in this appendix  before having read this book, \nalthough  some  of the  speci\u00fbc  notational  conventions  appear ing here might differ \nfrom those you have seen elsewhere. Hence, you shou ld treat this appendix as \nreference material. As in the rest of this book, ho wever, we have included exercises \nand problems, in order for you to improve your skil ls in these areas. \nAppendix A offers methods for evaluating and boundi ng summations, which \noccur frequently in the analysis of algorithms. Man y of the formulas here appear \nin any  calculus  text,  but  you  will  \u00fbnd  it convenient  to have  these methods compiled \nin one place. \nAppendix  B contains  basic  de\u00fbnitions  and  notations  for  sets, relations, functions, \ngraphs, and trees. It also gives some basic propert ies of these mathematical objects. \nAppendix C begins with elementary principles of cou nting: permutations,  com-  \nbinations,  and  the  like.  The  remainder  contains  de\u00fbnitions  and properties of basic \nprobability. Most of the algorithms in this book re quire no probability for their \nanalysis, and thus you can easily omit the latter s ections of the  chapter  on  a \u00fbrst  \nreading, even without skimming them. Later, when yo u encounter a probabilistic \nanalysis  that  you  want  to understand  better,  you  will  \u00fbnd  Appendix  C well  orga-  \nnized for reference purposes. \nAppendix  D de\u00fbnes  matrices,  their  operations,  and  some  of their  basic  prop-  \nerties. You have probably seen most of this materia l already if you have taken a \ncourse  in linear  algebra.  But  you  might  \u00fbnd  it helpful  to have  one place to look for \nnotations  and  de\u00fbnitions.  A Summations  \nWhen an algorithm contains an iterative control con struct such as a while  or for  \nloop, you can express its running time as the sum o f the times spent  on  each  execu-  \ntion of the body of the loop. For example, Section 2.2 argued that the i th iteration \nof insertion sort took time proportional to i in the worst case. Adding up the time \nspent on each iteration produced the summation (or series) P  n \ni D2 i . Evaluating this \nsummation resulted in a bound of \u201a.n  2 / on  the  worst-case  running  time  of the  \nalgorithm. This example illustrates why you should know how to manipulate and \nbound summations. \nSection  A.1  lists  several  basic  formulas  involving  summations.  Section  A.2  of-  \nfers useful techniques for bounding summations. The  formulas in Section  A.1  \nappear without proof, though proofs for some of the m appear in Section A.2 to \nillustrate  the  methods  of that  section.  You  can  \u00fbnd  most  of the other proofs in any \ncalculus text. \nA.1  Summation  formulas  and  properties  \nGiven  a sequence  a 1 ;a  2 ;:::;a  n of numbers, where n is a nonnegative integer, the \n\u00fbnite  sum  a 1 C a 2 C \ue001 \ue001 \ue001 C  a n can be expressed as P  n \nkD1 a k . If n D 0, the value of \nthe  summation  is de\u00fbned  to be 0. The  value  of a \u00fbnite  series  is always  well  de\u00fbned,  \nand the order in which its terms are added does not  matter. \nGiven  an in\u00fbnite  sequence  a 1 ;a  2 ;:::  of numbers,  we  can  write  their  in\u00fbnite  sum  \na 1 C a 2 C \ue001 \ue001 \ue001  as P  1  \nkD1 a k , which means lim n!1  P  n \nkD1 a k . If the limit does not \nexist, the series diverges , and otherwise, it converges . The terms of a convergent \nseries cannot always be added in any order. You can , however, rearrange the terms \nof an absolutely  convergent  series , that is, a series P  1  \nkD1 a k for which the series P  1  \nkD1 ja k j also converges. A.1  Summation  formulas  and  properties  1141 \nLinearity  \nFor any real number c and  any  \u00fbnite  sequences  a 1 ;a  2 ;:::;a  n and b 1 ;b  2 ;:::;b  n , \nn X  \nkD1 .ca  k C b k / D c n X  \nkD1 a k C n X  \nkD1 b k : \nThe  linearity  property  also  applies  to in\u00fbnite  convergent  series. \nThe linearity property applies to summations incorp orating asymptotic notation. \nFor example, \nn X  \nkD1 \u201a.f.k//  D \u201a \ue001 n X  \nkD1 f.k/  ! \n: \nIn this equation, the \u201a-notation  on  the  left-hand  side  applies  to the  variable  k, but \non  the  right-hand  side,  it applies  to n. Such  manipulations  also  apply  to in\u00fbnite  \nconvergent series. \nArithmetic  series  \nThe summation \nn X  \nkD1 k D 1 C 2 C \ue001 \ue001 \ue001 C  n;  \nis an arithmetic  series  and has the value \nn X  \nkD1 k D n.n  C 1/ \n2 (A.1)  \nD \u201a.n  2 /: (A.2) \nA general  arithmetic  series  includes an additive constant a \ue004 0 and a constant \ncoef\u00fbcient  b>0  in each term, but has the same total asymptotically : \nn X  \nkD1 .a C bk/  D \u201a.n  2 /: (A.3)  \nSums  of squares  and  cubes  \nThe following formulas apply to summations of squar es and cubes: \nn X  \nkD0 k 2 D n.n  C 1/.2n  C 1/ \n6 ; (A.4)  \nn X  \nkD0 k 3 D n 2 .n C 1/ 2 \n4 : (A.5)  1142  Appendix  A Summations  \nGeometric  series  \nFor real x \u00a4 1, the summation \nn X  \nkD0 x k D 1 C x C x 2 C \ue001 \ue001 \ue001 C  x n \nis a geometric  series  and has the value \nn X  \nkD0 x k D x nC1 \ue003 1 \nx \ue003 1 : (A.6)  \nThe  in\u00fbnite  decreasing  geometric  series  occurs  when  the  summation  is in\u00fbnite  \nand jx j <1: \n1  X  \nkD0 x k D 1 \n1 \ue003 x : (A.7)  \nIf we assume that 0 0 D 1, these formulas apply even when x D 0. \nHarmonic  series  \nFor positive integers n, the nth harmonic  number  is \nH n D 1 C 1 \n2 C 1 \n3 C 1 \n4 C \ue001 \ue001 \ue001 C  1 \nn \nD n X  \nkD1 1 \nk (A.8)  \nD ln n C O.1/:  (A.9) \nInequalities  (A.20)  and  (A.21)  on  page  1150  provide  the  stronger bounds \nln.n C 1/ \u0dc4 H n \u0dc4 ln n C 1:  (A.10)  \nIntegrating  and  differentiating  series  \nIntegrating or differentiating the formulas above y ields additional formulas. For \nexample,  differentiating  both  sides  of the  in\u00fbnite  geometric  series  (A.7)  and  mul-  \ntiplying by x gives \n1  X  \nkD0 kx  k D x \n.1 \ue003 x/  2 (A.11)  \nfor jx j <1. A.1  Summation  formulas  and  properties  1143 \nTelescoping  series  \nFor any sequence a 0 ;a  1 ;:::;a  n , \nn X  \nkD1 .a k \ue003 a k\ue0021 / D a n \ue003 a 0 ; (A.12)  \nsince each of the terms a 1 ;a  2 ;:::;a  n\ue0021 is added in exactly once and subtracted out \nexactly once. We say that the sum telescopes . Similarly, \nn\ue0021 X  \nkD0 .a k \ue003 a kC1 / D a 0 \ue003 a n : \nAs an example of a telescoping sum, consider the se ries \nn\ue0021 X  \nkD1 1 \nk.k  C 1/ : \nRewriting each term as \n1 \nk.k  C 1/ D 1 \nk \ue003 1 \nk C 1 ; \ngives \nn\ue0021 X  \nkD1 1 \nk.k  C 1/ D n\ue0021 X  \nkD1 \u00ce 1 \nk \ue003 1 \nk C 1 \u00cf \nD 1 \ue003 1 \nn : \nReindexing  summations  \nA series  can  sometimes  be simpli\u00fbed  by  changing  its  index,  often reversing the \norder of summation. Consider the series P  n \nkD0 a n\ue002k . Because the terms in this \nsummation are a n ;a  n\ue0021 ;:::;a  0 , we can reverse the order of indices by letting j D \nn \ue003 k and rewrite this summation as \nn X  \nkD0 a n\ue002k D n X  \nj D0 a j : (A.13)  \nGenerally,  if the  summation  index  appears  in the  body  of the  sum with a minus \nsign,  it\u2019s  worth  thinking  about  reindexing.  \nAs an example, consider the summation 1144  Appendix  A Summations  \nn X  \nkD1 1 \nn \ue003 k C 1 : \nThe index k appears with a negative sign in 1=.n  \ue003 k C 1/. And indeed, we can \nsimplify this summation, this time setting j D n \ue003 k C 1, yielding \nn X  \nkD1 1 \nn \ue003 k C 1 D n X  \nj D1 1 \nj ; (A.14)  \nwhich  is just  the  harmonic  series  (A.8).  \nProducts  \nThe  \u00fbnite  product  a 1 a 2 \ue001 \ue001 \ue001  a n can be expressed as \nn Y  \nkD1 a k : \nIf n D 0, the  value  of the  product  is de\u00fbned  to be 1. You can convert a formula \nwith a product to a formula with a summation by usi ng the identity \nlg \ue001 n Y  \nkD1 a k ! \nD n X  \nkD1 lg a k : \nExercises  \nA.1-1  \nProve that P  n \nkD1 O.f  k .i//  D O \u00e3P  n \nkD1 f k .i/  \u00e4 \nby using the linearity property of \nsummations. \nA.1-2  \nFind a simple formula for P  n \nkD1 .2k  \ue003 1/. \nA.1-3  \nInterpret  the  decimal  number  111,111,111  in light  of equation  (A.6).  \nA.1-4  \nEvaluate  the  in\u00fbnite  series  1 \ue003 1 \n2 C 1 \n4 \ue003 1 \n8 C 1 \n16  \ue003 \ue001 \ue001 \ue001 . \nA.1-5  \nLet c \ue004 0 be a constant. Show that P  n \nkD1 k c D \u201a.n  cC1 /. \nA.1-6  \nShow that P  1  \nkD0 k 2 x k D x.1  C x/=.1  \ue003 x/  3 for jx j <1. A.2  Bounding  summations  1145 \nA.1-7  \nProve that P  n \nkD1 p \nk lg k D \u201a.n  3=2  lg 1=2  n/. (Hint: Show the asymptotic upper \nand lower bounds separately.) \n? A.1-8  \nShow that P  n \nkD1 1=.2k  \ue003 1/ D ln. p n/ C O.1/  by manipulating the harmonic \nseries. \n? A.1-9  \nShow that P  1  \nkD0 .k \ue003 1/=2  k D 0. \n? A.1-10  \nEvaluate the sum P  1  \nkD1 .2k  C 1/x  2k  for jx j <1. \n? A.1-11  \nEvaluate the product Q  n \nkD2 .1 \ue003 1=k  2 /. \nA.2  Bounding  summations  \nYou can choose from several techniques to bound the  summations that describe the \nrunning times of algorithms. Here are some of the m ost frequently used methods. \nMathematical  induction  \nThe most basic way to evaluate a series is to use m athematical induction. As an \nexample,  let\u2019s  prove  that  the  arithmetic  series  P  n \nkD1 k evaluates to n.n  C 1/=2 . For \nn D 1, we have that n.n  C 1/=2  D 1 \ue001 2=2  D 1, which equals P  1 \nkD1 k. With the \ninductive assumption that it holds for n, we prove that it holds for n C 1. We have \nnC1 X  \nkD1 k D n X  \nkD1 k C .n C 1/ \nD n.n  C 1/ \n2 C .n C 1/ \nD n 2 C n C 2n  C 2 \n2 \nD .n C 1/.n  C 2/ \n2 : \nYou  don\u2019t  always  need  to guess  the  exact  value  of a summation  in order to use \nmathematical induction. Instead, you can use induct ion to prove an upper or lower 1146  Appendix  A Summations  \nbound  on  a summation.  As  an example,  let\u2019s  prove  the  asymptot ic upper bound P  n \nkD0 3 k D O.3  n /. More  speci\u00fbcally,  we\u2019ll  prove  that  P  n \nkD0 3 k \u0dc4 c3  n for some \nconstant c . For the initial condition n D 0, we have P  0 \nkD0 3 k D 1 \u0dc4 c \ue001 1 as long \nas c \ue004 1. Assuming that the bound holds for n, we prove that it holds for n C 1. \nWe have \nnC1 X  \nkD0 3 k D n X  \nkD0 3 k C 3 nC1 \n\u0dc4 c3  n C 3 nC1 (by the inductive hypothesis) \nD \u00ce 1 \n3 C 1 \nc \u00cf \nc3  nC1 \n\u0dc4 c3  nC1 \nas long as .1=3  C 1=c/  \u0dc4 1 or, equivalently, c \ue004 3=2. Thus, P  n \nkD0 3 k D O.3  n /, \nas we wished to show. \nYou need to take care when using asymptotic notatio n to prove bounds  by  in-  \nduction. Consider the following fallacious proof th at P  n \nkD1 k D O.n/ . Certainly, P  1 \nkD1 k D O.1/ . Assuming that the bound holds for n, we now prove it for n C 1: \nnC1 X  \nkD1 k D n X  \nkD1 k C .n C 1/ \nD O.n/  C .n C 1/ \u0143  wrong! \nD O.n  C 1/:  \nThe bug in the argument is that the <constant= hidd en by the <big-oh=  grows  with  n \nand thus is not constant. We have not shown that th e same constant works for all n. \nBounding  the  terms  \nYou can sometimes obtain a good upper bound on a se ries by bounding each term \nof the  series,  and  it often  suf\u00fbces  to use  the  largest  term  to bound the others. For \nexample,  a quick  upper  bound  on  the  arithmetic  series  (A.1)  is \nn X  \nkD1 k \u0dc4 n X  \nkD1 n \nD n 2 : \nIn general, for a series P  n \nkD1 a k , if we let a max D max fa k W 1 \u0dc4 k \u0dc4 ng, then \nn X  \nkD1 a k \u0dc4 n \ue001 a max : A.2  Bounding  summations  1147 \nThe technique of bounding each term in a series by the largest term is a weak \nmethod when the series can in fact be bounded by a geometric se ries.  Given  the  \nseries P  n \nkD0 a k , suppose that a kC1 =a  k \u0dc4 r for all k \ue004 0, where 0 <r <1  is a \nconstant.  You  can  bound  the  sum  by  an in\u00fbnite  decreasing  geom etric series, since \na k \u0dc4 a 0 r k , and thus \nn X  \nkD0 a k \u0dc4 1  X  \nkD0 a 0 r k \nD a 0 1  X  \nkD0 r k (A.15)  \nD a 0 1 \n1 \ue003 r : (A.16)  \nYou can apply this method to bound the summation P  1  \nkD1 .k=3  k /. In order to \nstart the summation at k D 0, rewrite it as P  1  \nkD0 ..k  C1/=3  kC1 /. The  \u00fbrst  term  (a 0 ) \nis 1=3, and the ratio ( r ) of consecutive terms is \n.k C 2/=3  kC2 \n.k C 1/=3  kC1 D 1 \n3 \ue001 k C 2 \nk C 1 \n\u0dc4 2 \n3 \nfor all k \ue004 0. Thus, we have \n1  X  \nkD1 k \n3 k D 1  X  \nkD0 k C 1 \n3 kC1 \n\u0dc4 1 \n3 \ue001 1 \n1 \ue003 2=3  \nD 1:  \nA common bug in applying this method is to show tha t the ratio of consecu-  \ntive terms is less than 1 and then to assume that the summation is bounded by  a \ngeometric  series.  An  example  is the  in\u00fbnite  harmonic  series , which diverges since \n1  X  \nkD1 1 \nk D lim \nn!1  n X  \nkD1 1 \nk \nD lim \nn!1  \u201a.lg n/ \nD 1  : \nThe ratio of the .k C1/st and kth terms in this series is k=.k  C1/<1 , but the series \nis not bounded by a decreasing geometric series. To  bound a series by a geometric 1148  Appendix  A Summations  \nseries, you need to show that there is an r <1 , which is a constant , such that the \nratio of all pairs of consecutive terms never excee ds r . In the harmonic series, no \nsuch r exists because the ratio becomes arbitrarily close to 1. \nSplitting  summations  \nOne  way  to obtain  bounds  on  a dif\u00fbcult  summation  is to express  the series as the \nsum of two or more series by partitioning the range  of the index and then to bound \neach  of the  resulting  series.  For  example,  let\u2019s  \u00fbnd  a lower  bound on the arithmetic \nseries P  n \nkD1 k, which we have already seen has an upper bound of n 2 . You might \nattempt to bound each term in the summation by the smallest term, but since that \nterm is 1, you would get a lower bound of n for  the  summation4far  off  from  the  \nupper bound of n 2 . \nYou  can  obtain  a better  lower  bound  by  \u00fbrst  splitting  the  summ ation. Assume \nfor convenience that n is even, so that \nn X  \nkD1 k D n=2  X  \nkD1 k C n X  \nkDn=2C1 k \n\ue004 n=2  X  \nkD1 0 C n X  \nkDn=2C1 n \n2 \nD \ue002 n \n2 \u00cd 2 \nD \ufffd.n  2 /; \nwhich is an asymptotically tight bound, since P  n \nkD1 k D O.n  2 /. \nFor a summation arising from the analysis of an alg orithm, you can sometimes \nsplit the summation and ignore a constant number of  the initial terms.  Generally,  \nthis technique applies when each term a k in a summation P  n \nkD0 a k is independent \nof n. Then for any constant k 0 >0, you can write \nn X  \nkD0 a k D k 0 \ue0021 X  \nkD0 a k C n X  \nkDk 0 a k \nD \u201a.1/  C n X  \nkDk 0 a k ; \nsince the initial terms of the summation are all co nstant and there are a constant \nnumber of them. You can then use other methods to b ound P  n \nkDk 0 a k . This  tech-  \nnique  applies  to in\u00fbnite  summations  as well.  For  example,  let\u2019s  \u00fbnd  an asymptotic  \nupper bound on P  1  \nkD0 k 2 =2  k . The ratio of consecutive terms is A.2  Bounding  summations  1149 \n.k C 1/ 2 =2  kC1 \nk 2 =2  k D .k C 1/ 2 \n2k  2 \n\u0dc4 8=9  \nif k \ue004 3. Thus, you can split the summation into \n1  X  \nkD0 k 2 \n2 k D 2 X  \nkD0 k 2 \n2 k C 1  X  \nkD3 k 2 \n2 k \nD 2 X  \nkD0 k 2 \n2 k C 1  X  \nkD0 .k C 3/ 2 \n2 kC3 (by reindexing) \n\u0dc4 2 X  \nkD0 k 2 \n2 k C 9 \n8 1  X  \nkD0 \u00ce 8 \n9 \u00cf k \n(by  inequality  (A.15))  \nD .0 C 1=2  C 1/ C 9=8  \n1 \ue003 8=9  (by  equation  (A.16))  \nD O.1/:  \nThe technique of splitting summations can help dete rmine asymptotic bounds in \nmuch  more  dif\u00fbcult  situations.  For  example,  here  is one  way  to obtain a bound \nof O.lg n/ on the harmonic series (A.9): \nH n D n X  \nkD1 1 \nk : \nThe idea is to split the range 1 to n into blg nc C  1 pieces  and  upper-bound  the  \ncontribution of each piece by 1. For i D 0;1;:::;  blg nc, the i th piece consists of \nthe terms starting at 1=2  i and going up to but not including 1=2  i C1 . The last piece \nmight contain terms not in the original harmonic se ries, giving \nn X  \nkD1 1 \nk \u0dc4 blg nc X  \ni D0 2 i \ue0021 X  \nj D0 1 \n2 i C j \n\u0dc4 blg nc X  \ni D0 2 i \ue0021 X  \nj D0 1 \n2 i \nD blg nc X  \ni D0 \u00ce \n2 i \ue001 1 \n2 i \u00cf \nD blg nc X  \ni D0 1 \n\u0dc4 lg n C 1:  (A.17)  1150  Appendix  A Summations  \nApproximation  by  integrals  \nWhen a summation has the form P  n \nkDm f.k/ , where f.k/  is a monotonically  in-  \ncreasing function, you can approximate it by integr als: \nZ n \nm\ue0021 f.x/dx  \u0dc4 n X  \nkDm f.k/  \u0dc4 Z nC1 \nm f.x/dx:  (A.18)  \nFigure  A.1  justi\u00fbes  this  approximation.  The  summation  is represented as the area \nof the  rectangles  in the  \u00fbgure,  and  the  integral  is the  blue  region under the curve. \nWhen f.k/  is a monotonically decreasing function, you can use  a similar method \nto provide the bounds \nZ nC1 \nm f.x/dx  \u0dc4 n X  \nkDm f.k/  \u0dc4 Z n \nm\ue0021 f.x/dx:  (A.19)  \nThe  integral  approximation  (A.19)  can  be used  to prove  the  tight  bounds  in in-  \nequality  (A.10)  for  the  nth harmonic number. The lower bound is \nn X  \nkD1 1 \nk \ue004 Z nC1 \n1 dx  \nx \nD ln.n C 1/;  (A.20) \nFor the upper bound, the integral approximation giv es \nn X  \nkD1 1 \nk D n X  \nkD2 1 \nk C 1 \n\u0dc4 Z n \n1 dx  \nx C 1 \nD ln n C 1:  (A.21)  \nExercises  \nA.2-1  \nShow that P  n \nkD1 1=k  2 is bounded above by a constant. \nA.2-2  \nFind an asymptotic upper bound on the summation \nblg nc X  \nkD0 \u02d9 \nn=2  k \ue00c \n: A.2  Bounding  summations  1151 \nn+1  n31  n\u20132 m+2 m m 31  f (m) \nf (m+1) f (m+2) f (n\u20132) f (n31)\n f (n) f (x) \nx \u2026 \u2026 n \u2026 \u2026 \n(a) m+1  \nn+1  n31  n\u20132 m+2 m m 31  f (m) \nf (m+1) f (m+2) f (n\u20132) f (n31)\n f (n) f (x) \nx \u2026 \u2026 n \u2026 \u2026 \n(b) m+1  \nFigure  A.1  Approximation of P  n \nkDm f.k/  by integrals. The area of each rectangle is shown \nwithin the rectangle, and the total rectangle area represents the value of the summation. The integral  \nis represented by the blue area under the curve. Co mparing areas in (a)  gives the lower bound R n \nm\ue0021 f.x/dx  \u0dc4 P  n \nkDm f.k/ . Shifting the rectangles one unit to the right giv es the upper bound P  n \nkDm f.k/  \u0dc4 R nC1 \nm f.x/dx  in (b). 1152  Appendix  A Summations  \nA.2-3  \nShow that the nth harmonic number is \ufffd.lg n/ by splitting the summation. \nA.2-4  \nApproximate P  n \nkD1 k 3 with an integral. \nA.2-5  \nWhy  can\u2019t  you  use  the  integral  approximation  (A.19)  directl y on P  n \nkD1 1=k  to \nobtain an upper bound on the nth harmonic  number?  \nProblems  \nA-1  Bounding  summations  \nGive  asymptotically  tight  bounds  on  the  following  summatio ns. Assume that r \ue004 0 \nand s \ue004 0 are constants. \na. n X  \nkD1 k r . \nb. n X  \nkD1 lg s k. \nc. n X  \nkD1 k r lg s k. \nAppendix  notes  \nKnuth  [259]  provides  an excellent  reference  for  the  materia l presented here. You \ncan  \u00fbnd  basic  properties  of series  in any  good  calculus  book,  such  as Apostol  [19]  \nor Thomas  et al.  [433].  B Sets,  Etc.  \nMany chapters of this book touch on the elements of  discrete mathematics. This \nappendix  reviews  the  notations,  de\u00fbnitions,  and  elementary  properties  of sets,  re-  \nlations, functions, graphs, and trees. If you are a lready well versed in this material, \nyou can probably just skim this chapter. \nB.1  Sets  \nA set  is a collection of distinguishable objects, called its members  or elements . If \nan object x is a member of a set S , we write x 2 S (read <x is a member of S = \nor,  more  brie\u00fcy,  <x belongs to S =). If x is not a member of S , we write x \u2026 S . \nTo describe a set explicitly, write its members as a list inside braces. For example, \nto de\u00fbne  a set  S to contain precisely the numbers 1, 2, and 3, write S D f1;2;3 g. \nSince 2 belongs to the set S , we can write 2 2 S , and since 4 is not a member, \nwe can write 4 \u2026 S . A set cannot contain the same object more than on ce, 1 and \nits elements are not ordered. Two sets A and B are equal , written A D B , if they \ncontain the same elements. For example, f1;2;3;1 g D f1;2;3 g D f3;2;1 g. \nWe adopt special notations for frequently encounter ed sets: \n\ue001 ; denotes the empty  set, that is, the set containing no members. \n\ue001 Z denotes the set of integers , that is, the set f:::;  \ue0032; \ue0031;0;1;2;:::  g. \n\ue001 R denotes the set of real  numbers . \n\ue001 N denotes the set of natural  numbers , that is, the set f0;1;2;::: g. 2 \n1 A variation of a set, which can contain the same ob ject more than once, is called a multiset . \n2 Some authors start the natural numbers with 1 instead of 0. The modern trend seems to be to start \nwith 0. 1154  Appendix  B Sets,  Etc.  \nIf all the elements of a set A are contained in a set B , that is, if x 2 A implies \nx 2 B , then we write A \u0dc2 B and say that A is a subset  of B . A set A is a proper  \nsubset  of set B , written A \ue00a B , if A \u0dc2 B but A \u00a4 B . (Some authors use the \nsymbol < \ue00a= to denote the ordinary subset relation, rather th an the proper-subset  \nrelation.) Every set is a subset of itself: A \u0dc2 A for any set A. For two sets A \nand B , we have A D B if and only if A \u0dc2 B and B \u0dc2 A. The subset relation is \ntransitive  (see  page  1159):  for  any  three  sets  A, B , and C , if A \u0dc2 B and B \u0dc2 C , \nthen A \u0dc2 C . The  proper-subset  relation  is transitive  as well.  The  empt y set is a \nsubset of all sets: for any set A, we have ; \u0dc2  A. \nSets  can  be speci\u00fbed  in terms  of other  sets.  Given  a set  A, a set B \u0dc2 A can be \nde\u00fbned  by  stating  a property  that  distinguishes  the  element s of B . For example, \none  way  to de\u00fbne  the  set  of even  integers  is fx W x 2 Z and x=2  is an integer g. The \ncolon in this notation is read <such that.= (Some a uthors use a vertical bar in place \nof the colon.) \nGiven  two  sets  A and B , set  operations  de\u00fbne  new  sets:  \n\ue001 The intersection  of sets A and B is the set \nA \\ B D fx W x 2 A and x 2 B g : \n\ue001 The union  of sets A and B is the set \nA [ B D fx W x 2 A or x 2 B g : \n\ue001 The difference  between two sets A and B is the set \nA \ue003 B D fx W x 2 A and x \u2026 B g : \nSet operations obey the following laws: \nEmpty  set  laws:  \nA \\ ; D ;  ; \nA [ ; D  A:  \nIdempotency  laws:  \nA \\ A D A;  \nA [ A D A:  \nCommutative  laws:  \nA \\ B D B \\ A;  \nA [ B D B [ A:  B.1 Sets 1155 \nA A A A A \nA B B B B B \n\ue003 \ue003 \n.B  \\ C/  [ [ \nD D D D \nA \ue003 .B  \\ C/  .A  \ue003 B/  .A  \ue003 C/  C C C C C \nFigure  B.1  A Venn  diagram  illustrating  the  \u00fbrst  of DeMorgan\u2019s  laws  (B.2). Each of the sets A, B, \nand C is represented as a circle. \nAssociative  laws:  \nA \\ .B  \\ C/  D .A  \\ B/  \\ C ;  \nA [ .B  [ C/  D .A  [ B/  [ C :  \nDistributive  laws:  \nA \\ .B  [ C/  D .A  \\ B/  [ .A  \\ C/;  \nA [ .B  \\ C/  D .A  [ B/  \\ .A  [ C/:  (B.1)  \nAbsorption  laws:  \nA \\ .A  [ B/  D A;  \nA [ .A  \\ B/  D A:  \nDeMorgan\u2019s  laws:  \nA \ue003 .B  \\ C/  D .A  \ue003 B/  [ .A  \ue003 C/;  \nA \ue003 .B  [ C/  D .A  \ue003 B/  \\ .A  \ue003 C/:  (B.2) \nFigure  B.1  illustrates  the  \u00fbrst  of DeMorgan\u2019s  laws,  using  a Venn  diagram: a graph-  \nical picture in which sets are represented as regio ns of the plane. \nOften,  all  the  sets  under  consideration  are  subsets  of some  larger set U called the \nuniverse . For example, when considering various sets made u p only of integers, \nthe set Z of integers  is an appropriate  universe.  Given  a universe  U , we  de\u00fbne  \nthe complement  of a set A as A D U \ue003 A D fx W x 2 U and x \u2026 Ag. For any \nset A \u0dc2 U , we have the following laws: \nA D A;  \nA \\ A D ;  ; \nA [ A D U :  1156  Appendix  B Sets,  Etc.  \nAn  equivalent  way  to express  DeMorgan\u2019s  laws  (B.2)  uses  set  complements. For \nany two sets B;C  \u0dc2 U , we have \nB \\ C D B [ C ;  \nB [ C D B \\ C :  \nTwo sets A and B are disjoint  if they have no elements in common, that is, if \nA \\ B D ;. A collection  of sets S 1 ;S  2 ;:::, either  \u00fbnite  or in\u00fbnite,  is a set  of sets,  \nin which each member is a set S i . A collection S D fS i g of nonempty sets forms \na partition  of a set S if \n\ue001 the sets are pairwise  disjoint , that is, S i ;S  j 2 S and i \u00a4 j imply S i \\ S j D ;, \nand \n\ue001 their union is S , that is, \nS D [  \nS i 2S S i : \nIn other words, S forms a partition of S if each element of S appears in exactly \none set S i 2 S . \nThe number of elements in a set is the cardinality  (or size) of the set, denoted jS j. \nTwo sets have the same cardinality if their element s can be put into  a one-to-one  \ncorrespondence. The cardinality of the empty set is  j;j D  0. If the cardinality of \na set is a natural number, the set is \u00fbnite , and otherwise, it is in\u00fbnite. An  in\u00fbnite  \nset  that  can  be put  into  a one-to-one  correspondence  with  the  natural numbers N is \ncountably  in\u00fbnite , and otherwise, it is uncountable . For example, the integers Z \nare countable, but the reals R are uncountable. \nFor  any  two  \u00fbnite  sets  A and B , we have the identity \njA [ B j D jAj C jB j \ue003 jA \\ B j ; (B.3)  \nfrom which we can conclude that \njA [ B j \u0dc4 jAj C jB j : \nIf A and B are disjoint, then jA \\ B j D  0 and thus jA [ B j D jAj C jB j. If \nA \u0dc2 B , then jAj \u0dc4 jB j. \nA \u00fbnite  set  of n elements is sometimes called an n-set. A 1-set  is called  a \nsingleton . A subset of k elements of a set is sometimes called a k-subset . \nWe denote the set of all subsets of a set S , including the empty set and S itself, \nby 2 S , called the power  set  of S . For example, 2 fa;bg D f;; fag ; fbg ; fa;bgg. The \npower  set  of a \u00fbnite  set  S has cardinality 2 jSj (see  Exercise  B.1-5).  \nWe sometimes care about setlike structures in which  the elements are ordered. \nAn ordered  pair  of two elements a and b is denoted .a;b/  and  is de\u00fbned  formally  B.1 Sets 1157 \nas the set .a;b/  D fa; fa;bgg. Thus, the ordered pair .a;b/  is not the same as the \nordered pair .b;a/ . \nThe Cartesian  product  of two sets A and B , denoted A \ue005 B , is the set of all \nordered  pairs  such  that  the  \u00fbrst  element  of the  pair  is an elem ent of A and the \nsecond is an element of B . More formally, \nA \ue005 B D f.a;b/  W a 2 A and b 2 B g : \nFor example, fa;bg\ue005fa;b;c  g D f.a;a/;.a;b/;.a;c/;.b;a/;.b;b/;.b;c/ g. When \nA and B are  \u00fbnite  sets,  the  cardinality  of their  Cartesian  product  is \njA \ue005 B j D jAj \ue001 jB j : (B.4)  \nThe Cartesian product of n sets A 1 ;A  2 ;:::;A  n is the set of n-tuples  \nA 1 \ue005 A 2 \ue005 \ue001 \ue001 \ue001 \ue005  A n D f.a 1 ;a  2 ;:::;a  n / W a i 2 A i for i D 1;2;:::;n g ; \nwhose cardinality is \njA 1 \ue005 A 2 \ue005 \ue001 \ue001 \ue001 \ue005  A n j D jA 1 j \ue001 jA 2 j \ue001 \ue001 \ue001 jA n j \nif all sets A i are  \u00fbnite.  We  denote  an n-fold  Cartesian  product  over  a single  set  A \nby the set \nA n D A \ue005 A \ue005 \ue001 \ue001 \ue001 \ue005  A \u203a  \nn times ; \nwhose cardinality is jA n j D jAj n if A is \u00fbnite.  We  can  also  view  an n-tuple  as a \n\u00fbnite  sequence  of length  n (see  page  1162).  \nIntervals are continuous sets of real numbers. We d enote them with  parenthe-  \nses  and/or  brackets.  Given  real  numbers  a and b, the closed  interval  \u0152a; b\ufffd  is \nthe set fx 2 R W a \u0dc4 x \u0dc4 bg of reals between a and b, including both a and b. \n(If a > b, this  de\u00fbnition  implies  that  \u0152a; b\ufffd  D ;.) The open  interval  .a;b/  D \nfx 2 R W a<x<b g omits both of the endpoints from the set. There are  two half-  \nopen  intervals  \u0152a;b/  D fx 2 R W a \u0dc4 x<b g and .a; b\ufffd  D fx 2 R W a<x  \u0dc4 bg, \neach of which excludes one endpoint. \nIntervals  can  also  be de\u00fbned  on  the  integers  by  replacing  R in the  these  de\u00fbni-  \ntions by Z. Whether  the  interval  is de\u00fbned  over  the  reals  or integers  can usually be \ninferred from context. \nExercises  \nB.1-1  \nDraw  Venn  diagrams  that  illustrate  the  \u00fbrst  of the  distributive  laws  (B.1).  1158  Appendix  B Sets,  Etc.  \nB.1-2  \nProve  the  generalization  of DeMorgan\u2019s  laws  to any  \u00fbnite  collection of sets: \nA 1 \\ A 2 \\ \ue001 \ue001 \ue001 \\  A n D A 1 [ A 2 [ \ue001 \ue001 \ue001 [  A n ; \nA 1 [ A 2 [ \ue001 \ue001 \ue001 [  A n D A 1 \\ A 2 \\ \ue001 \ue001 \ue001 \\  A n : \n? B.1-3  \nProve  the  generalization  of equation  (B.3),  which  is called  the principle  of inclu-  \nsion  and  exclusion : \njA 1 [ A 2 [ \ue001 \ue001 \ue001 [  A n j D  \njA 1 j C jA 2 j C \ue001 \ue001 \ue001 C jA n j \n\ue003 jA 1 \\ A 2 j \ue003 jA 1 \\ A 3 j \ue003 \ue001 \ue001 \ue001  (all pairs) \nC jA 1 \\ A 2 \\ A 3 j C \ue001 \ue001 \ue001  (all triples) \n: : : \nC .\ue0031/ n\ue0021 jA 1 \\ A 2 \\ \ue001 \ue001 \ue001 \\  A n j : \nB.1-4  \nShow that the set of odd natural numbers is countab le. \nB.1-5  \nShow  that  for  any  \u00fbnite  set  S , the power set 2 S has 2 jSj elements (that is, there are \n2 jSj distinct subsets of S ). \nB.1-6  \nGive  an inductive  de\u00fbnition  for  an n-tuple  by  extending  the  set-theoretic  de\u00fbnition  \nfor an ordered pair. \nB.2  Relations  \nA binary  relation  R on two sets A and B is a subset of the Cartesian product A\ue005B . \nIf .a;b/  2 R, we sometimes write aRb . When we say that R is a binary relation \non a set A, we mean that R is a subset of A \ue005 A. For example, the <less than= \nrelation on the natural numbers is the set f.a;b/  W a;b  2 N and a<b g. An n-ary  \nrelation on sets A 1 ;A  2 ;:::;A  n is a subset of A 1 \ue005 A 2 \ue005 \ue001 \ue001 \ue001 \ue005  A n . \nA binary relation R \u0dc2 A \ue005 A is re\u00fcexive  if \naRa  B.2 Relations 1159 \nfor all a 2 A. For example, < D= and < \u0dc4= are  re\u00fcexive  relations  on  N, but <<= is \nnot. The relation R is symmetric  if \naRb  implies bRa  \nfor all a;b  2 A. For example, < D= is symmetric, but < <= and < \u0dc4= are not. The \nrelation R is transitive  if \naRb  and bRc  imply aRc  \nfor all a;b;c  2 A. For example, the relations < <,= <\u0dc4,= and < D= are transitive, but \nthe relation R D f.a;b/  W a;b  2 N and a D b \ue003 1g is not, since 3R4  and 4R5  \ndo not imply 3R5 . \nA relation  that  is re\u00fcexive,  symmetric,  and  transitive  is an equivalence  relation . \nFor example, < D= is an equivalence relation on the natural numbers , but <<= is not. \nIf R is an equivalence relation on a set A, then for a 2 A, the equivalence  class  \nof a is the set \u0152a\ufffd  D fb 2 A W aRb g, that is, the set of all elements equivalent to a. \nFor  example,  if we  de\u00fbne  R D f.a;b/  W a;b  2 N and a C b is an even number g, \nthen R is an equivalence relation, since a C a is even  (re\u00fcexive),  a C b is even \nimplies b C a is even (symmetric), and a C b is even and b C c is even imply \na C c is even (transitive). The equivalence class of 4 is \u01524\ufffd  D f0;2;4;6;:::  g, and \nthe equivalence class of 3 is \u01523\ufffd  D f1;3;5;7;:::  g. A basic theorem of equivalence \nclasses is the following. \nTheorem  B.1  (An  equivalence  relation  is the  same  as a partition)  \nThe equivalence classes of any equivalence relation  R on a set A form a partition \nof A, and any partition of A determines an equivalence relation on A for which the \nsets in the partition are the equivalence classes. \nProof  For  the  \u00fbrst  part  of the  proof,  we  must  show  that  the  equivalen ce classes \nof R are  nonempty,  pairwise-disjoint  sets  whose  union  is A. Because R is re\u00fcex-  \nive, a 2 \u0152a\ufffd, and so the equivalence classes are nonempty. More over, since every \nelement a 2 A belongs to the equivalence class \u0152a\ufffd, the union of the equivalence \nclasses is A. It remains to show that the equivalence classes a re pairwise disjoint, \nthat is, if two equivalence classes \u0152a\ufffd  and \u0152b\ufffd  have an element c in common, then \nthey are in fact the same set. Suppose that aRc  and bRc  . Symmetry gives \nthat cRb  and, by transitivity, aRb . Thus, we have xRa  for  any  arbitrary  ele-  \nment x 2 \u0152a\ufffd  and, by transitivity, xRb , and thus \u0152a\ufffd  \u0dc2 \u0152b\ufffd. Similarly, \u0152b\ufffd  \u0dc2 \u0152a\ufffd, \nand thus \u0152a\ufffd  D \u0152b\ufffd. \nFor the second part of the proof, let A D fA i g be a partition of A, and  de-  \n\u00fbne  R D f.a;b/  W there exists i such that a 2 A i and b 2 A i g. We claim that R \nis an equivalence relation on A. Re\u00fcexivity  holds,  since  a 2 A i implies aRa . \nSymmetry holds, because if aRb , then a and b belong to the same set A i , and 1160  Appendix  B Sets,  Etc.  \nhence bRa . If aRb  and bRc  , then all three elements are in the same set A i , \nand thus aRc  and transitivity holds. To see that the sets in the  partition are the \nequivalence classes of R, observe that if a 2 A i , then x 2 \u0152a\ufffd  implies x 2 A i , and \nx 2 A i implies x 2 \u0152a\ufffd. \nA binary relation R on a set A is antisymmetric  if \naRb  and bRa  imply a D b:  \nFor example, the < \u0dc4= relation on the natural numbers is antisymmetric,  since a \u0dc4 b \nand b \u0dc4 a imply a D b. A relation  that  is re\u00fcexive,  antisymmetric,  and  transitiv e \nis a partial  order, and  we  call  a set  on  which  a partial  order  is de\u00fbned  a partially  \nordered  set. For example, the relation <is a descendant of= is  a partial order on the \nset of all people (if we view individuals as being their own descendants). \nIn a partially ordered set A, there may be no single <maximum= element a such \nthat bRa  for all b 2 A. Instead, the set may contain several maximal  elements a \nsuch that for no b 2 A, where b \u00a4 a, is it the case that aRb . For example, a \ncollection  of different-sized  boxes  may  contain  several  maximal  boxes  that  don\u2019t  \n\u00fbt inside  any  other  box,  yet  it has  no  single  <maximum=  box  into which any other \nbox  will  \u00fbt.  3 \nA relation R on a set A is a total  relation  if for all a;b  2 A, we have aRb  \nor bRa  (or both), that is, if every pairing of elements of  A is related by R. A \npartial order that is also a total relation is a total  order  or linear  order . For example, \nthe relation < \u0dc4= is a total order on the natural numbers, but the <is a descendant \nof= relation is not a total order on the set of all  people, since there are individuals \nneither of whom is descended from the other. A tota l relation that is transitive, but \nnot necessarily either symmetric or antisymmetric, is a total  preorder . \nExercises  \nB.2-1  \nProve that the subset relation < \u0dc2= on all subsets of Z is a partial order but not a \ntotal order. \nB.2-2  \nShow that for any positive integer n, the relation <equivalent modulo n= is an equiv-  \nalence relation on the integers. (We say that a D b .mod n/ if there exists an \ninteger q such that a \ue003 b D qn.) Into what equivalence classes does this relation  \npartition  the  integers?  \n3 To  be precise,  in order  for  the  <\u00fbt  inside=  relation  to be a partial order, we need to view a box as \n\u00fbtting  inside  itself.  B.3  Functions  1161 \nB.2-3  \nGive  examples  of relations  that  are  \na. re\u00fcexive  and  symmetric  but  not  transitive,  \nb. re\u00fcexive  and  transitive  but  not  symmetric,  \nc. symmetric  and  transitive  but  not  re\u00fcexive.  \nB.2-4  \nLet S be a \u00fbnite  set,  and  let  R be an equivalence relation on S \ue005 S . Show that if \nin addition R is antisymmetric, then the equivalence classes of S with respect to R \nare singletons. \nB.2-5  \nProfessor Narcissus claims that if a relation R is symmetric and transitive, then it is \nalso  re\u00fcexive.  He  offers  the  following  proof.  By  symmetry,  aRb  implies bRa . \nTransitivity, therefore, implies aRa. Is the  professor  correct?  \nB.3  Functions  \nGiven  two  sets  A and B , a function  f is a binary relation on A and B such that \nfor all a 2 A, there exists precisely one b 2 B such that .a;b/  2 f . The set A is \ncalled the domain  of f , and the set B is called the codomain  of f . We sometimes \nwrite f W A !  B , and if .a;b/  2 f , we write b D f.a/ , since the choice of a \nuniquely determines b. \nIntuitively, the function f assigns an element of B to each element of A. No \nelement of A is assigned two different elements of B , but the same element of B \ncan be assigned to two different elements of A. For example, the binary relation \nf D f.a;b/  W a;b  2 N and b D a mod 2g \nis a function f W N ! f0;1g, since for each natural number a, there is exactly one \nvalue b in f0;1g such that b D a mod 2. For this example, 0 D f.0/ , 1 D f.1/ , \n0 D f.2/ , 1 D f.3/ , etc. In contrast, the binary relation \ng D f.a;b/  W a;b  2 N and a C b is even g \nis not a function, since .1;3/  and .1;5/  are both in g, and thus for the choice a D 1, \nthere is not precisely one b such that .a;b/  2 g. \nGiven  a function  f W A !  B , if b D f.a/ , we say that a is the argument  of f \nand that b is the value  of f at a. We  can  de\u00fbne  a function  by  stating  its  value  for  1162  Appendix  B Sets,  Etc.  \nevery  element  of its  domain.  For  example,  we  might  de\u00fbne  f.n/  D 2n  for n 2 N, \nwhich means f D f.n;2n/  W n 2 Ng. Two functions f and g are equal  if they \nhave the same domain and codomain and if f.a/  D g.a/  for all a in the domain. \nA \u00fbnite  sequence  of length n is a function f whose domain is the set of n inte-  \ngers f0;1;:::;n  \ue003 1g. We  often  denote  a \u00fbnite  sequence  by  listing  its  values  in an-  \ngle brackets: hf.0/;f.1/;:::;f.n  \ue003 1/i. An in\u00fbnite  sequence  is a function whose \ndomain is the set N of natural numbers. For example, the Fibonacci sequ ence, \nde\u00fbned  by  recurrence  (3.31),  is the  in\u00fbnite  sequence  h0;1;1;2;3;5;8;13;21;:::  i. \nWhen the domain of a function f is a Cartesian product, we often omit the extra \nparentheses surrounding the argument of f . For example, if we have a function \nf W A 1 \ue005A 2 \ue005\ue001 \ue001 \ue001\ue005A n !  B , we write b D f.a  1 ;a  2 ;:::;a  n / instead of writing b D \nf..a  1 ;a  2 ;:::;a  n //. We also call each a i an argument  to the function f , though \ntechnically f has just a single argument, which is the n-tuple  .a 1 ;a  2 ;:::;a  n /. \nIf f W A !  B is a function and b D f.a/ , then we sometimes say that b is the \nimage  of a under f . The image of a set A 0 \u0dc2 A under f is de\u00fbned  by  \nf.A  0 / D fb 2 B W b D f.a/  for some a 2 A 0 g : \nThe range  of f is the image of its domain, that is, f.A/ . For example, the range \nof the function f W N !  N de\u00fbned  by  f.n/  D 2n  is f.N/ D fm W m D 2n  for \nsome n 2 Ng, in other words, the set of nonnegative even integ ers. \nA function is a surjection  if its  range  is its  codomain.  For  example,  the  func-  \ntion f.n/  D bn=2c is a surjective function from N to N, since every element in N \nappears as the value of f for some argument. In contrast, the function f.n/  D 2n  \nis not a surjective function from N to N, since no argument to f can produce any \nodd natural number as a value. The function f.n/  D 2n  is, however, a surjective \nfunction from the natural numbers to the even numbe rs. A surjection f W A !  B \nis sometimes described as mapping A onto  B . When we say that f is onto, we \nmean that it is surjective. \nA function f W A !  B is an injection  if distinct arguments to f produce  dis-  \ntinct values, that is, if a \u00a4 a 0 implies f.a/  \u00a4 f.a  0 /. For example, the function \nf.n/  D 2n  is an injective function from N to N, since each even number b is \nthe image under f of at most one element of the domain, namely b=2. The  func-  \ntion f.n/  D bn=2c is not injective, since the value 1 is produced by two arguments: \nf.2/  D 1 and f.3/  D 1. An injection is sometimes called a one-to-one  function. \nA function f W A !  B is a bijection  if it is injective and surjective. For example, \nthe function f.n/  D .\ue0031/ n dn=2e is a bijection from N to Z: B.3  Functions  1163 \n0 !  0;  \n1 ! \ue0031;  \n2 !  1;  \n3 ! \ue0032;  \n4 !  2;  \n: : : \nThe function is injective, since no element of Z is the image of more than one \nelement of N. It is surjective, since every element of Z appears as the image of \nsome element of N. Hence, the function is bijective. A bijection is sometimes \ncalled a one-to-one  correspondence , since it pairs elements in the domain and \ncodomain. A bijection from a set A to itself is sometimes called a permutation . \nWhen a function f is bijective,  we  de\u00fbne  its  inverse  f \ue0021 as \nf \ue0021 .b/  D a if and only if f.a/  D b:  \nFor example, the inverse of the function f.n/  D .\ue0031/ n dn=2e is \nf \ue0021 .m/  D ( \n2m  if m \ue004 0;  \n\ue0032m  \ue003 1 if m<0:  \nExercises  \nB.3-1  \nLet A and B be \u00fbnite  sets,  and  let  f W A !  B be a function. Show the following: \na. If f is injective, then jAj \u0dc4 jB j. \nb. If f is surjective, then jAj \ue004 jB j. \nB.3-2  \nIs the function f.x/  D x C 1 bijective when the domain and the codomain are the \nset N? Is it bijective  when  the  domain  and  the  codomain  are  the  set  Z? \nB.3-3  \nGive  a natural  de\u00fbnition  for  the  inverse  of a binary  relation  such that if a relation \nis in fact a bijective function, its relational inv erse is its functional inverse. \n? B.3-4  \nGive  a bijection  from  Z to Z \ue005 Z. 1164  Appendix  B Sets,  Etc.  \nB.4  Graphs  \nThis section presents two kinds of graphs: directed  and undirected.  Certain  def-  \ninitions in the literature differ from those given here, but for the most part, the \ndifferences  are  slight.  Section  20.1  shows  how  to represent  graphs in computer \nmemory. \nA directed  graph  (or digraph ) G is a pair .V;E/ , where V is a \u00fbnite  set  and  E \nis a binary relation on V . The set V is called the vertex  set  of G, and its elements \nare called vertices  (singular: vertex ). The set E is called the edge  set  of G, and its \nelements are called edges . Figure B.2(a) is a pictorial representation of a directed \ngraph on the vertex set f1;2;3;4;5;6 g . Vertices are represented by circles in the \n\u00fbgure,  and  edges  are  represented  by  arrows.  Self-loops4edges  from  a vertex  to \nitself4are  possible.  \nIn an undirected  graph  G D .V;E/ , the edge set E consists of unordered  \npairs of vertices, rather than ordered pairs. That is, an edge is a set fu;vg, where \nu;v  2 V and u \u00a4 v. By convention, we use the notation .u;v/  for an edge, rather \nthan the set notation fu;vg, and we consider .u;v/  and .v;u/  to be the same edge. \nIn an undirected  graph,  self-loops  are  forbidden,  so that  every edge consists of \ntwo distinct vertices. Figure B.2(b) shows an undir ected graph on the vertex set \nf1;2;3;4;5;6 g . \nMany  de\u00fbnitions  for  directed  and  undirected  graphs  are  the  same,  although  cer-  \ntain terms have slightly different meanings in the two contexts. If .u;v/  is an edge \nin a directed graph G D .V;E/ , we say that .u;v/  is incident  from  or leaves  ver-  \ntex u and is incident  to or enters  vertex v. For example, the edges leaving vertex 2 \n1 2 3 \n4 5 6 \n(a) 1 2 3 \n4 5 6 \n(b) 1 2 3 \n6 \n(c) \nFigure  B.2  Directed and undirected graphs. (a)  A directed graph G D .V;E/ , where V D \nf1;2;3;4;5;6 g and E D f.1;2/;.2;2/;.2;4/;.2;5/;.4;1/;.4;5/;.5;4/;.6;3/ g. The edge .2;2/  \nis a self-loop.  (b)  An undirected graph G D .V;E/ , where V D f1;2;3;4;5;6 g and E D \nf.1;2/;.1;5/;.2;5/;.3;6/ g. The vertex 4 is isolated. (c)  The subgraph of the graph in part (a) \ninduced by the vertex set f1;2;3;6 g. B.4 Graphs 1165 \nin Figure B.2(a) are .2;2/ , .2;4/ , and .2;5/ . The edges entering vertex 2 are .1;2/  \nand .2;2/ . If .u;v/  is an edge in an undirected graph G D .V;E/ , we say that \n.u;v/  is incident  on  vertices u and v. In Figure B.2(b), the edges incident on \nvertex 2 are .1;2/  and .2;5/ . \nIf .u;v/  is an edge in a graph G D .V;E/ , we say that vertex v is adjacent  \nto vertex u. When the graph is undirected, the adjacency relat ion is symmetric. \nWhen the graph is directed, the adjacency relation is not necessarily symmetric. If \nv is adjacent to u in a directed graph, we can write u !  v. In parts (a) and (b) of \nFigure B.2, vertex 2 is adjacent to vertex 1, since the edge .1;2/  belongs to both \ngraphs. Vertex 1 is not adjacent to vertex 2 in Figure B.2(a), since the edge .2;1/  \nis absent. \nThe degree  of a vertex in an undirected graph is the number of  edges incident on \nit. For example, vertex 2 in Figure B.2(b) has degree 2. A vertex whose degree is 0, \nsuch as vertex 4 in Figure B.2(b), is isolated . In a directed graph, the out-degree  \nof a vertex is the number of edges leaving it, and the in-degree  of a vertex is the \nnumber of edges entering it. The degree  of a vertex  in a directed  graph  is its  in-  \ndegree  plus  its  out-degree.  Vertex  2 in Figure  B.2(a)  has  in-degree  2, out-degree  3, \nand degree 5. \nA path  of length  k from a vertex u to a vertex u 0 in a graph G D .V;E/  \nis a sequence hv 0 ;v  1 ;v  2 ;:::;v  k i of vertices such that u D v 0 , u 0 D v k , and \n.v i \ue0021 ;v  i / 2 E for i D 1;2;:::;k . The length of the path is the number of edges in \nthe path, which is 1 less than the number of vertices in the path. The p ath contains  \nthe vertices v 0 ;v  1 ;:::;v  k and the edges .v 0 ;v  1 /;.v  1 ;v  2 /;:::;.v  k\ue0021 ;v  k /. (There \nis always a 0-length  path  from  u to u.) If there is a path p from u to u 0 , we say that \nu 0 is reachable  from u via p, which we can write as u p \u2740  u 0 . A path is simple  4 \nif all vertices in the path are distinct. In Figure  B.2(a), the path h1;2;5;4 i is a \nsimple path of length 3. The path h2;5;4;5 i is not simple. A subpath  of path \np D hv 0 ;v  1 ;:::;v  k i is a contiguous subsequence of its vertices. That i s, for any \n0 \u0dc4 i \u0dc4 j \u0dc4 k, the subsequence of vertices hv i ;v  i C1 ;:::;v  j i is a subpath of p. \nIn a directed graph, a path hv 0 ;v  1 ;:::;v  k i forms a cycle  if v 0 D v k and the \npath contains at least one edge. The cycle is simple  if, in addition, v 1 ;v  2 ;:::;v  k \nare distinct. A cycle consisting of k vertices has length  k. A self-loop  is a cycle  \nof length 1. Two paths hv 0 ;v  1 ;v  2 ;:::;v  k\ue0021 ;v  0 i and hv 0 \n0 ;v  0 \n1 ;v  0 \n2 ;:::;v  0 \nk\ue0021 ;v  0 \n0 i \nform the same cycle if there exists an integer j such that v 0 \ni D v .i Cj /  mod k for \ni D 0;1;:::;k \ue0031. In Figure B.2(a), the path h1;2;4;1 i forms the same cycle as the \npaths h2;4;1;2 i and h4;1;2;4 i. This cycle is simple, but the cycle h1;2;4;5;4;1 i \nis not. The cycle h2;2i formed by the edge .2;2/  is a self-loop.  A directed  graph  \n4 Some authors refer to what we call a path as a <wal k= and to what we call a simple path as just a \n<path.= 1166  Appendix  B Sets,  Etc.  \nwith  no  self-loops  is simple . In an undirected graph, a path hv 0 ;v 1 ;:::;v  k i forms a \ncycle  if k>0 , v 0 D v k , and all edges on the path are distinct. The cycle  is simple  \nif v 1 ;v  2 ;:::;v  k are distinct. For example, in Figure B.2(b), the pa th h1;2;5;1 i is \na simple cycle. A graph with no simple cycles is acyclic . \nAn undirected graph is connected  if every vertex is reachable from all other \nvertices. The connected  components  of an undirected graph are the equivalence \nclasses of vertices under the <is reachable from= r elation. The graph shown in \nFigure B.2(b) has three connected components: f1;2;5 g, f3;6g, and f4g. Every \nvertex in the connected component f1;2;5 g is reachable from every other vertex \nin f1;2;5 g. An undirected graph is connected if it has exactl y one connected  com-  \nponent. The edges of a connected component are thos e that are incident on only the \nvertices of the component. In other words, edge .u;v/  is an edge of a connected \ncomponent only if both u and v are vertices of the component. \nA directed graph is strongly  connected  if every two vertices are reachable from \neach other. The strongly  connected  components  of a directed  graph  are  the  equiv-  \nalence classes of vertices under the <are mutually reachable= relation. A directed \ngraph is strongly connected if it has only one stro ngly connected component. The \ngraph in Figure B.2(a) has three strongly connected  components: f1;2;4;5 g, f3g, \nand f6g. All pairs of vertices in f1;2;4;5 g are  mutually  reachable.  The  ver-  \ntices f3;6g do not form a strongly connected component, since v ertex 6 cannot \nbe reached from vertex 3. \nTwo graphs G D .V;E/  and G 0 D .V  0 ;E  0 / are isomorphic  if there exists a \nbijection f W V !  V 0 such that .u;v/  2 E if and only if .f.u/;f.v//  2 E 0 . \nIn other words, G and G 0 are isomorphic if the vertices of G can be relabeled \nto be vertices of G 0 , maintaining the corresponding edges in G and G 0 . Fig-  \nure  B.3(a)  shows  a pair  of isomorphic  graphs  G and G 0 with respective vertex \nsets V D f1;2;3;4;5;6 g and V 0 D fu;v;w;x;y;\u00b4 g. The mapping from V to V 0 \ngiven by f.1/  D u;f.2/  D v;f.3/  D w;f.4/  D x;f.5/  D y;f.6/  D \u00b4 \nprovides the required bijective function. The graph s in Figure  B.3(b)  are  not  iso-  \nmorphic. Although both graphs have 5 vertices and 7 edges, the top graph has a \nvertex of degree 4 and the bottom graph does not. \nWe say that a graph G 0 D .V  0 ;E  0 / is a subgraph  of G D .V;E/  if V 0 \u0dc2 V \nand E 0 \u0dc2 E. Given  a set  V 0 \u0dc2 V , the subgraph of G induced  by V 0 is the \ngraph G 0 D .V  0 ;E  0 /, where \nE 0 D f.u;v/  2 E W u;v  2 V 0 g : \nThe subgraph induced by the vertex set f1;2;3;6 g in Figure B.2(a) appears in \nFigure B.2(c) and has the edge set f.1;2/;.2;2/;.6;3/ g . \nGiven  an undirected  graph  G D .V;E/ , the directed  version  of G is the directed \ngraph G 0 D .V;E  0 /, where .u;v/  2 E 0 if and only if .u;v/  2 E. That is, each \nundirected edge .u;v/  in G turns into two directed edges, .u;v/  and .v;u/ , in the B.4 Graphs 1167 \n1 2 \n3 \n4 5 6 \nu w x y z \n(a) 1 2 \n3 \n4 5 \nu w x y \n(b) G \nG\u02b9 v v \nFigure  B.3  (a)  A pair of isomorphic graphs. The vertices of the to p graph are mapped to the \nvertices of the bottom graph by f.1/  D u;f.2/  D v;f.3/  D w;f.4/  D x;f.5/  D y;f.6/  D \u00b4. \n(b)  Two graphs that are not isomorphic. The top graph h as a vertex of degree 4, and the bottom graph \ndoes not. \ndirected  version.  Given  a directed  graph  G D .V;E/ , the undirected  version  of G \nis the undirected graph G 0 D .V;E  0 /, where .u;v/  2 E 0 if and only if u \u00a4 v \nand E contains at least one of the edges .u;v/  and .v;u/ . That is, the undirected \nversion contains the edges of G <with  their  directions  removed=  and  with  self-loops  \neliminated. (Since .u;v/  and .v;u/  are the same edge in an undirected graph, the \nundirected version of a directed graph contains it only once, even if the directed \ngraph contains both edges .u;v/  and .v;u/ .) In a directed graph G D .V;E/ , a \nneighbor  of a vertex u is any vertex that is adjacent to u in the undirected version \nof G. That is, v is a neighbor of u if u \u00a4 v and either .u;v/  2 E or .v;u/  2 E. In \nan undirected graph, u and v are neighbors if they are adjacent. \nSeveral kinds of graphs have special names. A complete  graph  is an undirected \ngraph in which every pair of vertices is adjacent. An undirected graph G D .V;E/  \nis bipartite  if V can be partitioned into two sets V 1 and V 2 such that .u;v/  2 E \nimplies either u 2 V 1 and v 2 V 2 or u 2 V 2 and v 2 V 1 . That is, all edges go \nbetween the two sets V 1 and V 2 . An acyclic, undirected graph is a forest , and a \nconnected, acyclic, undirected graph is a (free)  tree  (see  Section  B.5).  We  often  \ntake  the  \u00fbrst  letters  of <directed  acyclic  graph=  and  call  such a graph a dag. \nThere are two variants of graphs that you may occas ionally encounter. A multi-  \ngraph  is like an undirected graph, but it can have both m ultiple edges between  ver-  \ntices (such as two distinct edges .u;v/  and .u;v/) and  self-loops.  A hypergraph  is \nlike an undirected graph, but each hyperedge , rather than connecting two vertices, 1168  Appendix  B Sets,  Etc.  \nconnects an arbitrary subset of vertices. Many algo rithms written  for  ordinary  di-  \nrected and undirected graphs can be adapted to run on these graphlike structures. \nThe contraction  of an undirected graph G D .V;E/  by an edge e D .u;v/  \nis a graph G 0 D .V  0 ;E  0 /, where V 0 D V \ue003 fu;vg [ fx g and x is a new vertex. \nThe set of edges E 0 is formed from E by deleting the edge .u;v/  and, for each \nvertex w adjacent to u or v, deleting whichever of .u;w/  and .v;w/  belongs to E \nand adding the new edge .x;w/ . In effect, u and v are <contracted= into a single \nvertex. \nExercises  \nB.4-1  \nAttendees of a faculty party shake hands to greet e ach other, with every pair of \nprofessors shaking hands one time. Each professor r emembers the number of times \nhe or she shook hands. At the end of the party, the  department head asks the \nprofessors for their totals and adds them all up. S how that the result is even by \nproving the handshaking  lemma : if G D .V;E/  is an undirected graph, then \nX  \nv2V degree.v/  D 2 jEj : \nB.4-2  \nShow that if a directed or undirected graph contain s a path between two vertices \nu and v, then it contains a simple path between u and v. Show that if a directed \ngraph contains a cycle, then it contains a simple c ycle. \nB.4-3  \nShow that any connected, undirected graph G D .V;E/  satis\u00fbes  jEj \ue004 jV j \ue003  1. \nB.4-4  \nVerify that in an undirected graph, the <is reachab le from= relation  is an equiv-  \nalence relation on the vertices of the graph. Which  of the three properties of an \nequivalence relation hold in general for the <is re achable from= relation on the \nvertices  of a directed  graph?  \nB.4-5  \nWhat is the undirected version of the directed grap h in Figure B.2(a)?  What  is the  \ndirected  version  of the  undirected  graph  in Figure  B.2(b)?  \nB.4-6  \nShow how a bipartite graph can represent a hypergra ph by letting incidence in the \nhypergraph correspond to adjacency in the bipartite  graph. ( Hint: Let one set of B.5 Trees 1169 \nvertices in the bipartite graph correspond to verti ces of the hypergraph, and let the \nother set of vertices of the bipartite graph corres pond to hyperedges.) \nB.5  Trees  \nAs with graphs, there are many related, but slightl y different, notions of trees. This \nsection  presents  de\u00fbnitions  and  mathematical  properties  of several kinds of trees. \nSections  10.3  and  20.1  describe  how  to represent  trees  in computer memory. \nB.5.1  Free  trees  \nAs  de\u00fbned  in Section  B.4,  a free  tree  is a connected, acyclic, undirected graph. We \noften omit the adjective <free= when we say that a graph is a tree. If an undirected \ngraph is acyclic but possibly disconnected, it is a  forest . Many algorithms that work \nfor  trees  also  work  for  forests.  Figure  B.4(a)  shows  a free  tree,  and  Figure  B.4(b)  \nshows  a forest.  The  forest  in Figure  B.4(b)  is not  a tree  becau se it is not connected. \nThe  graph  in Figure  B.4(c)  is connected  but  neither  a tree  nor  a forest, because it \ncontains a cycle. \nThe following theorem captures many important facts  about free trees. \nTheorem  B.2  (Properties  of free  trees)  \nLet G D .V;E/  be an undirected graph. The following statements ar e equivalent. \n1. G is a free tree. \n2. Any two vertices in G are connected by a unique simple path. \n3. G is connected, but if any edge is removed from E, the  resulting  graph  is dis-  \nconnected. \n(a) (b) (c) \nFigure  B.4  (a)  A free tree. (b)  A forest. (c)  A graph that contains a cycle and is therefore neit her \na tree nor a forest. 1170  Appendix  B Sets,  Etc.  \nu w \nz x \ny p\u02b9 \np\u02b9\u02b9 v \nFigure  B.5  A step  in the  proof  of Theorem  B.2:  if (1)  G is a free tree, then (2) any two vertices \nin G are connected by a unique simple path. Assume for t he sake of contradiction that vertices u \nand v are  connected  by  two  distinct  simple  paths.  These  paths  \u00fbrst  diverge at vertex w, and they \n\u00fbrst  reconverge  at vertex  \u00b4. The path p 0 concatenated with the reverse of the path p 00 forms a cycle, \nwhich yields the contradiction. \n4. G is connected, and jEj D jV j \ue003  1. \n5. G is acyclic, and jEj D jV j \ue003  1. \n6. G is acyclic, but if any edge is added to E, the resulting graph contains a cycle. \nProof  (1)  )  (2): Since a tree is connected, any two vertices in  G are connected \nby at least one simple path. Suppose for the sake o f contradiction that vertices \nu and v are connected by two distinct simple paths as shown  in Figure B.5.  Let  \nw be the  vertex  at which  the  paths  \u00fbrst  diverge.  That  is, if we  call the paths p 1 \nand p 2 , then w is the  \u00fbrst  vertex  on  both  p 1 and p 2 whose successor on p 1 is \nx and whose successor on p 2 is y , where x \u00a4 y . Let \u00b4 be the  \u00fbrst  vertex  at which  \nthe paths reconverge, that is, \u00b4 is the  \u00fbrst  vertex  following  w on p 1 that is also \non p 2 . Let p 0 D w !  x \u2740  \u00b4 be the subpath of p 1 from w through x to \u00b4, so \nthat p 1 D u \u2740  w p 0 \n\u2740  \u00b4 \u2740  v, and let p 00 D w !  y \u2740  \u00b4 be the subpath of p 2 \nfrom w through y to \u00b4, so that p 2 D u \u2740  w p 00 \n\u2740  \u00b4 \u2740  v. Paths p 0 and p 00 share no \nvertices  except  their  endpoints.  Then,  as Figure  B.5  shows,  the path obtained by \nconcatenating p 0 and the reverse of p 00 is a cycle, which contradicts our assumption \nthat G is a tree. Thus, if G is a tree, there can be at most one simple path bet ween \ntwo vertices. \n(2) )  (3):  If any  two  vertices  in G are connected by a unique simple path, then \nG is connected. Let .u;v/  be any edge in E. This edge is a path from u to v, and \nso it must be the unique path from u to v. If .u;v/  were to be removed from G, \nthere would be no path from u to v, and G would be disconnected. \n(3)  )  (4):  By  assumption,  the  graph  G is connected,  so Exercise  B.4-3  gives  \nthat jEj \ue004 jV j \ue003  1. We prove jEj \u0dc4 jV j \ue003  1 by induction on jV j. The base cases \nare when jV j D  1 or jV j D  2, and in either case, jEj D jV j \ue003  1. For the inductive \nstep, suppose that jV j \ue004  3 for graph G and that any graph G 0 D .V  0 ;E  0 /, where B.5 Trees 1171 \njV 0 j < jV j, that  satis\u00fbes  (3)  also  satis\u00fbes  jE 0 j \u0dc4 jV 0 j \ue003  1. Removing  an arbi-  \ntrary edge from G separates the graph into k \ue004 2 connected components (actually \nk D 2). Each  component  satis\u00fbes  (3),  or else  G would  not  satisfy  (3).  Consider  \neach connected component V i , with edge set E i , as a separate free tree. Then, \nbecause each connected component has fewer than jV j vertices,  the  inductive  hy-  \npothesis implies that jE i j \u0dc4 jV i j \ue003  1. Thus, the number of edges in all k connected \ncomponents combined is at most jV j \ue003  k \u0dc4 jV j \ue003  2. Adding in the removed edge \nyields jEj \u0dc4 jV j \ue003  1. \n(4)  )  (5):  Suppose  that  G is connected and that jEj D jV j \ue003  1. We must show \nthat G is acyclic. Suppose that G has a cycle containing k vertices v 1 ;v  2 ;:::;v  k , \nand without loss of generality assume that this cyc le is simple. Let G k D .V  k ;E  k / \nbe the subgraph of G consisting of the cycle, so that jV k j D jE k j D  k. If k<  jV j, \nthen because G is connected, there must be a vertex v kC1 2 V \ue003 V k that is adjacent \nto some vertex v i 2 V k . De\u00fbne  G kC1 D .V  kC1 ;E  kC1 / to be the subgraph of G \nwith V kC1 D V k [ fv kC1 g and E kC1 D E k [ f.v i ;v  kC1 /g. Note that jV kC1 j D  \njE kC1 j D  k C 1. If k C 1 <  jV j, then  continue,  de\u00fbning  G kC2 in the same \nmanner, and so forth, until we obtain G n D .V  n ;E  n /, where n D jV j, V n D V , \nand jE n j D jV n j D jV j. Since G n is a subgraph of G, we have E n \u0dc2 E, and hence \njEj \ue004 jE n j D jV n j D jV j, which contradicts the assumption that jEj D jV j \ue003  1. \nThus, G is acyclic. \n(5)  )  (6):  Suppose  that  G is acyclic and that jEj D jV j \ue003  1. Let k be the \nnumber of connected components of G. Each connected component is a free tree \nby  de\u00fbnition,  and  since  (1)  implies  (5),  the  sum  of all  edges  in all  connected  com-  \nponents of G is jV j \ue003  k. Consequently, k must equal 1, and G is in fact a tree. \nSince  (1)  implies  (2),  any  two  vertices  in G are connected by a unique simple path. \nThus, adding any edge to G creates a cycle. \n(6)  )  (1):  Suppose  that  G is acyclic but that adding any edge to E creates a \ncycle. We must show that G is connected. Let u and v be arbitrary vertices in G. \nIf u and v are not already adjacent, adding the edge .u;v/  creates a cycle in which \nall edges but .u;v/  belong to G. Thus, the cycle minus edge .u;v/  must contain a \npath from u to v, and since u and v were chosen arbitrarily, G is connected. \nB.5.2  Rooted  and  ordered  trees  \nA rooted  tree  is a free tree in which one of the vertices is dist inguished from the \nothers. We call the distinguished vertex the root  of the tree. We often refer to a 1172  Appendix  B Sets,  Etc.  \n9 6 5 8 \n1 12  3 10  7 \n11  2 4 \nheight  = 4 depth 0 \ndepth  1 \ndepth 2 \ndepth  3 \ndepth  4 \n(a) 9 6 5 8 12  3 10  7 \n11  2 4 \n(b) 1 \nFigure  B.6  Rooted and ordered trees. (a)  A rooted tree with height 4. The tree is drawn in a \nstandard way: the root (node 7) is at the top, its children (nodes with depth 1) are beneath it, their \nchildren (nodes with depth 2) are beneath them, and so forth. If the tree is or dered, the re lative  left-  \nto-right  order  of the  children  of a node  matters;  otherwise,  it doesn\u2019t.  (b)  Another rooted tree. As a \nrooted tree, it is identical to the tree in (a), bu t as an ordered tree it is different, since the chi ldren of \nnode 3 appear in a different order. \nvertex of a rooted tree as a node  5 of the  tree.  Figure  B.6(a)  shows  a rooted  tree  on  \na set of 12  nodes with root 7. \nConsider a node x in a rooted tree T with root r . We call any node y on the \nunique simple path from r to x an ancestor  of x . If y is an ancestor of x , then x is \na descendant  of y . (Every node is both an ancestor and a descendant of itself.) If \ny is an ancestor of x and x \u00a4 y , then y is a proper  ancestor  of x and x is a proper  \ndescendant  of y . The subtree  rooted  at x is the tree induced by descendants of x , \nrooted at x . For example, the subtree rooted at node 8 in Figure  B.6(a)  contains  \nnodes 8, 6, 5, and 9. \nIf the last edge on the simple path from the root r of a tree T to a node x is .y;x/ , \nthen y is the parent  of x , and x is a child  of y . The root is the only node in T with \nno parent. If two nodes have the same parent, they are siblings . A node with no \nchildren is a leaf  or external  node . A nonleaf node is an internal  node . \n5 The term <node= is often used in the graph theory l iterature as a synonym for <vertex.= We reserve \nthe term <node= to mean a vertex of a rooted tree. B.5 Trees 1173 \nThe number of children of a node x in a rooted tree T is the degree  of x . 6 The \nlength of the simple path from the root r to a node x is the depth  of x in T . A level  \nof a tree consists of all nodes at the same depth. The height  of a node in a tree is \nthe number of edges on the longest simple downward path from the node to a leaf, \nand the height of a tree is the height of its root.  The height of a tree is also equal to \nthe largest depth of any node in the tree. \nAn ordered  tree  is a rooted tree in which the children of each node  are ordered. \nThat is, if a node has k children,  then  there  is a \u00fbrst  child,  a second  child,  and  so \non, up to and including a kth child.  The  two  trees  in Figure  B.6  are  different  when  \nconsidered to be ordered trees, but the same when c onsidered to be just rooted \ntrees. \nB.5.3  Binary  and  positional  trees  \nWe  de\u00fbne  binary  trees  recursively.  A binary  tree  T is a structure  de\u00fbned  on  a \u00fbnite  \nset of nodes that either \n\ue001 contains no nodes, or \n\ue001 is composed of three disjoint sets of nodes: a root  node, a binary tree called its \nleft  subtree , and a binary tree called its right  subtree . \nThe binary tree that contains no nodes is called th e empty  tree  or null  tree, some-  \ntimes denoted NIL. If the left subtree is nonempty, its root is call ed the left  child  of \nthe root of the entire tree. Likewise, the root of a nonnull right subtree is the right  \nchild  of the root of the entire tree. If a subtree is the  null tree NIL, we say that the \nchild is absent  or missing. Figure  B.7(a)  shows  a binary  tree.  \nA binary tree is not simply an ordered tree in whic h each node has degree at \nmost 2. For example, in a binary tree, if a node has just  one child, the position \nof the  child4whether  it is the  left  child  or the right  child4matters.  In an or-  \ndered tree, there is no distinguishing a sole child  as being either  left  or right.  Fig-  \nure  B.7(b)  shows  a binary  tree  that  differs  from  the  tree  in Figure  B.7(a)  because  of \nthe position of one node. Considered as ordered tre es, however, the two trees are \nidentical. \nOne  way  to represent  the  positioning  information  in a binary  tree  is by  the  inter-  \nnal  nodes  of an ordered  tree,  as shown  in Figure  B.7(c).  The  idea is to replace each \nmissing child in the binary tree with a node having  no children. These leaf nodes \n6 The degree of a node depends on whether we consider  T to be a rooted tree or a free tree. The \ndegree of a vertex in a free tree is, as in any und irected graph, the number of adjacent vertices. In \na rooted  tree,  however,  the  degree  is the  number  of children4 the parent of a node does not count \ntoward its degree. 1174  Appendix  B Sets,  Etc.  \n3 \n2 \n4 1 \n6 7 \n5 \n(a) 3 \n2 \n4 1 \n6 7 \n5 \n(b) 3 \n2 \n4 1 \n6 7 \n5 \n(c) \nFigure  B.7  Binary trees. (a)  A binary tree drawn in a standard way. The left chi ld of a node is \ndrawn beneath the node and to the left. The right c hild is drawn beneath and to the right. (b)  A binary \ntree different from the one in (a). In (a), the lef t child of node 7 is 5 and the right child is absent. \nIn (b), the left child of node 7 is absent and the right child is 5. As ordered trees, these trees are \nthe same, but as binary trees, they are distinct. (c)  The binary tree in (a) represented by the internal \nnodes of a full binary tree: an ordered tree in whi ch each internal node has degree 2. The leaves in \nthe tree are shown as squares. \nare  drawn  as squares  in the  \u00fbgure.  The  tree  that  results  is a full  binary  tree: each \nnode is either a leaf or has degree exactly 2. No nodes have degree 1. Consequently, \nthe order of the children of a node preserves the p osition information. \nThe positioning information that distinguishes bina ry trees from ordered trees \nextends to trees with more than two children per no de. In a positional  tree, the \nchildren of a node are labeled with distinct positi ve integers. The i th child of a \nnode is absent  if no child is labeled with integer i . A k-ary  tree is a positional tree \nin which for every node, all children with labels g reater than k are missing. Thus, \na binary tree is a k-ary  tree  with  k D 2. \nA complete  k-ary  tree  is a k-ary  tree  in which  all  leaves  have  the  same  depth  \nand all internal nodes have degree k. Figure  B.8  shows  a complete  binary  tree  of \nheight 3. How many leaves does a complete k-ary  tree  of height  h have?  The  root  \nhas k children at depth 1, each of which has k children at depth 2, etc. Thus, the \nnumber of nodes at depth d is k d . In a complete k-ary  tree  with  height  h, the leaves \nare at depth h, so that there are k h leaves. Consequently, the height of a complete \nk-ary  tree  with  n leaves is log k n. A complete k-ary  tree  of height  h has \n1 C k C k 2 C \ue001 \ue001 \ue001 C  k h\ue0021 D h\ue0021 X  \nd D0 k d \nD k h \ue003 1 \nk \ue003 1 (by  equation  (A.6)  on  page  1142)  \ninternal nodes. Thus, a complete binary tree has 2 h \ue003 1 internal nodes. B.5 Trees 1175 \nheight  = 3 depth 0 \ndepth  1 \ndepth 2 \ndepth  3 \nFigure  B.8  A complete binary tree of height 3 with 8 leaves and 7 internal nodes. \nExercises  \nB.5-1  \nDraw all the free trees composed of the three verti ces x , y , and \u00b4. Draw all the \nrooted trees with nodes x , y , and \u00b4 with x as the root. Draw all the ordered trees \nwith nodes x , y , and \u00b4 with x as the root. Draw all the binary trees with nodes x , \ny , and \u00b4 with x as the root. \nB.5-2  \nLet G D .V;E/  be a directed acyclic graph in which there is a ver tex v 0 2 V \nsuch that there exists a unique path from v 0 to every vertex v 2 V . Prove that the \nundirected version of G forms a tree. \nB.5-3  \nShow  by  induction  that  the  number  of degree-2 nodes in any nonempty binary tree \nis one less than the number of leaves. Conclude tha t the number of internal nodes \nin a full binary tree is one less than the number o f leaves. \nB.5-4  \nProve that for any integer k \ue004 1, there is a full binary tree with k leaves. \nB.5-5  \nUse induction to show that a nonempty binary tree w ith n nodes has height at \nleast blg nc. \n? B.5-6  \nThe internal  path  length  of a full binary tree is the sum, taken over all in ternal \nnodes of the tree, of the depth of each node. Likew ise, the external  path  length  is \nthe sum, taken over all leaves of the tree, of the depth of each leaf. Consider a full \nbinary tree with n internal nodes, internal path length i , and external path length e. \nProve that e D i C 2n. 1176  Appendix  B Sets,  Etc.  \n? B.5-7  \nAssociate a <weight= w.x/  D 2 \ue002d with each leaf x of depth d in a binary tree T , \nand let L be the set of leaves of T . Prove the Kraft  inequality : P  \nx2L w.x/  \u0dc4 1. \n? B.5-8  \nShow that if L \ue004 2, then every binary tree with L leaves contains a subtree having \nbetween L=3  and 2L=3  leaves, inclusive. \nProblems  \nB-1  Graph  coloring  \nA k-coloring  of undirected graph G D .V;E/  is a function c W V ! f1;2;:::;k g \nsuch that c.u/  \u00a4 c.v/  for every edge .u;v/  2 E. In other words, the numbers \n1;2;:::;k  represent the k colors, and adjacent vertices must have different c olors. \na. Show that any tree is 2-colorable.  \nb. Show that the following are equivalent: \n1. G is bipartite. \n2. G is 2-colorable.  \n3. G has no cycles of odd length. \nc. Let d be the maximum degree of any vertex in a graph G. Prove that G can be \ncolored with d C 1 colors. \nd. Show that if G has O.jV j/ edges, then G can be colored with O.  p \njV j/ colors. \nB-2  Friendly  graphs  \nReword each of the following statements as a theore m about undirected graphs, \nand then prove it. Assume that friendship is symmet ric but not re\u00fcexive.  \na. Any group of at least two people contains at least two people with the same \nnumber of friends in the group. \nb. Every group of six people contains either at least three mutual friends or at least \nthree mutual strangers. \nc. Any group of people can be partitioned into two sub groups such that at least \nhalf the friends of each person belong to the subgr oup of which that person is \nnot a member. Notes for Appendix B 1177 \nd. If everyone in a group is the friend of at least ha lf the people in the group, then \nthe group can be seated around a table in such a wa y that everyone is seated \nbetween two friends. \nB-3  Bisecting  trees  \nMany  divide-and-conquer  algorithms  that  operate  on  graphs  require that the graph \nbe bisected  into  two  nearly  equal-sized  subgraphs,  which  are induced by a partition \nof the vertices. This problem investigates bisectio ns of trees formed by removing a \nsmall number of edges. We require that whenever two  vertices end up in the same \nsubtree after removing edges, then they must belong  to the same partition. \na. Show that the vertices of any n-vertex  binary  tree  can  be partitioned  into  two  \nsets A and B , such that jAj \u0dc4  3n=4  and jB j \u0dc4  3n=4 , by removing a single \nedge. \nb. Show that the constant 3=4  in part (a) is optimal in the worst case by giving \nan example of a simple binary tree whose most evenl y balanced partition upon \nremoval of a single edge has jAj D  3n=4 . \nc. Show that by removing at most O.lg n/ edges, we can partition the vertices \nof any n-vertex  binary  tree  into  two  sets  A and B such that jAj D bn=2c and \njB j D dn=2e. \nAppendix  notes  \nG.  Boole  pioneered  the  development  of symbolic  logic,  and  he introduced many of \nthe  basic  set  notations  in a book  published  in 1854.  Modern  set theory was created \nby  G.  Cantor  during  the  period  187431895.  Cantor  focused  primarily on sets of \nin\u00fbnite  cardinality.  The  term  <function=  is attributed  to G. W. Leibniz, who used it \nto refer to several kinds of mathematical formulas.  His limited  de\u00fbnition  has  been  \ngeneralized  many  times.  Graph  theory  originated  in 1736,  when L. Euler proved \nthat it was impossible to cross each of the seven b ridges in the city  of K\u00a8  onigsberg  \nexactly once and return to the starting point. \nThe  book  by  Harary  [208]  provides  a useful  compendium  of many  de\u00fbnitions  \nand results from graph theory. C Counting  and  Probability  \nThis appendix reviews elementary combinatorics and probability theory. If you \nhave a good background in these areas, you may want  to skim the beginning of this \nappendix lightly and concentrate on the later secti ons. Most of this  book\u2019s  chapters  \ndo not require probability, but for some chapters i t is essential. \nSection  C.1  reviews  elementary  results  in counting  theory,  including standard \nformulas for counting permutations and combinations . The axioms of probability \nand basic facts concerning probability distribution s form Section C.2. Random \nvariables  are  introduced  in Section  C.3,  along  with  the  properties of expectation \nand  variance.  Section  C.4  investigates  the  geometric  and  binomial distributions \nthat arise from studying Bernoulli trials. The stud y of the binomial distribution \ncontinues  in Section  C.5,  an advanced  discussion  of the  <tails= of the distribution. \nC.1  Counting  \nCounting  theory  tries  to answer  the  question  <How  many?=  without  actually  enu-  \nmerating all the choices. For example, you might as k, <How many different n-bit  \nnumbers  are  there?=  or <How  many  orderings  of n distinct  elements  are  there?=  \nThis section reviews the elements of counting theor y. Since some of the material \nassumes a basic understanding of sets, you might wi sh to start by reviewing the \nmaterial  in Section  B.1.  \nRules  of sum  and  product  \nWe can sometimes express a set of items that we wis h to count as a union of disjoint \nsets or as a Cartesian product of sets. \nThe rule  of sum  says that the number of ways to choose one element from one \nof two disjoint sets is the sum of the cardinalities of the sets. T hat is, if A and B \nare  two  \u00fbnite  sets  with  no  members  in common,  then  jA [ B j D jAj C jB j, which C.1  Counting  1179 \nfollows  from  equation  (B.3)  on  page  1156.  For  example,  if each  position  on  a car\u2019s  \nlicense plate is a letter or a digit, then the numb er of possibilities for each position \nis 26  C 10  D 36, since there are 26  choices if it is a letter and 10  choices if it is a \ndigit. \nThe rule  of product  says that the number of ways to choose an ordered p air is \nthe  number  of ways  to choose  the  \u00fbrst  element  times  the  number  of ways to choose \nthe second element. That is, if A and B are  two  \u00fbnite  sets,  then  jA \ue005 B j D jAj\ue001jB j, \nwhich  is simply  equation  (B.4)  on  page  1157.  For  example,  if an ice-cream  parlor  \noffers 28  \u00fcavors  of ice  cream  and  four  toppings,  the  number  of possible  sundaes \nwith one scoop of ice cream and one topping is 28  \ue001 4 D 112. \nStrings  \nA string  over  a \u00fbnite  set  S is a sequence of elements of S . For example, there are \neight binary strings of length 3: \n000;001;010;011;100;101;110;111:  \n(Here we use the shorthand of omitting the angle br ackets when denoting  a se-  \nquence.) We sometimes call a string of length k a k-string . A substring  s 0 of a \nstring s is an ordered sequence of consecutive elements of s . A k-substring  of a \nstring is a substring of length k. For example, 010  is a 3-substring  of 01101001  \n(the 3-substring  that  begins  in position  4), but 111  is not a substring of 01101001 . \nWe can view a k-string  over  a set  S as an element of the Cartesian product S k \nof k-tuples,  which  means  that  there  are  jS j k strings of length k. For example, the \nnumber of binary k-strings  is 2 k . Intuitively, to construct a k-string  over  an n-set,  \nthere are n ways  to pick  the  \u00fbrst  element;  for  each  of these  choices,  there are n \nways to pick the second element; and so forth k times. This construction leads to \nthe k-fold  product  n \ue001 n \ue001 \ue001 \ue001  n \u02dc  \nn times D n k as the number of k-strings.  \nPermutations  \nA permutation  of a \u00fbnite  set  S is an ordered sequence of all the elements of S , \nwith each element appearing exactly once. For examp le, if S D fa;b;c  g, then S \nhas 6 permutations: \nabc;acb;bac;bca;cab;cba:  \n(Again, we use the shorthand of omitting the angle brackets when  denoting  a se-  \nquence.) There are n\u0160 permutations of a set of n elements, since there are n ways to \nchoose  the  \u00fbrst  element  of the  sequence,  n \ue003 1 ways for the second element, n \ue003 2 \nways for the third, and so on. 1180  Appendix  C Counting  and  Probability  \nA k-permutation  of S is an ordered sequence of k elements of S , with  no  ele-  \nment appearing more than once in the sequence. (Thu s, an ordinary permutation is \nan n-permutation  of an n-set.)  Here  are  the  2-permutations  of the  set  fa;b;c;d  g: \nab;ac;ad;ba;bc;bd;ca;cb;cd;da;db;dc:  \nThe number of k-permutations  of an n-set  is \nn.n  \ue003 1/.n  \ue003 2/ \ue001 \ue001 \ue001  .n \ue003 k C 1/ D n\u0160 \n.n \ue003 k/\u0160  ; (C.1)  \nsince there are n ways  to choose  the  \u00fbrst  element,  n \ue003 1 ways to choose the second \nelement, and so on, until k elements are chosen, with the last element chosen f rom \nthe remaining n \ue003 k C 1 elements. For the above example, with n D 4 and k D 2, \nthe  formula  (C.1)  evaluates  to 4\u0160=2\u0160  D 12, matching the number of 2-permutations  \nlisted. \nCombinations  \nA k-combination  of an n-set  S is simply a k-subset  of S . For example, the 4-set  \nfa;b;c;d  g has six 2-combinations:  \nab;ac;ad;bc;bd;cd :  \n(Here we use the shorthand of omitting the braces a round each subset.)  To  con-  \nstruct a k-combination  of an n-set,  choose  k distinct (different) elements from the \nn-set.  The  order  of selecting  the  elements  does  not  matter.  \nWe can express the number of k-combinations  of an n-set  in terms  of the  number  \nof k-permutations  of an n-set.  Every  k-combination  has  exactly  k\u0160 permutations \nof its elements, each of which is a distinct k-permutation  of the  n-set.  Thus  the  \nnumber of k-combinations  of an n-set  is the  number  of k-permutations  divided  \nby k\u0160. From  equation  (C.1),  this  quantity  is \nn\u0160 \nk\u0160.n  \ue003 k/\u0160  : (C.2) \nFor k D 0, this formula tells us that the number of ways to choose 0 elements from \nan n-set  is 1 (not 0), since 0\u0160 D 1. \nBinomial  coef\ufb01cients  \nThe notation \u00e3 n \nk \u00e4 \n(read <n choose k=) denotes the number of k-combinations  of an \nn-set.  Equation  (C.2)  gives  \n\ue001 \nn \nk ! \nD n\u0160 \nk\u0160.n  \ue003 k/\u0160  : C.1  Counting  1181 \nThis formula is symmetric in k and n \ue003 k: \ue001 \nn \nk ! \nD \ue001 \nn \nn \ue003 k ! \n: (C.3)  \nThese numbers are also known as binomial  coef\ufb01cients , due to their appearance in \nthe binomial  theorem : \n.x C y/  n D n X  \nkD0 \ue001 \nn \nk ! \nx k y n\ue002k ; (C.4)  \nwhere n 2 N and x;y  2 R. The  right-hand  side  of equation  (C.4)  is called  the  \nbinomial  expansion  of the  left-hand  side.  A special  case  of the  binomial  theorem  \noccurs when x D y D 1: \n2 n D n X  \nkD0 \ue001 \nn \nk ! \n: \nThis formula corresponds to counting the 2 n binary n-strings  by  the  number  of 1s \nthey contain: \u00e3 n \nk \u00e4 \nbinary n-strings  contain  exactly  k1s, since there are \u00e3 n \nk \u00e4 \nways to \nchoose k out of the n positions in which to place the 1s. \nMany  identities  involve  binomial  coef\u00fbcients.  The  exercis es at the end of this \nsection give you the opportunity to prove a few. \nBinomial  bounds  \nYou  sometimes  need  to bound  the  size  of a binomial  coef\u00fbcient . For 1 \u0dc4 k \u0dc4 n, \nwe have the lower bound \ue001 \nn \nk ! \nD n.n  \ue003 1/ \ue001 \ue001 \ue001  .n \ue003 k C 1/ \nk.k  \ue003 1/ \ue001 \ue001 \ue001  1 \nD \ue002 n \nk \u00cd \u00ce n \ue003 1 \nk \ue003 1 \u00cf \n\ue001 \ue001 \ue001  \u00ce n \ue003 k C 1 \n1 \u00cf \n\ue004 \ue002 n \nk \u00cd k \n: (C.5)  \nTaking advantage of the inequality k\u0160 \ue004 .k=e/  k derived  from  Stirling\u2019s  approxi-  \nmation  (3.25)  on  page  67,  we  obtain  the  upper  bounds  \ue001 \nn \nk ! \nD n.n  \ue003 1/ \ue001 \ue001 \ue001  .n \ue003 k C 1/ \nk.k  \ue003 1/ \ue001 \ue001 \ue001  1 \n\u0dc4 n k \nk\u0160 \n\u0dc4 \ue002 en  \nk \u00cd k \n: (C.6)  1182  Appendix  C Counting  and  Probability  \nFor all integers k such that 0 \u0dc4 k \u0dc4 n, you  can  use  induction  (see  Exercise  C.1-12)  \nto prove the bound \n\ue001 \nn \nk ! \n\u0dc4 n n \nk k .n \ue003 k/  n\ue002k ; (C.7)  \nwhere for convenience we assume that 0 0 D 1. For k D \ufffdn, where 0 \u0dc4 \ufffd \u0dc4 1, we \ncan rewrite this bound as \n\ue001 \nn \n\ufffdn  ! \n\u0dc4 n n \n.\ufffdn/  \u00e6n  ..1  \ue003 \ufffd/n/  .1\ue002\u00e6/n  \nD \ue001 \u00ce 1 \n\ufffd \u00cf \u00e6 \u00ce 1 \n1 \ue003 \ufffd \u00cf 1\ue002\u00e6 ! n \nD 2 n H.\u00e6/  ; \nwhere \nH.\ufffd/  D \ue003\ufffd lg \ufffd \ue003 .1 \ue003 \ufffd/  lg.1 \ue003 \ufffd/  (C.8)  \nis the (binary)  entropy  function  and where, for convenience, we assume that \n0 lg 0 D 0, so that H.0/  D H.1/  D 0. \nExercises  \nC.1-1  \nHow many k-substrings  does  an n-string  have?  (Consider  identical  k-substrings  at \ndifferent positions to be different.) How many subs trings does an n-string  have  in \ntotal?  \nC.1-2  \nAn n-input,  m-output  boolean  function  is a function from f0;1g n to f0;1g m . How \nmany n-input,  1-output  boolean  functions  are  there?  How  many  n-input,  m-output  \nboolean  functions  are  there?  \nC.1-3  \nIn how many ways can n professors  sit  around  a circular  conference  table?  Con-  \nsider two seatings to be the same if one can be rot ated to form the other. \nC.1-4  \nIn how many ways is it possible to choose three dis tinct numbers from the set \nf1;2;:::;99 g so that  their  sum  is even?  C.1  Counting  1183 \nC.1-5  \nProve the identity \n\ue001 \nn \nk ! \nD n \nk \ue001 \nn \ue003 1 \nk \ue003 1 ! \n(C.9) \nfor 0<k  \u0dc4 n. \nC.1-6  \nProve the identity \n\ue001 \nn \nk ! \nD n \nn \ue003 k \ue001 \nn \ue003 1 \nk ! \nfor 0 \u0dc4 k<n . \nC.1-7  \nTo choose k objects from n, you can make one of the objects distinguished and  \nconsider whether the distinguished object is chosen . Use this approach to prove \nthat \n\ue001 \nn \nk ! \nD \ue001 \nn \ue003 1 \nk ! \nC \ue001 \nn \ue003 1 \nk \ue003 1 ! \n: \nC.1-8  \nUsing  the  result  of Exercise  C.1-7,  make  a table  for  n D 0;1;:::;6  and 0 \u0dc4 k \u0dc4 n \nof the  binomial  coef\u00fbcients  \u00e3 n \nk \u00e4 \nwith \u00e3 0 \n0 \u00e4 \nat the top, \u00e3 1 \n0 \u00e4 \nand \u00e3 1 \n1 \u00e4 \non the next line, \nthen \u00e3 2 \n0 \u00e4 \n, \u00e3 2 \n1 \u00e4 \n, and \u00e3 2 \n2 \u00e4 \n, and  so forth.  Such  a table  of binomial  coef\u00fbcients  is called  \nPascal\u2019s  triangle . \nC.1-9  \nProve that \nn X  \ni D1 i D \ue001 \nn C 1 \n2 ! \n: \nC.1-10  \nShow that for any integers n \ue004 0 and 0 \u0dc4 k \u0dc4 n, the expression \u00e3 n \nk \u00e4 \nachieves its \nmaximum value when k D bn=2c or k D dn=2e. 1184  Appendix  C Counting  and  Probability  \n? C.1-11  \nArgue that for any integers n \ue004 0, j \ue004 0, k \ue004 0, and j C k \u0dc4 n, \ue001 \nn \nj C k ! \n\u0dc4 \ue001 \nn \nj !\ue001  \nn \ue003 j \nk ! \n: (C.10)  \nProvide both an algebraic proof and an argument bas ed on a method for choosing \nj C k items out of n. Give  an example  in which  equality  does  not  hold.  \n? C.1-12  \nUse induction on all integers k such that 0 \u0dc4 k \u0dc4 n=2  to prove  inequality  (C.7),  \nand  use  equation  (C.3)  to extend  it to all  integers  k such that 0 \u0dc4 k \u0dc4 n. \n? C.1-13  \nUse  Stirling\u2019s  approximation  to prove  that  \ue001 \n2n  \nn ! \nD 2 2n  \np \ufffdn  .1 C O.1=n//:  (C.11)  \n? C.1-14  \nBy differentiating the entropy function H.\ufffd/ , show that it achieves its maximum \nvalue at \ufffd D 1=2. What is H.1=2/? \n? C.1-15  \nShow that for any integer n \ue004 0, \nn X  \nkD0 \ue001 \nn \nk ! \nk D n2  n\ue0021 : (C.12)  \n? C.1-16  \nInequality  (C.5)  provides  a lower  bound  on  the  binomial  coef\u00fbcient  \u00e3 n \nk \u00e4 \n. For small \nvalues of k, a stronger bound holds. Prove that \ue001 \nn \nk ! \n\ue004 n k \n4k\u0160  (C.13)  \nfor k \u0dc4 p n. \nC.2  Probability  \nProbability is an essential tool for the design and  analysis of probabilistic  and  ran-  \ndomized algorithms. This section reviews basic prob ability theory. C.2  Probability  1185 \nWe  de\u00fbne  probability  in terms  of a sample  space  S , which  is a set  whose  ele-  \nments are called outcomes  or elementary  events. Think  of each  outcome  as a pos-  \nsible  result  of an experiment.  For  the  experiment  of \u00fcipping  two distinguishable \ncoins,  with  each  individual  \u00fcip  resulting  in a head  (H) or a tail ( T), you can view \nthe sample space S as consisting of the set of all possible 2-strings  over  fH; Tg: \nS D f HH; HT; TH; TTg : \nAn event  is a subset 1 of the sample space S . For example, in the experiment of \n\u00fcipping  two  coins,  the  event  of obtaining  one  head  and  one  tail is fHT; THg. The \nevent S is called the certain  event , and the event ; is called the null  event . We \nsay that two events A and B are mutually  exclusive  if A \\ B D ;. An outcome s \nalso  de\u00fbnes  the  event  fs g, which we sometimes write as just s . By  de\u00fbnition,  all  \noutcomes are mutually exclusive. \nAxioms  of probability  \nA probability  distribution  Pr fg on a sample space S is a mapping from events of S \nto real numbers satisfying the following probability  axioms : \n1. Pr fAg \ue004  0 for any event A. \n2. Pr fS g D  1. \n3. Pr fA [ B g D  Pr fAg C  Pr fB g for any two mutually exclusive events A and B . \nMore generally, for any sequence of events A 1 ;A  2 ;:::  (\u00fbnite  or countably  in\u00fb-  \nnite) that are pairwise mutually exclusive, \nPr \u00ef [  \ni A i \u00f0 \nD X  \ni Pr fA i g : \nWe call Pr fAg the probability  of the event A. Axiom 2 is simply a normalization \nrequirement: there is really nothing fundamental ab out choosing 1 as the  probabil-  \nity of the certain event, except that it is natural  and convenient. \nSeveral results follow immediately from these axiom s and basic set theory (see \nSection  B.1).  The  null  event  ; has probability Pr f;g  D 0. If A \u0dc2 B , then \n1 For a general probability distribution, there may b e some subsets of the sample space S that are not \nconsidered to be events. This situation usually ari ses when the  sample  space  is uncountably  in\u00fbnite.  \nThe main requirement for what subsets are events is  that the set of events of a sample space must \nbe closed under the operations of taking the comple ment of an event,  forming  the  union  of a \u00fbnite  \nor countable number of events, and taking the inter section of a \u00fbnite  or countable  number  of events.  \nMost of the probability distributions we see in thi s book are over  \u00fbnite  or countable  sample  spaces,  \nand we generally consider all subsets of a sample s pace to be events. A notable exception is the \ncontinuous  uniform  probability  distribution,  which  we\u2019ll  see shortly. 1186  Appendix  C Counting  and  Probability  \nPr fAg \u0dc4  Pr fB g. Using A to denote the event S \ue003 A (the complement  of A), \nwe have Pr \u02da \nA \ue009 \nD 1 \ue003 Pr fAg. For any two events A and B , \nPr fA [ B g D  Pr fAg C  Pr fB g \ue003  Pr fA \\ B g (C.14)  \n\u0dc4 Pr fAg C  Pr fB g : (C.15)  \nIn our  coin-\u00fcipping  example,  suppose  that  each  of the  four  outcomes  has  prob-  \nability 1=4. Then the probability of getting at least one head  is \nPr fHH; HT; THg D  Pr fHHg C  Pr fHTg C  Pr fTHg \nD 3=4:  \nAnother way to obtain the same result is to observe  that since the probability of \ngetting strictly less than one head is Pr fTTg D  1=4, the probability of getting at \nleast one head is 1 \ue003 1=4  D 3=4. \nDiscrete  probability  distributions  \nA probability distribution is discrete  if it is de\u00fbned  over  a \u00fbnite  or countably  in\u00fbnite  \nsample space. Let S be the sample space. Then for any event A, \nPr fAg D  X  \ns2A Pr fs g ; \nsince  outcomes,  speci\u00fbcally  those  in A, are mutually exclusive. If S is \u00fbnite  and  \nevery outcome s 2 S has probability Pr fs g D  1=  jS j, then we have the uniform  \nprobability  distribution  on S . In such a case the experiment is often described as \n<picking an element of S at random.= \nAs  an example,  consider  the  process  of \u00fcipping  a fair  coin, one for which the \nprobability of obtaining a head is the same as the probability of obtaining a tail, \nthat is, 1=2. Flipping the coin n times gives the uniform probability distribution \nde\u00fbned  on  the  sample  space  S D f H; Tg n , a set of size 2 n . We can represent each \noutcome in S as a string of length n over fH; Tg, with each string occurring with \nprobability 1=2  n . The event A D fexactly k heads and exactly n \ue003 k tails occur g \nis a subset of S of size jAj D  \u00e3 n \nk \u00e4 \n, since \u00e3 n \nk \u00e4 \nstrings of length n over fH; Tg contain \nexactly k H\u2019s. The  probability  of event  A is thus Pr fAg D  \u00e3 n \nk \u00e4 \n=2  n . \nContinuous  uniform  probability  distribution  \nThe continuous uniform probability distribution is an example  of a probability  dis-  \ntribution in which not all subsets of the sample sp ace are considered to be events. \nThe  continuous  uniform  probability  distribution  is de\u00fbned  over  a closed  inter-  \nval \u0152a; b\ufffd  of the reals, where a < b. The  intuition  is that  each  point  in the  in-  \nterval \u0152a; b\ufffd  should be <equally likely.= Because there are an un countable number C.2  Probability  1187 \nof points,  however,  if all  points  had  the  same  \u00fbnite,  positiv e probability, axioms 2 \nand  3 would  not  be simultaneously  satis\u00fbed.  For  this  reason,  we\u2019d  like  to associate  \na probability only with some of the subsets of S in such a way that the axioms are \nsatis\u00fbed  for  these  events.  \nFor any closed interval \u0152c; d \ufffd , where a \u0dc4 c \u0dc4 d \u0dc4 b, the continuous  uniform  \nprobability  distribution  de\u00fbnes  the  probability  of the  event  \u0152c; d \ufffd  to be \nPr f\u0152c; d \ufffdg D  d \ue003 c \nb \ue003 a : \nLetting c D d gives that the probability of a single point is 0. Removing  the  end-  \npoints \u0152c; c\ufffd  and \u0152d; d \ufffd  of an interval \u0152c; d \ufffd  results in the open interval .c;d/ . Since \n\u0152c; d \ufffd  D \u0152c; c\ufffd  [ .c;d/  [ \u0152d; d \ufffd, axiom  3 gives  Pr f\u0152c; d \ufffdg D  Pr f.c;d/ g. Generally,  \nthe set of events for the continuous uniform probab ility distribution contains any \nsubset of the sample space \u0152a; b\ufffd  that  can  be obtained  by  a \u00fbnite  or countable  union  \nof open and closed intervals, as well as certain mo re complicated sets. \nConditional  probability  and  independence  \nSometimes you have some prior partial knowledge abo ut the outcome  of an exper-  \niment.  For  example,  suppose  that  a friend  has  \u00fcipped  two  fair  coins and has told \nyou that at least one of the coins showed a head. W hat is the probability that both \ncoins  are  heads?  The  information  given  eliminates  the  possi bility of two tails. The \nthree remaining outcomes are equally likely, and so  you infer that each occurs with \nprobability 1=3. Since only one of these outcomes shows two heads,  the answer \nis 1=3. \nConditional probability formalizes the notion of ha ving prior partial knowledge \nof the outcome of an experiment. The conditional  probability  of an event A given \nthat another event B occurs  is de\u00fbned  to be \nPr fA j B g D  Pr fA \\ B g \nPr fB g (C.16)  \nwhenever Pr fB g \u00a4  0. (Read <Pr fA j B g= as <the probability of A given B .=) \nThe  idea  behind  equation  (C.16)  is that  since  we  are  given  that event B occurs, \nthe event that A also occurs is A \\ B . That is, A \\ B is the set of outcomes in \nwhich both A and B occur. Because the outcome is one of the elementary  events \nin B , we normalize the probabilities of all the element ary events in B by dividing \nthem by Pr fB g, so that they sum to 1. The conditional probability of A given B is, \ntherefore, the ratio of the probability of event A \\ B to the probability of event B . \nIn the example above, A is the event that both coins are heads, and B is the event \nthat at least one coin is a head. Thus, Pr fA j B g D  .1=4/=.3=4/  D 1=3. 1188  Appendix  C Counting  and  Probability  \nTwo events are independent  if \nPr fA \\ B g D  Pr fAg Pr fB g ; (C.17)  \nwhich is equivalent, if Pr fB g \u00a4  0, to the condition \nPr fA j B g D  Pr fAg : \nFor  example,  suppose  that  you  \u00fcip  two  fair  coins  and  that  the  outcomes  are  inde-  \npendent. Then the probability of two heads is .1=2/.1=2/  D 1=4. Now suppose \nthat  one  event  is that  the  \u00fbrst  coin  comes  up  heads  and  the  other event is that the \ncoins come up differently. Each of these events occ urs with probability 1=2, and \nthe probability that both events occur is 1=4. Thus,  according  to the  de\u00fbnition  \nof independence,  the  events  are  independent4even  though  you might think that \nboth  events  depend  on  the  \u00fbrst  coin.  Finally,  suppose  that  the coins are welded \ntogether so that they both fall heads or both fall tails and that the two possibilities \nare equally likely. Then the probability that each coin comes up heads is 1=2, but \nthe probability that they both come up heads is 1=2  \u00a4 .1=2/.1=2/ . Consequently, \nthe event that one comes up heads and the event tha t the other comes up heads are \nnot independent. \nA collection A 1 ;A  2 ;:::;A  n of events is said to be pairwise  independent  if \nPr fA i \\ A j g D  Pr fA i g Pr fA j g \nfor all 1 \u0dc4 i < j  \u0dc4 n. We say that the events of the collection are (mutually)  \nindependent  if every k-subset  A i 1 ;A  i 2 ;:::;A  i k of the collection, where 2 \u0dc4 k \u0dc4 n \nand 1 \u0dc4 i 1 <i  2 < \ue001 \ue001 \ue001  <i  k \u0dc4 n, satis\u00fbes  \nPr fA i 1 \\ A i 2 \\ \ue001 \ue001 \ue001 \\  A i k g D  Pr fA i 1 g Pr fA i 2 g \ue001 \ue001 \ue001  Pr fA i k g : \nFor  example,  suppose  that  you  \u00fcip  two  fair  coins.  Let  A 1 be the  event  that  the  \u00fbrst  \ncoin is heads, let A 2 be the event that the second coin is heads, and let  A 3 be the \nevent that the two coins are different. Then, \nPr fA 1 g D  1=2  , \nPr fA 2 g D  1=2  , \nPr fA 3 g D  1=2  , \nPr fA 1 \\ A 2 g D  1=4  , \nPr fA 1 \\ A 3 g D  1=4  , \nPr fA 2 \\ A 3 g D  1=4  , \nPr fA 1 \\ A 2 \\ A 3 g D  0 . \nSince for 1 \u0dc4 i < j  \u0dc4 3, we have Pr fA i \\ A j g D  Pr fA i g Pr fA j g D  1=4, the \nevents A 1 , A 2 , and A 3 are  pairwise  independent.  The  events  are  not  mutually  inde-  \npendent, however, because Pr fA 1 \\ A 2 \\ A 3 g D  0 and Pr fA 1 g Pr fA 2 g Pr fA 3 g D  \n1=8  \u00a4 0. C.2  Probability  1189 \nBayes\u2019s  theorem  \nFrom  the  de\u00fbnition  (C.16)  of conditional  probability  and  the commutative law \nA \\ B D B \\ A, it follows that for two events A and B , each  with  nonzero  prob-  \nability, \nPr fA \\ B g D  Pr fB g Pr fA j B g (C.18)  \nD Pr fAg Pr fB j Ag : \nSolving for Pr fA j B g, we obtain \nPr fA j B g D  Pr fAg Pr fB j Ag \nPr fB g ; (C.19)  \nwhich is known as Bayes\u2019s  theorem . The denominator Pr fB g is a normalizing \nconstant, which we can reformulate as follows. Sinc e B D .B  \\ A/  [ .B  \\ A/, \nand since B \\ A and B \\ A are mutually exclusive events, \nPr fB g D  Pr fB \\ Ag C  Pr \u02da \nB \\ A \ue009 \nD Pr fAg Pr fB j Ag C  Pr \u02da \nA \ue009 \nPr \u02da \nB j A \ue009 \n: \nSubstituting  into  equation  (C.19)  produces  an equivalent  form  of Bayes\u2019s  theorem:  \nPr fA j B g D  Pr fAg Pr fB j Ag \nPr fAg Pr fB j Ag C  Pr \u02da \nA \ue009 \nPr \u02da \nB j A \ue009 : (C.20) \nBayes\u2019s  theorem  can  simplify  the  computing  of conditional  probabilities. For \nexample, suppose that you have a fair coin and a bi ased coin that always comes up \nheads. Run an experiment consisting of three indepe ndent events: choose one of \nthe  two  coins  at random,  \u00fcip  that  coin  once,  and  then  \u00fcip  it again. Suppose that the \ncoin you have chosen comes up heads both times. Wha t is the probability  that  it\u2019s  \nthe  biased  coin?  \nBayes\u2019s  theorem  solves  this  problem.  Let  A be the event that you choose the \nbiased coin, and let B be the event that the chosen coin comes up heads bo th times. \nWe wish to determine Pr fA j B g, knowing that Pr fAg D  1=2, Pr fB j Ag D  1, \nPr \u02da \nA \ue009 \nD 1=2, and Pr \u02da \nB j A \ue009 \nD 1=4. Thus we have \nPr fA j B g D  .1=2/  \ue001 1 \n.1=2/  \ue001 1 C .1=2/  \ue001 .1=4/  \nD 4=5:  1190  Appendix  C Counting  and  Probability  \nExercises  \nC.2-1  \nProfessor  Rosencrantz  \u00fcips  a fair  coin  twice.  Professor  Guildenstern  \u00fcips  a fair  \ncoin once. What is the probability that Professor R osencrantz obtains strictly more \nheads  than  Professor  Guildenstern?  \nC.2-2  \nProve Boole\u2019s  inequality: For  any  \u00fbnite  or countably  in\u00fbnite  sequence  of events  \nA 1 ;A  2 ;:::, \nPr fA 1 [ A 2 [ \ue001 \ue001 \ue001g \u0dc4  Pr fA 1 g C  Pr fA 2 g C \ue001 \ue001 \ue001  : (C.21)  \nC.2-3  \nYou  shuf\u00fce  a deck  of 10  cards, each bearing a distinct number from 1 to 10, in \norder to mix the cards thoroughly. You then remove three cards, one at a time, \nfrom the deck. What is the probability that the thr ee cards you select are in sorted \n(increasing)  order?  \nC.2-4  \nProve that \nPr fA j B g C  Pr \u02da \nA j B \ue009 \nD 1:  \nC.2-5  \nProve that for any collection of events A 1 ;A  2 ;:::;A  n , \nPr fA 1 \\ A 2 \\ \ue001 \ue001 \ue001 \\  A n g D  Pr fA 1 g \ue001 Pr fA 2 j A 1 g \ue001 Pr fA 3 j A 1 \\ A 2 g \ue001 \ue001 \ue001  \nPr fA n j A 1 \\ A 2 \\ \ue001 \ue001 \ue001 \\  A n\ue0021 g : (C.22) \n? C.2-6  \nShow how to construct a set of n events that are pairwise independent but such that \nno subset of k>2  of them is mutually independent. \n? C.2-7  \nTwo events A and B are conditionally  independent , given C , if \nPr fA \\ B j C g D  Pr fA j C g \ue001 Pr fB j C g : \nGive  a simple  but  nontrivial  example  of two  events  that  are  not independent but are \nconditionally independent given a third event. \n? C.2-8  \nProfessor  Gore  teaches  a music  class  on  rhythm  in which  three  students4Jeff,  Tim,  \nand  Carmine4are  in danger  of failing.  Professor  Gore  tells  the three that one of C.3  Discrete  random  variables  1191 \nthem will pass the course and the other two will fa il. Carmine asks  Professor  Gore  \nprivately  which  of Jeff  and  Tim  will  fail,  arguing  that  since  he already knows at \nleast  one  of them  will  fail,  the  professor  won\u2019t  be revealing  any information about \nCarmine\u2019s  outcome.  In a breach  of privacy  law,  Professor  Gore tells Carmine that \nJeff  will  fail.  Carmine  feels  somewhat  relieved  now,  \u00fbgurin g that either he or Tim \nwill pass, so that his probability of passing is no w 1=2. Is Carmine correct, or is \nhis chance of passing still 1=3? Explain.  \nC.3  Discrete  random  variables  \nA (discrete)  random  variable  X is a function  from  a \u00fbnite  or countably  in\u00fbnite  \nsample space S to the real numbers. It associates a real number wi th each possible \noutcome of an experiment, which allows us to work w ith the probability  distri-  \nbution induced on the resulting set of numbers. Ran dom variables can also be \nde\u00fbned  for  uncountably  in\u00fbnite  sample  spaces,  but  they  raise technical issues that \nare  unnecessary  to address  for  our  purposes.  Therefore  we\u2019ll assume that random \nvariables are discrete. \nFor a random variable X and a real number x , we  de\u00fbne  the  event  X D x to be \nfs 2 S W X.s/  D x g, and thus \nPr fX D x g D  X  \ns2SWX.s/Dx Pr fs g : \nThe function \nf.x/  D Pr fX D x g \nis the probability  density  function  of the random variable X . From the probability \naxioms, Pr fX D x g \ue004  0 and P  \nx Pr fX D x g D  1. \nAs an example, consider the experiment of rolling a  pair of ordinary, 6-sided  \ndice. There are 36  possible outcomes in the sample space. Assume that the \nprobability distribution is uniform, so that each o utcome s 2 S is equally likely: \nPr fs g D  1=36. De\u00fbne  the  random  variable  X to be the maximum  of the two values \nshowing on the dice. We have Pr fX D 3g D  5=36 , since X assigns a value of 3 \nto 5 of the 36  possible outcomes, namely, .1;3/ , .2;3/ , .3;3/ , .3;2/ , and .3;1/ . \nWe  can  de\u00fbne  several  random  variables  on  the  same  sample  space. If X and Y \nare random variables, the function \nf.x;y/  D Pr fX D x and Y D y g \nis the joint  probability  density  function  of X and Y . For  a \u00fbxed  value  y , 1192  Appendix  C Counting  and  Probability  \nPr fY D y g D  X  \nx Pr fX D x and Y D y g ; \nand  similarly,  for  a \u00fbxed  value  x , \nPr fX D x g D  X  \ny Pr fX D x and Y D y g : \nUsing  the  de\u00fbnition  (C.16)  of conditional  probability  on  page  1187,  we  have  \nPr fX D x j Y D y g D  Pr fX D x and Y D y g \nPr fY D y g : \nWe  de\u00fbne  two  random  variables  X and Y to be independent  if for all x and y , the \nevents X D x and Y D y are independent or, equivalently, if for all x and y , we \nhave Pr fX D x and Y D y g D  Pr fX D x g Pr fY D y g. \nGiven  a set  of random  variables  de\u00fbned  over  the  same  sample  space, we can \nde\u00fbne  new  random  variables  as sums,  products,  or other  funct ions of the original \nvariables. \nExpected  value  of a random  variable  \nThe simplest, and often the most useful, summary of  the distribution of a random \nvariable is the <average= of the values it takes on . The expected  value  (or,  synony-  \nmously, expectation  or mean ) of a discrete random variable X is \nE \u0152X\ufffd  D X  \nx x \ue001 Pr fX D x g ; (C.23)  \nwhich  is well  de\u00fbned  if the  sum  is \u00fbnite  or converges  absolute ly. Sometimes the \nexpectation of X is denoted by \ufffd X or, when the random variable is apparent from \ncontext, simply by \ufffd. \nConsider  a game  in which  you  \u00fcip  two  fair  coins.  You  earn  $3 for each head but \nlose $2 for each tail. The expected value of the random var iable X representing \nyour earnings is \nE \u0152X\ufffd  D 6 \ue001 Pr f2 H\u2019sg C  1 \ue001 Pr f1 H,1  Tg \ue003  4 \ue001 Pr f2 T\u2019sg \nD 6 \ue001 .1=4/  C 1 \ue001 .1=2/  \ue003 4 \ue001 .1=4/  \nD 1:  \nLinearity  of expectation  says that the expectation of the sum of two random \nvariables is the sum of their expectations, that is , \nE \u0152X  C Y \ufffd  D E \u0152X\ufffd  C E \u0152Y \ufffd ;  (C.24)  C.3  Discrete  random  variables  1193 \nwhenever E \u0152X\ufffd  and E \u0152Y \ufffd  are  de\u00fbned.  Linearity  of expectation  applies  to a broad  \nrange of situations, holding even when X and Y are  not  independent.  It also  ex-  \ntends  to \u00fbnite  and  absolutely  convergent  summations  of expe ctations. Linearity of \nexpectation is the key property that enables us to perform probabilistic analyses by \nusing  indicator  random  variables  (see  Section  5.2).  \nIf X is any random variable, any function g.x/  de\u00fbnes  a new  random  vari-  \nable g.X/ . If the expectation of g.X/  is de\u00fbned,  then  \nE \u0152g.X/\ufffd  D X  \nx g.x/  \ue001 Pr fX D x g : \nLetting g.x/  D ax  , we have for any constant a, \nE \u0152aX\ufffd  D aE \u0152X\ufffd :  (C.25)  \nConsequently, expectations are linear: for any two random variables X and Y and \nany constant a, \nE \u0152aX  C Y \ufffd  D aE \u0152X\ufffd  C E \u0152Y \ufffd :  (C.26)  \nWhen two random variables X and Y are  independent  and  each  has  a de\u00fbned  \nexpectation, \nE \u0152XY \ufffd  D X  \nx X  \ny xy  \ue001 Pr fX D x and Y D y g \nD X  \nx X  \ny xy  \ue001 Pr fX D x g Pr fY D y g (by independence of X and Y ) \nD \ue001 X  \nx x \ue001 Pr fX D x g !\ue001  X  \ny y \ue001 Pr fY D y g ! \nD E \u0152X\ufffd  E \u0152Y \ufffd  (by  equation  (C.23))  . \nIn general, when n random variables X 1 ;X  2 ;:::;X  n are mutually independent, \nE \u0152X  1 X 2 \ue001 \ue001 \ue001  X n \ufffd D E \u0152X  1 \ufffd E \u0152X  2 \ufffd \ue001 \ue001 \ue001  E \u0152X  n \ufffd :  (C.27)  \nWhen a random variable X takes on values from the set of natural numbers \nN D f0;1;2;::: g, we have a nice formula for its expectation: \nE \u0152X\ufffd  D 1  X  \ni D0 i \ue001 Pr fX D i g \nD 1  X  \ni D0 i \ue001 .Pr fX \ue004 i g \ue003  Pr fX \ue004 i C 1g/ \nD 1  X  \ni D1 Pr fX \ue004 i g ; (C.28)  1194  Appendix  C Counting  and  Probability  \nsince each term Pr fX \ue004 i g is added in i times and subtracted out i \ue003 1 times \n(except Pr fX \ue004 0g, which is added in 0 times and not subtracted out at all). \nA function f.x/  is convex  if \nf.\ufffdx  C .1 \ue003 \ufffd/y/  \u0dc4 \ufffdf  .x/  C .1 \ue003 \ufffd/f  .y/  (C.29) \nfor all x and y and for all 0 \u0dc4 \ufffd \u0dc4 1. Jensen\u2019s  inequality  says that when a convex \nfunction f.x/  is applied to a random variable X , \nE \u0152f .X/\ufffd  \ue004 f.E \u0152X\ufffd/ ;  (C.30)  \nprovided  that  the  expectations  exist  and  are  \u00fbnite.  \nVariance  and  standard  deviation  \nThe expected value of a random variable does not ex press how <spread out= the \nvariable\u2019s  values  are.  For  example,  consider  random  variab les X and Y for which \nPr fX D 1=4g D  Pr fX D 3=4g D  1=2  and Pr fY D 0g D  Pr fY D 1g D  1=2. \nThen both E \u0152X\ufffd  and E \u0152Y \ufffd  are 1=2, yet the actual values taken on by Y are further \nfrom the mean than the actual values taken on by X . \nThe notion of variance mathematically expresses how  far from the  mean  a ran-  \ndom  variable\u2019s  values  are  likely  to be.  The  variance  of a random variable X with \nmean E \u0152X\ufffd  is \nVar \u0152X\ufffd  D E \u00ed \n.X  \ue003 E \u0152X\ufffd/  2 \u00ee \nD E \u00ed X 2 \ue003 2X  E \u0152X\ufffd  C E 2 \u0152X\ufffd  \u00ee \nD E \u0152X  2 \ufffd \ue003 2E \u0152X  E \u0152X\ufffd\ufffd  C E 2 \u0152X\ufffd  \nD E \u0152X  2 \ufffd \ue003 2E 2 \u0152X\ufffd  C E 2 \u0152X\ufffd  \nD E \u0152X  2 \ufffd \ue003 E 2 \u0152X\ufffd :  (C.31)  \nTo justify the equation E \u0152E 2 \u0152X\ufffd\ufffd  D E 2 \u0152X\ufffd, note that because E \u0152X\ufffd  is a real  num-  \nber and not a random variable, so is E 2 \u0152X\ufffd. The equation E \u0152X  E \u0152X\ufffd\ufffd  D E 2 \u0152X\ufffd  \nfollows  from  equation  (C.25),  with  a D E \u0152X\ufffd. Rewriting  equation  (C.31)  yields  \nan expression for the expectation of the square of a random variable: \nE \u0152X  2 \ufffd D Var \u0152X\ufffd  C E 2 \u0152X\ufffd :  (C.32)  \nThe variance of a random variable X and the variance of aX  are related (see \nExercise  C.3-10):  \nVar \u0152aX\ufffd  D a 2 Var \u0152X\ufffd :  \nWhen X and Y are independent random variables, \nVar \u0152X  C Y \ufffd  D Var \u0152X\ufffd  C Var \u0152Y \ufffd :  C.3  Discrete  random  variables  1195 \nIn general, if n random variables X 1 ;X  2 ;:::;X  n are pairwise independent, then \nVar \" n X  \ni D1 X i # \nD n X  \ni D1 Var \u0152X  i \ufffd :  (C.33)  \nThe standard  deviation  of a random variable X is the nonnegative square root \nof the variance of X . The standard deviation of a random variable X is sometimes \ndenoted \ufffd X or simply \ufffd when the random variable X is understood from context. \nWith this notation, the variance of X is denoted \ufffd 2 . \nExercises  \nC.3-1  \nYou  roll  two  ordinary,  6-sided  dice.  What  is the  expectation  of the sum of the \ntwo  values  showing?  What  is the  expectation  of the  maximum  of the two values \nshowing?  \nC.3-2  \nAn array A\u01521  W n\ufffd contains n distinct numbers that are randomly ordered, with ea ch \npermutation of the n numbers being equally likely. What is the expectati on of the \nindex  of the  maximum  element  in the  array?  What  is the  expecta tion of the index \nof the  minimum  element  in the  array?  \nC.3-3  \nA carnival game consists of three dice in a cage. A  player can bet a dollar on \nany of the numbers 1 through 6. The  cage  is shaken,  and  the  payoff  is as fol-  \nlows.  If the  player\u2019s  number  doesn\u2019t  appear  on  any  of the  dice, the player loses the \ndollar.  Otherwise,  if the  player\u2019s  number  appears  on  exactl y k of the three dice, \nfor k D 1;2;3 , the player keeps the dollar and wins k more dollars. What is the \nexpected  gain  from  playing  the  carnival  game  once?  \nC.3-4  \nArgue that if X and Y are nonnegative random variables, then \nE \u0152max fX;Y  g\ufffd \u0dc4 E \u0152X\ufffd  C E \u0152Y \ufffd :  \n? C.3-5  \nLet X and Y be independent random variables. Prove that f.X/  and g.Y/  are \nindependent for any choice of functions f and g. 1196  Appendix  C Counting  and  Probability  \n? C.3-6  \nLet X be a nonnegative random variable, and suppose that E \u0152X\ufffd  is well  de\u00fbned.  \nProve Markov\u2019s  inequality : \nPr fX \ue004 t g \u0dc4  E \u0152X\ufffd =t  (C.34)  \nfor all t>0 . \n? C.3-7  \nLet S be a sample space, and let X and X 0 be random variables such that \nX.s/  \ue004 X 0 .s/  for all s 2 S . Prove that for any real constant t , \nPr fX \ue004 t g \ue004  Pr fX 0 \ue004 t g : \nC.3-8  \nWhich is larger: the expectation of the square of a  random variable, or the square \nof its  expectation?  \nC.3-9  \nShow that for any random variable X that takes on only the values 0 and 1, we have \nVar \u0152X\ufffd  D E \u0152X\ufffd  E \u01521 \ue003 X\ufffd. \nC.3-10  \nProve that Var \u0152aX\ufffd  D a 2 Var \u0152X\ufffd  from  the  de\u00fbnition  (C.31)  of variance.  \nC.4  The  geometric  and  binomial  distributions  \nA Bernoulli  trial  is an experiment with only two possible outcomes: success , \nwhich occurs with probability p, and failure , which occurs with probability \nq D 1 \ue003 p. A coin  \u00fcip  serves  as an example  where,  depending  on  your  point of \nview, heads equates to success and tails to failure . When we speak of Bernoulli  \ntrials  collectively, we mean that the trials are mutually independent and, unless we \nspeci\u00fbcally  say  otherwise,  that  each  has  the  same  probabili ty p for success. Two \nimportant distributions arise from Bernoulli trials : the geometric distribution and \nthe binomial distribution. \nThe  geometric  distribution  \nConsider a sequence of Bernoulli trials, each with a probability p of success and a \nprobability q D 1 \ue003 p of failure.  How  many  trials  occur  before  a success?  De\u00fbne  \nthe random variable X to be the number of trials needed to obtain a succe ss. Then \nX has values in the range f1;2;::: g, and for k \ue004 1, C.4  The  geometric  and  binomial  distributions  1197 \n0.05  0.10  0.15  0.20 0.25  \n1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  0.30  0.35  \nk \u00ce 2 \n3 \u00cf k\ue0021 \u00ce 1 \n3 \u00cf \nFigure  C.1  A geometric distribution with probability p D 1=3  of success and a probability \nq D 1 \ue003 p of failure. The expectation of the distribution is 1=p  D 3. \nPr fX D kg D  q k\ue0021 p;  (C.35)  \nsince k \ue003 1 failures  occur  before  the  \u00fbrst  success.  A probability  distribution  satis-  \nfying  equation  (C.35)  is said  to be a geometric  distribution. Figure  C.1  illustrates  \nsuch a distribution. \nAssuming that q<1, we  can  calculate  the  expectation  of a geometric  distribu-  \ntion: \nE \u0152X\ufffd  D 1  X  \nkD1 kq  k\ue0021 p \nD p \nq 1  X  \nkD0 kq  k \nD p \nq \ue001 q \n.1 \ue003 q/ 2 (by  equation  (A.11)  on  page  1142)  \nD p \nq \ue001 q \np 2 \nD 1=p  : (C.36)  1198  Appendix  C Counting  and  Probability  \nThus, on average, it takes 1=p  trials before a success occurs, an intuitive result . As \nExercise  C.4-3  asks  you  to show,  the  variance  is \nVar \u0152X\ufffd  D q=p  2 : (C.37)  \nAs an example, suppose that you repeatedly roll two  dice until you obtain either \na seven  or an eleven.  Of  the  36  possible outcomes, 6 yield a seven and 2 yield an \neleven. Thus, the probability of success is p D 8=36  D 2=9, and  you\u2019d  have  to \nroll 1=p  D 9=2  D 4:5  times on average to obtain a seven or eleven. \nThe  binomial  distribution  \nHow many successes occur during n Bernoulli trials, where a success occurs with \nprobability p and a failure with probability q D 1 \ue003 p? De\u00fbne  the  random  vari-  \nable X to be the number of successes in n trials. Then X has values in the range \nf0;1;:::;n g, and for k D 0;1;:::;n , \nPr fX D kg D  \ue001 \nn \nk ! \np k q n\ue002k ; (C.38)  \nsince there are \u00e3 n \nk \u00e4 \nways to pick which k of the n trials are successes, and the \nprobability that each occurs is p k q n\ue002k . A probability  distribution  satisfying  equa-  \ntion  (C.38)  is said  to be a binomial  distribution. For  convenience,  we  de\u00fbne  the  \nfamily of binomial distributions using the notation  \nb.kI n;p/  D \ue001 \nn \nk ! \np k .1 \ue003 p/  n\ue002k : (C.39)  \nFigure C.2 illustrates a binomial distribution. The  name <binomial= comes from the \nright-hand  side  of equation  (C.38)  being  the  kth term of the expansion of .p  C q/ n . \nConsequently, since p C q D 1, equation  (C.4)  on  page  1181  gives  \nn X  \nkD0 b.kI n;p/  D 1;  (C.40)  \nas axiom 2 of the probability axioms requires. \nWe can compute the expectation of a random variable  having a binomial  distri-  \nbution  from  equations  (C.9)  and  (C.40).  Let  X be a random variable that follows \nthe binomial distribution b.kI n;p/ , and let q D 1 \ue003 p. The  de\u00fbnition  of expecta-  \ntion gives C.4  The  geometric  and  binomial  distributions  1199 \n0.05  0.10  0.15  0.20 0.25  \nk 0 1 2 3 4 5 6 7 8 9 10  11  12  13  14  15  b (k; 15,  1/3)  \nFigure  C.2  The binomial distribution b.kI 15;1=3/  resulting from n D 15  Bernoulli trials, each \nwith probability p D 1=3  of success. The expectation of the distribution is np  D 5. \nE \u0152X\ufffd  D n X  \nkD0 k \ue001 Pr fX D kg \nD n X  \nkD0 k \ue001 b.kI n;p/  \nD n X  \nkD1 k \ue001 \nn \nk ! \np k q n\ue002k \nD np  n X  \nkD1 \ue001 \nn \ue003 1 \nk \ue003 1 ! \np k\ue0021 q n\ue002k (by  equation  (C.9)  on  page  1183)  \nD np  n\ue0021 X  \nkD0 \ue001 \nn \ue003 1 \nk ! \np k q .n\ue0021/\ue002k \nD np  n\ue0021 X  \nkD0 b.kI n \ue003 1;p/  \nD np  (by  equation  (C.40))  . (C.41)  \nLinearity of expectation produces the same result w ith substantially less algebra. \nLet X i be the random variable describing the number of suc cesses in the i th trial. \nThen E \u0152X  i \ufffd D p \ue001 1 C q \ue001 0 D p, and the expected number of successes for n trials \nis 1200  Appendix  C Counting  and  Probability  \nE \u0152X\ufffd  D E \" n X  \ni D1 X i # \nD n X  \ni D1 E \u0152X  i \ufffd (by  equation  (C.24)  on  page  1192)  \nD n X  \ni D1 p \nD np  : (C.42)  \nWe can use the same approach to calculate the varia nce of the distribution. By \nequation  (C.31),  Var  \u0152X  i \ufffd D E \u0152X  2 \ni \ufffd \ue003 E 2 \u0152X  i \ufffd. Since X i takes on only the values 0 \nand 1, we have X 2 \ni D X i , which implies E \u0152X  2 \ni \ufffd D E \u0152X  i \ufffd D p. Hence, \nVar \u0152X  i \ufffd D p \ue003 p 2 D p.1  \ue003 p/  D pq:  (C.43)  \nTo compute the variance of X , we take advantage of the independence of the n \ntrials.  By  equation  (C.33),  we  have  \nVar \u0152X\ufffd  D Var \" n X  \ni D1 X i # \nD n X  \ni D1 Var \u0152X  i \ufffd \nD n X  \ni D1 pq  \nD npq:  (C.44)  \nAs Figure C.2 shows, the binomial distribution b.kI n;p/  increases with k until \nit reaches the mean np, and then it decreases. To prove that the distribu tion always \nbehaves in this manner, examine the ratio of succes sive terms: \nb.kI n;p/  \nb.k  \ue003 1I n;p/  D \u00e3 n \nk \u00e4 \np k q n\ue002k \n\u00e3 n \nk\ue0021 \u00e4 \np k\ue0021 q n\ue002kC1 \nD n\u0160.k  \ue003 1/\u0160.n  \ue003 k C 1/\u0160p  \nk\u0160.n  \ue003 k/\u0160n\u0160q  \nD .n \ue003 k C 1/p  \nkq  (C.45)  \nD 1 C .n \ue003 k C 1/p  \ue003 kq  \nkq  \nD 1 C .n \ue003 k C 1/p  \ue003 k.1  \ue003 p/  \nkq  C.4  The  geometric  and  binomial  distributions  1201 \nD 1 C .n C 1/p  \ue003 k \nkq  : \nThis ratio is greater than 1 precisely when .n C 1/p  \ue003 k is positive. Consequently, \nb.kI n;p/  > b.k  \ue003 1I n;p/  for k < .n C 1/p  (the distribution increases), and \nb.kI n;p/  < b.k  \ue003 1I n;p/  for k > .n C 1/p  (the distribution decreases). If \n.n C 1/p  is an integer, then for k D .n C 1/p, the ratio b.kI n;p/=b.k  \ue003 1I n;p/  \nequals 1, so that b.kI n;p/  D b.k  \ue003 1I n;p/ . In this case, the distribution has two \nmaxima: at k D .nC1/p  and at k \ue0031 D .nC1/p\ue0031 D np\ue003q. Otherwise,  it attains  \na maximum at the unique integer k that lies in the range np  \ue003 q<k<.n  C 1/p. \nThe following lemma provides an upper bound on the binomial distribution. \nLemma  C.1  \nLet n \ue004 0, let 0<p<1 , let q D 1 \ue003 p, and let 0 \u0dc4 k \u0dc4 n. Then \nb.kI n;p/  \u0dc4 \ue002 np  \nk \u00cd k \ue002 nq  \nn \ue003 k \u00cd n\ue002k \n: \nProof  We have \nb.kI n;p/  D \ue001 \nn \nk ! \np k q n\ue002k \n\u0dc4 \ue002 n \nk \u00cd k \ue002 n \nn \ue003 k \u00cd n\ue002k \np k q n\ue002k (by  inequality  (C.7)  on  page  1182)  \nD \ue002 np  \nk \u00cd k \ue002 nq  \nn \ue003 k \u00cd n\ue002k \n: \nExercises  \nC.4-1  \nVerify axiom 2 of the probability axioms for the ge ometric distribution. \nC.4-2  \nHow  many  times  on  average  do  you  need  to \u00fcip  six  fair  coins  before obtaining \nthree  heads  and  three  tails?  \nC.4-3  \nShow that the variance of the geometric distributio n is q=p  2 . (Hint: Use  Exer-  \ncise  A.1-6  on  page  1144.)  \nC.4-4  \nShow that b.kI n;p/  D b.n  \ue003 kI n;q/ , where q D 1 \ue003 p. 1202  Appendix  C Counting  and  Probability  \nC.4-5  \nShow that the value of the maximum of the binomial distribution b.kI n;p/  is \napproximately 1=  p 2\ufffdnpq  , where q D 1 \ue003 p. \n? C.4-6  \nShow that the probability of no successes in n Bernoulli trials, each with probability \np D 1=n  of success, is approximately 1=e. Show that the probability of exactly \none success is also approximately 1=e. \n? C.4-7  \nProfessor  Rosencrantz  \u00fcips  a fair  coin  n times,  and  so does  Professor  Guildenstern.  \nShow that the probability that they get the same nu mber of heads is \u00e3 2n  \nn \u00e4 \n=4  n . (Hint: \nFor Professor Rosencrantz, call a head a success, a nd for Professor  Guildenstern,  \ncall a tail a success.) Use your argument to verify  the identity \nn X  \nkD0 \ue001 \nn \nk ! 2 \nD \ue001 \n2n  \nn ! \n: \n? C.4-8  \nShow that for 0 \u0dc4 k \u0dc4 n, \nb.kI n;1=2/  \u0dc4 2 n H.k=n/ \ue002n ; \nwhere H.x/  is the  entropy  function  (C.8)  on  page  1182.  \n? C.4-9  \nConsider n Bernoulli trials, where for i D 1;2;:::;n , the i th trial  has  probabil-  \nity p i of success, and let X be the random variable denoting the total number of  \nsuccesses. Let p \ue004 p i for all i D 1;2;:::;n . Prove that for 1 \u0dc4 k \u0dc4 n, \nPr fX<k g \ue004  k\ue0021 X  \ni D0 b.i  I n;p/:  \n? C.4-10  \nLet X be the random variable for the total number of succ esses in a set A of n \nBernoulli trials, where the i th trial has a probability p i of success, and let X 0 \nbe the random variable for the total number of succ esses in a second set A 0 of n \nBernoulli trials, where the i th trial has a probability p 0 \ni \ue004 p i of success. Prove that \nfor 0 \u0dc4 k \u0dc4 n, \nPr fX 0 \ue004 kg \ue004  Pr fX \ue004 kg : \n(Hint: Show how to obtain the Bernoulli trials in A 0 by an experiment involving \nthe trials of A, and  use  the  result  of Exercise  C.3-7.)  C.5  The  tails  of the  binomial  distribution  1203 \n? C.5  The  tails  of the  binomial  distribution  \nThe probability of having at least, or at most, k successes in n Bernoulli trials, \neach with probability p of success, is often of more interest than the prob ability of \nhaving exactly k successes. In this section, we investigate the tails  of the binomial \ndistribution: the two regions of the distribution b.kI n;p/  that are far from the \nmean np. We\u2019ll  prove  several  important  bounds  on  (the  sum  of all  term s in) a tail. \nWe  \u00fbrst  provide  a bound  on  the  right  tail  of the  distribution  b.kI n;p/. To  deter-  \nmine bounds on the left tail, simply invert the rol es of successes and failures. \nTheorem  C.2  \nConsider a sequence of n Bernoulli trials, where success occurs with probabi lity p. \nLet X be the random variable denoting the total number of  successes. Then for \n0 \u0dc4 k \u0dc4 n, the probability of at least k successes is \nPr fX \ue004 kg D  n X  \ni Dk b.i  I n;p/  \n\u0dc4 \ue001 \nn \nk ! \np k : \nProof  For S \u0dc2 f1;2;:::;n g, let A S denote the event that the i th trial is a success \nfor every i 2 S . Since Pr fA S g D  p k , where jS j D  k, we have \nPr fX \ue004 kg D  Pr fthere exists S \u0dc2 f1;2;:::;n g W jS j D  k and A S g \nD Pr \u00ef [  \nS\u0dc2f1;2;:::;n gWjSjDk A S \u00f0 \n\u0dc4 X  \nS\u0dc2f1;2;:::;n gWjSjDk Pr fA S g (by  inequality  (C.21)  on  page  1190)  \nD \ue001 \nn \nk ! \np k : \nThe following corollary restates the theorem for th e left tail of the binomial \ndistribution.  In general,  we\u2019ll  leave  it to you  to adapt  the  proofs from one tail to \nthe other. \nCorollary  C.3  \nConsider a sequence of n Bernoulli  trials,  where  success  occurs  with  probabil-  \nity p. If X is the random variable denoting the total number of  successes, then for \n0 \u0dc4 k \u0dc4 n, the probability of at most k successes is 1204  Appendix  C Counting  and  Probability  \nPr fX \u0dc4 kg D  k X  \ni D0 b.i  I n;p/  \n\u0dc4 \ue001 \nn \nn \ue003 k ! \n.1 \ue003 p/  n\ue002k \nD \ue001 \nn \nk ! \n.1 \ue003 p/  n\ue002k : \nOur  next  bound  concerns  the  left  tail  of the  binomial  distrib ution. Its corollary \nshows that, far from the mean, the left tail dimini shes exponentially. \nTheorem  C.4  \nConsider a sequence of n Bernoulli trials, where success occurs with probabi lity p \nand failure with probability q D 1 \ue003 p. Let X be the random variable denoting the \ntotal number of successes. Then for 0 < k < np , the probability of fewer than k \nsuccesses is \nPr fX<k g D  k\ue0021 X  \ni D0 b.i  I n;p/  \n< kq  \nnp  \ue003 k b.kI n;p/:  \nProof  We bound the series P  k\ue0021 \ni D0 b.i  I n;p/  by  a geometric  series  using  the  tech-  \nnique  from  Section  A.2,  page  1147.  For  i D 1;2;:::;k, equation  (C.45)  gives  \nb.i  \ue003 1I n;p/  \nb.i  I n;p/  D iq \n.n \ue003 i C 1/p  \n< iq \n.n \ue003 i/p  \n\u0dc4 kq  \n.n \ue003 k/p  : \nIf we let \nx D kq  \n.n \ue003 k/p  \n< kq  \n.n \ue003 np/p  \nD kq  \nnqp  C.5  The  tails  of the  binomial  distribution  1205 \nD k \nnp  \n< 1;  \nit follows that \nb.i  \ue003 1I n;p/<xb.i  I n;p/  \nfor 0<i  \u0dc4 k. Iteratively applying this inequality k \ue003 i times gives \nb.i  I n;p/<x  k\ue002i b.kI n;p/  \nfor 0 \u0dc4 i<k , and hence \nk\ue0021 X  \ni D0 b.i  I n;p/  < k\ue0021 X  \ni D0 x k\ue002i b.kI n;p/  \n< b.kI n;p/  1  X  \ni D1 x i \nD x \n1 \ue003 x b.kI n;p/  \nD kq=..n  \ue003 k/p/  \n..n  \ue003 k/p  \ue003 kq/=..n  \ue003 k/p/  b.kI n;p/  \nD kq  \nnp  \ue003 kp  \ue003 kq  b.kI n;p/  \nD kq  \nnp  \ue003 k b.kI n;p/:  \nCorollary  C.5  \nConsider a sequence of n Bernoulli trials, where success occurs with probabi lity p \nand failure with probability q D 1 \ue003 p. Then for 0<k  \u0dc4 np=2 , the probability \nof fewer than k successes is less than half the probability of fewe r than k C 1 \nsuccesses. \nProof  Because k \u0dc4 np=2 , we have \nkq  \nnp  \ue003 k \u0dc4 .np=2/q  \nnp  \ue003 .np=2/  \nD .np=2/q  \nnp=2  \n\u0dc4 1;  (C.46)  \nsince q \u0dc4 1. Letting X be the random variable denoting the number of succe sses, \nTheorem  C.4  and  inequality  (C.46)  imply  that  the  probabilit y of fewer than k suc-  \ncesses is 1206  Appendix  C Counting  and  Probability  \nPr fX<k g D  k\ue0021 X  \ni D0 b.i  I n;p/<b.k I n;p/:  \nThus we have \nPr fX<k g \nPr fX<k  C 1g D P  k\ue0021 \ni D0 b.i  I n;p/  \nP  k \ni D0 b.i  I n;p/  \nD P  k\ue0021 \ni D0 b.i  I n;p/  \nP  k\ue0021 \ni D0 b.i  I n;p/  C b.kI n;p/  \n< 1=2  ; \nsince P  k\ue0021 \ni D0 b.i  I n;p/<b.k I n;p/ . \nBounds  on  the  right  tail  follow  similarly.  Exercise  C.5-2  asks you to prove them. \nCorollary  C.6  \nConsider a sequence of n Bernoulli trials, where success occurs with probabi lity p. \nLet X be the random variable denoting the total number of  successes. Then for \nnp<k<n , the probability of more than k successes is \nPr fX>k g D  n X  \ni DkC1 b.i  I n;p/  \n< .n \ue003 k/p  \nk \ue003 np  b.kI n;p/:  \nCorollary  C.7  \nConsider a sequence of n Bernoulli trials, where success occurs with probabi lity p \nand failure with probability q D 1 \ue003 p. Then for .np  C n/=2  < k < n , the \nprobability of more than k successes is less than half the probability of more  than \nk \ue003 1 successes. \nThe next theorem considers n Bernoulli trials, each with a probability p i of \nsuccess, for i D 1;2;:::;n . As the subsequent corollary shows, we can use the  \ntheorem to provide a bound on the right tail of the  binomial distribution by setting \np i D p for each trial. \nTheorem  C.8  \nConsider a sequence of n Bernoulli trials, where in the i th trial, for i D 1;2;:::;n , \nsuccess occurs with probability p i and failure occurs with probability q i D 1 \ue003 p i . \nLet X be the random variable describing the total number of successes, and let \n\ufffd D E \u0152X\ufffd. Then for r > \ufffd , C.5  The  tails  of the  binomial  distribution  1207 \nPr fX \ue003 \ufffd \ue004 r g \u0dc4  \ue002 \ufffde  \nr \u00cd r \n: \nProof  Since for any \u02db>0 , the function e \u02dbx  strictly increases in x , \nPr fX \ue003 \ufffd \ue004 r g D  Pr \u02da \ne \u02db.X\ue002\u00e7/  \ue004 e \u02dbr  \ue009 \n; (C.47)  \nwhere we will determine \u02db later.  Using  Markov\u2019s  inequality  (C.34),  we  obtain  \nPr \u02da \ne \u02db.X\ue002\u00e7/  \ue004 e \u02dbr  \ue009 \n\u0dc4 E \u00ed \ne \u02db.X\ue002\u00e7/  \u00ee \ne \ue002\u02dbr  : (C.48)  \nThe bulk of the proof consists of bounding E \u00ed \ne \u02db.X\ue002\u00e7/  \u00ee \nand  substituting  a suit-  \nable value for \u02db in inequality  (C.48).  First,  we  evaluate  E \u00ed e \u02db.X\ue002\u00e7/  \u00ee . Using the \ntechnique  of indicator  random  variables  (see  Section  5.2),  let X i D I f the i th \nBernoulli trial is a success g for i D 1;2;:::;n . That is, X i is the  random  vari-  \nable that is 1 if the i th Bernoulli trial is a success and 0 if it is a failure. Thus, we \nhave \nX D n X  \ni D1 X i ; \nand by linearity of expectation, \n\ufffd D E \u0152X\ufffd  D E \" n X  \ni D1 X i # \nD n X  \ni D1 E \u0152X  i \ufffd D n X  \ni D1 p i ; \nwhich implies \nX \ue003 \ufffd D n X  \ni D1 .X  i \ue003 p i /: \nTo evaluate E \u00ed \ne \u02db.X\ue002\u00e7/  \u00ee \n, we substitute for X \ue003 \ufffd, obtaining \nE \u00ed \ne \u02db.X\ue002\u00e7/  \u00ee \nD E \u00ed \ne \u02db P  n \ni D1 .X  i \ue002p i / \u00ee \nD E \" n Y  \ni D1 e \u02db.X  i \ue002p i / # \nD n Y  \ni D1 E \u00ed \ne \u02db.X  i \ue002p i / \u00ee \n; \nwhich  follows  from  equation  (C.27),  since  the  mutual  indepe ndence of the random \nvariables X i implies the mutual independence of the random varia bles e \u02db.X  i \ue002p i / \n(see  Exercise  C.3-5).  By  the  de\u00fbnition  of expectation,  1208  Appendix  C Counting  and  Probability  \nE \u00ed \ne \u02db.X  i \ue002p i / \u00ee \nD e \u02db.1\ue002p i / p i C e \u02db.0\ue002p i / q i \nD p i e \u02dbq  i C q i e \ue002\u02dbp  i \n\u0dc4 p i e \u02db C 1 (C.49)  \n\u0dc4 exp.p  i e \u02db /; \nwhere exp.x/  denotes the exponential function: exp .x/  D e x . (Inequality  (C.49)  \nfollows from the inequalities \u02db >0 , q i \u0dc4 1, e \u02dbq  i \u0dc4 e \u02db , and e \ue002\u02dbp  i \u0dc4 1. The last \nline  follows  from  inequality  (3.14)  on  page  66.)  Consequent ly, \nE \u00ed \ne \u02db.X\ue002\u00e7/  \u00ee \nD n Y  \ni D1 E \u00ed \ne \u02db.X  i \ue002p i / \u00ee \n\u0dc4 n Y  \ni D1 exp.p  i e \u02db / \nD exp \ue001 n X  \ni D1 p i e \u02db ! \nD exp.\ufffde  \u02db /; (C.50)  \nsince \ufffd D P  n \ni D1 p i . Therefore,  from  equation  (C.47)  and  inequalities  (C.48)  \nand  (C.50),  it follows  that  \nPr fX \ue003 \ufffd \ue004 r g \u0dc4  exp.\ufffde  \u02db \ue003 \u02dbr/:  (C.51)  \nChoosing \u02db D ln.r=\ufffd/  (see  Exercise  C.5-7),  we  obtain  \nPr fX \ue003 \ufffd \ue004 r g \u0dc4  exp.\ufffde  ln.r=\u00e7/  \ue003 r ln.r=\ufffd//  \nD exp.r \ue003 r ln.r=\ufffd//  \nD e r \n.r=\ufffd/  r \nD \ue002 \ufffde  \nr \u00cd r \n: \nWhen applied to Bernoulli trials in which each tria l has the same probability of \nsuccess,  Theorem  C.8  yields  the  following  corollary  boundi ng the right tail of a \nbinomial distribution. \nCorollary  C.9  \nConsider a sequence of n Bernoulli trials, where in each trial success occur s with \nprobability p and failure occurs with probability q D 1 \ue003 p. Then for r > np , C.5  The  tails  of the  binomial  distribution  1209 \nPr fX \ue003 np  \ue004 r g D  n X  \nkDdnpCr e b.kI n;p/  \n\u0dc4 \ue002 npe  \nr \u00cd r \n: \nProof  By  equation  (C.41),  we  have  \ufffd D E \u0152X\ufffd  D np. \nExercises  \n? C.5-1  \nWhich is more likely: getting exactly n heads in 2n  \u00fcips  of a fair  coin,  or n heads \nin n \u00fcips  of a fair  coin?  \n? C.5-2  \nProve  Corollaries  C.6  and  C.7.  \n? C.5-3  \nShow that \nk\ue0021 X  \ni D0 \ue001 \nn \ni ! \na i <.a  C 1/ n k \nna  \ue003 k.a  C 1/ b.kI n;a=.a  C 1//  \nfor all a>0  and all k such that 0<k<na=.a  C 1/. \n? C.5-4  \nProve that if 0<k<np , where 0<p<1  and q D 1 \ue003 p, then \nk\ue0021 X  \ni D0 p i q n\ue002i < kq  \nnp  \ue003 k \ue002 np  \nk \u00cd k \ue002 nq  \nn \ue003 k \u00cd n\ue002k \n: \n? C.5-5  \nUse  Theorem  C.8  to show  that  \nPr f\ufffd \ue003 X \ue004 r g \u0dc4  \u00ce .n \ue003 \ufffd/e  \nr \u00cf r \nfor r >n  \ue003 \ufffd. Similarly, use Corollary C.9 to show that \nPr fnp  \ue003 X \ue004 r g \u0dc4  \ue002 nqe  \nr \u00cd r \nfor r >n  \ue003 np. 1210  Appendix  C Counting  and  Probability  \n? C.5-6  \nConsider a sequence of n Bernoulli trials, where in the i th trial, for i D 1;2;:::;n , \nsuccess occurs with probability p i and failure occurs with probability q i D 1 \ue003 p i . \nLet X be the random variable describing the total number of successes, and let \n\ufffd D E \u0152X\ufffd. Show that for r \ue004 0, \nPr fX \ue003 \ufffd \ue004 r g \u0dc4  e \ue002r 2 =2n  : \n(Hint: Prove that p i e \u02dbq  i C q i e \ue002\u02dbp  i \u0dc4 e \u02db 2 =2  . Then follow the outline of the proof \nof Theorem  C.8,  using  this  inequality  in place  of inequality  (C.49).)  \n? C.5-7  \nShow that choosing \u02db D ln.r=\ufffd/  minimizes  the  right-hand  side  of inequal-  \nity  (C.51).  \nProblems  \nC-1  The  Monty  Hall  problem  \nImagine  that  you  are  a contestant  in the  1960s  game  show  Let\u2019s Make a Deal , \nhosted by emcee Monty Hall. A valuable prize is hid den behind one of three doors \nand comparatively worthless prizes behind the other  two doors. You will win the \nvaluable prize, typically an automobile or other ex pensive product, if you select the \ncorrect door. After you have picked one door, but b efore the door has been opened, \nMonty, who knows which door hides the automobile, d irects his assistant Carol \nMerrill to open one of the other doors, revealing a  goat (not a valuable prize). He \nasks whether you would like to stick with your curr ent choice or to switch to the \nother closed door. What should you do to maximize y our chances of winning the \nautomobile  and  not  the  other  goat?  \nThe  answer  to this  question4stick  or switch?4has  been  heavi ly debated, in part \nbecause  the  problem  setup  is ambiguous.  We\u2019ll  explore  different  subtle  assump-  \ntions. \na. Suppose  that  your  \u00fbrst  pick  is random,  with  probability  1=3  of choosing the \nright door. Moreover, you know that Monty always gi ves every contestant (and \nwill give you) the opportunity to switch. Prove tha t it is better to switch than \nstick.  What  is your  probability  of winning  the  automobile?  \nThis answer is the one typically given, even though  the original statement of the \nproblem rarely mentions the assumption that Monty always  offers the contestant \nthe opportunity to switch. But, as the remainder of  this problem will elucidate, \nyour best strategy may be different if this unstate d assumption does not hold. In Problems for Appendix C 1211 \nfact, in the real game show, after a contestant pic ked a door, Monty sometimes \nsimply asked Carol to open the door that the contes tant had chosen. \nLet\u2019s  model  the  interactions  between  you  and  Monty  as a probabilistic  experi-  \nment,  where  you  both  employ  randomized  strategies.  Speci\u00fbc ally, after you pick \na door, Monty offers you the opportunity to switch with probability p right if you \npicked the right door and with probability p wrong if you picked the wrong door. \nGiven  the  opportunity  to switch,  you  randomly  choose  to switch  with  probabil-  \nity p switch . For example, if Monty always offers you the oppor tunity to switch, then \nhis strategy is given by p right D p wrong D 1. If you always switch, then your strategy \nis given by p switch D 1. \nThe  game  can  now  be viewed  as an experiment  consisting  of \u00fbve  steps: \n1. You  pick  a door  at random,  choosing  the  automobile  (right)  with probability \n1=3  or a goat (wrong) with probability 2=3. \n2. Carol opens one of the two closed doors, reveali ng a goat. \n3. Monty  offers  you  the  opportunity  to switch  with  probabili ty p right if your choice \nis right and with probability p wrong if your choice is wrong. \n4. If Monty  makes  you  an offer  in step  3, you  switch  with  probab ility p switch . \n5. Carol  opens  the  door  you\u2019ve  chosen,  revealing  either  an automobile (you win) \nor a goat (you lose). \nLet\u2019s  now  analyze  this  game  and  understand  how  the  choices  of p right , p wrong , and \np switch in\u00fcuence  the  probability  of winning.  \nb. What  are  the  six  outcomes  in the  sample  space  for  this  game?  Which outcomes \ncorrespond  to you  winning  the  automobile?  What  are  the  proba bilities in terms \nof p right , p wrong , and p switch of each  outcome?  Organize  your  answers  into  a table.  \nc. Use the results of your table (or other means) to p rove that the probability of \nwinning the automobile is \n1 \n3 .2p  wrong p switch \ue003 p right p switch C 1/:  \nSuppose that Monty knows the probability p switch that you switch, and his goal is \nto minimize your chance of winning. \nd. If p switch > 0  (you  switch  with  a positive  probability),  what  is Monty\u2019s  best \nstrategy, that is, his best choice for p right and p wrong ? \ne. If p switch D 0 (you  always  stick),  argue  that  all  of Monty\u2019s  possible  strategies \nare optimal for him. 1212  Appendix  C Counting  and  Probability  \nSuppose  that  now  Monty\u2019s  strategy  is \u00fbxed,  with  particular  values for p right and \np wrong . \nf. If you know p right and p wrong , what  is your  best  strategy  for  choosing  your  prob-  \nability p switch of switching as a function of p right and p wrong ? \ng. If you  don\u2019t  know  p right and p wrong , what choice of p switch maximizes  the  mini-  \nmum probability of winning over all the choices of p right and p wrong ? \nLet\u2019s  return  to the  original  problem  as stated,  where  Monty  has given you the \noption  of switching,  but  you  have  no  knowledge  of Monty\u2019s  possible motivations \nor strategies. \nh. Argue that the conditional probability of winning t he automobile given that \nMonty offers you the opportunity to switch is \np right \ue003 p right p switch C 2p  wrong p switch \np right C 2p  wrong : (C.52)  \nExplain why p right C 2p  wrong \u00a4 0. \ni. What  is the  value  of expression  (C.52)  when  p switch D 1=2? Show  that  choosing  \np switch <1=2  or p switch >1=2  allows Monty to select values for p right and p wrong \nthat  yield  a lower  value  for  expression  (C.52)  than  choosing  p switch D 1=2. \nj. Suppose  that  you  don\u2019t  know  Monty\u2019s  strategy.  Explain  why  choosing to switch \nwith probability 1=2  is a good  strategy  for  the  original  problem  as stated.  Sum-  \nmarize what you have learned overall from this prob lem. \nC-2  Balls  and  bins  \nThis problem investigates the effect of various ass umptions on the number of ways \nof placing n balls into b distinct bins. \na. Suppose that the n balls are distinct and that their order within a bi n does not \nmatter. Argue that the number of ways of placing th e balls in the bins is b n . \nb. Suppose that the balls are distinct and that the ba lls in each bin are ordered. \nProve that there are exactly .b C n \ue003 1/\u0160=.b  \ue003 1/\u0160  ways to place the balls in \nthe bins. ( Hint: Consider the number of ways of arranging n distinct balls and \nb \ue003 1 indistinguishable sticks in a row.) \nc. Suppose that the balls are identical, and hence the ir order within a bin does not \nmatter. Show that the number of ways of placing the  balls in the bins is \u00e3 bCn\ue0021 \nn \u00e4 \n. \n(Hint: Of  the  arrangements  in part  (b),  how  many  are  repeated  if the  balls are \nmade  identical?)  Notes for Appendix C 1213 \nd. Suppose that the balls are identical and that no bi n may contain more than one \nball, so that n \u0dc4 b. Show that the number of ways of placing the balls  is \u00e3 b \nn \u00e4 \n. \ne. Suppose that the balls are identical and that no bi n may be left empty. Assuming \nthat n \ue004 b, show that the number of ways of placing the balls  is \u00e3 n\ue0021 \nb\ue0021 \u00e4 . \nAppendix  notes  \nThe  \u00fbrst  general  methods  for  solving  probability  problems  were discussed in a \nfamous correspondence between B. Pascal and P. de F ermat, which  began  in 1654,  \nand  in a book  by  C. Huygens  in 1657.  Rigorous  probability  theory began with the \nwork  of J. Bernoulli  in 1713  and  A.  De  Moivre  in 1730.  Further  developments of \nthe  theory  were  provided  by  P.-S.  Laplace,  S.-D.  Poisson,  and  C. F. Gauss.  \nSums of random variables were originally studied by  P. L. Chebyshev and A. A. \nMarkov.  A.  N.  Kolmogorov  axiomatized  probability  theory  in 1933.  Chernoff  [91]  \nand Hoeffding [222] provided bounds on the tails of  distributions. Seminal work \nin random  combinatorial  structures  was  done  by  P. Erd\u02dd  os.  \nKnuth  [259]  and  Liu  [302]  are  good  references  for  elementary  combinatorics and \ncounting.  Standard  textbooks  such  as Billingsley  [56],  Chung  [93],  Drake  [125],  \nFeller  [139],  and  Rozanov  [390]  offer  comprehensive  introd uctions to probability. D Matrices  \nMatrices arise in numerous applications, including,  but by no means limited to, \nscienti\u00fbc  computing.  If you  have  seen  matrices  before,  much  of the material in this \nappendix will be familiar to you, but some of it mi ght be new. S ection  D.1  covers  \nbasic  matrix  de\u00fbnitions  and  operations,  and  Section  D.2  presents some basic matrix \nproperties. \nD.1  Matrices  and  matrix  operations  \nThis section reviews some basic concepts of matrix theory and some fundamental \nproperties of matrices. \nMatrices  and  vectors  \nA matrix  is a rectangular array of numbers. For example, \nA D \u00ce a 11  a 12  a 13  \na 21  a 22  a 23  \u00cf \nD \u00ce 1 2 3  \n4 5 6  \u00cf \n(D.1)  \nis a 2 \ue005 3 matrix A D .a ij /, where for i D 1;2  and j D 1;2;3 , the element \nof the matrix in row i and column j is denoted by a ij . By convention, uppercase \nletters denote matrices and corresponding subscript ed lowercase letters denote their \nelements. We denote the set of all m \ue005 n matrices  with  real-valued  entries  by  R m\ue005n \nand, in general, the set of m \ue005 n matrices with entries drawn from a set S by S m\ue005n . \nThe transpose  of a matrix A is the matrix A T obtained by exchanging the rows \nand columns of A. For the matrix A of equation  (D.1),  D.1  Matrices  and  matrix  operations  1215 \nA T D \u00e3 \n1 4  \n2 5  \n3 6  \u00e4 \n: \nA vector  is a one-dimensional  array  of numbers.  For  example,  \nx D \u00e3 \n2 \n3 \n5 \u00e4 \nis a vector of size 3. We sometimes call a vector of length n an n-vector. By  con-  \nvention, lowercase letters denote vectors, and the i th element  of a size-n vector x \nis denoted by x i , for i D 1;2;:::;n . We take the standard form of a vector to be \nas a column  vector  equivalent to an n \ue005 1 matrix, whereas the corresponding row  \nvector  is obtained by taking the transpose: \nx T D .2  3 5/:  \nThe unit  vector  e i is the vector whose i th element is 1 and all of whose other \nelements are 0. Usually, the context makes the size of a unit vec tor clear. \nA zero  matrix  is a matrix all of whose entries are 0. Such a matrix is often \ndenoted 0, since the ambiguity between the number 0 and a matrix of 0s can usually \nbe resolved from context. If a matrix of 0s is intended, then the size of the matrix \nalso needs to be derived from the context. \nSquare  matrices  \nSquare  n \ue005 n matrices arise frequently. Several special cases of  square matrices \nare of particular interest: \n1. A diagonal  matrix  has a ij D 0 whenever i \u00a4 j . Because  all  of the  off-diagonal  \nelements are 0, a succinct way to specify the matrix lists only t he elements along \nthe diagonal: \ndiag.a 11  ;a  22  ;:::;a  nn  / D \u02d9 \na 11  0 :::  0 \n0 a  22  :::  0 \n: : : : : : : : : : : : \n0 0 :::  a nn  \ue005 \n: \n2. The n \ue005 n identity  matrix  I n is a diagonal matrix with 1s along the diagonal: \nI n D diag.1;1;:::;1/  \nD \u02d9 \n1 0 :::  0 \n0 1 :::  0 \n: : : : : : : : : : : : \n0 0 :::  1 \ue005 \n: 1216  Appendix  D Matrices  \nWhen I appears without a subscript, its size derives from the context. The i th \ncolumn of an identity matrix is the unit vector e i . \n3. A tridiagonal  matrix  T is one for which t ij D 0 if ji \ue003 j j >1. Nonzero entries \nappear only on the main diagonal, immediately above  the main diagonal ( t i;i  C1 \nfor i D 1;2;:::;n  \ue003 1), or immediately below the main diagonal ( t i C1;i  for \ni D 1;2;:::;n  \ue003 1): \nT D \ue001 \nt 11  t 12  0 0 :::  0 0 0 \nt 21  t 22  t 23  0 :::  0 0 0 \n0 t  32  t 33  t 34  :::  0 0 0 \n: : : : : : : : : : : : : : : : : : : : : : : : \n0 0 0 0 :::  t n\ue0022;n\ue0022 t n\ue0022;n\ue0021 0 \n0 0 0 0 :::  t n\ue0021;n\ue0022 t n\ue0021;n\ue0021 t n\ue0021;n  \n0 0 0 0 :::  0 t n;n\ue0021 t nn  \u02d8 \n: \n4. An  upper-triangular  matrix  U is one for which u ij D 0 if i >j  . All entries \nbelow the diagonal are 0: \nU D \u02d9 \nu 11  u 12  :::  u 1n  \n0 u  22  :::  u 2n  \n: : : : : : : : : : : : \n0 0 :::  u nn  \ue005 \n: \nAn  upper-triangular  matrix  is unit  upper-triangular  if it has all 1s along the \ndiagonal. \n5. A lower-triangular  matrix  L is one for which l ij D 0 if i < j  . All entries \nabove the diagonal are 0: \nL D \u02d9 \nl 11  0 :::  0 \nl 21  l 22  :::  0 \n: : : : : : : : : : : : \nl n1  l n2  :::  l nn  \ue005 \n: \nA lower-triangular  matrix  is unit  lower-triangular  if it has all 1s along the \ndiagonal. D.1  Matrices  and  matrix  operations  1217 \n6. A permutation  matrix  P has exactly one 1 in each row or column, and 0s \nelsewhere. An example of a permutation matrix is \nP D \u02c7 \n0 1 0 0 0  \n0 0 0 1 0  \n1 0 0 0 0  \n0 0 0 0 1  \n0 0 1 0 0  \ue002 \n: \nSuch a matrix is called a permutation matrix becaus e multiplying a vector x \nby a permutation matrix has the effect of permuting  (rearranging) the elements \nof x . Exercise  D.1-4  explores  additional  properties  of permuta tion matrices. \n7. A symmetric  matrix  A satis\u00fbes  the  condition  A D A T . For example, \u00e3 \n1 2 3  \n2 6 4  \n3 4 5  \u00e4 \nis a symmetric matrix. \nBasic  matrix  operations  \nThe elements of a matrix or vector are scalar  numbers  from a number system, \nsuch as the real numbers, the complex numbers, or i ntegers modulo a prime. The \nnumber  system  de\u00fbnes  how  to add  and  multiply  scalars.  These  de\u00fbnitions  extend  \nto encompass addition and multiplication of matrice s. \nWe  de\u00fbne  matrix  addition  as follows. If A D .a ij / and B D .b ij / are m \ue005 n \nmatrices, then their matrix sum C D .c ij / D A C B is the m \ue005 n matrix  de\u00fbned  by  \nc ij D a ij C b ij \nfor i D 1;2;:::;m  and j D 1;2;:::;n . That is, matrix addition is performed \ncomponentwise. A zero matrix is the identity for ma trix addition: \nA C 0 D A D 0 C A:  \nIf \ufffd is a scalar number and A D .a ij / is a matrix, then \ufffdA  D .\ufffda  ij / is the scalar  \nmultiple  of A obtained by multiplying each of its elements by \ufffd. As a special case, \nwe  de\u00fbne  the  negative  of a matrix A D .a ij / to be \ue0031 \ue001 A D \ue003A, so that the ij th \nentry of \ue003A is \ue003a ij . Thus, \nA C .\ue003A/  D 0 D .\ue003A/  C A:  1218  Appendix  D Matrices  \nThe  negative  of a matrix  de\u00fbnes  matrix  subtraction : A \ue003 B D A C .\ue003B/. \nWe  de\u00fbne  matrix  multiplication  as follows. Start with two matrices A and B \nthat are compatible  in the sense that the number of columns of A equals the number \nof rows of B . (In general, an expression containing a matrix pr oduct AB  is always \nassumed to imply that matrices A and B are compatible.) If A D .a ik  / is a p \ue005 q \nmatrix and B D .b kj  / is a q \ue005 r matrix, then their matrix product C D AB  is the \np \ue005 r matrix C D .c ij /, where \nc ij D q X  \nkD1 a ik  b kj  (D.2) \nfor i D 1;2;:::;m  and j D 1;2;:::;p . The procedure R ECTANGULAR - \nMATRIX-MULTIPLY on  page  374  implements  matrix  multiplication  in the  straight-  \nforward manner based on equation (D.2), assuming th at C is initialized to 0, using \npqr  multiplications and p.q  \ue003 1/r  additions for a running time of \u201a.pqr/ . If the \nmatrices are n\ue005n square matrices, so that n D p D q D r , the pseudocode reduces \nto M ATRIX-MULTIPLY on  page  81,  whose  running  time  is \u201a.n  3 /. (Section  4.2  de-  \nscribes an asymptotically faster \u201a.n  lg 7 /-time  algorithm  due  to V. Strassen.)  \nMatrices have many (but not all) of the algebraic p roperties typical of numbers. \nIdentity matrices are identities for matrix multipl ication: \nI m A D AI  n D A \nfor any m \ue005 n matrix A. Multiplying by a zero matrix gives a zero matrix:  \nA \ue001 0 D 0:  \nMatrix multiplication is associative: \nA.BC/  D .AB/C  \nfor compatible matrices A, B , and C . Matrix  multiplication  distributes  over  addi-  \ntion: \nA.B  C C/  D AB  C AC  ; \n.B  C C/D  D BD  C CD:  \nFor n >1 , multiplication of n \ue005 n matrices is not commutative. For example, if \nA D \u00ce 0 1  \n0 0  \u00cf \nand B D \u00ce 0 0  \n1 0  \u00cf \n, then AB  D \u00ce 1 0  \n0 0  \u00cf \nand BA  D \u00ce 0 0  \n0 1  \u00cf \n. \nWe  de\u00fbne  matrix-vector  products  or vector-vector  products  as if the vector were \nthe equivalent n \ue005 1 matrix (or a 1 \ue005 n matrix, in the case of a row vector). Thus, if \nA is an m \ue005 n matrix and x is an n-vector,  then  Ax  is an m-vector.  If x and y are \nn-vectors,  then  D.2  Basic  matrix  properties  1219 \nx T y D n X  \ni D1 x i y i \nis a scalar number (actually a 1 \ue005 1 matrix) called the inner  product  of x and y . \nWe also use the notation hx;y  i to denote x T y . The  inner-product  operator  is com-  \nmutative: hx;y  i D hy;x  i. The matrix xy  T is an n \ue005 n matrix Z called the outer  \nproduct  of x and y , where \u00b4 ij D x i y j . The (euclidean)  norm  kx k of an n-vector  x \nis de\u00fbned  by  \nkx k D  .x 2 \n1 C x 2 \n2 C \ue001 \ue001 \ue001 C  x 2 \nn / 1=2  \nD .x T x/  1=2  : \nThus, the norm of x is its length in n-dimensional  euclidean  space.  A useful  fact,  \nwhich follows from the equality \n\u00e3 \n.ax  1 / 2 C .ax  2 / 2 C \ue001 \ue001 \ue001 C  .ax  n / 2 \u00e4 1=2  D jaj .x 2 \n1 C x 2 \n2 C \ue001 \ue001 \ue001 C  x 2 \nn / 1=2  \nis that for any real number a and n-vector  x , \nkax  k D jaj kx k : (D.3)  \nExercises  \nD.1-1  \nShow that if A and B are symmetric n \ue005 n matrices, then so are A C B and A \ue003 B . \nD.1-2  \nProve that .AB/  T D B T A T and that A T A is always a symmetric matrix. \nD.1-3  \nProve  that  the  product  of two  lower-triangular  matrices  is lower-triangular.  \nD.1-4  \nProve that if P is an n \ue005 n permutation matrix and A is an n \ue005 n matrix, then the \nmatrix product PA  is A with its rows permuted, and the matrix product AP  is A \nwith its columns permuted. Prove that the product o f two permutation matrices is \na permutation matrix. \nD.2  Basic  matrix  properties  \nWe  now  de\u00fbne  some  basic  properties  pertaining  to matrices:  inverses,  linear  de-  \npendence and independence, rank, and determinants. We also de\u00fbne  the  class  of \npositive-de\u00fbnite  matrices.  1220  Appendix  D Matrices  \nMatrix  inverses,  ranks,  and  determinants  \nThe inverse  of an n \ue005 n matrix A is the n \ue005 n matrix, denoted A \ue0021 (if it exists), \nsuch that AA  \ue0021 D I n D A \ue0021 A. For example, \n\u00ce 1 1  \n1 0  \u00cf \ue0021 \nD \u00ce 0 1  \n1 \ue0031 \u00cf \n: \nMany nonzero n \ue005 n matrices do not have inverses. A matrix without an inverse is \ncalled noninvertible , or singular . An example of a nonzero singular matrix is \n\u00ce 1 0  \n1 0  \u00cf \n: \nIf a matrix has an inverse, it is called invertible , or nonsingular . Matrix inverses, \nwhen  they  exist,  are  unique.  (See  Exercise  D.2-1.)  If A and B are nonsingular \nn \ue005 n matrices, then \n.BA/  \ue0021 D A \ue0021 B \ue0021 : \nThe inverse operation commutes with the transpose o peration: \n.A  \ue0021 / T D .A  T / \ue0021 : \nThe vectors x 1 ;x  2 ;:::;x  n are linearly  dependent  if there  exist  coef\u00fbcients  \nc 1 ;c 2 ;:::;c  n , not all of which are 0, such that c 1 x 1 C c 2 x 2 C \ue001 \ue001 \ue001 C  c n x n D 0. The \nrow vectors x 1 D .1  2 3/ , x 2 D .2  6 4/ , and x 3 D .4  11  9/  are  lin-  \nearly dependent, for example, since 2x  1 C3x  2 \ue0032x  3 D 0. If vectors are not linearly \ndependent, they are linearly  independent . For example, the columns of an identity \nmatrix are linearly independent. \nThe column  rank  of a nonzero m \ue005 n matrix A is the size of the largest set \nof linearly independent columns of A. Similarly, the row  rank  of A is the size \nof the largest set of linearly independent rows of A. A fundamental property of \nany matrix A is that its row rank always equals its column rank,  so that we can \nsimply refer to the rank  of A. The rank of an m \ue005 n matrix is an integer between 0 \nand min fm;ng, inclusive. (The rank of a zero matrix is 0, and the rank of an n \ue005 n \nidentity matrix is n.) An  alternate,  but  equivalent  and  often  more  useful,  de\u00fbni tion \nis that the rank of a nonzero m \ue005 n matrix A is the smallest number r such that there \nexist matrices B and C of respective sizes m \ue005 r and r \ue005 n such that A D BC  . \nA square n \ue005 n matrix has full  rank  if its rank is n. An m \ue005 n matrix has full  \ncolumn  rank  if its rank is n. The following theorem gives a fundamental propert y \nof ranks. \nTheorem  D.1  \nA square matrix has full rank if and only if it is nonsingular. D.2  Basic  matrix  properties  1221 \nA null  vector  for a matrix A is a nonzero vector x such that Ax  D 0. The \nfollowing  theorem  (whose  proof  is left  as Exercise  D.2-7)  and its corollary relate \nthe notions of column rank and singularity to null vectors. \nTheorem  D.2  \nA matrix has full column rank if and only if it doe s not have a null vector. \nCorollary  D.3  \nA square matrix is singular if and only if it has a  null vector. \nThe ij th minor  of an n\ue005n matrix A, for n>1 , is the .n\ue0031/ \ue005.n\ue0031/ matrix A \u0152ij  \u0141 \nobtained by deleting the i th row and j th column of A. The determinant  of an n \ue005 n \nmatrix A is de\u00fbned  recursively  in terms  of its  minors  by  \ndet.A/  D \u201a \na 11  if n D 1;  \nn X  \nj D1 .\ue0031/ 1Cj a 1j  det.A  \u01521j  \u0141 / if n>1:  \nThe term .\ue0031/ i Cj det.A  \u0152ij  \u0141 / is known as the cofactor  of the element a ij . \nThe following theorems, whose proofs are omitted, e xpress fundamental  prop-  \nerties of the determinant. \nTheorem  D.4  (Determinant  properties)  \nThe determinant of a square matrix A has the following properties: \n\ue001 If any row or any column of A is zero, then det .A/  D 0. \n\ue001 The determinant of A is multiplied by \ufffd if the entries of any one row (or any \none column) of A are all multiplied by \ufffd. \n\ue001 The determinant of A is unchanged  if the  entries  in one  row  (respectively,  col-  \numn) are added to those in another row (respectivel y, column). \n\ue001 The determinant of A equals the determinant of A T . \n\ue001 The determinant of A is multiplied by \ue0031 if any two rows (or any two columns) \nare exchanged. \nAlso, for any square matrices A and B , we have det.AB/  D det.A/  det.B/. \nTheorem  D.5  \nAn n \ue005 n matrix A is singular if and only if det .A/  D 0. 1222  Appendix  D Matrices  \nPositive-de\ufb01nite  matrices  \nPositive-de\u00fbnite  matrices  play  an important  role  in many  applications. An n \ue005 n \nmatrix A is positive-de\ufb01nite  if x T Ax >0  for all n-vectors  x \u00a4 0. For example, \nthe  identity  matrix  is positive-de\u00fbnite,  since  if x D .x  1 x 2 \ue001 \ue001 \ue001  x n / T is a nonzero \nvector, then \nx T I n x D x T x \nD n X  \ni D1 x 2 \ni \n> 0:  \nMatrices  that  arise  in applications  are  often  positive-de\u00fb nite due to the following \ntheorem. \nTheorem  D.6  \nFor any matrix A with full column rank, the matrix A T A is positive-de\u00fbnite.  \nProof  We must show that x T .A  T A/x  > 0 for any nonzero vector x . For any \nvector x , \nx T .A  T A/x  D .Ax/  T .Ax/  (by  Exercise  D.1-2)  \nD kAx  k 2 : \nThe value kAx  k 2 is just the sum of the squares of the elements of t he vector Ax  . \nTherefore, kAx  k 2 \ue004 0. We\u2019ll  show  by  contradiction  that  kAx  k 2 >0. Suppose that \nkAx  k 2 D 0. Then, every element of Ax  is 0, which is to say Ax  D 0. Since A has \nfull column rank, Theorem D.2 says that x D 0, which contradicts the requirement \nthat x is nonzero. Hence, A T A is positive-de\u00fbnite.  \nSection  28.3  explores  other  properties  of positive-de\u00fbnite  matrices.  Section  33.3  \nuses  a similar  condition,  known  as positive-semide\u00fbnite.  An n \ue005 n matrix A is \npositive-semide\ufb01nite  if x T Ax  \ue004 0 for all n-vectors  x \u00a4 0. \nExercises  \nD.2-1  \nProve that matrix inverses are unique, that is, if B and C are inverses of A, then \nB D C . Problems for Appendix D 1223 \nD.2-2  \nProve  that  the  determinant  of a lower-triangular  or upper-t riangular matrix is equal \nto the product of its diagonal elements. Prove that  the inverse of a lower-triangular  \nmatrix,  if it exists,  is lower-triangular.  \nD.2-3  \nProve that if P is a permutation matrix, then P is invertible, its inverse is P T , and \nP T is a permutation matrix. \nD.2-4  \nLet A and B be n \ue005 n matrices such that AB  D I . Prove that if A 0 is obtained \nfrom A by adding row j into row i , where i \u00a4 j , then subtracting column i from \ncolumn j of B yields the inverse B 0 of A 0 . \nD.2-5  \nLet A be a nonsingular n \ue005 n matrix with complex entries. Show that every entry \nof A \ue0021 is real if and only if every entry of A is real. \nD.2-6  \nShow that if A is a nonsingular, symmetric, n \ue005 n matrix, then A \ue0021 is symmetric. \nShow that if B is an arbitrary m \ue005 n matrix, then the m \ue005 m matrix given by the \nproduct BAB  T is symmetric. \nD.2-7  \nProve Theorem D.2. That is, show that a matrix A has full column rank if and only \nif Ax  D 0 implies x D 0. (Hint: Express the linear dependence of one column on \nthe  others  as a matrix-vector  equation.)  \nD.2-8  \nProve that for any two compatible matrices A and B , \nrank.AB/  \u0dc4 min frank.A/;  rank.B/g ; \nwhere equality holds if either A or B is a nonsingular square matrix. ( Hint: Use \nthe  alternate  de\u00fbnition  of the  rank  of a matrix.)  \nProblems  \nD-1  Vandermonde  matrix  \nGiven  numbers  x 0 ;x  1 ;:::;x  n\ue0021 , prove that the determinant of the Vandermonde  \nmatrix  1224  Appendix  D Matrices  \nV.x  0 ;x  1 ;:::;x  n\ue0021 / D \u02d9 1 x  0 x 2 \n0 \ue001 \ue001 \ue001  x n\ue0021 \n0 \n1 x  1 x 2 \n1 \ue001 \ue001 \ue001  x n\ue0021 \n1 : : : : : : : : : : : : : : : \n1 x  n\ue0021 x 2 \nn\ue0021 \ue001 \ue001 \ue001  x n\ue0021 \nn\ue0021 \ue005 \nis \ndet.V.x  0 ;x  1 ;:::;x  n\ue0021 // D Y  \n0\u0dc4j <k\u0dc4n\ue0021 .x k \ue003 x j /: \n(Hint: Multiply column i by \ue003x 0 and add it to column i C 1 for i D n \ue003 1; \nn \ue003 2;:::;1 , and then use induction.) \nD-2  Permutations  de\ufb01ned  by matrix-vector  multiplication  over  GF.2/ \nOne  class  of permutations  of the  integers  in the  set  S n D f0;1;2;:::;2  n \ue003 1g is \nde\u00fbned  by  matrix  multiplication  over  GF.2/, the  Galois  \u00fbeld  of two  elements.  For  \neach integer x 2 S n , we view its binary representation as an n-bit  vector  \u00e2 \nx 0 \nx 1 \nx 2 \n: : : \nx n\ue0021 \u00e3 \n; \nwhere x D P  n\ue0021 \ni D0 x i 2 i . If A is an n \ue005 n matrix in which each entry is either 0 \nor 1, then  we  can  de\u00fbne  a permutation  mapping  each  value  x 2 S n to the number \nwhose  binary  representation  is the  matrix-vector  product  Ax  . All this arithmetic \nis performed over GF.2/: all values are either 0 or 1, and with one exception, the \nusual rules of addition and multiplication apply. T he exception is that 1 C 1 D 0. \nYou can think of arithmetic over GF.2/  as being just like regular integer arithmetic, \nexcept  that  you  use  only  the  least-signi\u00fbcant  bit.  \nAs an example, for S 2 D f0;1;2;3 g, the matrix \nA D \u00ce 1 0  \n1 1  \u00cf \nde\u00fbnes  the  following  permutation  \ufffd A : \ufffd A .0/  D 0, \ufffd A .1/  D 3, \ufffd A .2/  D 2, \n\ufffd A .3/  D 1. To see why \ufffd A .3/  D 1, observe that, working in GF.2/, Problems for Appendix D 1225 \n\ufffd A .3/  D \u00ce 1 0  \n1 1  \u00cf\u00ce  1 \n1 \u00cf \nD \u00ce 1 \ue001 1 C 0 \ue001 1 \n1 \ue001 1 C 1 \ue001 1 \u00cf \nD \u00ce 1 \n0 \u00cf \n; \nwhich is the binary representation of 1. \nFor  the  remainder  of this  problem,  we\u2019ll  work  over  GF.2/, and all matrix and \nvector entries will be 0 or 1. De\u00fbne  the  rank  of a 0-1 matrix (a matrix for which \neach entry is either 0 or 1) over GF.2/  the same as for a regular matrix, but with all \narithmetic that determines linear independence perf ormed over GF.2/. We  de\u00fbne  \nthe range  of an n \ue005 n0-1 matrix A by \nR.A/  D fy W y D Ax  for some x 2 S n g ; \nso that R.A/  is the set of numbers in S n that are produced by multiplying each \nvalue x 2 S n by A. \na. If r is the rank of matrix A, prove that jR.A/ j D  2 r . Conclude that A de\u00fbnes  a \npermutation on S n only if A has full rank. \nFor a given n \ue005 n matrix A and a given value y 2 R.A/, we  de\u00fbne  the  preimage  \nof y by \nP.A;y/  D fx W Ax  D y g ; \nso that P.A;y/  is the set of values in S n that map to y when multiplied by A. \nb. If r is the rank of n \ue005 n matrix A and y 2 R.A/ , prove that jP.A;y/ j D  2 n\ue002r . \nLet 0 \u0dc4 m \u0dc4 n, and suppose that we partition the set S n into  blocks  of con-  \nsecutive numbers, where the i th block consists of the 2 m numbers i2 m ;i2  m C 1; \ni2 m C 2;:::;.i  C 1/2  m \ue003 1. For any subset S \u0dc2 S n , de\u00fbne  B.S;m/  to be the set of \nsize-2 m blocks of S n containing some element of S . As an example, when n D 3, \nm D 1, and S D f1;4;5 g, then B.S;m/  consists of blocks 0 (since 1 is in the 0th \nblock) and 2 (since both 4 and 5 belong to block 2). \nc. Let r be the rank of the lower left .n \ue003 m/  \ue005 m submatrix of A, that is, the \nmatrix formed by taking the intersection of the bot tom n \ue003 m rows and the \nleftmost m columns of A. Let S be any  size-2 m block of S n , and let S 0 D \nfy W y D Ax  for some x 2 S g. Prove that jB.S  0 ;m/j D  2 r and that for each \nblock in B.S  0 ;m/, exactly 2 m\ue002r numbers in S map to that block. 1226  Appendix  D Matrices  \nBecause multiplying the zero vector by any matrix y ields a zero vector, the set \nof permutations of S n de\u00fbned  by  multiplying  by  n \ue005 n0-1 matrices with full rank \nover GF.2/  cannot include all permutations of S n . Let\u2019s  extend  the  class  of per-  \nmutations  de\u00fbned  by  matrix-vector  multiplication  to inclu de an additive term, so \nthat x 2 S n maps to Ax  C c , where c is an n-bit  vector  and  addition  is performed  \nover GF.2/. For example, when \nA D \u00ce 1 0  \n1 1  \u00cf \nand \nc D \u00ce 0 \n1 \u00cf \n; \nwe get the following permutation \ufffd A;c  : \ufffd A;c  .0/  D 2, \ufffd A;c  .1/  D 1, \ufffd A;c  .2/  D 0, \n\ufffd A;c  .3/  D 3. We call any permutation that maps x 2 S n to Ax  C c , for some n \ue005 n \n0-1 matrix A with full rank and some n-bit  vector  c , a linear  permutation . \nd. Use a counting argument to show that the number of linear permutations of S n \nis much less than the number of permutations of S n . \ne. Give  an example  of a value  of n and a permutation of S n that cannot be achieved \nby any linear permutation. ( Hint: For a given permutation, think about how \nmultiplying a matrix by a unit vector relates to th e columns of the matrix.) \nAppendix  notes  \nLinear-algebra  textbooks  provide  plenty  of background  information on matrices. \nThe  books  by  Strang  [422,  423]  are  particularly  good.  Bibliography \n[1]  Milton  Abramowitz  and  Irene  A.  Stegun,  editors.  Handbook  of Mathematical  Functions . \nDover,  1965.  \n[2]  G.  M.  Adel\u2019son-Vel\u2019ski\u02d8  \u0131 and  E. M.  Landis.  An  algorithm  for the organization of information. \nSoviet  Mathematics  Doklady, 3(5):125931263,  1962.  \n[3]  Alok  Aggarwal  and  Jeffrey  Scott  Vitter.  The  input/outpu t complexity of sorting and related \nproblems. Communications  of the  ACM, 31(9):111631127,  1988.  \n[4]  Manindra  Agrawal,  Neeraj  Kayal,  and  Nitin  Saxena.  PRIME S is in P. Annals of Mathe- \nmatics, 160(2):7813793,  2004.  \n[5]  Alfred  V. Aho,  John  E. Hopcroft,  and  Jeffrey  D.  Ullman.  The  Design  and  Analysis  of \nComputer  Algorithms. Addison-Wesley,  1974.  \n[6]  Alfred  V. Aho,  John  E. Hopcroft,  and  Jeffrey  D.  Ullman.  Data  Structures  and  Algorithms . \nAddison-Wesley,  1983.  \n[7]  Ravindra  K.  Ahuja,  Thomas  L. Magnanti,  and  James  B. Orlin . Network  Flows:  Theory,  \nAlgorithms,  and  Applications . Prentice  Hall,  1993.  \n[8]  Ravindra  K.  Ahuja,  Kurt  Mehlhorn,  James  B. Orlin,  and  Robert E. Tarjan. Faster algorithms \nfor the shortest path problem. Journal  of the  ACM, 37(2):2133223,  1990.  \n[9]  Ravindra  K.  Ahuja  and  James  B. Orlin.  A fast  and  simple  algorithm  for  the  maximum  \u00fcow  \nproblem. Operations  Research, 37(5):7483759,  1989.  \n[10]  Ravindra  K.  Ahuja,  James  B. Orlin,  and  Robert  E. Tarjan.  Improved time bounds for the \nmaximum  \u00fcow  problem.  SIAM  Journal  on  Computing, 18(5):9393954,  1989.  \n[11]  Mikl\u00b4  os Ajtai,  Nimrod  Megiddo,  and  Orli  Waarts.  Improv ed algorithms and analysis for \nsecretary problems and generalizations. SIAM  Journal  on  Discrete  Mathematics , 14(1):13  \n27,  2001.  \n[12]  Selim  G.  Akl.  The  Design  and  Analysis  of Parallel  Algorithms. Prentice  Hall,  1989.  \n[13]  Mohamad  Akra  and  Louay  Bazzi.  On  the  solution  of linear  recurrence equations. Compu-  \ntational  Optimization  and  Applications , 10(2):1953210,  1998.  \n[14]  Susanne  Albers.  Online  algorithms:  A survey.  Mathematical  Programming , 97(1-2):3326,  \n2003.  \n[15]  Noga  Alon.  Generating  pseudo-random  permutations  and  maximum  \u00fcow  algorithms.  In- \nformation  Processing  Letters, 35:2013204,  1990.  1228  Bibliography  \n[16]  Arne  Andersson.  Balanced  search  trees  made  simple.  In Proceedings  of the  Third  Workshop  \non  Algorithms  and  Data  Structures, volume  709  of Lecture  Notes  in Computer  Science , \npages  60371.  Springer,  1993.  \n[17]  Arne  Andersson.  Faster  deterministic  sorting  and  searching in linear space. In Proceedings  \nof the  37th  Annual  Symposium  on  Foundations  of Computer  Science, pages  1353141,  1996.  \n[18]  Arne  Andersson,  Torben  Hagerup,  Stefan  Nilsson,  and  Rajeev Raman. Sorting in linear \ntime?  Journal  of Computer  and  System  Sciences, 57:74393,  1998.  \n[19]  Tom  M.  Apostol.  Calculus, volume  1. Blaisdell  Publishing  Company,  second  edition,  1967.  \n[20]  Nimar  S. Arora,  Robert  D.  Blumofe,  and  C. Greg  Plaxton.  Thread  scheduling  for  multipro-  \ngrammed multiprocessors. Theory  of Computing  Systems, 34(2):1153144,  2001.  \n[21]  Sanjeev  Arora.  Probabilistic  checking  of proofs  and  the  hardness  of approx imation prob- \nlems. PhD  thesis,  University  of California,  Berkeley,  1994.  \n[22]  Sanjeev  Arora.  The  approximability  of NP-hard  problem s. In Proceedings  of the  30th  \nAnnual  ACM  Symposium  on  Theory  of Computing, pages  3373348,  1998.  \n[23]  Sanjeev  Arora.  Polynomial  time  approximation  schemes  for euclidean traveling salesman \nand other geometric problems. Journal  of the  ACM, 45(5):7533782,  1998.  \n[24]  Sanjeev  Arora  and  Boaz  Barak.  Computational  Complexity:  A Modern  Approach. Cam-  \nbridge University Press, 2009. \n[25]  Sanjeev  Arora,  Elad  Hazan,  and  Satyen  Kale.  The  multipl icative weights update method: A \nmeta-algorithm  and  applications.  Theory  of Computing, 8(1):1213164,  2012.  \n[26]  Sanjeev  Arora  and  Carsten  Lund.  Hardness  of approximat ions. In Dorit S. Hochbaum, \neditor, Approximation Algorithms for NP-Hard Problems , pages  3993446.  PWS  Publishing  \nCompany,  1997.  \n[27]  Mikhail  J. Atallah  and  Marina  Blanton,  editors.  Algorithms  and  Theory  of Computation  \nHandbook, volume  1. Chapman  & Hall/CRC  Press,  second  edition,  2009.  \n[28]  Mikhail  J. Atallah  and  Marina  Blanton,  editors.  Algorithms  and  Theory  of Computation  \nHandbook, volume  2. Chapman  & Hall/CRC  Press,  second  edition,  2009.  \n[29]  G.  Ausiello,  P. Crescenzi,  G.  Gambosi,  V. Kann,  A.  Marchetti-Spaccamela,  and  M.  Protasi.  \nComplexity  and  Approximation:  Combinatorial  Optimizatio n Problems and Their Approx- \nimability  Properties. Springer,  1999.  \n[30]  Shai  Avidan  and  Ariel  Shamir.  Seam  carving  for  content- aware image resizing. ACM Trans- \nactions  on  Graphics, 26(3),  article  10,  2007.  \n[31]  L\u00b4  aszl\u00b4  o Babai,  Eugene  M.  Luks,  and  \u00b4 Akos Seress. Fast management of permutation groups I. \nSIAM  Journal  on  Computing, 26(5):131031342,  1997.  \n[32]  Eric  Bach.  Private  communication,  1989.  \n[33]  Eric  Bach.  Number-theoretic  algorithms.  In Annual  Review  of Computer  Science, volume  4, \npages  1193172.  Annual  Reviews,  Inc.,  1990.  \n[34]  Eric  Bach  and  Jeffrey  Shallit.  Algorithmic  Number  Theory\u2014Volume  I: Ef\ufb01cient  Algorithms . \nThe  MIT  Press,  1996.  \n[35]  Nikhil  Bansal  and  Anupam  Gupta.  Potential-function  proofs  for  \u00fbrst-order  methods.  CoRR , \nabs/1712.04581,  2017.  Bibliography  1229 \n[36]  Hannah  Bast,  Daniel  Delling,  Andrew  V. Goldberg,  Matthias  M\u00a8  uller-Hannemann,  Thomas  \nPajor, Peter Sanders, Dorothea Wagner, and Renato F . Werneck. Route  planning  in trans-  \nportation networks. In Algorithm  Engineering  - Selected  Results  and  Surveys , volume 9220 \nof Lecture  Notes  in Computer  Science, pages  19380.  Springer,  2016.  \n[37]  Surender  Baswana,  Ramesh  Hariharan,  and  Sandeep  Sen.  Improved  decremental  algo-  \nrithms  for  maintaining  transitive  closure  and  all-pairs  shortest paths. Journal  of Algorithms , \n62(2):74392,  2007.  \n[38]  R. Bayer.  Symmetric  binary  B-trees:  Data  structure  and  maintenance algorithms. Acta  \nInformatica, 1(4):2903306,  1972.  \n[39]  R. Bayer  and  E. M.  McCreight.  Organization  and  maintena nce of large ordered indexes. \nActa  Informatica, 1(3):1733189,  1972.  \n[40]  Pierre  Beauchemin,  Gilles  Brassard,  Claude  Cr\u00b4  epeau,  Claude  Goutier,  and  Carl  Pomerance.  \nThe generation of random numbers that are probably prime. Journal  of Cryptology, 1(1):533  \n64,  1988.  \n[41]  L. A.  Belady.  A study  of replacement  algorithms  for  a virtual-storage  computer.  IBM \nSystems  Journal, 5(2):783101,  1966.  \n[42]  Mihir  Bellare,  Joe  Kilian,  and  Phillip  Rogaway.  The  security of cipher block chaining \nmessage authentication code. Journal  of Computer  and  System  Sciences, 61(3):3623399,  \n2000. \n[43]  Mihir  Bellare  and  Phillip  Rogaway.  Random  oracles  are  practical: A paradigm for designing \nef\u00fbcient  protocols.  In CCS  \u201993,  Proceedings  of the  1st  ACM  Conference  on  Computer  and \nCommunications  Security, pages  62373,  1993.  \n[44]  Richard  Bellman.  Dynamic  Programming . Princeton  University  Press,  1957.  \n[45]  Richard  Bellman.  On  a routing  problem.  Quarterly  of Applied  Mathematics , 16(1):87390,  \n1958.  \n[46]  Michael  Ben-Or.  Lower  bounds  for  algebraic  computatio n trees. In Proceedings  of the  \nFifteenth  Annual  ACM  Symposium  on  Theory  of Computing, pages  80386,  1983.  \n[47]  Michael  A.  Bender,  Erik  D.  Demaine,  and  Martin  Farach-Colton.  Cache-oblivious  B-trees.  \nSIAM  Journal  on  Computing, 35(2):3413358,  2005.  \n[48]  Samuel  W.  Bent  and  John  W.  John.  Finding  the  median  requi res 2n  comparisons. In Pro- \nceedings  of the  Seventeenth  Annual  ACM  Symposium  on  Theory  of Computing, pages  2133  \n216,  1985.  \n[49]  Jon  L. Bentley.  Writing  Ef\ufb01cient  Programs. Prentice  Hall,  1982.  \n[50]  Jon  L. Bentley.  More Programming Pearls: Confessions of a Coder . Addison-Wesley,  \n1988.  \n[51]  Jon  L. Bentley.  Programming Pearls . Addison-Wesley,  second  edition,  1999.  \n[52]  Jon  L. Bentley,  Dorothea  Haken,  and  James  B. Saxe.  A general  method  for  solving  divide-  \nand-conquer  recurrences.  SIGACT News , 12(3):36344,  1980.  \n[53]  Claude  Berge.  Two  theorems  in graph  theory.  Proceedings  of the  National  Academy  of \nSciences, 43(9):8423844,  1957.  \n[54]  Aditya  Y. Bhargava.  Grokking  Algorithms:  An  Illustrated  Guide  For  Programmers  and \nOther  Curious  People. Manning  Publications,  2016.  1230  Bibliography  \n[55]  Daniel  Bienstock  and  Benjamin  McClosky.  Tightening  simplex  mixed-integer  sets  with  \nguaranteed bounds. Optimization  Online, 2008.  \n[56]  Patrick  Billingsley.  Probability  and  Measure. John  Wiley  & Sons,  second  edition,  1986.  \n[57]  Guy  E. Blelloch.  Scan  Primitives  and  Parallel  Vector  Models . PhD thesis, Department of \nElectrical  Engineering  and  Computer  Science,  MIT,  1989.  Available as MIT Laboratory for \nComputer  Science  Technical  Report  MIT/LCS/TR-463.  \n[58]  Guy  E. Blelloch.  Programming  parallel  algorithms.  Communications  of the  ACM , \n39(3):85397,  1996.  \n[59]  Guy  E. Blelloch,  Jeremy  T. Fineman,  Phillip  B. Gibbons,  and  Julian  Shun.  Internally  deter-  \nministic parallel algorithms can be fast. In 17th  ACM  SIGPLAN  Symposium  on  Principles  \nand  Practice  of Parallel  Programming , pages  1813192,  2012.  \n[60]  Guy  E. Blelloch,  Jeremy  T. Fineman,  Yan  Gu,  and  Yihan  Sun.  Optimal  parallel  algorithms  \nin the  binary-forking  model.  In Proceedings  of the  32nd  Annual  ACM  Symposium  on  Par-  \nallelism  in Algorithms  and  Architectures , pages  893102,  2020.  \n[61]  Guy  E. Blelloch,  Phillip  B. Gibbons,  and  Yossi  Matias.  Provably  ef\u00fbcient  scheduling  for  \nlanguages  with  \u00fbne-grained  parallelism.  Journal  of the  ACM, 46(2):2813321,  1999.  \n[62]  Manuel  Blum,  Robert  W.  Floyd,  Vaughan  Pratt,  Ronald  L. Rivest, and Robert E. Tarjan. \nTime bounds for selection. Journal  of Computer  and  System  Sciences, 7(4):4483461,  1973.  \n[63]  Robert  D.  Blumofe  and  Charles  E. Leiserson.  Scheduling  multithreaded computations by \nwork stealing. Journal  of the  ACM, 46(5):7203748,  1999.  \n[64]  Robert  L Bocchino,  Jr.,  Vikram  S. Adve,  Sarita  V. Adve,  and  Marc  Snir.  Parallel  program-  \nming must be deterministic by default. In Proceedings  of the  First  USENIX  Conference  on  \nHot  Topics  in Parallelism  (HotPar) , 2009. \n[65]  B\u00b4  ela  Bollob\u00b4  as.  Random Graphs . Academic  Press,  1985.  \n[66]  Leonardo  Bonacci.  Liber  Abaci, 1202.  \n[67]  J. A.  Bondy  and  U.  S. R. Murty.  Graph  Theory  with  Applications . American  Elsevier,  1976.  \n[68]  A.  Borodin  and  R. El-Yaniv.  Online  Computation  and  Competitive  Analysis . Cambridge \nUniversity  Press,  1998.  \n[69]  Stephen  P. Boyd  and  Lieven  Vandenberghe.  Convex  Optimization . Cambridge University \nPress,  2004.  \n[70]  Gilles  Brassard  and  Paul  Bratley.  Fundamentals  of Algorithmics . Prentice  Hall,  1996.  \n[71]  Richard  P. Brent.  The  parallel  evaluation  of general  arithmetic expressions. Journal  of the  \nACM, 21(2):2013206,  1974.  \n[72]  Gerth  St\u00f8lting  Brodal.  A survey  on  priority  queues.  In Andrej Brodnik, Alejandro \nL\u00b4  opez-Ortiz,  Venkatesh  Raman,  and  Alfredo  Viola,  editors , Space-Ef\ufb01cient  Data  Structures,  \nStreams,  and  Algorithms:  Papers  in Honor  of J. Ian  Munro  on  the  Occasion  of His  66th  \nBirthday, volume  8066  of Lecture  Notes  in Computer  Science, pages  1503163.  Springer,  \n2013.  \n[73]  Gerth  St\u00f8lting  Brodal,  George  Lagogiannis,  and  Robert  E. Tarjan. Strict Fibonacci heaps. \nIn Proceedings  of the  44th  Annual  ACM  Symposium  on  Theory  of Computing, pages  11773  \n1184,  2012.  Bibliography  1231 \n[74]  George  W.  Brown.  Some  notes  on  computation  of games  solutions. RAND Corporation \nReport, P-78,  1949.  \n[75]  S\u00b4  ebastien  Bubeck.  Convex  optimization:  Algorithms  and complexity. Foundations  and  \nTrends  in Machine  Learning, 8(3-4):2313357,  2015.  \n[76]  Niv  Buchbinder  and  Joseph  Naor.  The  design  of competitive  online  algorithms  via  a primal-  \ndual approach. Foundations  and  Trends  in Theoretical  Computer  Science, 3(233):933263,  \n2009. \n[77]  J. P. Buhler,  H.  W.  Lenstra,  Jr.,  and  Carl  Pomerance.  Factoring integers with the number \n\u00fbeld  sieve.  In A.  K.  Lenstra  and  H.  W.  Lenstra,  Jr.,  editors,  The  Development  of the  Number  \nField Sieve, volume  1554  of Lecture  Notes  in Mathematics , pages  50394.  Springer,  1993.  \n[78]  M.  Burrows  and  D.  J. Wheeler.  A block-sorting  lossless  data compression algorithm. SRC \nResearch  Report  124,  Digital  Equipment  Corporation  Systems  Research  Center,  May  1994.  \n[79]  Neville  Campbell.  Recurrences.  Unpublished  treatise  available at https://nevillecampbell. \ncom/Recurrences.pdf, 2020. \n[80]  J. Lawrence  Carter  and  Mark  N.  Wegman.  Universal  classe s of hash functions. Journal  of \nComputer  and  System  Sciences, 18(2):1433154,  1979.  \n[81]  Barbara  Chapman,  Gabriele  Jost,  and  Ruud  van  der  Pas.  Using OpenMP: Portable Shared \nMemory  Parallel  Programming . The  MIT  Press,  2007.  \n[82]  Philippe  Charles,  Christian  Grothoff,  Vijay  Saraswat,  Christopher  Donawa,  Allan  Kiel-  \nstra,  Kemal  Ebcioglu,  Christoph  Von  Praun,  and  Vivek  Sarkar.  X10:  An  object-oriented  \napproach  to non-uniform  cluster  computing.  In ACM  SIGPLAN  Conference  on  Object-  \noriented  Programming,  Systems,  Languages,  and  Applications  (OOPSLA), pages  5193538,  \n2005.  \n[83]  Bernard  Chazelle.  A minimum  spanning  tree  algorithm  with  inverse-Ackermann  type  com-  \nplexity. Journal  of the  ACM, 47(6):102831047,  2000.  \n[84]  Ke  Chen  and  Adrian  Dumitrescu.  Selection  algorithms  with small groups. International \nJournal  of Foundations  of Computer  Science, 31(3):3553369,  2020.  \n[85]  Guang-Ien  Cheng,  Mingdong  Feng,  Charles  E. Leiserson,  Keith  H.  Randall,  and  Andrew  F. \nStark. Detecting data races in Cilk programs that u se locks. In Proceedings  of the  10th  \nAnnual  ACM  Symposium  on  Parallel  Algorithms  and  Architectu res, pages  2983309,  1998.  \n[86]  Joseph  Cheriyan  and  Torben  Hagerup.  A randomized  maximum-\u00fcow  algorithm.  SIAM \nJournal  on  Computing, 24(2):2033226,  1995.  \n[87]  Joseph  Cheriyan  and  S. N.  Maheshwari.  Analysis  of pre\u00fco w push algorithms for maximum \nnetwork  \u00fcow.  SIAM  Journal  on  Computing, 18(6):105731086,  1989.  \n[88]  Boris  V. Cherkassky  and  Andrew  V. Goldberg.  On  implementing  the  push-relabel  method  \nfor  the  maximum  \u00fcow  problem.  Algorithmica , 19(4):3903410,  1997.  \n[89]  Boris  V.Cherkassky,  Andrew  V. Goldberg,  and  Tomasz  Radzik. Shortest paths algorithms: \nTheory and experimental evaluation. Mathematical  Programming , 73(2):1293174,  1996.  \n[90]  Boris  V. Cherkassky,  Andrew  V. Goldberg,  and  Craig  Silverstein. Buckets, heaps, lists and \nmonotone priority queues. SIAM  Journal  on  Computing, 28(4):132631346,  1999.  \n[91]  H.  Chernoff.  A measure  of asymptotic  ef\u00fbciency  for  tests of a hypothesis based on the sum \nof observations. Annals  of Mathematical  Statistics, 23(4):4933507,  1952.  1232  Bibliography  \n[92]  Brian  Christian  and  Tom  Grif\u00fbths.  Algorithms  to Live  By:  The  Computer  Science  of Human  \nDecisions. Picador,  2017.  \n[93]  Kai  Lai  Chung.  Elementary  Probability  Theory  with  Stochastic  Processes. Springer,  1974.  \n[94]  V. Chv\u00b4  atal.  Linear Programming . W.  H.  Freeman  and  Company,  1983.  \n[95]  V. Chv\u00b4  atal,  D.  A.  Klarner,  and  D.  E. Knuth.  Selected  combinatorial research problems. \nTechnical  Report  STAN-CS-72-292,  Computer  Science  Depart ment, Stanford University, \n1972.  \n[96]  Alan  Cobham.  The  intrinsic  computational  dif\u00fbculty  of functions. In Proceedings  of the  \n1964  Congress  for  Logic,  Methodology,  and  the  Philosophy  of Science, pages  24330.  North-  \nHolland,  1964.  \n[97]  H.  Cohen  and  H.  W.  Lenstra,  Jr. Primality  testing  and  Jacobi sums. Mathematics  of Com-  \nputation, 42(165):2973330,  1984.  \n[98]  Michael  B. Cohen,  Aleksander  Madry,  Piotr  Sankowski,  and  Adrian  Vladu.  Negative-  \nweight  shortest  paths  and  unit  capacity  minimum  cost  \u00fcow  in e O.m  10=7  log w/  time  (ex-  \ntended abstract). In Proceedings  of the  28th  ACM-SIAM  Symposium  on  Discrete  Algo rithms , \npages  7523771,  2017.  \n[99]  Douglas  Comer.  The  ubiquitous  B-tree.  ACM  Computing  Surveys, 11(2):1213137,  1979.  \n[100]  Stephen  Cook.  The  complexity  of theorem  proving  proce dures. In Proceedings  of the  Third  \nAnnual  ACM  Symposium  on  Theory  of Computing, pages  1513158,  1971.  \n[101]  James  W.  Cooley  and  John  W.  Tukey.  An  algorithm  for  the  machine calculation of complex \nFourier series. Mathematics  of Computation , 19(90):2973301,  1965.  \n[102]  Don  Coppersmith.  Modi\u00fbcations  to the  number  \u00fbeld  sieve. Journal  of Cryptology , \n6(3):1693180,  1993.  \n[103]  Don  Coppersmith  and  Shmuel  Winograd.  Matrix  multipli cation via arithmetic progression. \nJournal  of Symbolic  Computation , 9(3):2513280,  1990.  \n[104]  Thomas  H.  Cormen.  Algorithms  Unlocked. The  MIT  Press,  2013.  \n[105]  Thomas  H.  Cormen,  Thomas  Sundquist,  and  Leonard  F. Wisniewski. Asymptotically tight \nbounds for performing BMMC permutations on parallel  disk systems. SIAM  Journal  on  \nComputing, 28(1):1053136,  1998.  \n[106]  Don  Dailey  and  Charles  E. Leiserson.  Using  Cilk  to write multiprocessor chess programs. \nIn H.  J. van  den  Herik  and  B. Monien,  editors,  Advances  in Computer  Games , volume 9, \npages  25352.  University  of Maastricht,  Netherlands,  2001.  \n[107]  Sanjoy  Dasgupta,  Christos  Papadimitriou,  and  Umesh  V azirani. Algorithms. McGraw-Hill,  \n2008.  \n[108]  Abraham  de Moivre.  De  fractionibus  algebraicis  radicalitate  immunibus  ad  fractiones  sim-  \npliciores reducendis, deque summandis terminis quar undam serierum aequali intervallo a se \ndistantibus. Philosophical  Transactions , 32(373):1623168,  1722.  \n[109]  Erik  D.  Demaine,  Dion  Harmon,  John  Iacono,  and  Mihai  P\u02c7  atras  \u00b8cu.  Dynamic  optimality4  \nalmost. SIAM  Journal  on  Computing, 37(1):2403251,  2007.  \n[110]  Camil  Demetrescu,  David  Eppstein,  Zvi  Galik,  and  Gius eppe F. Italiano. Dynamic graph \nalgorithms.  In Mikhail  J. Attalah  and  Marina  Blanton,  edito rs, Algorithms  and  Theory  of \nComputation  Handbook, chapter  9, pages  9-139-28.  Chapman  & Hall/CRC,  second  edition, \n2009. Bibliography  1233 \n[111]  Camil  Demetrescu  and  Giuseppe  F. Italiano.  Fully  dyna mic all pairs shortest paths with real \nedge weights. Journal  of Computer  and  System  Sciences, 72(5):8133837,  2006.  \n[112]  Eric  V. Denardo  and  Bennett  L. Fox.  Shortest-route  methods:  1. Reaching,  pruning,  and  \nbuckets. Operations  Research, 27(1):1613186,  1979.  \n[113]  Martin  Dietzfelbinger,  Torben  Hagerup,  Jyrki  Kataja inen, and Martti Penttonen. A reliable \nrandomized  algorithm  for  the  closest-pair  problem.  Journal  of Algorithms, 25(1):19351,  \n1997.  \n[114]  Martin  Dietzfelbinger,  Anna  Karlin,  Kurt  Mehlhorn,  Friedhelm Meyer auf der Heide, Hans \nRohnert, and Robert E. Tarjan. Dynamic perfect hash ing: Upper and lower bounds. SIAM \nJournal  on  Computing, 23(4):7383761,  1994.  \n[115]  Whit\u00fbeld  Dif\u00fbe  and  Martin  E. Hellman.  New  directions  in cryptography. IEEE  Transac-  \ntions  on  Information  Theory, IT-22(6):6443654,  1976.  \n[116]  Edsger  W.  Dijkstra.  A note  on  two  problems  in connexion  with graphs. Numerische  Math-  \nematik, 1(1):2693271,  1959.  \n[117]  Edsger  W.  Dijkstra.  A Discipline  of Programming . Prentice-Hall,  1976.  \n[118]  Dimitar  Dimitrov,  Martin  Vechev,  and  Vivek  Sarkar.  Race detection in two dimensions. \nACM  Transactions  on  Parallel  Computing, 4(4):1322,  2018.  \n[119]  E. A.  Dinic.  Algorithm  for  solution  of a problem  of maximum  \u00fcow  in a network  with  power  \nestimation. Soviet  Mathematics  Doklady, 11(5):127731280,  1970.  \n[120]  Brandon  Dixon,  Monika  Rauch,  and  Robert  E. Tarjan.  Veri\u00fbcation  and  sensitivity  analysis  \nof minimum spanning trees in linear time. SIAM  Journal  on  Computing, 21(6):118431192,  \n1992.  \n[121]  John  D.  Dixon.  Factorization  and  primality  tests.  The  American  Mathematical  Monthly , \n91(6):3333352,  1984.  \n[122]  Dorit  Dor,  Johan  H\u02da  astad,  Staffan  Ulfberg,  and  Uri  Zwick.  On  lower  bounds  for  selecting  \nthe median. SIAM  Journal  on  Discrete  Mathematics , 14(3):2993311,  2001.  \n[123]  Dorit  Dor  and  Uri  Zwick.  Selecting  the  median.  SIAM  Journal  on  Computing, 28(5):17223  \n1758,  1999.  \n[124]  Dorit  Dor  and  Uri  Zwick.  Median  selection  requires  .2 C \ufffd/n  comparisons. SIAM  Journal  \non  Discrete  Mathematics , 14(3):3123325,  2001.  \n[125]  Alvin  W.  Drake.  Fundamentals  of Applied  Probability  Theory. McGraw-Hill,  1967.  \n[126]  James  R. Driscoll,  Neil  Sarnak,  Daniel  D.  Sleator,  and  Robert E. Tarjan. Making data \nstructures persistent. Journal  of Computer  and  System  Sciences, 38(1):863124,  1989.  \n[127]  Ran  Duan,  Seth  Pettie,  and  Hsin-Hao  Su.  Scaling  algori thms for weighted matching in \ngeneral graphs. ACM  Transactions  on  Algorithms, 14(1):8:138:35,  2018.  \n[128]  Richard  Durstenfeld.  Algorithm  235  (RANDOM  PERMUTATION).  Communications  of \nthe ACM, 7(7):420,  1964.  \n[129]  Derek  L. Eager,  John  Zahorjan,  and  Edward  D.  Lazowska.  Speedup  versus  ef\u00fbciency  in \nparallel systems. IEEE  Transactions  on  Computers, 38(3):4083423,  1989.  \n[130]  Jack  Edmonds.  Paths,  trees,  and  \u00fcowers.  Canadian  Journal  of Mathematics , 17:4493467,  \n1965.  1234  Bibliography  \n[131]  Jack  Edmonds.  Matroids  and  the  greedy  algorithm.  Mathematical  Programming , 1(1):1273  \n136,  1971.  \n[132]  Jack  Edmonds  and  Richard  M.  Karp.  Theoretical  improvements  in the  algorithmic  ef\u00fb-  \nciency  for  network  \u00fcow  problems.  Journal  of the  ACM, 19(2):2483264,  1972.  \n[133]  Jeff  Edmonds.  How  To  Think  About  Algorithms. Cambridge  University  Press,  2008.  \n[134]  Mourad  Elloumi  and  Albert  Y. Zomaya,  editors.  Algorithms  in Computational  Molecular  \nBiology:  Techniques,  Approaches  and  Applications . John  Wiley  & Sons,  2011.  \n[135]  Jeff  Erickson.  Algorithms. https://archive.org/details/Algorithms-Jeff-Erickso n, 2019.  \n[136]  Martin  Erwig.  Once  Upon  an  Algorithm:  How  Stories  Explain  Computing . The MIT Press, \n2017.  \n[137]  Shimon  Even.  Graph Algorithms . Computer  Science  Press,  1979.  \n[138]  Shimon  Even  and  Yossi  Shiloach.  An  on-line  edge-delet ion problem. Journal  of the  ACM , \n28(1):134,  1981.  \n[139]  William  Feller.  An  Introduction  to Probability  Theory  and  Its  Applications . John  Wiley  & \nSons,  third  edition,  1968.  \n[140]  Mingdong  Feng  and  Charles  E. Leiserson.  Ef\u00fbcient  detection of determinacy races in Cilk \nprograms. In Proceedings  of the  9th  Annual  ACM  Symposium  on  Parallel  Algo rithms and \nArchitectures , pages  1311,  1997.  \n[141]  Amos  Fiat,  Richard  M.  Karp,  Michael  Luby,  Lyle  A.  McGeo ch, Daniel Dominic Sleator, \nand Neal E. Young. Competitive paging algorithms. Journal  of Algorithms, 12(4):6853699,  \n1991.  \n[142]  Amos  Fiat  and  Gerhard  J. Woeginger,  editors.  Online Algorithms, The State of the Art , \nvolume  1442  of Lecture  Notes  in Computer  Science. Springer,  1998.  \n[143]  Sir  Ronald  A.  Fisher  and  Frank  Yates.  Statistical  Tables  for  Biological,  Agricultural  and  \nMedical  Research. Hafner  Publishing  Company,  \u00fbfth  edition,  1957.  \n[144]  Robert  W.  Floyd.  Algorithm  97  (SHORTEST  PATH).  Communications  of the  ACM , \n5(6):345,  1962.  \n[145]  Robert  W.  Floyd.  Algorithm  245  (TREESORT).  Communications  of the  ACM, 7(12):701,  \n1964.  \n[146]  Robert  W.  Floyd.  Permuting  information  in idealized  two-level  storage.  In Raymond  E. \nMiller  and  James  W.  Thatcher,  editors,  Complexity  of Computer  Computations , pages  1053  \n109.  Plenum  Press,  1972.  \n[147]  Robert  W.  Floyd  and  Ronald  L. Rivest.  Expected  time  bounds for selection. Communica-  \ntions of the ACM , 18(3):1653172,  1975.  \n[148]  L. R. Ford.  Network  Flow  Theory.  RAND  Corporation,  Santa  Monica,  CA,  1956.  \n[149]  Lestor  R. Ford,  Jr. and  D.  R. Fulkerson.  Flows in Networks . Princeton University Press, \n1962.  \n[150]  Lestor  R. Ford,  Jr. and  Selmer  M.  Johnson.  A tournament  problem. The  American  Mathe-  \nmatical  Monthly, 66(5):3873389,  1959.  \n[151]  E. W.  Forgy.  Cluster  analysis  of multivariate  ef\u00fbciency  versus  interpretatbility  of classi\u00fbca-  \ntions. Biometrics, 21(3):7683769,  1965.  Bibliography  1235 \n[152]  Lance  Fortnow.  The  Golden  Ticket:  P , NP ,  and  the  Search  for  the  Impossible . Princeton \nUniversity  Press,  2013.  \n[153]  Michael  L. Fredman.  New  bounds  on  the  complexity  of the  shortest path problem. SIAM \nJournal  on  Computing, 5(1):83389,  1976.  \n[154]  Michael  L. Fredman,  J\u00b4 anos  Koml\u00b4  os,  and  Endre  Szemer\u00b4  edi. Storing a sparse table with O.1/  \nworst case access time. Journal  of the  ACM, 31(3):5383544,  1984.  \n[155]  Michael  L. Fredman  and  Michael  E. Saks.  The  cell  probe  complexity  of dynamic  data  struc-  \ntures. In Proceedings  of the  Twenty  First  Annual  ACM  Symposium  on  Theory  of Computing , \npages  3453354,  1989.  \n[156]  Michael  L. Fredman  and  Robert  E. Tarjan.  Fibonacci  heaps and their uses in improved \nnetwork optimization algorithms. Journal  of the  ACM, 34(3):5963615,  1987.  \n[157]  Michael  L. Fredman  and  Dan  E. Willard.  Surpassing  the  information theoretic bound with \nfusion trees. Journal  of Computer  and  System  Sciences, 47(3):4243436,  1993.  \n[158]  Michael  L. Fredman  and  Dan  E. Willard.  Trans-dichotomous  algorithms  for  minimum  span-  \nning trees and shortest paths. Journal  of Computer  and  System  Sciences, 48(3):5333551,  \n1994.  \n[159]  Yoav  Freund  and  Robert  E. Schapire.  A decision-theoretic  generalization  of on-line  learning  \nand an application to boosting. Journal  of Computer  and  System  Sciences, 55(1):1193139,  \n1997.  \n[160]  Matteo  Frigo,  Pablo  Halpern,  Charles  E. Leiserson,  and  Stephen  Lewin-Berlin.  Reducers  \nand other Cilk++ hyperobjects. In Proceedings  of the  21st  Annual  ACM  Symposium  on  \nParallelism  in Algorithms  and  Architectures , pages  79390,  2009.  \n[161]  Matteo  Frigo  and  Steven  G.  Johnson.  The  design  and  implementation  of FFTW3.  Proceed-  \nings of the IEEE , 93(2):2163231,  2005.  \n[162]  Hannah  Fry.  Hello  World:  Being  Human  in the  Age  of Algorithms. W.W.  Norton  & Com-  \npany,  2018.  \n[163]  Harold  N.  Gabow.  Path-based  depth-\u00fbrst  search  for  strong and biconnected components. \nInformation  Processing  Letters, 74(334):1073114,  2000.  \n[164]  Harold  N.  Gabow.  The  weighted  matching  approach  to maximum cardinality matching. \nFundamenta  Informaticae , 154(1-4):1093130,  2017.  \n[165]  Harold  N.  Gabow,  Z. Galil,  T. Spencer,  and  Robert  E. Tarjan.  Ef\u00fbcient  algorithms  for  \u00fbnd-  \ning minimum spanning trees in undirected and direct ed graphs. Combinatorica , 6(2):1093  \n122,  1986.  \n[166]  Harold  N.  Gabow  and  Robert  E. Tarjan.  A linear-time  algorithm for a special case of disjoint \nset union. Journal  of Computer  and  System  Sciences, 30(2):2093221,  1985.  \n[167]  Harold  N.  Gabow  and  Robert  E. Tarjan.  Faster  scaling  algorithms for network problems. \nSIAM  Journal  on  Computing, 18(5):101331036,  1989.  \n[168]  Harold  N.  Gabow  and  Robert  Endre  Tarjan.  Faster  scaling  algorithms  for  general  graph-  \nmatching problems. Journal  of the  ACM, 38(4):8153853,  1991.  \n[169]  D.  Gale  and  L. S. Shapley.  College  admissions  and  the  stability of marriage. American  \nMathematical  Monthly, 69(1):9315,  1962.  \n[170]  Zvi  Galil  and  Oded  Margalit.  All  pairs  shortest  distan ces for graphs with small integer \nlength edges. Information  and  Computation , 134(2):1033139,  1997.  1236  Bibliography  \n[171]  Zvi  Galil  and  Oded  Margalit.  All  pairs  shortest  paths  for graphs with small integer length \nedges. Journal  of Computer  and  System  Sciences, 54(2):2433254,  1997.  \n[172]  Zvi  Galil  and  Kunsoo  Park.  Dynamic  programming  with  convexity, concavity and sparsity. \nTheoretical  Computer  Science, 92(1):49376,  1992.  \n[173]  Zvi  Galil  and  Joel  Seiferas.  Time-space-optimal  string matching. Journal  of Computer  and  \nSystem  Sciences, 26(3):2803294,  1983.  \n[174]  Igal  Galperin  and  Ronald  L. Rivest.  Scapegoat  trees.  In Proceedings  of the  4th  ACM-SIAM  \nSymposium  on  Discrete  Algorithms, pages  1653174,  1993.  \n[175]  Michael  R. Garey,  R. L. Graham,  and  J. D.  Ullman.  Worst-case  analyis  of memory  al-  \nlocation algorithms. In Proceedings  of the  Fourth  Annual  ACM  Symposium  on  Theory  of \nComputing, pages  1433150,  1972.  \n[176]  Michael  R. Garey  and  David  S. Johnson.  Computers  and  Intractability:  A Guide  to the  \nTheory  of NP-Completeness . W.  H.  Freeman,  1979.  \n[177]  Naveen  Garg  and  Jochen  K\u00a8  onemann.  Faster  and  simpler  algorithms for multicommodity \n\u00fcow  and  other  fractional  packing  problems.  SIAM  Journal  on  Computing, 37(2):6303652,  \n2007.  \n[178]  Saul  Gass.  Linear  Programming:  Methods  and  Applications . International  Thomson  Pub-  \nlishing,  fourth  edition,  1975.  \n[179]  F\u02d8  anic\u02d8  a Gavril.  Algorithms  for  minimum  coloring,  maximum clique, minimum covering by \ncliques, and maximum independent set of a chordal g raph. SIAM  Journal  on  Computing , \n1(2):1803187,  1972.  \n[180]  Alan  George  and  Joseph  W-H  Liu.  Computer  Solution  of Large  Sparse  Positive  De\ufb01nite  \nSystems. Prentice  Hall,  1981.  \n[181]  E. N.  Gilbert  and  E. F. Moore.  Variable-length  binary  encodings. Bell  System  Technical  \nJournal, 38(4):9333967,  1959.  \n[182]  Ashish  Goel,  Sanjeev  Khanna,  Daniel  H.  Larkin,  and  Rober E. Tarjan. Disjoint set union \nwith randomized linking. In Proceedings  of the  25th  ACM-SIAM  Symposium  on  Discrete  \nAlgorithms, pages  100531017,  2014.  \n[183]  Michel  X.  Goemans  and  David  P. Williamson.  Improved  approximation algorithms for \nmaximum  cut  and  satis\u00fbability  problems  using  semide\u00fbnite  programming. Journal  of the  \nACM, 42(6):111531145,  1995.  \n[184]  Michel  X.  Goemans  and  David  P. Williamson.  The  primal- dual method for approximation \nalgorithms and its application to network design pr oblems. In Dorit S. Hochbaum, editor, \nApproximation Algorithms for NP-Hard Problems , pages  1443191.  PWS  Publishing  Com-  \npany,  1997.  \n[185]  Andrew  V. Goldberg.  Ef\ufb01cient  Graph  Algorithms  for  Sequential  and  Parallel  Computers . \nPhD thesis, Department of Electrical Engineering an d Computer  Science,  MIT,  1987.  \n[186]  Andrew  V. Goldberg.  Scaling  algorithms  for  the  shorte st paths problem. SIAM  Journal  on  \nComputing, 24(3):4943504,  1995.  \n[187]  Andrew  V. Goldberg  and  Satish  Rao.  Beyond  the  \u00fcow  decom position barrier. Journal  of \nthe ACM, 45(5):7833797,  1998.  \n[188]  Andrew  V. Goldberg  and  Robert  E. Tarjan.  A new  approach  to the  maximum  \u00fcow  problem.  \nJournal  of the  ACM, 35(4):9213940,  1988.  Bibliography  1237 \n[189]  D.  Goldfarb  and  M.  J. Todd.  Linear  programming.  In G.  L. Nemhauser,  A.  H.  G.  Rinnooy-  \nKan,  and  M.  J. Todd,  editors,  Handbooks  in Operations  Research  and  Management  Science,  \nVol.  1, Optimization , pages  733170.  Elsevier  Science  Publishers,  1989.  \n[190]  Sha\u00fb  Goldwasser  and  Silvio  Micali.  Probabilistic  encryption. Journal  of Computer  and  \nSystem  Sciences, 28(2):2703299,  1984.  \n[191]  Sha\u00fb  Goldwasser,  Silvio  Micali,  and  Ronald  L. Rivest.  A digital signature scheme secure \nagainst  adaptive  chosen-message  attacks.  SIAM  Journal  on  Computing, 17(2):2813308,  \n1988.  \n[192]  Gene  H.  Golub  and  Charles  F. Van  Loan.  Matrix  Computations . The  Johns  Hopkins  Uni-  \nversity  Press,  third  edition,  1996.  \n[193]  G.  H.  Gonnet  and  R. Baeza-Yates.  Handbook  of Algorithms  and  Data  Structures  in Pascal  \nand C. Addison-Wesley,  second  edition,  1991.  \n[194]  Rafael  C. Gonzalez  and  Richard  E. Woods.  Digital  Image  Processing. Addison-Wesley,  \n1992.  \n[195]  Michael  T. Goodrich  and  Roberto  Tamassia.  Algorithm  Design:  Foundations,  Analysis,  and  \nInternet Examples . John  Wiley  & Sons,  2001.  \n[196]  Michael  T. Goodrich  and  Roberto  Tamassia.  Data  Structures  and  Algorithms  in Java. John  \nWiley  & Sons,  sixth  edition,  2014.  \n[197]  Ronald  L. Graham.  Bounds  for  certain  multiprocessor  anomalies. Bell  System  Technical  \nJournal, 45(9):156331581,  1966.  \n[198]  Ronald  L. Graham  and  Pavol  Hell.  On  the  history  of the  minimum spanning tree problem. \nAnnals  of the  History  of Computing, 7(1):43357,  1985.  \n[199]  Ronald  L. Graham,  Donald  E. Knuth,  and  Oren  Patashnik.  Concrete  Mathematics . \nAddison-Wesley,  second  edition,  1994.  \n[200]  David  Gries.  The  Science  of Programming . Springer,  1981.  \n[201]  M.  Gr\u00a8  otschel,  L\u00b4  aszl\u00b4  o Lov\u00b4  asz,  and  Alexander  Schri jver. Geometric  Algorithms  and  Combi-  \nnatorial  Optimization . Springer,  1988.  \n[202]  Leo  J. Guibas  and  Robert  Sedgewick.  A dichromatic  fram ework for balanced trees. In \nProceedings  of the  19th  Annual  Symposium  on  Foundations  of Computer  Science , pages \n8321,  1978.  \n[203]  Dan  Gus\u00fbeld  and  Robert  W.  Irving.  The  Stable  Marriage  Problem:  Structure  and  Algo-  \nrithms. The  MIT  Press,  1989.  \n[204]  Gregory  Gutin  and  Abraham  P. Punnen,  editors.  The Traveling Salesman Problem and Its \nVariations. Kluwer  Academic  Publishers,  2002.  \n[205]  Torben  Hagerup.  Improved  shortest  paths  on  the  word  RAM. In Procedings  of 27th  In-  \nternational  Colloquium  on  Automata,  Languages  and  Program ming, ICALP 2000 , volume \n1853  of Lecture  Notes  in Computer  Science, pages  61372.  Springer,  2000.  \n[206]  H.  Halberstam  and  R. E. Ingram,  editors.  The  Mathematical  Papers  of Sir  William  Rowan  \nHamilton, volume  III  (Algebra).  Cambridge  University  Press,  1967.  \n[207]  Yijie  Han.  Improved  fast  integer  sorting  in linear  space. Information  and  Computation , \n170(1):81394,  2001.  \n[208]  Frank  Harary.  Graph  Theory. Addison-Wesley,  1969.  1238  Bibliography  \n[209]  Gregory  C. Harfst  and  Edward  M.  Reingold.  A potential- based amortized analysis of the \nunion-\u00fbnd  data  structure.  SIGACT News , 31(3):86395,  2000.  \n[210]  J. Hartmanis  and  R. E. Stearns.  On  the  computational  complexity of algorithms. Transac-  \ntions  of the  American  Mathematical  Society, 117:2853306,  1965.  \n[211]  Michael  T. Heideman,  Don  H.  Johnson,  and  C. Sidney  Burrus.  Gauss  and  the  history  of the  \nFast Fourier Transform. IEEE  ASSP  Magazine, 1(4):14321,  1984.  \n[212]  Monika  R. Henzinger  and  Valerie  King.  Fully  dynamic  biconnectivity  and  transitive  clo-  \nsure. In Proceedings  of the  36th  Annual  Symposium  on  Foundations  of Computer  Science , \npages  6643672,  1995.  \n[213]  Monika  R. Henzinger  and  Valerie  King.  Randomized  fully dynamic graph algorithms with \npolylogarithmic time per operation. Journal  of the  ACM, 46(4):5023516,  1999.  \n[214]  Monika  R. Henzinger,  Satish  Rao,  and  Harold  N.  Gabow.  Computing vertex connectivity: \nNew bounds from old techniques. Journal  of Algorithms, 34(2):2223250,  2000.  \n[215]  Nicholas  J. Higham.  Exploiting  fast  matrix  multiplication  within  the  level  3 BLAS.  ACM \nTransactions  on  Mathematical  Software, 16(4):3523368,  1990.  \n[216]  Nicholas  J. Higham.  Accuracy  and  Stability  of Numerical  Algorithms. SIAM,  second  edi-  \ntion, 2002. \n[217]  W.  Daniel  Hillis  and  Jr. Guy  L. Steele.  Data  parallel  algorithms. Communications  of the  \nACM, 29(12):117031183,  1986.  \n[218]  C. A.  R. Hoare.  Algorithm  63  (PARTITION)  and  algorithm  65  (FIND).  Communications  \nof the ACM, 4(7):3213322,  1961.  \n[219]  C. A.  R. Hoare.  Quicksort.  The  Computer  Journal, 5(1):10315,  1962.  \n[220]  Dorit  S. Hochbaum.  Ef\u00fbcient  bounds  for  the  stable  set,  vertex  cover  and  set  packing  prob-  \nlems. Discrete  Applied  Mathematics , 6(3):2433254,  1983.  \n[221]  Dorit  S. Hochbaum,  editor.  Approximation Algorithms for NP-Hard Problems . PWS  Pub-  \nlishing  Company,  1997.  \n[222]  W.  Hoeffding.  On  the  distribution  of the  number  of successes in independent trials. Annals \nof Mathematical  Statistics, 27(3):7133721,  1956.  \n[223]  Micha  Hofri.  Probabilistic  Analysis  of Algorithms. Springer,  1987.  \n[224]  John  E. Hopcroft  and  Richard  M.  Karp.  An  n 5=2  algorithm for maximum matchings in \nbipartite graphs. SIAM  Journal  on  Computing, 2(4):2253231,  1973.  \n[225]  John  E. Hopcroft,  Rajeev  Motwani,  and  Jeffrey  D.  Ullma n. Introduction  to Automata  The-  \nory,  Languages,  and  Computation . Addison  Wesley,  third  edition,  2006.  \n[226]  John  E. Hopcroft  and  Robert  E. Tarjan.  Ef\u00fbcient  algori thms for graph manipulation. Com- \nmunications  of the  ACM, 16(6):3723378,  1973.  \n[227]  John  E. Hopcroft  and  Jeffrey  D.  Ullman.  Set  merging  algorithms. SIAM  Journal  on  Com-  \nputing, 2(4):2943303,  1973.  \n[228]  John  E. Hopcroft  and  Jeffrey  D.  Ullman.  Introduction  to Automata  Theory,  Languages,  and  \nComputation . Addison-Wesley,  1979.  \n[229]  Juraj  Hromkovi\u02c7  c. Algorithmics  for  Hard  Problems:  Introduction  to Combinato rial Opti- \nmization,  Randomization,  Approximation,  and  Heuristics. Springer-Verlag,  2001.  Bibliography  1239 \n[230]  T. C. Hu  and  M.  T. Shing.  Computation  of matrix  chain  products. Part I. SIAM  Journal  on  \nComputing, 11(2):3623373,  1982.  \n[231]  T. C. Hu  and  M.  T. Shing.  Computation  of matrix  chain  products. Part II. SIAM  Journal  on  \nComputing, 13(2):2283251,  1984.  \n[232]  T. C. Hu  and  A.  C. Tucker.  Optimal  computer  search  trees  and  variable-length  alphabetic  \ncodes. SIAM  Journal  on  Applied  Mathematics , 21(4):5143532,  1971.  \n[233]  David  A.  Huffman.  A method  for  the  construction  of minimum-redundancy  codes.  Pro- \nceedings  of the  IRE, 40(9):109831101,  1952.  \n[234]  Oscar  H.  Ibarra  and  Chul  E. Kim.  Fast  approximation  algorithms for the knapsack and sum \nof subset problems. Journal  of the  ACM, 22(4):4633468,  1975.  \n[235]  E. J. Isaac  and  R. C. Singleton.  Sorting  by  address  calculation. Journal  of the  ACM , \n3(3):1693174,  1956.  \n[236]  David  S. Johnson.  Approximation  algorithms  for  combi natorial problems. Journal  of Com-  \nputer  and  System  Sciences, 9(3):2563278,  1974.  \n[237]  David  S. Johnson.  The  NP-completeness  column:  An  ongoing  guide4The  tale  of the  sec-  \nond prover. Journal  of Algorithms, 13(3):5023524,  1992.  \n[238]  Donald  B. Johnson.  Ef\u00fbcient  algorithms  for  shortest  paths in sparse networks. Journal  of \nthe ACM, 24(1):1313,  1977.  \n[239]  Richard  Johnsonbaugh  and  Marcus  Schaefer.  Algorithms. Pearson  Prentice  Hall,  2004.  \n[240]  Neil  C. Jones  and  Pavel  Pevzner.  An  Introduction  to Bioinformatics  Algorithms . The MIT \nPress,  2004.  \n[241]  T. Kanungo,  D.  M.  Mount,  N.  S. Netanyahu,  C. D.  Piatko,  R. Silverman, and A. Y . Wu. \nA local search approximation algorithm for k-means  clustering.  Computational  Geometry , \n28:893112,  2004.  \n[242]  A.  Karatsuba  and  Yu.  Ofman.  Multiplication  of multidi git numbers on automata. Soviet \nPhysics\u2014Doklady , 7(7):5953596,  1963.  Translation  of an  article  in Doklady  Akademii  Nauk  \nSSSR, 145(2),  1962.  \n[243]  David  R. Karger,  Philip  N.  Klein,  and  Robert  E. Tarjan.  A randomized  linear-time  algorithm  \nto \u00fbnd  minimum  spanning  trees.  Journal  of the  ACM, 42(2):3213328,  1995.  \n[244]  David  R. Karger,  Daphne  Koller,  and  Steven  J. Phillips . Finding the hidden path: Time \nbounds  for  all-pairs  shortest  paths.  SIAM  Journal  on  Computing, 22(6):119931217,  1993.  \n[245]  Juha  K\u00a8  arkk\u00a8  ainen,  Peter  Sanders,  and  Stefan  Burkhardt.  Linear  work  suf\u00fbx  array  construc-  \ntion. Journal  of the  ACM, 53(6):9183936,  2006.  \n[246]  Howard  Karloff.  Linear Programming . Birkh\u00a8  auser,  1991.  \n[247]  N.  Karmarkar.  A new  polynomial-time  algorithm  for  linear programming. Combinatorica , \n4(4):3733395,  1984.  \n[248]  Richard  M.  Karp.  Reducibility  among  combinatorial  problems. In Raymond E. Miller and \nJames  W.  Thatcher,  editors,  Complexity  of Computer  Computations , pages  853103.  Plenum  \nPress,  1972.  \n[249]  Richard  M.  Karp.  An  introduction  to randomized  algori thms. Discrete  Applied  Mathemat-  \nics, 34(133):1653201,  1991.  1240  Bibliography  \n[250]  Richard  M.  Karp  and  Michael  O.  Rabin.  Ef\u00fbcient  randomized  pattern-matching  algorithms.  \nIBM  Journal  of Research  and  Development , 31(2):2493260,  1987.  \n[251]  A.  V. Karzanov.  Determining  the  maximal  \u00fcow  in a network  by  the  method  of pre\u00fcows.  \nSoviet  Mathematics  Doklady, 15(2):4343437,  1974.  \n[252]  Toru  Kasai,  Gunho  Lee,  Hiroki  Arimura,  Setsuo  Arikawa,  and  Kunsoo  Park.  Linear-time  \nlongest-common-pre\u00fbx  computation  in suf\u00fbx  arrays  and  its  applications. In Proceedings  \nof the  12th  Annual  Symposium  on  Combinatorial  Pattern  Match ing, volume  2089,  pages  \n1813192.  Springer-Verlag,  2001.  \n[253]  Jonathan  Katz  and  Yehuda  Lindell.  Introduction  to Modern  Cryptography . CRC Press, \nsecond  edition,  2015.  \n[254]  Valerie  King.  A simpler  minimum  spanning  tree  veri\u00fbca tion algorithm. Algorithmica , \n18(2):2633270,  1997.  \n[255]  Valerie  King,  Satish  Rao,  and  Robert  E. Tarjan.  A faster  deterministic  maximum  \u00fcow  algo-  \nrithm. Journal  of Algorithms, 17(3):4473474,  1994.  \n[256]  Philip  N.  Klein  and  Neal  E. Young.  Approximation  algorithms  for  NP-hard  optimization  \nproblems. In CRC Handbook on Algorithms , pages  34-1334-19.  CRC  Press,  1999.  \n[257]  Jon  Kleinberg  and  \u00b4 Eva Tardos. Algorithm Design . Addison-Wesley,  2006.  \n[258]  Robert  D.  Kleinberg.  A multiple-choice  secretary  algorithm with applications to online \nauctions. In Proceedings  of the  16th  ACM-SIAM  Symposium  on  Discrete  Algo rithms , pages \n6303631,  2005.  \n[259]  Donald  E. Knuth.  Fundamental  Algorithms, volume  1 of The  Art  of Computer  Program-  \nming. Addison-Wesley,  third  edition,  1997.  \n[260]  Donald  E. Knuth.  Seminumerical  Algorithms , volume 2 of The  Art  of Computer  Program-  \nming. Addison-Wesley,  third  edition,  1997.  \n[261]  Donald  E. Knuth.  Sorting  and  Searching, volume  3 of The  Art  of Computer  Programming . \nAddison-Wesley,  second  edition,  1998.  \n[262]  Donald  E. Knuth.  Combinatorial Algorithms , volume  4A  of The  Art  of Computer  Program-  \nming. Addison-Wesley,  2011.  \n[263]  Donald  E. Knuth.  Satis\ufb01ability, volume  4, fascicle  6 of The  Art  of Computer  Programming . \nAddison-Wesley,  2015.  \n[264]  Donald  E. Knuth.  Optimum  binary  search  trees.  Acta  Informatica, 1(1):14325,  1971.  \n[265]  Donald  E. Knuth.  Big  omicron  and  big  omega  and  big  theta . SIGACT News , 8(2):18323,  \n1976.  \n[266]  Donald  E. Knuth.  Stable Marriage and Its Relation to Other Combinato rial Problems: An \nIntroduction  to the  Mathematical  Analysis  of Algorithms, volume  10  of CRM  Proceedings  \nand  Lecture  Notes. American  Mathematical  Society,  1997.  \n[267]  Donald  E. Knuth,  James  H.  Morris,  Jr.,  and  Vaughan  R. Pratt. Fast pattern matching in \nstrings. SIAM  Journal  on  Computing, 6(2):3233350,  1977.  \n[268]  Mykel  J. Kochenderfer  and  Tim  A.  Wheeler.  Algorithms  for  Optimization . The MIT Press, \n2019.  \n[269]  J. Koml\u00b4  os.  Linear  veri\u00fbcation  for  spanning  trees.  Combinatorica , 5(1):57365,  1985.  \n[270]  Dexter  C. Kozen.  The  Design  and  Analysis  of Algorithms. Springer,  1992.  Bibliography  1241 \n[271]  David  W.  Krumme,  George  Cybenko,  and  K.  N.  Venkataraman.  Gossiping  in minimal  time.  \nSIAM  Journal  on  Computing, 21(1):1113139,  1992.  \n[272]  Joseph  B. Kruskal,  Jr. On  the  shortest  spanning  subtre e of a graph and the traveling salesman \nproblem. Proceedings  of the  American  Mathematical  Society, 7(1):48350,  1956.  \n[273]  Harold  W.  Kuhn.  The  Hungarian  method  for  the  assignmen t problem. Naval  Research  \nLogistics  Quarterly, 2:83397,  1955.  \n[274]  William  Kuszmaul  and  Charles  E. Leiserson.  Floors  and  ceilings  in divide-and-conquer  \nrecurrences. In Proceedings  of the  3rd  SIAM  Symposium  on  Simplicity  in Algor ithms , pages \n1333141,  2021.  \n[275]  Leslie  Lamport.  How  to make  a multiprocessor  computer  that  correctly  executes  multipro-  \ncess programs. IEEE  Transactions  on  Computers, C-28(9):6903691,  1979.  \n[276]  Eugene  L. Lawler.  Combinatorial  Optimization:  Networks  and  Matroids . Holt, Rinehart, \nand  Winston,  1976.  \n[277]  Eugene  L. Lawler,  J. K.  Lenstra,  A.  H.  G.  Rinnooy  Kan,  and D. B. Shmoys, editors. The \nTraveling Salesman Problem . John  Wiley  & Sons,  1985.  \n[278]  Franc  \u00b8ois  Le  Gall.  Powers  of tensors  and  fast  matrix  multiplication. In Proceedings  of the  \n2014  International  Symposium  on  Symbolic  and  Algebraic  Computation,  (ISSAC) , pages \n2963303,  2014.  \n[279]  Doug  Lea.  A Java  fork/join  framework.  In ACM  2000  Conference  on  Java  Grande , pages \n36343,  2000.  \n[280]  C. Y. Lee.  An  algorithm  for  path  connection  and  its  applications. IRE  Transactions  on  \nElectronic  Computers, EC-10(3):3463365,  1961.  \n[281]  Edward  A.  Lee.  The  problem  with  threads.  IEEE  Computer, 39(3):33342,  2006.  \n[282]  I-Ting  Angelina  Lee,  Charles  E. Leiserson,  Tao  B. Schardl,  Zhunping  Zhang,  and  Jim  \nSukha.  On-the-\u00fcy  pipeline  parallelism.  ACM  Transactions  on  Parallel  Computing , \n2(3):17:1317:42,  2015.  \n[283]  I-Ting  Angelina  Lee  and  Tao  B. Schardl.  Ef\u00fbcient  race  detection for reducer hyperobjects. \nACM  Transactions  on  Parallel  Computing, 4(4):1340,  2018.  \n[284]  Mun-Kyu  Lee,  Pierre  Michaud,  Jeong  Seop  Sim,  and  Daehu n Nyang. A simple proof \nof optimality for the MIN cache replacement policy.  Information  Processing  Letters , \n116(2):1683170,  2016.  \n[285]  Yin  Tat  Lee  and  Aaron  Sidford.  Path  \u00fbnding  methods  for  linear  programming:  Solving  lin-  \near programs in e O.  p \nrank/ iterations  and  faster  algorithms  for  maximum  \u00fcow.  In Proceed-  \nings  of the  55th  Annual  Symposium  on  Foundations  of Computer  Science, pages  4243433,  \n2014.  \n[286]  Tom  Leighton.  Tight  bounds  on  the  complexity  of parall el sorting. IEEE  Transactions  on  \nComputers, C-34(4):3443354,  1985.  \n[287]  Tom  Leighton.  Notes  on  better  master  theorems  for  divide-and-conquer  recurrences.  \nClass notes. Available at http://citeseerx.ist.psu. edu/viewdoc/summary?doi=10.1.1.39.1636,  \n1996.  \n[288]  Tom  Leighton  and  Satish  Rao.  Multicommodity  max-\u00fcow  min-cut  theorems  and  their  use  \nin designing approximation algorithms. Journal  of the  ACM, 46(6):7873832,  1999.  1242  Bibliography  \n[289]  Daan  Leijen  and  Judd  Hall.  Optimize  managed  code  for  multi-core  machines.  MSDN \nMagazine, 2007.  \n[290] Charles E. Leiserson. The Cilk++ concurrency platform. Journal  of Supercomputing , \n51(3):2443257,  March  2010.  \n[291]  Charles  E. Leiserson.  Cilk.  In David  Padua,  editor,  Encyclopedia  of Parallel  Computing , \npages  2733288.  Springer,  2011.  \n[292]  Charles  E. Leiserson,  Tao  B. Schardl,  and  Jim  Sukha.  Deterministic  parallel  random-  \nnumber  generation  for  dynamic-multithreading  platforms.  In Proceddings  of the  17th  ACM  \nSIGPLAN  Symposium  on  Principles  and  Practice  of Parallel  Programming  (PPoPP) , pages \n1933204,  2012.  \n[293]  Charles  E. Leiserson,  Neil  C. Thompson,  Joel  S. Emer,  Bradley  C. Kuszmaul,  Butler  W.  \nLampson,  Daniel  Sanchez,  and  Tao  B. Schardl.  There\u2019s  plenty  of room at the Top: What \nwill  drive  computer  performance  after  Moore\u2019s  law?  Science, 368(6495),  2020.  \n[294]  Debra  A.  Lelewer  and  Daniel  S. Hirschberg.  Data  compre ssion. ACM  Computing  Surveys , \n19(3):2613296,  1987.  \n[295]  A.  K.  Lenstra,  H.  W.  Lenstra,  Jr.,  M.  S. Manasse,  and  J. M.  Pollard.  The  number  \u00fbeld  sieve.  \nIn A.  K.  Lenstra  and  H.  W.  Lenstra,  Jr.,  editors,  The  Development  of the  Number  Field  Sieve , \nvolume  1554  of Lecture  Notes  in Mathematics , pages  11342.  Springer,  1993.  \n[296]  H.  W.  Lenstra,  Jr. Factoring  integers  with  elliptic  curves. Annals  of Mathematics , \n126(3):6493673,  1987.  \n[297]  L. A.  Levin.  Universal  sequential  search  problems.  Problems of Information Transmission , \n9(3):2653266,  1973.  Translated  from  the  original  Russian  article in Problemy  Peredachi  \nInformatsii 9(3):  1153116,  1973.  \n[298]  Anany  Levitin.  Introduction  to the  Design  & Analysis  of Algorithms. Addison-Wesley,  third  \nedition,  2011.  \n[299] Harry R. Lewis and Christos H. Papadimitriou.  Elements  of the  Theory  of Computation . \nPrentice  Hall,  second  edition,  1998.  \n[300]  Nick  Littlestone.  Learning  quickly  when  irrelevant  attributes  abound:  A new  linear-  \nthreshold algorithm. Machine  Learning, 2(4):2853318,  1988.  \n[301]  Nick  Littlestone  and  Manfred  K.  Warmuth.  The  weighted  majority algorithm. Information \nand  Computation , 108(2):2123261,  1994.  \n[302]  C. L. Liu.  Introduction  to Combinatorial  Mathematics . McGraw-Hill,  1968.  \n[303]  Yang  P. Liu  and  Aaron  Sidford.  Faster  energy  maximization  for  faster  maximum  \u00fcow.  In \nProceedings  of the  52nd  Annual  ACM  Symposium  on  Theory  of Computing, pages  8033814,  \n2020. \n[304]  S. P. Lloyd.  Least  squares  quantization  in PCM.  IEEE  Transactions  on  Information  Theory , \n28(2):1293137,  1982.  \n[305]  Panos  Louridas.  Real-World  Algorithms:  A Beginner\u2019s  Guide. The  MIT  Press,  2017.  \n[306]  L\u00b4  aszl\u00b4  o Lov\u00b4  asz  and  Michael  D.  Plummer.  Matching  Theory, volume  121  of Annals of Dis- \ncrete  Mathematics . North  Holland,  1986.  \n[307]  John  MacCormick.  9 Algorithms  That  Changed  the  Future:  The  Ingenious  Ideas  That Drive \nToday\u2019s  Computers. Princeton  University  Press,  2012.  Bibliography  1243 \n[308]  Aleksander  Madry.  Navigating  central  path  with  electrical  \u00fcows:  From  \u00fcows  to matchings,  \nand back. In Proceedings  of the  54th  Annual  Symposium  on  Foundations  of Computer  \nScience, pages  2533262,  2013.  \n[309]  Bruce  M.  Maggs  and  Serge  A.  Plotkin.  Minimum-cost  spanning  tree  as a path-\u00fbnding  \nproblem. Information  Processing  Letters, 26(6):2913293,  1988.  \n[310]  M.  Mahajan,  P. Nimbhorkar,  and  K.  Varadarajan.  The  planar k-means  problem  is NP-hard.  \nIn S. Das and R. Uehara, editors, WALCOM  2009:  Algorithms  and  Computation , volume \n5431  of Lecture  Notes  in Computer  Science, pages  2743285.  Springer,  2009.  \n[311]  Michael  Main.  Data  Structures  and  Other  Objects  Using  Java. Addison-Wesley,  1999.  \n[312]  Udi  Manber  and  Gene  Myers.  Suf\u00fbx  arrays:  A new  method  for  on-line  string  searches.  \nSIAM  Journal  on  Computing, 22(5):9353948,  1993.  \n[313]  David  F. Manlove.  Algorithmics  of Matching  Under  Preferences , volume 2 of Series on \nTheoretical  Computer  Science. World  Scienti\u00fbc,  2013.  \n[314]  Giovanni  Manzini.  An  analysis  of the  Burrows-Wheeler  transform. Journal  of the  ACM , \n48(3):4073430,  2001.  \n[315]  Mario  Andrea  Marchisio,  editor.  Computational  Methods  in Synthetic  Biology . Humana \nPress,  2015.  \n[316]  William  J. Masek  and  Michael  S. Paterson.  A faster  algorithm  computing  string  edit  dis-  \ntances. Journal  of Computer  and  System  Sciences, 20(1):18331,  1980.  \n[317]  Yu.  V. Matiyasevich.  Real-time  recognition  of the  inclusion relation. Journal  of Soviet  \nMathematics , 1(1):64370,  1973.  Translated  from  the  original  Russian  article in Zapiski \nNauchnykh  Seminarov  Leningradskogo  Otdeleniya  Matematicheskogo  Institute  im.  V . A. \nSteklova  Akademii  Nauk  SSSR  20:  1043114,  1971.  \n[318]  H.  A.  Maurer,  Th.  Ottmann,  and  H.-W.  Six.  Implementing  dictionaries using binary trees of \nvery small height. Information  Processing  Letters, 5(1):11314,  1976.  \n[319]  Ernst  W.  Mayr,  Hans  J\u00a8 urgen  Pr\u00a8  omel,  and  Angelika  Steger, editors. Lectures  on  Proof  Veri\ufb01-  \ncation  and  Approximation  Algorithms, volume  1367  of Lecture  Notes  in Computer  Science . \nSpringer,  1998.  \n[320]  Catherine  C. McGeoch.  All  pairs  shortest  paths  and  the  essential subgraph. Algorithmica , \n13(5):4263441,  1995.  \n[321]  Catherine  C. McGeoch.  A Guide  to Experimental  Algorithmics . Cambridge University \nPress,  2012.  \n[322]  Andrew  McGregor.  Graph  stream  algorithms:  A survey.  SIGMOD  Record, 43(1):9320,  \n2014.  \n[323]  M.  D.  McIlroy.  A killer  adversary  for  quicksort.  Software\u2014Practice  and  Experience , \n29(4):3413344,  1999.  \n[324]  Kurt  Mehlhorn  and  Stefan  N\u00a8  aher.  LEDA:  A Platform  for  Combinatorial  and  Geometric  \nComputing. Cambridge  University  Press,  1999.  \n[325]  Kurt  Mehlhorn  and  Peter  Sanders.  Algorithms  and  Data  Structures:  The  Basic  Toolbox . \nSpringer,  2008.  \n[326]  Dinesh  P. Mehta  and  Sartaj  Sahni.  Handbook  of Data  Structures  and  Applications . Chap-  \nman  and  Hall/CRC,  second  edition,  2018.  1244  Bibliography  \n[327]  Gary  L. Miller.  Riemann\u2019s  hypothesis  and  tests  for  primality. Journal  of Computer  and  \nSystem  Sciences, 13(3):3003317,  1976.  \n[328]  Marvin  Minsky  and  Seymore  A.  Pappert.  Perceptrons. The  MIT  Press,  1969.  \n[329]  John  C. Mitchell.  Foundations  for  Programming  Languages. The  MIT  Press,  1996.  \n[330]  Joseph  S. B. Mitchell.  Guillotine  subdivisions  approximate  polygonal  subdivisions:  A sim-  \nple  polynomial-time  approximation  scheme  for  geometric  TSP, k-MST,  and  related  prob-  \nlems. SIAM  Journal  on  Computing, 28(4):129831309,  1999.  \n[331]  Michael  Mitzenmacher  and  Eli  Upfal.  Probability  and  Computing . Cambridge University \nPress,  second  edition,  2017.  \n[332]  Louis  Monier.  Algorithmes  de Factorisation  D\u2019Entiers. PhD  thesis,  L\u2019Universit\u00b4  e Paris-Sud,  \n1980.  \n[333]  Louis  Monier.  Evaluation  and  comparison  of two  ef\u00fbcie nt probabilistic primality testing \nalgorithms. Theoretical  Computer  Science, 12(1):973108,  1980.  \n[334]  Edward  F. Moore.  The  shortest  path  through  a maze.  In Proceedings  of the  International  \nSymposium  on  the  Theory  of Switching, pages  2853292.  Harvard  University  Press,  1959.  \n[335]  Rajeev  Motwani,  Joseph  (Sef\u00fb)  Naor,  and  Prabhakar  Raghavan.  Randomized  approxima-  \ntion algorithms in combinatorial optimization. In D orit Hochbaum, editor, Approximation \nAlgorithms for NP-Hard Problems , chapter  11,  pages  4473481.  PWS  Publishing  Company,  \n1997.  \n[336]  Rajeev  Motwani  and  Prabhakar  Raghavan.  Randomized  Algorithms . Cambridge University \nPress,  1995.  \n[337]  James  Munkres.  Algorithms  for  the  assignment  and  transportation problems. Journal  of the  \nSociety  for  Industrial  and  Applied  Mathematics , 5(1):32338,  1957.  \n[338]  J. I. Munro  and  V. Raman.  Fast  stable  in-place  sorting  with O.n/  data moves. Algorithmica , \n16(2):1513160,  1996.  \n[339]  Yoichi  Muraoka  and  David  J. Kuck.  On  the  time  required  for a sequence of matrix products. \nCommunications  of the  ACM, 16(1):22326,  1973.  \n[340]  Kevin  P. Murphy.  Machine  Learning:  A Probabilistic  Perspective. MIT  Press,  2012.  \n[341]  S. Muthukrishnan.  Data  streams:  Algorithms  and  appli cations. Foundations  and  Trends  in \nTheoretical  Computer  Science, 1(2),  2005.  \n[342]  Richard  Neapolitan.  Foundations  of Algorithms. Jones  & Bartlett  Learning,  \u00fbfth  edition,  \n2014.  \n[343]  Yurii  Nesterov.  Introductory  Lectures  on  Convex  Optimization:  A Basic  Cour se, volume  87  \nof Applied  Optimization . Springer,  2004.  \n[344]  J. Nievergelt  and  E. M.  Reingold.  Binary  search  trees  of bounded balance. SIAM  Journal  \non  Computing, 2(1):33343,  1973.  \n[345]  Ivan  Niven  and  Herbert  S. Zuckerman.  An  Introduction  to the  Theory  of Numbers. John  \nWiley  & Sons,  fourth  edition,  1980.  \n[346]  National  Institute  of Standards  and  Technology.  Hash  functions. https://csrc.nist.gov/ \nprojects/hash-functions,  2019.  \n[347]  Alan  V. Oppenheim  and  Ronald  W.  Schafer,  with  John  R. Buck. Discrete-Time  Signal  \nProcessing. Prentice  Hall,  second  edition,  1998.  Bibliography  1245 \n[348]  Alan  V. Oppenheim  and  Alan  S. Willsky,  with  S. Hamid  Naw ab. Signals  and  Systems . \nPrentice  Hall,  second  edition,  1997.  \n[349]  James  B. Orlin.  A polynomial  time  primal  network  simpl ex algorithm for minimum cost \n\u00fcows.  Mathematical  Programming , 78(1):1093129,  1997.  \n[350]  James  B. Orlin.  Max  \u00fcows  in O.nm/  time, or better. In Proceedings  of the  45th  Annual  \nACM  Symposium  on  Theory  of Computing, pages  7653774,  2013.  \n[351]  Anna  Pagh,  Rasmus  Pagh,  and  Milan  Ruzic.  Linear  probin g with constant independence. \nhttps://arxiv.org/abs/cs/0612055,  2006.  \n[352]  Christos  H.  Papadimitriou.  Computational  Complexity. Addison-Wesley,  1994.  \n[353]  Christos  H.  Papadimitriou  and  Kenneth  Steiglitz.  Combinatorial  Optimization:  Algorithms  \nand  Complexity. Prentice  Hall,  1982.  \n[354]  Michael  S. Paterson.  Progress  in selection.  In Proceedings  of the  Fifth  Scandinavian  Work-  \nshop  on  Algorithm  Theory, pages  3683379,  1996.  \n[355]  Seth  Pettie.  A new  approach  to all-pairs  shortest  paths  on  real-weighted  graphs.  Theoretical  \nComputer  Science, 312(1):47374,  2004.  \n[356]  Seth  Pettie  and  Vijaya  Ramachandran.  An  optimal  minim um spanning tree algorithm. Jour-  \nnal of the ACM , 49(1):16334,  2002.  \n[357]  Seth  Pettie  and  Vijaya  Ramachandran.  A shortest  path  algorithm  for  real-weighted  undi-  \nrected graphs. SIAM  Journal  on  Computing, 34(6):139831431,  2005.  \n[358]  Steven  Phillips  and  Jeffery  Westbrook.  Online  load  balancing  and  network  \u00fcow.  Algorith- \nmica, 21(3):2453261,  1998.  \n[359]  Serge  A.  Plotkin,  David.  B. Shmoys,  and  \u00b4 Eva Tardos. Fast approximation algorithms for \nfractional packing and covering problems. Mathematics  of Operations  Research, 20:2573  \n301,  1995.  \n[360]  J. M.  Pollard.  Factoring  with  cubic  integers.  In A.  K.  Lenstra  and  H.  W.  Lenstra,  Jr.,  editors,  \nThe  Development  of the  Number  Field  Sieve, volume  1554  of Lecture  Notes  in Mathematics , \npages  4310.  Springer,  1993.  \n[361]  Carl  Pomerance.  On  the  distribution  of pseudoprimes.  Mathematics  of Computation , \n37(156):5873593,  1981.  \n[362]  Carl  Pomerance,  editor.  Proceedings  of the  AMS  Symposia  in Applied  Mathematics:  Com - \nputational  Number  Theory  and  Cryptography . American  Mathematical  Society,  1990.  \n[363]  William  K.  Pratt.  Digital  Image  Processing. John  Wiley  & Sons,  fourth  edition,  2007.  \n[364]  Franco  P. Preparata  and  Michael  Ian  Shamos.  Computational  Geometry:  An  Introduction . \nSpringer,  1985.  \n[365]  WilliamH.  Press,  Saul  A.  Teukolsky,  William  T. Vetter ling, and Brian P. Flannery. Numer-  \nical  Recipes  in C++:  The  Art  of Scienti\ufb01c  Computing . Cambridge University Press, second \nedition, 2002. \n[366]  WilliamH.  Press,  Saul  A.  Teukolsky,  William  T. Vetter ling, and Brian P. Flannery. Numer-  \nical  Recipes:  The  Art  of Scienti\ufb01c  Computing . Cambridge University Press, third edition, \n2007.  \n[367]  R. C. Prim.  Shortest  connection  networks  and  some  gene ralizations. Bell  System  Technical  \nJournal, 36(6):138931401,  1957.  1246  Bibliography  \n[368]  Robert  L. Probert.  On  the  additive  complexity  of matri x multiplication. SIAM  Journal  on  \nComputing, 5(2):1873203,  1976.  \n[369]  William  Pugh.  Skip  lists:  A probabilistic  alternativ e to balanced trees. Communications  of \nthe ACM, 33(6):6683676,  1990.  \n[370]  Simon  J. Puglisi,  W.  F. Smyth,  and  Andrew  H.  Turpin.  A taxonomy  of suf\u00fbx  array  construc-  \ntion algorithms. ACM  Computing  Surveys, 39(2),  2007.  \n[371]  Paul  W.  Purdom,  Jr. and  Cynthia  A.  Brown.  The  Analysis  of Algorithms . Holt, Rinehart, \nand  Winston,  1985.  \n[372]  Michael  O.  Rabin.  Probabilistic  algorithms.  In J. F. Traub, editor, Algorithms and Com- \nplexity:  New  Directions  and  Recent  Results, pages  21339.  Academic  Press,  1976.  \n[373]  Michael  O.  Rabin.  Probabilistic  algorithm  for  testin g primality. Journal  of Number  Theory , \n12(1):1283138,  1980.  \n[374]  P. Raghavan  and  C. D.  Thompson.  Randomized  rounding:  A technique for provably good \nalgorithms and algorithmic proofs. Combinatorica , 7(4):3653374,  1987.  \n[375]  Rajeev  Raman.  Recent  results  on  the  single-source  shortest paths problem. SIGACT News , \n28(2):81387,  1997.  \n[376]  James  Reinders.  Intel  Threading  Building  Blocks:  Out\ufb01tting  C++  for  Multi-core  Processor  \nParallelism. O\u2019Reilly  Media,  Inc.,  2007.  \n[377]  Edward  M.  Reingold,  Kenneth  J. Urban,  and  David  Gries.  K-M-P  string  matching  revisited.  \nInformation  Processing  Letters, 64(5):2173223,  1997.  \n[378]  Hans  Riesel.  Prime  Numbers  and  Computer  Methods  for  Factorization , volume  126  of \nProgress  in Mathematics . Birkh\u00a8  auser,  second  edition,  1994.  \n[379]  Ronald  L. Rivest,  M.  J. B. Robshaw,  R. Sidney,  and  Y. L. Yin.  The  RC6  block  cipher.  In \nFirst  Advanced  Encryption  Standard  (AES)  Conference, 1998.  \n[380]  Ronald  L. Rivest,  Adi  Shamir,  and  Leonard  M.  Adleman.  A method for obtaining digital \nsignatures  and  public-key  cryptosystems.  Communications  of the  ACM, 21(2):1203126,  \n1978.  See  also  U.S.  Patent  4,405,829.  \n[381]  Herbert  Robbins.  A remark  on  Stirling\u2019s  formula.  American  Mathematical  Monthly , \n62(1):26329,  1955.  \n[382]  Julia  Robinson.  An  iterative  method  of solving  a game.  The  Annals  of Mathematics , \n54(2):2963301,  1951.  \n[383]  Arch  D.  Robison  and  Charles  E. Leiserson.  Cilk  Plus.  In Pavan Balaji, editor, Programming \nModels  for  Parallel  Computing, chapter  13,  pages  3233352.  The  MIT  Press,  2015.  \n[384]  D.  J. Rosenkrantz,  R. E. Stearns,  and  P. M.  Lewis.  An  analysis of several heuristics for the \ntraveling salesman problem. SIAM  Journal  on  Computing, 6(3):5633581,  1977.  \n[385]  Tim  Roughgarden.  Algorithms  Illuminated,  Part  1: The  Basics. Soundlikeyourself  Publish-  \ning,  2017.  \n[386]  Tim  Roughgarden.  Algorithms  Illuminated,  Part  2: Graph  Algorithms  and  Data  Structures . \nSoundlikeyourself  Publishing,  2018.  \n[387]  Tim  Roughgarden.  Algorithms  Illuminated,  Part  3: Greedy  Algorithms  and  Dynamic  Pro-  \ngramming. Soundlikeyourself  Publishing,  2019.  Bibliography  1247 \n[388]  Tim  Roughgarden.  Algorithms  Illuminated,  Part  4: Algorithms  for  NP-Hard  Problems . \nSoundlikeyourself Publishing, 2020. \n[389]  Salvador  Roura.  Improved  master  theorems  for  divide-and-conquer  recurrences.  Journal  of \nthe ACM, 48(2):1703205,  2001.  \n[390]  Y. A.  Rozanov.  Probability  Theory:  A Concise  Course. Dover,  1969.  \n[391]  Stuart  Russell  and  Peter  Norvig.  Arti\ufb01cial  Intelligence:  A Modern  Approach . Pearson, \nfourth edition, 2020. \n[392]  S. Sahni  and  T. Gonzalez.  P-complete  approximation  problems. Journal  of the  ACM , \n23(3):5553565,  1976.  \n[393]  Peter  Sanders,  Kurt  Mehlhorn,  Martin  Dietzfelbinger  , and Roman Dementiev. Sequential  \nand  Parallel  Algorithms  and  Data  Structures:  The  Basic  Toolkit. Springer,  2019.  \n[394]  Piotr  Sankowski.  Shortest  paths  in matrix  multiplica tion time. In Proceedings  of the  13th  \nAnnual  European  Symposium  on  Algorithms, pages  7703778,  2005.  \n[395]  Russel  Schaffer  and  Robert  Sedgewick.  The  analysis  of heapsort. Journal  of Algorithms , \n15(1):763100,  1993.  \n[396]  Tao  B. Schardl,  I-Ting  Angelina  Lee,  and  Charles  E. Leiserson.  Brief  announcement:  Open  \nCilk. In Proceedings  of the  30th  Annual  ACM  Symposium  on  Parallelism  in Algorithms and \nArchitectures , pages  3513353,  2018.  \n[397]  A.  Sch\u00a8  onhage,  M.  Paterson,  and  N.  Pippenger.  Finding  the median. Journal  of Computer  \nand  System  Sciences, 13(2):1843199,  1976.  \n[398]  Alexander  Schrijver.  Theory  of Linear  and  Integer  Programming . John  Wiley  & Sons,  \n1986.  \n[399]  Alexander  Schrijver.  Paths  and  \u00fcows4A  historical  survey. CWI  Quarterly, 6(3):1693183,  \n1993.  \n[400]  Alexander  Schrijver.  On  the  history  of the  shortest  paths problem. Documenta  Mathemat-  \nica, 17(1):1553167,  2012.  \n[401]  Robert  Sedgewick.  Implementing  quicksort  programs.  Communications  of the  ACM , \n21(10):8473857,  1978.  \n[402]  Robert  Sedgewick  and  Kevin  Wayne.  Algorithms. Addison-Wesley,  fourth  edition,  2011.  \n[403]  Raimund  Seidel.  On  the  all-pairs-shortest-path  prob lem in unweighted undirected graphs. \nJournal  of Computer  and  System  Sciences, 51(3):4003403,  1995.  \n[404]  Raimund  Seidel  and  C. R. Aragon.  Randomized  search  trees. Algorithmica , 16(435):4643  \n497,  1996.  \n[405]  Jo\u02dc  ao  Setubal  and  Jo\u02dc  ao  Meidanis.  Introduction  to Computational  Molecular  Biology . PWS \nPublishing  Company,  1997.  \n[406]  Clifford  A.  Shaffer.  A Practical  Introduction  to Data  Structures  and  Algorithm  Analysis . \nPrentice  Hall,  second  edition,  2001.  \n[407]  Jeffrey  Shallit.  Origins  of the  analysis  of the  Euclid ean algorithm. Historia  Mathematica , \n21(4):4013419,  1994.  \n[408]  M.  Sharir.  A strong-connectivity  algorithm  and  its  applications  in data  \u00fcow  analysis.  Com- \nputers  and  Mathematics  with  Applications , 7(1):67372,  1981.  1248  Bibliography  \n[409]  David  B. Shmoys.  Computing  near-optimal  solutions  to combinatorial  optimization  prob-  \nlems. In William Cook, L\u00b4 aszl\u00b4 o Lov\u00b4 asz, and Pau l Seymour, editors, Combinatorial Opti- \nmization , volume 20 of DIMACS  Series  in Discrete  Mathematics  and  Theoretical  Computer  \nScience. American  Mathematical  Society,  1995.  \n[410]  Avi  Shoshan  and  Uri  Zwick.  All  pairs  shortest  paths  in undirected graphs with integer \nweights. In Proceedings  of the  40th  Annual  Symposium  on  Foundations  of Computer  Sci-  \nence, pages  6053614,  1999.  \n[411]  Victor  Shoup.  A Computational  Introduction  to Number  Theory  and  Algebra . Cambridge \nUniversity Press, second edition, 2009. \n[412]  Julian  Shun.  Shared-Memory  Parallelism  Can  Be  Simple,  Fast,  and  Scalabl e. Association \nfor  Computing  Machinery  and  Morgan  & Claypool,  2017.  \n[413]  Michael  Sipser.  Introduction  to the  Theory  of Computation . Cengage  Learning,  third  edi-  \ntion,  2013.  \n[414]  Steven  S. Skiena.  The  Algorithm  Design  Manual. Springer,  second  edition,  corrected  print-  \ning,  2012.  \n[415]  Daniel  D.  Sleator  and  Robert  E. Tarjan.  A data  structur e for dynamic trees. Journal  of \nComputer  and  System  Sciences, 26(3):3623391,  1983.  \n[416]  Daniel  D.  Sleator  and  Robert  E. Tarjan.  Amortized  ef\u00fbciency of list update rules. In Pro- \nceedings  of the  Sixteenth  Annual  ACM  Symposium  on  Theory  of Computing, pages  4883492,  \n1984.  \n[417]  Daniel  D.  Sleator  and  Robert  E. Tarjan.  Amortized  ef\u00fbciency of list update and paging \nrules. Communications  of the  ACM, 28(2):2023208,  1985.  \n[418]  Daniel  D.  Sleator  and  Robert  E. Tarjan.  Self-adjustin g binary search trees. Journal  of the  \nACM, 32(3):6523686,  1985.  \n[419]  Michael  Soltys-Kulinicz.  An  Introduction  to the  Analysis  of Algorithms. World  Scienti\u00fbc,  \nthird  edition,  2018.  \n[420]  Joel  Spencer.  Ten  Lectures  on  the  Probabilistic  Method, volume  64  of CBMS-NSF Regional \nConference  Series  in Applied  Mathematics . Society for Industrial and Applied Mathematics, \n1993.  \n[421]  Daniel  A.  Spielman  and  Shang-Hua  Teng.  Smoothed  analysis  of algorithms:  Why  the  sim-  \nplex algorithm usually takes polynomial time. Journal  of the  ACM, 51(3):3853463,  2004.  \n[422]  Gilbert  Strang.  Introduction  to Applied  Mathematics . Wellesley-Cambridge  Press,  1986.  \n[423]  Gilbert  Strang.  Linear  Algebra  and  Its  Applications . Thomson Brooks/Cole, fourth edition, \n2006.  \n[424]  Volker  Strassen.  Gaussian  elimination  is not  optimal . Numerische  Mathematik, 14(3):3543  \n356,  1969.  \n[425]  T. G.  Szymanski.  A special  case  of the  maximal  common  subsequence problem. Technical \nReport  TR-170,  Computer  Science  Laboratory,  Princeton  University,  1975.  \n[426]  Robert  E. Tarjan.  Depth  \u00fbrst  search  and  linear  graph  algorithms. SIAM  Journal  on  Com-  \nputing, 1(2):1463160,  1972.  \n[427]  Robert  E. Tarjan.  Ef\u00fbciency  of a good  but  not  linear  set  union algorithm. Journal  of the  \nACM, 22(2):2153225,  1975.  Bibliography  1249 \n[428]  Robert  E. Tarjan.  A class  of algorithms  which  require  nonlinear time to maintain disjoint \nsets. Journal  of Computer  and  System  Sciences, 18(2):1103127,  1979.  \n[429]  Robert  E. Tarjan.  Data  Structures  and  Network  Algorithms . Society for Industrial and \nApplied  Mathematics,  1983.  \n[430]  Robert  E. Tarjan.  Amortized  computational  complexit y. SIAM  Journal  on  Algebraic  and  \nDiscrete  Methods, 6(2):3063318,  1985.  \n[431]  Robert  E. Tarjan.  Class  notes:  Disjoint  set  union.  COS  423,  Princeton  University,  1999.  \nAvailable at https://www.cs.princeton.edu/courses/a rchive/spr00/cs423/handout3.pdf.  \n[432]  Robert  E. Tarjan  and  Jan  van  Leeuwen.  Worst-case  analy sis of set union algorithms. Jour-  \nnal of the ACM , 31(2):2453281,  1984.  \n[433]  George  B. Thomas,  Jr.,  Maurice  D.  Weir,  Joel  Hass,  and  Frank  R. Giordano.  Thomas\u2019 \nCalculus. Addison-Wesley,  eleventh  edition,  2005.  \n[434]  Mikkel  Thorup.  Faster  deterministic  sorting  and  priority queues in linear space. In Pro- \nceedings  of the  9th  ACM-SIAM  Symposium  on  Discrete  Algorith ms, pages  5503555,  1998.  \n[435]  Mikkel  Thorup.  Undirected  single-source  shortest  paths with positive integer weights in \nlinear time. Journal  of the  ACM, 46(3):3623394,  1999.  \n[436]  Mikkel  Thorup.  On  RAM  priority  queues.  SIAM  Journal  on  Computing, 30(1):863109,  \n2000. \n[437]  Mikkel  Thorup.  High  speed  hashing  for  integers  and  strings.  http://arxiv.org/abs/1504.  \n06804,  2015.  \n[438]  Mikkel  Thorup.  Linear  probing  with  5-independent  hashing.  http://arxiv.org/abs/1509.  \n04549,  2015.  \n[439]  Richard  Tolimieri,  Myoung  An,  and  Chao  Lu.  Mathematics  of Multidimensional  Fourier  \nTransform Algorithms . Springer,  second  edition,  1997.  \n[440]  P. van  Emde  Boas.  Preserving  order  in a forest  in less  than logarithmic time and linear \nspace. Information  Processing  Letters, 6(3):80382,  1977.  \n[441]  P. van  Emde  Boas,  R. Kaas,  and  E. Zijlstra.  Design  and  implementation  of an  ef\u00fbcient  \npriority queue. Mathematical  Systems  Theory, 10(1):993127,  1976.  \n[442]  Charles  Van  Loan.  Computational  Frameworks  for  the  Fast  Fourier  Transform . Society for \nIndustrial  and  Applied  Mathematics,  1992.  \n[443]  Benjamin  Van  Roy.  A short  proof  of optimality  for  the  MIN cache replacement algorithm. \nInformation  Processing  Letters, 102(233):72373,  2007.  \n[444]  Robert  J. Vanderbei.  Linear  Programming:  Foundations  and  Extensions. Kluwer  Academic  \nPublishers,  1996.  \n[445]  Virginia  Vassilevska  Williams.  Multiplying  matrices  faster  than  Coppersmith-Winograd.  In \nProceedings  of the  44th  Annual  ACM  Symposium  on  Theory  of Computing, pages  8873898,  \n2012.  \n[446]  Vijay  V. Vazirani.  Approximation Algorithms . Springer,  2001.  \n[447]  Rakesh  M.  Verma.  General  techniques  for  analyzing  recursive algorithms with applications. \nSIAM  Journal  on  Computing, 26(2):5683581,  1997.  1250  Bibliography  \n[448]  Berthold  V\u00a8  ocking,  Helmut  Alt,  Martin  Dietzfelbinger,  R\u00a8  udiger  Reischuk,  Christian  Schei-  \ndeler, Heribert V ollmer, and Dorothea Wager, editor s. Algorithms  Unplugged . Springer, \n2011.  \n[449]  Antony  F. Ware.  Fast  approximate  Fourier  transforms  for irregularly spaced data. SIAM \nReview, 40(4):8383856,  1998.  \n[450]  Stephen  Warshall.  A theorem  on  boolean  matrices.  Journal  of the  ACM, 9(1):11312,  1962.  \n[451]  Mark  Allen  Weiss.  Data  Structures  and  Problem  Solving  Using  C++. Addison-Wesley,  \nsecond edition, 2000. \n[452]  Mark  Allen  Weiss.  Data  Structures  and  Problem  Solving  Using  Java. Addison-Wesley,  \nthird  edition,  2006.  \n[453]  Mark  Allen  Weiss.  Data  Structures  and  Algorithm  Analysis  in C++. Addison-Wesley,  third  \nedition,  2007.  \n[454]  Mark  Allen  Weiss.  Data  Structures  and  Algorithm  Analysis  in Java. Addison-Wesley,  \nsecond  edition,  2007.  \n[455]  Herbert  S. Wilf.  Algorithms  and  Complexity. A K Peters,  second  edition,  2002.  \n[456]  J. W.  J. Williams.  Algorithm  232  (HEAPSORT).  Communications  of the  ACM, 7(6):3473  \n348,  1964.  \n[457]  Ryan  Williams.  Faster  all-pairs  shortest  paths  via  circuit complexity. SIAM  Journal  on  \nComputing, 47(5):196531985,  2018.  \n[458]  David  P. Williamson.  Network Flow Algorithms . Cambridge  University  Press,  2019.  \n[459]  David  P. Williamson  and  David  B. Shmoys.  The Design of Approximation Algorithms . \nCambridge  University  Press,  2011.  \n[460]  Shmuel  Winograd.  On  the  algebraic  complexity  of funct ions. In Actes  du  Congr`  es Interna-  \ntional  des  Math\u00b4  ematiciens, volume  3, pages  2833288,  1970.  \n[461]  Yifan  Xu,  I-Ting  Angelina  Lee,  and  Kunal  Agrawal.  Ef\u00fbc ient parallel determinacy race \ndetection  for  two-dimensional  dags.  In Proceedings  of the  23rd  ACM  SIGPLAN  Symposium  \non  Principles  and  Practice  of Parallel  Programming  (PPoPP), pages  3683380,  2018.  \n[462]  Chee  Yap.  A real  elementary  approach  to the  master  recurrence and generalizations. In \nM.  Ogihara  and  J. Tarui,  editors,  Theory  and  Applications  of Models  of Computation.  TAMC  \n2011, volume  6648  of Lecture  Notes  in Computer  Science, pages  14326.  Springer,  2011.  \n[463]  Yinyu  Ye.  Interior  Point  Algorithms:  Theory  and  Analysis. John  Wiley  & Sons,  1997.  \n[464]  Neal  E. Young.  Online  paging  and  caching.  In Encyclopedia  of Algorithms, pages  14573  \n1461.  Springer,  2016.  \n[465]  Raphael  Yuster  and  Uri  Zwick.  Answering  distance  queries in directed graphs using fast \nmatrix multiplication. In Proceedings  of the  46th  Annual  Symposium  on  Foundations  of \nComputer  Science, pages  3893396,  2005.  \n[466]  Jisheng  Zhao  and  Vivek  Sarkar.  The  design  and  implementation  of the  Habanero-Java  par-  \nallel programming language. In Symposium  on  Object-Oriented  Programming,  Systems,  \nLanguages  and  Applications  (OOPSLA), pages  1853186,  2011.  \n[467]  Uri  Zwick.  All  pairs  shortest  paths  using  bridging  sets  and  rectangular  matrix  multiplica-  \ntion. Journal  of the  ACM, 49(3):2893317,  2002.  \n[468]  Daniel  Zwillinger,  editor.  CRC  Standard  Mathematical  Tables  and  Formulae. Chapman  & \nHall/CRC  Press,  31st  edition,  2003.  Index \nThis index uses the following conventions. Numbers are alphabetized as if spelled \nout;  for  example,  <2-3-4  tree=  is indexed  as if it were  <two-three-four  tree.=  When  \nan entry refers to a place other than the main text , the page number is followed by \na tag:  ex.  for  exercise,  pr.  for  problem,  \u00fbg.  for  \u00fbgure,  and  n. for footnote. A tagged \npage  number  often  indicates  the  \u00fbrst  page  of an exercise  or problem, which is not \nnecessarily the page on which the reference actuall y appears. \n\u02db.n/ , 533  \n\u02db-strongly  convex  function,  1041  \n\u02c7-smooth  function,  1041  \n\u0131 \n(shortest-path  distance),  558  \n(shortest-path  weight),  604  \n\ufffd (golden ratio), 69  \ny \ufffd (conjugate of the golden ratio), 69  \n\ufffd.n/  (Euler\u2019s  phi  function),  920 \n\ufffd \n(predecessor  in a breadth-\u00fbrst  tree),  555  \n(predecessor  in a shortest-paths  tree),  608  \n\ufffd.n/-approximation  algorithm,  1104,  1120  \no-notation,  60  \nO-notation,  50,  54355  \nO 0 -notation,  73  pr.  \ne O-notation,  73  pr.  \n!-notation,  61  \n\ufffd-notation,  51,  54  \u00fbg.,  55356  \n1  \ufffd-notation,  73  pr.  \ne \ufffd-notation,  73  pr.  \n\u201a-notation,  33,  51,  54  \u00fbg.,  56  \ne \u201a-notation,  73  pr.  \nf g  (set), 1153  \n2 (set member), 1153  \n\u2026 (not a set member), 1153  ; \n(empty language), 1052  \n(empty set), 1153  \n\u0dc2 (subset), 1154  \n\ue00a (proper subset), 1154  \nW (such that), 54  n.,  1154  \n\\ (set intersection), 1154  \n[ (set union), 1154  \n\ue003 (set difference), 1154  \nj j \n(\u00fcow  value),  672  \n(length of a string), 959  \n(set cardinality), 1156  \n\ue005 (Cartesian product), 1157  \nh i  \n(sequence), 1162  \n(standard encoding), 1052  \n: (subarray), 19,  23  \n\u0152a; b\ufffd  (closed interval), 1157  \n.a; b/  (open interval), 1157  \n\u0152a; b/  or .a; b\ufffd  (half-open  interval),  1157  \u00e3 n \nk \u00e4 \n(choose), 1180  \nk k  (euclidean norm), 1219  \n\u0160 (factorial), 67368  \nd e  (ceiling), 63  \nb c  (\u00fcoor),  63  1252 Index \n@ (partial derivative), 1023  P  (sum), 1140  Q  (product), 1144  \n!  (adjacency relation), 1165  \ng  (reachability relation), 1165  \n^ (AND), 659,  1065  \nk (concatenation), 291  \n: (NOT),  1065  \n_ (OR),  659,  1065  \nn  (left shift), 305  \no  (logical right shift), 285  \n\u02da \n(group operator), 917  \n(semiring operator), 651  n. \n(symmetric difference), 706  \n\u02dd \n(convolution operator), 880  \n(semiring operator), 651  n. \n\ue003 (closure operator), 1052  \nj (divides relation), 904  \n\u2212 (does-not-divide  relation),  904  \nD (mod n) (equivalent, modulo n), 64  \n\u00a4 (mod n) (not equivalent, modulo n), 64  \n\u0152a\ufffd  n (equivalence class modulo n), 905  \nC n (addition modulo n), 917  \n\ue001 n (multiplication modulo n), 917  \ue002 \na \np \u00cd \n(Legendre symbol), 954  pr.  \n\" (empty string), 959,  1052  \nh (pre\u00fbx  relation),  959  \ni (suf\u00fbx  relation),  959  \n/ / (comment symbol), 22 \n\ue007  (much-greater-than  relation),  533  \n\ue008  (much-less-than  relation),  761  \n\u0dc4 P (polynomial-time  reducibility  relation),  \n1062,  1071  ex.  \nAA-tree,  358  \nabelian group, 917  \nabsent child, 1173  \nabsolutely convergent series, 1140  \nabsorption laws for sets, 1155  \nabstract problem, 1048  \nabuse of asymptotic notation, 55,  59360  \nacceptable pair of integers, 950  \nacceptance \nby an algorithm, 1053  \nby  a \u00fbnite  automaton,  968  accepting state, 967  \naccounting method, 4533456  \nfor binary counters, 455  \nfor dynamic tables, 463  \nfor stack operations, 4543455  \nAckermann\u2019s  function,  544  \nactivity-selection  problem,  4183425  \nacyclic graph, 1166  \nADD-BINARY-I NTEGERS , 25  ex.  \nadd instruction, 26  \naddition \nof matrices, 1217  \nmodulo n (C n ), 917  \nof polynomials, 877  \nadditive group modulo n, 918  \naddressing, open, see open-address  hash  table  \nADD-SUBARRAY , 783  pr.  \nadjacency-list  representation,  5503551  \nreplaced by a hash table, 553  ex.  \nadjacency-matrix  representation,  5513552  \nadjacency relation ( !), 1165  \nadjacent vertices, 1165  \nAdvanced Encryption Standard (AES), 291  \nadversary, 204,  286,  805,  807,  941  \nAES, 291  \naggregate analysis, 4493453  \nfor binary counters, 4513453  \nfor  breadth-\u00fbrst  search,  558  \nfor  depth-\u00fbrst  search,  5663567  \nfor  Dijkstra\u2019s  algorithm,  6233624  \nfor  disjoint-set  data  structures,  5253526,  \n527  ex.  \nfor dynamic tables, 4623463  \nfor  the  Knuth-Morris-Pratt  algorithm,  \n9773978  \nfor  Prim\u2019s  algorithm,  597  \nfor rod cutting, 370  \nfor shortest paths in a dag, 617  \nfor stack operations, 4493451  \naggregate  \u00fcow,  864  \nAkra-Bazzi  recurrence,  1153119  \nsolving  by  Akra-Bazzi  method,  1173118  \nalgorithm, 131226  \nanalysis of, 25334  \napproximation, 110431136  \ncompare-exchange,  222 pr. \ncorrectness of, 6 \ndecision, 1053  Index 1253 \nalgorithm, continued  \ndeterministic, 135  \nlookahead, 815  ex.  \nnondeterministic, 765  \noblivious, 222 pr. \nof\u00fcine,  791  \nonline, see online algorithm \norigin of word, 48  \nparallel, see parallel algorithm \npush-relabel,  702  \nrandomized, see randomized algorithm \nrecursive, 34  \nreduction, 1046,  1062  \nrunning time of, 29 \nscaling, 641  pr.,  699  pr.  \nstreaming, 818  \nas a technology, 13  \nveri\u00fbcation,  1058  \nalgorithmic recurrence, 77378  \nALLOCATE-NODE, 506  \nall-pairs  shortest  paths,  605,  6463669  \nin dynamic graphs, 669  \nin \ufffd-dense  graphs,  668  pr.  \nFloyd-Warshall  algorithm  for,  6553659  \nJohnson\u2019s  algorithm  for,  6623667  \nby matrix multiplication, 6483655,  6683669  \nby repeated squaring, 6523653  \n\u02db-balanced,  472  pr.  \n\u02db.n/ , 533  \n\u02db-strongly  convex  function,  1041  \nalphabet, 967,  1052  \nalternating path, 705  \namortized analysis, 4483475  \nby accounting method, 4533456  \nby aggregate analysis, 370,  4493453  \nfor  breadth-\u00fbrst  search,  558  \nfor  depth-\u00fbrst  search,  5663567  \nfor  Dijkstra\u2019s  algorithm,  6233624  \nfor  disjoint-set  data  structures,  5253526,  \n527  ex.,  531  ex.,  5343540,  541  ex.  \nfor dynamic tables, 4603471  \nfor  the  Knuth-Morris-Pratt  algorithm,  \n9773978  \nfor making binary search dynamic, 472  pr.  \nby potential method, 4563460  \nfor  Prim\u2019s  algorithm,  597  \nfor  restructuring  red-black  trees,  473  pr.  \nfor shortest paths in a dag, 617  for stacks on secondary storage, 517  pr.  \nfor  weight-balanced  trees,  472  pr.  \namortized cost \nin the accounting method, 453  \nin aggregate analysis, 449  \nin the potential method, 456  \namortized progress, 1028  \nanalysis of algorithms, 25334  \nsee also amortized analysis, competitive \nanalysis, probabilistic analysis \nancestor, 1172  \nlowest common, 543  pr.  \nAND function ( ^), 659,  1065  \nAND gate, 1065  \nand, in pseudocode, 24  \nantiparallel edges, 6733674  \nantisymmetric relation, 1160  \napproximation \nby least squares, 8413845  \nof summation by integrals, 1150  \napproximation algorithm, 110331136  \nfor bin packing, 1131  pr.  \nfor  MAX-CNF  satis\u00fbability,  1124  ex.  \nfor maximum clique, 1131  pr.  \nfor maximum matching, 1132  pr.  \nfor maximum spanning tree, 1134  pr.  \nfor  maximum-weight  cut,  1124  ex.  \nfor  MAX-3-CNF  satis\u00fbability,  112031121  \nfor parallel machine scheduling, 1133  pr.  \nrandomized, 1120  \nfor set cover, 111531119  \nfor subset sum, 112431130  \nfor  traveling-salesperson  problem,  \n110931115  \nfor vertex cover, 110631109,  112131124  \nfor weighted set cover, 1132  pr.  \nfor  0-1  knapsack  problem,  1134  pr.  \napproximation error, 842  \napproximation ratio, 1104,  1120  \napproximation scheme, 1105  \nAPPROX-MIN-WEIGHT-VC,  1123  \nAPPROX-SUBSET-SUM, 1128  \nAPPROX-TSP-TOUR, 1111  \nAPPROX-VERTEX-COVER , 1107  \narbitrage, 641  pr.  \narc, see edge \nargument of a function, 116131162  \narithmetic instructions, 26  1254 Index \narithmetic, modular, 64,  9163923  \narithmetic series, 1141  \narithmetic  with  in\u00fbnities,  611  \narm in a disk drive, 498  \narray \nindexing into, 22323,  26  n.,  252  \ninversion in, 47  pr.  \nMonge, 123  pr.  \npassing as a parameter, 24  \nin pseudocode, 22323  \nstorage of, 26  n.,  252  \narticulation point, 582  pr.  \nassignment \noptimal, 7233739  \nsatisfying, 1066,  1074  \ntruth, 1066,  1073  \nassignment problem, 7233739  \nassociative laws for sets, 1155  \nassociative operation, 917  \nasymptotically larger, 62  \nasymptotically nonnegative, 54  \nasymptotically positive, 54  \nasymptotically smaller, 62  \nasymptotically tight bound, 56  \nasymptotic lower bound, 55  \nasymptotic notation, 53363,  72  pr.  \nand graph algorithms, 548  \nand linearity of summations, 1141  \nasymptotic running time, 49  \nasymptotic upper bound, 54  \nattribute \nin clustering, 1006  \nin a graph, 552  \nof an object, 23  \naugmentation  of a \u00fcow,  678  \naugmented primal linear program, 870  \naugmenting data structures, 4803496  \naugmenting path, 6813682,  705  \nwidest, 700  pr.  \nauthentication, 309  pr.,  9383939,  942  \nautomaton, 9673974  \nauxiliary hash function, 295  \naverage-case  running  time,  32,  128  \nA VL tree, 357  pr.,  358  \nback edge, 569,  573  \nback substitution, 823  balanced search tree \nAA-trees,  358  \nA VL trees, 357  pr.,  358  \nB-trees,  4973519  \nk-neighbor  trees,  358  \nleft-leaning  red-black  binary  search  trees,  \n358  \nred-black  trees,  3313359  \nscapegoat trees, 358  \nsplay trees, 359,  478  \ntreaps, 358  \n2-3-4  trees,  502,  518  pr.  \n2-3  trees,  358,  519  \nweight-balanced  trees,  358,  472  pr.  \nballs and bins, 1433144,  1212  pr.  \nbase- a pseudoprime, 944  \nbase case \nof a divide-and-conquer  algorithm,  34,  76  \nof a recurrence, 41,  77378  \nbase, in DNA, 393  \nbasis function, 841  \nBayes\u2019s  theorem,  1189  \nBELLMAN-FORD, 612  \nBellman-Ford  algorithm,  6123616  \nfor  all-pairs  shortest  paths,  647  \nin Johnson\u2019s  algorithm,  6643666  \nand objective functions, 632  ex.  \nto solve systems of difference constraints, \n6303631  \nYen\u2019s  improvement  to,  640  pr.  \nBernoulli trial, 1196  \nand balls and bins, 1433144  \nin bucket sort analysis, 217  \nin \u00fbnding  prime  numbers,  943  \nin randomized selection analysis, 232  \nand streaks, 1443150  \nbest-case  running  time,  34  ex.  \n\u02c7-smooth  function,  1041  \nBFS, 556  \nsee also breadth-\u00fbrst  search  \nBIASED-RANDOM , 129  ex.  \nbiconnected component, 582  pr.  \nbig-oh  notation  (O), 50,  54355  \nbig-omega  notation  (\ufffd), 51,  54  \u00fbg.,  55356  \nbijective function, 1162  \nbinary character code, 431  Index 1255 \nbinary counter \nanalyzed by accounting method, 455  \nanalyzed by aggregate analysis, 4513453  \nanalyzed by potential method, 4583459  \nbinary entropy function, 1182  \nbinary gcd algorithm, 953  pr.  \nbinary heap, see heap \nbinary logarithm (lg), 66  \nbinary  re\u00fcected  Gray  code,  471  pr.  \nbinary relation, 1158  \nbinary search, 44  ex.  \nwith fast insertion, 472  pr.  \nin insertion sort, 45  ex.  \nin parallel merging, 7773778  \nin searching  B-trees,  512  ex.  \nbinary search tree, 3123330  \nAA-trees,  358  \nA VL trees, 357  pr.,  358  \ndeletion from, 3223325,  326  ex.  \nwith equal keys, 327  pr.  \ninsertion into, 3213322  \nk-neighbor  trees,  358  \nleft-leaning  red-black  binary  search  trees,  \n358  \nmaximum key of, 3173318  \nminimum key of, 3173318  \noptimal, 4003407  \npersistent, 355  pr.  \npredecessor in, 3183319  \nquerying, 3163320  \nrandomly built, 328  pr.  \nred-black  trees,  3313359  \nright-converting  of,  337  ex.  \nscapegoat trees, 358  \nsearching, 3163317  \nfor sorting, 326  ex.  \nsplay trees, 359  \nsuccessor in, 3183319  \nweight-balanced  trees,  358  \nsee also red-black  tree  \nbinary-search-tree  property,  3133314  \nvs.  min-heap  property,  315  ex.  \nbinary tree, 1173  \nfull, 433,  1174  \nnumber of different ones, 329  pr.  \nrepresentation of, 265  \nsee also binary search tree \nbinomial  coef\u00fbcient,  118131182  binomial distribution, 119831201  \nand balls and bins, 143  \nin bucket sort analysis, 217  \nmaximum value of, 1202  ex.  \ntails of, 120331210  \nbinomial expansion, 1181  \nbinomial theorem, 1181  \nbin packing, 1131  pr.  \nbipartite graph, 1167  \ncomplete, 716  \ncorresponding  \u00fcow  network  of,  694  \nd -regular,  716  ex.,  740  pr.  \nmatching in, 6933697,  7043743  \nbipartite matching, 6933697,  7043743  \nbirthday paradox, 1403143  \nbisection of a tree, 1177  pr.  \nbitonic  euclidean  traveling-salesperson  \nproblem, 407  pr.  \nbitonic sequence, 644  pr.  \nbitonic tour, 407  pr.  \nbit operation, 904  \nin Euclid\u2019s  algorithm,  954  pr.  \nbit-reversal  permutation,  897  \nbit vector, 274  ex.  \nblack-height,  332  \nblack vertex, 554,  564  \nblock \nin a cache, 440,  802  \non a disk, 499,  512  ex.,  517  pr.  \nblocking  \u00fcow,  702  \nblocking pair, 716  \nblock representation of matrices, 254  \nblock structure in pseudocode, 21322  \nbody, 1032  \nBoole\u2019s  inequality,  1190  ex.  \nboolean combinational circuit, 1065  \nboolean combinational element, 1065  \nboolean connective, 1073  \nboolean data type, 26  \nboolean formula, 1043,  1060  ex.,  107331074  \nboolean function, 1182  ex.  \nboolean operators, 24  \nBor\u02da  uvka\u2019s  algorithm,  603  \nbottleneck spanning tree, 601  pr.  \nbottleneck  traveling-salesperson  problem,  \n1115  ex.  \nbottoming out, 76  \nbottom of a stack, 254  1256 Index \nBOTTOM-UP-CUT-ROD, 369  \nbottom-up  method,  for  dynamic  programming,  \n368  \nbound \nasymptotically tight, 56  \nasymptotic lower, 55  \nasymptotic upper, 54  \non  binomial  coef\u00fbcients,  118131182  \non binomial distributions, 1201  \npolylogarithmic, 67  \non the tails of a binomial distribution, \n120331210  \nsee also lower bounds \nbounding a summation, 114531152  \nbox, nesting, 640  pr.  \nB C -tree,  501  \nbranch instructions, 26  \nbreadth-\u00fbrst  forest,  728  \nbreadth-\u00fbrst  search,  5543563  \nin the  Hopcroft-Karp  algorithm,  711  \nin the Hungarian algorithm, 7273728  \nin maximum  \u00fcow,  6893691  \nand shortest paths, 5583561,  605  \nsimilarity  to Dijkstra\u2019s  algorithm,  624,  \n625  ex.  \nbreadth-\u00fbrst  tree,  555,  561  \nbridge, 582  pr.  \nB \ue003 -tree,  502  n. \nB-tree,  4973519  \ncompared  with  red-black  trees,  497,  503  \ncreating, 5053506  \ndeletion from, 5133516  \nfull node in, 502  \nheight of, 5023504  \ninsertion into, 5063511  \nminimum degree of, 502  \nproperties of, 5013504  \nsearching, 5043505  \nsplitting a node in, 5063508  \n2-3-4  trees,  502  \nB-T REE-CREATE , 506  \nB-T REE-DELETE , 513  \nB-T REE-I NSERT , 508  \nB-T REE-I NSERT-NONFULL , 511  \nB-T REE-SEARCH , 505,  512  ex.  \nB-T REE-SPLIT-CHILD , 507  \nB-T REE-SPLIT-ROOT, 509  BUBBLESORT , 46  pr.  \nbucket, 215  \nbucket sort, 2153219  \nBUCKET-SORT, 216  \nBUILD-MAX-HEAP, 167  \nBUILD-MAX-HEAP 0 , 179  pr.  \nBUILD-MIN-HEAP, 169  \nBurrows-Wheeler  transform  (BWT),  1000  pr.  \nbutter\u00fcy  operation,  894  \nBWT  (Burrows-Wheeler  transform),  1000  pr.  \nby, in pseudocode, 22 \ncache, 27,  301,  440,  802  \ncache block, 301,  440,  802  \ncache hit, 440,  803  \ncache line, see cache block \ncache miss, 440,  803  \ncache obliviousness, 519  \ncaching \nof\u00fcine,  4403446  \nonline, 8023815  \ncall \nin a parallel computation, 753  \nof a subroutine, 26,  29  n. \nby value, 23  \ncancellation lemma, 886  \ncancellation  of \u00fcow,  679  \ncapacity \nof a cut, 682  \nof an edge, 671  \nresidual, 677,  681  \nof a vertex, 676  ex.  \ncapacity constraint, 672  \ncardinality of a set ( j j), 1156  \nCarmichael number, 945,  953  ex.  \nCartesian product ( \ue005), 1157  \nCartesian sum, 885  ex.  \nCatalan numbers, 329  pr.,  375  \nCBC-MAC,  291,  306  \nc-competitive,  793  \nceiling function ( d e), 63  \nin recurrences, 1163117  \nceiling instruction, 26  \ncenter of a cluster, 1008  \ncentralized scheduler, 759  \ncentroid of a cluster, 1009  \ncertain event, 1185  Index 1257 \ncerti\u00fbcate  \nin a cryptosystem, 942  \nfor  veri\u00fbcation  algorithms,  1058  \nCHAINED-HASH-DELETE , 278  \nCHAINED-HASH-I NSERT , 278  \nCHAINED-HASH-SEARCH , 278  \nchaining, 2773281,  308  pr.  \nchanging variables, to solve a recurrence, \n120  pr.  \ncharacter code, 431  \ncharacter data type, 26  \nchess-playing  program,  7683769  \nchild \nin a binary tree, 1173  \nin a parallel computation, 753  \nin a rooted tree, 1172  \nChinese remainder theorem, 9283931  \nchirp transform, 893  ex.  \nchoose \u00e3 n \nk \u00e4 \n, 1180  \nchord, 486  ex.  \nCilk, 750,  790  \nciphertext, 938  \ncircuit \nboolean combinational, 1065  \ndepth of, 894  \nfor fast Fourier transform, 8943897  \nCIRCUIT-SAT,  1067  \ncircuit  satis\u00fbability,  106431071  \ncircular, doubly linked list with a sentinel, 262  \ncircular linked list, 259  \nclass \ncomplexity, 1054  \nequivalence, 1159  \nclassi\u00fbcation  of edges  \nin breadth-\u00fbrst  search,  581  pr.  \nin depth-\u00fbrst  search,  5693570,  571  ex.  \nclause, 107531076  \nclean area, 222 pr. \nclimate change, 845  \nclique, 1081  \nCLIQUE,  1081  \nclique problem \napproximation algorithm for, 1131  pr.  \nNP-completeness  of,  108131084  \nclosed convex body, 1032  \nclosed interval ( \u0152a; b\ufffd ), 1157  \nclosed semiring, 669  \nclosest-point  heuristic,  1115  ex.  closure \ngroup property, 917  \nof a language ( \ue003 ), 1052  \ntransitive, see transitive closure \ncluster, 1008  \nfor parallel computing, 748  \nclustering, 100531013  \nLloyd\u2019s  procedure  for,  101131013  \nprimary, 303  \nCNF (conjunctive normal form), 1043,  1076  \nCNF  satis\u00fbability,  1124  ex.  \ncoarsening leaves of recursion \nin merge sort, 45  pr.  \nin quicksort, 198  ex.  \nwhen recursively spawning, 764  \ncode, 4313432  \nHuffman, 4313439  \ncodeword, 432  \ncodomain, 1161  \ncoef\u00fbcient  \nbinomial, 1181  \nof a polynomial, 65,  877  \ncoef\u00fbcient  representation,  879  \nand fast multiplication, 8823884  \ncofactor, 1221  \ncoin changing, 446  pr.  \ncoin  \u00fcipping,  1313132  \ncollection of sets, 1156  \ncollision, 275  \nresolution by chaining, 2773281  \nresolution by open addressing, 2933301  \ncollision-resistant  hash  function,  941  \ncoloring, 425  ex.,  1100  pr.,  1176  pr.  \ncolor,  of a red-black-tree  node,  331  \ncolumn-major  order,  222  pr.,  253  \ncolumn rank, 1220  \ncolumnsort, 222 pr. \ncolumn vector, 1215  \ncombination, 1180  \ncombinational circuit, 1065  \ncombinational element, 1065  \ncombine  step,  in divide-and-conquer,  34,  76  \ncomment, in pseudocode ( / /), 22 \ncommodity, 864  \ncommon divisor, 906  \ngreatest, see greatest common divisor \ncommon multiple, 916  ex.  \ncommon subexpression, 894  1258 Index \ncommon subsequence, 394  \nlongest, 3933399  \ncommutative laws for sets, 1154  \ncommutative operation, 917  \ncompact list, 269  pr.  \nCOMPACT-LIST-SEARCH , 269  pr.  \nCOMPACT-LIST-SEARCH 0 , 270  pr.  \nCOMPARE-EXCHANGE , 222 pr. \nCOMPARE-EXCHANGE-I NSERTION-SORT, \n223  pr.  \ncompare-exchange  operation,  222 pr. \ncomparison sort, 205  \nand binary search trees, 315  ex.  \nrandomized, 219  pr.  \nand selection, 241  \ncompatible activities, 418  \ncompatible matrices, 1218  \ncompetitive analysis, 792  \ncompetitive ratio, 793  \nexpected, 808  \nunbounded, 804  \ncomplement \nof an event, 1186  \nof a graph, 1085  \nof a language, 1052  \nSchur, 825,  839  \nof a set, 1155  \ncomplementary slackness, 873  pr.  \ncomplete graph, 1167  \nbipartite, 716  \ncomplete k-ary  tree,  1174  \nsee also heap \ncompleteness of a language, 1072  ex.  \ncomplete step, 759  \ncompletion time, 446  pr.,  816  pr.,  1133  pr.  \nCOMPLETION -TIME-SCHEDULE , 817  pr.  \ncomplexity class, 1054  \nco-NP,  1059  \nNP, 1043,  1058,  1060  ex.  \nNPC, 1044,  1063  \nP, 1043,  1050,  1054,  1055  ex.  \ncomplexity measure, 1054  \ncomplex numbers \ninverting matrices of, 838  ex.  \nmultiplication of, 90 ex. \ncomplex root of unity, 885  \ninterpolation at, 8913892  component \nbiconnected, 582  pr.  \nconnected, 1166  \nstrongly connected, 1166  \ncomponent graph, 576  \ncomposite number, 905  \nwitness to, 946  \ncomposition \nof logarithms, 66  \nof parallel traces, 762  \u00fbg.  \ncompression \nby Huffman code, 4313439  \nof images, 412  pr.  \ncompulsory miss, 440  \ncomputational depth, see span \ncomputational problem, 536  \ncomputation dag, 754  n. \nCOMPUTE-LCP,  993  \nCOMPUTE-PREFIX-FUNCTION , 978  \nCOMPUTE-SUFFIX-ARRAY , 988  \nCOMPUTE-TRANSITION-FUNCTION , 974  \nconcatenation \nof languages, 1052  \noperator ( k), 291  \nof strings, 959  \nconcrete problem, 1049  \nconditional branch instruction, 26  \nconditional independence, 1190  ex.  \nconditional probability, 1187,  1189  \ncon\u00fbguration,  1068  \nconjugate of the golden ratio ( y \ufffd), 69,  70  ex.  \nconjugate transpose, 838  ex.  \nconjunctive normal form, 1043,  1076  \nconnected component, 1166  \nidenti\u00fbed  using  depth-\u00fbrst  search,  572  ex.  \nidenti\u00fbed  using  disjoint-set  data  structures,  \n5213523  \nCONNECTED-COMPONENTS , 522  \nconnected graph, 1166  \nconnective, 1073  \nco-NP  (complexity  class),  1059  \nconquer  step,  in divide-and-conquer,  34,  76  \nconservation  of \u00fcow,  672  \nconsistency \nof literals, 1082  \nsequential, 756  \nconstrained gradient descent, 103231034  Index 1259 \nconstraint \ndifference, 627  \nequality, 632  ex.  \nlinear, 851,  8533854  \nnonnegativity, 854  \nconstraint graph, 6283630  \ncontain, in a path, 1165  \ncontinuous master theorem, 112  \nproof of, 1073115  \ncontinuous uniform probability distribution, \n1187  \ncontraction \nof a dynamic table, 4653470  \nof an undirected graph by an edge, 1168  \ncontraction algorithm, 701  pr.  \ncontrol instructions, 26  \nconvergence property, 611,  6343635  \nconvergent series, 1140  \nconverting binary to decimal, 910  ex.  \nconvex body, 1032  \nconvex function, 102531027,  1194  \n\u02db-strongly  convex,  1041  \nconvex set, 675  ex.  \nconvolution ( \u02dd), 880  \nconvolution theorem, 892  \ncopy instruction, 26  \ncorrectness of an algorithm, 6 \ncorresponding  \u00fcow  network  for  bipartite  \nmatching, 694  \ncountably  in\u00fbnite  set,  1156  \ncounter, see binary counter \ncounting, 117831184  \nprobabilistic, 153  pr.  \ncounting sort, 2083211  \nin computing  suf\u00fbx  arrays,  992 \nin radix sort, 213  \nCOUNTING-SORT, 209 \ncoupon  collector\u2019s  problem,  144  \ncover \npath, 698  pr.  \nby a subfamily, 1116  \nvertex, 1084,  1106  \ncredit, 453  \ncritical edge, 690  \ncritical path \nin a dag, 619  \nof a PERT chart, 617  \nof a task-parallel  trace,  757  cross a cut, 587,  701  pr.  \ncross edge, 569  \ncryptographic hash function, 291  \ncryptosystem, 9363942  \ncubic spline, 847  pr.  \ncurrency exchange, 641  pr.  \ncurve  \u00fbtting,  8413845  \ncut \ncapacity of, 682  \nof a \u00fcow  network,  6823685  \nglobal, 701  pr.  \nminimum, 682  \nnet  \u00fcow  across,  682  \nof an undirected graph, 587  \nweight of, 1124  ex.  \nCUT-ROD, 366  \ncycle of a graph, 116531166  \nhamiltonian, 1043,  1056,  108531090  \nminimum  mean-weight,  642  pr.  \nnegative-weight,  see negative-weight  cycle  \nand shortest paths, 6073608  \ncycle cover, 741  pr.  \ncyclic group, 932  \ndag, see directed acyclic graph \nDAG-SHORTEST-PATHS , 617  \nd -ary  heap,  179  pr.  \nin shortest-paths  algorithms,  668  pr.  \ndata-movement  instructions,  26  \ndata-parallel  model,  789  \ndata science, 14315  \ndata structure, 9, 2493359,  4773545  \nAA-trees,  358  \naugmentation of, 4803496  \nA VL trees, 357  pr.,  358  \nbinary search trees, 3123330  \nbit vectors, 274  ex.  \nB-trees,  4973519  \ndeques, 258  ex.  \ndictionaries, 249  \ndirect-address  tables,  2733275  \nfor disjoint sets, 5203545  \nfor dynamic graphs, 479  \ndynamic sets, 2493251  \ndynamic trees, 478  \nexponential search trees, 226,  478  \nFibonacci heaps, 478  \nfusion trees, 226,  478  1260 Index \ndata structure, continued  \nhash tables, 2753282  \nheaps, 1613181  \ninterval trees, 4893495  \nk-neighbor  trees,  358  \nleft-leaning  red-black  binary  search  trees,  \n358  \nlinked lists, 2583264  \norder-statistic  trees,  4803486  \npersistent, 355  pr.,  478  \npotential of, 456  \npriority queues, 1723178  \nqueues, 254,  2563257  \nradix trees, 327  pr.  \nred-black  trees,  3313359  \nrooted trees, 2653268  \nscapegoat trees, 358  \non secondary storage, 4983501  \nskip lists, 359  \nsplay trees, 359,  478  \nstacks, 2543255  \ntreaps, 358  \n2-3-4  trees,  502,  518  pr.  \n2-3  trees,  358,  519  \nvan Emde Boas trees, 478  \nweight-balanced  trees,  358  \ndata type, 26  \ndecision by an algorithm, 1053  \ndecision problem, 1045,  1049  \nand optimization problems, 1045  \ndecision tree, 2063207,  219  pr.  \ndecision variable, 851  \nDECREASE-KEY, 173  \ndecrementing, 22 \ndecryption, 936  \ndefault vertex labeling, 724  \ndegree \nminimum,  of a B-tree,  502  \nof a node, 1173  \nof a polynomial, 65,  877  \nof a vertex, 1165  \ndegree-bound,  877  \nDELETE , 250  \nDELETE-LARGER-HALF, 460  ex.  \ndeletion \nfrom binary search trees, 3223325,  326  ex.  \nfrom  B-trees,  5133516  \nfrom chained hash tables, 278  from  direct-address  tables,  274  \nfrom dynamic tables, 4653470  \nfrom hash tables with linear probing, \n3023303  \nfrom heaps, 178  ex.  \nfrom interval trees, 491  \nfrom linked lists, 261  \nfrom  open-address  hash  tables,  2943295  \nfrom  order-statistic  trees,  4843485  \nfrom queues, 256  \nfrom  red-black  trees,  3463355  \nfrom stacks, 254  \nDeMorgan\u2019s  laws  \nfor propositional logic, 1078  \nfor sets, 1155,  1158  ex.  \ndense graph, 549  \n\ufffd-dense,  668  pr.  \ndense matrix, 81  \ndensity \nof prime numbers, 943  \nof a rod, 372  ex.  \ndependence \nand indicator random variables, 131  \nlinear, 1220  \nsee also independence \ndepth \naverage, of a node in a randomly built binary \nsearch tree, 328  pr.  \nof a circuit, 894  \nof a node in a rooted tree, 1173  \nof quicksort recursion tree, 191  ex.  \nof a stack, 202 pr. \ndepth-determination  problem,  542  pr.  \ndepth-\u00fbrst  forest,  564  \ndepth-\u00fbrst  search,  5633572  \nin \u00fbnding  articulation  points,  bridges,  and  \nbiconnected components, 582  pr.  \nin \u00fbnding  strongly  connected  components,  \n5763581  \nin the  Hopcroft-Karp  algorithm,  711  \nin topological sorting, 5733576  \ndepth-\u00fbrst  tree,  564  \ndeque, 258  ex.  \nDEQUEUE , 257  \nderivative of a series, 1142  \ndescendant, 1172  \ndestination vertex, 605  \ndet, 1221  Index 1261 \ndeterminacy race, 7653768  \ndeterminant, 1221  \ndeterministic algorithm, 135  \nparallel, 765  \nDETERMINISTIC -SEARCH , 154  pr.  \nDFS, 565  \nsee also depth-\u00fbrst  search  \nDFS-V ISIT, 565  \nDFT, 888  \ndiagonal matrix, 1215  \ndiameter \nof a network, 646  \nof a tree, 563  ex.  \ndictionary, 249  \ndifference \nof sets ( \ue003), 1154  \nsymmetric, 706  \ndifference constraints, 6263632  \ndifferentiation of a series, 1142  \ndigital signature, 938  \ndigraph, see directed graph \nDIJKSTRA , 620  \nDijkstra\u2019s  algorithm,  6203626  \nfor  all-pairs  shortest  paths,  646,  666  \nwith edge weights in a range, 626  ex.  \nimplemented with a Fibonacci heap, \n6233624  \nimplemented  with  a min-heap,  623  \nwith integer edge weights, 6253626  ex.  \nin Johnson\u2019s  algorithm,  664  \nsimilarity  to breadth-\u00fbrst  search,  624,  \n625  ex.  \nsimilarity  to Prim\u2019s  algorithm,  624  \nd -independent  family  of hash  functions,  288  \nDIRECT-ADDRESS-DELETE , 274  \ndirect addressing, 2733275  \nDIRECT-ADDRESS-I NSERT , 274  \nDIRECT-ADDRESS-SEARCH , 274  \ndirect-address  table,  2733275  \ndirected acyclic graph (dag), 1167  \nand back edges, 573  \nand component graphs, 578  \nand hamiltonian paths, 1060  ex.  \nlongest simple path in, 407  pr.  \nfor representing a parallel computation, 754  \nsingle-source  shortest-paths  algorithm  for,  \n6163619  \ntopological sort of, 5733576  directed equality subgraph, 727  \ndirected graph, 1164  \nall-pairs  shortest  paths  in,  6463669  \nconstraint graph, 628  \nEuler tour of, 583  pr.,  1043  \nhamiltonian cycle of, 1043  \nincidence matrix of, 553  ex.  \nand longest paths, 1042  \npath cover of, 698  pr.  \nPERT chart, 617,  619  ex.  \nsemiconnected, 581  ex.  \nshortest path in, 604  \nsingle-source  shortest  paths  in,  6043645  \nsingly connected, 572  ex.  \nsquare of, 553  ex.  \ntransitive closure of, 659  \ntranspose of, 553  ex.  \nuniversal sink in, 553  ex.  \nsee also directed acyclic graph, graph, \nnetwork \ndirected version of an undirected graph, 1166  \ndirty area, 222 pr. \ndiscovered vertex, 554,  564  \ndiscovery time, 565  \ndiscrete Fourier transform, 888  \ndiscrete logarithm, 933  \ndiscrete logarithm theorem, 933  \ndiscrete probability distribution, 1186  \ndiscrete random variable, 119131196  \ndisjoint-set  data  structure,  5203545  \nanalysis of, 5343540  \nin connected components, 5213523  \nin depth determination, 542  pr.  \ndisjoint-set-forest  implementation  of,  \n5273531  \nin Kruskal\u2019s  algorithm,  593  \nlinear-time  special  case  of,  545  \nlinked-list  implementation  of,  5233527  \nlower bound for, 545  \nin of\u00fcine  lowest  common  ancestors,  543  pr.  \nin of\u00fcine  minimum,  541  pr.  \ndisjoint-set  forest,  5273531  \nanalysis of, 5343540  \nrank properties of, 5333534,  540  ex.  \nsee also disjoint-set  data  structure  \ndisjoint sets, 1156  \ndisjunctive normal form, 1078  1262 Index \ndisk drive, 4983500  \nsee also secondary storage \nDISK-READ, 500  \nDISK-WRITE , 500  \ndissimilarity, 1006  \ndistance \nedit, 409  pr.  \nManhattan, 244  pr.  \nof a shortest path ( \u0131), 558  \ndistributed memory, 748  \ndistribution \nbinomial, see binomial distribution \ncontinuous uniform, 1187  \ndiscrete, 1186  \ngeometric, see geometric distribution \nof inputs, 128,  134  \nof prime numbers, 943  \nprobability, 218  ex.,  1185  \nuniform, 1186  \ndistributive laws for sets, 1155  \ndivergent series, 1140  \ndivide-and-conquer  method,  34,  76  \nanalysis of, 39341,  903119  \nfor binary search, 44  ex.  \nfor conversion of binary to decimal, 910  ex.  \nfor fast Fourier transform, 8883891,  895  \nfor matrix inversion, 8343837  \nfor matrix multiplication, 81390,  7703775,  \n783  pr.  \nfor merge sort, 34344,  7753782  \nfor multiplication, 899  pr.  \nfor quicksort, 1823204  \nrelation to dynamic programming, 362  \nfor selection, 2303243  \nsolving recurrences for, 903119  \nfor  Strassen\u2019s  algorithm,  85390,  7733774  \ndivide instruction, 26  \ndivides relation ( j), 904  \ndivide  step,  in divide-and-conquer,  34,  76  \ndivision method, 284,  292  ex.  \ndivision theorem, 905  \ndivisor, 904  \ncommon, 906  \nsee also greatest common divisor \nDNA, 6, 3933394,  409  pr.  \nDNF (disjunctive normal form), 1078  \ndoes-not-divide  relation  (\u2212), 904  \nDog River, 717  dolphins, allowing to vote, 850  \ndomain, 1161  \ndouble hashing, 2953297,  301  ex.  \ndoubly linked list, 2583259,  264  ex.  \ncircular, with a sentinel, 262  \ndownto , in pseudocode, 22 \nd -regular  graph,  716  ex.,  740  pr.  \ndriving function, 101  \nduality, 734,  8663873,  874  pr.  \nweak, 8683869,  874  pr.  \ndual linear program, 866  \ndummy key, 400  \ndynamic graph, 523  \nall-pairs  shortest  paths  algorithms  for,  669  \ndata structures for, 479  \nminimum-spanning-tree  algorithm  for,  \n599  ex.  \ntransitive closure of, 667  pr.,  669  \ndynamic graph algorithm, 817  \ndynamic multiset, 460  ex.  \ndynamic order statistics, 4803486  \ndynamic-programming  method,  3623416  \nfor activity selection, 424  ex.  \nfor  all-pairs  shortest  paths,  6483659  \nfor  bitonic  euclidean  traveling-salesperson  \nproblem, 407  pr.  \nbottom-up,  368  \nfor breaking a string, 412  pr.  \ncompared with greedy method, 3843385,  \n393  ex.,  421,  4263430  \nfor edit distance, 409  pr.  \nelements of, 3823393  \nfor  Floyd-Warshall  algorithm,  6553659  \nfor inventory planning, 414  pr.  \nfor longest common subsequence, 3933399  \nfor longest palindrome subsequence, 407  pr.  \nfor longest simple path in a weighted \ndirected acyclic graph, 407  pr.  \nfor  matrix-chain  multiplication,  3733382  \nand memoization, 3903392  \nfor optimal binary search trees, 4003407  \noptimal substructure in, 3823387  \noverlapping subproblems in, 3873390  \nfor printing neatly, 408  pr.  \nreconstructing an optimal solution in, 390  \nrelation  to divide-and-conquer,  362  \nfor rod cutting, 3633373  \nfor seam carving, 412  pr.  Index 1263 \ndynamic-programming  method,  continued  \nfor signing free agents, 414  pr.  \ntop-down  with  memoization,  368  \nfor transitive closure, 6593661  \nfor Viterbi algorithm, 411  pr.  \nfor  the  0-1  knapsack  problem,  430  ex.  \ndynamic set, 2493251  \nsee also data structure \ndynamic table, 4603471  \nanalyzed by accounting method, 463  \nanalyzed by aggregate analysis, 4623463  \nanalyzed by potential method, 4633470  \nload factor of, 461  \ndynamic tree, 478  \nE \u0152 \ufffd, see expected value \ne (base of the natural logarithm), 65  \nedge, 1164  \nantiparallel, 6733674  \nattributes of, 552  \nback, 569  \nbridge, 582  pr.  \ncapacity of, 671  \nclassi\u00fbcation  in breadth-\u00fbrst  search,  581  pr.  \nclassi\u00fbcation  in depth-\u00fbrst  search,  5693570,  \n571  ex.  \ncritical, 690  \ncross, 569  \nforward, 569  \nlight, 587  \nnegative-weight,  6063607  \nresidual, 678  \nsafe, 587  \ntree, 561,  564,  569  \nweight of, 551  \nedge connectivity, 692  ex.  \nedge set, 1164  \nedit distance, 409  pr.  \nEdmonds-Karp  algorithm,  6893691  \nelementary event, 1185  \nelementary insertion, 461  \nelement of a set ( 2), 1153  \nellipsoid algorithm, 857  \nelliptic-curve  factorization  method,  956  \nelseif , in pseudocode, 22 n. \nelse, in pseudocode, 22 \nempty language ( ;), 1052  \nempty set ( ;), 1153  empty set laws, 1154  \nempty stack, 255  \nempty string ( \"), 959,  1052  \nempty tree, 1173  \nencoding of problem instances, 104931052  \nencryption, 936  \nendpoint of an interval, 489  \nENQUEUE , 257  \nentering a vertex, 1164  \nentropy function, 1182  \nepoch, 805  \n\ufffd-dense  graph,  668  pr.  \n\ufffd-universal  family  of hash  functions,  287,  \n292 ex. \nequality \nof functions, 1162  \nlinear, 853  \nof sets, 1153  \nequality constraint, 632  ex.  \nequality subgraph, 724  \ndirected, 727  \nequations and asymptotic notation, 58359  \nequivalence class, 1159  \nmodulo n (\u0152a\ufffd  n ), 905  \nequivalence, modular ( D (mod n)), 64  \nequivalence relation, 1159  \nerror bound, 1027  \nerror , in pseudocode, 24  \nescape problem, 697  pr.  \nEUCLID , 912  \nEuclid\u2019s  algorithm,  9113916,  954  pr.  \neuclidean norm ( k k), 1219  \nEuler\u2019s  constant,  921  \nEuler\u2019s  phi  function,  920 \nEuler\u2019s  theorem,  932,  953  ex.  \nEuler tour, 583  pr.,  740  pr.  \nand hamiltonian cycles, 1043  \nevaluation of a polynomial, 46  pr.,  879,  884  ex.  \nderivatives of, 900 pr. \nat multiple points, 900 pr. \nevent, 1185  \nevent-driven  simulation,  173,  181  \nEXACT-SUBSET-SUM, 1125  \nexample, in clustering, 1006  \nexclusion and inclusion, 1158  ex.  \nexecute a subroutine, 29 n. \nexpansion of a dynamic table, 4613465  \nexpectation, see expected value 1264 Index \nexpected competitive ratio, 808  \nexpected running time, 32,  129  \nexpected value, 119231194  \nof a binomial distribution, 1198  \nof a geometric distribution, 1197  \nof an indicator random variable, 130  \nexplored edge, 565  \nexponential function, 65366  \nexponential search tree, 226,  478  \nexponentiation \nof logarithms, 66  \nmodular, 9343935  \nexponentiation instruction, 27  \nEXTENDED-BOTTOM-UP-CUT-ROD, 372  \nEXTENDED-EUCLID , 914  \nEXTEND-SHORTEST-PATHS , 650  \nexternal node, 1172  \nexternal path length, 1175  ex.  \nextracting the maximum key \nfrom d -ary  heaps,  179  pr.  \nfrom  max-heaps,  174  \nextracting the minimum key \nfrom Young tableaus, 179  pr.  \nEXTRACT-MAX, 1733174  \nEXTRACT-MIN, 173  \nfactor, 904  \ntwiddle, 891  \nfactorial function ( \u0160), 67368  \nfactorization, 956  \nunique, 909 \nfailure, in a Bernoulli trial, 1196  \nfair coin, 1186  \nfamily of hash functions, 2863288,  292  ex.  \nfan-out,  1066  \nFarkas\u2019s  lemma,  869  \nFASTER-APSP,  653,  655  ex.  \nfast Fourier transform (FFT), 8773902  \ncircuit for, 8943897  \nmultidimensional, 899  pr.  \nrecursive implementation of, 8883891  \nusing modular arithmetic, 901  pr.  \nfeasibility problem, 627,  873  pr.  \nfeasible linear program, 854  \nfeasible region, 854  \nfeasible solution, 627,  854  \nfeasible vertex labeling, 724,  742  pr.  \nfeature vector, 1006  Fermat\u2019s  theorem,  932  \nFFT, 890  \nsee also fast Fourier transform \nFFTW, 902 \nFIB, 751  \nFibonacci heap, 478  \nin Dijkstra\u2019s  algorithm,  6233624  \nin Johnson\u2019s  algorithm,  666  \nin Prim\u2019s  algorithm,  597  \nFibonacci numbers, 69,  70  ex.,  121  pr.  \ncomputation of, 7503753,  954  pr.  \nFIFO,  see \u00fbrst-in,  \u00fbrst-out;  queue  \n\u00fbnal-state  function,  968  \nFIND-AUGMENTING -PAT H, 738  \nFIND-DEPTH , 542  pr.  \n\u00fbnd  path,  528  \nFIND-POM,  496  pr.  \nFIND-SET, 521  \ndisjoint-set-forest  implementation  of,  530,  \n544  \nlinked-list  implementation  of,  523  \nFIND-SPLIT-POINT , 778  \n\u00fbnished  vertex,  564  \n\u00fbnish  time  \nin activity selection, 418  \nin depth-\u00fbrst  search,  565  \nand strongly connected components, 578  \n\u00fbnite  automaton,  9673975  \nFINITE-AUTOMATON-MATCHER , 971  \n\u00fbnite  group,  917  \n\u00fbnite  sequence,  1162  \n\u00fbnite  set,  1156  \n\u00fbnite  sum,  1140  \n\u00fbrst-\u00fbt  heuristic,  1131  pr.  \n\u00fbrst-in,  \u00fbrst-out  (FIFO),  254,  8033804,  814  ex.  \nimplemented with a priority queue, 178  ex.  \nsee also queue \n\u00fbxed-length  code,  432  \n\u00fcoating-point  data  type,  26  \n\u00fcoor  function  (b c), 63  \nin recurrences, 1163117  \n\u00fcoor  instruction,  26  \n\u00fcow,  6713676  \naggregate, 864  \naugmentation of, 678  \nblocking, 702  \ncancellation of, 679  \ninteger-valued,  695  Index 1265 \n\u00fcow,  continued  \nnet, across a cut, 682  \nvalue of, 672  \n\u00fcow  conservation,  672  \n\u00fcow  network,  6713676  \ncorresponding to a bipartite graph, 694  \ncut of, 6823685  \nwith multiple sources and sinks, 674  \nFLOYD-WARSHALL , 657  \nFLOYD-WARSHALL 0 , 661  ex.  \nFloyd-Warshall  algorithm,  6553659,  \n6613662  ex.  \n\u00fcying  cars,  highways  for,  850  \nFORD-FULKERSON , 686  \nFord-Fulkerson  method,  6763693  \nFORD-FULKERSON-METHOD , 676  \nFORESEE , 797  \nforest, 1167,  1169  \nbreadth-\u00fbrst,  728  \ndepth-\u00fbrst,  564  \ndisjoint-set,  5273531  \nfor, in pseudocode, 22 \nand loop invariants, 21  n. \nfork-join  parallelism,  7493770  \nsee also parallel algorithm \nfork-join  scheduling,  7593761,  769  ex.  \nformal power series, 121  pr.  \nformula  satis\u00fbability,  107331076  \nforward edge, 569  \nforward substitution, 8223823  \nFourier transform, see discrete Fourier \ntransform, fast Fourier transform \nfractional knapsack problem, 429  \nfractional matching, 741  pr.  \nfree tree, 1167,  116931171  \nfrequency count, 802  ex.  \nfrequency domain, 877  \nfull binary tree, 1174  \nrelation to optimal code, 433  \nfull node, 502  \nfull rank, 1220  \nfull walk of a tree, 1112  \nfully  parenthesized  matrix-chain  product,  374  \nfully  polynomial-time  approximation  scheme,  \n1105  \nfor subset sum, 112431130  function, 116131163  \nAckermann\u2019s,  544  \n\u02db-strongly  convex,  1041  \nbasis, 841  \n\u02c7-smooth,  1041  \nboolean, 1182  ex.  \nconvex, 102531027,  1194  \ndriving, 101  \n\u00fbnal-state,  968  \nhash, see hash function \niterated, 68,  74  pr.  \nlinear, 30,  853  \nobjective, 626,  852,  854  \npotential, 456  \npre\u00fbx,  9753977  \nprobability distribution, 218  ex.  \nquadratic, 31  \nreduction, 1062  \nsuf\u00fbx,  968  \ntransition, 967,  9733974  \nwatershed, 103  \nfunctional iteration, 68  \nfundamental theorem of linear programming, \n872  \nfurthest-in-future,  441  \nfusion tree, 226,  478  \nfuzzy sorting, 203  pr.  \nGabow\u2019s  scaling  algorithm  for  single-source  \nshortest paths, 641  pr.  \ngadget, 1086,  1097  \nGALE-SHAPLEY , 719  \nGale-Shapley  algorithm,  7183722  \nGalois  \u00fbeld  of two  elements  (GF.2/), 1224  pr.  \ngap character, 961  ex.,  975  ex.  \ngate, 1065  \nGaussian  elimination,  825  \ngcd, see greatest common divisor \nGCD  recursion  theorem,  911  \ngeneral arithmetic series, 1141  \ngeneral  number-\u00fbeld  sieve,  956  \ngenerating function, 121  pr.  \ngeneration of partitioned sets, 234  \ngenerator \nof a subgroup, 922 \nof Z \ue003 \nn , 932  1266 Index \nGENERIC-MST,  587  \ngeometric distribution, 119631198  \nand balls and bins, 1433144  \nin \u00fbnding  prime  numbers,  943  \nin randomized selection analysis, 232  \ngeometric series, 1142  \nGF.2/  (Galois  \u00fbeld  of two  elements),  1224  pr.  \nglobal cut, 701  pr.  \nglobal minimizer, 1022,  1024  \u00fbg.,  1026  \u00fbg.  \nglobal variable, 22 \ngolden ratio ( \ufffd), 69,  70  ex.  \ngossiping, 475  \ngradient descent, 102231038  \nconstrained, 103231034  \nin machine learning, 103531037  \nfor solving systems of linear equations, \n103431035  \nstochastic, 1040  pr.  \nunconstrained, 102331031  \nGRADIENT-DESCENT , 1025  \nGRADIENT-DESCENT-CONSTRAINED , 1032  \ngradient of a function, 1023  \nGRAFT , 542  pr.  \ngrain size in a parallel algorithm, 783  pr.  \ngraph, 116431169  \nadjacency-list  representation  of,  5503551  \nadjacency-matrix  representation  of,  5513552  \nand asymptotic notation, 548  \nattributes of, 548,  552  \nbreadth-\u00fbrst  search  of,  5543563  \ncoloring of, 1100  pr.  \ncomplement of, 1085  \ncomponent, 576  \nconstraint, 6283630  \ndense, 549  \ndepth-\u00fbrst  search  of,  5633572  \ndynamic, 523,  817  \n\ufffd-dense,  668  pr.  \nhamiltonian, 1056  \ninterval, 425  ex.  \nmatching in, 6933697,  7043743  \nnonhamiltonian, 1056  \nplanar, 584  pr.  \nregular, 716  ex.,  740  pr.  \nshortest path in, 558  \nsingly connected, 572  ex.  \nsparse, 549  \nstatic, 522  subproblem, 3703371  \ntour of, 1090  \nweighted, 551  \nsee also directed acyclic graph, directed \ngraph,  \u00fcow  network,  undirected  graph,  \ntree \nGRAPH-ISOMORPHISM,  1060  ex.  \nGray  code,  471  pr.  \ngray vertex, 554,  564  \ngreatest common divisor (gcd), 9063907,  \n910  ex.  \nbinary gcd algorithm for, 953  pr.  \nEuclid\u2019s  algorithm  for,  9113916,  954  pr.  \nwith more than two arguments, 916  ex.  \nrecursion theorem for, 911  \nGREEDY-ACTIVITY-SELECTOR , 424  \nGREEDY-BIPARTITE-MATCHING , 726  \ngreedy-choice  property,  4273428  \nof activity selection, 4203421  \nof Huffman codes, 4363437  \nof of\u00fcine  caching,  4423445  \ngreedy method, 4173447  \nfor activity selection, 4183425  \nfor coin changing, 446  pr.  \ncompared with dynamic programming, \n3843385,  393  ex.,  421,  4263430  \nDijkstra\u2019s  algorithm,  6203626  \nelements of, 4263431  \nfor the fractional knapsack problem, 429  \ngreedy-choice  property  in,  4273428  \nfor Huffman code, 4313439  \nKruskal\u2019s  algorithm,  5923594  \nfor maximal bipartite matching, 726  \nfor minimum spanning tree, 5913599  \nfor  of\u00fcine  caching,  4403446  \noptimal substructure in, 428  \nPrim\u2019s  algorithm,  5943597  \nfor set cover, 111531119  \nfor  task-parallel  scheduling,  7593761,  \n769  ex.  \nfor task scheduling, 446  pr.  \nfor weighted set cover, 1132  pr.  \ngreedy scheduler, 759  \nGREEDY-SET-COVER , 1117  \ngrid, 697  pr.  \ngroup, 9163923  \ncyclic, 932  \noperator ( \u02da), 917  Index 1267 \ngrowth step, 736  \nguessing the solution, in the substitution \nmethod, 92 \nHabanero-Java,  750  \nhalf  3-CNF  satis\u00fbability,  1099  ex.  \nhalf-open  interval  (\u0152a; b/  or .a; b\ufffd ), 1157  \nHall\u2019s  theorem,  715  ex.  \nhalting, 6 \nhalting problem, 1042  \nhalving lemma, 887  \nHAM-CYCLE,  1056  \nhamiltonian cycle, 1043,  1056  \nNP completeness of, 108531090  \nhamiltonian graph, 1056  \nhamiltonian path, 1060  ex.,  1098  ex.  \nHAM-PATH,  1060  ex.  \nhandle, 173  \nhandshaking lemma, 1168  ex.  \nharmonic number, 1142,  1149  \nharmonic series, 1142,  1149  \nHASH-DELETE , 300  ex.  \nhash function, 275,  2823292  \nauxiliary, 295  \ncollision-resistant,  941  \ncryptographic, 291  \ndivision method for, 284,  292  ex.  \nfor hierarchical memory, 3043307  \nmultiplication method for, 2843286  \nmultiply-shift  method  for,  2853286  \nrandom, 2863290  \nstatic, 282,  2843286  \nuniversal, 2863290  \nwee, 3053307  \nsee also family of hash functions \nhashing, 2723311  \nwith chaining, 2773281,  308  pr.  \ndouble, 2953297,  301  ex.  \nindependent uniform, 276  \nwith linear probing, 297,  3023304  \nin memoization, 368,  391  \nwith open addressing, 2933301,  308  pr.  \nperfect, 310  \nrandom, 2863290  \nto replace adjacency lists, 553  ex.  \nof static sets, 308  pr.  \nof strings, 2903291,  292  ex.  \nuniform, 278  universal, 2863290,  309  pr.  \nof variable-length  inputs,  2903291  \nof vectors, 2903291  \nHASH-I NSERT , 294,  300  ex.  \nHASH-SEARCH , 294,  300  ex.  \nhash table, 2753282  \ndynamic, 470  ex.  \nused within a priority queue, 174  \nsee also hashing \nhash value, 275  \nhat-check  problem,  134  ex.  \nhead \nin a disk drive, 498  \nof a linked list, 259  \nof a queue, 256  \nheap, 1613181  \nanalyzed by potential method, 459  ex.  \nbuilding, 1673170,  178  pr.  \nin constructing Huffman codes, 436  \nd -ary,  179  pr.,  668  pr.  \ndeletion from, 178  ex.  \nin Dijkstra\u2019s  algorithm,  623  \nextracting the maximum key from, 174  \nFibonacci, 478  \nheight of, 163  \nincreasing a key in, 1743175  \ninsertion into, 175  \nin Johnson\u2019s  algorithm,  666  \nmax-heap,  162  \nmaximum key of, 174  \nmergeable, 268  pr.  \nmin-heap,  163  \nin Prim\u2019s  algorithm,  597  \nas a priority queue, 1723178  \nHEAP-DECREASE-KEY, 176  ex.  \nHEAP-EXTRACT-MIN, 176  ex.  \nHEAP-MINIMUM , 176  ex.  \nheap property, 162  \nmaintenance of, 1643167  \nvs.  binary-search-tree  property,  315  ex.  \nheapsort, 1613181  \nlower bound for, 207  \nHEAPSORT , 170  \nHEDGE , 1039  pr.  \nheight \nblack-,  332  \nof a B-tree,  5023504  \nof a d -ary  heap,  179  pr.  1268 Index \nheight, continued  \nof a decision tree, 207  \nof a heap, 163  \nof a node in a heap, 163,  170  ex.  \nof a node in a tree, 1173  \nof a red-black  tree,  332  \nof a tree, 1173  \nheight-balanced  tree,  357  pr.  \nhelpful partitioning, 232  \nHermitian matrix, 838  ex.  \nHessian matrix, 1035  \nheuristic \n\u00fbrst-\u00fbt  for  bin  packing,  1131  pr.  \npath compression, 528  \nin the  Rabin-Karp  algorithm,  965  \nfor  the  set-covering  problem,  1116,  1132  pr.  \ntable doubling, 461  \nfor  the  traveling-salesperson  problem,  \n1115  ex.  \nunion by rank, 528  \nweighted union, 525  \nhigh endpoint of an interval, 489  \nhigh side of a partition, 183  \nHIRE-ASSISTANT , 127  \nhiring problem, 1263127,  1353136  \nonline, 1503152  \nprobabilistic analysis of, 1323133  \nhit, 965  \nHOARE-PARTITION , 199  pr.  \nHOPCROFT-KARP, 709  \nHopcroft-Karp  algorithm,  7093715  \nHORNER , 47  pr.  \nHorner\u2019s  rule,  46  pr.,  879,  963  \nHUFFMAN , 434  \nHuffman code, 4313439  \nHuman  Genome  Project,  6 \nHUNGARIAN , 737  \nHungarian algorithm, 7233739,  740  pr.  \nhybrid cryptosystem, 941  \nhyperedge, 1167  \nhypergraph, 1167  \nhypotheses, 1003  \nideal parallel computer, 756  \nidempotency laws, 1154  \nidentity, 917  \nidentity matrix, 1215  \nidentity permutation, 138  ex.  if, in pseudocode, 22 \nill-de\u00fbned  recurrence,  77  \nimage, 1162  \nimage compression, 412  pr.  \nincidence, 116431165  \nincidence matrix \nand difference constraints, 628  \nof a directed graph, 553  ex.  \ninclusion and exclusion, 1158  ex.  \nincomplete step, 759  \nI NCREASE-KEY, 173  \nincreasing  a key,  in a max-heap,  1743175  \nI NCREMENT , 451  \nincremental design method, 34  \nincrementing, 21  \nin-degree,  1165  \nindentation in pseudocode, 21322  \nindependence \nof events, 1188,  1190  ex.  \nof random variables, 1192  \nof subproblems in dynamic programming, \n3863387  \nindependent family of hash functions, 288  \nindependent set, 1099  pr.  \nindependent uniform hash function, 276  \nindependent uniform hashing, 276,  278  \nindependent uniform permutation hashing, 295  \nindexing into an array, 22323,  26  n.,  252  \nindex of an element of Z \ue003 \nn , 933  \nindicator random variable, 1303133  \nin approximation algorithm for \nMAX-3-CNF  satis\u00fbability,  112031121  \nin birthday paradox analysis, 1423143  \nin bounding the right tail of the binomial \ndistribution, 120731208  \nin coin  \u00fcipping  analysis,  1313132  \nexpected value of, 130  \nin hashing analysis, 2793281  \nin the  hat-check  problem,  134  ex.  \nin hiring-problem  analysis,  1323133  \nand linearity of expectation, 131  \nin quicksort analysis, 1973198,  200  pr.  \nin randomized caching analysis, 812  \nin randomized-selection  analysis,  245  pr.  \nin streak analysis, 1483150  \ninduced subgraph, 1166  \ninequality, linear, 853  \ninfeasible linear program, 854  Index 1269 \ninfeasible solution, 854  \ninference, 1004  \nin\u00fbnite  sequence,  1162  \nin\u00fbnite  set,  1156  \nin\u00fbnite  sum,  1140  \nin\u00fbnity,  arithmetic  with,  611  \ninitialization of a loop invariant, 20 \nI NITIALIZE-SINGLE-SOURCE , 609  \ninjective function, 1162  \ninner product, 1219  \ninorder tree walk, 314,  320  ex.  \nI NORDER-TREE-WALK, 314  \nin-place  permuting,  136  \nin-place  sorting,  158,  220  pr.  \nin play, 232  \ninput \nto an algorithm, 5 \nto a combinational circuit, 1066  \ndistribution of, 128,  134  \nto a logic gate, 1065  \nsize of, 28  \ninput alphabet, 967  \nI NSERT , 173,  250,  460  ex.  \ninsertion \ninto binary search trees, 3213322  \ninto  B-trees,  5063511  \ninto chained hash tables, 278  \ninto d -ary  heaps,  179  pr.  \ninto  direct-address  tables,  274  \ninto dynamic tables, 4613465  \nelementary, 461  \ninto heaps, 175  \ninto interval trees, 491  \ninto linked lists, 260  \ninto  open-address  hash  tables,  2933294  \ninto  order-statistic  trees,  484  \ninto queues, 256  \ninto  red-black  trees,  3383346  \ninto stacks, 254  \ninto Young tableaus, 179  pr.  \ninsertion sort, 17321,  29331,  51353,  56357  \nin bucket sort, 2163218  \ncompared with merge sort, 12313,  15  ex.  \ncompared with quicksort, 191  ex.  \ndecision tree for, 206  \u00fbg.  \nlower bound for, 52353  \nin merge sort, 45  pr.  in quicksort, 198  ex.  \nusing binary search, 45  ex.  \nI NSERTION-SORT, 19,  30,  51  \ninstance \nof an abstract problem, 1045,  1049  \nof a problem, 6 \ninstructions of the RAM model, 26  \ninteger data type, 26  \ninteger linear programming, 857,  874  pr.,  \n1098  ex.  \nintegers ( Z), 1153  \ninteger-valued  \u00fcow,  695  \nintegrality theorem, 696  \nintegral, to approximate summations, 1150  \nintegration of a series, 1142  \ninterior-point  methods,  857  \nintermediate vertex, 655  \ninternal node, 1172  \ninternal path length, 1175  ex.  \ninterpolation by a cubic spline, 847  pr.  \ninterpolation by a polynomial, 880,  885  ex.  \nat complex roots of unity, 8913892  \nintersection \nof chords, 486  ex.  \nof languages, 1052  \nof sets ( \\), 1154  \ninterval, 4893490,  1157  \nfuzzy sorting of, 203  pr.  \nI NTERVAL-DELETE , 490,  496  pr.  \ninterval graph, 425  ex.  \nI NTERVAL-I NSERT , 490,  496  pr.  \nI NTERVAL-SEARCH , 490,  492  \nI NTERVAL-SEARCH-EXACTLY , 495  ex.  \ninterval tree, 4893495  \ninterval trichotomy, 490  \nintractability, 1042  \ninvalid shift, 957  \ninventory planning, 414  pr.  \ninverse \nof a bijective function, 1163  \nin a group, 917  \nof a matrix, 784  pr.,  8333837,  1220  \nmultiplicative, modulo n, 927  \ninversion \nin an array, 47  pr.  \nin linked lists, 798  \nin a sequence, 134  ex.,  486  ex.  1270 Index \ninversion count, 798  \ninverter, 1065  \ninvertible matrix, 1220  \ninvocation tree, 756  \nisolated vertex, 1165  \nisomorphic graphs, 1166  \niterated function, 68,  74  pr.  \niterated logarithm function (lg \ue003 ), 68  \nI TERATIVE-TREE-SEARCH , 316  \niter function, 536  \nJava  Fork-Join  Framework,  750  \nJensen\u2019s  inequality,  1194  \nJ OHNSON , 666  \nJohnson\u2019s  algorithm,  6623667  \njoining \nof red-black  trees,  356  pr.  \nof 2-3-4  trees,  518  pr.  \njoint probability density function, 1191  \nJosephus  permutation,  496  pr.  \nKarmarkar\u2019s  algorithm,  876  \nKarp\u2019s  minimum  mean-weight  cycle  algorithm,  \n642  pr.  \nk-ary  tree,  1174  \nk-clustering,  1008  \nk-CNF,  1043  \nk-coloring,  1100  pr.,  1176  pr.  \nk-combination,  1180  \nk-conjunctive  normal  form,  1043  \nKeeling  curve,  845  \u00fbg.  \nkey, 17,  157,  173,  249,  2833284  \nin a cryptosystem, 936,  939  \ndummy, 400  \nmedian,  of a B-tree  node,  506  \nkeywords, in pseudocode, 21322,  24  \nparallel, 750,  7523754,  7623763  \nKleene  star  ( \ue003 ), 1052  \nk-means  problem,  1008  \nKMP  algorithm,  9753985  \nKMP-M ATCHER , 978  \nknapsack problem \ndecision version, 1096  \nfractional, 429  \n0-1,  428,  430  ex.,  1134  pr.  \nk-neighbor  tree,  358  \nknot, of a spline, 847  pr.  \nKnuth-Morris-Pratt  algorithm,  9753985  k-permutation,  136,  1180  \nKraft  inequality,  1176  ex.  \nKruskal\u2019s  algorithm,  5923594  \nwith integer edge weights, 598  ex.  \nk-sorted,  221  pr.  \nk-string,  1179  \nk-subset,  1156  \nk-substring,  1179  \nkth power, 910  ex.  \nlabel \nin machine learning, 1003,  1035  \nof a vertex, 724,  742  pr.  \nLagrange\u2019s  formula,  881  \nLagrange\u2019s  theorem,  921  \nLam\u00b4  e\u2019s  theorem,  913  \nlanguage, 1052  \ncompleteness of, 1072  ex.  \nproving  NP-completeness  of,  107231073  \nveri\u00fbcation  of,  1058  \nlasers, sharks with, 850  \nlast-in,  \u00fbrst-out  (LIFO),  254,  8033804  \nimplemented with a priority queue, 178  ex.  \nsee also stack \nlatency, 499  \nLCA, 544  pr.  \nlcm (least common multiple), 916  ex.  \nLCP, see longest  common  pre\u00fbx  array  \nLCS, 3933399  \nLCS-LENGTH , 397  \nleading submatrix, 839  \nleaf, 1172  \nleast common multiple, 916  ex.  \nleast frequently used (LFU), 803,  814  ex.  \nleast recently used (LRU), 445  ex.,  8033805  \nleast-squares  approximation,  8413845,  \n103531037  \nleaving a vertex, 1164  \nLEFT, 162  \nleft child, 1173  \nleft-child,  right-sibling  representation,  265,  \n268  ex.  \nleft-leaning  red-black  binary  search  tree,  358  \nLEFT-ROTATE , 336,  495  ex.  \nleft rotation, 335  \nleft shift (n), 305  \nleft subtree, 1173  \nLegendre symbol \ue002 \na \np \u00cd \n, 954  pr.  Index 1271 \nlength \nof a cycle, 1165  \nof a path, 1165  \nof a sequence, 1162  \nof a string, 959,  1179  \nlevel \nof a function, 532  \nof a node  in a disjoint-set  forest,  535  \nof a tree, 1173  \nlexicographically less than, 327  pr.  \nlexicographic sorting, 327  pr.,  986  n. \nLFU (least frequently used), 803,  814  ex.  \nlg (binary logarithm), 66  \nlg \ue003 (iterated logarithm function), 68  \nlg k (exponentiation of logarithms), 66  \nlg lg (composition of logarithms), 66  \nLIFO,  see last-in,  \u00fbrst-out;  stack  \nlight edge, 587  \nlinear constraint, 8533854  \nlinear dependence, 1220  \nlinear equality, 853  \nlinear equations \nsolving modular, 9243928  \nsolving systems of, 8193833,  103431035  \nsolving tridiagonal systems of, 847  pr.  \nlinear function, 30,  853  \nlinear independence, 1220  \nlinear inequality, 853  \nlinear-inequality  feasibility  problem,  873  pr.  \nlinearity of expectation, 119231193  \nand indicator random variables, 131  \nlinearity of summations, 1141  \nlinear order, 1160  \nlinear permutation, 1224  pr.  \nlinear probing, 297,  3023304  \nLINEAR-PROBING-HASH-DELETE , 303  \nlinear programming, 8503876,  112131124  \napplications of, 8603866  \nduality in, 8663873  \nellipsoid algorithm for, 857  \nfundamental theorem of, 872  \ninteger, 857,  874  pr.  \ninterior-point  methods  for,  857  \nKarmarkar\u2019s  algorithm  for,  876  \nand  maximum  \u00fcow,  862  \nand  minimum-cost  circulation,  875  pr.  \nand  minimum-cost  \u00fcow,  8623864  \nand  multicommodity  \u00fcow,  8643865  simplex algorithm for, 857  \nand  single-pair  shortest  path,  861  \nand  single-source  shortest  paths,  6263632  \nstandard form for, 854  \nsee also integer  linear  programming,  0-1  \ninteger programming \nlinear-programming  relaxation,  1122  \nlinear regression, 1036  \nlinear search, 25  ex.  \nlinear speedup, 758  \nline search, 1031  \nLINK, 530  \nlinked list, 2583264  \ncompact, 269  pr.  \ndeletion from, 261  \nto implement disjoint sets, 5233527  \ninsertion into, 260  \nmaintained by an online algorithm, 7953802  \nsearching, 260,  292  ex.  \nlinking  of trees  in a disjoint-set  forest,  529  \nlist, see linked list \nLIST-DELETE , 261  \nLIST-DELETE 0 , 262  \nLIST-I NSERT , 261  \nLIST-I NSERT 0 , 263  \nLIST-PREPEND , 260  \nLIST-SEARCH , 260  \nLIST-SEARCH 0 , 263  \nliteral, 1076  \nlittle-oh  notation  (o), 60  \nlittle-omega  notation  (!), 61  \nLloyd\u2019s  procedure,  101131013,  1039  pr.  \nln (natural logarithm), 66  \nload factor \nof a dynamic table, 461  \nof a hash table, 278  \nload instruction, 26,  756  \nlocal minimizer, 1026  \u00fbg.  \nlocal variable, 22 \nlogarithm function (log), 66367  \ndiscrete, 933  \niterated (lg \ue003 ), 68  \nlogical parallelism, 753  \nlogical right shift ( o), 285  \nlogic gate, 1065  \nlongest  common  pre\u00fbx  (LCP) array, 986,  \n9923994  \nlongest common subsequence, 3933399  1272 Index \nlongest common substring, 995  ex.  \nlongest monotonically increasing subsequence, \n399  ex.  \nlongest palindrome subsequence, 407  pr.  \nLONGEST-PATH,  1055  ex.  \nLONGEST-PATH-LENGTH,  1055  ex.  \nlongest repeated substring, 987  \nlongest simple cycle, 1098  ex.  \nlongest simple path, 1042  \nin an unweighted graph, 385  \nin a weighted directed acyclic graph, 407  pr.  \nlookahead algorithm, 815  ex.  \nLOOKUP-CHAIN , 391  \nloop, in pseudocode, 22 \nparallel, 7623765  \nloop invariant, 19320  \nfor  breadth-\u00fbrst  search,  555  \nfor building a heap, 167  \nfor counting sort, 211  ex.  \nfor determining the rank of an element in an \norder-statistic  tree,  483  \nand for  loops, 21  n. \nfor  the  generic  minimum-spanning-tree  \nmethod, 586  \nfor heapsort, 172  ex.  \nfor  Horner\u2019s  rule,  46  pr.  \nfor increasing a key in a heap, 177  ex.  \nfor insertion sort, 19320  \nfor partitioning, 184  \nfor  Prim\u2019s  algorithm,  597  \nfor  the  Rabin-Karp  algorithm,  965  \nfor randomly permuting an array, 137  \nfor  red-black  tree  insertion,  340  \nfor  string-matching  automata,  970,  973  \nloss function, 1036  \nlow endpoint of an interval, 489  \nlower bounds \nasymptotic, 55  \non  binomial  coef\u00fbcients,  1181,  1184  ex.  \nfor comparing water jugs, 220 pr. \nfor competitive ratios for online caching, \n8043806  \nfor constructing binary search trees, 315  ex.  \nfor  disjoint-set  data  structures,  545  \nfor  \u00fbnding  the  minimum,  228  \nfor insertion sort, 52353  \nfor k-sorting,  221  pr.  for  median  \u00fbnding,  247  \nfor merging, 222 pr. \nand potential functions, 475  \nfor simultaneous minimum and maximum, \n229 ex. \nfor sorting, 2053208,  219  pr.,  225  \nfor streaks, 1473148,  153  ex.  \non summations, 1148,  1150  \nfor  task-parallel  computations,  757  \nfor  traveling-salesperson  tour,  111031113  \nfor vertex cover, 1108,  112131123,  1132  pr.  \nlower median, 227  \nlower-triangular  matrix,  1216  \nlowest common ancestor, 543  pr.  \nlow side of a partition, 183  \nLRU (least recently used), 445  ex.,  8033805  \nLU decomposition, 8243827  \nparallel algorithm for, 784  pr.  \nLU-DECOMPOSITION , 827  \nLUP decomposition, 821  \ncomputation of, 8283832  \nin matrix inversion, 8333834  \nand matrix multiplication, 838  ex.  \nparallel algorithm for, 784  pr.  \nuse of, 8213824  \nLUP-DECOMPOSITION , 830  \nLUP-SOLVE , 824  \nmachine learning, 14,  100331041  \nmain memory, 498  \nmaintenance of a loop invariant, 20 \nMAKE-RANKS , 988  \nMAKE-SET, 521  \ndisjoint-set-forest  implementation  of,  530  \nlinked-list  implementation  of,  523  \nmakespan, 1133  pr.  \nMAKE-TREE, 542  pr.  \nManhattan distance, 244  pr.  \nMARKING , 807,  815  ex.  \nMarkov\u2019s  inequality,  1196  ex.  \nmaster method for solving a recurrence, \n1013107  \nmaster recurrence, 101  \nmaster theorem, 102  \ncontinuous, 112  \nproof of, 1073115  \nmatched vertex, 693,  705  Index 1273 \nmatching, 7043743  \nbipartite, 6933697,  7043743  \nfractional, 741  pr.  \nby  Hopcroft-Karp  algorithm,  7093715  \nmaximal, 705,  1108,  1132  pr.  \nmaximum, 7043716,  1132  pr.  \nand  maximum  \u00fcow,  6933697  \nperfect, 715  ex.,  740  pr.  \nstable, 716  \nof strings, 95731002  \nunstable, 717  \nmatrix, 121431226  \naddition of, 1217  \nadjacency, 5513552  \nconjugate transpose of, 838  ex.  \ndense, 81  \ndeterminant of, 1221  \ndiagonal, 1215  \nHermitian, 838  ex.  \nHessian, 1035  \nidentity, 1215  \nincidence, 553  ex.  \ninverse of, 784  pr.,  8333837,  1220  \nlower-triangular,  1216  \nminor of, 1221  \nmultiplication of, see matrix multiplication \nnegative of, 1217  \npermutation, 1217  \npositive-de\u00fbnite,  1222  \npositive-semide\u00fbnite,  1222  \npredecessor, 647,  655  ex.,  6573659,  661  ex.  \nproduct of, with a vector, 7623765,  767,  \n1218  \npseudoinverse of, 843  \nrepresentation of, 2533254  \nscalar multiple of, 1217  \nsparse, 81  \nsubtraction of, 1218  \nsymmetric, 1217  \nsymmetric  positive-de\u00fbnite,  8383841  \ntranspose of, 1214  \ntridiagonal, 1216  \nunit  lower-triangular,  1216  \nunit  upper-triangular,  1216  \nupper-triangular,  1216  \nVandermonde, 881,  1223  pr.  \nmatrix-chain  multiplication,  3733382  MATRIX-CHAIN-MULTIPLY , 381  ex.  \nMATRIX-CHAIN-ORDER , 378  \nmatrix multiplication, 80390,  1218  \nfor  all-pairs  shortest  paths,  6483655,  \n6683669  \ndivide-and-conquer  method  for,  81390,  \n7703775,  783  pr.  \nand LUP decomposition, 838  ex.  \nand matrix inversion, 8343837  \nPan\u2019s  method  for,  89  ex.  \nparallel algorithm for, 7703775,  783  pr.  \nStrassen\u2019s  algorithm  for,  85390,  1243125,  \n7733774  \nand transitive closure, 838  ex.  \nMATRIX-MULTIPLY , 81  \nMATRIX-MULTIPLY-RECURSIVE , 83  \nmatrix-vector  multiplication,  7623765,  767,  \n1218  \nMAX-CNF  satis\u00fbability,  1124  ex.  \nMAX-CUT  problem,  1124  ex.  \nMAX-FLOW-BY-SCALING , 700  pr.  \nmax-\u00fcow  min-cut  theorem,  684  \nmax-heap,  162  \nbuilding, 1673170  \nd -ary,  179  pr.  \ndeletion from, 178  ex.  \nextracting the maximum key from, 174  \nin heapsort, 1703172  \nincreasing a key in, 1743175  \ninsertion into, 175  \nmaximum key of, 174  \nas a max-priority  queue,  1723178  \nmergeable, 268  n. \nMAX-HEAP-DECREASE-KEY, 176  ex.  \nMAX-HEAP-DELETE , 178  ex.  \nMAX-HEAP-EXTRACT-MAX, 175  \nMAX-HEAPIFY , 165  \nMAX-HEAP-I NCREASE-KEY, 176  \nMAX-HEAP-I NSERT , 176  \nbuilding a heap with, 178  pr.  \nMAX-HEAP-MAXIMUM , 175  \nmax-heap  property,  162  \nmaintenance of, 1643167  \nmaximal element, 1160  \nmaximal matching, 705,  1108,  1132  pr.  \ngreedy method for, 726  \nmaximization linear program, 853  1274 Index \nmaximum, 227  \nin binary search trees, 3173318  \nof a binomial distribution, 1202  ex.  \n\u00fbnding,  2283229  \nin heaps, 174  \nin red-black  trees,  334  \nMAXIMUM , 1733174,  250  \nmaximum bipartite matching, 6933697,  \n7053716  \nmaximum  \u00fcow,  6703703  \nEdmonds-Karp  algorithm  for,  6893691  \nFord-Fulkerson  method  for,  6763693  \nas a linear program, 862  \nand maximum bipartite matching, 6933697  \npush-relabel  algorithms  for,  702  \nscaling algorithm for, 699  pr.  \nupdating, 699  pr.  \nmaximum matching, 693,  704,  1132  pr.  \nsee also maximum bipartite matching \nmaximum spanning tree, 1134  pr.  \nmax-priority  queue,  173  \nMAX-3-CNF  satis\u00fbability,  112031121  \nMAYBE-MST-A,  602  pr.  \nMAYBE-MST-B,  602  pr.  \nMAYBE-MST-C,  602  pr.  \nmean \nof a cluster, 1009  \nsee also expected value \nmean weight of a cycle, 642  pr.  \nmedian, 2273247  \nweighted, 244  pr.  \nmedian  key,  of a B-tree  node,  506  \nmedian-of-3  method,  203  pr.  \nmember of a set ( 2), 1153  \nmemoization, 368,  3903392  \nMEMOIZED-CUT-ROD, 369  \nMEMOIZED-CUT-ROD-AUX, 369  \nMEMOIZED-MATRIX-CHAIN , 391  \nmemory hierarchy, 27,  301  \nhash functions for, 3043307  \nMERGE , 36  \nmergeable heap, 268  pr.  \nMERGE-LISTS, 1125  \nmerge sort, 34344,  57  \ncompared with insertion sort, 12313,  15  ex.  \nlower bound for, 207  \nparallel algorithm for, 7753782  \nuse of insertion sort in, 45  pr.  MERGE-SORT, 39  \nmerging \nof k sorted lists, 178  ex.  \nlower bounds for, 222 pr. \nparallel algorithm for, 7763780  \nof two sorted subarrays, 35338  \nMILLER-RABIN , 946  \nMiller-Rabin  primality  test,  9453953  \nMIN-GAP, 495  ex.  \nmin-heap,  163  \nanalyzed by potential method, 459  ex.  \nbuilding, 1673170  \nin constructing Huffman codes, 436  \nd -ary,  668  pr.  \nin Dijkstra\u2019s  algorithm,  623  \nin Johnson\u2019s  algorithm,  666  \nmergeable, 268  n. \nas a min-priority  queue,  176  ex.  \nin Prim\u2019s  algorithm,  597  \nMIN-HEAPIFY , 166  ex.  \nMIN-HEAP-I NSERT , 176  ex.  \nmin-heap  property,  163  \nmaintenance of, 166  ex.  \nvs.  binary-search-tree  property,  315  ex.  \nminimization linear program, 853  \nminimizer of a function, 1022,  1024  \u00fbg.,  \n1026  \u00fbg.  \nminimum, 227  \nin binary search trees, 3173318  \n\u00fbnding,  2283229  \nof\u00fcine,  541  pr.  \nin red-black  trees,  334  \nMINIMUM , 173,  228,  250  \nminimum-cost  circulation,  875  pr.  \nminimum-cost  \u00fcow,  8623864  \nminimum-cost  multicommodity  \u00fcow,  866  ex.  \nminimum-cost  spanning  tree,  see minimum \nspanning tree \nminimum cut, 682  \nglobal, 701  pr.  \nminimum  degree,  of a B-tree,  502  \nminimum  mean-weight  cycle,  642  pr.  \nminimum path cover, 698  pr.  \nminimum spanning tree, 5853603  \nin approximation algorithm for \ntraveling-salesperson  problem,  1110  \nBor\u02da  uvka\u2019s  algorithm  for,  603  \non dynamic graphs, 599  ex.  Index 1275 \nminimum spanning tree, continued  \ngeneric method for, 5863591  \nKruskal\u2019s  algorithm  for,  5923594  \nPrim\u2019s  algorithm  for,  5943597  \nsecond-best,  599  pr.  \nminimum-weight  spanning  tree,  see minimum \nspanning tree \nminimum-weight  vertex  cover,  112131124  \nminor of a matrix, 1221  \nmin-priority  queue,  173  \nin constructing Huffman codes, 434  \nin Dijkstra\u2019s  algorithm,  6233624  \nin Prim\u2019s  algorithm,  5963597  \nmissing child, 1173  \nmod, 64,  905  \nmodeling, 851  \nmodifying operation, 250  \nmodular arithmetic, 64,  901  pr.,  9163923  \nmodular equivalence ( D (mod n)), 64,  905  \nmodular exponentiation, 9343935  \nMODULAR-EXPONENTIATION , 935  \nmodular linear equations, 9243928  \nMODULAR-LINEAR-EQUATION-SOLVER , \n926  \nmodulo, 64,  905  \nMonge array, 123  pr.  \nmonotone sequence, 181  \nmonotonically decreasing, 63  \nmonotonically increasing, 63  \nMonty Hall problem, 1210  pr.  \nMOVE-TO-FRONT , 7963797  \nMST-KRUSKAL , 594  \nMST-P RIM, 596  \nMST-R EDUCE , 601  pr.  \nmuch-greater-than  (\ue007), 533  \nmuch-less-than  (\ue008), 761  \nmulticommodity  \u00fcow,  8643865  \nmulticore computer, 748  \nmultidimensional fast Fourier transform, \n899  pr.  \nmultigraph, 1167  \nmultiple, 904  \nof an element modulo n, 9243928  \nleast common, 916  ex.  \nscalar, 1217  \nmultiple sources and sinks, 674  multiplication \nof complex numbers, 90 ex. \ndivide-and-conquer  method  for,  899  pr.  \nof matrices, see matrix multiplication \nof a matrix chain, 3733382  \nmatrix-vector,  7623765,  767,  1218  \nmodulo n (\ue001 n ), 917  \nof polynomials, 878  \nmultiplication method, 2843286  \nmultiplicative group modulo n, 919  \nmultiplicative inverse, modulo n, 927  \nmultiplicative weights, 101531022  \nmultiply instruction, 26  \nmultiply-shift  method,  2853286  \nMULTIPOP , 450  \nmultiset, 1153  n. \ndynamic, 460  ex.  \nmutually exclusive events, 1185  \nmutually independent events, 1188  \nmutually noninterfering strands, 767  \nN (set of natural numbers), 1153  \nnaive algorithm for string matching, 9603962  \nNAIVE-STRING-MATCHER , 960  \nNational Resident Matching Program, 704,  \n722  ex.  \nnatural cubic spline, 847  pr.  \nnatural logarithm (ln), 66  \nnatural numbers ( N), 1153  \nkeys interpreted as, 2833284  \nnearest-center  rule,  1008  \nnegative of a matrix, 1217  \nnegative-weight  cycle  \nand difference constraints, 629  \nand relaxation, 639  ex.  \nand shortest paths, 6063607,  6143615,  \n655  ex.,  662  ex.  \nnegative-weight  edges,  6063607  \nneighbor, 1167  \nneighborhood, 715  ex.  \nnesting boxes, 640  pr.  \nnet  \u00fcow  across  a cut,  682  \nnetwork \n\u00fcow,  see \u00fcow  network  \nresidual, 6773681  \nfor sorting, 789  1276 Index \nnew request, 810  \nNewton\u2019s  method,  1038  pr.  \nNIL, 23  \nnode, 1172  \nsee also vertex \nnondeterministic algorithm, 765  \nnondeterministic polynomial time, 1058  n. \nsee also NP \nnonempty  suf\u00fbx,  997  pr.  \nnonhamiltonian graph, 1056  \nnoninstance, 1051  n. \nnoninvertible matrix, 1220  \nnonnegativity constraint, 854  \nnonoblivious adversary, 807  \nnonoverlappable string pattern, 974  ex.  \nnonsample position, 997  pr.  \nnonsample  suf\u00fbx,  997  pr.  \nnonsingular matrix, 1220  \nnontrivial power, 910  ex.  \nnontrivial square root of 1, modulo n, 934  \nno-path  property,  611,  634  \nnormal equation, 843  \nnorm of a vector ( k k), 1219  \nNOT  function  (:), 1065  \nnot a set member ( \u2026), 1153  \nnot equivalent ( \u00a4 (mod n)), 64  \nNOT  gate,  1065  \nNP (complexity class), 1043,  1058,  1060  ex.  \nNPC (complexity class), 1044,  1063  \nNP-complete,  1044,  1063  \nNP-completeness,  9310,  104231103  \nof the  circuit-satis\u00fbability  problem,  \n106431071  \nof the clique problem, 108131084  \nof the  formula-satis\u00fbability  problem,  \n107331076  \nof the  graph-coloring  problem,  1100  pr.  \nof the  half  3-CNF  satis\u00fbability  problem,  \n1099  ex.  \nof the  hamiltonian-cycle  problem,  \n108531090  \nof the  hamiltonian-path  problem,  1098  ex.  \nof the  independent-set  problem,  1099  pr.  \nof integer linear programming, 1098  ex.  \nof the  longest-simple-cycle  problem,  \n1098  ex.  \nproving, of a language, 107231073  \nreduction strategies for, 109531098  of scheduling  with  pro\u00fbts  and  deadlines,  \n1102  pr.  \nof the  set-covering  problem,  1119  ex.  \nof the  set-partition  problem,  1098  ex.  \nof the  subgraph-isomorphism  problem,  \n1098  ex.  \nof the  subset-sum  problem,  109231095  \nof the  3-CNF-satis\u00fbability  problem,  \n107631079  \nof the  traveling-salesperson  problem,  \n109031092  \nof the  vertex-cover  problem,  108431085  \nof 0-1  integer  programming,  1098  ex.  \nNP-hard,  1063  \nn-set,  1156  \nn-tuple,  1157  \nnull event, 1185  \nnull tree, 1173  \nnull vector, 1221  \nnumber-\u00fbeld  sieve,  956  \nnumerical stability, 819,  821  \nn-vector,  1215  \no-notation,  60  \nO-notation,  50,  54355  \nO 0 -notation,  73  pr.  \ne O-notation,  73  pr.  \nobject, 23  \nobjective function, 626,  852,  854  \nobjective value, 854  \noblivious adversary, 807  \noblivious  compare-exchange  algorithm,  222 pr. \noccurrence of a pattern, 957  \nof\u00fcine  algorithm,  791  \nOFFLINE-MINIMUM , 542  pr.  \nof\u00fcine  problem  \ncaching, 4403446  \nlowest common ancestors, 543  pr.  \nminimum, 541  pr.  \nold request, 810  \nOmega-notation,  51,  54  \u00fbg.,  55356  \n1-approximation  algorithm,  1105  \none-pass  method,  544  \none-to-one  correspondence,  1163  \none-to-one  function,  1162  \nonline algorithm, 7913818  \nfor caching, 8023815  \nfor  the  cow-path  problem,  815  pr.  Index 1277 \nonline algorithm, continued  \nfor hiring, 1503152  \nfor maintaining a linked list, 7953802  \nfor task scheduling, 816  pr.  \nfor waiting for an elevator, 7923794  \nonline learning, 1003  \nONLINE-MAXIMUM , 150  \nonline  task-parallel  scheduler,  759  \nonto function, 1162  \nopen-address  hash  table,  2933301,  308  pr.  \nwith double hashing, 2953297,  301  ex.  \nwith linear probing, 297,  3023304  \nopen interval ( .a; b/ ), 1157  \nOpenMP,  750  \noptimal assignment, 7233739  \noptimal binary search tree, 4003407  \nOPTIMAL-BST,  405  \noptimal objective value, 854  \noptimal solution, 854  \noptimal substructure, 3823387  \nof activity selection, 419  \nof binary search trees, 4023403  \nof the fractional knapsack problem, 429  \nin greedy method, 428  \nof Huffman codes, 438  \nof longest common subsequences, 3943395  \nof matrix-chain  multiplication,  376  \nof of\u00fcine  caching,  4413442  \nof rod cutting, 365  \nof shortest paths, 6053606,  649,  6553656  \nof unweighted shortest paths, 385  \nof the  0-1  knapsack  problem,  429  \noptimal vertex cover, 1106  \noptimization problem, 362,  1045,  1049  \napproximation algorithms for, 110431136  \nand decision problems, 1045  \nOR  function  (_), 659,  1065  \norder \nof a group, 922 \nof growth, 32  \nlinear, 1160  \npartial, 1160  \ntotal, 1160  \nordered pair, 1156  \nordered tree, 1173  \norder statistics, 160,  2273247  \ndynamic, 4803486  \norder-statistic  tree,  4803486  ord function, 987  \nOR  gate,  1065  \nor, in pseudocode, 24  \northonormal, 849  \nOS-K EY-RANK, 485  ex.  \nOS-RANK, 483  \nOS-S ELECT , 482  \noutcome, 1185  \nout-degree,  1165  \nouter product, 1219  \noutput \nof an algorithm, 5 \nof a combinational circuit, 1066  \nof a logic gate, 1065  \noverdetermined system of linear equations, 821  \nover\u00fcow  \nof a queue, 257  \nof a stack, 255  \nover\u00fcowing  vertex,  703  \noverlapping intervals, 489  \n\u00fbnding  all,  495  ex.  \npoint of maximum overlap, 496  pr.  \noverlapping rectangles, 495  ex.  \noverlapping subproblems, 3873390  \noverlapping-suf\u00fbx  lemma,  959  \nP (complexity class), 1043,  1050,  1054,  \n1055  ex.  \npage, in virtual memory, 440  \npair \nblocking, 716  \nordered, 1156  \npairwise disjoint sets, 1156  \npairwise independence, 1188  \npairwise relatively prime, 908  \npalindrome, 407  pr.,  995  ex.  \nPan\u2019s  method  for  matrix  multiplication,  89  ex.  \nparallel algorithm, 7483790  \nfor computing Fibonacci numbers, 7503753  \ngrain size in, 783  pr.  \nfor LU decomposition, 784  pr.  \nfor LUP decomposition, 784  pr.  \nfor matrix inversion, 784  pr.  \nfor matrix multiplication, 7703775,  783  pr.  \nfor  matrix-vector  product,  7623765,  767  \nfor merge sort, 7753782  \nfor merging, 7763780  \nfor  pre\u00fbx  computation,  784  pr.  1278 Index \nparallel algorithm, continued  \nfor quicksort, 789  pr.  \nrandomized, 789  pr.  \nfor reduction, 784  pr.  \nfor a simple stencil calculation, 787  pr.  \nfor solving systems of linear equations, \n784  pr.  \nStrassen\u2019s  algorithm,  7733774  \nfor  well-formed  parentheses,  786  pr.  \nparallel computer, 10,  748,  756  \nparallel  for, in pseudocode, 7623763  \nparallelism \nlogical, 753  \nof a randomized parallel algorithm, 789  pr.  \nspawning, 753  \nsyncing, 754  \nof a task-parallel  computation,  758  \nparallel keywords, 750,  752,  762  \nparallel loop, 7623765,  783  pr.  \nparallel-machine-scheduling  problem,  1133  pr.  \nparallel  pre\u00fbx,  784  pr.  \nparallel  random-access  machine,  789  \nparallel slackness, 758  \nrule of thumb, 761  \nparallel, strands logically in, 756  \nparallel trace, 7543756  \nseries-parallel  composition  of,  762  \u00fbg.  \nparameter, 23  \ncosts of passing, 120  pr.  \nparent \nin a breadth-\u00fbrst  tree  (\ufffd ), 555  \nin a parallel computation, 753  \nin a rooted tree, 1172  \nPARENT , 162  \nparenthesis theorem, 567  \nparenthesization  of a matrix-chain  product,  374  \nPareto optimality, 722  ex.  \nparse tree, 1077  \npartial derivative ( @), 1023  \npartial order, 1160  \nPARTITION , 184  \nPARTITION  0 , 200 pr. \nPARTITION-AROUND , 237  \npartition function, 363  n. \npartitioning, 1833186  \naround  median  of 3 elements,  198  ex.  \nhelpful, 232  Hoare\u2019s  method  for,  199  pr.  \nrandomized, 192,  198  ex.,  200  pr.,  203  pr.  \npartition of a set, 1156,  1159  \nPascal\u2019s  triangle,  1183  ex.  \npath, 1165  \nalternating, 705  \naugmenting, 6813682,  705  \ncritical, 619  \n\u00fbnd,  528  \nhamiltonian, 1060  ex.,  1098  ex.  \nlongest, 385,  1042  \nshortest, see shortest paths \nsimple, 1165  \nweight of, 407  pr.,  604  \nPATH, 1045,  1053  \npath compression, 528  \npath cover, 698  pr.  \npath length, of a tree, 328  pr.,  1175  ex.  \npath-relaxation  property,  611,  635  \npattern, 957  \nnonoverlappable, 974  ex.  \npattern matching, see string matching \nperfect hashing, 310  \nperfect linear speedup, 758  \nperfect matching, 715  ex.,  740  pr.  \npermutation, 1163,  117931180  \nbit-reversal,  897  \nidentity, 138  ex.  \nin place, 136  \nJosephus,  496  pr.  \nk-permutation,  136,  1180  \nlinear, 1224  pr.  \nrandom, 1363138  \nuniform random, 128,  136  \npermutation matrix, 1217  \nPERMUTE-BY-CYCLE , 139  ex.  \nPERMUTE-WITH-ALL, 139  ex.  \nPERMUTE-WITHOUT-I DENTITY , 138  ex.  \npersistent data structure, 355  pr.,  478  \nPERSISTENT-TREE-I NSERT , 355  pr.  \nPERT chart, 617,  619  ex.  \nP-F IB, 753  \nphi function ( \ufffd.n/ ), 920 \npivot \nin LU decomposition, 826  \nin quicksort, 183  \nin selection, 230  Index 1279 \nP \u0152  W k\ufffd (pre\u00fbx  of a pattern),  959  \nplanar graph, 584  pr.  \nplatter in a disk drive, 498  \nP-M ATRIX-MULTIPLY , 771  \nP-M ATRIX-MULTIPLY-RECURSIVE , 772  \nP-M AT-VEC, 763  \nP-M AT-VEC-RECURSIVE , 763  \nP-M AT-VEC-WRONG , 768  \nP-MERGE , 779  \nP-MERGE-AUX, 779  \nP-MERGE-SORT, 775  \nP-N AIVE-MERGE-SORT, 775  \npointer, 23  \ntrailing, 321  \npoint, in clustering, 1006  \npoint-value  representation,  880  \npolylogarithmically bounded, 67  \npolynomial, 65,  877\u2013885  \naddition of, 877  \nasymptotic behavior of, 71  pr.  \ncoef\u00fbcient  representation  of,  879  \nderivatives of, 900 pr. \nevaluation of, 46  pr.,  879,  884  ex.,  900  pr.  \ninterpolation by, 880,  885  ex.  \nmultiplication of, 878,  882\u2013884,  899  pr.  \npoint-value  representation  of,  880  \npolynomial-growth  condition,  116\u2013117  \npolynomially bounded, 65  \npolynomially related, 1051  \npolynomial-time  acceptance,  1053  \npolynomial-time  algorithm,  904,  1042  \npolynomial-time  approximation  scheme,  1105  \nfor maximum clique, 1131  pr.  \nfor subset sum, 1124\u20131130  \npolynomial-time  computability,  1051  \npolynomial-time  decision,  1053  \npolynomial-time  reducibility  (\u0dc4 P ), 1062,  \n1071  ex.  \npolynomial-time  solvability,  1050  \npolynomial-time  veri\u00fbcation,  1056\u20131061  \nPOP, 255,  449  \npop from a runtime stack, 202 pr. \npositional tree, 1174  \npositive-de\u00fbnite  matrix,  1222  \npositive-semide\u00fbnite  matrix,  1222  \npost-of\u00fbce  location  problem,  244  pr.  \npostorder tree walk, 314  potential function, 456  \nfor lower bounds, 475  \npotential method, 456\u2013460  \nfor binary counters, 458\u2013459  \nfor  disjoint-set  data  structures,  534\u2013540,  \n541  ex.  \nfor dynamic tables, 463\u2013470  \nfor maintaining a linked list, 799\u2013801  \nfor  min-heaps,  459  ex.  \nfor  restructuring  red-black  trees,  473  pr.  \nfor stack operations, 457\u2013458  \npotential of a data structure, 456  \npower \nof an element, modulo n, 932\u2013936  \nkth, 910  ex.  \nnontrivial, 910  ex.  \npower series, 121  pr.  \npower set, 1156  \nPr f g  (probability distribution), 1185  \nPRAM, 789  \npredecessor \nin binary search trees, 318\u2013319  \nin breadth-\u00fbrst  trees  (\ufffd ), 555  \nin linked lists, 259  \nin red-black  trees,  334  \nin shortest-paths  trees  (\ufffd ), 608  \nPREDECESSOR , 250  \npredecessor matrix, 647,  655  ex.,  657\u2013659,  \n661  ex.  \npredecessor subgraph \nin all-pairs  shortest  paths,  647  \nin breadth-\u00fbrst  search,  561  \nin depth-\u00fbrst  search,  564  \nin single-source  shortest  paths,  608  \npredecessor-subgraph  property,  611,  637\u2013638  \nprediction, 1004  \nprediction phase, 1003  \npreemption, 446  pr.,  816  pr.  \npre\u00fbx  \nof a sequence, 395  \nof a string ( h), 959  \npre\u00fbx  computation,  784  pr.  \npre\u00fbx-free  code,  432  \npre\u00fbx  function,  975\u2013977  \npre\u00fbx-function  iteration  lemma,  980  \npre\u00fcow,  703  \npreimage of a matrix, 1224  pr.  1280 Index \npreorder, total, 1160  \npreorder tree walk, 314  \nPrim\u2019s  algorithm,  594\u2013597  \nwith an adjacency matrix, 598  ex.  \nin approximation algorithm for \ntraveling-salesperson  problem,  1110  \nwith integer edge weights, 598  ex.  \nsimilarity  to Dijkstra\u2019s  algorithm,  624  \nfor sparse graphs, 599  pr.  \nprimality testing, 942\u2013953,  956  \nMiller-Rabin  test,  945\u2013953  \npseudoprimality testing, 944\u2013945  \nprimal linear program, 866  \naugmented, 870  \nprimary clustering, 303  \nprime distribution function, 943  \nprime factorization of integers, 909 \nprime number, 905  \ndensity of, 943  \nprime number theorem, 943  \nprimitive root of Z \ue003 \nn , 932  \nprincipal root of unity, 886  \nprinciple of inclusion and exclusion, 1158  ex.  \nPRINT-ALL-PAIRS-SHORTEST-PATH, 648  \nPRINT-CUT-ROD-SOLUTION , 372  \nPRINT-LCS,  397  \nPRINT-OPTIMAL-PARENS , 381  \nPRINT-PAT H, 562  \nPRINT-SET, 531  ex.  \npriority queue, 172\u2013178  \nin constructing Huffman codes, 434  \nin Dijkstra\u2019s  algorithm,  623\u2013624  \nheap implementation of, 172\u2013178  \nmax-priority  queue,  173  \nmin-priority  queue,  173,  176  ex.  \nwith monotone extractions, 181  \nin Prim\u2019s  algorithm,  596\u2013597  \nsee also Fibonacci heap \nprobabilistically checkable proof, 1103,  1136  \nprobabilistic analysis, 127\u2013128,  140\u2013153  \nof approximation algorithm for \nMAX-3-CNF  satis\u00fbability,  1120\u20131121  \nand average inputs, 32  \nof average node depth in a randomly built \nbinary search tree, 328  pr.  \nof balls and bins, 143\u2013144  \nof birthday paradox, 140\u2013143  \nof bucket sort, 216\u2013218,  218  ex.  of collisions, 281  ex.  \nof \u00fble  comparison,  967  ex.  \nof fuzzy sorting of intervals, 203  pr.  \nof hashing with chaining, 278\u2013281  \nof hiring problem, 132\u2013133,  150\u2013152  \nof insertion into a binary search tree with \nequal keys, 327  pr.  \nof longest probe bound for hashing, 308  pr.  \nof lower bound for sorting, 219  pr.  \nof Miller-Rabin  primality  test,  948\u2013953  \nof online hiring problem, 150\u2013152  \nof open-address  hashing,  297\u2013300  \nand parallel algorithms, 789  pr.  \nof partitioning, 191  ex.,  198  ex.,  200  pr.,  \n203  pr.  \nof probabilistic counting, 153  pr.  \nof quicksort, 194\u2013198,  200  pr.,  203  pr.  \nof Rabin-Karp  algorithm,  965\u2013966  \nand randomized algorithms, 134\u2013136  \nof randomized online caching, 809\u2013814  \nof randomized selection, 232\u2013236,  245  pr.  \nof randomized weighted majority, 1022  ex.  \nof searching a sorted compact list, 269  pr.  \nof slot-size  bound  for  chaining,  308  pr.  \nof sorting points by distance from origin, \n218  ex.  \nof streaks, 144\u2013150  \nof universal hashing, 286\u2013290  \nprobabilistic counting, 153  pr.  \nprobability, 1184\u20131191  \nprobability axioms, 1185  \nprobability density function, 1191  \nprobability distribution, 1185  \nprobability distribution function, 218  ex.  \nprobe sequence, 293  \nprobing, 293  \nsee also linear probing, double hashing \nproblem \nabstract, 1048  \ncomputational, 5\u20136  \nconcrete, 1049  \ndecision, 1045,  1049  \nintractable, 1042  \noptimization, 362,  1045,  1049  \nsolution to, 6, 1049  \ntractable, 1042  \nprocedure, 18  \ncalling, 23,  26,  29  n. Index 1281 \nproduct . Q  /, 1144  \nCartesian ( \ue005), 1157  \ninner, 1219  \nof matrices, see matrix multiplication \nouter, 1219  \nof polynomials, 878  \nrule of, 1179  \nscalar  \u00fcow,  675  ex.  \nprofessional wrestler, 563  ex.  \nprogram counter, 1068  \nprogramming, see dynamic programming, \nlinear programming \nprojection, 1032  \nproper ancestor, 1172  \nproper descendant, 1172  \nproper  pre\u00fbx,  959  \nproper subgroup, 921  \nproper subset ( \ue00a), 1154  \nproper  suf\u00fbx,  959  \nP-S CAN-1,  785  pr.  \nP-S CAN-1-A UX, 785  pr.  \nP-S CAN-2,  786  pr.  \nP-S CAN-2-A UX, 786  pr.  \nP-S CAN-3,  787  pr.  \nP-S CAN-DOWN , 787  pr.  \nP-S CAN-UP, 787  pr.  \npseudocode, 18,  21\u201324  \npseudoinverse, 843  \npseudoprime, 944\u2013945  \nPSEUDOPRIME , 945  \npseudorandom-number  generator,  129  \nP-TRANSPOSE , 770  ex.  \npublic key, 936,  939  \npublic-key  cryptosystem,  936\u2013942  \nPUSH, 255,  449  \npush onto a runtime stack, 202 pr. \npush-relabel  algorithms,  702  \nquadratic convergence, 1039  pr.  \nquadratic function, 31  \nquadratic residue, 954  pr.  \nquantile, 242  ex.  \nquery, 250  \nqueue, 254,  256\u2013257  \nin breadth-\u00fbrst  search,  554  \nimplemented by stacks, 258  ex.,  460  ex.  \nlinked-list  implementation  of,  264  ex.  \npriority, see priority queue quicksort, 182\u2013204  \nanalysis of, 187\u2013191,  193\u2013198  \naverage-case  analysis  of,  194\u2013198  \ncompared with insertion sort, 191  ex.  \ncompared with radix sort, 214  \nwith equal element values, 200 pr. \ngood  worst-case  implementation  of,  241  ex.  \nwith  median-of-3  method,  203  pr.  \nparallel algorithm for, 789  pr.  \nrandomized version of, 191\u2013193,  200  pr.,  \n203  pr.  \nstack depth of, 202 pr. \nand tail recursion, 202 pr. \nuse of insertion sort in, 198  ex.  \nworst-case  analysis  of,  193\u2013194  \nQUICKSORT , 183  \nQUICKSORT  0 , 200 pr. \nquotient, 905  \nR (set of real numbers), 1153  \nRabin-Karp  algorithm,  962\u2013967  \nRABIN-KARP-MATCHER , 966  \nrace condition, 765\u2013768  \nRACE-EXAMPLE , 766  \nradix sort, 211\u2013215  \ncompared with quicksort, 214  \nin computing  suf\u00fbx  arrays,  992 \nRADIX-SORT, 213  \nradix tree, 327  pr.  \nRAM, 26\u201327  \nRANDOM , 129  \nrandom-access  machine,  26\u201327  \nparallel, 789  \nrandom hashing, 286\u2013290  \nrandomized algorithm, 128\u2013129,  134\u2013140  \nand average inputs, 32  \ncomparison sort, 219  pr.  \nfor fuzzy sorting of intervals, 203  pr.  \nfor hiring problem, 135\u2013136  \nfor insertion into a binary search tree with \nequal keys, 327  pr.  \nfor  MAX-3-CNF  satis\u00fbability,  1120\u20131121  \nMiller-Rabin  primality  test,  945\u2013953  \nfor online caching, 807\u2013814  \nparallel, 789  pr.  \nfor partitioning, 192,  198  ex.,  200  pr.,  203  pr.  \nfor permuting an array, 136\u2013138  \nand probabilistic analysis, 134\u2013136  1282 Index \nrandomized algorithm, continued  \nquicksort, 191\u2013193,  200  pr.,  203  pr.  \nrandom hashing, 286\u2013290  \nrandomized rounding, 1136  \nfor searching a sorted compact list, 269  pr.  \nfor selection, 230\u2013236,  245  pr.  \nuniversal hashing, 286\u2013290  \nfor weighted majority, 1022  ex.  \nRANDOMIZED -HIRE-ASSISTANT , 135  \nRANDOMIZED -MARKING , 808  \nRANDOMIZED -PARTITION , 192  \nRANDOMIZED -PARTITION  0 , 200 pr. \nRANDOMIZED -QUICKSORT , 192  \nrelation to randomly built binary search \ntrees, 328  pr.  \nrandomized rounding, 1136  \nRANDOMIZED -SELECT , 230  \nrandomly built binary search tree, 328  pr.  \nRANDOMLY-PERMUTE , 136,  138  ex.  \nrandom-number  generator,  129  \nrandom oracle, 276  \nrandom permutation, 136\u2013138  \nuniform, 128,  136  \nRANDOM-SAMPLE , 139  ex.  \nRANDOM-SEARCH , 154  pr.  \nrandom variable, 1191\u20131196  \nindicator, see indicator random variable \nrange, 1162  \nof a matrix, 1224  pr.  \nrank \ncolumn, 1220  \nin computing  suf\u00fbx  arrays,  987  \nfull, 1220  \nof a matrix, 1220,  1224  pr.  \nof a node  in a disjoint-set  forest,  528,  \n533\u2013534,  540  ex.  \nof a number in an ordered set, 480  \nin order-statistic  trees,  482\u2013484,  485\u2013486  ex.  \nrow, 1220  \nrate of growth, 32  \nRB-D ELETE , 348  \nRB-D ELETE-FIXUP , 351  \nRB-E NUMERATE , 355  ex.  \nRB-I  NSERT , 338  \nRB-I  NSERT-FIXUP , 339  \nRB-J  OIN, 356  pr.  \nRB-T RANSPLANT , 347  \nRC6,  304  reachability in a graph ( g), 1165  \nreal numbers ( R), 1153  \nreconstructing an optimal solution, in dynamic \nprogramming, 390  \nrecord, 17,  157  \nrectangle, 495  ex.  \nRECTANGULAR -MATRIX-MULTIPLY , 374  \nrecurrence, 39,  76\u201380,  90\u2013125  \nAkra-Bazzi,  115\u2013119  \nalgorithmic, 77\u201378  \ninequalities in, 78  \nmaster, 101  \nsolution  by  Akra-Bazzi  method,  117\u2013118  \nsolution by master method, 101\u2013107  \nsolution  by  recursion-tree  method,  95\u2013101  \nsolution by substitution method, 90\u201395  \nrecursion, 34  \nrecursion tree, 42,  95\u2013101  \nin matrix-chain  multiplication  analysis,  \n388\u2013390  \nin merge sort analysis, 42\u201344  \nin proof of continuous master theorem, \n108\u2013110  \nin quicksort analysis, 188\u2013190  \nin rod cutting analysis, 366\u2013367  \nand the substitution method, 98  \nRECURSIVE-ACTIVITY-SELECTOR , 422  \nrecursive case, 34  \nof a divide-and-conquer  algorithm,  76  \nof a recurrence, 77  \nRECURSIVE-MATRIX-CHAIN , 389  \nred-black  properties,  331\u2013332  \nred-black  tree,  331\u2013359  \naugmentation of, 487\u2013489  \ncompared  with  B-trees,  497,  503  \ndeletion from, 346\u2013355  \nfor enumerating keys in a range, 355  ex.  \nheight of, 332  \ninsertion into, 338\u2013346  \nin interval trees, 490\u2013495  \njoining of, 356  pr.  \nleft-leaning,  358  \nmaximum key of, 334  \nminimum key of, 334  \nin order-statistic  trees,  480\u2013486  \npersistent, 355  pr.  \npredecessor in, 334  \nproperties of, 331\u2013335  Index 1283 \nred-black  tree,  continued  \nrelaxed, 334  ex.  \nrestructuring, 473  pr.  \nrotation in, 335\u2013338  \nsearching in, 334  \nsuccessor in, 334  \nsee also interval  tree,  order-statistic  tree  \nREDUCE , 784  pr.  \nreducibility, 1061\u20131063  \nreduction algorithm, 1046,  1062  \nreduction function, 1062  \nreduction, of an array, 784  pr.  \nreduction strategies, 1095\u20131098  \nreference, 23  \nre\u00fcexive  relation,  1158  \nre\u00fcexivity  of asymptotic  notation,  61  \nregion, feasible, 854  \nregister, 301,  756  \nregret, 1016  \nregular graph, 716  ex.,  740  pr.  \nregularity condition, 103,  112,  114  ex.  \nregularization, 1012,  1036\u20131037  \nreindexing summations, 1143\u20131144  \nreinforcement learning, 1004  \nrejection \nby an algorithm, 1053  \nby  a \u00fbnite  automaton,  968  \nrelation, 1158\u20131161  \nrelatively prime, 908  \nRELAX , 610  \nrelaxation \nof an edge, 609\u2013611  \nlinear programming, 1122  \nrelaxed  red-black  tree,  334  ex.  \nrelease time, 446  pr.,  816  pr.  \nremainder, 64,  905  \nremainder instruction, 26  \nrepeated squaring \nfor  all-pairs  shortest  paths,  652\u2013653  \nfor raising a number to a power, 934  \nrepeat , in pseudocode, 22 \nrepetition factor, of a string, 996  pr.  \nREPETITION-MATCHER , 996  pr.  \nrepresentative of a set, 520  \nRESET , 456  ex.  \nresidual capacity, 677,  681  \nresidual edge, 678  \nresidual network, 677\u2013681  residue, 64,  905,  954  pr.  \nrespecting a set of edges, 587  \nreturn , in pseudocode, 24  \nreturn instruction, 26  \nreweighting \nin all-pairs  shortest  paths,  662\u2013664  \nin single-source  shortest  paths,  641  pr.  \n\ufffd.n/-approximation  algorithm,  1104,  1120  \nRIGHT , 162  \nright child, 1173  \nright-conversion,  337  ex.  \nRIGHT-ROTATE , 336  \nright rotation, 335  \nright shift (o), 285  \nright subtree, 1173  \nrod cutting, 363\u2013373,  393  ex.  \nroot \nof a tree, 1171  \nof unity, 885\u2013886  \nof Z \ue003 \nn , 932  \nrooted tree, 1171  \nrepresentation of, 265\u2013268  \nrotation, 335\u2013338  \nrounding, 1122  \nrandomized, 1136  \nrow-major  order,  253,  396  \nrow rank, 1220  \nrow vector, 1215  \nRSA  public-key  cryptosystem,  936\u2013942  \nrule of product, 1179  \nrule of sum, 1178  \nrunning time, 29 \nasymptotic, 49  \naverage-case,  32,  128  \nbest-case,  34  ex.  \nexpected, 32,  129  \nof a graph algorithm, 548  \norder of growth, 32  \nparallel, 757\u2013758  \nand proper use of asymptotic notation, \n56\u201357  \nrate of growth, 32  \nworst-case,  31  \nSA, see suf\u00fbx  array  \nsabermetrics, 415  n. \nsafe edge, 587  \nSAME-COMPONENT , 522  1284 Index \nsample position, 997  pr.  \nsample space, 1185  \nsample  suf\u00fbx,  997  pr.  \nsampling, 139  ex.  \nSAT, 1074  \nsatellite data, 17,  157,  249  \nsatis\u00fbability,  1066,  1073\u20131079,  1120\u20131121,  \n1124  ex.  \nsatis\u00fbable  formula,  1043,  1074  \nsatisfying assignment, 1066,  1074  \nscalar, 1217  \nscalar  \u00fcow  product,  675  ex.  \nscaling \nin maximum  \u00fcow,  699  pr.  \nin single-source  shortest  paths,  641  pr.  \nscan, 784  pr.  \nSCAN, 785  pr.  \nscapegoat tree, 358  \nschedule, 1133  pr.  \nscheduler  for  task-parallel  computations,  753,  \n759\u2013761,  769  ex.,  789  \nscheduling, 446  pr.,  816  pr.,  1102  pr.,  1133  pr.  \nSchur complement, 825,  839  \nSchur complement lemma, 840  \nSCRAMBLE-SEARCH , 154  pr.  \nseam carving, 412  pr.  \nSEARCH , 250  \nsearching \nbinary search, 44  ex.,  777\u2013778  \nin binary search trees, 316\u2013317  \nin B-trees,  504\u2013505  \nin chained hash tables, 278  \nin direct-address  tables,  274  \nfor an exact interval, 495  ex.  \nin interval trees, 492\u2013494  \nlinear search, 25  ex.  \nin linked lists, 260  \nin open-address  hash  tables,  294  \nin red-black  trees,  334  \nin sorted compact lists, 269  pr.  \nof static sets, 308  pr.  \nin an unsorted array, 154  pr.  \nsearch list, see linked list \nsearch tree, see balanced search tree, binary \nsearch  tree,  B-tree,  exponential  search  \ntree, interval tree, optimal binary search \ntree,  order-statistic  tree,  red-black  tree,  \nsplay  tree,  2-3  tree,  2-3-4  tree  secondary storage \nsearch tree for, 497\u2013519  \nstacks on, 517  pr.  \nsecond-best  minimum  spanning  tree,  599  pr.  \nsecret key, 936,  939  \nSELECT , 237  \nused in quicksort, 241  ex.  \nSELECT3, 247  pr.  \nselection, 227  \nof activities, 418\u2013425  \nand comparison sorts, 241  \nin order-statistic  trees,  481\u2013482  \nrandomized, 230\u2013236,  245  pr.  \nin worst-case  linear  time,  236\u2013243  \nselection sort, 33  ex.,  53  ex.  \nselector vertex, 1087  \nself-loop,  1164  \nsemiconnected graph, 581  ex.  \nsemiring, 651  n.,  669  \nsentinel \nin linked lists, 261\u2013264  \nin red-black  trees,  332  \nsequence ( h i), 1162  \nbitonic, 644  pr.  \ninversion in, 134  ex.,  486  ex.  \nprobe, 293  \nsequential consistency, 756  \nserial algorithm versus parallel algorithm, 748  \nserial projection, 750,  753  \nseries, 1141\u20131144  \nstrands logically in, 756  \nseries-parallel  composition  of parallel  traces,  \n762  \u00fbg.  \nset (f g), 1153\u20131158  \ncardinality ( j j), 1156  \ncollection of, 1156  \nconvex, 675  ex.  \ndifference ( \ue003), 1154  \nindependent, 1099  pr.  \nintersection ( \\), 1154  \nmember ( 2), 1153  \nnot a member ( \u2026), 1153  \npartially ordered, 1160  \nstatic, 308  pr.  \nunion ( [), 1154  \nset-covering  problem,  1115\u20131119  \nweighted, 1132  pr.  \nset-partition  problem,  1098  ex.  Index 1285 \nSHA-256,  291  \nshared memory, 748  \nsharks with lasers, 850  \nShell\u2019s  sort,  48  \nshift \nleft (n), 305  \nright (o), 285  \nin string matching, 957  \nshift instruction, 27  \nshort-circuiting  operator,  24  \nSHORTEST-PATH,  1045  \nshortest paths, 604\u2013669  \nall-pairs,  605,  646\u2013669  \nBellman-Ford  algorithm  for,  612\u2013616  \nwith bitonic shortest paths, 644  pr.  \nand  breadth-\u00fbrst  search,  558\u2013561,  605  \nconvergence property of, 611,  634\u2013635  \nand cycles, 607\u2013608  \nand difference constraints, 626\u2013632  \nDijkstra\u2019s  algorithm  for,  620\u2013626  \nin a directed acyclic graph, 616\u2013619  \ndistance in ( \u0131), 558  \nin \ufffd-dense  graphs,  668  pr.  \nestimate of, 609  \nFloyd-Warshall  algorithm  for,  655\u2013659,  \n662  ex.  \nGabow\u2019s  scaling  algorithm  for,  641  pr.  \nJohnson\u2019s  algorithm  for,  662\u2013667  \nas a linear program, 861  \nand longest paths, 1042  \nby matrix multiplication, 648\u2013655,  668\u2013669  \nand  negative-weight  cycles,  606\u2013607,  \n614\u2013615,  655  ex.,  662  ex.  \nwith  negative-weight  edges,  606\u2013607  \nno-path  property  of,  611,  634  \noptimal substructure of, 605\u2013606,  649,  \n655\u2013656  \npath-relaxation  property  of,  611,  635  \npredecessor in ( \ufffd ), 608  \npredecessor-subgraph  property  of,  611,  \n637\u2013638  \nproblem variants, 605  \nand relaxation, 609\u2013611  \nby repeated squaring, 652\u2013653  \nsingle-destination,  605  \nsingle-pair,  385,  605  single-source,  604\u2013645  \ntree of, 608\u2013609,  635\u2013638  \ntriangle inequality of, 611,  633  \nin an unweighted graph, 385,  558  \nupper-bound  property  of,  611,  633\u2013634  \nin a weighted graph, 604  \nweight in ( \u0131), 604  \nshortest remaining processing time (SRPT), \n816  pr.  \nsibling, 1172  \nsignature, 938  \nsimple cycle, 1165\u20131166  \nsimple graph, 1166  \nsimple path, 1165  \nlongest, 385,  1042  \nSIMPLER-RANDOMIZED -SELECT , 243  pr.  \nsimplex, 857  \nsimplex algorithm, 626,  857,  876  \nsimulation, 173,  181  \nsingle-destination  shortest  paths,  605  \nsingle-pair  shortest  path,  385,  605  \nas a linear program, 861  \nsingle-source  shortest  paths,  604\u2013645  \nBellman-Ford  algorithm  for,  612\u2013616  \nwith bitonic shortest paths, 644  pr.  \nand difference constraints, 626\u2013632  \nDijkstra\u2019s  algorithm  for,  620\u2013626  \nin a directed acyclic graph, 616\u2013619  \nin \ufffd-dense  graphs,  668  pr.  \nGabow\u2019s  scaling  algorithm  for,  641  pr.  \nand longest paths, 1042  \nsingleton, 1156  \nsingly connected graph, 572  ex.  \nsingly linked list, 259  \nsingular matrix, 1220  \nsingular value decomposition, 849  \nsink vertex, 553  ex.,  671,  674  \nsize \nof an  algorithm\u2019s  input,  28,  903\u2013904,  \n1049\u20131052  \nof a boolean combinational circuit, 1067  \nof a clique, 1081  \nof a group, 917  \nof a set, 1156  \nof a vertex cover, 1084,  1106  \nskip list, 359  1286 Index \nslackness \ncomplementary, 873  pr.  \nparallel, 758  \nslot \nof a direct-access  table,  273  \nof a hash table, 275  \nSLOW-APSP,  652  \nsmoothed analysis, 876  \nsolution \nto an abstract problem, 1049  \nto a computational problem, 6 \nto a concrete problem, 1049  \nfeasible, 627,  854  \ninfeasible, 854  \noptimal, 854  \nto a system of linear equations, 820  \nsorted linked list, 259  \nsorting, 5, 17\u201321,  34\u201344,  51\u201353,  56\u201357,  \n157\u2013226,  775\u2013782  \nbubblesort, 46  pr.  \nbucket sort, 215\u2013219  \ncolumnsort, 222 pr. \ncomparison sort, 205  \ncounting sort, 208\u2013211  \nfuzzy, 203  pr.  \nheapsort, 161\u2013181  \nin place, 158,  220  pr.  \ninsertion sort, 12\u201313,  17\u201321,  51\u201353,  56\u201357  \nk-sorting,  221  pr.  \nlexicographic, 327  pr.,  986  n. \nin linear time, 208\u2013219,  220  pr.  \nlower bounds for, 205\u2013208,  225  \nmerge sort, 12\u201313,  34\u201344,  57,  775\u2013782  \nby  an  oblivious  compare-exchange  \nalgorithm, 222 pr. \nparallel merge sort, 775\u2013782  \nparallel quicksort, 789  pr.  \nprobabilistic lower bound for, 219  pr.  \nquicksort, 182\u2013204  \nradix sort, 211\u2013215  \nselection sort, 33  ex.,  53  ex.  \nShell\u2019s  sort,  48  \nstable, 210  \ntable of running times, 159  \ntopological, 573\u2013576  \nusing a binary search tree, 326  ex.  \nwith  variable-length  items,  220 pr. \n0-1  sorting  lemma,  222 pr. sorting network, 789  \nsource vertex, 554,  605,  671,  674  \nspan, 757  \nspan law, 758  \nspanning tree, 585  \nbottleneck, 601  pr.  \nmaximum, 1134  pr.  \nveri\u00fbcation  of,  603  \nsee also minimum spanning tree \nsparse graph, 549  \nall-pairs  shortest  paths  for,  662\u2013667  \nand  Prim\u2019s  algorithm,  599  pr.  \nsparse matrix, 81  \nspawn , in pseudocode, 752\u2013754  \nspawning, 753  \nspeedup, 758  \nof a randomized parallel algorithm, 789  pr.  \nspindle in a disk drive, 498  \nspine  of a string-matching  automaton,  970  \nsplay tree, 359,  478  \nsplicing \nin a binary search tree, 324\u2013325  \nin a linked list, 260\u2013261  \nspline, 847  pr.  \nsplitting \nof B-tree  nodes,  506\u2013508  \nof 2-3-4  trees,  518  pr.  \nsplitting summations, 1148\u20131149  \nspurious hit, 965  \nsquare matrix, 1215  \nsquare of a directed graph, 553  ex.  \nsquare root, modulo a prime, 954  pr.  \nsquaring, repeated \nfor  all-pairs  shortest  paths,  652\u2013653  \nfor raising a number to a power, 934  \nSRPT (shortest remaining processing time), \n816  pr.  \nstability \nnumerical, 819,  821  \nof sorting algorithms, 210  \nstable-marriage  problem,  716\u2013723  \nstable matching, 716  \nstable-roommates  problem,  723  ex.  \nstack, 254\u2013255  \nimplemented by queues, 258  ex.  \nimplemented with a priority queue, 178  ex.  \nlinked-list  implementation  of,  264  ex.  Index 1287 \nstack, continued  \noperations analyzed by accounting method, \n454\u2013455  \noperations analyzed by aggregate analysis, \n449\u2013451  \noperations analyzed by potential method, \n457\u2013458  \nfor procedure execution, 202 pr. \non secondary storage, 517  pr.  \nSTAC  K-EMPTY , 255  \nstandard deviation, 1195  \nstandard encoding ( h i), 1052  \nstandard form of a linear program, 854  \nstart state, 967  \nstart time, 418  \nstate  of a \u00fbnite  automaton,  967  \nstatic graph, 522  \nstatic hashing, 282,  284\u2013286  \nstatic set, 308  pr.  \nstencil, 787  pr.  \nStirling\u2019s  approximation,  67  \nstochastic gradient descent, 1040  pr.  \nSTOOGE-SORT, 202 pr. \nstore instruction, 26,  756  \nstrand, 754  \nmutually noninterfering, 767  \nStrassen\u2019s  algorithm,  85\u201390,  124\u2013125  \nparallel algorithm for, 773\u2013774  \nstreaks, 144\u2013150,  153  ex.  \nstreaming algorithms, 818  \nstrict Fibonacci heap, 478  \nstrictly decreasing, 63  \nstrictly increasing, 63  \nstring, 957,  1179  \ninterpreted as a key, 290\u2013291,  292  ex.  \nstring matching, 957\u20131002  \nbased on repetition factors, 996  pr.  \nby  \u00fbnite  automata,  967\u2013975  \nwith gap characters, 961  ex.,  975  ex.  \nKnuth-Morris-Pratt  algorithm  for,  975\u2013985  \nnaive algorithm for, 960\u2013962  \nRabin-Karp  algorithm  for,  962\u2013967  \nby  suf\u00fbx  arrays,  985\u2013996  \nstring-matching  automaton,  968\u2013975  \nstrongly connected component, 1166  \ndecomposition into, 576\u2013581  \nSTRONGLY-CONNECTED-COMPONENTS , 577  strongly connected graph, 1166  \nsubarray ( W), 19,  23  \nsubgraph, 1166  \nequality, 724  \npredecessor, see predecessor subgraph \nsubgraph-isomorphism  problem,  1098  ex.  \nsubgroup, 921\u2013923  \nsubpath, 1165  \nsubproblem graph, 370\u2013371  \nsubroutine, 23,  26,  29  n. \nsubsequence, 394  \nsubset ( \u0dc2), 1154,  1156  \nSUBSET-SUM,  1092  \nsubset-sum  problem  \napproximation algorithm for, 1124\u20131130  \nNP-completeness  of,  1092\u20131095  \nwith unary target, 1098  ex.  \nsubstitution method, 90\u201395  \nin quicksort analysis, 191  ex.,  193\u2013194  \nand recursion trees, 98  \nin selection analysis, 240\u2013241  \nsubstring, 962,  1179  \nrank of, 987  \nsubtracting  a low-order  term,  in the  substitution  \nmethod, 92\u201393  \nsubtract instruction, 26  \nsubtraction of matrices, 1218  \nsubtree, 1172  \nmaintaining  size  of,  in order-statistic  trees,  \n484\u2013485  \nsuccess, in a Bernoulli trial, 1196  \nsuccessor \nin binary search trees, 318\u2013319  \n\u00fbnding  i th,  of a node  in an  order-statistic  \ntree, 486  ex.  \nin linked lists, 259  \nin red-black  trees,  334  \nSUCCESSOR , 250  \nsuch that ( W), 1154  \nsuf\u00fbx  (i), 959  \nsuf\u00fbx  array  (SA), 985\u2013996,  997  pr.  \nsuf\u00fbx  function,  968  \nsuf\u00fbx-function  inequality,  971  \nsuf\u00fbx-function  recursion  lemma,  972  \nsum . P  /, 1140  \nCartesian, 885  ex.  \nof matrices, 1217  1288 Index \nsum . P  /, continued  \nof polynomials, 877  \nrule of, 1178  \ntelescoping, 1143  \nSUM-ARRAY , 25  ex.  \nSUM-ARRAYS , 783  pr.  \nSUM-ARRAYS 0 , 783  pr.  \nsummation, 1140\u20131152  \napproximated by integrals, 1150  \nin asymptotic notation, 58,  1141  \nbounding, 1145\u20131152  \nformulas and properties of, 1140\u20131145  \nlinearity of, 1141  \nlower bounds on, 1148,  1150  \nsplitting, 1148\u20131149  \nsummation lemma, 887  \nsupercomputer, 748  \nsuperpolynomial time, 1042  \nsupersink, 674  \nsupersource, 674  \nsupervised learning, 1004  \nsurjection, 1162  \nSVD, 849  \nsymbol table, 272  \nsymmetric difference, 706  \nsymmetric-key  cryptosystem,  941  \nsymmetric matrix, 1217  \nsymmetric  positive-de\u00fbnite  matrix,  838\u2013841  \ninverse of, 784  pr.  \nsymmetric relation, 1159  \nsymmetry of \u201a-notation,  61  \nsync , in pseudocode, 752\u2013754  \nsystem of difference constraints, 626\u2013632  \nsystem of linear equations, 784  pr.,  819\u2013833,  \n847  pr.,  1034\u20131035  \nTABLE-DELETE , 467  \nTABLE-I NSERT , 462  \ntail \nof a binomial distribution, 1203\u20131210  \nof a linked list, 259  \nof a queue, 256  \ntail recursion, 202  pr.,  422  \ntarget, 1092  \nTarjan\u2019s  of\u00fcine  lowest-common-ancestors  \nalgorithm, 543  pr.  \ntask parallelism, 749  \nsee also parallel algorithm Task Parallel Library, 750  \ntask-parallel  scheduling,  759\u2013761,  769  ex.  \ntask scheduling, 446  pr.,  816  pr.  \ntautology, 1060  ex.  \nTaylor series, 329  pr.  \ntelescoping series, 1143  \ntelescoping sum, 1143  \ntermination of a loop invariant, 20 \ntesting \nof primality, 942\u2013953,  956  \nof pseudoprimality, 944\u2013945  \ntext, 957  \nTheta-notation  (\u201a/, 33,  51,  54  \u00fbg.,  56  \nthread, 748  \nThreading Building Blocks, 750  \nthread parallelism, 748  \n3-CNF,  1076  \n3-CNF-SAT,  1076  \n3-CNF  satis\u00fbability,  1076\u20131079  \napproximation algorithm for, 1120\u20131121  \nand  2-CNF  satis\u00fbability,  1043  \n3-COLOR,  1100  pr.  \n3-conjunctive  normal  form,  1076  \nthreshold constant, 77  \ntight bounds, 56  \ntime, see running time \ntime domain, 877  \ntime-memory  trade-off,  367  \ntimestamp, 564,  571  ex.  \nT \u0152i  W \ufffd (suf\u00fbx  of a text),  986  \nT \u0152  W k\ufffd (pre\u00fbx  of a text),  959  \nto, in pseudocode, 22 \ntop-down  method,  for  dynamic  programming,  \n368  \ntop of a stack, 254  \ntopological sort, 573\u2013576  \nin computing  single-source  shortest  paths  in \na dag, 616  \nTOPOLOGICAL -SORT, 573  \ntotal order, 1160  \ntotal path length, 328  pr.  \ntotal preorder, 1160  \ntotal relation, 1160  \ntour \nbitonic, 407  pr.  \nEuler, 583  pr.,  1043  \nof a graph, 1090  Index 1289 \ntrace, 754\u2013756  \nseries-parallel  composition  of,  762  \u00fbg.  \ntrack in a disk drive, 498  \ntractability, 1042  \ntrailing pointer, 321  \ntraining data, 1003  \ntraining phase, 1003  \ntransition function, 967,  973\u2013974  \ntransitive closure, 659\u2013661  \nand boolean matrix multiplication, 838  ex.  \nof dynamic graphs, 667  pr.,  669  \nTRANSITIVE-CLOSURE , 660  \ntransitive relation, 1159  \ntransitivity of asymptotic notation, 61  \nTRANSPLANT , 324,  346  \ntranspose \nconjugate, 838  ex.  \nof a directed graph, 553  ex.  \nof a matrix, 1214  \ntranspose symmetry of asymptotic notation, 62  \ntraveling-salesperson  problem  \napproximation algorithm for, 1109\u20131115  \nbitonic euclidean, 407  pr.  \nbottleneck, 1115  ex.  \nNP-completeness  of,  1090\u20131092  \nwith the triangle inequality, 1110\u20131113  \nwithout the triangle inequality, 1113\u20131114  \ntraversal of a tree, 314,  320  ex.,  1112  \ntreap, 358  \ntree, 1169\u20131176  \nAA-trees,  358  \nA VL, 357  pr.,  358  \nbinary, see binary tree \nbisection of, 1177  pr.  \nbreadth-\u00fbrst,  555,  561  \nB-trees,  497\u2013519  \ndecision, 206\u2013207,  219  pr.  \ndepth-\u00fbrst,  564  \ndiameter of, 563  ex.  \ndynamic, 478  \nfree, 1167,  1169\u20131171  \nfull walk of, 1112  \nfusion, 226,  478  \nheap, 161\u2013181  \nheight-balanced,  357  pr.  \nheight of, 1173  \ninterval, 489\u2013495  \nk-neighbor,  358  left-leaning  red-black  binary  search  trees,  \n358  \nminimum spanning, see minimum spanning \ntree \noptimal binary search, 400\u2013407  \norder-statistic,  480\u2013486  \nparse, 1077  \nrecursion, 42,  95\u2013101  \nred-black,  see red-black  tree  \nrooted, 265\u2013268,  1171  \nscapegoat, 358  \nsearch, see search tree \nshortest-paths,  608\u2013609,  635\u2013638  \nspanning, see minimum spanning tree, \nspanning tree \nsplay, 359,  478  \ntreap, 358  \n2-3,  358,  519  \n2-3-4,  502,  518  pr.  \nvan Emde Boas, 478  \nwalk of, 314,  320  ex.,  1112  \nweight-balanced  trees,  358  \nTREE-DELETE , 325,  326  ex.,  346\u2013347  \ntree edge, 561,  564,  569  \nTREE-I NSERT , 321,  338  \nTREE-MAXIMUM , 318  \nTREE-MINIMUM , 318  \nTREE-PREDECESSOR , 319  \nTREE-SEARCH , 316  \nTREE-SUCCESSOR , 319  \ntree walk, 314,  320  ex.,  1112  \nTRE-QUICKSORT , 202 pr. \ntrial division, 943  \ntriangle inequality, 1110  \nfor shortest paths, 611,  633  \ntriangular matrix, 1216  \ntrichotomy, interval, 490  \ntrichotomy property of real numbers, 62  \ntridiagonal linear systems, 847  pr.  \ntridiagonal matrix, 1216  \ntrie (radix tree), 327  pr.  \nTRIM, 1127  \ntrimming a list, 1126  \ntrivial divisor, 904  \ntropical semiring, 651  n. \ntruth assignment, 1066,  1073  \ntruth table, 1065  \nTSP, 1091  1290 Index \ntuple, 1157  \ntwiddle factor, 891  \n2-CNF-SAT,  1080  ex.  \n2-CNF  satis\u00fbability,  1080  ex.  \nand  3-CNF  satis\u00fbability,  1043  \ntwo-pass  method,  529  \n2-3-4  tree,  502,  518  pr.  \n2-3  tree,  358,  519  \nunary, 1050  \nunbounded competitive ratio, 804  \nunbounded linear program, 854  \nuncle, 340  \nunconditional branch instruction, 26  \nunconstrained gradient descent, 1023\u20131031  \nuncountable set, 1156  \nunderdetermined system of linear equations, \n820  \nunder\u00fcow  \nof a queue, 256  \nof a stack, 255  \nundirected graph, 1164  \narticulation point of, 582  pr.  \nbiconnected component of, 582  pr.  \nbridge of, 582  pr.  \nclique in, 1081  \ncoloring of, 1100  pr.,  1176  pr.  \ncomputing a minimum spanning tree in, \n585\u2013603  \nd -regular,  716  ex.,  740  pr.  \ngrid, 697  pr.  \nhamiltonian, 1056  \nindependent set of, 1099  pr.  \nmatching in, 693\u2013697,  704\u2013743  \nnonhamiltonian, 1056  \nvertex cover of, 1084,  1106  \nsee also graph \nundirected version of a directed graph, 1167  \nuniform family of hash functions, 287  \nuniform hash function, 278  \nuniform hashing, 295  \nuniform probability distribution, 1186\u20131187  \nuniform random permutation, 128,  136  \nunion \nof languages, 1052  \nof linked lists, 264  ex.  \nof sets ( [), 1154  UNION , 264  ex.,  521  \ndisjoint-set-forest  implementation  of,  530  \nlinked-list  implementation  of,  524\u2013526  \nunion by rank, 528  \nunit ( 1), 905  \nunit  lower-triangular  matrix,  1216  \nunit  upper-triangular  matrix,  1216  \nunit vector, 1215  \nuniversal family of hash functions, 286\u2013287  \nuniversal hash function, 278  \nuniversal hashing, 286\u2013290,  309  pr.  \nuniversal sink, 553  ex.  \nuniverse, 273,  1155  \nunmatched vertex, 693,  705  \nunsorted linked list, 259  \nunstable matching, 717  \nunsupervised learning, 1004  \nuntil , in pseudocode, 22 \nunweighted longest simple paths, 385  \nunweighted shortest paths, 385  \nupper bound, 54  \nupper-bound  property,  611,  633\u2013634  \nupper median, 227  \nupper-triangular  matrix,  1216  \nvalid shift, 957  \nvalue \nof a \u00fcow,  672  \nof a function, 1161  \nobjective, 854  \nVandermonde matrix, 881,  1223  pr.  \nvan Emde Boas tree, 478  \nVar \u0152 \ufffd, see variance \nvariable \ndecision, 851  \nin pseudocode, 22 \nrandom, 1191\u20131196  \nsee also indicator random variable \nvariable-length  code,  432  \nvariable-length  input  \ninterpreted as a key, 290\u2013291  \nto the wee hash function, 306  \nvariance, 1194  \nof a binomial distribution, 1200  \nof a geometric distribution, 1198  \nvector, 1215,  1219\u20131221  \nconvolution of, 880  "}
